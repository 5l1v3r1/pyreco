__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Imposm documentation build configuration file, created by
# sphinx-quickstart on Thu Feb 17 15:23:25 2011.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Imposm'
copyright = u'2011, Oliver Tonnhofer, Omniscale'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '2.5'
# The full version, including alpha/beta/rc tags.
release = '2.5.1a'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'sphinxdoc'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'imposmdoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'imposm.tex', u'Imposm Documentation',
   u'Oliver Tonnhofer', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'imposm', u'Imposm Documentation',
     [u'Oliver Tonnhofer'], 1)
]

########NEW FILE########
__FILENAME__ = example_imposm_test_conf
# update and save as imposm_test_conf.py to enable tests with PostGIS DB
db_conf = dict(
    db='osm',
    host='localhost',
    port=5432,
    user='osm',
    password='osm',
    sslmode='allow',
    prefix='osm_test_',
    proj='epsg:4326',
)

########NEW FILE########
__FILENAME__ = app
# Copyright 2011 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import with_statement
import glob
import sys
import os
import optparse
import logging

import multiprocessing
from imposm.util import setproctitle

try:
    import shapely.speedups
    if shapely.speedups.available:
        print 'Enabling Shapely speedups.'
        shapely.speedups.enable()
except ImportError:
    try:
        import shapely_speedups
        print 'Patching Shapely.'
        shapely_speedups.patch_shapely()
    except ImportError:
        pass

import imposm.config
import imposm.mapping
import imposm.util
import imposm.version
from imposm.writer import ImposmWriter
from imposm.db.config import DB, check_connection
from imposm.cache import OSMCache
from imposm.reader import ImposmReader
from imposm.mapping import TagMapper
from imposm.geom import load_geom

try:
    n_cpu = multiprocessing.cpu_count()
except NotImplementedError:
    n_cpu = 2

def setup_logging(debug=False):
    imposm_log = logging.getLogger('imposm')
    imposm_log.setLevel(logging.DEBUG if debug else logging.INFO)

    ch = logging.StreamHandler(sys.stdout)
    ch.setLevel(logging.DEBUG)
    formatter = logging.Formatter(
        "[%(asctime)s] %(name)s - %(levelname)s - %(message)s")
    ch.setFormatter(formatter)
    imposm_log.addHandler(ch)

__version__ = imposm.version.__version__

def main(argv=None):
    setproctitle('imposm: main')

    usage = '%prog [options] [input]...'
    parser = optparse.OptionParser(usage=usage, add_help_option=False,
        version="%prog " + __version__)
    parser.add_option('--help', dest='help', action='store_true',
        default=False, help='show this help message and exit')
    parser.add_option('--debug', action='store_true',
        default=False, help='show debug information')
    parser.add_option('--quiet', action='store_true',
        default=False, help='only print progress every 60 seconds')

    parser.add_option('-m', '--mapping-file', dest='mapping_file',
        metavar='<file>')
    parser.add_option('-h', '--host', dest='host', metavar='<host>')
    parser.add_option('-p', '--port', dest='port', metavar='<port>')
    parser.add_option('-d', '--database', dest='db', metavar='<dbname>')
    parser.add_option('-U', '--user', dest='user', metavar='<user>')
    parser.add_option('--proj', dest='proj', metavar='EPSG:900913')
    parser.add_option('--connection', dest='connection',
        help="connection string like postgis://user:pass@host:port/database,"
             " this overwrites the -h/-p/-d/-U options")

    parser.add_option('-c', '--concurrency', dest='concurrency', metavar='N',
                      type='int', default=n_cpu)

    parser.add_option('--merge-cache', dest='merge_cache', default=False,
        action='store_true')
    parser.add_option('--overwrite-cache', dest='overwrite_cache', default=False,
        action='store_true')
    parser.add_option('--cache-dir', dest='cache_dir', default='.',
        help="path where node/ways/relations should be cached [current working dir]")


    parser.add_option('--table-prefix',
        dest='table_prefix', default=None, metavar='osm_new_',
        help='prefix for imported tables')
    parser.add_option('--table-prefix-production',
        dest='table_prefix_production', default='osm_', metavar='osm_',
        help='prefix for production tables')
    parser.add_option('--table-prefix-backup',
        dest='table_prefix_backup', default='osm_old_', metavar='osm_old_',
        help='prefix for backup tables')



    parser.add_option('--read', dest='read', default=False,
        action='store_true')
    parser.add_option('--write', dest='write', default=False,
        action='store_true')
    parser.add_option('--optimize', dest='optimize', default=False,
        action='store_true')
    parser.add_option('--deploy-production-tables', dest='deploy_tables', default=False,
        action='store_true', help='remove backup tables, move production tables '
        'to backup tables and move import tables to production tables')
    parser.add_option('--recover-production-tables', dest='recover_tables', default=False,
        action='store_true', help='move production tables to import tables and'
        'move backup tables to production tables')
    parser.add_option('--remove-backup-tables', dest='remove_backup_tables', default=False,
        action='store_true')

    parser.add_option('-n', '--dry-run', dest='dry_run', default=False,
        action='store_true')

    parser.add_option('--limit-to', dest='limit_to', metavar='file',
        help='limit imported geometries to (multi)polygons in EPSG:4326')

    (options, args) = parser.parse_args(argv)

    setup_logging(debug=options.debug)

    if (argv and len(argv) == 0) or (not argv and len(sys.argv) == 1):
        options.help = True

    if not any([options.read, options.write, options.optimize, options.deploy_tables,
        options.recover_tables, options.remove_backup_tables]):
        options.help = True

    if options.help:
        parser.print_help()
        sys.exit(1)

    if options.quiet:
        logger = imposm.util.QuietProgressLog
        logger_parser = imposm.util.QuietParserProgress
    else:
        logger = imposm.util.ProgressLog
        logger_parser = imposm.util.ParserProgress

    if options.proj:
        if ':' not in options.proj:
            print 'ERROR: --proj should be in EPSG:00000 format'
            sys.exit(1)
        # check proj if meter_to_mapunit needs to do anything
        if options.proj.lower() == 'epsg:4326':
            imposm.mapping.import_srs_is_geographic = True

    mapping_file = os.path.join(os.path.dirname(__file__),
        'defaultmapping.py')
    if options.mapping_file:
        print 'loading %s as mapping' % options.mapping_file
        mapping_file = options.mapping_file

    polygon = None
    if options.limit_to:
        logger.message('## reading --limit-to %s' % options.limit_to)
        polygon_timer = imposm.util.Timer('reading', logger)
        polygon = load_geom(options.limit_to)
        polygon_timer.stop()
        if polygon is None:
            print 'ERROR: No valid polygon/multipolygon found'
            sys.exit(1)

    mappings = {}
    execfile(mapping_file, mappings)
    tag_mapping = TagMapper([m for n, m in mappings.iteritems()
        if isinstance(m, imposm.mapping.Mapping)], limit_to=polygon)

    if 'IMPOSM_MULTIPOLYGON_REPORT' in os.environ:
        imposm.config.imposm_multipolygon_report = float(os.environ['IMPOSM_MULTIPOLYGON_REPORT'])
    if 'IMPOSM_MULTIPOLYGON_MAX_RING' in os.environ:
        imposm.config.imposm_multipolygon_max_ring = int(os.environ['IMPOSM_MULTIPOLYGON_MAX_RING'])

    if options.table_prefix:
        options.table_prefix = options.table_prefix.rstrip('_') + '_'
    if options.table_prefix_production:
        options.table_prefix_production = options.table_prefix_production.rstrip('_') + '_'
    if options.table_prefix_backup:
        options.table_prefix_backup = options.table_prefix_backup.rstrip('_') + '_'

    if (options.write or options.optimize or options.deploy_tables
        or options.remove_backup_tables or options.recover_tables):
        db_conf = mappings['db_conf']
        if options.table_prefix:
            db_conf.prefix = options.table_prefix
        else:
            options.table_prefix = db_conf.prefix.rstrip('_') + '_'

        if options.connection:
            from imposm.db.config import db_conf_from_string
            db_conf = db_conf_from_string(options.connection, db_conf)
        else:
            db_conf.host = options.host or db_conf.host
            db_conf.port = options.port or getattr(db_conf, 'port', None) #backw. compat
            if not options.db:
                parser.error('-d/--database is required for this mode')
            db_conf.db = options.db or db_conf.db
            db_conf.user = options.user or db_conf.user
            if options.user:
                from getpass import getpass
                db_conf.password = getpass('password for %(user)s at %(host)s:' % db_conf)

        if options.proj:
            db_conf.proj = options.proj

    imposm_timer = imposm.util.Timer('imposm', logger)

    if options.read:
        if not options.merge_cache:
            cache_files = glob.glob(os.path.join(options.cache_dir, 'imposm_*.cache'))
            if cache_files:
                if not options.overwrite_cache:
                    print (
                        "ERROR: found existing cache files in '%s'. "
                        'Remove --read option to use the existing cache '
                        'or use --overwrite-cache or --merge-cache to '
                        'overwrite or merge it.'
                        % os.path.abspath(options.cache_dir)
                    )
                    sys.exit(2)
                for cache_file in cache_files:
                    os.unlink(cache_file)

    cache = OSMCache(options.cache_dir)

    if options.read:
        read_timer = imposm.util.Timer('reading', logger)

        if not args:
            print "no file(s) supplied"
            sys.exit(2)

        if options.write:
            err = check_connection(db_conf)
            if err:
                logger.message("ERROR: unable to connect to database. Check your DB settings.\n{0}".format(err))
                sys.exit(2)

        reader = ImposmReader(tag_mapping, cache=cache, merge=options.merge_cache,
            pool_size=options.concurrency, logger=logger_parser)
        reader.estimated_coords = imposm.util.estimate_records(args)
        for arg in args:
            logger.message('## reading %s' % arg)
            reader.read(arg)
        read_timer.stop()

    if options.write:
        db = DB(db_conf)
        write_timer = imposm.util.Timer('writing', logger)

        logger.message('## dropping/creating tables')
        if not options.dry_run:
            db.create_tables(tag_mapping.mappings)

        logger.message('## writing data')
        # create views so we can access the table during the insert, ignore
        # errors for missing tables (i.e. generalized tables)
        if not options.dry_run:
            db.create_views(mappings, ignore_errors=True)
            db.commit()

        writer = ImposmWriter(tag_mapping, db, cache=cache,
            pool_size=options.concurrency, logger=logger,
            dry_run=options.dry_run)
        writer.relations()
        writer.ways()
        writer.nodes()

        if not options.dry_run:
            db = DB(db_conf)

            logger.message('## creating generalized tables')
            generalized_timer = imposm.util.Timer('generalizing tables', logger)
            db.create_generalized_tables(mappings)
            generalized_timer.stop()

            logger.message('## creating union views')
            view_timer = imposm.util.Timer('creating views', logger)
            db.create_views(mappings)
            view_timer.stop()

            logger.message('## creating geometry indexes')
            index_timer = imposm.util.Timer('creating indexes', logger)
            db.post_insert(mappings);
            index_timer.stop()

            logger.message('## post-processing tables')
            valid_timer = imposm.util.Timer('post-processing tables', logger)
            db.postprocess_tables(mappings)
            valid_timer.stop()

            db.commit()

        write_timer.stop()

    if options.optimize:
        db = DB(db_conf)
        optimize_timer = imposm.util.Timer('optimizing', logger)
        logger.message('## optimizing tables')
        db.optimize(mappings)
        optimize_timer.stop()

    if options.recover_tables:
        assert not options.deploy_tables, ('cannot swap and recover production '
            'tables at the same time')
        options.table_prefix, options.table_prefix_backup = \
            options.table_prefix_backup, options.table_prefix

    if options.deploy_tables or options.recover_tables:
        db = DB(db_conf)
        db.swap_tables(options.table_prefix,
            options.table_prefix_production, options.table_prefix_backup)
        db.remove_views(options.table_prefix)
        db.db_conf.prefix = options.table_prefix_production
        db.create_views(mappings)
        db.commit()

    if options.remove_backup_tables:
        db = DB(db_conf)
        db.remove_tables(options.table_prefix_backup)
        db.commit()

    imposm_timer.stop()

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = base
# Copyright 2011 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import with_statement

import itertools
from imposm.merge import multimerge

__all__ = [
    'Node', 'Way', 'Relation',
]

class Node(object):
    def __init__(self, osm_id, tags, coord):
        self.osm_id = osm_id
        self.tags = tags
        self.coord = coord
    
    def __repr__(self):
        return 'Node(%r, %r, %r)' % (self.osm_id, self.tags, self.coord)

    def merge(self, tags, coord):
        pass

    def to_tuple(self):
        return self.osm_id, self.tags, self.coord

class Way(object):
    def __init__(self, osm_id, tags, refs, inserted=False):
        self.osm_id = osm_id
        self.tags = tags
        self.refs = refs
        self.partial_refs = None
        if refs and isinstance(refs[0], list):
            self.refs = refs[0]
            self.partial_refs = refs
        self.inserted = inserted

    def __repr__(self):
        return 'Way(%r, %r, %r, inserted=%r)' % (self.osm_id, self.tags,
            self.refs, self.inserted)

    def merge(self, tags, refs):
        self.tags.update(tags)

        if self.refs != refs:
            if self.partial_refs:
                merge_refs = []
                merge_refs.extend(self.partial_refs)
            else:
                merge_refs = [self.refs]
            merge_refs.append(refs)
            result = multimerge(merge_refs)
            if result is None:
                self.partial_refs = merge_refs
            else:
                self.refs = result
                self.partial_refs = None

    def to_tuple(self):
        return self.osm_id, self.tags, self.refs


class Relation(object):
    def __init__(self, osm_id, tags, members):
        self.osm_id = osm_id
        self.tags = tags
        self.members = members

    def merge(self, tags, members):
        self.tags.update(tags)
        if self.members != members:
            self.members = merge_relation_members(self.members, members)

    def to_tuple(self):
        return self.osm_id, self.tags, self.members

def merge_relation_members(a, b):
    """
    concatenate two lists of members, removing duplicates, retaining order
    """
    combined = []
    added_ids = set()
    for m in itertools.chain(a, b):
        if m[0] not in added_ids:
            combined.append(m)
            added_ids.add(m[0])
    return combined


class OSMElem(object):
    __slots__ = 'osm_id name coords cls type tags geom'.split()
    
    def __init__(self, osm_id, coords, type, tags):
        self.osm_id = osm_id
        self.name = tags.get('name')
        self.coords = coords
        self.cls = type[0]
        self.type = type[1]
        self.tags = tags
        self.geom = None
########NEW FILE########
__FILENAME__ = osm
# Copyright 2011 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os

import imposm.config

from . tc import DeltaCoordsDB, CoordDB, NodeDB, WayDB, InsertedWayDB, RelationDB

class OSMCache(object):
    def __init__(self, path, prefix='imposm_', suffix='.cache'):
        self.path = path
        self.prefix = prefix
        self.suffix = suffix
        self.coords_fname = os.path.join(path, prefix + 'coords' + suffix) 
        self.nodes_fname = os.path.join(path, prefix + 'nodes' + suffix) 
        self.ways_fname = os.path.join(path, prefix + 'ways' + suffix) 
        self.inserted_ways_fname = os.path.join(path, prefix + 'inserted_ways' + suffix) 
        self.relations_fname = os.path.join(path, prefix + 'relations' + suffix) 
        self.caches = {}

    def close_all(self):
        for mode_, cache in self.caches.values():
            cache.close()
        self.caches = {}

    def coords_cache(self, mode='r', estimated_records=None):
        if imposm.config.imposm_compact_coords_cache:
            coords_db = DeltaCoordsDB
        else:
            coords_db = CoordDB
        return self._x_cache(self.coords_fname, coords_db, mode, estimated_records)

    def nodes_cache(self, mode='r', estimated_records=None):
        return self._x_cache(self.nodes_fname, NodeDB, mode, estimated_records)

    def ways_cache(self, mode='r', estimated_records=None):
        return self._x_cache(self.ways_fname, WayDB, mode, estimated_records)

    def inserted_ways_cache(self, mode='r', estimated_records=None):
        return self._x_cache(self.inserted_ways_fname, InsertedWayDB, mode, estimated_records)

    def remove_inserted_way_cache(self):
        if os.path.exists(self.inserted_ways_fname):
            os.unlink(self.inserted_ways_fname)

    def relations_cache(self, mode='r', estimated_records=None):
        return self._x_cache(self.relations_fname, RelationDB, mode, estimated_records)

    def _x_cache(self, x, x_class, mode, estimated_records=None):
        if x in self.caches:
            current_mode, cache = self.caches[x]
            if current_mode == mode:
                return cache
            else:
                cache.close()
        cache = x_class(x, mode, estimated_records=estimated_records)
        self.caches[x] = mode, cache

        return cache

########NEW FILE########
__FILENAME__ = config
# Copyright 2011 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# import relations with missing rings
import_partial_relations = False

# select relation builder: union or contains
relation_builder = 'contains'

# log relation that take longer than x seconds
imposm_multipolygon_report = 60

# skip relations with more rings (0 skip nothing)
imposm_multipolygon_max_ring = 0

# split ways that are longer than x nodes (0 to split nothing)
imposm_linestring_max_length = 0

# create a SERIAL PRIMARY KEY column (id) for all Postgres tables
# solves cases where osm_id is not unique (e.g. tram and road share the
# same way and are combined in a union view)
imposm_pg_serial_id = True

# cache coords in a compact storage (with delta encoding)
# use this when memory is limited (default)
imposm_compact_coords_cache = True
########NEW FILE########
__FILENAME__ = config
# Copyright 2011 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
import cgi
import urllib

from . postgis import PostGISDB
from .. mapping import Options

def DB(db_conf):
    if db_conf.get('name', 'postgis') == 'postgis':
        # default and backwards compat
        return PostGISDB(db_conf)
    raise ValueError('unknown db: %s' % (db_conf.name,))

def check_connection(db_conf):
    try:
        db = DB(db_conf)
        db.connection
    except Exception, e:
        return e

def db_conf_from_string(conf, base_db_conf):
    db_conf = _parse_rfc1738_args(conf)
    if 'proj' not in db_conf:
        db_conf.proj = base_db_conf.proj
    if 'prefix' not in db_conf:
        db_conf.prefix = base_db_conf.prefix
    return db_conf


def _parse_rfc1738_args(name):
    # from SQLAlchemy lib/sqlalchemy/engine/url.py
    # MIT licensed
    pattern = re.compile(r'''
            (?P<name>\w+)://
            (?:
                (?P<user>[^:/]*)
                (?::(?P<password>[^/]*))?
            @)?
            (?:
                (?P<host>[^/:]*)
                (?::(?P<port>[^/]*))?
            )?
            (?:/(?P<db>.*))?
            '''
            , re.X)

    m = pattern.match(name)
    if m is not None:
        components = m.groupdict()
        if components['db'] is not None:
            tokens = components['db'].split('?', 2)
            components['db'] = tokens[0]
            query = (len(tokens) > 1 and dict(cgi.parse_qsl(tokens[1]))) or None
            if query is not None:
                query = dict((k.encode('ascii'), query[k]) for k in query)
        else:
            query = None
        components['query'] = query

        if components['password'] is not None:
            components['password'] = urllib.unquote_plus(components['password'])

        return Options(**components)
    else:
        raise ValueError(
            "Could not parse rfc1738 URL from string '%s'" % name)

########NEW FILE########
__FILENAME__ = postgis
# Copyright 2011-2012 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import time
import uuid
from contextlib import contextmanager

import psycopg2
import psycopg2.extensions

import logging
log = logging.getLogger(__name__)

from imposm import config
from imposm.mapping import UnionView, GeneralizedTable, FixInvalidPolygons, Mapping

unknown = object()

class PostGISDB(object):
    insert_data_format = 'tuple'

    def __init__(self, db_conf, use_geometry_columns_table=unknown):
        self.db_conf = db_conf
        self.srid = int(db_conf['proj'].split(':')[1])

        self._insert_stmts = {}
        self._connection = None
        self._cur = None

        if use_geometry_columns_table is unknown:
            if self.is_postgis_2():
                use_geometry_columns_table = False
            else:
                use_geometry_columns_table = True
        self.use_geometry_columns_table = use_geometry_columns_table

    @property
    def table_prefix(self):
        if self.db_conf.prefix:
            return self.db_conf.prefix.rstrip('_') + '_'
        return self.db_conf.prefix

    def to_tablename(self, name):
        return self.table_prefix + name.lower()

    def is_postgis_2(self):
        cur = self.connection.cursor()
        cur.execute('SELECT postgis_version()')
        version_string = cur.fetchone()[0]
        return version_string.strip()[0] == '2'

    @property
    def connection(self):
        if not self._connection:
            kw = {}
            if self.db_conf.port:
                kw['port'] = int(self.db_conf.port)
            self._connection = psycopg2.connect(
                database=self.db_conf.db,
                host=self.db_conf.host,
                user=self.db_conf.user,
                password=self.db_conf.password,
                sslmode=self.db_conf.get('sslmode', 'allow'),
                **kw
            )
            self._connection.set_isolation_level(
                psycopg2.extensions.ISOLATION_LEVEL_READ_COMMITTED)
        return self._connection

    def commit(self):
        self.connection.commit()

    @property
    def cur(self):
        if self._cur is None:
            self._cur = self.connection.cursor()
        return self._cur

    @contextmanager
    def savepoint(self, cur, raise_errors=False):
        savepoint_name = 'savepoint' + uuid.uuid4().get_hex()
        try:
            cur.execute('SAVEPOINT %s' % savepoint_name)
            yield
        except psycopg2.ProgrammingError:
            cur.execute('ROLLBACK TO SAVEPOINT %s' % savepoint_name)
            if raise_errors:
                raise

    def insert(self, mapping, insert_data, tries=0):
        insert_stmt = self.insert_stmt(mapping)
        try:
            if tries:
                self.reconnect()
            self.cur.executemany(insert_stmt, insert_data)
        except psycopg2.OperationalError, ex:
            if tries >= 8:
                log.warn('%s, giving up', ex)
                raise
            seconds = 2 ** (tries + 1)
            log.warn('%s, retry in %d', ex, seconds)
            time.sleep(seconds)
            self.insert(mapping, insert_data, tries=tries + 1)
        except psycopg2.Error, ex:
            self.connection.rollback()
            for data in insert_data:
                try:
                    self.cur.execute(insert_stmt, data)
                except psycopg2.Error, ex:
                    log.warn('error while importing "%r": %s', data, ex)
                    self.connection.rollback()
                else:
                    self.connection.commit()

        self.connection.commit()

    def post_insert(self, mappings):
        mappings = [m for m in mappings.values() if isinstance(m, (GeneralizedTable, Mapping))]
        for mapping in mappings:
            table_name = self.to_tablename(mapping.name)
            self.create_geom_index(table_name)

    def create_geom_index(self, table_name):
        idx_name = '%s_geom' % table_name
        cur = self.connection.cursor()
        cur.execute("""
            CREATE INDEX "%s" ON "%s" USING GIST (geometry)
        """ % (idx_name,table_name))
        self.connection.commit()

    def geom_wrapper(self, geom):
        return psycopg2.Binary(geom.wkb)

    def reconnect(self):
        if self._connection:
            try:
                self._connection.close()
            except psycopg2.InterfaceError:
                pass
        self._connection = None
        self._cur = None

    def insert_stmt(self, mapping):
        if mapping.name not in self._insert_stmts:
            self._insert_stmts[mapping.name] = self._insert_stmt(mapping)

        return self._insert_stmts[mapping.name]

    def _insert_stmt(self, mapping):
        extra_arg_names = extra_args = ''
        if mapping.fields:
            extra_arg_names = [n for n, t in mapping.fields]
            extra_args = ', %s' * len(extra_arg_names)
            extra_arg_names = ', ' + ', '.join('"' + name + '"' for name in extra_arg_names)
        return """INSERT INTO "%(tablename)s"
            (osm_id, geometry %(extra_arg_names)s)
            VALUES (%%s, ST_Transform(ST_GeomFromWKB(%%s, 4326), %(srid)s)
                %(extra_args)s)
        """.strip() % dict(tablename=self.table_prefix + mapping.name, srid=self.srid,
            extra_arg_names=extra_arg_names, extra_args=extra_args)


    def create_tables(self, mappings):
        for mapping in mappings:
            self.create_table(mapping)

    def drop_table_or_view(self, cur, name):
        with self.savepoint(cur):
            cur.execute('DROP TABLE "' + name + '" CASCADE')
        with self.savepoint(cur):
            cur.execute('DROP VIEW "' + name + '" CASCADE')

    def create_table(self, mapping):
        tablename = self.table_prefix + mapping.name
        cur = self.connection.cursor()

        self.drop_table_or_view(cur, tablename)

        extra_fields = ''
        for n, t in mapping.fields:
            extra_fields += ', "%s" %s ' % (n, t.column_type)

        if config.imposm_pg_serial_id:
            serial_column = "id SERIAL PRIMARY KEY,"
        else:
            serial_column = ""

        cur.execute("""
            CREATE TABLE "%s" (
                %s
                osm_id BIGINT
                %s
            );
        """ % (tablename, serial_column, extra_fields))

        self.create_geometry_column(cur, tablename, mapping)

        self.create_field_indices(cur=cur, mapping=mapping, tablename=tablename)


    def create_geometry_column(self, cur, tablename, mapping):
        if self.use_geometry_columns_table:
            cur.execute("""
                SELECT AddGeometryColumn ('', '%(tablename)s', 'geometry',
                                          %(srid)s, '%(pg_geometry_type)s', 2)
            """ % dict(tablename=tablename, srid=self.srid,
                       pg_geometry_type=mapping.geom_type))
        else:
            cur.execute("""
                ALTER TABLE %(tablename)s ADD COLUMN geometry geometry(%(pg_geometry_type)s, %(srid)s);
            """ % dict(tablename=tablename, srid=self.srid,
                       pg_geometry_type=mapping.geom_type))

    def create_field_indices(self, cur, mapping, tablename):
        for n, t in mapping.fields:
            if isinstance(t, TrigramIndex):
                cur.execute("""
                    CREATE INDEX "%(tablename)s_trgm_idx_%(column)s" ON "%(tablename)s" USING GIST ("%(column)s" gist_trgm_ops)
                """ % dict(tablename=tablename, column=n))
            if isinstance(t, (StringIndex, Index)):
                cur.execute("""
                    CREATE INDEX "%(tablename)s_idx_%(column)s" ON "%(tablename)s" ("%(column)s")
                """ % dict(tablename=tablename, column=n))

    def swap_tables(self, new_prefix, existing_prefix, backup_prefix):
        cur = self.connection.cursor()

        # remove views before tables, because remove_tables will also remove
        # views via CASCADE and we need the view names for cleanup of
        # geometry_columns
        self.remove_views(backup_prefix)
        self.remove_tables(backup_prefix)

        cur.execute('SELECT tablename FROM pg_tables WHERE tablename like %s', (existing_prefix + '%', ))
        existing_tables = []
        for row in cur:
            table_name = row[0]
            if table_name.startswith(existing_prefix) and not table_name.startswith((new_prefix, backup_prefix)):
                # check for overlapping prefixes: osm_ but not osm_new_ or osm_backup_
                existing_tables.append(table_name)

        cur.execute('SELECT viewname FROM pg_views WHERE viewname like %s', (existing_prefix + '%', ))
        existing_views = []
        for row in cur:
            view_name = row[0]
            if view_name.startswith(existing_prefix) and not view_name.startswith((new_prefix, backup_prefix)):
                # check for overlapping prefixes: osm_ but not osm_new_ or osm_backup_
                existing_views.append(view_name)

        cur.execute('SELECT indexname FROM pg_indexes WHERE indexname like %s', (existing_prefix + '%', ))
        existing_indexes = set()
        for row in cur:
            index_name = row[0]
            if index_name.startswith(existing_prefix) and not index_name.startswith((new_prefix, backup_prefix)):
                # check for overlapping prefixes: osm_ but not osm_new_ or osm_backup_
                existing_indexes.add(index_name)

        cur.execute('SELECT relname FROM pg_class WHERE relname like %s', (existing_prefix + '%_id_seq', ))
        existing_seq = set()
        for row in cur:
            seq_name = row[0]
            if seq_name.startswith(existing_prefix) and not seq_name.startswith((new_prefix, backup_prefix)):
                # check for overlapping prefixes: osm_ but not osm_new_ or osm_backup_
                existing_seq.add(seq_name)

        cur.execute('SELECT tablename FROM pg_tables WHERE tablename like %s', (new_prefix + '%', ))
        new_tables = []
        for row in cur:
            table_name = row[0]
            new_tables.append(table_name)

        cur.execute('SELECT viewname FROM pg_views WHERE viewname like %s', (new_prefix + '%', ))
        new_views = []
        for row in cur:
            view_name = row[0]
            new_views.append(view_name)

        cur.execute('SELECT indexname FROM pg_indexes WHERE indexname like %s', (new_prefix + '%', ))
        new_indexes = set()
        for row in cur:
            index_name = row[0]
            new_indexes.add(index_name)

        cur.execute('SELECT relname FROM pg_class WHERE relname like %s', (new_prefix + '%_id_seq', ))
        new_seq = []
        for row in cur:
            seq_name = row[0]
            new_seq.append(seq_name)


        if not new_tables:
            raise RuntimeError('did not found tables to swap')

        # rename existing tables (osm_) to backup_prefix (osm_backup_)
        for table_name in existing_tables:
            rename_to = table_name.replace(existing_prefix, backup_prefix)
            cur.execute('ALTER TABLE "%s" RENAME TO "%s"' % (table_name, rename_to))

            for idx in existing_indexes:
                if idx in (table_name + '_geom', table_name + '_pkey') or idx.startswith(table_name + '_trgm_idx_') or idx.startswith(table_name + '_idx_'):
                    new_idx = idx.replace(table_name, rename_to, 1)
                    cur.execute('ALTER INDEX "%s" RENAME TO "%s"' % (idx, new_idx))
            if table_name + '_id_seq' in existing_seq:
                cur.execute('ALTER SEQUENCE "%s" RENAME TO "%s"' % (table_name + '_id_seq', rename_to + '_id_seq'))
            if self.use_geometry_columns_table:
                cur.execute('UPDATE geometry_columns SET f_table_name = %s WHERE f_table_name = %s', (rename_to, table_name))

        # rename existing views (osm_) to backup_prefix (osm_backup_)
        for view_name in existing_views:
            rename_to = view_name.replace(existing_prefix, backup_prefix)
            cur.execute('ALTER VIEW "%s" RENAME TO "%s"' % (view_name, rename_to))

            if self.use_geometry_columns_table:
                cur.execute('UPDATE geometry_columns SET f_table_name = %s WHERE f_table_name = %s', (rename_to, view_name))

        # rename new tables (osm_new_) to existing_prefix (osm_)
        for table_name in new_tables:
            rename_to = table_name.replace(new_prefix, existing_prefix)
            cur.execute('ALTER TABLE "%s" RENAME TO "%s"' % (table_name, rename_to))

            for idx in new_indexes:
                if idx in (table_name + '_geom', table_name + '_pkey') or idx.startswith(table_name + '_trgm_idx_') or idx.startswith(table_name + '_idx_'):
                    new_idx = idx.replace(table_name, rename_to, 1)
                    cur.execute('ALTER INDEX "%s" RENAME TO "%s"' % (idx, new_idx))
            if table_name + '_id_seq' in new_seq:
                cur.execute('ALTER SEQUENCE "%s" RENAME TO "%s"' % (table_name + '_id_seq', rename_to + '_id_seq'))
            if self.use_geometry_columns_table:
                cur.execute('UPDATE geometry_columns SET f_table_name = %s WHERE f_table_name = %s', (rename_to, table_name))

        # rename new views (osm_new_) to existing_prefix (osm_)
        for view_name in new_views:
            rename_to = view_name.replace(new_prefix, existing_prefix)
            cur.execute('ALTER VIEW "%s" RENAME TO "%s"' % (view_name, rename_to))

            if self.use_geometry_columns_table:
                cur.execute('UPDATE geometry_columns SET f_table_name = %s WHERE f_table_name = %s', (rename_to, view_name))


    def remove_tables(self, prefix):
        cur = self.connection.cursor()
        cur.execute('SELECT tablename FROM pg_tables WHERE tablename like %s', (prefix + '%', ))
        remove_tables = [row[0] for row in cur]

        for table_name in remove_tables:
            cur.execute("DROP TABLE %s CASCADE" % (table_name, ))
            if self.use_geometry_columns_table:
                cur.execute("DELETE FROM geometry_columns WHERE f_table_name = %s", (table_name, ))


    def remove_views(self, prefix):
        cur = self.connection.cursor()
        cur.execute('SELECT viewname FROM pg_views WHERE viewname like %s', (prefix + '%', ))
        remove_views = [row[0] for row in cur]

        for view_name in remove_views:
            cur.execute('DROP VIEW "%s" CASCADE' % (view_name, ))
            if self.use_geometry_columns_table:
                cur.execute("DELETE FROM geometry_columns WHERE f_table_name = %s", (view_name, ))


    def create_views(self, mappings, ignore_errors=False):
        for mapping in mappings.values():
            if isinstance(mapping, UnionView):
                PostGISUnionView(self, mapping).create(ignore_errors=ignore_errors)

    def create_generalized_tables(self, mappings):
        mappings = [m for m in mappings.values() if isinstance(m, GeneralizedTable)]
        for mapping in sorted(mappings, key=lambda x: x.name, reverse=True):
            PostGISGeneralizedTable(self, mapping).create()

    def postprocess_tables(self, mappings):
        mappings = [m for m in mappings.values() if isinstance(m, FixInvalidPolygons)]
        for mapping in mappings:
            PostGISFixInvalidPolygons(self, mapping).update()

    def optimize(self, mappings):
        mappings = [m for m in mappings.values() if isinstance(m, (GeneralizedTable, Mapping))]
        for mapping in mappings:
            table_name = self.to_tablename(mapping.name)
            self.optimize_table(table_name, '%s_geom' % table_name)
        self.vacuum()

    def optimize_table(self, table_name, idx_name):
        cur = self.connection.cursor()
        print 'Clustering table %s' % table_name
        cur.execute('CLUSTER "%s" ON "%s"' % (idx_name, table_name))
        self.connection.commit()

    def vacuum(self):
        old_isolation_level = self.connection.isolation_level
        self.reconnect()
        self.connection.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)
        cur = self.connection.cursor()
        print 'Vacuum analyze'
        cur.execute("VACUUM ANALYZE")
        self.connection.set_isolation_level(old_isolation_level)

class PostGISUnionView(object):
    def __init__(self, db, mapping):
        self.mapping = mapping
        self.db = db
        self.view_name = db.to_tablename(mapping.name)

    def _view_stmt(self):
        selects = []
        if config.imposm_pg_serial_id:
            serial_column = "id, "
        else:
            serial_column = ""

        for mapping in self.mapping.mappings:
            field_str = ', '.join(self._mapping_fields(mapping))
            selects.append("""SELECT %s osm_id, geometry, %s,
                '%s' as class from "%s" """ % (
                serial_column, field_str,
                mapping.classname or mapping.name, self.db.to_tablename(mapping.name)))

        selects = '\nUNION ALL\n'.join(selects)

        stmt = 'CREATE VIEW "%s" as (\n%s\n)' % (self.view_name, selects)

        return stmt

    def _geom_table_stmt(self):
        assert self.db.use_geometry_columns_table
        stmt = "insert into geometry_columns values ('', 'public', '%s', 'geometry', 2, %d, 'GEOMETRY')" % (
            self.view_name, self.db.srid)
        return stmt

    def _mapping_fields(self, mapping):
        mapping_fields = set([n for n, t in mapping.fields])
        fields = []
        for name, default in self.mapping.fields:
            if name in mapping_fields:
                fields.append('"' + name + '"')
            else:
                if default is None:
                    default = 'null'
                elif isinstance(default, basestring):
                    default = "'%s'" % default
                else:
                    default = str(default)
                fields.append(default + ' as "' + name + '"')
        return fields

    def create(self, ignore_errors):
        cur = self.db.connection.cursor()
        cur.execute('BEGIN')

        self.db.drop_table_or_view(cur, self.view_name)

        with self.db.savepoint(cur, raise_errors=not ignore_errors):
            cur.execute(self._view_stmt())

        if self.db.use_geometry_columns_table:
            cur.execute('SELECT * FROM geometry_columns WHERE f_table_name = %s', (self.view_name, ))
            if cur.fetchall():
                # drop old entry to handle changes of SRID
                cur.execute('DELETE FROM geometry_columns WHERE f_table_name = %s', (self.view_name, ))
            cur.execute(self._geom_table_stmt())


class PostGISGeneralizedTable(object):
    def __init__(self, db, mapping):
        self.db = db
        self.mapping = mapping
        self.table_name = db.to_tablename(mapping.name)

    def _geom_table_stmt(self):
        assert self.db.use_geometry_columns_table
        stmt = "insert into geometry_columns values ('', 'public', '%s', 'geometry', 2, %d, 'GEOMETRY')" % (
            self.table_name, self.db.srid)
        return stmt

    def _stmt(self):
        fields = ', '.join(['"' + n + '"' for n, t in self.mapping.fields])
        if fields:
            fields += ','

        where = ''
        if self.mapping.where:
            where = ' WHERE %s' % (self.mapping.where)

        if config.imposm_pg_serial_id:
            serial_column = "id, "
        else:
            serial_column = ""

        return """CREATE TABLE "%s" AS (SELECT %s osm_id, %s
            ST_SimplifyPreserveTopology(geometry, %f) as geometry from "%s"%s)""" % (
            self.table_name, serial_column, fields, self.mapping.tolerance,
            self.db.to_tablename(self.mapping.origin.name),
            where)

    def create(self):
        cur = self.db.connection.cursor()
        cur.execute('BEGIN')

        self.db.drop_table_or_view(cur, self.table_name)

        cur.execute(self._stmt())

        if self.db.use_geometry_columns_table:
            cur.execute('SELECT * FROM geometry_columns WHERE f_table_name = %s', (self.table_name, ))
            if cur.fetchall():
                # drop old entry to handle changes of SRID
                cur.execute('DELETE FROM geometry_columns WHERE f_table_name = %s', (self.table_name, ))
            cur.execute(self._geom_table_stmt())

class PostGISFixInvalidPolygons(object):
    """
    Try to make all polygons valid.
    ST_SimplifyPreserveTopology (used for the generalized tables) can return invalid
    geometries but ST_Buffer should be able to fix them.
    """
    def __init__(self, db, mapping):
        self.db = db
        self.mapping = mapping
        self.table_name = db.to_tablename(mapping.name)

    def _fetch_invalid_geometries(self):
        select_invalid = 'SELECT osm_id FROM %s WHERE ST_IsValid(geometry)=False' %(self.table_name,)

        cur = self.db.connection.cursor()
        cur.execute(select_invalid)

        for row in cur:
            yield row[0]

    def update(self):
        if self.mapping.geom_type != 'GEOMETRY':
            log.info('Validating of polygons only usable for Polygon/GEOMETRY mappings')
            return

        cur = self.db.connection.cursor()

        # fix geometries one-by-one because ST_buffer can fail an we wouldn't be able to
        # tell wich geometry caused it to fail
        for osm_id in self._fetch_invalid_geometries():
            update = 'UPDATE %s SET geometry = ST_Buffer(geometry,0) WHERE osm_id = %d' % (self.table_name, osm_id)
            cur.execute('SAVEPOINT polygonfix;')
            try:
                cur.execute(update)
            except psycopg2.DatabaseError, ex:
                log.warn('Could not fix geometry with osm_id %d. Row will be deleted. Internal error was: %s' % (osm_id, ex))
                cur.execute('ROLLBACK TO SAVEPOINT polygonfix;')
                cur.execute('DELETE FROM %s WHERE osm_id = %d' % (self.table_name, osm_id))
            else:
                cur.execute('RELEASE SAVEPOINT polygonfix;')

class TrigramIndex(object):
    pass

class StringIndex(object):
    pass

class Index(object):
    pass

########NEW FILE########
__FILENAME__ = dbimporter
# Copyright 2011, 2012 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from collections import defaultdict
from multiprocessing import Process

import threading
from Queue import Queue

from imposm.base import OSMElem
from imposm.geom import IncompletePolygonError
from imposm.mapping import DropElem, PolygonTable
from imposm.multipolygon import RelationBuilder
from imposm.util import setproctitle


import logging
log = logging.getLogger(__name__)

class ImporterProcess(Process):
    name = 'importer'

    def __init__(self, in_queue, db, mapper, osm_cache, dry_run):
        Process.__init__(self)
        self.daemon = True
        setproctitle('imposm %s process' % self.name)

        self.in_queue = in_queue
        self.mapper = mapper
        self.osm_cache = osm_cache
        self.db = db
        self.dry_run = dry_run
        self.db_queue = Queue(256)

    def run(self):
        self.setup()
        # cProfile.runctx('self.doit()', globals(), locals(), 'profile%s.dat' % (self.name,))
        self.doit()
        self.teardown()

    def setup(self):
        self.db_importer = threading.Thread(target=self.db_importer,
            args=(self.db_queue, self.db),
            kwargs=dict(dry_run=self.dry_run))
        self.db_importer.start()

    def doit(self):
        pass

    def teardown(self):
        self.osm_cache.close_all()
        self.db_queue.put(None)
        self.db_importer.join()

class TupleBasedImporter(ImporterProcess):
    def db_importer(self, queue, db, dry_run=False):
        db.reconnect()
        mappings = defaultdict(list)

        while True:
            data = queue.get()
            if data is None:
                break

            mapping, osm_id, osm_elem, extra_args = data
            insert_data = mappings[mapping]

            if isinstance(osm_elem.geom, (list)):
                for geom in osm_elem.geom:
                    insert_data.append((osm_id, db.geom_wrapper(geom)) + tuple(extra_args))
            else:
                insert_data.append((osm_id, db.geom_wrapper(osm_elem.geom)) + tuple(extra_args))

            if len(insert_data) >= 128:
                if not dry_run:
                    db.insert(mapping, insert_data)
                del mappings[mapping]

        # flush
        for mapping, insert_data in mappings.iteritems():
            if not dry_run:
                db.insert(mapping, insert_data)

    def insert(self, mappings, osm_id, geom, tags):
        inserted = False
        for type, ms in mappings:
            for m in ms:
                osm_elem = OSMElem(osm_id, geom, type, tags)
                try:
                    m.filter(osm_elem)
                    m.build_geom(osm_elem)
                    extra_args = m.field_values(osm_elem)
                    self.db_queue.put((m, osm_id, osm_elem, extra_args))
                    inserted = True
                except DropElem:
                    pass
        return inserted

class DictBasedImporter(ImporterProcess):
    def db_importer(self, queue, db, dry_run=False):
        db.reconnect()
        insert_data = []

        while True:
            data = queue.get()
            if data is None:
                break

            data['geometry'] = db.geom_wrapper(data['geometry'])
            insert_data.append(data)

            if len(insert_data) >= 128:
                if not dry_run:
                    db.insert(insert_data)
                insert_data = []
        # flush
        if not dry_run:
            db.insert(insert_data)


    def insert(self, mappings, osm_id, geom, tags):
        inserted = False
        osm_objects = {}

        for type, ms in mappings:
            for m in ms:
                osm_elem = OSMElem(osm_id, geom, type, tags)
                try:
                    m.filter(osm_elem)
                except DropElem:
                    continue

                if m.geom_type in osm_objects:
                    obj = osm_objects[m.geom_type]
                    obj['fields'].update(m.field_dict(osm_elem))
                    obj['fields'][type[0]] = type[1]
                    obj['mapping_names'].append(m.name)
                else:
                    try:
                        m.build_geom(osm_elem)
                    except DropElem:
                        continue
                    obj = {}
                    obj['fields'] = m.field_dict(osm_elem)
                    obj['fields'][type[0]] = type[1]
                    obj['osm_id'] = osm_id
                    obj['geometry'] = osm_elem.geom
                    obj['mapping_names'] = [m.name]
                    osm_objects[m.geom_type] = obj

                inserted = True

        for obj in osm_objects.itervalues():
            if isinstance(obj['geometry'], (list, )):
                for geom in obj['geometry']:
                    obj_part = obj.copy()
                    obj_part['geometry'] = geom
                    self.db_queue.put(obj_part)
            else:
                self.db_queue.put(obj)

        return inserted


class NodeProcess(ImporterProcess):
    name = 'node'

    def doit(self):
        while True:
            nodes = self.in_queue.get()
            if nodes is None:
                break

            for node in nodes:
                mappings = self.mapper.for_nodes(node.tags)
                if not mappings:
                    continue

                self.insert(mappings, node.osm_id, node.coord, node.tags)

class NodeProcessDict(NodeProcess, DictBasedImporter):
    pass

class NodeProcessTuple(NodeProcess, TupleBasedImporter):
    pass


def filter_out_polygon_mappings(mappings):
    result = []
    for tag, ms in mappings:
        ms = [m for m in ms if m.table != PolygonTable]
        if ms:
            result.append((tag, ms))
    return result

class WayProcess(ImporterProcess):
    name = 'way'

    def doit(self):
        coords_cache = self.osm_cache.coords_cache(mode='r')
        inserted_ways_cache = self.osm_cache.inserted_ways_cache(mode='r')
        inserted_ways = iter(inserted_ways_cache)

        try:
            skip_id = inserted_ways.next()
        except StopIteration:
            skip_id = 2**64

        while True:
            ways = self.in_queue.get()
            if ways is None:
                break

            for way in ways:
                # forward to the next skip id that is not smaller
                # than our current id
                while skip_id < way.osm_id:
                    try:
                        skip_id = inserted_ways.next()
                    except StopIteration:
                        skip_id = 2**64

                mappings = self.mapper.for_ways(way.tags)
                if not mappings:
                    continue

                if skip_id == way.osm_id:
                    # skip polygon mappings, way was already inserted as MultiPolygon
                    mappings = filter_out_polygon_mappings(mappings)
                    if not mappings:
                        continue

                coords = coords_cache.get_coords(way.refs)

                if not coords:
                    log.debug('missing coords for way %s', way.osm_id)
                    continue

                self.insert(mappings, way.osm_id, coords, way.tags)

class WayProcessDict(WayProcess, DictBasedImporter):
    pass

class WayProcessTuple(WayProcess, TupleBasedImporter):
    pass

class RelationProcess(ImporterProcess):
    name = 'relation'

    def __init__(self, in_queue, db, mapper, osm_cache, dry_run, inserted_way_queue):
        super(RelationProcess, self).__init__(in_queue, db, mapper, osm_cache, dry_run)
        self.inserted_way_queue = inserted_way_queue

    def doit(self):
        coords_cache = self.osm_cache.coords_cache(mode='r')
        ways_cache = self.osm_cache.ways_cache(mode='r')

        while True:
            relations = self.in_queue.get()
            if relations is None:
                break

            for relation in relations:
                builder = RelationBuilder(relation, ways_cache, coords_cache)
                try:
                    builder.build()
                except IncompletePolygonError, ex:
                    if str(ex):
                        log.debug(ex)
                    continue
                mappings = self.mapper.for_relations(relation.tags)

                inserted = False
                if mappings:
                    inserted = self.insert(mappings, relation.osm_id, relation.geom, relation.tags)
                if inserted and any(m.skip_inserted_ways for _, ms in mappings for m in ms):
                    for w in relation.ways:
                        if mappings_intersect(mappings, self.mapper.for_relations(w.tags)):
                            self.inserted_way_queue.put(w.osm_id)


def mappings_intersect(a, b):
    """
    True if `a` and `b` share a mapping.
    Mapping is a list of ((key, value), (mapping1, mapping2,...)).

    >>> mappings_intersect([(('waterway', 'riverbank'), ('mapping_waterareas',))],
    ... [(('waterway', 'riverbank'), ('mapping_waterareas',))])
    True
    >>> mappings_intersect([(('waterway', 'riverbank'), ('mapping_waterareas',))],
    ... [(('place', 'island'), ('mapping_landusage',))])
    False
    >>> mappings_intersect([(('waterway', 'riverbank'), ('mapping_waterareas',))],
    ... [(('place', 'island'), ('mapping_landusage',)),
    ...  (('waterway', 'riverbank'), ('mapping_waterareas',))])
    True
    """

    for a_key_val, a_mappings in a:
        for a_map in a_mappings:
            for b_key_val, b_mappings in b:
                for b_map in b_mappings:
                    if a_key_val == b_key_val and a_map == b_map:
                        return True

    return False

class RelationProcessDict(RelationProcess, DictBasedImporter):
    pass

class RelationProcessTuple(RelationProcess, TupleBasedImporter):
    pass

########NEW FILE########
__FILENAME__ = defaultmapping
# Copyright 2011 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from imposm.mapping import (
    Options,
    Points, LineStrings, Polygons,
    String, Bool, Integer, OneOfInt,
    set_default_name_type, LocalizedName,
    WayZOrder, ZOrder, Direction,
    GeneralizedTable, UnionView,
    FixInvalidPolygons,
    PseudoArea, meter_to_mapunit, sqr_meter_to_mapunit,
)

# # internal configuration options
# # uncomment to make changes to the default values
# import imposm.config
#
# # import relations with missing rings
# imposm.config.import_partial_relations = False
#
# # select relation builder: union or contains
# imposm.config.relation_builder = 'contains'
#
# # log relation that take longer than x seconds
# imposm.config.imposm_multipolygon_report = 60
#
# # skip relations with more rings (0 skip nothing)
# imposm.config.imposm_multipolygon_max_ring = 0
#
# # split ways that are longer than x nodes (0 to split nothing)
# imposm.config.imposm_linestring_max_length = 50
#
# # cache coords in a compact storage (with delta encoding)
# # use this when memory is limited (default)
# imposm.config.imposm_compact_coords_cache = True

# set_default_name_type(LocalizedName(['name:en', 'int_name', 'name']))

db_conf = Options(
    # db='osm',
    host='localhost',
    port=5432,
    user='osm',
    password='osm',
    sslmode='allow',
    prefix='osm_new_',
    proj='epsg:900913',
)

class Highway(LineStrings):
    fields = (
        ('tunnel', Bool()),
        ('bridge', Bool()),
        ('oneway', Direction()),
        ('ref', String()),
        ('z_order', WayZOrder()),
    )
    field_filter = (
        ('area', Bool()),
    )

places = Points(
    name = 'places',
    mapping = {
        'place': (
            'country',
            'state',
            'region',
            'county',
            'city',
            'town',
            'village',
            'hamlet',
            'suburb',
            'locality',
        ),
    },
    fields = (
        ('z_order', ZOrder([
            'country',
            'state',
            'region',
            'county',
            'city',
            'town',
            'village',
            'hamlet',
            'suburb',
            'locality',
        ])),
        ('population', Integer()),
    ),
)

admin = Polygons(
    name = 'admin',
    mapping = {
        'boundary': (
            'administrative',
        ),
    },
    fields = (
        ('admin_level', OneOfInt('1 2 3 4 5 6'.split())),
    ),
)

motorways = Highway(
    name = 'motorways',
    mapping = {
        'highway': (
            'motorway',
            'motorway_link',
            'trunk',
            'trunk_link',
        ),
    }
)

mainroads = Highway(
    name = 'mainroads',
    mapping = {
        'highway': (
            'primary',
            'primary_link',
            'secondary',
            'secondary_link',
            'tertiary',
    )}
)

buildings = Polygons(
    name = 'buildings',
    mapping = {
        'building': (
            '__any__',
    )}
)

minorroads = Highway(
    name = 'minorroads',
    mapping = {
        'highway': (
            'road',
            'path',
            'track',
            'service',
            'footway',
            'bridleway',
            'cycleway',
            'steps',
            'pedestrian',
            'living_street',
            'unclassified',
            'residential',
    )}
)

transport_points = Points(
    name = 'transport_points',
    fields = (
        ('ref', String()),
    ),
    mapping = {
        'highway': (
            'motorway_junction',
            'turning_circle',
            'bus_stop',
        ),
        'railway': (
            'station',
            'halt',
            'tram_stop',
            'crossing',
            'level_crossing',
            'subway_entrance',
        ),
        'aeroway': (
            'aerodome',
            'terminal',
            'helipad',
            'gate',
    )}
)

railways = LineStrings(
    name = 'railways',
    fields = (
        ('tunnel', Bool()),
        ('bridge', Bool()),
        # ('ref', String()),
        ('z_order', WayZOrder()),
    ),
    mapping = {
        'railway': (
            'rail',
            'tram',
            'light_rail',
            'subway',
            'narrow_gauge',
            'preserved',
            'funicular',
            'monorail',
    )}
)

waterways = LineStrings(
    name = 'waterways',
    mapping = {
        'waterway': (
            'stream',
            'river',
            'canal',
            'drain',
    )},
    field_filter = (
        ('tunnel', Bool()),
    ),
)

waterareas = Polygons(
    name = 'waterareas',
    mapping = {
        'waterway': ('riverbank',),
        'natural': ('water',),
        'landuse': ('basin', 'reservoir'),
})

aeroways = LineStrings(
    name = 'aeroways',
    mapping = {
        'aeroway': (
            'runway',
            'taxiway',
    )}
)

transport_areas = Polygons(
    name = 'transport_areas',
    mapping = {
        'railway': (
            'station',
        ),
        'aeroway': (
            'aerodrome',
            'terminal',
            'helipad',
            'apron',
        ),
})

landusages = Polygons(
    name = 'landusages',
    fields = (
        ('area', PseudoArea()),
        ('z_order', ZOrder([
            'pedestrian',
            'footway',
            'playground',
            'park',
            'forest',
            'cemetery',
            'farmyard',
            'farm',
            'farmland',
            'wood',
            'meadow',
            'grass',
            'village_green',
            'recreation_ground',
            'garden',
            'sports_centre',
            'pitch',
            'common',
            'allotments',
            'golf_course',
            'university',
            'school',
            'college',
            'library',
            'fuel',
            'parking',
            'nature_reserve',
            'cinema',
            'theatre',
            'place_of_worship',
            'hospital',
            'scrub',
            'quarry',
            'residential',
            'retail',
            'commercial',
            'industrial',
            'railway',
            'land',
        ])),
    ),
    mapping = {
        'landuse': (
            'park',
            'forest',
            'residential',
            'retail',
            'commercial',
            'industrial',
            'railway',
            'cemetery',
            'grass',
            'farmyard',
            'farm',
            'farmland',
            'wood',
            'meadow',
            'village_green',
            'recreation_ground',
            'allotments',
            'quarry',
        ),
        'leisure': (
            'park',
            'garden',
            'playground',
            'golf_course',
            'sports_centre',
            'pitch',
            'stadium',
            'common',
            'nature_reserve',
        ),
        'natural': (
            'wood',
            'land',
            'scrub',
        ),
        'highway': (
            'pedestrian',
            'footway',
        ),
        'amenity': (
            'university',
            'school',
            'college',
            'library',
            'fuel',
            'parking',
            'cinema',
            'theatre',
            'place_of_worship',
            'hospital',
        ),
})

amenities = Points(
    name='amenities',
    mapping = {
        'amenity': (
            'university',
            'school',
            'library',
            'fuel',
            'hospital',
            'fire_station',
            'police',
            'townhall',
        ),
})

motorways_gen1 = GeneralizedTable(
    name = 'motorways_gen1',
    tolerance = meter_to_mapunit(50.0),
    origin = motorways,
)

mainroads_gen1 = GeneralizedTable(
    name = 'mainroads_gen1',
    tolerance = meter_to_mapunit(50.0),
    origin = mainroads,
)

railways_gen1 = GeneralizedTable(
    name = 'railways_gen1',
    tolerance = meter_to_mapunit(50.0),
    origin = railways,
)

motorways_gen0 = GeneralizedTable(
    name = 'motorways_gen0',
    tolerance = meter_to_mapunit(200.0),
    origin = motorways_gen1,
)

mainroads_gen0 = GeneralizedTable(
    name = 'mainroads_gen0',
    tolerance = meter_to_mapunit(200.0),
    origin = mainroads_gen1,
)

railways_gen0 = GeneralizedTable(
    name = 'railways_gen0',
    tolerance = meter_to_mapunit(200.0),
    origin = railways_gen1,
)

landusages_gen0 = GeneralizedTable(
    name = 'landusages_gen0',
    tolerance = meter_to_mapunit(200.0),
    origin = landusages,
    where = "ST_Area(geometry)>%f" % sqr_meter_to_mapunit(500000),
)

landusages_gen1 = GeneralizedTable(
    name = 'landusages_gen1',
    tolerance = meter_to_mapunit(50.0),
    origin = landusages,
    where = "ST_Area(geometry)>%f" % sqr_meter_to_mapunit(50000),
)

waterareas_gen0 = GeneralizedTable(
    name = 'waterareas_gen0',
    tolerance = meter_to_mapunit(200.0),
    origin = waterareas,
    where = "ST_Area(geometry)>%f" % sqr_meter_to_mapunit(500000),
)

waterareas_gen1 = GeneralizedTable(
    name = 'waterareas_gen1',
    tolerance = meter_to_mapunit(50.0),
    origin = waterareas,
    where = "ST_Area(geometry)>%f" % sqr_meter_to_mapunit(50000),
)

roads = UnionView(
    name = 'roads',
    fields = (
        ('bridge', 0),
        ('ref', None),
        ('tunnel', 0),
        ('oneway', 0),
        ('z_order', 0),
    ),
    mappings = [motorways, mainroads, minorroads, railways],
)

roads_gen1 = UnionView(
    name = 'roads_gen1',
    fields = (
        ('bridge', 0),
        ('ref', None),
        ('tunnel', 0),
        ('oneway', 0),
        ('z_order', 0),
    ),
    mappings = [railways_gen1, mainroads_gen1, motorways_gen1],
)

roads_gen0 = UnionView(
    name = 'roads_gen0',
    fields = (
        ('bridge', 0),
        ('ref', None),
        ('tunnel', 0),
        ('oneway', 0),
        ('z_order', 0),
    ),
    mappings = [railways_gen0, mainroads_gen0, motorways_gen0],
)

landuse_gen1_valid = FixInvalidPolygons(
    origin = landusages_gen1,
)

landuse_gen0_valid = FixInvalidPolygons(
    origin = landusages_gen0,
)

########NEW FILE########
__FILENAME__ = geom
# Copyright 2011, 2012 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import division

import math
import codecs
import os
import shapely.geometry
import shapely.geos
import shapely.prepared
from shapely.geometry.base import BaseGeometry
from shapely import geometry
from shapely import wkt
from shapely.ops import cascaded_union, linemerge
from shapely.topology import TopologicalError

try:
    import rtree
except ImportError:
    rtree = None

from imposm import config
from imposm.util.geom import load_polygons, load_datasource, build_multipolygon

import logging
log = logging.getLogger(__name__)

class InvalidGeometryError(Exception):
    pass

class IncompletePolygonError(Exception):
    pass


TOLERANCE_DEEGREES = 1e-8
TOLERANCE_METERS = 1e-3

# older versions had unhandled floating point execptions in .buffer(0)
SHAPELY_SUPPORTS_BUFFER = shapely.geos.geos_capi_version >= (1, 6, 0)

def validate_and_simplify(geom, meter_units=False):
    if SHAPELY_SUPPORTS_BUFFER:
        try:
            # buffer(0) is nearly fast as is_valid
            return geom.buffer(0)
        except ValueError:
            # shapely raises ValueError if buffer(0) result is empty
            raise InvalidGeometryError('geometry is empty')

    orig_geom = geom
    if not geom.is_valid:
        tolerance = TOLERANCE_METERS if meter_units else TOLERANCE_DEEGREES
        try:
            geom = geom.simplify(tolerance, False)
        except ValueError:
            # shapely raises ValueError if buffer(0) result is empty
            raise InvalidGeometryError('geometry is empty')

        if not geom.is_valid:
            raise InvalidGeometryError('geometry is invalid, could not simplify: %s' %
                                       orig_geom)
    return geom

class GeomBuilder(object):
    def build(self, osm_elem):
        # TODO is this method still in use?
        try:
            if isinstance(osm_elem.coords, BaseGeometry):
                return osm_elem.coords
            geom_wkt = self.to_wkt(osm_elem.coords)
            if geom_wkt is not None:
                geom = wkt.loads(geom_wkt)
        except Exception, ex:
            raise InvalidGeometryError('unable to build geometry %s: %s %s' %
                                       (osm_elem.osm_id, ex, osm_elem.coords))
        if geom_wkt is None or geom is None:
            # unable to build valid wkt (non closed polygon, etc)
            raise InvalidGeometryError()
        return geom

    def check_geom_type(self, geom):
        return

    def build_geom(self, osm_elem):
        try:
            if isinstance(osm_elem.coords, BaseGeometry):
                if osm_elem.coords.is_empty:
                    raise InvalidGeometryError('empty geometry')
                self.check_geom_type(osm_elem.coords)
                return osm_elem.coords
            geom = self.to_geom(osm_elem.coords)
        except InvalidGeometryError, ex:
            raise InvalidGeometryError('unable to build geometry %s: %s %s' %
                                       (osm_elem.osm_id, ex, osm_elem.coords))
        if geom is None:
            # unable to build valid wkt (non closed polygon, etc)
            raise InvalidGeometryError()
        return geom

class PointBuilder(GeomBuilder):
    def to_wkt(self, data):
        if len(data) != 2:
            return None
        return 'POINT(%f %f)' % data

    def to_geom(self, data):
        if len(data) != 2:
            return None
        return geometry.Point(*data)

    def check_geom_type(self, geom):
        if geom.type != 'Point':
            raise InvalidGeometryError('expected Point, got %s' % geom.type)

    def build_checked_geom(self, osm_elem, validate=False):
        geom = self.build_geom(osm_elem)
        if not validate or geom.is_valid:
            return geom
        else:
            raise InvalidGeometryError('invalid geometry for %s: %s, %s' %
                                       (osm_elem.osm_id, geom, osm_elem.coords))

class PolygonBuilder(GeomBuilder):
    def to_wkt(self, data):
        if len(data) >= 4 and data[0] == data[-1]:
            return 'POLYGON((' + ', '.join('%f %f' % p for p in data) + '))'
        return None

    def to_geom(self, data):
        if len(data) >= 4 and data[0] == data[-1]:
            return geometry.Polygon(data)
        return None

    def check_geom_type(self, geom):
        if geom.type not in ('Polygon', 'MultiPolygon'):
            raise InvalidGeometryError('expected Polygon or MultiPolygon, got %s' % geom.type)

    def build_checked_geom(self, osm_elem, validate=False):
        geom = self.build_geom(osm_elem)
        if not validate:
            return geom
        try:
            return validate_and_simplify(geom)
        except InvalidGeometryError:
            raise InvalidGeometryError('invalid geometry for %s: %s, %s' %
                                       (osm_elem.osm_id, geom, osm_elem.coords))

class LineStringBuilder(GeomBuilder):
    def to_wkt(self, data):
        if len(data) <= 1:
            return None
        if len(data) == 2 and data[0] == data[1]:
            return None
        return 'LINESTRING(' + ', '.join('%f %f' % p for p in data) + ')'

    def check_geom_type(self, geom):
        if geom.type != 'LineString':
            raise InvalidGeometryError('expected LineString, got %s' % geom.type)

    def to_geom(self, data, max_length=None):
        if len(data) <= 1:
            return None
        if len(data) == 2 and data[0] == data[1]:
            return None
        if max_length is None:
            max_length = config.imposm_linestring_max_length
        if max_length and len(data) > max_length:
            chunks = math.ceil(len(data) / max_length)
            length = int(len(data) // chunks)
            lines = []
            for i in xrange(1, len(data), length):
                lines.append(geometry.LineString(data[i-1:i+length]))
            return lines
        return geometry.LineString(data)

    def build_checked_geom(self, osm_elem, validate=False):
        geom = self.build_geom(osm_elem)
        if not validate or geom.is_valid:
            return geom
        else:
            raise InvalidGeometryError('invalid geometry for %s: %s, %s' %
                                       (osm_elem.osm_id, geom, osm_elem.coords))

def tile_bbox(bbox, grid_width):
    """
    Tile bbox into multiple sub-boxes, each of `grid_width` size.

    >>> list(tile_bbox((-1, 1, 0.49, 1.51), 0.5)) #doctest: +NORMALIZE_WHITESPACE
    [(-1.0, 1.0, -0.5, 1.5),
     (-1.0, 1.5, -0.5, 2.0),
     (-0.5, 1.0, 0.0, 1.5),
     (-0.5, 1.5, 0.0, 2.0),
     (0.0, 1.0, 0.5, 1.5),
     (0.0, 1.5, 0.5, 2.0)]
    """
    min_x = math.floor(bbox[0]/grid_width) * grid_width
    min_y = math.floor(bbox[1]/grid_width) * grid_width
    max_x = math.ceil(bbox[2]/grid_width) * grid_width
    max_y = math.ceil(bbox[3]/grid_width) * grid_width

    x_steps = math.ceil((max_x - min_x) / grid_width)
    y_steps = math.ceil((max_y - min_y) / grid_width)

    for x in xrange(int(x_steps)):
        for y in xrange(int(y_steps)):
            yield (
                min_x + x * grid_width,
                min_y + y * grid_width,
                min_x + (x + 1) * grid_width,
                min_y + (y + 1)* grid_width,
            )

def split_polygon_at_grid(geom, grid_width=0.1, current_grid_width=10.0):
    """
    >>> p = list(split_polygon_at_grid(geometry.box(-0.5, 1, 0.2, 2), 1))
    >>> p[0].contains(geometry.box(-0.5, 1, 0, 2))
    True
    >>> p[0].area == geometry.box(-0.5, 1, 0, 2).area
    True
    >>> p[1].contains(geometry.box(0, 1, 0.2, 2))
    True
    >>> p[1].area == geometry.box(0, 1, 0.2, 2).area
    True
    """
    if not geom.is_valid:
        geom = geom.buffer(0)

    for i, split_box in enumerate(tile_bbox(geom.bounds, current_grid_width)):
        try:
            polygon_part = geom.intersection(shapely.geometry.box(*split_box))
        except TopologicalError:
            continue
        if not polygon_part.is_empty and polygon_part.type.endswith('Polygon'):
            if grid_width >= current_grid_width:
                yield polygon_part
            else:
                for part in split_polygon_at_grid(polygon_part, grid_width, current_grid_width/10.0):
                    yield part

def load_geom(source):
    geom = load_datasource(source)
    if geom:
        # get the first and maybe only geometry
        if not check_wgs84_srs(geom[0]):
            log.error('Geometry is not in EPSG:4326')
            return None
        if rtree:
            return LimitRTreeGeometry(geom)
        else:
            log.info('You should install RTree for large --limit-to polygons')
            return LimitPolygonGeometry(build_multipolygon(geom)[1])
    return None

def check_wgs84_srs(geom):
    bbox = geom.bounds
    if bbox[0] >= -180 and bbox[1] >= -90 and bbox[2] <= 180 and bbox[3] <= 90:
        return True
    return False

class EmtpyGeometryError(Exception):
    pass

class LimitPolygonGeometry(object):
    def __init__(self, shapely_geom):
        self._geom = shapely_geom
        self._prepared_geom = None
        self._prepared_counter = 0
        self._prepared_max = 100000

    @property
    def geom(self):
        # GEOS internal data structure for prepared geometries grows over time,
        # recreate to limit memory consumption
        if not self._prepared_geom or self._prepared_counter > self._prepared_max:
            print 'create prepared'
            self._prepared_geom = shapely.prepared.prep(self._geom)
            self._prepared_counter = 0
        self._prepared_counter += 1
        return self._prepared_geom

    def intersection(self, geom):
        if self.geom.contains_properly(geom):
            # no need to limit contained geometries
            return geom

        new_geom = None
        if self.geom.intersects(geom):
            try:
                # can not use intersection with prepared geom
                new_geom = self._geom.intersection(geom)
            except TopologicalError:
                pass

        if not new_geom or new_geom.is_empty:
            raise EmtpyGeometryError('No intersection or empty geometry')

        new_geom = filter_geometry_by_type(new_geom, geom.type)
        if new_geom:
            return new_geom

        raise EmtpyGeometryError('No intersection or empty geometry')

def filter_geometry_by_type(geometry, geom_type):
    """
    Filter (multi)geometry for compatible `geom_type`,
    because we can't insert points into linestring tables for example
    """
    if geometry.type == geom_type:
        # same type is fine
        return geometry

    if geometry.type == 'Polygon' and geom_type == 'MultiPolygon':
        # multipolygon mappings also support polygons
        return geometry

    if geometry.type == 'MultiPolygon' and geom_type == 'Polygon':
        # polygon mappings should also support multipolygons
        return geometry

    if hasattr(geometry, 'geoms'):
        # GeometryCollection or MultiLineString? return list of geometries
        geoms = []
        for part in geometry.geoms:
            # only parts with same type
            if part.type == geom_type:
                geoms.append(part)

        if geoms:
            return geoms

    return None

def flatten_polygons(polygons):
    for polygon in polygons:
        if polygon.type == 'MultiPolygon':
            for p in polygon.geoms:
                yield p
        else:
            yield polygon

def flatten_linestrings(linestrings):
    for linestring in linestrings:
        if linestring.type == 'MultiLineString':
            for ls in linestring.geoms:
                yield ls
        else:
            yield linestring

def filter_invalid_linestrings(linestrings):
    for linestring in linestrings:
        # filter out tiny linestrings, can become invalid geometries in postgis
        if linestring.length > 1e-9:
            yield linestring

class LimitRTreeGeometry(object):
    def __init__(self, polygons):
        index = rtree.index.Index()
        sub_polygons = []
        part_idx = 0
        for polygon in polygons:
            for part in split_polygon_at_grid(polygon):
                sub_polygons.append(part)
                index.insert(part_idx, part.bounds)
                part_idx += 1

        self.polygons = sub_polygons
        self.index = index

    def intersection(self, geom):
        intersection_ids = list(self.index.intersection(geom.bounds))

        if not intersection_ids:
            raise EmtpyGeometryError('No intersection or empty geometry')

        intersections = []
        for i in intersection_ids:

            polygon = self.polygons[i]

            if polygon.contains(geom):
                return geom

            if polygon.intersects(geom):
                try:
                    new_geom_part = polygon.intersection(geom)
                    new_geom_part = filter_geometry_by_type(new_geom_part, geom.type)
                    if new_geom_part:
                        if isinstance(new_geom_part, list):
                            intersections.extend(new_geom_part)
                        else:
                            intersections.append(new_geom_part)
                except TopologicalError:
                        pass

        if not intersections:
            raise EmtpyGeometryError('No intersection or empty geometry')

        # intersections from multiple sub-polygons
        # try to merge them back to a single geometry
        try:
            if geom.type.endswith('Polygon'):
                union = cascaded_union(list(flatten_polygons(intersections)))
            elif geom.type.endswith('LineString'):
                linestrings = flatten_linestrings(intersections)
                linestrings = list(filter_invalid_linestrings(linestrings))
                if not linestrings:
                    raise EmtpyGeometryError()
                union = linemerge(linestrings)
                if union.type == 'MultiLineString':
                    union = list(union.geoms)
            elif geom.type == 'Point':
                union = intersections[0]
            else:
                log.warn('unexpexted geometry type %s', geom.type)
                raise EmtpyGeometryError()
        except ValueError, ex:
            # likely an 'No Shapely geometry can be created from null value' error
            log.warn('could not create union: %s', ex)
            raise EmtpyGeometryError()
        return union

########NEW FILE########
__FILENAME__ = mapping
# -:- encoding: UTF8 -:-
# Copyright 2011 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import division
import math
import imposm.geom

ANY = '__any__'

__all__ = [
    'LineStrings',
    'Polygons',
    'Points',
    'Options',
    'PolygonTable',
    'ZOrder',
    'PointTable',
    'String',
    'LocalizedName',
    'LineStringTable',
    'Direction',
    'OneOfInt',
    'Integer',
    'WayZOrder',
    'Bool',
    'GeneralizedTable',
    'FixInvalidPolygons',
    'UnionView',
    'set_default_name_field',
]

default_name_field = None

def set_default_name_type(type, column_name='name'):
    """
    Set new default type for 'name' field.

    ::

        set_default_name_type(LocalizedName(['name:en', 'int_name', 'name']))

    """
    global default_name_field
    default_name_field = column_name, type

# changed by imposm.app if the projection is epsg:4326
import_srs_is_geographic = False

def meter_to_mapunit(meter):
    """
    Convert ``meter`` into the mapunit of the import.
    Only supports EPSG:4326 (degrees) at the moment, all other
    SRS will use meter as mapunit.
    """
    if import_srs_is_geographic:
        deg_to_meter = (40000 * 1000) / 360
        return meter / deg_to_meter
    return meter

def sqr_meter_to_mapunit(sqr_meter):
    """
    Convert ``sqr_meter`` into the mapunit of the import.
    Only supports EPSG:4326 (degrees) at the moment, all other
    SRS will use meter as mapunit.
    """
    if import_srs_is_geographic:
        return meter_to_mapunit(math.sqrt(sqr_meter))**2
    return sqr_meter

class Mapping(object):
    table = None
    fields = ()
    field_filter = ()
    classname = None
    _insert_stmt = None
    with_type_field = True

    def __init__(self, name, mapping, fields=None, field_filter=None, with_type_field=None):
        self.name = name
        self.mapping = mapping
        self.fields = fields or tuple(self.fields)
        self.limit_to_polygon = None
        if with_type_field is not None:
            # allow subclass to define other default by setting it as class variable
            self.with_type_field = with_type_field
        self._add_type_field()
        self._add_name_field()
        if field_filter:
            self.field_filter = field_filter

    def _add_name_field(self):
        """
        Add name field to default if not set.
        """
        if not any(1 for name, _type in self.fields if name == 'name'):
            if default_name_field:
                self.fields = (default_name_field,) + self.fields
            else:
                self.fields = (('name', Name()),) + self.fields

    def _add_type_field(self):
        """
        Add type field.
        """
        if not self.with_type_field:
            return

        for name, type_ in self.fields:
            if name == 'type':
                # do not add type field if already present
                return
        self.fields = (('type', Type()), ) + self.fields

    @property
    def insert_stmt(self):
        if not self._insert_stmt:
            self._insert_stmt = self.table('osm_' + self.name, self).insert_stmt
        return self._insert_stmt

    def extra_field_names(self):
        extra_field_names = []
        for field_name, field_filter in self.field_filter:
            extra_field_names.append(field_name)

        for field_name, field in self.fields:
            field_names = field.extra_fields()
            if field_names is not None:
                extra_field_names.extend(field_names)
            else:
                extra_field_names.append(field_name)
        return extra_field_names

    def build_geom(self, osm_elem):
        try:
            geom = self.geom_builder.build_checked_geom(osm_elem)
            if self.limit_to_polygon is not None:
                geom = self.limit_to_polygon.intersection(geom)
            osm_elem.geom = geom
        except imposm.geom.InvalidGeometryError, ex:
            raise DropElem('invalid geometry: %s' % (ex, ))
        except imposm.geom.EmtpyGeometryError, ex:
            raise DropElem(ex)

    def field_values(self, osm_elem):
        return [t.value(osm_elem.tags.get(n), osm_elem) for n, t in self.fields]

    def field_dict(self, osm_elem):
        result = dict((n, t.value(osm_elem.tags.get(n), osm_elem)) for n, t in self.fields)
        if self.with_type_field:
            del result['type']
        result[osm_elem.cls] = osm_elem.type
        return result

    def filter(self, osm_elem):
        [t.filter(osm_elem.tags.get(n), osm_elem) for n, t in self.field_filter]

    def __repr__(self):
        return '<Mapping for %s>' % self.name


class TagMapper(object):
    def __init__(self, mappings, limit_to=None):
        self.mappings = mappings
        self.limit_to_polygon = limit_to
        self._init_map()

    def _init_map(self):
        self.point_mappings = {}
        self.line_mappings = {}
        self.polygon_mappings = {}
        self.point_tags = {}
        self.line_tags = {}
        self.polygon_tags = {}

        for mapping in self.mappings:
            if mapping.table is PointTable:
                tags = self.point_tags
                add_to = self.point_mappings
            elif mapping.table is LineStringTable:
                tags = self.line_tags
                add_to = self.line_mappings
            elif mapping.table is PolygonTable:
                tags = self.polygon_tags
                add_to = self.polygon_mappings

            for extra in mapping.extra_field_names():
                tags.setdefault(extra, set()).add('__any__')

            for tag, types in mapping.mapping.iteritems():
                add_to.setdefault(tag, {})
                for type in types:
                    tags.setdefault(tag, set()).add(type)
                    add_to[tag].setdefault(type, []).append(mapping)

            # add limit_to polygon to each mapping
            mapping.limit_to_polygon = self.limit_to_polygon

    def for_nodes(self, tags):
        return self._mapping_for_tags(self.point_mappings, tags)

    def for_ways(self, tags):
        return (self._mapping_for_tags(self.line_mappings, tags) +
                self._mapping_for_tags(self.polygon_mappings, tags))

    def for_relations(self, tags):
        return self._mapping_for_tags(self.polygon_mappings, tags)

    def _tag_filter(self, filter_tags):
        def filter(tags):
            for k in tags.keys():
                if k not in filter_tags:
                    del tags[k]
                else:
                    if '__any__' in filter_tags[k]:
                        pass
                    elif tags[k] in filter_tags[k]:
                        pass
                    else:
                        del tags[k]
            if 'name' in tags and len(tags) == 1:
                del tags['name']
        return filter

    def tag_filter_for_nodes(self):
        tags = dict(self.point_tags)
        return self._tag_filter(tags)

    def tag_filter_for_ways(self):
        tags = dict()
        for k, v in self.line_tags.iteritems():
            tags.setdefault(k, set()).update(v)

        for k, v in self.polygon_tags.iteritems():
            tags.setdefault(k, set()).update(v)
        return self._tag_filter(tags)

    def tag_filter_for_relations(self):
        tags = dict()
        for k, v in self.line_tags.iteritems():
            tags.setdefault(k, set()).update(v)
        for k, v in self.polygon_tags.iteritems():
            tags.setdefault(k, set()).update(v)
        tags['type'] = set(['multipolygon', 'boundary', 'land_area'])  # for type=multipolygon
        expected_tags = set(['type', 'name'])
        _rel_filter = self._tag_filter(tags)
        def rel_filter(tags):
            # we only support mulipolygon relations, skip all other
            # a lot of the admin boundary/land_area relations are not type=multipolygon
            if tags.get('type') not in ('multipolygon', 'boundary', 'land_area'):
                tags.clear()
                return
            if tags['type'] == 'boundary' and 'boundary' not in tags:
                # a lot of the boundary relations are not multipolygon
                # only import with boundary tags (e.g. boundary=administrative)
                tags.clear()
                return
            tag_count = len(tags)
            _rel_filter(tags)
            if len(tags) < tag_count:
                # we removed tags...
                if not set(tags).difference(expected_tags):
                    # but no tags except name and type are left
                    # remove all, otherwise tags from longest
                    # way/ring would be used during MP building
                    tags.clear()
        return rel_filter

    def _mapping_for_tags(self, tag_map, tags):
        result = []
        mapping_set = set()

        for tag_name in tags:
            if tag_name in tag_map:
                tag_value = tags[tag_name]
                mappings = []
                if tag_value in tag_map[tag_name]:
                    mappings.extend(tag_map[tag_name][tag_value])
                if ANY in tag_map[tag_name]:
                    mappings.extend(tag_map[tag_name][ANY])

                new_mappings = []
                for proc in mappings:
                    if proc not in mapping_set:
                        mapping_set.add(proc)
                        new_mappings.append(proc)
                if new_mappings:
                    result.append(((tag_name, tag_value), tuple(new_mappings)))

        return result


# marker classes
class PointTable(object):
    pass
class LineStringTable(object):
    pass
class PolygonTable(object):
    pass

class Points(Mapping):
    """
    Table class for point features.

    :PostGIS datatype: POINT
    """
    table = PointTable
    geom_builder = imposm.geom.PointBuilder()
    geom_type = 'POINT'

class LineStrings(Mapping):
    """
    Table class for line string features.

    :PostGIS datatype: LINESTRING
    """
    table = LineStringTable
    geom_builder = imposm.geom.LineStringBuilder()
    geom_type = 'LINESTRING'

class Polygons(Mapping):
    """
    Table class for polygon features.

    :PostGIS datatype: GEOMETRY (POLYGON does not support multi-polygons)
    """
    table = PolygonTable
    geom_builder = imposm.geom.PolygonBuilder()
    geom_type = 'GEOMETRY' # for multipolygon support

    """
    Prevent ways that are part of a multi-polygon to be inserted
    twice. E.g. multipolygon of two closed forests ways where the ways
    are also tagged would be inserted twice when skip_inserted_ways is False
    First as a multipolygon when processing the relations and second as a
    two polygons when processing the ways.
    """
    skip_inserted_ways = True


class BoundaryPolygons(Polygons):
    """
    Table class for boundary polygon features.
    Similar to `Polygons` but ways that are inserted during multi-polygon
    processing are processed again for ways.

    :PostGIS datatype: GEOMETRY (POLYGON does not support multi-polygons)
    """
    skip_inserted_ways = False

class GeneralizedTable(object):
    def __init__(self, name, tolerance, origin, where=None):
        self.name = name
        self.tolerance = tolerance
        self.origin = origin
        self.geom_type = origin.geom_type
        self.classname = origin.name
        self.fields = self.origin.fields
        self.with_type_field = self.origin.with_type_field
        self.where = where

class FixInvalidPolygons(object):
    """
    Post-processing that tries to fix all invalid polygons.

    :PostGIS datatype: GEOMETRY (POLYGON does not support multi-polygons)
    """
    def __init__(self, origin):
        self.origin = origin
        self.name = origin.name
        self.geom_type = getattr(origin, 'geom_type', None)

class UnionView(object):
    def __init__(self, name, mappings, fields):
        self.name = name
        self.mappings = mappings
        self.fields = fields
        self._add_name_field()
        self._add_type_field()

    def _add_name_field(self):
        """
        Add name field to default if not set.
        """
        if not any(1 for name, _type in self.fields if name == 'name'):
            if default_name_field:
                self.fields = ((default_name_field[0], ''),) + self.fields
            else:
                self.fields = (('name', ''),) + self.fields

    def _add_type_field(self):
        """
        Add type field if not configured and at least one mapping has a type field.
        """
        if 'type' not in self.fields and any(m.with_type_field for m in self.mappings):
            self.fields += (('type', None), )


class DropElem(Exception):
    pass


class FieldType(object):
    def extra_fields(self):
        """
        List with names of fields (keys) that should be processed
        during read-phase.

        Return ``None`` to use the field name from the mapping.
        Return ``[]`` if no extra fields (keys) are required.
        """
        return None

    def value(self, val, osm_elem):
        return val

class Type(FieldType):
    """
    Field for type values (i.e. the *value* of the mapped key/value).

    Use this in combination with ``with_type_field=False`` of the
    mapping class, if you want to store the value of the mapped
    key/value in a different column.

    For example, to get a column ``road_class`` instead of ``type``::

        roads = LineStrings(
            with_type_field = False,
            name = 'roads',
            mapping = {
                'highway': (
                    'motorway',
                    'trunk',
                    'secondary',
                ),
            },
            fields = (
                ('road_class', Type(),),
            ),
        )

    :PostgreSQL datatype: VARCHAR(255)

    .. versionadded:: 2.4.0

    """
    column_type = "VARCHAR(255)"

    def extra_fields(self):
        return []

    def value(self, val, osm_elem):
        return osm_elem.type

class Class(FieldType):
    """
    Field for class values (i.e. the *key* of the mapped key/value).

    Use this if you want to store the key that was used for
    this mapping. For example, the following mapping will
    create a column ``class`` that will have the value
    ``landuse`` or ``natural``, depending on the feature.

    ::

        landusages = Polygons(
            name = 'landusages',
            fields = (
                ('class', Class()),
            ),
            mapping = {
                'landuse': (
                    'wood',
                ),
                'natural': (
                    'wood',
                ),
            }
        )

    :PostgreSQL datatype: VARCHAR(255)

    .. versionadded:: 2.4.0

    """
    column_type = "VARCHAR(255)"

    def extra_fields(self):
        return []

    def value(self, val, osm_elem):
        return osm_elem.cls

class String(FieldType):
    """
    Field for string values.

    :PostgreSQL datatype: VARCHAR(255)
    """
    column_type = "VARCHAR(255)"

class Name(String):
    """
    Field for name values.

    Filters out common FixMe values.

    :PostgreSQL datatype: VARCHAR(255)

    .. versionadded:: 2.3.0
    """

    filter_out_names = set((
        'fixme', 'fix me', 'fix-me!',
        '0', 'none', 'n/a', 's/n',
        'kein name', 'kein',
        'unbenannt', 'unbekannt',
        'noch unbekannt', 'noch ohne namen',
        'noname', 'unnamed', 'namenlos', 'no_name', 'no name',
        'editme', '_edit_me_',
    ))

    def value(self, val, osm_elem):
        if val and val.lower() in self.filter_out_names:
            osm_elem.name = ''
            val = ''
        return val

class LocalizedName(Name):
    """
    Field for localized name values.
    Checks different name keys and uses the first key with
    a valid value.

    :param coalesce: list of name keys to check
    :PostgreSQL datatype: VARCHAR(255)

    .. versionadded:: 2.3.0
    """
    def __init__(self, coalesce=['name', 'int_name']):
        self.coalesce_keys = coalesce

    def extra_fields(self):
        return self.coalesce_keys

    def value(self, val, osm_elem):
        for key in self.coalesce_keys:
            val = osm_elem.tags.get(key)
            if val and val.lower() not in self.filter_out_names:
                osm_elem.name = val
                return val
        else:
            osm_elem.name = ''
            return ''

class Bool(FieldType):
    """
    Field for boolean values.
    Converts false, no, 0 to False and true, yes, 1 to True.

    :PostgreSQL datatype: SMALLINT
    """
    # there was a reason this is not BOOL
    # something didn't supported it, cascadenik? don't remember
    column_type = "SMALLINT"

    aliases = {
        True: set(['false', 'no', '0', 'undefined']),
        False: set(['true', 'yes', '1', 'undefined']),
    }

    def __init__(self, default=True, neg_aliases=None):
        self.default = default
        self.neg_aliases = neg_aliases or self.aliases[default]

    def value(self, val, osm_elem):
        if val is None or val.strip().lower() in self.neg_aliases:
            return 0  # not self.default
        return 1  # self.default

    def filter(self, val, osm_elem):
        if self.value(val, osm_elem):
            raise DropElem

class Direction(FieldType):
    """
    Field type for one-way directions.
    Converts `yes`, `true` and `1` to ``1`` for one ways in the direction of
    the way, `-1` to ``-1`` for one ways against the direction of the way and
    ``0`` for all other values.

    :PostgreSQL datatype: SMALLINT
    """
    column_type = "SMALLINT"
    def value(self, value, osm_elem):
        if value:
            value = value.strip().lower()
            if value in ('yes', 'true', '1'):
                return 1
            if value == '-1':
                return -1
        return 0

class PseudoArea(FieldType):
    """
    Field for the (pseudo) area of a polygon in square meters.

    The value is just an approximation since the geometries are in
    EPSG:4326 and not in a equal-area projection. The approximation
    is good for smaller polygons (<1%) and should be precise enough
    to compare geometries for rendering order (larger below smaller).

    The area of the geometry is multiplied by the cosine of
    the mid-latitude to compensate the reduced size towards
    the poles.

    :PostgreSQL datatype: REAL

    .. versionadded:: 2.3.0
    """

    column_type = "REAL"

    def value(self, val, osm_elem):
        area = osm_elem.geom.area
        if not area:
            return None

        extent = osm_elem.geom.bounds
        mid_lat = extent[1] + (abs(extent[3] - extent[1]) / 2)
        sqr_deg = area * math.cos(math.radians(mid_lat))

        # convert deg^2 to m^2
        sqr_m = (math.sqrt(sqr_deg) * (40075160 / 360))**2
        return sqr_m

    def extra_fields(self):
        return []

class OneOfInt(FieldType):
    """
    Field type for integer values.
    Converts values to integers, drops element if is not included in
    ``values``.

    :PostgreSQL datatype: SMALLINT
    """
    column_type = "SMALLINT"

    def __init__(self, values):
        self.values = set(values)

    def value(self, value, osm_elem):
        if value in self.values:
            return int(value)
        raise DropElem

class Integer(FieldType):
    """
    Field type for integer values.
    Converts values to integers, defaults to ``NULL``.

    :PostgreSQL datatype: INTEGER
    """
    column_type = "INTEGER"

    def value(self, value, osm_elem):
        try:
            return int(value)
        except:
            return None

class ZOrder(FieldType):
    """
    Field type for z-ordering based on the feature type.

    :param types: list of mapped feature types,
        from highest to lowest ranking
    :PostgreSQL datatype: SMALLINT
    """

    column_type = "SMALLINT"

    def __init__(self, types):
        self.rank = {}
        for i, t in enumerate(types[::-1]):
            self.rank[t] = i

    def extra_fields(self):
        return []

    def value(self, val, osm_elem):
        return self.rank.get(osm_elem.type, 0)


class WayZOrder(FieldType):
    """
    Field type for z-ordered based on highway types.

    Ordering based on the osm2pgsql z-ordering:
    From ``roads`` = 3 to ``motorways`` = 9, ``railway`` = 7 and unknown = 0.
    Ordering changes with ``tunnels`` by -10, ``bridges`` by +10 and
    ``layer`` by 10 * ``layer``.

    :PostgreSQL datatype: SMALLINT
    """

    column_type = "SMALLINT"

    rank = {
     'minor': 3,
     'road': 3,
     'unclassified': 3,
     'residential': 3,
     'tertiary_link': 3,
     'tertiary': 4,
     'secondary_link': 3,
     'secondary': 5,
     'primary_link': 3,
     'primary': 6,
     'trunk_link': 3,
     'trunk': 8,
     'motorway_link': 3,
     'motorway': 9,
    }

    brunnel_bool = Bool()

    def extra_fields(self):
        return []

    def value(self, val, osm_elem):
        tags = osm_elem.tags
        z_order = 0
        l = self.layer(tags)
        z_order += l * 10
        r = self.rank.get(osm_elem.type, 0)
        if not r:
            r = 7 if 'railway' in tags else 0
        z_order += r

        if self.brunnel_bool.value(tags.get('tunnel'), {}):
            z_order -= 10

        if self.brunnel_bool.value(tags.get('bridge'), {}):
            z_order += 10

        return z_order

    def layer(self, tags):
        l = tags.get('layer', 0)
        try:
            return int(l)
        except ValueError:
            return 0

class Options(dict):
    def __setattr__(self, name, value):
        self[name] = value
    def __getattr__(self, name):
        try:
            return self[name]
        except KeyError:
            raise AttributeError('%s not in %r' % (name, self))

########NEW FILE########
__FILENAME__ = merge
# Copyright 2011 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import difflib

def merge(a, b):
    sqm = difflib.SequenceMatcher(None, a, b)
    matching_blocks = sqm.get_matching_blocks()
    matching_blocks.pop(-1)
    
    if not matching_blocks:
        return None
    
    a_idx = b_idx = 0
    result = []

    for block in matching_blocks:
        if a_idx < block[0]:
            result.extend(a[a_idx:block[0]])
        if b_idx < block[1]:
            result.extend(b[b_idx:block[1]])
        a_idx = block[0]+block[-1]
        b_idx = block[1]+block[-1]
        result.extend(a[block[0]:block[0]+block[-1]])

    if a_idx < len(a):
        result.extend(a[a_idx:])
    if b_idx < len(b):
        result.extend(b[b_idx:])
        
    return result


def multimerge(candidates, merge_func=merge):
    candidates = list(candidates)
    while len(candidates) > 1:
        a, b, res = multimerge_(candidates, merge_func)
        if res is None:
            return candidates
        candidates.remove(b)
        if a is not res:
            candidates.remove(a)
            candidates.append(res)
        # else: in place merge
    return candidates[0]

def multimerge_(candidates, merge_func):
    for a, b in permutations(candidates, 2):
        res = merge_func(a, b)
        if res is not None:
            return a, b, res
    return None, None, None


try:
    from itertools import permutations
    permutations # prevent warning
except ImportError:
    def permutations(iterable, r=None):
        # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC
        # permutations(range(3)) --> 012 021 102 120 201 210
        pool = tuple(iterable)
        n = len(pool)
        r = n if r is None else r
        if r > n:
            return
        indices = range(n)
        cycles = range(n, n-r, -1)
        yield tuple(pool[i] for i in indices[:r])
        while n:
            for i in reversed(range(r)):
                cycles[i] -= 1
                if cycles[i] == 0:
                    indices[i:] = indices[i+1:] + indices[i:i+1]
                    cycles[i] = n - i
                else:
                    j = cycles[i]
                    indices[i], indices[-j] = indices[-j], indices[i]
                    yield tuple(pool[i] for i in indices[:r])
                    break
            else:
                return
########NEW FILE########
__FILENAME__ = multipolygon
# Copyright 2011 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import division
import os
import time

from imposm.geom import (
    PolygonBuilder,
    LineStringBuilder,
    InvalidGeometryError,
    IncompletePolygonError,
)
from imposm.merge import merge

import imposm.base
import imposm.geom
import imposm.config
import shapely.geometry
import shapely.ops
import shapely.geos
import shapely.prepared

import logging
log = logging.getLogger(__name__)

def RelationBuilder(*args, **kw):
    if imposm.config.relation_builder == 'contains':
        return ContainsRelationBuilder(*args, **kw)
    if imposm.config.relation_builder == 'union':
        return UnionRelationBuilder(*args, **kw)
    raise ValueError('unknown relation_builder "%s"'
        % (imposm.config.relation_builder, ))

class RelationBuilderBase(object):
    validate_rings = True
    def __init__(self, relation, ways_cache, coords_cache):
        self.relation = relation
        self.polygon_builder = PolygonBuilder()
        self.linestring_builder = LineStringBuilder()
        self.ways_cache = ways_cache
        self.coords_cache = coords_cache

    def fetch_ways(self):
        ways = []
        for member in self.relation.members:
            # skip label nodes, relations of relations, etc
            if member[1] != 'way': continue
            way = self.ways_cache.get(member[0])
            if way is None:
                log.debug('way not found %s:%s', self.relation.osm_id, member[0])
                if imposm.config.import_partial_relations:
                    continue
                else:
                    raise IncompletePolygonError('way not found %s:%s' % (self.relation.osm_id, member[0]))
            if way.partial_refs:
                log.warn('multiple linestrings in way %s (relation %s)',
                       member[0], self.relation.osm_id)
                raise IncompletePolygonError()

            way.coords = self.fetch_way_coords(way)
            if way.coords is None:
                if not imposm.config.import_partial_relations:
                    raise IncompletePolygonError()
            else:
                ways.append(way)
        return ways

    def build_rings(self, ways):
        rings = []
        incomplete_rings = []

        for ring in (Ring(w) for w in ways):
            if ring.is_closed():
                ring.geom = self.polygon_builder.build_checked_geom(ring, validate=self.validate_rings)
                rings.append(ring)
            else:
                incomplete_rings.append(ring)

        merged_rings = self.build_ring_from_incomplete(incomplete_rings)
        if len(rings) + len(merged_rings) == 0:
            raise IncompletePolygonError('linestrings from relation %s have no rings' % (self.relation.osm_id, ))

        return rings + merged_rings

    def build_ring_from_incomplete(self, incomplete_rings):

        rings = merge_rings(incomplete_rings)

        for ring in rings[:]:
            if not ring.is_closed():
                if imposm.config.import_partial_relations:
                    rings.remove(ring)
                    continue
                else:
                    raise InvalidGeometryError('linestrings from relation %s do not form a ring' %
                        self.relation.osm_id)
            ring.geom = self.polygon_builder.build_checked_geom(ring, validate=self.validate_rings)
        return rings

    def fetch_way_coords(self, way):
        """
        Fetch all coordinates of way.refs.
        """
        coords = self.coords_cache.get_coords(way.refs)
        if coords is None:
            log.debug('missing coord from way %s in relation %s',
                way.osm_id, self.relation.osm_id)
            return None
        return coords

    def build_relation_geometry(self, rings):
        """
        Build relation geometry from rings.
        """
        raise NotImplementedError()

    def build(self):
        try:
            time_start = time.time()
            ways = self.fetch_ways()
            time_ways = time.time() - time_start
            if not ways:
                raise IncompletePolygonError('no ways found')
            time_start = time.time()
            rings = self.build_rings(ways)
            time_rings = time.time() - time_start

            if (imposm.config.imposm_multipolygon_max_ring
                and len(rings) > imposm.config.imposm_multipolygon_max_ring):
                log.warn('skipping relation %d with %d ways (%.1fms) and %d rings (%.1fms): too many rings',
                    self.relation.osm_id, len(ways), time_ways*1000, len(rings), time_rings*1000)
                raise IncompletePolygonError('skipping too large multipolygon')
            time_start = time.time()
            self.build_relation_geometry(rings)
            time_relations = time.time() - time_start

            if time_ways + time_rings + time_relations > imposm.config.imposm_multipolygon_report:
                log.warn('building relation %d with %d ways (%.1fms) and %d rings (%.1fms) took %.1fms',
                    self.relation.osm_id, len(ways), time_ways*1000, len(rings), time_rings*1000, time_relations*1000)
        except InvalidGeometryError, ex:
            log.debug(ex)
            raise IncompletePolygonError(ex)
        except IncompletePolygonError:
            raise
        except Exception, ex:
            log.warn('error while building multipolygon:')
            log.exception(ex)
            raise IncompletePolygonError(ex)


class UnionRelationBuilder(RelationBuilderBase):
    def build_relation_geometry(self, rings):
        """
        Build relation geometry from rings.
        """
        rings.sort(key=lambda x: x.geom.area, reverse=True)

        # add/subtract all rings from largest
        polygon = rings[0]
        rel_tags = relation_tags(self.relation.tags, polygon.tags)
        polygon.mark_as_inserted(rel_tags)

        geom = polygon.geom
        for r in rings[1:]:
            if geom.contains(r.geom):
                # inside -> hole -> subtract
                geom = geom.difference(r.geom)
                r.mark_as_inserted(rel_tags)
            else:
                # outside or overlap -> merge(union) to multipolygon or to polygon
                try:
                    geom = geom.union(r.geom)
                except shapely.geos.TopologicalError:
                    raise InvalidGeometryError('multipolygon relation (%s) result is invalid'
                                               ' (topological error)' % self.relation.osm_id)
                r.mark_as_inserted(rel_tags)
        if not geom.is_valid:
            raise InvalidGeometryError('multipolygon relation (%s) result is invalid' %
                                       self.relation.osm_id)

        self.relation.geom = geom
        self.relation.tags = rel_tags
        all_ways = polygon.ways
        for r in rings:
            all_ways.extend(r.ways)
        self.relation.ways = all_ways

class ContainsRelationBuilder(RelationBuilderBase):
    validate_rings = False

    def _ring_is_hole(self, rings, idx):
        """
        Returns True if rings[idx] is a hole, False if it is a
        shell (also if hole in a hole, etc)
        """
        contained_counter = 0
        while True:
            idx = rings[idx].contained_by
            if idx is None:
                break
            contained_counter += 1

        return contained_counter % 2 == 1

    def build_relation_geometry(self, rings):
        """
        Build relation geometry from rings.
        """
        rings.sort(key=lambda x: x.geom.area, reverse=True)
        total_rings = len(rings)

        shells = set([rings[0]])

        for i in xrange(total_rings):
            test_geom = shapely.prepared.prep(rings[i].geom)
            for j in xrange(i+1, total_rings):
                if test_geom.contains(rings[j].geom):
                    # j in inside of i
                    if rings[j].contained_by is not None:
                        # j is inside a larger ring, remove that relationship
                        # e.g. j is hole inside a hole (i)
                        rings[rings[j].contained_by].holes.discard(rings[j])
                        shells.discard(rings[j])

                    # remember parent
                    rings[j].contained_by = i

                    # add ring as hole or shell
                    if self._ring_is_hole(rings, j):
                        rings[i].holes.add(rings[j])
                    else:
                        shells.add(rings[j])
            if rings[i].contained_by is None:
                # add as shell if it is not a hole
                shells.add(rings[i])

        rel_tags = relation_tags(self.relation.tags, rings[0].tags)

        # build polygons from rings
        polygons = []
        for shell in shells:
            shell.mark_as_inserted(rel_tags)
            exterior = shell.geom.exterior
            interiors = []
            for hole in shell.holes:
                hole.mark_as_inserted(rel_tags)
                interiors.append(hole.geom.exterior)

            polygons.append(shapely.geometry.Polygon(exterior, interiors))

        if len(polygons) == 1:
            geom = polygons[0]
        else:
            geom = shapely.geometry.MultiPolygon(polygons)

        geom = imposm.geom.validate_and_simplify(geom)
        if not geom.is_valid:
            raise InvalidGeometryError('multipolygon relation (%s) result is invalid' %
                                       self.relation.osm_id)
        self.relation.geom = geom
        self.relation.tags = rel_tags
        all_ways = []
        for r in rings:
            all_ways.extend(r.ways)
        self.relation.ways = all_ways


def relation_tags(rel_tags, way_tags):
    result = dict(rel_tags)

    if 'type' in result: del result['type']
    if 'name' in result: del result['name']

    if not result:
        # use way_tags
        result.update(way_tags)
    else:
        if 'name' in rel_tags:
            # put back name
            result['name'] = rel_tags['name']

    return result

def tags_differ(a, b):
    a_ = dict(a)
    a_.pop('name', None)
    b_ = dict(b)
    b_.pop('name', None)
    return a_ != b_

def tags_same_or_empty(a, b):
    return (
        not b or
        not tags_differ(a, b)
    )

def merge_rings(rings):
    """
    Merge rings at the endpoints.
    """
    endpoints = {}
    for ring in rings:
        if len(ring.refs) < 2:
            continue
        left = ring.refs[0]
        right = ring.refs[-1]
        orig_ring = None
        if left in endpoints:
            orig_ring = endpoints.pop(left)
            if left == orig_ring.refs[-1]:
                orig_ring.refs = orig_ring.refs + ring.refs[1:]
                orig_ring.coords = orig_ring.coords + ring.coords[1:]
            else:
                orig_ring.refs = orig_ring.refs[::-1] + ring.refs[1:]
                orig_ring.coords = orig_ring.coords[::-1] + ring.coords[1:]
            orig_ring.ways.extend(ring.ways)
            orig_ring.tags.update(ring.tags)
            if right in endpoints and endpoints[right] is not orig_ring:
                # close gap
                ring = endpoints.pop(right)
                if right == ring.refs[0]:
                    orig_ring.refs = orig_ring.refs + ring.refs[1:]
                    orig_ring.coords = orig_ring.coords + ring.coords[1:]
                else:
                    orig_ring.refs = orig_ring.refs[:-1] + ring.refs[::-1]
                    orig_ring.coords = orig_ring.coords[:-1] + ring.coords[::-1]
                orig_ring.ways.extend(ring.ways)
                orig_ring.tags.update(ring.tags)
                right  = orig_ring.refs[-1]
                endpoints[right] = orig_ring
            else:
                endpoints[right] = orig_ring
        elif right in endpoints:
            orig_ring = endpoints.pop(right)
            if right == orig_ring.refs[0]:
                orig_ring.refs = ring.refs[:-1] + orig_ring.refs
                orig_ring.coords = ring.coords[:-1] + orig_ring.coords
            else:
                orig_ring.refs = orig_ring.refs[:-1] + ring.refs[::-1]
                orig_ring.coords = orig_ring.coords[:-1] + ring.coords[::-1]
            orig_ring.ways.extend(ring.ways)
            orig_ring.tags.update(ring.tags)
            endpoints[left] = orig_ring
        else:
            endpoints[left] = ring
            endpoints[right] = ring
    return list(set(endpoints.values()))

class Ring(object):
    """
    Represents a ring (i.e. polygon without holes) build from one
    or more ways. Stores references to the building ways.
    """
    def __init__(self, way):
        self.ways = [way]
        self.osm_id = way.osm_id
        self.refs = way.refs
        self.coords = way.coords
        self.tags = dict(way.tags)
        self.inserted = way.inserted
        self.contained_by = None
        self.holes = set()

    def __repr__(self):
        return 'Ring(%r, %r, %r)' % (self.osm_id, self.tags, self.ways)

    def merge(self, ring, without_refs=False):
        """
        Try to merge `ring.refs` with this ring.
        Returns `self` on success, else `None`.
        """
        if without_refs:
            result = None
        else:
            result = merge(self.refs, ring.refs)
            if result is None:
                return None

        self.ways.extend(ring.ways)
        self.refs = [result]
        self.tags.update(ring.tags)
        return self

    def is_closed(self):
        return len(self.refs) >= 4 and self.refs[0] == self.refs[-1]

    def mark_as_inserted(self, tags):
        for w in self.ways:
            if tags_same_or_empty(tags, w.tags):
                w.inserted = True
        if tags_same_or_empty(tags, self.tags):
            self.inserted = True

########NEW FILE########
__FILENAME__ = psqldb
# Copyright 2011 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import optparse
import string
from os.path import join, dirname, exists

db_create_template = """
# run this as postgres user, eg:
# imposm-psqldb > create_db.sh; sudo su postgres; sh ./create_db.sh
set -xe
createuser --no-superuser --no-createrole --createdb ${user}
createdb -E UTF8 -O ${user} ${dbname}
createlang plpgsql ${dbname}
${postgis}
echo "ALTER TABLE spatial_ref_sys OWNER TO ${user};" | psql -d ${dbname}
echo "ALTER USER ${user} WITH PASSWORD '${password}';" |psql -d ${dbname}
echo "host\t${dbname}\t${user}\t127.0.0.1/32\tmd5" >> ${pg_hba}
set +x
echo "Done. Don't forget to restart postgresql!"
""".strip()

postgis_create_template_15 = """
psql -d ${dbname} -f ${postgis_sql}
psql -d ${dbname} -f ${spatial_ref_sys_sql}
psql -d ${dbname} -f ${epsg900913_sql}
echo "ALTER TABLE geometry_columns OWNER TO ${user};" | psql -d ${dbname}
""".strip()

postgis_create_template_20 = """
echo "CREATE EXTENSION postgis;" | psql -d ${dbname}
echo "ALTER TABLE geometry_columns OWNER TO ${user};" | psql -d ${dbname}
psql -d ${dbname} -f ${epsg900913_sql}
""".strip()

def find_sql_files(version, postgis_version, mapping):

    pg_hba = '/path/to/pg_hba.conf \t# <- CHANGE THIS PATH'
    postgis_sql = '/path/to/postgis.sql \t\t\t\t# <- CHANGE THIS PATH'
    spatial_ref_sys_sql = '/path/to/spatial_ref_sys.sql \t\t\t# <- CHANGE THIS PATH'

    if version in ('8.3', 'auto'):
        p = '/usr/share/postgresql-8.3-postgis/lwpostgis.sql'
        if exists(p):
            postgis_sql = p
        p = '/usr/share/postgresql-8.3-postgis/spatial_ref_sys.sql'
        if exists(p):
            spatial_ref_sys_sql = p
        p = '/etc/postgresql/8.3/main/pg_hba.conf'
        if exists(p):
            pg_hba = p

    if version in ('8.4', 'auto'):
        p = '/usr/share/postgresql/8.4/contrib/postgis.sql'
        if exists(p):
            postgis_sql = p
        p = '/usr/share/postgresql/8.4/contrib/postgis-1.5/postgis.sql'
        if exists(p):
            postgis_sql = p
        p = '/usr/share/postgresql/8.4/contrib/spatial_ref_sys.sql'
        if exists(p):
            spatial_ref_sys_sql = p
        p = '/usr/share/postgresql/8.4/contrib/postgis-1.5/spatial_ref_sys.sql'
        if exists(p):
            spatial_ref_sys_sql = p
        p = '/etc/postgresql/8.4/main/pg_hba.conf'
        if exists(p):
            pg_hba = p

    if version in ('9.1', 'auto'):
        p = '/usr/share/postgresql/9.1/contrib/postgis-1.5/postgis.sql'
        if exists(p):
            postgis_sql = p
        p = '/usr/share/postgresql/9.1/contrib/postgis-1.5/spatial_ref_sys.sql'
        if exists(p):
            spatial_ref_sys_sql = p
        p = '/etc/postgresql/9.1/main/pg_hba.conf'
        if exists(p):
            pg_hba = p

    if postgis_version == '2.0':
        postgis_sql = None
        spatial_ref_sys_sql = None

    mapping['postgis_sql'] = postgis_sql
    mapping['spatial_ref_sys_sql'] = spatial_ref_sys_sql
    mapping['pg_hba'] = pg_hba
    mapping['pg_version'] = postgis_version

def main():
    usage = '%prog [options]'
    desc = 'Outputs shell commands to create a PostGIS database.'
    parser = optparse.OptionParser(usage=usage, description=desc)
    parser.add_option('--database', dest='dbname', metavar='osm', default='osm')
    parser.add_option('--user', dest='user', metavar='osm', default='osm')
    parser.add_option('--password', dest='password', metavar='osm', default='osm')
    parser.add_option('--pg-version', dest='pg_version', metavar='8.3|8.4|9.1|auto', default='auto')
    parser.add_option('--postgis-version', dest='postgis_version', metavar='1.5|2.0', default='1.5')

    (options, args) = parser.parse_args()

    mapping = {
        'user': options.user,
        'dbname': options.dbname,
        'password': options.password,
    }

    mapping['epsg900913_sql'] = join(dirname(__file__), '900913.sql')
    find_sql_files(options.pg_version, options.postgis_version, mapping)

    if options.postgis_version == '2.0':
        mapping['postgis'] = string.Template(postgis_create_template_20).substitute(mapping)
    else:
        mapping['postgis'] = string.Template(postgis_create_template_15).substitute(mapping)

    template = string.Template(db_create_template)
    print template.substitute(mapping)



if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = reader
# Copyright 2011 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from functools import partial
from multiprocessing import Process, JoinableQueue

from imposm.parser import OSMParser
from imposm.util import setproctitle

class ImposmReader(object):
    def __init__(self, mapping, cache, pool_size=2, merge=False, logger=None):
        self.pool_size = pool_size
        self.mapper = mapping
        self.merge = merge
        self.cache = cache
        self.reader = None
        self.logger = logger
        self.estimated_coords = 0

    def read(self, filename):
        nodes_queue = JoinableQueue(128)
        coords_queue = JoinableQueue(512)
        ways_queue = JoinableQueue(128)
        relations_queue = JoinableQueue(128)

        log_proc = self.logger()
        log_proc.start()

        marshal = True
        if self.merge:
            # merging needs access to unmarshaled data
            marshal = False

        estimates = {
            'coords': self.estimated_coords,
            'nodes': self.estimated_coords//50,
            'ways': self.estimated_coords//7,
            'relations': self.estimated_coords//1000,
        }

        coords_writer = CacheWriterProcess(coords_queue, self.cache.coords_cache,
            estimates['coords'], log=partial(log_proc.log, 'coords'),
            marshaled_data=marshal)
        coords_writer.start()

        nodes_writer = CacheWriterProcess(nodes_queue, self.cache.nodes_cache,
            estimates['nodes'], log=partial(log_proc.log, 'nodes'),
            marshaled_data=marshal)
        nodes_writer.start()


        ways_writer = CacheWriterProcess(ways_queue, self.cache.ways_cache,
            estimates['ways'], merge=self.merge, log=partial(log_proc.log, 'ways'),
            marshaled_data=marshal)
        ways_writer.start()

        relations_writer = CacheWriterProcess(relations_queue, self.cache.relations_cache,
            estimates['relations'], merge=self.merge, log=partial(log_proc.log, 'relations'),
            marshaled_data=marshal)
        relations_writer.start()

        log_proc.message('coords: %dk nodes: %dk ways: %dk relations: %dk (estimated)' % (
            estimates['coords']/1000, estimates['nodes']/1000, estimates['ways']/1000,
            estimates['relations']/1000)
        )

        # keep one CPU free for writer proc on hosts with 4 or more CPUs
        pool_size = self.pool_size if self.pool_size < 4 else self.pool_size - 1

        parser = OSMParser(pool_size, nodes_callback=nodes_queue.put, coords_callback=coords_queue.put,
            ways_callback=ways_queue.put, relations_callback=relations_queue.put, marshal_elem_data=marshal)

        parser.nodes_tag_filter = self.mapper.tag_filter_for_nodes()
        parser.ways_tag_filter = self.mapper.tag_filter_for_ways()
        parser.relations_tag_filter = self.mapper.tag_filter_for_relations()

        parser.parse(filename)

        coords_queue.put(None)
        nodes_queue.put(None)
        ways_queue.put(None)
        relations_queue.put(None)
        coords_writer.join()
        nodes_writer.join()
        ways_writer.join()
        relations_writer.join()
        log_proc.stop()
        log_proc.join()


class CacheWriterProcess(Process):
    def __init__(self, queue, cache, estimated_records=None, merge=False, log=None,
        marshaled_data=False):
        Process.__init__(self)
        self.daemon = True
        setproctitle('imposm writer')
        self.queue = queue
        self.cache = cache
        self.merge = merge
        self.log = log
        self.marshaled_data = marshaled_data
        self.estimated_records = estimated_records

    def run(self):
        # print 'creating %s (%d)' % (self.filename, self.estimated_records or 0)
        cache = self.cache(mode='w', estimated_records=self.estimated_records)
        if self.marshaled_data:
            cache_put = cache.put_marshaled
        else:
            cache_put = cache.put
        while True:
            data = self.queue.get()
            if data is None:
                self.queue.task_done()
                break
            if self.merge:
                for d in data:
                    if d[0] in cache:
                        elem = cache.get(d[0])
                        elem.merge(*d[1:])
                        d = elem.to_tuple()
                    cache_put(*d)
            else:
                for d in data:
                    cache_put(*d)
            if self.log:
                self.log(len(data))
            self.queue.task_done()
        cache.close()



########NEW FILE########
__FILENAME__ = test_cache
# Copyright 2011 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import tempfile
from imposm.cache.tc import NodeDB, CoordDB, DeltaCoordsDB

from nose.tools import eq_, assert_almost_equal


class TestNodeDB(object):
    def setup(self):
        fd_, self.fname = tempfile.mkstemp('.db')
        self.db = NodeDB(self.fname)
    
    def teardown(self):
        os.unlink(self.fname)
    
    def test_insert(self):
        assert self.db.put(1000, {'foo': 2}, (123, 456))
        assert self.db.put(2**40, {'bar': 2}, (123, 456))
        
        nd = self.db.get(1000)
        eq_(nd.osm_id, 1000)
        eq_(nd.tags, {'foo': 2})
        eq_(nd.coord, (123, 456))

        nd = self.db.get(2**40)
        eq_(nd.osm_id, 2**40)

    
    def test_read_only(self):
        assert self.db.put(1000, {'foo': 2}, (123, 456))
        assert self.db.put(2**40, {'bar': 2}, (123, 456))
        self.db.close()
        self.db = NodeDB(self.fname, 'r')
        
        nd = self.db.get(1000)
        eq_(nd.osm_id, 1000)
        eq_(nd.tags, {'foo': 2})
        eq_(nd.coord, (123, 456))

        nd = self.db.get(2**40)
        eq_(nd.osm_id, 2**40)
        
        assert not self.db.put(1001, {'foo': 2}, (123, 456))
        assert not self.db.get(1001)

    def test_iter(self):
        assert self.db.put(1000, {'foo': 2}, (123, 456))
        
        nds = list(self.db)
        eq_(len(nds), 1)
        
        nd = nds[0]
        eq_(nd.osm_id, 1000)
        eq_(nd.tags, {'foo': 2})
        eq_(nd.coord, (123, 456))


class TestCoordDB(object):
    testclass = CoordDB
    def setup(self):
        fd_, self.fname = tempfile.mkstemp('.db')
        self.db = self.testclass(self.fname)

    def teardown(self):
        os.unlink(self.fname)

    def test_insert(self):
        assert self.db.put(1000, 123, 179.123456789)
        assert self.db.put(2**40, 123, 179.123456789)
        assert self.db.put(2**40+1, 123, 179.123456789)
        
        pos = self.db.get(1000)
        assert_almost_equal(pos[0], 123.0, 6)
        assert_almost_equal(pos[1], 179.123456789, 6)

        assert self.db.get(2**40)
        assert self.db.get(2**40+1)
    
    def test_read_only(self):
        assert self.db.put(1000, 123, 0)
        assert self.db.put(1001, -180.0, -90)
        assert self.db.put(1010, 180, 90)
        assert self.db.put(2**40, 123, 179.123456789)
        assert self.db.put(2**40+1, 123, 179.123456789)
        
        self.db.close()
        self.db = self.testclass(self.fname, 'r')
        
        pos = self.db.get(1000)
        assert_almost_equal(pos[0], 123.0, 6)
        assert_almost_equal(pos[1], 0.0, 6)

        pos = self.db.get(1001)
        assert_almost_equal(pos[0], -180.0, 6)
        assert_almost_equal(pos[1], -90.0, 6)
        
        pos = self.db.get(1010)
        assert_almost_equal(pos[0], 180.0, 6)
        assert_almost_equal(pos[1], 90.0, 6)
        
        assert self.db.get(2**40)
        assert self.db.get(2**40+1)
        
        assert not self.db.put(2001, 123, 456)
        assert not self.db.get(2001)


class TestDeltaCoordDB(TestCoordDB):
    testclass = DeltaCoordsDB

    def setup(self):
        fd_, self.fname = tempfile.mkstemp('.db')
        self.db = DeltaCoordsDB(self.fname)

########NEW FILE########
__FILENAME__ = test_dbimporter
# Copyright 2012 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from imposm.dbimporter import DictBasedImporter, TupleBasedImporter
from imposm import defaultmapping

from nose.tools import eq_, assert_almost_equal

class TestDictBasedImporter(object):
    def setup(self):
        dummy_db = None
        mapper = None
        self.importer = DictBasedImporter(None, dummy_db, mapper, None,
            dry_run=False)

    def test_insert(self):
        mappings = [
            (('highway', 'secondary'), [defaultmapping.mainroads]),
            (('railway', 'tram'), [defaultmapping.railways]),
            (('landusage', 'grass'), [defaultmapping.landusages]),
        ]
        assert self.importer.insert(mappings, 1234, [(0, 0), (1, 0), (1, 1), (0, 0)],
            {'highway': 'secondary', 'railway': 'tram', 'oneway': '1',
             'name': 'roundabout',
            }
        )

        # get items, sort by mapping_names so that landusages comes first
        queue_items = [self.importer.db_queue.get(), self.importer.db_queue.get()]
        queue_items.sort(key=lambda x: x['mapping_names'])

        polygon_item = queue_items[0]
        linestring_item = queue_items[1]

        eq_(linestring_item['mapping_names'], ['mainroads', 'railways'])
        eq_(linestring_item['osm_id'], 1234)
        eq_(linestring_item['fields'], {
            'highway': 'secondary',
            'railway': 'tram',
            'oneway': 1,
            'z_order': 7,
            'bridge': 0,
            'tunnel': 0,
            'name': 'roundabout',
            'ref': None
        })
        eq_(polygon_item['mapping_names'], ['landusages'])
        eq_(polygon_item['osm_id'], 1234)
        assert_almost_equal(polygon_item['fields']['area'], 6195822904.182782)
        del polygon_item['fields']['area']
        eq_(polygon_item['fields'], {
            'z_order': 27,
            'landusage': 'grass',
            'name': 'roundabout',
        })

class TestTupleBasedImporter(object):
    def setup(self):
        dummy_db = None
        mapper = None
        self.importer = TupleBasedImporter(None, dummy_db, mapper, None,
            dry_run=False)

    def test_insert(self):
        mappings = [
            (('highway', 'secondary'), [defaultmapping.mainroads]),
            (('railway', 'tram'), [defaultmapping.railways]),
            (('landusage', 'grass'), [defaultmapping.landusages]),
        ]
        assert self.importer.insert(mappings, 1234, [(0, 0), (1, 0), (1, 1), (0, 0)],
            {'highway': 'secondary', 'railway': 'tram', 'oneway': '1',
             'name': 'roundabout',
            }
        )

        mainroads_item = self.importer.db_queue.get()
        eq_(mainroads_item[0], defaultmapping.mainroads)
        eq_(mainroads_item[1], 1234)
        eq_(mainroads_item[3], ['roundabout', 'secondary', 0, 0, 1, None, 5])

        railways_item = self.importer.db_queue.get()
        eq_(railways_item[0], defaultmapping.railways)
        eq_(railways_item[1], 1234)
        eq_(railways_item[3], ['roundabout', 'tram', 0, 0, 7])

        landusages_item = self.importer.db_queue.get()
        eq_(landusages_item[0], defaultmapping.landusages)
        eq_(landusages_item[1], 1234)
        eq_(landusages_item[3], ['roundabout', 'grass', 6195822904.182782, 27])

########NEW FILE########
__FILENAME__ = test_field_types
# Copyright 2011 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import imposm

from imposm.base import OSMElem
from imposm.mapping import Name, LocalizedName


def test_name_field():
    name = Name()
    elem = OSMElem(1, [], 'test', tags={'name': 'fixme'})
    assert name.value('fixme', elem) == ''
    assert elem.name == ''
    
    elem = OSMElem(1, [], 'test', tags={'name': 'Foo Street'})
    assert name.value('Foo Street', elem) == 'Foo Street'
    assert elem.name == 'Foo Street'

def test_localized_name_field():
    name = LocalizedName(['name:de', 'name:en', 'foo'])
    elem = OSMElem(1, [], 'test', tags={'name': 'Foo'})
    assert name.value(None, elem) == ''
    assert elem.name == ''

    elem = OSMElem(1, [], 'test', tags={'name:de': 'Foo', 'name:en': 'Bar'})
    assert name.value(None, elem) == 'Foo'
    assert elem.name == 'Foo'

    elem = OSMElem(1, [], 'test', tags={'name:es': 'Foo', 'name:en': 'Bar'})
    assert name.value(None, elem) == 'Bar'
    assert elem.name == 'Bar'

    elem = OSMElem(1, [], 'test', tags={'name:es': 'Foo', 'foo': 'Bar'})
    assert name.value(None, elem) == 'Bar'
    assert elem.name == 'Bar'
    

########NEW FILE########
__FILENAME__ = test_imported
# Copyright 2011 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
import os
import tempfile
import shutil

from contextlib import contextmanager

import imposm.app
import imposm.db.config
import imposm.mapping

from nose.tools import eq_
from nose.plugins import skip

temp_dir = None
old_cwd = None

try:
    from imposm_test_conf import db_conf
    db_conf = imposm.mapping.Options(db_conf)
except ImportError:
    raise skip.SkipTest('no imposm_test_conf.py with db_conf found')

def setup_module():
    global old_cwd, temp_dir
    old_cwd = os.getcwd()
    temp_dir = tempfile.mkdtemp()
    os.chdir(temp_dir)
    test_osm_file = os.path.join(os.path.dirname(__file__), 'test.out.osm')
    with capture_out():
        print db_conf.password
        imposm.app.main(['--read', test_osm_file, '--write',
            '--proj', db_conf.proj, '--table-prefix', db_conf.prefix,
            '--connect', 'postgis://%(user)s:%(password)s@%(host)s:%(port)s/%(db)s' % db_conf])

class TestImported(object):
    def __init__(self):
        self.db = imposm.db.config.DB(db_conf)

    def test_point(self):
        cur = self.db.cur
        cur.execute('select osm_id, name, ST_AsText(geometry) from %splaces where osm_id = 1' % db_conf.prefix)
        results = cur.fetchall()
        eq_(len(results), 1)
        eq_(results[0], (1, 'Foo', 'POINT(13 47.5)'))

    def test_way(self):
        cur = self.db.cur
        cur.execute('select osm_id, name, ST_AsText(geometry) from %slandusages where osm_id = 1001' % db_conf.prefix)
        results = cur.fetchall()
        eq_(len(results), 1)
        eq_(results[0][:-1], (1001, 'way 1001',))
        eq_(roundwkt(results[0][-1]), 'POLYGON((13.0 47.5,14.5 50.0,16.5 49.0,17.0 47.0,14.5 45.5,13.0 47.5),(14.0 47.5,15.0 47.0,15.5 48.0,14.5 48.5,14.0 47.5))')

        cur.execute('select osm_id, name, ST_AsText(geometry) from %slandusages where osm_id = 2001' % db_conf.prefix)
        results = cur.fetchall()
        eq_(len(results), 1)
        eq_(results[0][:-1], (2001, 'way 2001',))
        eq_(roundwkt(results[0][-1]), 'POLYGON((23.0 47.5,24.5 50.0,26.5 49.0,27.0 47.0,24.5 45.5,23.0 47.5),(24.5 47.0,25.5 46.5,26.0 47.5,25.0 47.5,24.5 47.0),(24.2 48.25,25.25 47.7,25.7 48.8,24.7 49.25,24.2 48.25))')


        cur.execute('select osm_id, name, ST_AsText(geometry) from %slandusages where osm_id = 3001' % db_conf.prefix)
        results = cur.fetchall()
        eq_(len(results), 1)
        eq_(results[0][:-1], (3001, 'way 3002',))
        eq_(roundwkt(results[0][-1]), 'POLYGON((33.0 47.5,34.5 50.0,36.5 49.0,37.0 47.0,34.5 45.5,33.0 47.5),(34.0 47.5,35.0 47.0,35.5 48.0,34.5 48.5,34.0 47.5))')


def roundwkt(wkt):
    def round_num(num_str):
        return str(round(float(num_str.group(0)), 2))
    return re.sub('\d+(\.\d+)?', round_num, wkt)

def teardown_module():
    if old_cwd:
        os.chdir(old_cwd)

    if temp_dir and os.path.exists(temp_dir):
        shutil.rmtree(temp_dir)


@contextmanager
def capture_out():
    import sys
    from cStringIO import StringIO

    old_stdout = sys.stdout
    old_stderr = sys.stderr
    try:
        sys.stdout = StringIO()
        sys.stderr = StringIO()
        yield sys.stdout, sys.stderr
    finally:
        sys.stdout = old_stdout
        sys.stderr = old_stderr

########NEW FILE########
__FILENAME__ = test_limit_to
# Copyright 2012 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from imposm.geom import LimitPolygonGeometry, EmtpyGeometryError
from shapely.wkt import loads

from nose.tools import raises

class TestLimitPolygonGeometry(object):

    @raises(EmtpyGeometryError)
    def test_linestring_no_intersection(self):
        geom = 'POLYGON((0 0, 10 0, 10 10, 0 10, 0 0))'
        limit_to = LimitPolygonGeometry(loads(geom))
        limit_to.intersection(loads('LINESTRING(-100 -100, -50 -50)'))

    def test_linestring(self):
        geom = 'POLYGON((0 0, 10 0, 10 10, 0 10, 0 0))'
        limit_to = LimitPolygonGeometry(loads(geom))
        geom = limit_to.intersection(loads('LINESTRING(-10 -10, 20 20)'))
        assert geom.almost_equals(loads('LINESTRING(0 0, 10 10)'))

    def test_linestring_contained(self):
        geom = 'POLYGON((0 0, 10 0, 10 10, 0 10, 0 0))'
        limit_to = LimitPolygonGeometry(loads(geom))
        test_geom = loads('LINESTRING(1 1, 9 9)')
        geom = limit_to.intersection(test_geom)
        # should return unmodified input geometry
        assert geom is test_geom

    def test_linestring_multilinestring_result(self):
        geom = 'POLYGON((0 0, 10 0, 10 10, 0 10, 0 0))'
        limit_to = LimitPolygonGeometry(loads(geom))
        geom = limit_to.intersection(loads('LINESTRING(-10 -20, 5 10, 20 -20)'))
        assert isinstance(geom, list)
        assert geom[0].almost_equals(loads('LINESTRING(0 0, 5 10)'))
        assert geom[1].almost_equals(loads('LINESTRING(5 10, 10 0)'))

    @raises(EmtpyGeometryError)
    def test_linestring_point_result(self):
        geom = 'POLYGON((0 0, 10 0, 10 10, 0 10, 0 0))'
        limit_to = LimitPolygonGeometry(loads(geom))
        geom = limit_to.intersection(loads('LINESTRING(-10 -10, 0 0)'))

    def test_linestring_mixed_result(self):
        geom = 'POLYGON((0 0, 10 0, 10 10, 0 10, 0 0))'
        limit_to = LimitPolygonGeometry(loads(geom))
        geom = limit_to.intersection(loads('LINESTRING(0 0, 5 -10, 5 10)'))
        # point and linestring, point not returned
        assert isinstance(geom, list)
        assert len(geom) == 1
        assert geom[0].almost_equals(loads('LINESTRING(5 0, 5 10)'))

    def test_polygon_mixed_result(self):
        geom = 'POLYGON((0 0, 10 0, 10 10, 0 10, 0 0))'
        limit_to = LimitPolygonGeometry(loads(geom))
        test_geom = loads('POLYGON((0 -10, 0 5, 2.5 -5, 5 0, 7.5 -5, 10 5, 10 -10, 0 -10))')
        geom = limit_to.intersection(test_geom)
        # point and two polygons, point not returned
        assert isinstance(geom, list)
        assert len(geom) == 2
        assert geom[0].almost_equals(loads('POLYGON((1.25 0, 0 0, 0 5, 1.25 0))'))
        assert geom[1].almost_equals(loads('POLYGON((10 0, 8.75 0, 10 5, 10 0))'))

    def test_polygon_multipolygon_result(self):
        geom = 'POLYGON((0 0, 10 0, 10 10, 0 10, 0 0))'
        limit_to = LimitPolygonGeometry(loads(geom))
        test_geom = loads('POLYGON((0 -10, 0 5, 2.5 -5, 5 -1, 7.5 -5, 10 5, 10 -10, 0 -10))')
        geom = limit_to.intersection(test_geom)
        # similar to above, but point does not touch the box, so we should get
        # a single multipolygon
        assert geom.almost_equals(loads(
            'MULTIPOLYGON(((1.25 0, 0 0, 0 5, 1.25 0)),'
            '((10 0, 8.75 0, 10 5, 10 0)))'))

########NEW FILE########
__FILENAME__ = test_multipolygon
# Copyright 2011 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from imposm.base import Relation, Way
from imposm.multipolygon import UnionRelationBuilder, ContainsRelationBuilder, Ring, merge_rings

from nose.tools import eq_, assert_almost_equal

class RelationBuilderTestBase(object):

    def test_broken_polygon_self_intersect(self):
        #  2##3    6##7
        #  #  #    ####
        #  1##4____5##8
        w1 = Way(1, {}, [1, 2, 3, 4, 5, 6, 7, 8, 1])
        w1.coords = [(0, 0), (0, 10), (10, 10), (10, 0), (20, 0), (20, 10), (30, 10), (30, 0), (0, 0)]
        w2 = Way(2, {}, [15, 16, 17, 18, 15])
        w2.coords = [(2, 2), (8, 2), (8, 8), (2, 8), (2, 2)]
        yield self.check_broken_polygon, w1, w2

        #  2##3    6##7
        #  #  #    ####
        #  1##4____5##8
        w1 = Way(1, {}, [4, 1, 2, 3, 4, 5, 6, 7, 8, 4])
        w1.coords = [(10, 0), (0, 0), (0, 10), (10, 10), (10, 0), (20, 0), (20, 10), (30, 10), (30, 0), (10, 0)]
        yield self.check_broken_polygon, w1, w2
        
    def check_broken_polygon(self, w1, w2):
        r = Relation(1, {}, [(1, 'way', 'outer'), (2, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2])
        eq_(len(rings), 2)
        eq_(rings[0].geom.area, 200)
        eq_(rings[1].geom.area, 36)
    
        builder.build_relation_geometry(rings)
    
        eq_(r.geom.area, 200-36)

    def test_broken_polygon_self_intersect_triangle(self):
        #  2###
        #  #    ###4
        #  #    ###3
        #  1###
        # triangle with four points, minor overlapping
        
        w1 = Way(1, {}, [1, 2, 3, 4, 1])
        w1.coords = [(0, 0), (0, 100), (100, 50 - 0.00001), (100, 50 + 0.00001), (0, 0)]
        w2 = Way(2, {}, [15, 16, 17, 18, 15])
        w2.coords = [(10, 45), (10, 55), (20, 55), (20, 45), (10, 45)]

        r = Relation(1, {}, [(1, 'way', 'outer'), (2, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2])
        eq_(len(rings), 2)
        assert_almost_equal(rings[0].geom.area, 100 * 100 / 2, 2)
        eq_(rings[1].geom.area, 100)
    
        builder.build_relation_geometry(rings)
        assert_almost_equal(r.geom.area, 100 * 100 / 2 - 100, 2)

        # larger overlapp
        w1 = Way(1, {}, [1, 2, 3, 4, 1])
        w1.coords = [(0, 0), (0, 100), (100, 50 - 1), (100, 50 + 1), (0, 0)]
        w2 = Way(2, {}, [15, 16, 17, 18, 15])
        w2.coords = [(10, 45), (10, 55), (20, 55), (20, 45), (10, 45)]

        r = Relation(1, {}, [(1, 'way', 'outer'), (2, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2])
        eq_(len(rings), 2)
        assert_almost_equal(rings[0].geom.area, 100 * 100 / 2, -3)
        eq_(rings[1].geom.area, 100)
    
        builder.build_relation_geometry(rings)
        assert_almost_equal(r.geom.area, 100 * 100 / 2 - 100, -3)

        # #  2###    ###4
        # #  #    ###   #
        # #  #    ###   #
        # #  1###    ###3
        # # hourglass
        # w1 = Way(1, {}, [1, 2, 3, 4, 1])
        # w1.coords = [(0, 0), (0, 100), (100, 0), (100, 100), (0, 0)]
        # w2 = Way(2, {}, [15, 16, 17, 18, 15])
        # w2.coords = [(10, 45), (10, 55), (20, 55), (20, 45), (10, 45)]
        # w3 = Way(3, {}, [25, 26, 27, 28, 25])
        # w3.coords = [(80, 45), (80, 55), (90, 55), (90, 45), (80, 45)]
        # 
        # r = Relation(1, {}, [(1, 'way', 'outer'), (2, 'way', 'inner')])
        # builder = self.relation_builder(r, None, None)
        # rings = builder.build_rings([w1, w2, w3])
        # eq_(len(rings), 3)
        # print rings[0].geom.wkt, rings[0].geom.simplify(0.000001, False).wkt
        # eq_(rings[0].geom.area, 100 * 100 / 2)
        # eq_(rings[1].geom.area, 100)
        # eq_(rings[2].geom.area, 100)
        #     
        # builder.build_relation_geometry(rings)
        # assert_almost_equal(r.geom.area, 100 * 100 / 2 - 100, -3)

    def test_simple_polygon_w_hole(self):
        w1 = Way(1, {}, [1, 2, 3, 4, 1])
        w1.coords = [(0, 0), (10, 0), (10, 10), (0, 10), (0, 0)]
        w2 = Way(2, {}, [5, 6, 7, 8, 5])
        w2.coords = [(2, 2), (8, 2), (8, 8), (2, 8), (2, 2)]
    
        r = Relation(1, {}, [(1, 'way', 'outer'), (2, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2])
        eq_(len(rings), 2)
        eq_(rings[0].geom.area, 100)
        eq_(rings[1].geom.area, 36)
    
        builder.build_relation_geometry(rings)
    
        eq_(r.geom.area, 100-36)

    def test_polygon_w_multiple_holes(self):
        w1 = Way(1, {'landusage': 'forest'}, [1, 2, 3, 4, 1])
        w1.coords = [(0, 0), (10, 0), (10, 10), (0, 10), (0, 0)]
        w2 = Way(2, {'water': 'basin'}, [1, 2, 3, 4, 1])
        w2.coords = [(1, 1), (2, 1), (2, 2), (1, 2), (1, 1)]
        w3 = Way(3, {'landusage': 'scrub'}, [1, 2, 3, 4, 1])
        w3.coords = [(3, 3), (4, 3), (4, 4), (3, 4), (3, 3)]
    
        r = Relation(1, {'landusage': 'forest'}, [
            (1, 'way', 'outer'), (2, 'way', 'inner'), (3, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2, w3])
        eq_(len(rings), 3)
        eq_(rings[0].geom.area, 100)
        eq_(rings[1].geom.area, 1)
        eq_(rings[2].geom.area, 1)
    
        builder.build_relation_geometry(rings)
    
        eq_(rings[0].inserted, True)
        eq_(rings[1].inserted, False)
        eq_(rings[2].inserted, False)
    
        eq_(r.geom.area, 100-1-1)


    def test_polygon_w_nested_holes(self):
        w1 = Way(1, {'landusage': 'forest'}, [1, 2, 3, 4, 1])
        w1.coords = [(0, 0), (10, 0), (10, 10), (0, 10), (0, 0)]
        w2 = Way(2, {'landusage': 'scrub'}, [1, 2, 3, 4, 1])
        w2.coords = [(1, 1), (9, 1), (9, 9), (1, 9), (1, 1)]
        w3 = Way(3, {}, [5, 6, 7, 8, 5]) # with no tags
        w3.coords = [(2, 2), (8, 2), (8, 8), (2, 8), (2, 2)]
        w4 = Way(4, {'landusage': 'scrub'}, [9, 10, 11, 12, 9])
        w4.coords = [(3, 3), (7, 3), (7, 7), (3, 7), (3, 3)]
        w5 = Way(5, {'landusage': 'forest'}, [9, 10, 11, 12, 9])
        w5.coords = [(4, 4), (6, 4), (6, 6), (4, 6), (4, 4)]
    
        r = Relation(1, {'landusage': 'forest'}, [
            (1, 'way', 'outer'), (2, 'way', 'inner'), (3, 'way', 'inner'),
            (4, 'way', 'inner'), (5, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2, w3, w4, w5])
        eq_(len(rings), 5)
        eq_(rings[0].geom.area, 100)
        eq_(rings[1].geom.area, 64)
        eq_(rings[2].geom.area, 36)
        eq_(rings[3].geom.area, 16)
        eq_(rings[4].geom.area, 4)
    
        builder.build_relation_geometry(rings)

        eq_(rings[0].inserted, True)
        eq_(rings[1].inserted, False)
        eq_(rings[2].inserted, True)
        eq_(rings[3].inserted, False)
        eq_(rings[4].inserted, True)
    
        eq_(r.geom.area, 100-64+36-16+4)

    def test_polygon_w_touching_holes(self):
        w1 = Way(1, {'landusage': 'forest'}, [1, 2, 3, 4, 1])
        w1.coords = [(0, 0), (10, 0), (10, 10), (0, 10), (0, 0)]
        w2 = Way(2, {'landusage': 'scrub'}, [1, 2, 3, 4, 1])
        w2.coords = [(1, 1), (5, 1), (5, 9), (1, 9), (1, 1)]
        w3 = Way(3, {'water': 'basin'}, [1, 2, 3, 4, 1])
        w3.coords = [(5, 1), (9, 1), (9, 9), (5, 9), (5, 1)]
    
        r = Relation(1, {'landusage': 'forest'}, [
            (1, 'way', 'outer'), (2, 'way', 'inner'), (3, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2, w3])
        eq_(len(rings), 3)
        eq_(rings[0].geom.area, 100)
        eq_(rings[1].geom.area, 32)
        eq_(rings[2].geom.area, 32)
    
        builder.build_relation_geometry(rings)

        eq_(rings[0].inserted, True)
        eq_(rings[1].inserted, False)
        eq_(rings[2].inserted, False)
    
        eq_(r.geom.area, 100-64)

    def test_touching_polygons_w_hole(self):
        w1 = Way(1, {'water': 'riverbank'}, [1, 2, 3, 4, 1])
        w1.coords = [(0, 0), (10, 0), (10, 10), (0, 10), (0, 0)]
        w2 = Way(2, {'water': 'riverbank'}, [2, 5, 6, 3, 2])
        w2.coords = [(10, 0), (30, 0), (30, 10), (10, 10), (10, 0)]
        w3 = Way(3, {'landusage': 'forest'}, [7, 8, 9, 10, 7])
        w3.coords = [(2, 2), (8, 2), (8, 8), (2, 8), (2, 2)]

        r = Relation(1, {'water': 'riverbank'}, [
            (1, 'way', 'outer'), (2, 'way', 'outer'), (3, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2, w3])
        eq_(len(rings), 3)
        eq_(rings[0].geom.area, 100)
        eq_(rings[1].geom.area, 200)
        eq_(rings[2].geom.area, 36)

        builder.build_relation_geometry(rings)

        eq_(rings[0].inserted, True)
        eq_(rings[1].inserted, True)
        eq_(rings[2].inserted, False)

        eq_(r.geom.area, 100+200-36)

    def test_simple_polygon_from_two_lines(self):
        w1 = Way(1, {}, [1, 2, 3])
        w1.coords = [(0, 0), (10, 0), (10, 10)]
        w2 = Way(2, {}, [3, 4, 1])
        w2.coords = [(10, 10), (0, 10), (0, 0)]
    
        r = Relation(1, {}, [(1, 'way', 'outer'), (2, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2])
        eq_(len(rings), 1)
        eq_(rings[0].geom.area, 100)
    
        builder.build_relation_geometry(rings)
    
        eq_(r.geom.area, 100)

    def test_inserted_ways_different_tags(self):
        w1 = Way(1, {'landusage': 'forest'}, [1, 2, 3])
        w1.coords = [(0, 0), (10, 0), (10, 10)]
        w2 = Way(2, {'highway': 'secondary'}, [3, 4, 1])
        w2.coords = [(10, 10), (0, 10), (0, 0)]
    
        r = Relation(1, {'landusage': 'forest'}, [(1, 'way', 'outer'), (2, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2])
        
        builder.build_relation_geometry(rings)
        
        eq_(w1.inserted, True)
        eq_(w2.inserted, False)

    def test_inserted_multiple_tags(self):
        w1 = Way(1, {'landusage': 'forest', 'highway': 'secondary'}, [1, 2, 3])
        w1.coords = [(0, 0), (10, 0), (10, 10)]
        w2 = Way(2, {'highway': 'secondary'}, [3, 4, 1])
        w2.coords = [(10, 10), (0, 10), (0, 0)]
    
        r = Relation(1, {'landusage': 'forest'}, [(1, 'way', 'outer'), (2, 'way', 'inner')])
        builder = self.relation_builder(r, None, None)
        rings = builder.build_rings([w1, w2])
        
        builder.build_relation_geometry(rings)
        
        eq_(w1.inserted, False) # also highway=secondary
        eq_(w2.inserted, False)
    
class TestUnionRelationBuilder(RelationBuilderTestBase):
    relation_builder = UnionRelationBuilder


class TestContainsRelationBuilder(RelationBuilderTestBase):
    relation_builder = ContainsRelationBuilder


def test_merge_rings():
    w1 = Way(1, {}, [1, 2, 3])
    w1.coords = [(0, 0), (10, 0), (10, 10)]
    r1 = Ring(w1)
    w2 = Way(2, {}, [3, 4, 1])
    w2.coords = [(10, 10), (0, 10), (0, 0)]
    r2 = Ring(w2)
    
    rings = merge_rings([r1, r2])
    eq_(len(rings), 1)
    r = rings[0]
    eq_(r.is_closed(), True)
    # eq_(r.ways, [w1, w2])

def test_merge_rings_reverse_endpoint():
    w1 = Way(1, {'name': 'foo'}, [1, 2, 3, 4])
    w1.coords = []
    r1 = Ring(w1)
    w2 = Way(2, {'building': 'true'}, [6, 5, 4])
    w2.coords = []
    r2 = Ring(w2)
    w3 = Way(3, {}, [1, 7, 6])
    w3.coords = []
    r3 = Ring(w3)
    
    rings = merge_rings([r1, r2, r3])
    eq_(len(rings), 1)
    r = rings[0]
    eq_(r.tags, {'name': 'foo', 'building': 'true'})
    eq_(r.is_closed(), True)
    # eq_(r.ways, [w1, w2, w3])


class W(Way):
    # way without coords
    coords = []

from imposm.merge import permutations

def test_merge_rings_permutations():
    """
    Test all possible permutations of 4 ring segments.
    """
    for i in range(16):
        # test each segment in both directions
        f1 = i & 1 == 0
        f2 = i & 2 == 0
        f3 = i & 4 == 0
        f4 = i & 8 == 0
        for i1, i2, i3, i4 in permutations([0, 1, 2, 3]):
            ways = [
                W(1, {}, [1, 2, 3, 4] if f1 else [4, 3, 2, 1]),
                W(2, {}, [4, 5, 6, 7] if f2 else [7, 6, 5, 4]),
                W(3, {}, [7, 8, 9, 10] if f3 else [10, 9, 8, 7]),
                W(4, {}, [10, 11, 12, 1] if f4 else [1, 12, 11, 10]),
            ]
            ways = [ways[i1], ways[i2], ways[i3], ways[i4]]
            rings = [Ring(w) for w in ways]
            
            merged_rings = merge_rings(rings)
            eq_(len(merged_rings), 1)
            r = merged_rings[0]
            eq_(r.is_closed(), True, (ways, r.refs))
            eq_(set(r.ways), set(ways))

            # check order of refs
            prev_x = r.refs[0]
            for x in r.refs[1:]:
                if not abs(prev_x - x) == 1:
                    assert (
                        (prev_x == 1 and x == 12) or 
                        (prev_x == 12 and x == 1)
                    ), 'not in order %r' % r.refs
                prev_x = x
########NEW FILE########
__FILENAME__ = test_tag_mapper
# Copyright 2011 Omniscale (http://omniscale.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import imposm
from imposm.mapping import TagMapper, LineStrings

from nose.tools import eq_

class TestTagMapper(object):
    def __init__(self):
        mapping_file = os.path.join(os.path.dirname(__file__), '..',
            'defaultmapping.py')
        mappings = {}
        execfile(mapping_file, mappings)
        self.tag_mapping = TagMapper([m for n, m in mappings.iteritems()
            if isinstance(m, imposm.mapping.Mapping)])

    def test_tag_filter_nodes(self):
        tag_filter_for_nodes = self.tag_mapping.tag_filter_for_nodes()
        tagfilter = lambda x: tag_filter_for_nodes(x) or x

        eq_(tagfilter({'name': 'foo'}), {})
        eq_(tagfilter({'name': 'foo', 'unknown': 'baz'}), {})
        eq_(tagfilter({'name': 'foo', 'place': 'unknown'}), {})
        eq_(tagfilter({'name': 'foo', 'place': 'village'}), {'name': 'foo', 'place': 'village'})
        eq_(tagfilter({'name': 'foo', 'place': 'village', 'population': '1000'}),
            {'name': 'foo', 'place': 'village', 'population': '1000'})
        eq_(tagfilter({'name': 'foo', 'place': 'village', 'highway': 'unknown'}),
            {'name': 'foo', 'place': 'village'})
        eq_(tagfilter({'name': 'foo', 'place': 'village', 'highway': 'bus_stop'}),
            {'name': 'foo', 'place': 'village', 'highway': 'bus_stop'})

    def test_tag_filter_ways(self):
        tag_filter_for_ways = self.tag_mapping.tag_filter_for_ways()
        tagfilter = lambda x: tag_filter_for_ways(x) or x

        eq_(tagfilter({'name': 'foo'}), {})
        eq_(tagfilter({'name': 'foo', 'unknown': 'baz'}), {})
        eq_(tagfilter({'name': 'foo', 'highway': 'unknown'}), {})
        eq_(tagfilter({'name': 'foo', 'highway': 'track'}), {'name': 'foo', 'highway': 'track'})
        eq_(tagfilter({'name': 'foo', 'highway': 'track', 'oneway': 'yes', 'tunnel': '1'}),
            {'name': 'foo', 'highway': 'track', 'oneway': 'yes', 'tunnel': '1'})
        eq_(tagfilter({'name': 'foo', 'place': 'village', 'highway': 'track'}),
            {'name': 'foo', 'highway': 'track'})
        eq_(tagfilter({'name': 'foo', 'railway': 'tram', 'highway': 'secondary'}),
            {'name': 'foo', 'railway': 'tram', 'highway': 'secondary'})

        # with __any__ value
        eq_(tagfilter({'name': 'foo', 'building': 'yes'}),
            {'name': 'foo', 'building': 'yes'})
        eq_(tagfilter({'name': 'foo', 'building': 'whatever'}),
            {'name': 'foo', 'building': 'whatever'})

    def test_tag_filter_relations(self):
        tag_filter_for_relations = self.tag_mapping.tag_filter_for_relations()
        tagfilter = lambda x: tag_filter_for_relations(x) or x

        eq_(tagfilter({'name': 'foo'}), {})
        eq_(tagfilter({'name': 'foo', 'unknown': 'baz'}), {})
        eq_(tagfilter({'name': 'foo', 'landuse': 'unknown'}), {})
        eq_(tagfilter({'name': 'foo', 'landuse': 'farm'}), {})
        eq_(tagfilter({'name': 'foo', 'landuse': 'farm', 'type': 'multipolygon'}),
            {'name': 'foo', 'landuse': 'farm', 'type': 'multipolygon'})

        # skip multipolygon with filtered tags, otherwise tags from longest way would be used
        eq_(tagfilter({'name': 'foo', 'landuse': 'unknown', 'type': 'multipolygon'}), {})
        eq_(tagfilter({'name': 'foo', 'landuse': 'park', 'type': 'multipolygon'}),
            {'name': 'foo', 'type': 'multipolygon', 'landuse': 'park'})

        eq_(tagfilter({'name': 'foo', 'landuse': 'farm', 'boundary': 'administrative', 'type': 'multipolygon'}),
            {'name': 'foo', 'landuse': 'farm', 'boundary': 'administrative', 'type': 'multipolygon'})

        # boundary relation for boundary
        eq_(tagfilter({'name': 'foo', 'landuse': 'farm', 'boundary': 'administrative', 'type': 'boundary'}),
            {'name': 'foo', 'landuse': 'farm', 'boundary': 'administrative', 'type': 'boundary'})
        # boundary relation for non boundary
        eq_(tagfilter({'name': 'foo', 'landuse': 'farm', 'type': 'boundary'}), {})

        # skip boundary with filtered tags, otherwise tags from longest way would be used
        eq_(tagfilter({'name': 'foo', 'boundary': 'unknown', 'type': 'boundary'}), {})
        eq_(tagfilter({'name': 'foo', 'boundary': 'administrative', 'type': 'boundary'}),
            {'name': 'foo', 'boundary': 'administrative', 'type': 'boundary'})

    def test_mapping_for_nodes(self):
        for_nodes = self.tag_mapping.for_nodes
        eq_mapping(for_nodes({'unknown': 'baz'}), [])
        eq_mapping(for_nodes({'place': 'unknown'}), [])
        eq_mapping(for_nodes({'place': 'city'}), [(('place', 'city'), ('places',))])
        eq_mapping(for_nodes({'place': 'city', 'highway': 'unknown'}), [(('place', 'city'), ('places',))])
        eq_mapping(for_nodes({'place': 'city', 'highway': 'bus_stop'}),
            [(('place', 'city'), ('places',)), (('highway', 'bus_stop'), ('transport_points',))])

    def test_mapping_for_ways(self):
        for_ways = self.tag_mapping.for_ways
        eq_mapping(for_ways({'unknown': 'baz'}), [])
        eq_mapping(for_ways({'highway': 'unknown'}), [])
        eq_mapping(for_ways({'highway': 'track'}), [(('highway', 'track'), ('minorroads',))])
        eq_mapping(for_ways({'highway': 'secondary', 'railway': 'tram'}),
            [(('railway', 'tram'), ('railways',)), (('highway', 'secondary'), ('mainroads',))])
        eq_mapping(for_ways({'highway': 'footway'}),
            [(('highway', 'footway'), ('minorroads',)), (('highway', 'footway'), ('landusages',))])

        eq_mapping(for_ways({'highway': 'footway', 'landuse': 'park'}),
            [(('highway', 'footway'), ('minorroads',)), (('landuse', 'park'), ('landusages',))])

    def test_mapping_for_relation(self):
        for_relations = self.tag_mapping.for_relations
        eq_mapping(for_relations({'unknown': 'baz'}), [])
        eq_mapping(for_relations({'landuse': 'unknown'}), [])
        eq_mapping(for_relations({'landuse': 'farm'}), [(('landuse', 'farm'), ('landusages',))])
        eq_mapping(for_relations({'landuse': 'farm', 'highway': 'secondary'}),
            [(('landuse', 'farm'), ('landusages',))])

        eq_mapping(for_relations({'landuse': 'farm', 'aeroway': 'apron'}),
            [(('aeroway', 'apron'), ('transport_areas',)), (('landuse', 'farm'), ('landusages',))])

        eq_mapping(for_relations({'boundary': 'administrative', 'admin_level': '8'}),
            [(('boundary', 'administrative'), ('admin',))])

    def test_multiple_mappings(self):
        roads = LineStrings(
            name = 'roads',
            mapping = {
                'highway': ('secondary', ),
                'railway': ('tram', ),
            }
        )
        tag_mapping = TagMapper([roads])
        for_ways = tag_mapping.for_ways
        eq_mapping(for_ways({'unknown': 'baz'}), [])
        eq_mapping(for_ways({'highway': 'unknown'}), [])
        eq_mapping(for_ways({'highway': 'secondary'}), [(('highway', 'secondary'), ('roads',))])
        eq_mapping(for_ways({'highway': 'secondary', 'railway': 'tram'}),
            [(('railway', 'tram'), ('roads',)), (('highway', 'secondary'), ('roads',))])


def eq_mapping(actual_mappings, expected_mappings):
    assert len(actual_mappings) == len(expected_mappings), '%s != %s' % (actual_mappings, expected_mappings)
    actual_mappings = [(tags, tuple(m.name for m in mappings)) for tags, mappings in actual_mappings]
    actual_mappings.sort()
    expected_mappings.sort()
    eq_(actual_mappings, expected_mappings)

########NEW FILE########
__FILENAME__ = geom
# This file is part of the MapProxy project.
# Copyright (C) 2010 Omniscale <http://omniscale.de>
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#    http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import division, with_statement

import codecs
import os
from functools import partial

import logging
log = logging.getLogger(__name__)

try:
    import shapely.wkt
    import shapely.geometry
    import shapely.ops
    import shapely.prepared
    geom_support = True
except ImportError:
    geom_support = False

def require_geom_support():
    if not geom_support:
        raise ImportError('Shapely required for geometry support')


def load_datasource(datasource, where=None):
    """
    Loads polygons from WKT text files or OGR datasources.

    Returns a list of Shapely Polygons.
    """
    # check if it is a  wkt file
    if os.path.exists(os.path.abspath(datasource)):
        with open(os.path.abspath(datasource), 'r') as fp:
            data = fp.read(50)
        if data.lower().lstrip().startswith(('polygon', 'multipolygon')):
            return load_polygons(datasource)

    # otherwise pass to OGR
    return load_ogr_datasource(datasource, where=where)

def load_ogr_datasource(datasource, where=None):
    """
    Loads polygons from any OGR datasource.

    Returns a list of Shapely Polygons.
    """
    from imposm.util.ogr import OGRShapeReader

    polygons = []
    for wkt in OGRShapeReader(datasource).wkts(where):
        geom = shapely.wkt.loads(wkt)
        if geom.type == 'Polygon':
            polygons.append(geom)
        elif geom.type == 'MultiPolygon':
            for p in geom:
                polygons.append(p)
        else:
            log.info('skipping %s geometry from %s: not a Polygon/MultiPolygon',
                geom.type, datasource)

    return polygons

def load_polygons(geom_files):
    """
    Loads WKT polygons from one or more text files.
    
    Returns a Shapely MultiPolygon with
    the loaded geometries.
    """
    polygons = []
    if isinstance(geom_files, basestring):
        geom_files = [geom_files]
    
    for geom_file in geom_files:
        # open with utf-8-sig encoding to get rid of UTF8 BOM from MS Notepad
        with codecs.open(geom_file, encoding='utf-8-sig') as f:
            polygons.extend(load_polygon_lines(f, source=geom_files))
    
    return polygons

def load_polygon_lines(line_iter, source='<string>'):
    polygons = []
    for line in line_iter:
        if not line.strip():
            continue
        geom = shapely.wkt.loads(line)
        if geom.type == 'Polygon':
            polygons.append(geom)
        elif geom.type == 'MultiPolygon':
            for p in geom:
                polygons.append(p)
        else:
            log.info('ignoring non-polygon geometry (%s) from %s',
                geom.type, source)

    return polygons
    
def build_multipolygon(polygons, simplify=False):
    if polygons:
        mp = shapely.geometry.MultiPolygon(polygons)
        if simplify:
            mp = simplify_geom(mp)
    else:
        mp = shapely.geometry.Polygon()
    return mp.bounds, mp

def simplify_geom(geom):
    bounds = geom.bounds
    w, h = bounds[2] - bounds[0], bounds[3] - bounds[1]
    tolerance = min((w/1e6, h/1e6))
    return geom.simplify(tolerance, preserve_topology=True)

def bbox_polygon(bbox):
    """
    Create Polygon that covers the given bbox.
    """
    return shapely.geometry.Polygon((
        (bbox[0], bbox[1]),
        (bbox[2], bbox[1]),
        (bbox[2], bbox[3]),
        (bbox[0], bbox[3]),
        ))

def transform_geometry(from_srs, to_srs, geometry):
    transf = partial(transform_xy, from_srs, to_srs)
    
    if geometry.type == 'Polygon':
        return transform_polygon(transf, geometry)
    
    if geometry.type == 'MultiPolygon':
        return transform_multipolygon(transf, geometry)
    
    raise ValueError('cannot transform %s' % geometry.type)

def transform_polygon(transf, polygon):
    ext = transf(polygon.exterior.xy)
    ints = [transf(ring.xy) for ring in polygon.interiors]
    return shapely.geometry.Polygon(ext, ints)

def transform_multipolygon(transf, multipolygon):
    transformed_polygons = []
    for polygon in multipolygon:
        transformed_polygons.append(transform_polygon(transf, polygon))
    return shapely.geometry.MultiPolygon(transformed_polygons)

def transform_xy(from_srs, to_srs, xy):
    return list(from_srs.transform_to(to_srs, zip(*xy)))

########NEW FILE########
__FILENAME__ = lib
# This file is part of the MapProxy project.
# Copyright (C) 2010 Omniscale <http://omniscale.de>
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#    http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
ctypes utilities.
"""

import sys
import os

from ctypes import CDLL
from ctypes.util import find_library as _find_library


default_locations = dict(
    darwin=dict(
        paths = ['/opt/local/lib'],
        exts = ['.dylib'],
    ),
    win32=dict(
        paths = [os.path.dirname(os.__file__) + '/../../../DLLs'],
        exts = ['.dll']
    ),
    other=dict(
        paths = [], # MAPPROXY_LIB_PATH will add paths here
        exts = ['.so']
    ),
)

# TODO does this work for imposm too?

additional_lib_path = os.environ.get('MAPPROXY_LIB_PATH')
if additional_lib_path:
    additional_lib_path = additional_lib_path.split(os.pathsep)
    additional_lib_path.reverse()
    for locs in default_locations.values():
        for path in additional_lib_path:
            locs['paths'].insert(0, path)

def load_library(lib_names, locations_conf=default_locations):
    """
    Load the `lib_name` library with ctypes.
    If ctypes.util.find_library does not find the library,
    different path and filename extensions will be tried.
    
    Retruns the loaded library or None.
    """
    if isinstance(lib_names, basestring):
        lib_names = [lib_names]
    
    for lib_name in lib_names:
        lib = load_library_(lib_name, locations_conf)
        if lib is not None: return lib

def load_library_(lib_name, locations_conf=default_locations):
    lib_path = find_library(lib_name)
    
    if lib_path:
        return CDLL(lib_path)
    
    if sys.platform in locations_conf:
        paths = locations_conf[sys.platform]['paths']
        exts = locations_conf[sys.platform]['exts']
        lib_path = find_library(lib_name, paths, exts)
    else:
        paths = locations_conf['other']['paths']
        exts = locations_conf['other']['exts']
        lib_path = find_library(lib_name, paths, exts)
    
    if lib_path:
        return CDLL(lib_path)
        

def find_library(lib_name, paths=None, exts=None):
    """
    Search for library in all permutations of `paths` and `exts`.
    If nothing is found None is returned.
    """
    if not paths or not exts:
        lib = _find_library(lib_name)
        if lib is None and lib_name.startswith('lib'):
            lib = _find_library(lib_name[3:])
        return lib
    
    for lib_name in [lib_name] + ([lib_name[3:]] if lib_name.startswith('lib') else []):
        for path in paths:
            for ext in exts:
                lib_path = os.path.join(path, lib_name + ext)
                if os.path.exists(lib_path):
                    return lib_path
    
    return None

if __name__ == '__main__':
    print load_library(sys.argv[1])

########NEW FILE########
__FILENAME__ = ogr
# This file is part of the MapProxy project.
# Copyright (C) 2010 Omniscale <http://omniscale.de>
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#    http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from imposm.util.lib import load_library
import ctypes
from ctypes import c_void_p, c_char_p, c_int

def init_libgdal():
    libgdal = load_library(['libgdal', 'libgdal1'])
    
    if not libgdal: return
    
    libgdal.OGROpen.argtypes = [c_char_p, c_int, c_void_p]
    libgdal.OGROpen.restype = c_void_p

    libgdal.CPLGetLastErrorMsg.argtypes = []
    libgdal.CPLGetLastErrorMsg.restype = c_char_p

    libgdal.OGR_DS_GetLayer.argtypes = [c_void_p, c_int]
    libgdal.OGR_DS_GetLayer.restype = c_void_p

    libgdal.OGR_FD_GetName.argtypes = [c_void_p]
    libgdal.OGR_FD_GetName.restype = c_char_p

    libgdal.OGR_L_GetLayerDefn.argtypes = [c_void_p]
    libgdal.OGR_L_GetLayerDefn.restype = c_void_p

    libgdal.OGR_DS_Destroy.argtypes = [c_void_p]

    libgdal.OGR_DS_ExecuteSQL.argtypes = [c_void_p, c_char_p, c_void_p, c_char_p]
    libgdal.OGR_DS_ExecuteSQL.restype = c_void_p
    libgdal.OGR_DS_ReleaseResultSet.argtypes = [c_void_p, c_void_p]

    libgdal.OGR_L_ResetReading.argtypes = [c_void_p]
    libgdal.OGR_L_GetNextFeature.argtypes = [c_void_p]
    libgdal.OGR_L_GetNextFeature.restype = c_void_p

    libgdal.OGR_F_Destroy.argtypes = [c_void_p]

    libgdal.OGR_F_GetGeometryRef.argtypes = [c_void_p]
    libgdal.OGR_F_GetGeometryRef.restype = c_void_p

    libgdal.OGR_G_ExportToWkt.argtypes = [c_void_p, ctypes.POINTER(c_char_p)]
    libgdal.OGR_G_ExportToWkt.restype = c_void_p

    libgdal.VSIFree.argtypes = [c_void_p]

    libgdal.OGRRegisterAll()
    
    return libgdal

libgdal = init_libgdal()

class OGRShapeReaderError(Exception):
    pass

class OGRShapeReader(object):
    def __init__(self, datasource):
        self.datasource = datasource
        self.opened = False
        self._ds = None
        
    def open(self):
        if self.opened: return
        self._ds = libgdal.OGROpen(self.datasource, False, None)
        if self._ds is None:
            msg = libgdal.CPLGetLastErrorMsg()
            if not msg:
                msg = 'failed to open %s' % self.datasource
            raise OGRShapeReaderError(msg)

    def wkts(self, where=None):
        if not self.opened: self.open()
        
        if where:
            if not where.lower().startswith('select'):
                layer = libgdal.OGR_DS_GetLayer(self._ds, 0)
                layer_def = libgdal.OGR_L_GetLayerDefn(layer)
                name = libgdal.OGR_FD_GetName(layer_def)
                where = 'select * from %s where %s' % (name, where)
            layer = libgdal.OGR_DS_ExecuteSQL(self._ds, where, None, None)
        else:
            layer = libgdal.OGR_DS_GetLayer(self._ds, 0)
        if layer is None:
            msg = libgdal.CPLGetLastErrorMsg()
            raise OGRShapeReaderError(msg)
        
        libgdal.OGR_L_ResetReading(layer)
        while True:
            feature = libgdal.OGR_L_GetNextFeature(layer)
            if feature is None:
                break
            geom = libgdal.OGR_F_GetGeometryRef(feature)
            res = c_char_p()
            libgdal.OGR_G_ExportToWkt(geom, ctypes.byref(res))
            yield res.value
            libgdal.VSIFree(res)
            libgdal.OGR_F_Destroy(feature)
        
        if where:
            libgdal.OGR_DS_ReleaseResultSet(self._ds, layer)
    
    def close(self):
        if self.opened:
            libgdal.OGR_DS_Destroy(self._ds)
            self.opened = False
    
    def __del__(self):
        self.close()
        
if __name__ == '__main__':
    import sys
    reader = OGRShapeReader(sys.argv[1])
    where = None
    if len(sys.argv) == 3:
        where = sys.argv[2]
    for wkt in reader.wkts(where):
        print wkt
########NEW FILE########
__FILENAME__ = version
# Copyright 2011 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

__version__ = '2.5.1a'

########NEW FILE########
__FILENAME__ = writer
# Copyright 2011 Omniscale (http://omniscale.com)
# 
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from multiprocessing import Process, JoinableQueue

from imposm.dbimporter import NodeProcessTuple, WayProcessTuple, RelationProcessTuple
from imposm.dbimporter import NodeProcessDict, WayProcessDict, RelationProcessDict
from imposm.util import create_pool, shutdown_pool

import_processes = {
    'tuple': {
        'node': NodeProcessTuple,
        'way': WayProcessTuple,
        'relation': RelationProcessTuple,
    },
    'dict': {
        'node': NodeProcessDict,
        'way': WayProcessDict,
        'relation': RelationProcessDict,
    }
}

class ImposmWriter(object):
    def __init__(self, mapping, db, cache, pool_size=2, logger=None, dry_run=False):
        self.mapping = mapping
        self.db = db
        self.mapper = mapping
        self.cache = cache
        self.pool_size = pool_size
        self.logger = logger
        self.dry_run = dry_run

    def _write_elem(self, proc, elem_cache, log, pool_size, proc_args=[]):
        queue = JoinableQueue(16)

        importer = lambda: proc(queue, self.db, self.mapper, self.cache, self.dry_run, *proc_args)
        pool = create_pool(importer, pool_size)

        data = []
        for i, elem in enumerate(elem_cache):
            if elem.tags:
                data.append(elem)
            if len(data) >= 128:
                queue.put(data)
                log.log(i)
                data = []
        queue.put(data)

        shutdown_pool(pool, queue)
        log.stop()
        self.cache.close_all()

    def relations(self):
        self.cache.remove_inserted_way_cache()
        cache = self.cache.relations_cache()
        log = self.logger('relations', len(cache))
        inserted_way_queue = JoinableQueue()
        way_marker = WayMarkerProcess(inserted_way_queue, self.cache, self.logger)
        way_marker.start()

        self._write_elem(import_processes[self.db.insert_data_format]['relation'],
            cache, log, self.pool_size, [inserted_way_queue])

        inserted_way_queue.put(None)
        way_marker.join()

    def ways(self):
        cache = self.cache.ways_cache()
        log = self.logger('ways', len(cache))
        self._write_elem(import_processes[self.db.insert_data_format]['way'],
            cache, log, self.pool_size)
        self.cache.remove_inserted_way_cache()

    def nodes(self):
        cache = self.cache.nodes_cache()
        log = self.logger('nodes', len(cache))
        self._write_elem(import_processes[self.db.insert_data_format]['node'],
            cache, log, self.pool_size)


class WayMarkerProcess(Process):
    def __init__(self, queue, cache, logger):
        Process.__init__(self)
        self.daemon = True
        self.queue = queue
        self.cache = cache
        self.logger = logger

    def run(self):
        inserted_ways = self.cache.inserted_ways_cache('w')
        while True:
            osmid = self.queue.get()
            if osmid is None:
                break
            inserted_ways.put(osmid)

        inserted_ways.close()


########NEW FILE########
__FILENAME__ = release
import scriptine
from scriptine import path
from scriptine.shell import backtick_, sh

PACKAGE_NAME = 'imposm'
REMOTE_DOC_LOCATION = 'omniscale.de:domains/imposm.org/docs/imposm'
# REMOTE_REL_LOCATION = 'os@imposm.org:imposm_homepage/static/rel'

VERSION_FILES = [
    ('imposm/version.py', "__version__ = '###'"),
    ('doc/source/conf.py', "version = '##'"),
    ('doc/source/conf.py', "release = '###'"),
]

def version_command():
    print version()

def prepare_command(tag=""):
    sh('python setup.py egg_info -D -b "%s"' % tag)

def version():
    package_name = PACKAGE_NAME
    version = backtick_('grep Version: %(package_name)s.egg-info/PKG-INFO' % locals())
    version = version.split(':')[-1].strip()
    return version

def clean_all_command():
    path('build/').rmtree(ignore_errors=True)
    for pyc in path.cwd().walkfiles('*.pyc'):
        pyc.remove()

def bump_version_command(version):
    short_version = '.'.join(version.split('.')[:2])
    for filename, replace in VERSION_FILES:
        if '###' in replace:
            search_for = replace.replace('###', '[^\'"]+')
            replace_with = replace.replace('###', version)
        else:
            search_for = replace.replace('##', '[^\'"]+')
            replace_with = replace.replace('##', short_version)

        search_for = search_for.replace('"', '\\"')
        replace_with = replace_with.replace('"', '\\"')
        sh('''perl -p -i -e "s/%(search_for)s/%(replace_with)s/" %(filename)s ''' % locals())

    prepare_command()

def build_docs_command():
    sh('python setup.py build_sphinx')
    ver = version()
    package_name = PACKAGE_NAME
    sh("tar -c -v -z -C build/sphinx/ -f dist/%(package_name)s-docs-%(ver)s.tar.gz -s "
       "'/^html/%(package_name)s-docs-%(ver)s/' html"
        % locals())

def upload_docs_command():
    ver = version()
    remote_doc_location = REMOTE_DOC_LOCATION
    sh('rsync -a -v -P -z build/sphinx/html/ %(remote_doc_location)s/%(ver)s' % locals())

def build_sdist_command():
    sh('python setup.py egg_info -b "" -D sdist')

def upload_sdist_command():
    sh('python setup.py egg_info -b "" -D sdist')
    ver = version()
    remote_rel_location = REMOTE_REL_LOCATION
    sh('scp dist/MapProxy-%(ver)s.* %(remote_rel_location)s' % locals())

def upload_final_sdist_command():
    sh('python setup.py egg_info -b "" -D sdist upload')

def link_latest_command(ver=None):
    if ver is None:
        ver = version()
    host, path = REMOTE_DOC_LOCATION.split(':')
    sh('ssh %(host)s "cd %(path)s && rm latest && ln -s %(ver)s latest"' % locals())

if __name__ == '__main__':
    scriptine.run()

########NEW FILE########
