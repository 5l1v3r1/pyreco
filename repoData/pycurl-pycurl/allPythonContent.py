__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# PycURL documentation build configuration file, created by
# sphinx-quickstart on Tue Feb  4 03:14:18 2014.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys
import os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.coverage',
]

# Add any paths that contain templates here, relative to this directory.
templates_path = ['templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'PycURL'
copyright = u'2001-2014 Kjetil Jacobsen, Markus F.X.J. Oberhumer, Oleg Pudeyev'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '7.19.3.1'
# The full version, including alpha/beta/rc tags.
release = '7.19.3.1'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['build']

# The reST default role (used for this markup: `text`) to use for all
# documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
html_favicon = 'favicon.ico'

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['static']

# Add any extra paths that contain custom files (such as robots.txt or
# .htaccess) here, relative to this directory. These files are copied
# directly to the root of the documentation.
#html_extra_path = []

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'PycURLdoc'

########NEW FILE########
__FILENAME__ = basicfirst
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import sys
import pycurl

class Test:
    def __init__(self):
        self.contents = ''

    def body_callback(self, buf):
        self.contents = self.contents + buf

sys.stderr.write("Testing %s\n" % pycurl.version)

t = Test()
c = pycurl.Curl()
c.setopt(c.URL, 'http://curl.haxx.se/dev/')
c.setopt(c.WRITEFUNCTION, t.body_callback)
c.perform()
c.close()

print(t.contents)

########NEW FILE########
__FILENAME__ = file_upload
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import os, sys
import pycurl

# Class which holds a file reference and the read callback
class FileReader:
    def __init__(self, fp):
        self.fp = fp
    def read_callback(self, size):
        return self.fp.read(size)

# Check commandline arguments
if len(sys.argv) < 3:
    print("Usage: %s <url> <file to upload>" % sys.argv[0])
    raise SystemExit
url = sys.argv[1]
filename = sys.argv[2]

if not os.path.exists(filename):
    print("Error: the file '%s' does not exist" % filename)
    raise SystemExit

# Initialize pycurl
c = pycurl.Curl()
c.setopt(pycurl.URL, url)
c.setopt(pycurl.UPLOAD, 1)

# Two versions with the same semantics here, but the filereader version
# is useful when you have to process the data which is read before returning
if 1:
    c.setopt(pycurl.READFUNCTION, FileReader(open(filename, 'rb')).read_callback)
else:
    c.setopt(pycurl.READFUNCTION, open(filename, 'rb').read)

# Set size of file to be uploaded.
filesize = os.path.getsize(filename)
c.setopt(pycurl.INFILESIZE, filesize)

# Start transfer
print('Uploading file %s to url %s' % (filename, url))
c.perform()
c.close()

########NEW FILE########
__FILENAME__ = linksys
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et
#
# linksys.py -- program settings on a Linkys router
#
# This tool is designed to help you recover from the occasional episodes
# of catatonia that afflict Linksys boxes. It allows you to batch-program
# them rather than manually entering values to the Web interface.  Commands
# are taken from the command line first, then standard input.
#
# The somewhat spotty coverage of status queries is because I only did the
# ones that were either (a) easy, or (b) necessary.  If you want to know the
# status of the box, look at the web interface.
#
# This code has been tested against the following hardware:
#
#   Hardware    Firmware
#   ----------  ---------------------
#   BEFW11S4v2  1.44.2.1, Dec 20 2002
#
# The code is, of course, sensitive to changes in the names of CGI pages
# and field names.
#
# Note: to make the no-arguments form work, you'll need to have the following
# entry in your ~/.netrc file.  If you have changed the router IP address or
# name/password, modify accordingly.
#
# machine 192.168.1.1
#   login ""
#   password admin
#
# By Eric S. Raymond, August April 2003.  All rites reversed.

import sys, re, copy, curl, exceptions

def print_stderr(arg):
    sys.stderr.write(arg)
    sys.stderr.write("\n")

class LinksysError(exceptions.Exception):
    def __init__(self, *args):
        self.args = args

class LinksysSession:
    months = 'Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec'

    WAN_CONNECT_AUTO = '1'
    WAN_CONNECT_STATIC = '2'
    WAN_CONNECT_PPOE = '3'
    WAN_CONNECT_RAS = '4'
    WAN_CONNECT_PPTP = '5'
    WAN_CONNECT_HEARTBEAT = '6'

    # Substrings to check for on each page load.
    # This may enable us to detect when a firmware change has hosed us.
    check_strings = {
        "":           "basic setup functions",
        "Passwd.htm": "For security reasons,",
        "DHCP.html":  "You can configure the router to act as a DHCP",
        "Log.html":   "There are some log settings and lists in this page.",
        "Forward.htm":"Port forwarding can be used to set up public services",
        }

    def __init__(self):
        self.actions = []
        self.host = "http://192.168.1.1"
        self.verbosity = False
        self.pagecache = {}

    def set_verbosity(self, flag):
        self.verbosity = flag

    # This is not a performance hack -- we need the page cache to do
    # sanity checks at configure time.
    def cache_load(self, page):
        if page not in self.pagecache:
            fetch = curl.Curl(self.host)
            fetch.set_verbosity(self.verbosity)
            fetch.get(page)
            self.pagecache[page] = fetch.body()
            if fetch.answered("401"):
                raise LinksysError("authorization failure.", True)
            elif not fetch.answered(LinksysSession.check_strings[page]):
                del self.pagecache[page]
                raise LinksysError("check string for page %s missing!" % os.path.join(self.host, page), False)
            fetch.close()
    def cache_flush(self):
        self.pagecache = {}

    # Primitives
    def screen_scrape(self, page, template):
        self.cache_load(page)
        match = re.compile(template).search(self.pagecache[page])
        if match:
            result = match.group(1)
        else:
            result = None
        return result
    def get_MAC_address(self, page, prefix):
        return self.screen_scrape("", prefix+r":[^M]*\(MAC Address: *([^)]*)")
    def set_flag(page, flag, value):
        if value:
            self.actions.append(page, flag, "1")
        else:
            self.actions.append(page, flag, "0")
    def set_IP_address(self, page, cgi, role, ip):
        ind = 0
        for octet in ip.split("."):
            self.actions.append(("", "F1", role + `ind+1`, octet))
            ind += 1

    # Scrape configuration data off the main page
    def get_firmware_version(self):
        # This is fragile.  There is no distinguishing tag before the firmware
        # version, so we have to key off the pattern of the version number.
        # Our model is ">1.44.2.1, Dec 20 2002<"
        return self.screen_scrape("", ">([0-9.v]*, (" + \
                                  LinksysSession.months + ")[^<]*)<", )
    def get_LAN_MAC(self):
        return self.get_MAC_address("", r"LAN IP Address")
    def get_Wireless_MAC(self):
        return self.get_MAC_address("", r"Wireless")
    def get_WAN_MAC(self):
        return self.get_MAC_address("", r"WAN Connection Type")

    # Set configuration data on the main page
    def set_host_name(self, name):
        self.actions.append(("", "hostName", name))
    def set_domain_name(self, name):
        self.actions.append(("", "DomainName", name))
    def set_LAN_IP(self, ip):
        self.set_IP_address("", "ipAddr", ip)
    def set_LAN_netmask(self, ip):
        if not ip.startswith("255.255.255."):
            raise ValueError
        lastquad = ip.split(".")[-1]
        if lastquad not in ("0", "128", "192", "240", "252"):
            raise ValueError
        self.actions.append("", "netMask", lastquad)
    def set_wireless(self, flag):
        self.set_flag("", "wirelessStatus")
    def set_SSID(self, ssid):
        self.actions.append(("", "wirelessESSID", ssid))
    def set_SSID_broadcast(self, flag):
        self.set_flag("", "broadcastSSID")
    def set_channel(self, channel):
        self.actions.append(("", "wirelessChannel", channel))
    def set_WEP(self, flag):
        self.set_flag("", "WepType")
    # FIXME: Add support for setting WEP keys
    def set_connection_type(self, type):
        self.actions.append(("", "WANConnectionType", type))
    def set_WAN_IP(self, ip):
        self.set_IP_address("", "aliasIP", ip)
    def set_WAN_netmask(self, ip):
        self.set_IP_address("", "aliasMaskIP", ip)
    def set_WAN_gateway_address(self, ip):
        self.set_IP_address("", "routerIP", ip)
    def set_DNS_server(self, index, ip):
        self.set_IP_address("", "dns" + "ABC"[index], ip)

    # Set configuration data on the password page
    def set_password(self, str):
        self.actions.append("Passwd.htm","sysPasswd", str)
        self.actions.append("Passwd.htm","sysPasswdConfirm", str)
    def set_UPnP(self, flag):
        self.set_flag("Passwd.htm", "UPnP_Work")
    def reset(self):
        self.actions.append("Passwd.htm", "FactoryDefaults")

    # DHCP features
    def set_DHCP(self, flag):
        if flag:
            self.actions.append("DHCP.htm","dhcpStatus","Enable")
        else:
            self.actions.append("DHCP.htm","dhcpStatus","Disable")
    def set_DHCP_starting_IP(self, val):
        self.actions.append("DHCP.htm","dhcpS4", str(val))
    def set_DHCP_users(self, val):
        self.actions.append("DHCP.htm","dhcpLen", str(val))
    def set_DHCP_lease_time(self, val):
        self.actions.append("DHCP.htm","leaseTime", str(val))
    def set_DHCP_DNS_server(self, index, ip):
        self.set_IP_address("DHCP.htm", "dns" + "ABC"[index], ip)
    # FIXME: add support for setting WINS key

    # Logging features
    def set_logging(self, flag):
        if flag:
            self.actions.append("Log.htm", "rLog", "Enable")
        else:
            self.actions.append("Log.htm", "rLog", "Disable")
    def set_log_address(self, val):
        self.actions.append("DHCP.htm","trapAddr3", str(val))

    # The AOL parental control flag is not supported by design.

    # FIXME: add Filters and other advanced features

    def configure(self):
        "Write configuration changes to the Linksys."
        if self.actions:
            fields = []
            self.cache_flush()
            for (page, field, value) in self.actions:
                self.cache_load(page)
                if self.pagecache[page].find(field) == -1:
                    print_stderr("linksys: field %s not found where expected in page %s!" % (field, os.path.join(self.host, page)))
                    continue
                else:
                    fields.append((field, value))
            # Clearing the action list before fieldsping is deliberate.
            # Otherwise we could get permanently wedged by a 401.
            self.actions = []
            transaction = curl.Curl(self.host)
            transaction.set_verbosity(self.verbosity)
            transaction.get("Gozila.cgi", tuple(fields))
            transaction.close()

if __name__ == "__main__":
    import os, cmd

    class LinksysInterpreter(cmd.Cmd):
        """Interpret commands to perform LinkSys programming actions."""
        def __init__(self):
            cmd.Cmd.__init__(self)
            self.session = LinksysSession()
            if os.isatty(0):
                import readline
                print("Type ? or `help' for help.")
                self.prompt = self.session.host + ": "
            else:
                self.prompt = ""
                print("Bar1")

        def flag_command(self, func, line):
            if line.strip() in ("on", "enable", "yes"):
                func(True)
            elif line.strip() in ("off", "disable", "no"):
                func(False)
            else:
                print_stderr("linksys: unknown switch value")
            return 0

        def do_connect(self, line):
            newhost = line.strip()
            if newhost:
                self.session.host = newhost
                self.session.cache_flush()
                self.prompt = self.session.host + ": "
            else:
                print(self.session.host)
            return 0
        def help_connect(self):
            print("Usage: connect [<hostname-or-IP>]")
            print("Connect to a Linksys by name or IP address.")
            print("If no argument is given, print the current host.")

        def do_status(self, line):
            self.session.cache_load("")
            if "" in self.session.pagecache:
                print("Firmware:", self.session.get_firmware_version())
                print("LAN MAC:", self.session.get_LAN_MAC())
                print("Wireless MAC:", self.session.get_Wireless_MAC())
                print("WAN MAC:", self.session.get_WAN_MAC())
                print(".")
            return 0
        def help_status(self):
            print("Usage: status")
            print("The status command shows the status of the Linksys.")
            print("It is mainly useful as a sanity check to make sure")
            print("the box is responding correctly.")

        def do_verbose(self, line):
            self.flag_command(self.session.set_verbosity, line)
        def help_verbose(self):
            print("Usage: verbose {on|off|enable|disable|yes|no}")
            print("Enables display of HTTP requests.")

        def do_host(self, line):
            self.session.set_host_name(line)
            return 0
        def help_host(self):
            print("Usage: host <hostname>")
            print("Sets the Host field to be queried by the ISP.")

        def do_domain(self, line):
            print("Usage: host <domainname>")
            self.session.set_domain_name(line)
            return 0
        def help_domain(self):
            print("Sets the Domain field to be queried by the ISP.")

        def do_lan_address(self, line):
            self.session.set_LAN_IP(line)
            return 0
        def help_lan_address(self):
            print("Usage: lan_address <ip-address>")
            print("Sets the LAN IP address.")

        def do_lan_netmask(self, line):
            self.session.set_LAN_netmask(line)
            return 0
        def help_lan_netmask(self):
            print("Usage: lan_netmask <ip-mask>")
            print("Sets the LAN subnetwork mask.")

        def do_wireless(self, line):
            self.flag_command(self.session.set_wireless, line)
            return 0
        def help_wireless(self):
            print("Usage: wireless {on|off|enable|disable|yes|no}")
            print("Switch to enable or disable wireless features.")

        def do_ssid(self, line):
            self.session.set_SSID(line)
            return 0
        def help_ssid(self):
            print("Usage: ssid <string>")
            print("Sets the SSID used to control wireless access.")

        def do_ssid_broadcast(self, line):
            self.flag_command(self.session.set_SSID_broadcast, line)
            return 0
        def help_ssid_broadcast(self):
            print("Usage: ssid_broadcast {on|off|enable|disable|yes|no}")
            print("Switch to enable or disable SSID broadcast.")

        def do_channel(self, line):
            self.session.set_channel(line)
            return 0
        def help_channel(self):
            print("Usage: channel <number>")
            print("Sets the wireless channel.")

        def do_wep(self, line):
            self.flag_command(self.session.set_WEP, line)
            return 0
        def help_wep(self):
            print("Usage: wep {on|off|enable|disable|yes|no}")
            print("Switch to enable or disable WEP security.")

        def do_wan_type(self, line):
            try:
                type=eval("LinksysSession.WAN_CONNECT_"+line.strip().upper())
                self.session.set_connection_type(type)
            except ValueError:
                print_stderr("linksys: unknown connection type.")
            return 0
        def help_wan_type(self):
            print("Usage: wan_type {auto|static|ppoe|ras|pptp|heartbeat}")
            print("Set the WAN connection type.")

        def do_wan_address(self, line):
            self.session.set_WAN_IP(line)
            return 0
        def help_wan_address(self):
            print("Usage: wan_address <ip-address>")
            print("Sets the WAN IP address.")

        def do_wan_netmask(self, line):
            self.session.set_WAN_netmask(line)
            return 0
        def help_wan_netmask(self):
            print("Usage: wan_netmask <ip-mask>")
            print("Sets the WAN subnetwork mask.")

        def do_wan_gateway(self, line):
            self.session.set_WAN_gateway(line)
            return 0
        def help_wan_gateway(self):
            print("Usage: wan_gateway <ip-address>")
            print("Sets the LAN subnetwork mask.")

        def do_dns(self, line):
            (index, address) = line.split()
            if index in ("1", "2", "3"):
                self.session.set_DNS_server(eval(index), address)
            else:
                print_stderr("linksys: server index out of bounds.")
            return 0
        def help_dns(self):
            print("Usage: dns {1|2|3} <ip-mask>")
            print("Sets a primary, secondary, or tertiary DNS server address.")

        def do_password(self, line):
            self.session.set_password(line)
            return 0
        def help_password(self):
            print("Usage: password <string>")
            print("Sets the router password.")

        def do_upnp(self, line):
            self.flag_command(self.session.set_UPnP, line)
            return 0
        def help_upnp(self):
            print("Usage: upnp {on|off|enable|disable|yes|no}")
            print("Switch to enable or disable Universal Plug and Play.")

        def do_reset(self, line):
            self.session.reset()
        def help_reset(self):
            print("Usage: reset")
            print("Reset Linksys settings to factory defaults.")

        def do_dhcp(self, line):
            self.flag_command(self.session.set_DHCP, line)
        def help_dhcp(self):
            print("Usage: dhcp {on|off|enable|disable|yes|no}")
            print("Switch to enable or disable DHCP features.")

        def do_dhcp_start(self, line):
            self.session.set_DHCP_starting_IP(line)
        def help_dhcp_start(self):
            print("Usage: dhcp_start <number>")
            print("Set the start address of the DHCP pool.")

        def do_dhcp_users(self, line):
            self.session.set_DHCP_users(line)
        def help_dhcp_users(self):
            print("Usage: dhcp_users <number>")
            print("Set number of address slots to allocate in the DHCP pool.")

        def do_dhcp_lease(self, line):
            self.session.set_DHCP_lease(line)
        def help_dhcp_lease(self):
            print("Usage: dhcp_lease <number>")
            print("Set number of address slots to allocate in the DHCP pool.")

        def do_dhcp_dns(self, line):
            (index, address) = line.split()
            if index in ("1", "2", "3"):
                self.session.set_DHCP_DNS_server(eval(index), address)
            else:
                print_stderr("linksys: server index out of bounds.")
            return 0
        def help_dhcp_dns(self):
            print("Usage: dhcp_dns {1|2|3} <ip-mask>")
            print("Sets primary, secondary, or tertiary DNS server address.")

        def do_logging(self, line):
            self.flag_command(self.session.set_logging, line)
        def help_logging(self):
            print("Usage: logging {on|off|enable|disable|yes|no}")
            print("Switch to enable or disable session logging.")

        def do_log_address(self, line):
            self.session.set_Log_address(line)
        def help_log_address(self):
            print("Usage: log_address <number>")
            print("Set the last quad of the address to which to log.")

        def do_configure(self, line):
            self.session.configure()
            return 0
        def help_configure(self):
            print("Usage: configure")
            print("Writes the configuration to the Linksys.")

        def do_cache(self, line):
            print(self.session.pagecache)
        def help_cache(self):
            print("Usage: cache")
            print("Display the page cache.")

        def do_quit(self, line):
            return 1
        def help_quit(self, line):
            print("The quit command ends your linksys session without")
            print("writing configuration changes to the Linksys.")
        def do_EOF(self, line):
            print("")
            self.session.configure()
            return 1
        def help_EOF(self):
            print("The EOF command writes the configuration to the linksys")
            print("and ends your session.")

        def default(self, line):
            """Pass the command through to be executed by the shell."""
            os.system(line)
            return 0

        def help_help(self):
            print("On-line help is available through this command.")
            print("? is a convenience alias for help.")

        def help_introduction(self):
            print("""\

This program supports changing the settings on Linksys blue-box routers.  This
capability may come in handy when they freeze up and have to be reset.  Though
it can be used interactively (and will command-prompt when standard input is a
terminal) it is really designed to be used in batch mode. Commands are taken
from the command line first, then standard input.

By default, it is assumed that the Linksys is at http://192.168.1.1, the
default LAN address.  You can connect to a different address or IP with the
'connect' command.  Note that your .netrc must contain correct user/password
credentials for the router.  The entry corresponding to the defaults is:

machine 192.168.1.1
    login ""
    password admin

Most commands queue up changes but don't actually send them to the Linksys.
You can force pending changes to be written with 'configure'.  Otherwise, they
will be shipped to the Linksys at the end of session (e.g.  when the program
running in batch mode encounters end-of-file or you type a control-D).  If you
end the session with `quit', pending changes will be discarded.

For more help, read the topics 'wan', 'lan', and 'wireless'.""")

        def help_lan(self):
            print("""\
The `lan_address' and `lan_netmask' commands let you set the IP location of
the Linksys on your LAN, or inside.  Normally you'll want to leave these
untouched.""")

        def help_wan(self):
            print("""\
The WAN commands become significant if you are using the BEFSR41 or any of
the other Linksys boxes designed as DSL or cable-modem gateways.  You will
need to use `wan_type' to declare how you expect to get your address.

If your ISP has issued you a static address, you'll need to use the
`wan_address', `wan_netmask', and `wan_gateway' commands to set the address
of the router as seen from the WAN, the outside. In this case you will also
need to use the `dns' command to declare which remote servers your DNS
requests should be forwarded to.

Some ISPs may require you to set host and domain for use with dynamic-address
allocation.""")

        def help_wireless(self):
            print("""\
The channel, ssid, ssid_broadcast, wep, and wireless commands control
wireless routing.""")

        def help_switches(self):
            print("Switches may be turned on with 'on', 'enable', or 'yes'.")
            print("Switches may be turned off with 'off', 'disable', or 'no'.")
            print("Switch commands include: wireless, ssid_broadcast.")

        def help_addresses(self):
            print("An address argument must be a valid IP address;")
            print("four decimal numbers separated by dots, each ")
            print("between 0 and 255.")

        def emptyline(self):
            pass

    interpreter = LinksysInterpreter()
    for arg in sys.argv[1:]:
        interpreter.onecmd(arg)
    fatal = False
    while not fatal:
        try:
            interpreter.cmdloop()
            fatal = True
        except LinksysError, (message, fatal):
            print "linksys:", message

# The following sets edit modes for GNU EMACS
# Local Variables:
# mode:python
# End:

########NEW FILE########
__FILENAME__ = retriever-multi
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

#
# Usage: python retriever-multi.py <file with URLs to fetch> [<# of
#          concurrent connections>]
#

import sys
import pycurl

# We should ignore SIGPIPE when using pycurl.NOSIGNAL - see
# the libcurl tutorial for more info.
try:
    import signal
    from signal import SIGPIPE, SIG_IGN
    signal.signal(signal.SIGPIPE, signal.SIG_IGN)
except ImportError:
    pass


# Get args
num_conn = 10
try:
    if sys.argv[1] == "-":
        urls = sys.stdin.readlines()
    else:
        urls = open(sys.argv[1]).readlines()
    if len(sys.argv) >= 3:
        num_conn = int(sys.argv[2])
except:
    print("Usage: %s <file with URLs to fetch> [<# of concurrent connections>]" % sys.argv[0])
    raise SystemExit


# Make a queue with (url, filename) tuples
queue = []
for url in urls:
    url = url.strip()
    if not url or url[0] == "#":
        continue
    filename = "doc_%03d.dat" % (len(queue) + 1)
    queue.append((url, filename))


# Check args
assert queue, "no URLs given"
num_urls = len(queue)
num_conn = min(num_conn, num_urls)
assert 1 <= num_conn <= 10000, "invalid number of concurrent connections"
print("PycURL %s (compiled against 0x%x)" % (pycurl.version, pycurl.COMPILE_LIBCURL_VERSION_NUM))
print("----- Getting", num_urls, "URLs using", num_conn, "connections -----")


# Pre-allocate a list of curl objects
m = pycurl.CurlMulti()
m.handles = []
for i in range(num_conn):
    c = pycurl.Curl()
    c.fp = None
    c.setopt(pycurl.FOLLOWLOCATION, 1)
    c.setopt(pycurl.MAXREDIRS, 5)
    c.setopt(pycurl.CONNECTTIMEOUT, 30)
    c.setopt(pycurl.TIMEOUT, 300)
    c.setopt(pycurl.NOSIGNAL, 1)
    m.handles.append(c)


# Main loop
freelist = m.handles[:]
num_processed = 0
while num_processed < num_urls:
    # If there is an url to process and a free curl object, add to multi stack
    while queue and freelist:
        url, filename = queue.pop(0)
        c = freelist.pop()
        c.fp = open(filename, "wb")
        c.setopt(pycurl.URL, url)
        c.setopt(pycurl.WRITEDATA, c.fp)
        m.add_handle(c)
        # store some info
        c.filename = filename
        c.url = url
    # Run the internal curl state machine for the multi stack
    while 1:
        ret, num_handles = m.perform()
        if ret != pycurl.E_CALL_MULTI_PERFORM:
            break
    # Check for curl objects which have terminated, and add them to the freelist
    while 1:
        num_q, ok_list, err_list = m.info_read()
        for c in ok_list:
            c.fp.close()
            c.fp = None
            m.remove_handle(c)
            print("Success:", c.filename, c.url, c.getinfo(pycurl.EFFECTIVE_URL))
            freelist.append(c)
        for c, errno, errmsg in err_list:
            c.fp.close()
            c.fp = None
            m.remove_handle(c)
            print("Failed: ", c.filename, c.url, errno, errmsg)
            freelist.append(c)
        num_processed = num_processed + len(ok_list) + len(err_list)
        if num_q == 0:
            break
    # Currently no more I/O is pending, could do something in the meantime
    # (display a progress bar, etc.).
    # We just call select() to sleep until some more data is available.
    m.select(1.0)


# Cleanup
for c in m.handles:
    if c.fp is not None:
        c.fp.close()
        c.fp = None
    c.close()
m.close()


########NEW FILE########
__FILENAME__ = retriever
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

#
# Usage: python retriever.py <file with URLs to fetch> [<# of
#          concurrent connections>]
#

import sys, threading, Queue
import pycurl

# We should ignore SIGPIPE when using pycurl.NOSIGNAL - see
# the libcurl tutorial for more info.
try:
    import signal
    from signal import SIGPIPE, SIG_IGN
    signal.signal(signal.SIGPIPE, signal.SIG_IGN)
except ImportError:
    pass


# Get args
num_conn = 10
try:
    if sys.argv[1] == "-":
        urls = sys.stdin.readlines()
    else:
        urls = open(sys.argv[1]).readlines()
    if len(sys.argv) >= 3:
        num_conn = int(sys.argv[2])
except:
    print("Usage: %s <file with URLs to fetch> [<# of concurrent connections>]" % sys.argv[0])
    raise SystemExit


# Make a queue with (url, filename) tuples
queue = Queue.Queue()
for url in urls:
    url = url.strip()
    if not url or url[0] == "#":
        continue
    filename = "doc_%03d.dat" % (len(queue.queue) + 1)
    queue.put((url, filename))


# Check args
assert queue.queue, "no URLs given"
num_urls = len(queue.queue)
num_conn = min(num_conn, num_urls)
assert 1 <= num_conn <= 10000, "invalid number of concurrent connections"
print("PycURL %s (compiled against 0x%x)" % (pycurl.version, pycurl.COMPILE_LIBCURL_VERSION_NUM))
print("----- Getting", num_urls, "URLs using", num_conn, "connections -----")


class WorkerThread(threading.Thread):
    def __init__(self, queue):
        threading.Thread.__init__(self)
        self.queue = queue

    def run(self):
        while 1:
            try:
                url, filename = self.queue.get_nowait()
            except Queue.Empty:
                raise SystemExit
            fp = open(filename, "wb")
            curl = pycurl.Curl()
            curl.setopt(pycurl.URL, url)
            curl.setopt(pycurl.FOLLOWLOCATION, 1)
            curl.setopt(pycurl.MAXREDIRS, 5)
            curl.setopt(pycurl.CONNECTTIMEOUT, 30)
            curl.setopt(pycurl.TIMEOUT, 300)
            curl.setopt(pycurl.NOSIGNAL, 1)
            curl.setopt(pycurl.WRITEDATA, fp)
            try:
                curl.perform()
            except:
                import traceback
                traceback.print_exc(file=sys.stderr)
                sys.stderr.flush()
            curl.close()
            fp.close()
            sys.stdout.write(".")
            sys.stdout.flush()


# Start a bunch of threads
threads = []
for dummy in range(num_conn):
    t = WorkerThread(queue)
    t.start()
    threads.append(t)


# Wait for all threads to finish
for thread in threads:
    thread.join()

########NEW FILE########
__FILENAME__ = sfquery
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et
#
# sfquery -- Source Forge query script using the ClientCGI high-level interface
#
# Retrieves a SourceForge XML export object for a given project.
# Specify the *numeric* project ID. the user name, and the password,
# as arguments. If you have a valid ~/.netrc entry for sourceforge.net,
# you can just give the project ID.
#
# By Eric S. Raymond, August 2002.  All rites reversed.

import os, sys, netrc
import curl

class SourceForgeUserSession(curl.Curl):
    # SourceForge-specific methods.  Sensitive to changes in site design.
    def login(self, name, password):
        "Establish a login session."
        self.post("account/login.php", (("form_loginname", name),
                                        ("form_pw", password),
                                        ("return_to", ""),
                                        ("stay_in_ssl", "1"),
                                        ("login", "Login With SSL")))
    def logout(self):
        "Log out of SourceForge."
        self.get("account/logout.php")
    def fetch_xml(self, numid):
        self.get("export/xml_export.php?group_id=%s" % numid)

if __name__ == "__main__":
    if len(sys.argv) == 1:
        project_id = '28236'    # PyCurl project ID
    else:
        project_id = sys.argv[1]
    # Try to grab authenticators out of your .netrc
    try:
        auth = netrc.netrc().authenticators("sourceforge.net")
        name, account, password = auth
    except:
        if len(sys.argv) < 4:
            print("Usage: %s <project id> <username> <password>" % sys.argv[0])
            raise SystemExit
        name = sys.argv[2]
        password = sys.argv[3]
    session = SourceForgeUserSession("https://sourceforge.net/")
    session.set_verbosity(0)
    session.login(name, password)
    # Login could fail.
    if session.answered("Invalid Password or User Name"):
        sys.stderr.write("Login/password not accepted (%d bytes)\n" % len(session.body()))
        sys.exit(1)
    # We'll see this if we get the right thing.
    elif session.answered("Personal Page For: " + name):
        session.fetch_xml(project_id)
        sys.stdout.write(session.body())
        session.logout()
        sys.exit(0)
    # Or maybe SourceForge has changed its site design so our check strings
    # are no longer valid.
    else:
        sys.stderr.write("Unexpected page (%d bytes)\n"%len(session.body()))
        sys.exit(1)


########NEW FILE########
__FILENAME__ = test_gtk
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import sys, threading
import pycurl
import pygtk
pygtk.require('2.0')
import gtk

# We should ignore SIGPIPE when using pycurl.NOSIGNAL - see
# the libcurl tutorial for more info.
try:
    import signal
    from signal import SIGPIPE, SIG_IGN
    signal.signal(signal.SIGPIPE, signal.SIG_IGN)
except ImportError:
    pass


class ProgressBar:
    def __init__(self, uri):
        self.round = 0.0
        win = gtk.Window(gtk.WINDOW_TOPLEVEL)
        win.set_title("PycURL progress")
        win.show()
        vbox = gtk.VBox(spacing=5)
        vbox.set_border_width(10)
        win.add(vbox)
        win.set_default_size(200, 20)
        vbox.show()
        label = gtk.Label("Downloading %s" % uri)
        label.set_alignment(0, 0.5)
        vbox.pack_start(label)
        label.show()
        pbar = gtk.ProgressBar()
        pbar.show()
        self.pbar = pbar
        vbox.pack_start(pbar)
        win.connect("destroy", self.close_app)

    def progress(self, download_t, download_d, upload_t, upload_d):
        if download_t == 0:
            self.round = self.round + 0.1
            if self.round >= 1.0:  self.round = 0.0
        else:
            self.round = float(download_d) / float(download_t)
        gtk.threads_enter()
        self.pbar.set_fraction(self.round)
        gtk.threads_leave()

    def mainloop(self):
        gtk.threads_enter()
        gtk.main()
        gtk.threads_leave()

    def close_app(self, *args):
        args[0].destroy()
        gtk.main_quit()


class Test(threading.Thread):
    def __init__(self, url, target_file, progress):
        threading.Thread.__init__(self)
        self.target_file = target_file
        self.progress = progress
        self.curl = pycurl.Curl()
        self.curl.setopt(pycurl.URL, url)
        self.curl.setopt(pycurl.WRITEDATA, self.target_file)
        self.curl.setopt(pycurl.FOLLOWLOCATION, 1)
        self.curl.setopt(pycurl.NOPROGRESS, 0)
        self.curl.setopt(pycurl.PROGRESSFUNCTION, self.progress)
        self.curl.setopt(pycurl.MAXREDIRS, 5)
        self.curl.setopt(pycurl.NOSIGNAL, 1)

    def run(self):
        self.curl.perform()
        self.curl.close()
        self.target_file.close()
        self.progress(1.0, 1.0, 0, 0)


# Check command line args
if len(sys.argv) < 3:
    print("Usage: %s <URL> <filename>" % sys.argv[0])
    raise SystemExit

# Make a progress bar window
p = ProgressBar(sys.argv[1])
# Start thread for fetching url
Test(sys.argv[1], open(sys.argv[2], 'wb'), p.progress).start()
# Enter the GTK mainloop
gtk.threads_init()
try:
    p.mainloop()
except KeyboardInterrupt:
    pass

########NEW FILE########
__FILENAME__ = test_xmlrpc
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

## XML-RPC lib included in python2.2
try:
    import xmlrpclib
except ImportError:
    import xmlrpc.client as xmlrpclib
import pycurl

# Header fields passed in request
xmlrpc_header = [
    "User-Agent: PycURL XML-RPC Test", "Content-Type: text/xml"
    ]

# XML-RPC request template
xmlrpc_template = """
<?xml version='1.0'?><methodCall><methodName>%s</methodName>%s</methodCall>
"""

# Engage
c = pycurl.Curl()
c.setopt(c.URL, 'http://betty.userland.com/RPC2')
c.setopt(c.POST, 1)
c.setopt(c.HTTPHEADER, xmlrpc_header)
c.setopt(c.POSTFIELDS, xmlrpc_template % ("examples.getStateName", xmlrpclib.dumps((5,))))

print('Response from http://betty.userland.com/')
c.perform()
c.close()

########NEW FILE########
__FILENAME__ = xmlrpc_curl
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

# We should ignore SIGPIPE when using pycurl.NOSIGNAL - see
# the libcurl tutorial for more info.
try:
    import signal
    from signal import SIGPIPE, SIG_IGN
    signal.signal(signal.SIGPIPE, signal.SIG_IGN)
except ImportError:
    pass
try:
    from cStringIO import StringIO
except ImportError:
    try:
        from StringIO import StringIO
    except ImportError:
        from io import StringIO
try:
    import xmlrpclib
except ImportError:
    import xmlrpc.client as xmlrpclib
import pycurl


class CURLTransport(xmlrpclib.Transport):
    """Handles a cURL HTTP transaction to an XML-RPC server."""

    xmlrpc_h = [ "Content-Type: text/xml" ]

    def __init__(self, username=None, password=None):
        self.c = pycurl.Curl()
        self.c.setopt(pycurl.POST, 1)
        self.c.setopt(pycurl.NOSIGNAL, 1)
        self.c.setopt(pycurl.CONNECTTIMEOUT, 30)
        self.c.setopt(pycurl.HTTPHEADER, self.xmlrpc_h)
        if username != None and password != None:
            self.c.setopt(pycurl.USERPWD, '%s:%s' % (username, password))
        self._use_datetime = False

    def request(self, host, handler, request_body, verbose=0):
        b = StringIO()
        self.c.setopt(pycurl.URL, 'http://%s%s' % (host, handler))
        self.c.setopt(pycurl.POSTFIELDS, request_body)
        self.c.setopt(pycurl.WRITEFUNCTION, b.write)
        self.c.setopt(pycurl.VERBOSE, verbose)
        self.verbose = verbose
        try:
           self.c.perform()
        except pycurl.error, v:
            raise xmlrpclib.ProtocolError(
                host + handler,
                v[0], v[1], None
                )
        b.seek(0)
        return self.parse_response(b)


if __name__ == "__main__":
    ## Test
    server = xmlrpclib.ServerProxy("http://betty.userland.com",
                                   transport=CURLTransport())
    print(server)
    try:
        print(server.examples.getStateName(41))
    except xmlrpclib.Error, v:
        print("ERROR", v)

########NEW FILE########
__FILENAME__ = app
import time as _time, sys
import bottle
try:
    import json
except ImportError:
    import simplejson as json

py3 = sys.version_info[0] == 3

app = bottle.Bottle()
app.debug = True

@app.route('/success')
def ok():
    return 'success'

@app.route('/short_wait')
def ok():
    _time.sleep(0.1)
    return 'success'

@app.route('/status/403')
def forbidden():
    return bottle.HTTPResponse('forbidden', 403)

@app.route('/status/404')
def not_found():
    return bottle.HTTPResponse('not found', 404)

@app.route('/postfields', method='post')
def postfields():
    return json.dumps(dict(bottle.request.forms))

@app.route('/raw_utf8', method='post')
def raw_utf8():
    data = bottle.request.body.getvalue().decode('utf8')
    return json.dumps(data)

# XXX file is not a bottle FileUpload instance, but FieldStorage?
def convert_file(key, file):
    return {
        'key': key,
        'name': file.name,
        'raw_filename': file.raw_filename,
        'headers': file.headers,
        'content_type': file.content_type,
        'content_length': file.content_length,
        'data': file.read(),
    }

if hasattr(bottle, 'FileUpload'):
    # bottle 0.12
    def convert_file(key, file):
        return {
            'name': file.name,
            # file.filename lowercases the file name
            # https://github.com/defnull/bottle/issues/582
            # raw_filenames is a string on python 3
            'filename': file.raw_filename,
            'data': file.file.read().decode(),
        }
else:
    # bottle 0.11
    def convert_file(key, file):
        return {
            'name': file.name,
            'filename': file.filename,
            'data': file.file.read().decode(),
        }

@app.route('/files', method='post')
def files():
    files = [convert_file(key, bottle.request.files[key]) for key in bottle.request.files]
    return json.dumps(files)

@app.route('/header')
def header():
    return bottle.request.headers[bottle.request.query['h']]

# This is a hacky endpoint to test non-ascii text being given to libcurl
# via headers.
# HTTP RFC requires headers to be latin1-encoded.
# Any string can be decoded as latin1; here we encode the header value
# back into latin1 to obtain original bytestring, then decode it in utf-8.
# Thanks to bdarnell for the idea: https://github.com/pycurl/pycurl/issues/124
@app.route('/header_utf8')
def header():
    header_value = bottle.request.headers[bottle.request.query['h']]
    if py3:
        # header_value is a string, headers are decoded in latin1
        header_value = header_value.encode('latin1').decode('utf8')
    else:
        # header_value is a binary string, decode in utf-8 directly
        header_value = header_value.decode('utf8')
    return header_value

@app.route('/param_utf8_hack', method='post')
def param_utf8_hack():
    param = bottle.request.forms['p']
    if py3:
        # python 3 decodes bytes as latin1 perhaps?
        # apply the latin1-utf8 hack
        param = param.encode('latin').decode('utf8')
    return param

def pause_writer():
    yield 'part1'
    _time.sleep(0.5)
    yield 'part2'

@app.route('/pause')
def pause():
    return pause_writer()

########NEW FILE########
__FILENAME__ = appmanager
import sys, time, os

def noop(*args):
    pass

def setup(*specs):
    if os.environ.get('PYCURL_STANDALONE_APP') and os.environ['PYCURL_STANDALONE_APP'].lower() in ['1', 'yes', 'true']:
        return (noop, noop)
    else:
        return perform_setup(*specs)

def perform_setup(*specs):
    from . import runwsgi
    
    app_specs = []
    for spec in specs:
        app_module = __import__(spec[0], globals(), locals(), ['app'], 1)
        app = getattr(app_module, 'app')
        app_specs.append([app] + list(spec[1:]))
    
    return runwsgi.app_runner_setup(*app_specs)

quit = False

def sigterm_handler(*args):
    global quit
    quit = True

def run_standalone():
    import signal
    
    funcs = []
    
    signal.signal(signal.SIGTERM, sigterm_handler)
    
    funcs.append(setup(('app', 8380)))
    funcs.append(setup(('app', 8381)))
    funcs.append(setup(('app', 8382)))
    funcs.append(setup(('app', 8383, dict(ssl=True))))
    
    for setup_func, teardown_func in funcs:
        setup_func(sys.modules[__name__])
    
    sys.stdout.write("Running, use SIGTERM or SIGINT to stop\n")
    
    try:
        while not quit:
            time.sleep(1)
    except KeyboardInterrupt:
        pass
    
    for setup_func, teardown_func in funcs:
        teardown_func(sys.modules[__name__])

if __name__ == '__main__':
    run_standalone()

########NEW FILE########
__FILENAME__ = certinfo_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import nose.plugins.skip

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8383, dict(ssl=True)))

class CertinfoTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    # CURLOPT_CERTINFO was introduced in libcurl-7.19.1
    @util.min_libcurl(7, 19, 1)
    def test_certinfo_option(self):
        assert hasattr(pycurl, 'OPT_CERTINFO')
    
    # CURLOPT_CERTINFO was introduced in libcurl-7.19.1
    @util.min_libcurl(7, 19, 1)
    @util.only_ssl
    def test_request_without_certinfo(self):
        self.curl.setopt(pycurl.URL, 'https://localhost:8383/success')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        # self signed certificate
        self.curl.setopt(pycurl.SSL_VERIFYPEER, 0)
        self.curl.perform()
        assert sio.getvalue().decode() == 'success'
        
        certinfo = self.curl.getinfo(pycurl.INFO_CERTINFO)
        self.assertEqual([], certinfo)
    
    # CURLOPT_CERTINFO was introduced in libcurl-7.19.1
    @util.min_libcurl(7, 19, 1)
    @util.only_ssl
    def test_request_with_certinfo(self):
        # CURLOPT_CERTINFO only works with OpenSSL
        if 'openssl' not in pycurl.version.lower():
            raise nose.plugins.skip.SkipTest('libcurl does not use openssl')
        
        self.curl.setopt(pycurl.URL, 'https://localhost:8383/success')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.setopt(pycurl.OPT_CERTINFO, 1)
        # self signed certificate
        self.curl.setopt(pycurl.SSL_VERIFYPEER, 0)
        self.curl.perform()
        assert sio.getvalue().decode() == 'success'
        
        certinfo = self.curl.getinfo(pycurl.INFO_CERTINFO)
        # self signed certificate, one certificate in chain
        assert len(certinfo) == 1
        certinfo = certinfo[0]
        # convert to a dictionary
        certinfo_dict = {}
        for entry in certinfo:
            certinfo_dict[entry[0]] = entry[1]
        assert 'Subject' in certinfo_dict
        assert 'PycURL test suite' in certinfo_dict['Subject']

########NEW FILE########
__FILENAME__ = debug_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class DebugTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
        self.debug_entries = []
    
    def tearDown(self):
        self.curl.close()
    
    def debug_function(self, t, b):
        self.debug_entries.append((t, b))
    
    def test_perform_get_with_debug_function(self):
        self.curl.setopt(pycurl.VERBOSE, 1)
        self.curl.setopt(pycurl.DEBUGFUNCTION, self.debug_function)
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        
        # Some checks with no particular intent
        self.check(0, 'Trying')
        if util.pycurl_version_less_than(7, 24):
            self.check(0, 'connected')
        else:
            self.check(0, 'Connected to localhost')
        self.check(0, 'port 8380')
        # request
        self.check(2, 'GET /success HTTP/1.1')
        # response
        self.check(1, 'HTTP/1.0 200 OK')
        self.check(1, 'Content-Length: 7')
        # result
        self.check(3, 'success')
    
    def check(self, wanted_t, wanted_b):
        for t, b in self.debug_entries:
            if t == wanted_t and wanted_b in b:
                return
        assert False, "%d: %s not found in debug entries\nEntries are:\n%s" % \
            (wanted_t, wanted_b, repr(self.debug_entries))

########NEW FILE########
__FILENAME__ = default_write_function_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import unittest
import pycurl
import sys
import tempfile
import os

from . import appmanager

setup_module, teardown_module = appmanager.setup(('app', 8380))

STDOUT_FD_NUM = 1

def try_fsync(fd):
    try:
        os.fsync(fd)
    except OSError:
        # On travis:
        # OSError: [Errno 22] Invalid argument
        # ignore
        pass

class DefaultWriteFunctionTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_perform_get(self):
        # This test performs a GET request without doing anything else.
        # Unfortunately, the default curl behavior is to print response
        # body to standard output, which spams test output.
        # As a result this test is commented out. Uncomment for debugging.
        # test_perform_get_with_default_write_function is the test
        # which exercises default curl write handler.
        
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        self.curl.perform()
        # If this flush is not done, stdout output bleeds into the next test
        # that is executed (without nose output capture)
        sys.stdout.flush()
        try_fsync(STDOUT_FD_NUM)
    
    # I have a really hard time getting this to work with nose output capture
    def skip_perform_get_with_default_write_function(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        f = tempfile.NamedTemporaryFile()
        try:
        #with open('w', 'w+') as f:
            # nose output capture plugin replaces sys.stdout with a StringIO
            # instance. We want to redirect the underlying file descriptor
            # anyway because underlying C code uses it.
            # Therefore:
            # 1. Use file descriptor 1 rather than sys.stdout.fileno() to
            # reference the standard output file descriptor.
            # 2. We do not touch sys.stdout. This means anything written to
            # sys.stdout will be captured by nose, and not make it to our code.
            # But the output we care about happens at libcurl level, below
            # nose, therefore this is fine.
            saved_stdout_fd = os.dup(STDOUT_FD_NUM)
            os.dup2(f.fileno(), STDOUT_FD_NUM)
            #os.dup2(1, 100)
            #os.dup2(2, 1)
            # We also need to flush the output that libcurl wrote to stdout.
            # Since sys.stdout might be nose's StringIO instance, open the
            # stdout file descriptor manually.
            
            try:
                self.curl.perform()
                sys.stdout.flush()
            finally:
                try_fsync(STDOUT_FD_NUM)
                os.dup2(saved_stdout_fd, STDOUT_FD_NUM)
                os.close(saved_stdout_fd)
                #os.dup2(100, 1)
            f.seek(0)
            body = f.read()
        finally:
            f.close()
        self.assertEqual('success', body)

########NEW FILE########
__FILENAME__ = easy_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest

class EasyTest(unittest.TestCase):
    def test_easy_close(self):
        c = pycurl.Curl()
        c.close()
    
    def test_easy_close_twice(self):
        c = pycurl.Curl()
        c.close()
        c.close()

########NEW FILE########
__FILENAME__ = error_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import sys
import unittest

class ErrorTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()

    def tearDown(self):
        self.curl.close()

    # error originating in libcurl
    def test_pycurl_error_libcurl(self):
        try:
            # perform without a url
            self.curl.perform()
        except pycurl.error:
            exc_type, exc = sys.exc_info()[:2]
            assert exc_type == pycurl.error
            # pycurl.error's arguments are libcurl errno and message
            self.assertEqual(2, len(exc.args))
            self.assertEqual(int, type(exc.args[0]))
            self.assertEqual(str, type(exc.args[1]))
            # unpack
            err, msg = exc.args
            self.assertEqual(pycurl.E_URL_MALFORMAT, err)
            # possibly fragile
            self.assertEqual('No URL set!', msg)
        else:
            self.fail('Expected pycurl.error to be raised')
    
    def test_pycurl_errstr_initially_empty(self):
        self.assertEqual('', self.curl.errstr())
    
    def test_pycurl_errstr_type(self):
        self.assertEqual('', self.curl.errstr())
        try:
            # perform without a url
            self.curl.perform()
        except pycurl.error:
            # might be fragile
            self.assertEqual('No URL set!', self.curl.errstr())
            # repeated checks do not clear value
            self.assertEqual('No URL set!', self.curl.errstr())
            # check the type - on all python versions
            self.assertEqual(str, type(self.curl.errstr()))
        else:
            self.fail('no exception')

    # pycurl raises standard library exceptions in some cases
    def test_pycurl_error_stdlib(self):
        try:
            # set an option of the wrong type
            self.curl.setopt(pycurl.WRITEFUNCTION, True)
        except TypeError:
            exc_type, exc = sys.exc_info()[:2]
        else:
            self.fail('Expected TypeError to be raised')

    # error originating in pycurl
    def test_pycurl_error_pycurl(self):
        try:
            # invalid option combination
            self.curl.setopt(pycurl.WRITEFUNCTION, lambda x: x)
            f = open(__file__)
            try:
                self.curl.setopt(pycurl.WRITEHEADER, f)
            finally:
                f.close()
        except pycurl.error:
            exc_type, exc = sys.exc_info()[:2]
            assert exc_type == pycurl.error
            # for non-libcurl errors, arguments are just the error string
            self.assertEqual(1, len(exc.args))
            self.assertEqual(str, type(exc.args[0]))
            self.assertEqual('cannot combine WRITEHEADER with WRITEFUNCTION.', exc.args[0])
        else:
            self.fail('Expected pycurl.error to be raised')

########NEW FILE########
__FILENAME__ = ftp_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

# Note: this test is meant to be run from pycurl project root.

import pycurl
import unittest

from . import util
from . import procmgr

setup_module, teardown_module = procmgr.vsftpd_setup()

class FtpTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_get_ftp(self):
        self.curl.setopt(pycurl.URL, 'ftp://localhost:8321')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        
        result = sio.getvalue().decode()
        assert 'README.rst' in result
        assert 'INSTALL.rst' in result
    
    # XXX this test needs to be fixed
    def test_quote(self):
        self.curl.setopt(pycurl.URL, 'ftp://localhost:8321')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.setopt(pycurl.QUOTE, ['CWD tests'])
        self.curl.perform()
        
        result = sio.getvalue().decode()
        assert 'README.rst' not in result
        assert 'ftp_test.py' in result
    
    def test_epsv(self):
        self.curl.setopt(pycurl.URL, 'ftp://localhost:8321')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.setopt(pycurl.FTP_USE_EPSV, 1)
        self.curl.perform()
        
        result = sio.getvalue().decode()
        assert 'README.rst' in result
        assert 'INSTALL.rst' in result

########NEW FILE########
__FILENAME__ = functools_backport
# partial implementation from
# http://stackoverflow.com/questions/12274814/functools-wraps-for-python-2-4

def partial(func, *args, **kwds):
    """Emulate Python2.6's functools.partial"""
    return lambda *fargs, **fkwds: func(*(args+fargs), **dict(kwds, **fkwds))

# functools from python 2.5

"""functools.py - Tools for working with functions and callable objects
"""
# Python module wrapper for _functools C module
# to allow utilities written in Python to be added
# to the functools module.
# Written by Nick Coghlan <ncoghlan at gmail.com>
#   Copyright (C) 2006 Python Software Foundation.
# See C source code for _functools credits/copyright

# update_wrapper() and wraps() are tools to help write
# wrapper functions that can handle naive introspection

WRAPPER_ASSIGNMENTS = ('__module__', '__name__', '__doc__')
WRAPPER_UPDATES = ('__dict__',)
def update_wrapper(wrapper,
                   wrapped,
                   assigned = WRAPPER_ASSIGNMENTS,
                   updated = WRAPPER_UPDATES):
    """Update a wrapper function to look like the wrapped function

       wrapper is the function to be updated
       wrapped is the original function
       assigned is a tuple naming the attributes assigned directly
       from the wrapped function to the wrapper function (defaults to
       functools.WRAPPER_ASSIGNMENTS)
       updated is a tuple naming the attributes off the wrapper that
       are updated with the corresponding attribute from the wrapped
       function (defaults to functools.WRAPPER_UPDATES)
    """
    for attr in assigned:
        setattr(wrapper, attr, getattr(wrapped, attr))
    for attr in updated:
        getattr(wrapper, attr).update(getattr(wrapped, attr, {}))
    # Return the wrapper so this can be used as a decorator via partial()
    return wrapper

def wraps(wrapped,
          assigned = WRAPPER_ASSIGNMENTS,
          updated = WRAPPER_UPDATES):
    """Decorator factory to apply update_wrapper() to a wrapper function

       Returns a decorator that invokes update_wrapper() with the decorated
       function as the wrapper argument and the arguments to wraps() as the
       remaining arguments. Default arguments are as for update_wrapper().
       This is a convenience function to simplify applying partial() to
       update_wrapper().
    """
    return partial(update_wrapper, wrapped=wrapped,
                   assigned=assigned, updated=updated)

########NEW FILE########
__FILENAME__ = getinfo_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class GetinfoTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_getinfo(self):
        self.make_request()
        
        self.assertEqual(200, self.curl.getinfo(pycurl.HTTP_CODE))
        assert type(self.curl.getinfo(pycurl.TOTAL_TIME)) is float
        assert self.curl.getinfo(pycurl.TOTAL_TIME) > 0
        assert self.curl.getinfo(pycurl.TOTAL_TIME) < 1
        assert type(self.curl.getinfo(pycurl.SPEED_DOWNLOAD)) is float
        assert self.curl.getinfo(pycurl.SPEED_DOWNLOAD) > 0
        self.assertEqual(7, self.curl.getinfo(pycurl.SIZE_DOWNLOAD))
        self.assertEqual('http://localhost:8380/success', self.curl.getinfo(pycurl.EFFECTIVE_URL))
        self.assertEqual('text/html; charset=utf-8', self.curl.getinfo(pycurl.CONTENT_TYPE).lower())
        assert type(self.curl.getinfo(pycurl.NAMELOOKUP_TIME)) is float
        assert self.curl.getinfo(pycurl.NAMELOOKUP_TIME) > 0
        assert self.curl.getinfo(pycurl.NAMELOOKUP_TIME) < 1
        self.assertEqual(0, self.curl.getinfo(pycurl.REDIRECT_TIME))
        self.assertEqual(0, self.curl.getinfo(pycurl.REDIRECT_COUNT))
        # time not requested
        self.assertEqual(-1, self.curl.getinfo(pycurl.INFO_FILETIME))
    
    @util.min_libcurl(7, 21, 0)
    def test_primary_port_etc(self):
        self.make_request()
        assert type(self.curl.getinfo(pycurl.PRIMARY_PORT)) is int
        assert type(self.curl.getinfo(pycurl.LOCAL_IP)) is str
        assert type(self.curl.getinfo(pycurl.LOCAL_PORT)) is int
    
    def make_request(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        self.assertEqual('success', sio.getvalue().decode())

########NEW FILE########
__FILENAME__ = global_init_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import nose.tools
import nose.plugins.skip

from . import util

class GlobalInitTest(unittest.TestCase):
    def test_global_init_default(self):
        # initialize libcurl with DEFAULT flags
        pycurl.global_init(pycurl.GLOBAL_DEFAULT)
        pycurl.global_cleanup()

    def test_global_init_ack_eintr(self):
        # the GLOBAL_ACK_EINTR flag was introduced in libcurl-7.30, but can also
        # be backported for older versions of libcurl at the distribution level
        if util.pycurl_version_less_than(7, 30) and not hasattr(pycurl, 'GLOBAL_ACK_EINTR'):
            raise nose.plugins.skip.SkipTest('libcurl < 7.30.0 or no GLOBAL_ACK_EINTR')
        
        # initialize libcurl with the GLOBAL_ACK_EINTR flag
        pycurl.global_init(pycurl.GLOBAL_ACK_EINTR)
        pycurl.global_cleanup()
    
    @nose.tools.raises(ValueError)
    def test_global_init_bogus(self):
        # initialize libcurl with bogus flags
        pycurl.global_init(0xffff)

########NEW FILE########
__FILENAME__ = header_function_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import time as _time

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class HeaderFunctionTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
        self.header_lines = []
    
    def tearDown(self):
        self.curl.close()
    
    def header_function(self, line):
        self.header_lines.append(line.decode())
    
    def test_get(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.setopt(pycurl.HEADERFUNCTION, self.header_function)
        self.curl.perform()
        self.assertEqual('success', sio.getvalue().decode())
        
        assert len(self.header_lines) > 0
        self.assertEqual("HTTP/1.0 200 OK\r\n", self.header_lines[0])
        # day of week
        # important: must be in utc
        todays_day = _time.strftime('%a', _time.gmtime())
        # Date: Sun, 03 Mar 2013 05:38:12 GMT\r\n
        self.check('Date: %s' % todays_day)
        # Server: WSGIServer/0.1 Python/2.7.3\r\n
        self.check('Server: WSGIServer')
        self.check('Content-Length: 7')
        self.check('Content-Type: text/html')
    
    def check(self, wanted_text):
        for line in self.header_lines:
            if wanted_text in line:
                return
        assert False, "%s not found in header lines" % wanted_text

########NEW FILE########
__FILENAME__ = header_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import nose.tools

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

# NB: HTTP RFC requires headers to be latin1 encoded, which we violate.
# See the comments under /header_utf8 route in app.py.

class HeaderTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_ascii_string_header(self):
        self.check('x-test-header: ascii', 'ascii')
    
    def test_ascii_unicode_header(self):
        self.check(util.u('x-test-header: ascii'), 'ascii')
    
    # on python 2 unicode is accepted in strings because strings are byte strings
    @util.only_python3
    @nose.tools.raises(UnicodeEncodeError)
    def test_unicode_string_header(self):
        self.check('x-test-header: Москва', 'Москва')
    
    @nose.tools.raises(UnicodeEncodeError)
    def test_unicode_unicode_header(self):
        self.check(util.u('x-test-header: Москва'), util.u('Москва'))
    
    def test_encoded_unicode_header(self):
        self.check(util.u('x-test-header: Москва').encode('utf-8'), util.u('Москва'))
    
    def check(self, send, expected):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/header_utf8?h=x-test-header')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.setopt(pycurl.HTTPHEADER, [send])
        self.curl.perform()
        self.assertEqual(expected, sio.getvalue().decode('utf-8'))

########NEW FILE########
__FILENAME__ = internals_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
try:
    import cPickle
except ImportError:
    cPickle = None
import pickle
import copy

from . import util

class InternalsTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
        del self.curl
    
    # /***********************************************************************
    # // test misc
    # ************************************************************************/
    
    def test_constant_aliasing(self):
        assert self.curl.URL is pycurl.URL
    
    # /***********************************************************************
    # // test handles
    # ************************************************************************/

    def test_remove_invalid_handle(self):
        m = pycurl.CurlMulti()
        try:
            m.remove_handle(self.curl)
        except pycurl.error:
            pass
        else:
            assert False, "No exception when trying to remove a handle that is not in CurlMulti"
        del m
    
    def test_remove_invalid_closed_handle(self):
        m = pycurl.CurlMulti()
        c = pycurl.Curl()
        c.close()
        m.remove_handle(c)
        del m, c
    
    def test_add_closed_handle(self):
        m = pycurl.CurlMulti()
        c = pycurl.Curl()
        c.close()
        try:
            m.add_handle(c)
        except pycurl.error:
            pass
        else:
            assert 0, "No exception when trying to add a close handle to CurlMulti"
        m.close()
        del m, c
    
    def test_add_handle_twice(self):
        m = pycurl.CurlMulti()
        m.add_handle(self.curl)
        try:
            m.add_handle(self.curl)
        except pycurl.error:
            pass
        else:
            assert 0, "No exception when trying to add the same handle twice"
        del m
    
    def test_add_handle_on_multiple_stacks(self):
        m1 = pycurl.CurlMulti()
        m2 = pycurl.CurlMulti()
        m1.add_handle(self.curl)
        try:
            m2.add_handle(self.curl)
        except pycurl.error:
            pass
        else:
            assert 0, "No exception when trying to add the same handle on multiple stacks"
        del m1, m2
    
    def test_move_handle(self):
        m1 = pycurl.CurlMulti()
        m2 = pycurl.CurlMulti()
        m1.add_handle(self.curl)
        m1.remove_handle(self.curl)
        m2.add_handle(self.curl)
        del m1, m2
    
    # /***********************************************************************
    # // test copying and pickling - copying and pickling of
    # // instances of Curl and CurlMulti is not allowed
    # ************************************************************************/

    def test_copy_curl(self):
        try:
            copy.copy(self.curl)
        # python 2 raises copy.Error, python 3 raises TypeError
        except (copy.Error, TypeError):
            pass
        else:
            assert False, "No exception when trying to copy a Curl handle"
    
    def test_copy_multi(self):
        m = pycurl.CurlMulti()
        try:
            copy.copy(m)
        except (copy.Error, TypeError):
            pass
        else:
            assert False, "No exception when trying to copy a CurlMulti handle"
    
    def test_pickle_curl(self):
        fp = util.StringIO()
        p = pickle.Pickler(fp, 1)
        try:
            p.dump(self.curl)
        # python 2 raises pickle.PicklingError, python 3 raises TypeError
        except (pickle.PicklingError, TypeError):
            pass
        else:
            assert 0, "No exception when trying to pickle a Curl handle"
        del fp, p
    
    def test_pickle_multi(self):
        m = pycurl.CurlMulti()
        fp = util.StringIO()
        p = pickle.Pickler(fp, 1)
        try:
            p.dump(m)
        except (pickle.PicklingError, TypeError):
            pass
        else:
            assert 0, "No exception when trying to pickle a CurlMulti handle"
        del m, fp, p
    
    if cPickle is not None:
        def test_cpickle_curl(self):
            fp = util.StringIO()
            p = cPickle.Pickler(fp, 1)
            try:
                p.dump(self.curl)
            except cPickle.PicklingError:
                pass
            else:
                assert 0, "No exception when trying to pickle a Curl handle via cPickle"
            del fp, p
        
        def test_cpickle_multi(self):
            m = pycurl.CurlMulti()
            fp = util.StringIO()
            p = cPickle.Pickler(fp, 1)
            try:
                p.dump(m)
            except cPickle.PicklingError:
                pass
            else:
                assert 0, "No exception when trying to pickle a CurlMulti handle via cPickle"
            del m, fp, p

########NEW FILE########
__FILENAME__ = matrix
import os, os.path, subprocess, shutil, re

try:
    from urllib.request import urlopen
except ImportError:
    from urllib import urlopen

python_versions = ['2.4.6', '2.5.6', '2.6.8', '2.7.5', '3.0.1', '3.1.5', '3.2.5', '3.3.3']
libcurl_versions = ['7.19.0', '7.33.0']

python_meta = {
    '2.5.6': {
        'patches': ['python25.patch'],
    },
    '3.0.1': {
        'patches': ['python25.patch', 'python30.patch'],
    },
}

root = os.path.abspath(os.path.dirname(__file__))

class in_dir:
    def __init__(self, dir):
        self.dir = dir
    
    def __enter__(self):
        self.oldwd = os.getcwd()
        os.chdir(self.dir)
    
    def __exit__(self, type, value, traceback):
        os.chdir(self.oldwd)

def fetch(url, archive=None):
    if archive is None:
        archive = os.path.basename(url)
    if not os.path.exists(archive):
        sys.stdout.write("Fetching %s\n" % url)
        io = urlopen(url)
        with open('.tmp.%s' % archive, 'wb') as f:
            while True:
                chunk = io.read(65536)
                if len(chunk) == 0:
                    break
                f.write(chunk)
        os.rename('.tmp.%s' % archive, archive)

def build(archive, dir, prefix, meta=None):
    if not os.path.exists(dir):
        sys.stdout.write("Building %s\n" % archive)
        subprocess.check_call(['tar', 'xf', archive])
        with in_dir(dir):
            if meta and 'patches' in meta:
                for patch in meta['patches']:
                    patch_path = os.path.join(root, 'matrix', patch)
                    subprocess.check_call(['patch', '-p1', '-i', patch_path])
            subprocess.check_call(['./configure', '--prefix=%s' % prefix])
            subprocess.check_call(['make'])
            subprocess.check_call(['make', 'install'])

def patch_pycurl_for_24():
    # change relative imports to old syntax as python 2.4 does not
    # support relative imports
    for root, dirs, files in os.walk('tests'):
        for file in files:
            if file.endswith('.py'):
                path = os.path.join(root, file)
                with open(path, 'r') as f:
                    contents = f.read()
                contents = re.compile(r'^(\s*)from \. import', re.M).sub(r'\1import', contents)
                contents = re.compile(r'^(\s*)from \.(\w+) import', re.M).sub(r'\1from \2 import', contents)
                with open(path, 'w') as f:
                    f.write(contents)

def run_matrix(python_versions, libcurl_versions):
    for python_version in python_versions:
        url = 'http://www.python.org/ftp/python/%s/Python-%s.tgz' % (python_version, python_version)
        archive = os.path.basename(url)
        fetch(url, archive)
        
        dir = archive.replace('.tgz', '')
        prefix = os.path.abspath('i/%s' % dir)
        build(archive, dir, prefix, meta=python_meta.get(python_version))

    for libcurl_version in libcurl_versions:
        url = 'http://curl.haxx.se/download/curl-%s.tar.gz' % libcurl_version
        archive = os.path.basename(url)
        fetch(url, archive)
        
        dir = archive.replace('.tar.gz', '')
        prefix = os.path.abspath('i/%s' % dir)
        build(archive, dir, prefix)

    fetch('https://raw.github.com/pypa/virtualenv/1.7/virtualenv.py', 'virtualenv-1.7.py')
    fetch('https://raw.github.com/pypa/virtualenv/1.9.1/virtualenv.py', 'virtualenv-1.9.1.py')

    if not os.path.exists('venv'):
        os.mkdir('venv')

    for python_version in python_versions:
        python_version_pieces = [int(piece) for piece in python_version.split('.')[:2]]
        for libcurl_version in libcurl_versions:
            python_prefix = os.path.abspath('i/Python-%s' % python_version)
            libcurl_prefix = os.path.abspath('i/curl-%s' % libcurl_version)
            venv = os.path.abspath('venv/Python-%s-curl-%s' % (python_version, libcurl_version))
            if os.path.exists(venv):
                shutil.rmtree(venv)
            if python_version_pieces >= [2, 5]:
                fetch('https://pypi.python.org/packages/2.5/s/setuptools/setuptools-0.6c11-py2.5.egg')
                fetch('https://pypi.python.org/packages/2.6/s/setuptools/setuptools-0.6c11-py2.6.egg')
                fetch('https://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg')
                # I had virtualenv 1.8.2 installed systemwide which
                # did not work with python 3.0:
                # http://stackoverflow.com/questions/14224361/why-am-i-getting-this-error-related-to-pip-and-easy-install-when-trying-to-set
                # so, use known versions everywhere
                # md5=89e68df89faf1966bcbd99a0033fbf8e
                fetch('https://pypi.python.org/packages/source/d/distribute/distribute-0.6.49.tar.gz')
                subprocess.check_call(['python', 'virtualenv-1.9.1.py', venv, '-p', '%s/bin/python%d.%d' % (python_prefix, python_version_pieces[0], python_version_pieces[1]), '--no-site-packages', '--never-download'])
            else:
                # md5=bd639f9b0eac4c42497034dec2ec0c2b
                fetch('https://pypi.python.org/packages/2.4/s/setuptools/setuptools-0.6c11-py2.4.egg')
                # md5=6afbb46aeb48abac658d4df742bff714
                fetch('https://pypi.python.org/packages/source/p/pip/pip-1.4.1.tar.gz')
                subprocess.check_call(['python', 'virtualenv-1.7.py', venv, '-p', '%s/bin/python' % python_prefix, '--no-site-packages', '--never-download'])
            curl_config_path = os.path.join(libcurl_prefix, 'bin/curl-config')
            curl_lib_path = os.path.join(libcurl_prefix, 'lib')
            with in_dir('pycurl'):
                extra_patches = []
                extra_env = []
                if python_version_pieces >= [2, 6]:
                    deps_cmd = 'pip install -r requirements-dev.txt'
                elif python_version_pieces >= [2, 5]:
                    deps_cmd = 'pip install -r requirements-dev-2.5.txt'
                else:
                    deps_cmd = 'easy_install nose simplejson==2.1.0'
                    patch_pycurl_for_24()
                    extra_patches.append('(cd %s/lib/python2.4/site-packages/nose-* && patch -p1) <tests/matrix/nose-1.3.0-python24.patch' % venv)
                    extra_env.append('PYCURL_STANDALONE_APP=yes')
                extra_patches = ' && '.join(extra_patches)
                extra_env = ' '.join(extra_env)
                cmd = '''
                    make clean &&
                    . %(venv)s/bin/activate &&
                    %(deps_cmd)s && %(extra_patches)s
                    python -V &&
                    LD_LIBRARY_PATH=%(curl_lib_path)s PYCURL_CURL_CONFIG=%(curl_config_path)s %(extra_env)s make test
                ''' % dict(
                    venv=venv,
                    deps_cmd=deps_cmd,
                    extra_patches=extra_patches,
                    curl_lib_path=curl_lib_path,
                    curl_config_path=curl_config_path,
                    extra_env=extra_env
                )
                print(cmd)
                subprocess.check_call(cmd, shell=True)

if __name__ == '__main__':
    import sys
    
    def main():
        import optparse
        
        parser = optparse.OptionParser()
        parser.add_option('-p', '--python', help='Specify python version to test against')
        parser.add_option('-c', '--curl', help='Specify libcurl version to test against')
        options, args = parser.parse_args()
        if options.python:
            chosen_python_versions = [options.python]
        else:
            chosen_python_versions = python_versions
        if options.curl:
            chosen_libcurl_versions = [options.curl]
        else:
            chosen_libcurl_versions = libcurl_versions
        run_matrix(chosen_python_versions, chosen_libcurl_versions)
    
    if len(sys.argv) > 1 and sys.argv[1] == 'patch-24':
        patch_pycurl_for_24()
    else:
        main()

########NEW FILE########
__FILENAME__ = memory_mgmt_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import gc

debug = False

class MemoryMgmtTest(unittest.TestCase):
    def maybe_enable_debug(self):
        if debug:
            flags = gc.DEBUG_COLLECTABLE | gc.DEBUG_UNCOLLECTABLE
            # python 3 has no DEBUG_OBJECTS
            if hasattr(gc, 'DEBUG_OBJECTS'):
                flags |= gc.DEBUG_OBJECTS
                flags |= gc.DEBUG_STATS
            gc.set_debug(flags)
            gc.collect()

            print("Tracked objects:", len(gc.get_objects()))
    
    def maybe_print_objects(self):
        if debug:
            print("Tracked objects:", len(gc.get_objects()))
    
    def tearDown(self):
        gc.set_debug(0)
    
    def test_multi_collection(self):
        gc.collect()
        self.maybe_enable_debug()

        multi = pycurl.CurlMulti()
        t = []
        searches = []
        for a in range(100):
            curl = pycurl.Curl()
            multi.add_handle(curl)
            t.append(curl)
            
            c_id = id(curl)
            searches.append(c_id)
        m_id = id(multi)
        searches.append(m_id)

        self.maybe_print_objects()

        for curl in t:
            curl.close()
            multi.remove_handle(curl)

        self.maybe_print_objects()

        del curl
        del t
        del multi

        self.maybe_print_objects()
        gc.collect()
        self.maybe_print_objects()
        
        objects = gc.get_objects()
        for search in searches:
            for object in objects:
                assert search != id(object)
    
    def test_multi_cycle(self):
        gc.collect()
        self.maybe_enable_debug()

        multi = pycurl.CurlMulti()
        t = []
        searches = []
        for a in range(100):
            curl = pycurl.Curl()
            multi.add_handle(curl)
            t.append(curl)
            
            c_id = id(curl)
            searches.append(c_id)
        m_id = id(multi)
        searches.append(m_id)

        self.maybe_print_objects()

        del curl
        del t
        del multi

        self.maybe_print_objects()
        gc.collect()
        self.maybe_print_objects()
        
        objects = gc.get_objects()
        for search in searches:
            for object in objects:
                assert search != id(object)
    
    def test_share_collection(self):
        gc.collect()
        self.maybe_enable_debug()

        share = pycurl.CurlShare()
        t = []
        searches = []
        for a in range(100):
            curl = pycurl.Curl()
            curl.setopt(curl.SHARE, share)
            t.append(curl)
            
            c_id = id(curl)
            searches.append(c_id)
        m_id = id(share)
        searches.append(m_id)

        self.maybe_print_objects()

        for curl in t:
            curl.unsetopt(curl.SHARE)
            curl.close()

        self.maybe_print_objects()

        del curl
        del t
        del share

        self.maybe_print_objects()
        gc.collect()
        self.maybe_print_objects()
        
        objects = gc.get_objects()
        for search in searches:
            for object in objects:
                assert search != id(object)
    
    def test_share_cycle(self):
        gc.collect()
        self.maybe_enable_debug()

        share = pycurl.CurlShare()
        t = []
        searches = []
        for a in range(100):
            curl = pycurl.Curl()
            curl.setopt(curl.SHARE, share)
            t.append(curl)
            
            c_id = id(curl)
            searches.append(c_id)
        m_id = id(share)
        searches.append(m_id)

        self.maybe_print_objects()

        del curl
        del t
        del share

        self.maybe_print_objects()
        gc.collect()
        self.maybe_print_objects()
        
        objects = gc.get_objects()
        for search in searches:
            for object in objects:
                assert search != id(object)

    # basic check of reference counting (use a memory checker like valgrind)
    def test_reference_counting(self):
        c = pycurl.Curl()
        m = pycurl.CurlMulti()
        m.add_handle(c)
        del m
        m = pycurl.CurlMulti()
        c.close()
        del m, c
    
    def test_cyclic_gc(self):
        gc.collect()
        c = pycurl.Curl()
        c.m = pycurl.CurlMulti()
        c.m.add_handle(c)
        # create some nasty cyclic references
        c.c = c
        c.c.c1 = c
        c.c.c2 = c
        c.c.c3 = c.c
        c.c.c4 = c.m
        c.m.c = c
        c.m.m = c.m
        c.m.c = c
        # delete
        gc.collect()
        self.maybe_enable_debug()
        ##print gc.get_referrers(c)
        ##print gc.get_objects()
        #if opts.verbose >= 1:
            #print("Tracked objects:", len(gc.get_objects()))
        c_id = id(c)
        # The `del' below should delete these 4 objects:
        #   Curl + internal dict, CurlMulti + internal dict
        del c
        gc.collect()
        objects = gc.get_objects()
        for object in objects:
            assert id(object) != c_id
        #if opts.verbose >= 1:
            #print("Tracked objects:", len(gc.get_objects()))
    
    def test_refcounting_bug_in_reset(self):
        try:
            range_generator = xrange
        except NameError:
            range_generator = range
        # Ensure that the refcounting error in "reset" is fixed:
        for i in range_generator(100000):
            c = pycurl.Curl()
            c.reset()
    
    def test_opensocketfunction_collection(self):
        # Note: extracting a context manager seems to result in
        # everything being garbage collected even if the C code
        # does not clear the callback
        object_count = 0
        gc.collect()
        object_count = len(gc.get_objects())
        
        c = pycurl.Curl()
        c.setopt(c.OPENSOCKETFUNCTION, lambda x: True)
        del c
        
        gc.collect()
        new_object_count = len(gc.get_objects())
        self.assertEqual(new_object_count, object_count)
    
    def test_seekfunction_collection(self):
        # Note: extracting a context manager seems to result in
        # everything being garbage collected even if the C code
        # does not clear the callback
        object_count = 0
        gc.collect()
        object_count = len(gc.get_objects())
        
        c = pycurl.Curl()
        c.setopt(c.SEEKFUNCTION, lambda x: True)
        del c
        
        gc.collect()
        new_object_count = len(gc.get_objects())
        self.assertEqual(new_object_count, object_count)

########NEW FILE########
__FILENAME__ = multi_option_constants_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest

from . import util

class MultiOptionConstantsTest(unittest.TestCase):
    @util.min_libcurl(7, 30, 0)
    def test_multi_pipeline_opts(self):
        assert hasattr(pycurl, 'M_MAX_HOST_CONNECTIONS')
        assert hasattr(pycurl, 'M_MAX_PIPELINE_LENGTH')
        assert hasattr(pycurl, 'M_CONTENT_LENGTH_PENALTY_SIZE')
        assert hasattr(pycurl, 'M_CHUNK_LENGTH_PENALTY_SIZE')
        assert hasattr(pycurl, 'M_MAX_TOTAL_CONNECTIONS')
        m = pycurl.CurlMulti()
        m.setopt(pycurl.M_MAX_HOST_CONNECTIONS, 2)
        m.setopt(pycurl.M_MAX_PIPELINE_LENGTH, 2)
        m.setopt(pycurl.M_CONTENT_LENGTH_PENALTY_SIZE, 2)
        m.setopt(pycurl.M_CHUNK_LENGTH_PENALTY_SIZE, 2)
        m.setopt(pycurl.M_MAX_TOTAL_CONNECTIONS, 2)
        m.close()

########NEW FILE########
__FILENAME__ = multi_socket_select_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import select

from . import appmanager
from . import util

setup_module_1, teardown_module_1 = appmanager.setup(('app', 8380))
setup_module_2, teardown_module_2 = appmanager.setup(('app', 8381))
setup_module_3, teardown_module_3 = appmanager.setup(('app', 8382))

def setup_module(mod):
    setup_module_1(mod)
    setup_module_2(mod)
    setup_module_3(mod)

def teardown_module(mod):
    teardown_module_3(mod)
    teardown_module_2(mod)
    teardown_module_1(mod)

class MultiSocketSelectTest(unittest.TestCase):
    def test_multi_socket_select(self):
        sockets = set()
        timeout = 0

        urls = [
            # we need libcurl to actually wait on the handles,
            # and initiate polling.
            # thus use urls that sleep for a bit.
            'http://localhost:8380/short_wait',
            'http://localhost:8381/short_wait',
            'http://localhost:8382/short_wait',
        ]

        socket_events = []
        
        # socket callback
        def socket(event, socket, multi, data):
            if event == pycurl.POLL_REMOVE:
                #print("Remove Socket %d"%socket)
                sockets.remove(socket)
            else:
                if socket not in sockets:
                    #print("Add socket %d"%socket)
                    sockets.add(socket)
            socket_events.append((event, multi))

        # init
        m = pycurl.CurlMulti()
        m.setopt(pycurl.M_SOCKETFUNCTION, socket)
        m.handles = []
        for url in urls:
            c = pycurl.Curl()
            # save info in standard Python attributes
            c.url = url
            c.body = util.BytesIO()
            c.http_code = -1
            m.handles.append(c)
            # pycurl API calls
            c.setopt(c.URL, c.url)
            c.setopt(c.WRITEFUNCTION, c.body.write)
            m.add_handle(c)

        # get data
        num_handles = len(m.handles)

        while (pycurl.E_CALL_MULTI_PERFORM==m.socket_all()[0]):
            pass
            
        timeout = m.timeout()

        # timeout might be -1, indicating that all work is done
        # XXX make sure there is always work to be done here?
        while timeout >= 0:
            (rr, wr, er) = select.select(sockets,sockets,sockets,timeout/1000.0)
            socketSet = set(rr+wr+er)
            if socketSet:
                for s in socketSet:
                    while True:
                        (ret,running) = m.socket_action(s,0)
                        if ret!=pycurl.E_CALL_MULTI_PERFORM:
                            break
            else:
                (ret,running) = m.socket_action(pycurl.SOCKET_TIMEOUT,0)
            if running==0:
                break

        for c in m.handles:
            # save info in standard Python attributes
            c.http_code = c.getinfo(c.HTTP_CODE)

        # at least in and remove events per socket
        assert len(socket_events) >= 6, 'Less than 6 socket events: %s' % repr(socket_events)

        # print result
        for c in m.handles:
            self.assertEqual('success', c.body.getvalue().decode())
            self.assertEqual(200, c.http_code)
            
            # multi, not curl handle
            self.check(pycurl.POLL_IN, m, socket_events)
            self.check(pycurl.POLL_REMOVE, m, socket_events)
        
        # close handles
        for c in m.handles:
            # pycurl API calls
            m.remove_handle(c)
            c.close()
        m.close()
    
    def check(self, event, multi, socket_events):
        for event_, multi_ in socket_events:
            if event == event_ and multi == multi_:
                return
        assert False, '%d %s not found in socket events' % (event, multi)

########NEW FILE########
__FILENAME__ = multi_socket_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest

from . import appmanager
from . import util

setup_module_1, teardown_module_1 = appmanager.setup(('app', 8380))
setup_module_2, teardown_module_2 = appmanager.setup(('app', 8381))
setup_module_3, teardown_module_3 = appmanager.setup(('app', 8382))

def setup_module(mod):
    setup_module_1(mod)
    setup_module_2(mod)
    setup_module_3(mod)

def teardown_module(mod):
    teardown_module_3(mod)
    teardown_module_2(mod)
    teardown_module_1(mod)

class MultiSocketTest(unittest.TestCase):
    def test_multi_socket(self):
        urls = [
            # not sure why requesting /success produces no events.
            # see multi_socket_select_test.py for a longer explanation
            # why short wait is used there.
            'http://localhost:8380/short_wait',
            'http://localhost:8381/short_wait',
            'http://localhost:8382/short_wait',
        ]

        socket_events = []

        # socket callback
        def socket(event, socket, multi, data):
            #print(event, socket, multi, data)
            socket_events.append((event, multi))

        # init
        m = pycurl.CurlMulti()
        m.setopt(pycurl.M_SOCKETFUNCTION, socket)
        m.handles = []
        for url in urls:
            c = pycurl.Curl()
            # save info in standard Python attributes
            c.url = url
            c.body = util.BytesIO()
            c.http_code = -1
            m.handles.append(c)
            # pycurl API calls
            c.setopt(c.URL, c.url)
            c.setopt(c.WRITEFUNCTION, c.body.write)
            m.add_handle(c)

        # get data
        num_handles = len(m.handles)
        while num_handles:
            while 1:
                ret, num_handles = m.socket_all()
                if ret != pycurl.E_CALL_MULTI_PERFORM:
                    break
            # currently no more I/O is pending, could do something in the meantime
            # (display a progress bar, etc.)
            m.select(0.1)

        for c in m.handles:
            # save info in standard Python attributes
            c.http_code = c.getinfo(c.HTTP_CODE)

        # at least in and remove events per socket
        assert len(socket_events) >= 6

        # print result
        for c in m.handles:
            self.assertEqual('success', c.body.getvalue().decode())
            self.assertEqual(200, c.http_code)
            
            # multi, not curl handle
            self.check(pycurl.POLL_IN, m, socket_events)
            self.check(pycurl.POLL_REMOVE, m, socket_events)
        
        # close handles
        for c in m.handles:
            # pycurl API calls
            m.remove_handle(c)
            c.close()
        m.close()
    
    def check(self, event, multi, socket_events):
        for event_, multi_ in socket_events:
            if event == event_ and multi == multi_:
                return
        assert False, '%d %s not found in socket events' % (event, multi)

########NEW FILE########
__FILENAME__ = multi_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import select

from . import appmanager
from . import util

setup_module_1, teardown_module_1 = appmanager.setup(('app', 8380))
setup_module_2, teardown_module_2 = appmanager.setup(('app', 8381))
setup_module_3, teardown_module_3 = appmanager.setup(('app', 8382))

def setup_module(mod):
    setup_module_1(mod)
    setup_module_2(mod)
    setup_module_3(mod)

def teardown_module(mod):
    teardown_module_3(mod)
    teardown_module_2(mod)
    teardown_module_1(mod)

class MultiTest(unittest.TestCase):
    def test_multi(self):
        io1 = util.BytesIO()
        io2 = util.BytesIO()
        m = pycurl.CurlMulti()
        handles = []
        c1 = pycurl.Curl()
        c2 = pycurl.Curl()
        c1.setopt(c1.URL, 'http://localhost:8380/success')
        c1.setopt(c1.WRITEFUNCTION, io1.write)
        c2.setopt(c2.URL, 'http://localhost:8381/success')
        c2.setopt(c1.WRITEFUNCTION, io2.write)
        m.add_handle(c1)
        m.add_handle(c2)
        handles.append(c1)
        handles.append(c2)

        num_handles = len(handles)
        while num_handles:
            while 1:
                ret, num_handles = m.perform()
                if ret != pycurl.E_CALL_MULTI_PERFORM:
                    break
            m.select(1.0)

        m.remove_handle(c2)
        m.remove_handle(c1)
        m.close()
        c1.close()
        c2.close()
        
        self.assertEqual('success', io1.getvalue().decode())
        self.assertEqual('success', io2.getvalue().decode())
    
    def test_multi_select_fdset(self):
        c1 = pycurl.Curl()
        c2 = pycurl.Curl()
        c3 = pycurl.Curl()
        c1.setopt(c1.URL, "http://localhost:8380/success")
        c2.setopt(c2.URL, "http://localhost:8381/success")
        c3.setopt(c3.URL, "http://localhost:8382/success")
        c1.body = util.BytesIO()
        c2.body = util.BytesIO()
        c3.body = util.BytesIO()
        c1.setopt(c1.WRITEFUNCTION, c1.body.write)
        c2.setopt(c2.WRITEFUNCTION, c2.body.write)
        c3.setopt(c3.WRITEFUNCTION, c3.body.write)

        m = pycurl.CurlMulti()
        m.add_handle(c1)
        m.add_handle(c2)
        m.add_handle(c3)

        # Number of seconds to wait for a timeout to happen
        SELECT_TIMEOUT = 0.1

        # Stir the state machine into action
        while 1:
            ret, num_handles = m.perform()
            if ret != pycurl.E_CALL_MULTI_PERFORM:
                break

        # Keep going until all the connections have terminated
        while num_handles:
            select.select(*m.fdset() + (SELECT_TIMEOUT,))
            while 1:
                ret, num_handles = m.perform()
                if ret != pycurl.E_CALL_MULTI_PERFORM:
                    break

        # Cleanup
        m.remove_handle(c3)
        m.remove_handle(c2)
        m.remove_handle(c1)
        m.close()
        c1.close()
        c2.close()
        c3.close()
        
        self.assertEqual('success', c1.body.getvalue().decode())
        self.assertEqual('success', c2.body.getvalue().decode())
        self.assertEqual('success', c3.body.getvalue().decode())
    
    def test_multi_status_codes(self):
        # init
        m = pycurl.CurlMulti()
        m.handles = []
        urls = [
            'http://localhost:8380/success',
            'http://localhost:8381/status/403',
            'http://localhost:8382/status/404',
        ]
        for url in urls:
            c = pycurl.Curl()
            # save info in standard Python attributes
            c.url = url.rstrip()
            c.body = util.BytesIO()
            c.http_code = -1
            m.handles.append(c)
            # pycurl API calls
            c.setopt(c.URL, c.url)
            c.setopt(c.WRITEFUNCTION, c.body.write)
            m.add_handle(c)

        # get data
        num_handles = len(m.handles)
        while num_handles:
            while 1:
                ret, num_handles = m.perform()
                if ret != pycurl.E_CALL_MULTI_PERFORM:
                    break
            # currently no more I/O is pending, could do something in the meantime
            # (display a progress bar, etc.)
            m.select(0.1)

        # close handles
        for c in m.handles:
            # save info in standard Python attributes
            c.http_code = c.getinfo(c.HTTP_CODE)
            # pycurl API calls
            m.remove_handle(c)
            c.close()
        m.close()

        # check result
        self.assertEqual('success', m.handles[0].body.getvalue().decode())
        self.assertEqual(200, m.handles[0].http_code)
        # bottle generated response body
        self.assertEqual('forbidden', m.handles[1].body.getvalue().decode())
        self.assertEqual(403, m.handles[1].http_code)
        # bottle generated response body
        self.assertEqual('not found', m.handles[2].body.getvalue().decode())
        self.assertEqual(404, m.handles[2].http_code)
    
    def check_adding_closed_handle(self, close_fn):
        # init
        m = pycurl.CurlMulti()
        m.handles = []
        urls = [
            'http://localhost:8380/success',
            'http://localhost:8381/status/403',
            'http://localhost:8382/status/404',
        ]
        for url in urls:
            c = pycurl.Curl()
            # save info in standard Python attributes
            c.url = url
            c.body = util.BytesIO()
            c.http_code = -1
            c.debug = 0
            m.handles.append(c)
            # pycurl API calls
            c.setopt(c.URL, c.url)
            c.setopt(c.WRITEFUNCTION, c.body.write)
            m.add_handle(c)

        # debug - close a handle
        c = m.handles[2]
        c.debug = 1
        c.close()

        # get data
        num_handles = len(m.handles)
        while num_handles:
            while 1:
                ret, num_handles = m.perform()
                if ret != pycurl.E_CALL_MULTI_PERFORM:
                    break
            # currently no more I/O is pending, could do something in the meantime
            # (display a progress bar, etc.)
            m.select(0.1)

        # close handles
        for c in m.handles:
            # save info in standard Python attributes
            try:
                c.http_code = c.getinfo(c.HTTP_CODE)
            except pycurl.error:
                # handle already closed - see debug above
                assert c.debug
                c.http_code = -1
            # pycurl API calls
            close_fn(m, c)
        m.close()

        # check result
        self.assertEqual('success', m.handles[0].body.getvalue().decode())
        self.assertEqual(200, m.handles[0].http_code)
        # bottle generated response body
        self.assertEqual('forbidden', m.handles[1].body.getvalue().decode())
        self.assertEqual(403, m.handles[1].http_code)
        # bottle generated response body
        self.assertEqual('', m.handles[2].body.getvalue().decode())
        self.assertEqual(-1, m.handles[2].http_code)
    
    def _remove_then_close(self, m, c):
        m.remove_handle(c)
        c.close()
    
    def _close_then_remove(self, m, c):
        # in the C API this is the wrong calling order, but pycurl
        # handles this automatically
        c.close()
        m.remove_handle(c)
    
    def _close_without_removing(self, m, c):
        # actually, remove_handle is called automatically on close
        c.close
    
    def test_adding_closed_handle_remove_then_close(self):
        self.check_adding_closed_handle(self._remove_then_close)
    
    def test_adding_closed_handle_close_then_remove(self):
        self.check_adding_closed_handle(self._close_then_remove)
    
    def test_adding_closed_handle_close_without_removing(self):
        self.check_adding_closed_handle(self._close_without_removing)
    
    def test_multi_select(self):
        c1 = pycurl.Curl()
        c2 = pycurl.Curl()
        c3 = pycurl.Curl()
        c1.setopt(c1.URL, "http://localhost:8380/success")
        c2.setopt(c2.URL, "http://localhost:8381/success")
        c3.setopt(c3.URL, "http://localhost:8382/success")
        c1.body = util.BytesIO()
        c2.body = util.BytesIO()
        c3.body = util.BytesIO()
        c1.setopt(c1.WRITEFUNCTION, c1.body.write)
        c2.setopt(c2.WRITEFUNCTION, c2.body.write)
        c3.setopt(c3.WRITEFUNCTION, c3.body.write)

        m = pycurl.CurlMulti()
        m.add_handle(c1)
        m.add_handle(c2)
        m.add_handle(c3)

        # Number of seconds to wait for a timeout to happen
        SELECT_TIMEOUT = 1.0

        # Stir the state machine into action
        while 1:
            ret, num_handles = m.perform()
            if ret != pycurl.E_CALL_MULTI_PERFORM:
                break

        # Keep going until all the connections have terminated
        while num_handles:
            # The select method uses fdset internally to determine which file descriptors
            # to check.
            m.select(SELECT_TIMEOUT)
            while 1:
                ret, num_handles = m.perform()
                if ret != pycurl.E_CALL_MULTI_PERFORM:
                    break

        # Cleanup
        m.remove_handle(c3)
        m.remove_handle(c2)
        m.remove_handle(c1)
        m.close()
        c1.close()
        c2.close()
        c3.close()
        
        self.assertEqual('success', c1.body.getvalue().decode())
        self.assertEqual('success', c2.body.getvalue().decode())
        self.assertEqual('success', c3.body.getvalue().decode())
    
    def test_multi_info_read(self):
        c1 = pycurl.Curl()
        c2 = pycurl.Curl()
        c3 = pycurl.Curl()
        c1.setopt(c1.URL, "http://localhost:8380/short_wait")
        c2.setopt(c2.URL, "http://localhost:8381/short_wait")
        c3.setopt(c3.URL, "http://localhost:8382/short_wait")
        c1.body = util.BytesIO()
        c2.body = util.BytesIO()
        c3.body = util.BytesIO()
        c1.setopt(c1.WRITEFUNCTION, c1.body.write)
        c2.setopt(c2.WRITEFUNCTION, c2.body.write)
        c3.setopt(c3.WRITEFUNCTION, c3.body.write)

        m = pycurl.CurlMulti()
        m.add_handle(c1)
        m.add_handle(c2)
        m.add_handle(c3)

        # Number of seconds to wait for a timeout to happen
        SELECT_TIMEOUT = 1.0

        # Stir the state machine into action
        while 1:
            ret, num_handles = m.perform()
            if ret != pycurl.E_CALL_MULTI_PERFORM:
                break

        infos = []
        # Keep going until all the connections have terminated
        while num_handles:
            # The select method uses fdset internally to determine which file descriptors
            # to check.
            m.select(SELECT_TIMEOUT)
            while 1:
                ret, num_handles = m.perform()
                info = m.info_read()
                infos.append(info)
                if ret != pycurl.E_CALL_MULTI_PERFORM:
                    break

        all_handles = []
        for info in infos:
            handles = info[1]
            # last info is an empty array
            if handles:
                all_handles.extend(handles)
        
        self.assertEqual(3, len(all_handles))
        assert c1 in all_handles
        assert c2 in all_handles
        assert c3 in all_handles
        
        # Cleanup
        m.remove_handle(c3)
        m.remove_handle(c2)
        m.remove_handle(c1)
        m.close()
        c1.close()
        c2.close()
        c3.close()
        
        self.assertEqual('success', c1.body.getvalue().decode())
        self.assertEqual('success', c2.body.getvalue().decode())
        self.assertEqual('success', c3.body.getvalue().decode())
    
    def test_multi_close(self):
        m = pycurl.CurlMulti()
        m.close()
    
    def test_multi_close_twice(self):
        m = pycurl.CurlMulti()
        m.close()
        m.close()

########NEW FILE########
__FILENAME__ = multi_timer_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest

from . import appmanager
from . import util

setup_module_1, teardown_module_1 = appmanager.setup(('app', 8380))
setup_module_2, teardown_module_2 = appmanager.setup(('app', 8381))
setup_module_3, teardown_module_3 = appmanager.setup(('app', 8382))

def setup_module(mod):
    setup_module_1(mod)
    setup_module_2(mod)
    setup_module_3(mod)

def teardown_module(mod):
    teardown_module_3(mod)
    teardown_module_2(mod)
    teardown_module_1(mod)

class MultiSocketTest(unittest.TestCase):
    def test_multi_timer(self):
        urls = [
            'http://localhost:8380/success',
            'http://localhost:8381/success',
            'http://localhost:8382/success',
        ]

        timers = []
        
        # timer callback
        def timer(msecs):
            #print('Timer callback msecs:', msecs)
            timers.append(msecs)

        # init
        m = pycurl.CurlMulti()
        m.setopt(pycurl.M_TIMERFUNCTION, timer)
        m.handles = []
        for url in urls:
            c = pycurl.Curl()
            # save info in standard Python attributes
            c.url = url
            c.body = util.BytesIO()
            c.http_code = -1
            m.handles.append(c)
            # pycurl API calls
            c.setopt(c.URL, c.url)
            c.setopt(c.WRITEFUNCTION, c.body.write)
            m.add_handle(c)

        # get data
        num_handles = len(m.handles)
        while num_handles:
            while 1:
                ret, num_handles = m.perform()
                if ret != pycurl.E_CALL_MULTI_PERFORM:
                    break
                # currently no more I/O is pending, could do something in the meantime
                # (display a progress bar, etc.)
                m.select(1.0)

        for c in m.handles:
            # save info in standard Python attributes
            c.http_code = c.getinfo(c.HTTP_CODE)

        # print result
        for c in m.handles:
            self.assertEqual('success', c.body.getvalue().decode())
            self.assertEqual(200, c.http_code)
        
        assert len(timers) > 0
        # libcurl 7.23.0 produces a 0 timer
        assert timers[0] >= 0
        # this assertion does not appear to hold on older libcurls
        # or apparently on any linuxes, see
        # https://github.com/p/pycurl/issues/19
        #if not util.pycurl_version_less_than(7, 24):
        #    self.assertEqual(-1, timers[-1])

        # close handles
        for c in m.handles:
            # pycurl API calls
            m.remove_handle(c)
            c.close()
        m.close()

########NEW FILE########
__FILENAME__ = option_constants_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import nose.plugins.skip

from . import util

class OptionConstantsTest(unittest.TestCase):
    # CURLOPT_USERNAME was introduced in libcurl-7.19.1
    @util.min_libcurl(7, 19, 1)
    def test_username(self):
        assert hasattr(pycurl, 'USERNAME')
        assert hasattr(pycurl, 'PASSWORD')
        assert hasattr(pycurl, 'PROXYUSERNAME')
        assert hasattr(pycurl, 'PROXYPASSWORD')
    
    # CURLOPT_DNS_SERVERS was introduced in libcurl-7.24.0
    @util.min_libcurl(7, 24, 0)
    def test_dns_servers(self):
        assert hasattr(pycurl, 'DNS_SERVERS')
        
        # Does not work unless libcurl was built against c-ares
        #c = pycurl.Curl()
        #c.setopt(c.DNS_SERVERS, '1.2.3.4')
        #c.close()

    # CURLOPT_POSTREDIR was introduced in libcurl-7.19.1
    @util.min_libcurl(7, 19, 1)
    def test_postredir(self):
        assert hasattr(pycurl, 'POSTREDIR')
        assert hasattr(pycurl, 'REDIR_POST_301')
        assert hasattr(pycurl, 'REDIR_POST_302')
        assert hasattr(pycurl, 'REDIR_POST_ALL')
    
    # CURLOPT_POSTREDIR was introduced in libcurl-7.19.1
    @util.min_libcurl(7, 19, 1)
    def test_postredir_setopt(self):
        curl = pycurl.Curl()
        curl.setopt(curl.POSTREDIR, curl.REDIR_POST_301)
        curl.close()
    
    # CURL_REDIR_POST_303 was introduced in libcurl-7.26.0
    @util.min_libcurl(7, 26, 0)
    def test_redir_post_303(self):
        assert hasattr(pycurl, 'REDIR_POST_303')

    # CURLOPT_POSTREDIR was introduced in libcurl-7.19.1
    @util.min_libcurl(7, 19, 1)
    def test_postredir_flags(self):
        self.assertEqual(pycurl.REDIR_POST_301, pycurl.REDIR_POST_ALL & pycurl.REDIR_POST_301)
        self.assertEqual(pycurl.REDIR_POST_302, pycurl.REDIR_POST_ALL & pycurl.REDIR_POST_302)

    # CURL_REDIR_POST_303 was introduced in libcurl-7.26.0
    @util.min_libcurl(7, 26, 0)
    def test_postredir_flags(self):
        self.assertEqual(pycurl.REDIR_POST_303, pycurl.REDIR_POST_ALL & pycurl.REDIR_POST_303)

    # HTTPAUTH_DIGEST_IE was introduced in libcurl-7.19.3
    @util.min_libcurl(7, 19, 3)
    def test_httpauth_digest_ie(self):
        assert hasattr(pycurl, 'HTTPAUTH_DIGEST_IE')

    # CURLE_OPERATION_TIMEDOUT was introduced in libcurl-7.10.2
    # to replace CURLE_OPERATION_TIMEOUTED
    def test_operation_timedout_constant(self):
        self.assertEqual(pycurl.E_OPERATION_TIMEDOUT, pycurl.E_OPERATION_TIMEOUTED)
    
    # CURLOPT_NOPROXY was introduced in libcurl-7.19.4
    @util.min_libcurl(7, 19, 4)
    def test_noproxy_setopt(self):
        curl = pycurl.Curl()
        curl.setopt(curl.NOPROXY, 'localhost')
        curl.close()
    
    # CURLOPT_PROTOCOLS was introduced in libcurl-7.19.4
    @util.min_libcurl(7, 19, 4)
    def test_protocols_setopt(self):
        curl = pycurl.Curl()
        curl.setopt(curl.PROTOCOLS, curl.PROTO_ALL & ~curl.PROTO_HTTP)
        curl.close()
    
    # CURLOPT_REDIR_PROTOCOLS was introduced in libcurl-7.19.4
    @util.min_libcurl(7, 19, 4)
    def test_redir_protocols_setopt(self):
        curl = pycurl.Curl()
        curl.setopt(curl.PROTOCOLS, curl.PROTO_ALL & ~curl.PROTO_HTTP)
        curl.close()

########NEW FILE########
__FILENAME__ = pause_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest, signal
import time as _time

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class PauseTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_pause_via_call(self):
        self.check_pause(True)
    
    def test_pause_via_return(self):
        self.check_pause(False)
    
    def check_pause(self, call):
        # the app sleeps for 0.5 seconds
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/pause')
        sio = util.BytesIO()
        state = dict(paused=False, resumed=False)
        if call:
            def writefunc(data):
                rv = sio.write(data)
                if not state['paused']:
                    self.curl.pause(pycurl.PAUSE_ALL)
                    state['paused'] = True
                return rv
        else:
            def writefunc(data):
                if not state['paused']:
                    # cannot write to sio here, because
                    # curl takes pause return value to mean that
                    # nothing was written
                    state['paused'] = True
                    return pycurl.READFUNC_PAUSE
                else:
                    return sio.write(data)
        def resume(*args):
            state['resumed'] = True
            self.curl.pause(pycurl.PAUSE_CONT)
        signal.signal(signal.SIGALRM, resume)
        # alarm for 1 second which is 0.5 seconds more than the server side
        # should sleep for
        signal.alarm(1)
        start = _time.time()
        self.curl.setopt(pycurl.WRITEFUNCTION, writefunc)
        
        m = pycurl.CurlMulti()
        m.add_handle(self.curl)

        # Number of seconds to wait for a timeout to happen
        SELECT_TIMEOUT = 1.0

        # Stir the state machine into action
        while 1:
            ret, num_handles = m.perform()
            if ret != pycurl.E_CALL_MULTI_PERFORM:
                break

        # Keep going until all the connections have terminated
        while num_handles:
            # The select method uses fdset internally to determine which file descriptors
            # to check.
            m.select(SELECT_TIMEOUT)
            while 1:
                if _time.time() - start > 2:
                    # test is taking too long, fail
                    assert False, 'Test is taking too long'
                ret, num_handles = m.perform()
                if ret != pycurl.E_CALL_MULTI_PERFORM:
                    break
        
        # Cleanup
        m.remove_handle(self.curl)
        m.close()
        
        self.assertEqual('part1part2', sio.getvalue().decode())
        end = _time.time()
        # check that client side waited
        self.assertTrue(end-start > 1)
        
        assert state['resumed']

########NEW FILE########
__FILENAME__ = post_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import os.path
import pycurl
import unittest
try:
    import json
except ImportError:
    import simplejson as json
try:
    import urllib.parse as urllib_parse
except ImportError:
    import urllib as urllib_parse

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class PostTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_post_single_field(self):
        pf = {'field1': 'value1'}
        self.urlencode_and_check(pf)
    
    def test_post_multiple_fields(self):
        pf = {'field1':'value1', 'field2':'value2 with blanks', 'field3':'value3'}
        self.urlencode_and_check(pf)
    
    def test_post_fields_with_ampersand(self):
        pf = {'field1':'value1', 'field2':'value2 with blanks and & chars',
              'field3':'value3'}
        self.urlencode_and_check(pf)
    
    def urlencode_and_check(self, pf):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/postfields')
        postfields = urllib_parse.urlencode(pf)
        self.curl.setopt(pycurl.POSTFIELDS, postfields)
        
        # But directly passing urlencode result into setopt call:
        #self.curl.setopt(pycurl.POSTFIELDS, urllib_parse.urlencode(pf))
        # produces:
        # {'\x00\x00\x00\x00\x80\x00\x00\x00\x00\x00\x00\x00\x00': ''}
        # Traceback (most recent call last):
        #   File "/usr/local/bin/bottle.py", line 744, in _handle
        #     return route.call(**args)
        #   File "/usr/local/bin/bottle.py", line 1479, in wrapper
        #     rv = callback(*a, **ka)
        #   File "/home/pie/apps/pycurl/tests/app.py", line 21, in postfields
        #     return json.dumps(dict(bottle.request.forms))
        #   File "/usr/local/lib/python2.7/json/__init__.py", line 231, in dumps
        #     return _default_encoder.encode(obj)
        #   File "/usr/local/lib/python2.7/json/encoder.py", line 201, in encode
        #     chunks = self.iterencode(o, _one_shot=True)
        #   File "/usr/local/lib/python2.7/json/encoder.py", line 264, in iterencode
        #     return _iterencode(o, 0)
        # UnicodeDecodeError: 'utf8' codec can't decode byte 0x80 in position 4: invalid start byte
        
        #self.curl.setopt(pycurl.VERBOSE, 1)
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        self.assertEqual(200, self.curl.getinfo(pycurl.HTTP_CODE))
        body = sio.getvalue().decode()
        returned_fields = json.loads(body)
        self.assertEqual(pf, returned_fields)
    
    def test_post_with_null_byte(self):
        send = [
            ('field3', (pycurl.FORM_CONTENTS, 'this is wei\000rd, but null-bytes are okay'))
        ]
        expect = {
            'field3': 'this is wei\000rd, but null-bytes are okay',
        }
        self.check_post(send, expect, 'http://localhost:8380/postfields')
    
    def test_post_file(self):
        path = os.path.join(os.path.dirname(__file__), '..', 'README.rst')
        f = open(path)
        try:
            contents = f.read()
        finally:
            f.close()
        send = [
            #('field2', (pycurl.FORM_FILE, 'test_post.py', pycurl.FORM_FILE, 'test_post2.py')),
            ('field2', (pycurl.FORM_FILE, path)),
        ]
        expect = [{
            'name': 'field2',
            'filename': 'README.rst',
            'data': contents,
        }]
        self.check_post(send, expect, 'http://localhost:8380/files')
    
    def test_post_buffer(self):
        contents = 'hello, world!'
        send = [
            ('field2', (pycurl.FORM_BUFFER, 'uploaded.file', pycurl.FORM_BUFFERPTR, contents)),
        ]
        expect = [{
            'name': 'field2',
            'filename': 'uploaded.file',
            'data': contents,
        }]
        self.check_post(send, expect, 'http://localhost:8380/files')
    
    # XXX this test takes about a second to run, check keep-alives?
    def check_post(self, send, expect, endpoint):
        self.curl.setopt(pycurl.URL, endpoint)
        self.curl.setopt(pycurl.HTTPPOST, send)
        #self.curl.setopt(pycurl.VERBOSE, 1)
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        self.assertEqual(200, self.curl.getinfo(pycurl.HTTP_CODE))
        body = sio.getvalue().decode()
        returned_fields = json.loads(body)
        self.assertEqual(expect, returned_fields)

########NEW FILE########
__FILENAME__ = procmgr
import threading
import subprocess
import os
import sys
import signal
import nose.plugins.skip

from . import util

class ProcessManager(object):
    def __init__(self, cmd):
        self.cmd = cmd
        self.running = False
    
    def start(self):
        self.process = subprocess.Popen(self.cmd)
        self.running = True
        
        self.thread = threading.Thread(target=self.run)
        self.thread.daemon = True
        self.thread.start()
    
    def run(self):
        self.process.communicate()
    
    def stop(self):
        try:
            os.kill(self.process.pid, signal.SIGTERM)
        except OSError:
            pass
        self.running = False

managers = {}

def start(cmd):
    if str(cmd) in managers and managers[str(cmd)].running:
        # already started
        return
    
    manager = ProcessManager(cmd)
    managers[str(cmd)] = manager
    manager.start()

def start_setup(cmd):
    def do_start():
        start(cmd)
    return do_start

# Example on FreeBSD:
# PYCURL_VSFTPD_PATH=/usr/local/libexec/vsftpd nosetests

if 'PYCURL_VSFTPD_PATH' in os.environ:
    vsftpd_path = os.environ['PYCURL_VSFTPD_PATH']
else:
    vsftpd_path = None

try:
    # python 2
    exception_base = StandardError
except NameError:
    # python 3
    exception_base = Exception
class VsftpdNotConfigured(exception_base):
    pass

def vsftpd_setup():
    config_file_path = os.path.join(os.path.dirname(__file__), 'vsftpd.conf')
    root_path = os.path.join(os.path.dirname(__file__), '..')
    cmd = [
        vsftpd_path,
        config_file_path,
        '-oanon_root=%s' % root_path,
    ]
    setup_module = start_setup(cmd)
    def do_setup_module():
        if vsftpd_path is None:
            raise nose.plugins.skip.SkipTest('PYCURL_VSFTPD_PATH environment variable not set')
        try:
            setup_module()
        except OSError:
            import errno
            e = sys.exc_info()[1]
            if e.errno == errno.ENOENT:
                msg = "Tried to execute `%s`\nTry specifying path to vsftpd via PYCURL_VSFTPD_PATH environment variable\n" % vsftpd_path
                raise OSError(e.errno, e.strerror + "\n" + msg)
            else:
                raise
        ok = util.wait_for_network_service(('127.0.0.1', 8321), 0.1, 10)
        if not ok:
            import warnings
            warnings.warn('vsftpd did not start after 1 second')
    
    def teardown_module():
        try:
            manager = managers[str(cmd)]
        except KeyError:
            pass
        else:
            manager.stop()
    
    return do_setup_module, teardown_module

########NEW FILE########
__FILENAME__ = pycurl_object_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import sys

class PycurlObjectTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_set_attribute_curl(self):
        self.instantiate_and_check(self.check_set_attribute, 'Curl')
    
    def test_get_attribute_curl(self):
        self.instantiate_and_check(self.check_get_attribute, 'Curl')
    
    def test_get_missing_attribute_curl(self):
        self.instantiate_and_check(self.check_get_missing_attribute, 'Curl')
    
    def test_delete_attribute_curl(self):
        self.instantiate_and_check(self.check_delete_attribute, 'Curl')
    
    def test_delete_missing_attribute_curl(self):
        self.instantiate_and_check(self.check_delete_missing_attribute, 'Curl')
    
    def test_set_attribute_multi(self):
        self.instantiate_and_check(self.check_set_attribute, 'CurlMulti')
    
    def test_get_attribute_multi(self):
        self.instantiate_and_check(self.check_get_attribute, 'CurlMulti')
    
    def test_get_missing_attribute_curl(self):
        self.instantiate_and_check(self.check_get_missing_attribute, 'CurlMulti')
    
    def test_delete_attribute_multi(self):
        self.instantiate_and_check(self.check_delete_attribute, 'CurlMulti')
    
    def test_delete_missing_attribute_curl(self):
        self.instantiate_and_check(self.check_delete_missing_attribute, 'CurlMulti')
    
    def test_set_attribute_share(self):
        self.instantiate_and_check(self.check_set_attribute, 'CurlShare')
    
    def test_get_attribute_share(self):
        self.instantiate_and_check(self.check_get_attribute, 'CurlShare')
    
    def test_get_missing_attribute_curl(self):
        self.instantiate_and_check(self.check_get_missing_attribute, 'CurlShare')
    
    def test_delete_attribute_share(self):
        self.instantiate_and_check(self.check_delete_attribute, 'CurlShare')
    
    def test_delete_missing_attribute_curl(self):
        self.instantiate_and_check(self.check_delete_missing_attribute, 'CurlShare')
    
    def instantiate_and_check(self, fn, cls_name):
        cls = getattr(pycurl, cls_name)
        instance = cls()
        try:
            fn(instance)
        finally:
            instance.close()
    
    def check_set_attribute(self, pycurl_obj):
        assert not hasattr(pycurl_obj, 'attr')
        pycurl_obj.attr = 1
        assert hasattr(pycurl_obj, 'attr')
    
    def check_get_attribute(self, pycurl_obj):
        assert not hasattr(pycurl_obj, 'attr')
        pycurl_obj.attr = 1
        self.assertEqual(1, pycurl_obj.attr)
    
    def check_get_missing_attribute(self, pycurl_obj):
        try:
            getattr(pycurl_obj, 'doesnotexist')
            self.fail('Expected an AttributeError exception to be raised')
        except AttributeError:
            pass
    
    def check_delete_attribute(self, pycurl_obj):
        assert not hasattr(pycurl_obj, 'attr')
        pycurl_obj.attr = 1
        self.assertEqual(1, pycurl_obj.attr)
        assert hasattr(pycurl_obj, 'attr')
        del pycurl_obj.attr
        assert not hasattr(pycurl_obj, 'attr')
    
    def check_delete_missing_attribute(self, pycurl_obj):
        try:
            del pycurl_obj.doesnotexist
            self.fail('Expected an AttributeError exception to be raised')
        except AttributeError:
            pass
    
    def test_modify_attribute_curl(self):
        self.check_modify_attribute(pycurl.Curl, 'READFUNC_PAUSE')
    
    def test_modify_attribute_multi(self):
        self.check_modify_attribute(pycurl.CurlMulti, 'E_MULTI_OK')
    
    def test_modify_attribute_share(self):
        self.check_modify_attribute(pycurl.CurlShare, 'SH_SHARE')
    
    def check_modify_attribute(self, cls, name):
        obj1 = cls()
        obj2 = cls()
        old_value = getattr(obj1, name)
        self.assertNotEqual('helloworld', old_value)
        # value should be identical to pycurl global
        self.assertEqual(old_value, getattr(pycurl, name))
        setattr(obj1, name, 'helloworld')
        self.assertEqual('helloworld', getattr(obj1, name))
        
        # change does not affect other existing objects
        self.assertEqual(old_value, getattr(obj2, name))
        
        # change does not affect objects created later
        obj3 = cls()
        self.assertEqual(old_value, getattr(obj3, name))

########NEW FILE########
__FILENAME__ = read_callback_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import sys
try:
    import json
except ImportError:
    import simplejson as json
try:
    import urllib.parse as urllib_parse
except ImportError:
    import urllib as urllib_parse

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

POSTFIELDS = {
    'field1':'value1',
    'field2':'value2 with blanks',
    'field3':'value3',
}
POSTSTRING = urllib_parse.urlencode(POSTFIELDS)

class DataProvider(object):
    def __init__(self, data):
        self.data = data
        self.finished = False

    def read_cb(self, size):
        assert len(self.data) <= size
        if not self.finished:
            self.finished = True
            return self.data
        else:
            # Nothing more to read
            return ""

class ReadCallbackTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_post_with_read_callback(self):
        d = DataProvider(POSTSTRING)
        self.curl.setopt(self.curl.URL, 'http://localhost:8380/postfields')
        self.curl.setopt(self.curl.POST, 1)
        self.curl.setopt(self.curl.POSTFIELDSIZE, len(POSTSTRING))
        self.curl.setopt(self.curl.READFUNCTION, d.read_cb)
        #self.curl.setopt(self.curl.VERBOSE, 1)
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        
        actual = json.loads(sio.getvalue().decode())
        self.assertEqual(POSTFIELDS, actual)
    
    def test_post_with_read_callback_returning_bytes(self):
        self.check_bytes('world')
    
    def test_post_with_read_callback_returning_bytes_with_nulls(self):
        self.check_bytes("wor\0ld")
    
    def test_post_with_read_callback_returning_bytes_with_multibyte(self):
        self.check_bytes(util.u("Пушкин"))
    
    def check_bytes(self, poststring):
        data = poststring.encode('utf8')
        assert type(data) == util.binary_type
        d = DataProvider(data)
        
        self.curl.setopt(self.curl.URL, 'http://localhost:8380/raw_utf8')
        self.curl.setopt(self.curl.POST, 1)
        self.curl.setopt(self.curl.HTTPHEADER, ['Content-Type: application/octet-stream'])
        # length of bytes
        self.curl.setopt(self.curl.POSTFIELDSIZE, len(data))
        self.curl.setopt(self.curl.READFUNCTION, d.read_cb)
        #self.curl.setopt(self.curl.VERBOSE, 1)
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        
        # json should be ascii
        actual = json.loads(sio.getvalue().decode('ascii'))
        self.assertEqual(poststring, actual)
    
    def test_post_with_read_callback_returning_unicode(self):
        self.check_unicode(util.u('world'))
    
    def test_post_with_read_callback_returning_unicode_with_nulls(self):
        self.check_unicode(util.u("wor\0ld"))
    
    def test_post_with_read_callback_returning_unicode_with_multibyte(self):
        try:
            self.check_unicode(util.u("Пушкин"))
            # prints:
            # UnicodeEncodeError: 'ascii' codec can't encode characters in position 6-11: ordinal not in range(128)
        except pycurl.error:
            err, msg = sys.exc_info()[1].args
            # we expect pycurl.E_WRITE_ERROR as the response
            self.assertEqual(pycurl.E_ABORTED_BY_CALLBACK, err)
            self.assertEqual('operation aborted by callback', msg)
    
    def check_unicode(self, poststring):
        assert type(poststring) == util.text_type
        d = DataProvider(poststring)
        
        self.curl.setopt(self.curl.URL, 'http://localhost:8380/raw_utf8')
        self.curl.setopt(self.curl.POST, 1)
        self.curl.setopt(self.curl.HTTPHEADER, ['Content-Type: application/octet-stream'])
        self.curl.setopt(self.curl.POSTFIELDSIZE, len(poststring))
        self.curl.setopt(self.curl.READFUNCTION, d.read_cb)
        #self.curl.setopt(self.curl.VERBOSE, 1)
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        
        # json should be ascii
        actual = json.loads(sio.getvalue().decode('ascii'))
        self.assertEqual(poststring, actual)

########NEW FILE########
__FILENAME__ = relative_url_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

# uses the high level interface
import curl
import unittest

from . import appmanager

setup_module, teardown_module = appmanager.setup(('app', 8380))

class RelativeUrlTest(unittest.TestCase):
    def setUp(self):
        self.curl = curl.Curl('http://localhost:8380/')
    
    def tearDown(self):
        self.curl.close()
    
    def test_get_relative(self):
        self.curl.get('/success')
        self.assertEqual('success', self.curl.body().decode())

########NEW FILE########
__FILENAME__ = reload_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import nose.plugins.attrib
import sys

class ReloadTest(unittest.TestCase):
    @nose.plugins.attrib.attr('standalone')
    def test_reloading(self):
        try:
            # python 2
            reload_fn = reload
        except NameError:
            # python 3
            import imp
            reload_fn = imp.reload
        reload_fn(pycurl)

########NEW FILE########
__FILENAME__ = reset_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
try:
    import urllib.parse as urllib_parse
except ImportError:
    import urllib as urllib_parse

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class ResetTest(unittest.TestCase):
    # XXX this test was broken when it was test_reset.py
    def skip_reset(self):
        outf = util.BytesIO()
        cm = pycurl.CurlMulti()

        eh = pycurl.Curl()

        for x in range(1, 20):
            eh.setopt(pycurl.WRITEFUNCTION, outf.write)
            eh.setopt(pycurl.URL, 'http://localhost:8380/success')
            cm.add_handle(eh)

            while 1:
                ret, active_handles = cm.perform()
                if ret != pycurl.E_CALL_MULTI_PERFORM:
                    break

            while active_handles:
                ret = cm.select(1.0)
                if ret == -1:
                    continue
                while 1:
                    ret, active_handles = cm.perform()
                    if ret != pycurl.E_CALL_MULTI_PERFORM:
                        break

            count, good, bad = cm.info_read()

            for h, en, em in bad:
                print("Transfer to %s failed with %d, %s\n" % \
                    (h.getinfo(pycurl.EFFECTIVE_URL), en, em))
                raise RuntimeError

            for h in good:
                httpcode = h.getinfo(pycurl.RESPONSE_CODE)
                if httpcode != 200:
                    print("Transfer to %s failed with code %d\n" %\
                        (h.getinfo(pycurl.EFFECTIVE_URL), httpcode))
                    raise RuntimeError

                else:
                    print("Recd %d bytes from %s" % \
                        (h.getinfo(pycurl.SIZE_DOWNLOAD),
                        h.getinfo(pycurl.EFFECTIVE_URL)))

            cm.remove_handle(eh)
            eh.reset()

        eh.close()
        cm.close()
        outf.close()

########NEW FILE########
__FILENAME__ = resolve_test
# -*- coding: utf-8 -*-

import pycurl
import unittest
import nose.plugins.skip

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class ResolveTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_resolve(self):
        if util.pycurl_version_less_than(7, 21, 3) and not hasattr(pycurl, 'RESOLVE'):
            raise nose.plugins.skip.SkipTest('libcurl < 7.21.3 or no RESOLVE')
        
        self.curl.setopt(pycurl.URL, 'http://p.localhost:8380/success')
        self.curl.setopt(pycurl.RESOLVE, ['p.localhost:8380:127.0.0.1'])
        self.curl.perform()
        self.assertEqual(200, self.curl.getinfo(pycurl.RESPONSE_CODE))

########NEW FILE########
__FILENAME__ = runwsgi
# Run a WSGI application in a daemon thread

import sys
import bottle
import threading
import os.path

from . import util

global_stop = False

class Server(bottle.WSGIRefServer):
    def run(self, handler): # pragma: no cover
        from wsgiref.simple_server import make_server, WSGIRequestHandler
        if self.quiet:
            base = self.options.get('handler_class', WSGIRequestHandler)
            class QuietHandler(base):
                def log_request(*args, **kw):
                    pass
            self.options['handler_class'] = QuietHandler
        self.srv = make_server(self.host, self.port, handler, **self.options)
        if sys.version_info[0] == 2 and sys.version_info[1] < 6:
            # python 2.5 has no poll_interval
            # and thus no way to stop the server
            while not global_stop:
                self.srv.handle_request()
        else:
            self.srv.serve_forever(poll_interval=0.1)

class SslServer(bottle.CherryPyServer):
    def run(self, handler):
        import cherrypy.wsgiserver, cherrypy.wsgiserver.ssl_builtin
        server = cherrypy.wsgiserver.CherryPyWSGIServer((self.host, self.port), handler)
        cert_dir = os.path.join(os.path.dirname(__file__), 'certs')
        ssl_adapter = cherrypy.wsgiserver.ssl_builtin.BuiltinSSLAdapter(
            os.path.join(cert_dir, 'server.crt'),
            os.path.join(cert_dir, 'server.key'),
        )
        server.ssl_adapter = ssl_adapter
        try:
            server.start()
        finally:
            server.stop()

def start_bottle_server(app, port, server, **kwargs):
    server_thread = ServerThread(app, port, server, kwargs)
    server_thread.daemon = True
    server_thread.start()
    
    ok = util.wait_for_network_service(('127.0.0.1', port), 0.1, 10)
    if not ok:
        import warnings
        warnings.warn('Server did not start after 1 second')
    
    return server_thread.server

class ServerThread(threading.Thread):
    def __init__(self, app, port, server, server_kwargs):
        threading.Thread.__init__(self)
        self.app = app
        self.port = port
        self.server_kwargs = server_kwargs
        self.server = server(host='127.0.0.1', port=self.port, **self.server_kwargs)
    
    def run(self):
        bottle.run(self.app, server=self.server, quiet=True)

started_servers = {}

def app_runner_setup(*specs):
    '''Returns setup and teardown methods for running a list of WSGI
    applications in a daemon thread.
    
    Each argument is an (app, port) pair.
    
    Return value is a (setup, teardown) function pair.
    
    The setup and teardown functions expect to be called with an argument
    on which server state will be stored.
    
    Example usage with nose:
    
    >>> setup_module, teardown_module = \
        runwsgi.app_runner_setup((app_module.app, 8050))
    '''
    
    def setup(self):
        self.servers = []
        for spec in specs:
            if len(spec) == 2:
                app, port = spec
                kwargs = {}
            else:
                app, port, kwargs = spec
            if port in started_servers:
                assert started_servers[port] == (app, kwargs)
            else:
                server = Server
                if 'server' in kwargs:
                    server = kwargs['server']
                    del kwargs['server']
                elif 'ssl' in kwargs:
                    if kwargs['ssl']:
                        server = SslServer
                    del kwargs['ssl']
                self.servers.append(start_bottle_server(app, port, server, **kwargs))
            started_servers[port] = (app, kwargs)
    
    def teardown(self):
        return
        for server in self.servers:
            # if no tests from module were run, there is no server to shut down
            if hasattr(server, 'srv'):
                if hasattr(server.srv, 'shutdown'):
                    server.srv.shutdown()
                else:
                    # python 2.5
                    global global_stop
                    global_stop = True
    
    return [setup, teardown]

########NEW FILE########
__FILENAME__ = seek_function_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

# Note: this test is meant to be run from pycurl project root.

import pycurl
import unittest
import os.path

from . import procmgr

setup_module, teardown_module = procmgr.vsftpd_setup()

class PartialFileSource:
    def __init__(self):
        self.__buf = '1234567890.1234567890'
        self.__maxread = None
        self.__bufptr = 0

    def read(self, size):
        p = self.__bufptr
        end = p+size
        if self.__maxread:
            end = min(self.__maxread, end)
        ret = self.__buf[p:end]
        self.__bufptr+= len(ret)
        #print 20*">>>", "read(%s)   ==> %s" % (size, len(ret))
        return ret
      
    def seek(self, offset, origin):
        #print 20*">>>",  "seek(%s, %s)" %  (offset, origin)
        self.__bufptr = offset

    def set_maxread(self, maxread):
        self.__maxread = maxread

class SeekFunctionTest(unittest.TestCase):
    def test_seek_function(self):
        c = pycurl.Curl()
        c.setopt(pycurl.UPLOAD, 1)
        c.setopt(pycurl.URL, "ftp://localhost:8321/tests/tmp/upload.txt")
        c.setopt(pycurl.RESUME_FROM, 0)
        #c.setopt(pycurl.VERBOSE, 1)
        upload_file = PartialFileSource()
        c.setopt(pycurl.READFUNCTION, upload_file.read)
        upload_file.set_maxread(10)
        c.perform()
        
        f = open(os.path.join(os.path.dirname(__file__), 'tmp', 'upload.txt'))
        try:
            content = f.read()
        finally:
            f.close()
        self.assertEqual('1234567890', content)

        c.close()
        del c
        del upload_file

        c = pycurl.Curl()
        c.setopt(pycurl.URL, "ftp://localhost:8321/tests/tmp/upload.txt")
        c.setopt(pycurl.RESUME_FROM, -1)
        c.setopt(pycurl.UPLOAD, 1)
        #c.setopt(pycurl.VERBOSE, 1)
        upload_file = PartialFileSource()
        c.setopt(pycurl.READFUNCTION, upload_file.read)
        c.setopt(pycurl.SEEKFUNCTION, upload_file.seek)
        c.perform()
        c.close()
        
        f = open(os.path.join(os.path.dirname(__file__), 'tmp', 'upload.txt'))
        try:
            content = f.read()
        finally:
            f.close()
        self.assertEqual('1234567890.1234567890', content)

########NEW FILE########
__FILENAME__ = setopt_lifecycle_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import gc
import os.path
import pycurl
import unittest
try:
    import json
except ImportError:
    import simplejson as json

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class TestString(str):
    def __del__(self):
        self.replace('1', '2')
        #print self
        #print 'd'

class SetoptLifecycleTest(unittest.TestCase):
    # separate method to permit pf to go out of scope and be
    # garbage collected before perform call
    def do_setopt(self, curl, index):
        pf = TestString('&'.join(50*['field=value%d' % (index,)]))
        curl.setopt(pycurl.URL, 'http://localhost:8380/postfields')
        curl.setopt(pycurl.POSTFIELDS, pf)
    
    # This test takes 6+ seconds to run.
    # It seems to pass with broken pycurl code when run by itself,
    # but fails when run as part of the entire test suite.
    def test_postfields_lifecycle(self):
        requests = []
        for i in range(1000):
            curl = pycurl.Curl()
            self.do_setopt(curl, i)
            gc.collect()
            requests.append(curl)
        
        # send requests here to permit maximum garbage recycling
        for i in range(100):
            curl = requests[i]
            #self.curl.setopt(pycurl.VERBOSE, 1)
            sio = util.BytesIO()
            curl.setopt(pycurl.WRITEFUNCTION, sio.write)
            curl.perform()
            self.assertEqual(200, curl.getinfo(pycurl.HTTP_CODE))
            body = sio.getvalue().decode()
            returned_fields = json.loads(body)
            self.assertEqual(dict(field='value%d' % i), returned_fields)
        
        for i in range(100):
            curl = requests[i]
            curl.close()

########NEW FILE########
__FILENAME__ = setopt_unicode_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import nose.tools
try:
    import json
except ImportError:
    import simplejson as json

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class SetoptUnicodeTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_ascii_string(self):
        self.check('p=test', 'test')
    
    @nose.tools.raises(UnicodeEncodeError)
    def test_unicode_string(self):
        self.check(util.u('p=Москва'), util.u('Москва'))
    
    def test_unicode_encoded(self):
        self.check(util.u('p=Москва').encode('utf8'), util.u('Москва'))
    
    def check(self, send, expected):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/param_utf8_hack')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.setopt(pycurl.POSTFIELDS, send)
        self.curl.perform()
        self.assertEqual(expected, sio.getvalue().decode('utf-8'))

########NEW FILE########
__FILENAME__ = share_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import threading
import pycurl
import unittest
try:
    import urllib.parse as urllib_parse
except ImportError:
    import urllib as urllib_parse

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class WorkerThread(threading.Thread):

    def __init__(self, share):
        threading.Thread.__init__(self)
        self.curl = pycurl.Curl()
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        self.curl.setopt(pycurl.SHARE, share)
        self.sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, self.sio.write)

    def run(self):
        self.curl.perform()
        self.curl.close()

class ShareTest(unittest.TestCase):
    def test_share(self):
        s = pycurl.CurlShare()
        s.setopt(pycurl.SH_SHARE, pycurl.LOCK_DATA_COOKIE)
        s.setopt(pycurl.SH_SHARE, pycurl.LOCK_DATA_DNS)
        s.setopt(pycurl.SH_SHARE, pycurl.LOCK_DATA_SSL_SESSION)

        t1 = WorkerThread(s)
        t2 = WorkerThread(s)

        t1.start()
        t2.start()
        
        t1.join()
        t2.join()
        
        del s
        
        self.assertEqual('success', t1.sio.getvalue().decode())
        self.assertEqual('success', t2.sio.getvalue().decode())
    
    def test_share_close(self):
        s = pycurl.CurlShare()
        s.close()
    
    def test_share_close_twice(self):
        s = pycurl.CurlShare()
        s.close()
        s.close()

########NEW FILE########
__FILENAME__ = socket_open_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import socket
import pycurl
import unittest
try:
    import urllib.parse as urllib_parse
except ImportError:
    import urllib as urllib_parse

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

socket_open_called = False
socket_open_address = None

def socket_open(family, socktype, protocol, address):
    global socket_open_called
    global socket_open_address
    socket_open_called = True
    socket_open_address = address
    
    #print(family, socktype, protocol, address)
    s = socket.socket(family, socktype, protocol)
    s.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
    return s

class SocketOpenTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_socket_open(self):
        self.curl.setopt(pycurl.OPENSOCKETFUNCTION, socket_open)
        self.curl.setopt(self.curl.URL, 'http://localhost:8380/success')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        
        assert socket_open_called
        self.assertEqual(("127.0.0.1", 8380), socket_open_address)
        self.assertEqual('success', sio.getvalue().decode())

########NEW FILE########
__FILENAME__ = unset_range_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import os.path
import pycurl
import sys
import unittest

class UnsetRangeTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()

    def tearDown(self):
        self.curl.close()

    def test_unset_range(self):
        def write_cb(data):
            self.read += len(data)
            return None

        # download bytes 0-9 of the script itself through the file:// protocol
        self.read = 0
        self.curl.setopt(pycurl.URL, 'file://' + os.path.abspath(sys.argv[0]))
        self.curl.setopt(pycurl.WRITEFUNCTION, write_cb)
        self.curl.setopt(pycurl.RANGE, '0-9')
        self.curl.perform()
        assert 10 == self.read

        # the RANGE setting should be preserved from the previous transfer
        self.read = 0
        self.curl.perform()
        assert 10 == self.read

        # drop the RANGE setting using unsetopt() and download entire script
        self.read = 0
        self.curl.unsetopt(pycurl.RANGE)
        self.curl.perform()
        assert 10 < self.read

        # now set the RANGE again and check that pycurl takes it into account
        self.read = 0
        self.curl.setopt(pycurl.RANGE, '0-9')
        self.curl.perform()
        assert 10 == self.read

        # now drop the RANGE setting using setopt(..., None)
        self.read = 0
        self.curl.setopt(pycurl.RANGE, None)
        self.curl.perform()
        assert 10 < self.read

########NEW FILE########
__FILENAME__ = user_agent_string_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import unittest
import pycurl

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class UserAgentStringTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_pycurl_user_agent_string(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/header?h=user-agent')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        user_agent = sio.getvalue().decode()
        assert user_agent.startswith('PycURL/')
        assert 'libcurl/' in user_agent, 'User agent did not include libcurl/: %s' % user_agent

########NEW FILE########
__FILENAME__ = util
# -*- coding: utf-8 -*-
# vi:ts=4:et

import os, sys, socket
import time as _time
try:
    import functools
except ImportError:
    import functools_backport as functools

py3 = sys.version_info[0] == 3

# python 2/3 compatibility
if py3:
    from io import StringIO, BytesIO
    
    # borrowed from six
    def b(s):
        '''Byte literal'''
        return s.encode("latin-1")
    def u(s):
        '''Text literal'''
        return s
    text_type = str
    binary_type = bytes
else:
    try:
        from cStringIO import StringIO
    except ImportError:
        from StringIO import StringIO
    BytesIO = StringIO
    
    # borrowed from six
    def b(s):
        '''Byte literal'''
        return s
    # Workaround for standalone backslash
    def u(s):
        '''Text literal'''
        return unicode(s.replace(r'\\', r'\\\\'), "unicode_escape")
    text_type = unicode
    binary_type = str

def version_less_than_spec(version_tuple, spec_tuple):
    # spec_tuple may have 2 elements, expect version_tuple to have 3 elements
    assert len(version_tuple) >= len(spec_tuple)
    for i in range(len(spec_tuple)):
        if version_tuple[i] < spec_tuple[i]:
            return True
        if version_tuple[i] > spec_tuple[i]:
            return False
    return False

def pycurl_version_less_than(*spec):
    import pycurl
    
    version = [int(part) for part in pycurl.version_info()[1].split('.')]
    return version_less_than_spec(version, spec)

def only_python3(fn):
    import nose.plugins.skip
    
    @functools.wraps(fn)
    def decorated(*args, **kwargs):
        if sys.version_info[0] < 3:
            raise nose.plugins.skip.SkipTest('python < 3')
        
        return fn(*args, **kwargs)
    
    return decorated

def min_libcurl(major, minor, patch):
    import nose.plugins.skip
    
    def decorator(fn):
        @functools.wraps(fn)
        def decorated(*args, **kwargs):
            if pycurl_version_less_than(major, minor, patch):
                raise nose.plugins.skip.SkipTest('libcurl < %d.%d.%d' % (major, minor, patch))
            
            return fn(*args, **kwargs)
        
        return decorated
    
    return decorator

def only_ssl(fn):
    import nose.plugins.skip
    import pycurl
    
    @functools.wraps(fn)
    def decorated(*args, **kwargs):
        # easier to check that pycurl supports https, although
        # theoretically it is not the same test.
        # pycurl.version_info()[8] is a tuple of protocols supported by libcurl
        if 'https' not in pycurl.version_info()[8]:
            raise nose.plugins.skip.SkipTest('libcurl does not support ssl')
        
        return fn(*args, **kwargs)
    
    return decorated

try:
    create_connection = socket.create_connection
except AttributeError:
    # python 2.5
    def create_connection(netloc, timeout=None):
        # XXX ipv4 only
        s = socket.socket()
        if timeout is not None:
            s.settimeout(timeout)
        s.connect(netloc)
        return s

def wait_for_network_service(netloc, check_interval, num_attempts):
    ok = False
    for i in range(num_attempts):
        try:
            conn = create_connection(netloc, check_interval)
        except socket.error:
            #e = sys.exc_info()[1]
            _time.sleep(check_interval)
        else:
            conn.close()
            ok = True
            break
    return ok

#
# prepare sys.path in case we are still in the build directory
# see also: distutils/command/build.py (build_platlib)
#

def get_sys_path(p=None):
    if p is None:
        p = sys.path
    p = p[:]
    try:
        from distutils.util import get_platform
    except ImportError:
        return p
    p0 = ""
    if p:
        p0 = p[0]
    #
    plat = get_platform()
    plat_specifier = "%s-%s" % (plat, sys.version[:3])
    ##print plat, plat_specifier
    #
    for prefix in (p0, os.curdir, os.pardir,):
        if not prefix:
            continue
        d = os.path.join(prefix, "build")
        for subdir in ("lib", "lib." + plat_specifier, "lib." + plat):
            dir = os.path.normpath(os.path.join(d, subdir))
            if os.path.isdir(dir):
                if dir not in p:
                    p.insert(1, dir)
    #
    return p



########NEW FILE########
__FILENAME__ = version_comparison_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import unittest

from . import util

class VersionComparisonTest(unittest.TestCase):
    def test_comparison(self):
        assert util.version_less_than_spec((7, 22, 0), (7, 23, 0))
        assert util.version_less_than_spec((7, 22, 0), (7, 23))
        assert util.version_less_than_spec((7, 22, 0), (7, 22, 1))
        assert not util.version_less_than_spec((7, 22, 0), (7, 22, 0))
        assert not util.version_less_than_spec((7, 22, 0), (7, 22))

########NEW FILE########
__FILENAME__ = version_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import unittest
import pycurl

class VersionTest(unittest.TestCase):
    def test_pycurl_presence_and_case(self):
        assert pycurl.version.startswith('PycURL/')
    
    def test_libcurl_presence(self):
        assert 'libcurl/' in pycurl.version

########NEW FILE########
__FILENAME__ = opensocketcrash
import pycurl
from io import BytesIO
import socket

def socket_open(family, socktype, protocol, address):
    global socket_open_called
    global socket_open_address
    socket_open_called = True
    socket_open_address = address
    
    #print(family, socktype, protocol, address)
    s = socket.socket(family, socktype, protocol)
    s.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
    print(2)
    return s 

curl = pycurl.Curl() 
curl.setopt(pycurl.OPENSOCKETFUNCTION, socket_open)
curl.setopt(curl.URL, 'http://localhost:8380/success')
sio = BytesIO()
curl.setopt(pycurl.WRITEFUNCTION, sio.write)
print(1)
curl.perform()
print(1)

assert socket_open_called
assertEqual(("127.0.0.1", 8380), socket_open_address)
assertEqual('success', sio.getvalue().decode()) 

print(1)

########NEW FILE########
__FILENAME__ = write_abort_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import os.path
import pycurl
import sys
import unittest

class WriteAbortTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()

    def tearDown(self):
        self.curl.close()

    def test_write_abort(self):
        def write_cb(_):
            # this should cause pycurl.WRITEFUNCTION (without any range errors)
            return -1

        try:
            # set when running full test suite if any earlier tests
            # failed in Python code called from C
            del sys.last_value
        except AttributeError:
            pass

        # download the script itself through the file:// protocol into write_cb
        self.curl.setopt(pycurl.URL, 'file://' + os.path.abspath(sys.argv[0]))
        self.curl.setopt(pycurl.WRITEFUNCTION, write_cb)
        try:
            self.curl.perform()
        except pycurl.error:
            err, msg = sys.exc_info()[1].args
            # we expect pycurl.E_WRITE_ERROR as the response
            assert pycurl.E_WRITE_ERROR == err

        # no additional errors should be reported
        assert not hasattr(sys, 'last_value')

########NEW FILE########
__FILENAME__ = write_cb_bogus_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import os.path
import pycurl
import sys
import unittest

class WriteAbortTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()

    def tearDown(self):
        self.curl.close()

    def write_cb_returning_string(self, data):
        return 'foo'

    def write_cb_returning_float(self, data):
        return 0.5

    def test_write_cb_returning_string(self):
        self.check(self.write_cb_returning_string)
    
    def test_write_cb_returning_float(self):
        self.check(self.write_cb_returning_float)
    
    def check(self, write_cb):
        # download the script itself through the file:// protocol into write_cb
        c = pycurl.Curl()
        self.curl.setopt(pycurl.URL, 'file://' + os.path.abspath(sys.argv[0]))
        self.curl.setopt(pycurl.WRITEFUNCTION, write_cb)
        try:
            self.curl.perform()
            
            self.fail('Should not get here')
        except pycurl.error:
            err, msg = sys.exc_info()[1].args
            # we expect pycurl.E_WRITE_ERROR as the response
            assert pycurl.E_WRITE_ERROR == err

        # actual error
        assert hasattr(sys, 'last_type')
        self.assertEqual(pycurl.error, sys.last_type)
        assert hasattr(sys, 'last_value')
        self.assertEqual('write callback must return int or None', str(sys.last_value))

########NEW FILE########
__FILENAME__ = write_to_file_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import unittest
import pycurl
import tempfile
import shutil
import os.path

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class Acceptor(object):
    def __init__(self):
        self.buffer = ''
    
    def write(self, chunk):
        self.buffer += chunk.decode()

class WriteToFileTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_write_to_tempfile_via_function(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        f = tempfile.NamedTemporaryFile()
        try:
            self.curl.setopt(pycurl.WRITEFUNCTION, f.write)
            self.curl.perform()
            f.seek(0)
            body = f.read()
        finally:
            f.close()
        self.assertEqual('success', body.decode())
    
    @util.only_python3
    def test_write_to_tempfile_via_object(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        f = tempfile.NamedTemporaryFile()
        try:
            self.curl.setopt(pycurl.WRITEDATA, f)
            self.curl.perform()
            f.seek(0)
            body = f.read()
        finally:
            f.close()
        self.assertEqual('success', body.decode())
    
    def test_write_to_file_via_function(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        dir = tempfile.mkdtemp()
        try:
            path = os.path.join(dir, 'pycurltest')
            f = open(path, 'wb+')
            try:
                self.curl.setopt(pycurl.WRITEFUNCTION, f.write)
                self.curl.perform()
                f.seek(0)
                body = f.read()
            finally:
                f.close()
        finally:
            shutil.rmtree(dir)
        self.assertEqual('success', body.decode())
    
    def test_write_to_file_via_object(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        dir = tempfile.mkdtemp()
        try:
            path = os.path.join(dir, 'pycurltest')
            f = open(path, 'wb+')
            try:
                self.curl.setopt(pycurl.WRITEDATA, f)
                self.curl.perform()
                f.seek(0)
                body = f.read()
            finally:
                f.close()
        finally:
            shutil.rmtree(dir)
        self.assertEqual('success', body.decode())
    
    def test_write_to_file_like(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        acceptor = Acceptor()
        self.curl.setopt(pycurl.WRITEDATA, acceptor)
        self.curl.perform()
        self.assertEqual('success', acceptor.buffer)

########NEW FILE########
__FILENAME__ = write_to_stringio_test
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# vi:ts=4:et

import pycurl
import unittest
import sys

from . import appmanager
from . import util

setup_module, teardown_module = appmanager.setup(('app', 8380))

class WriteToStringioTest(unittest.TestCase):
    def setUp(self):
        self.curl = pycurl.Curl()
    
    def tearDown(self):
        self.curl.close()
    
    def test_write_to_bytesio(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        sio = util.BytesIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        self.curl.perform()
        self.assertEqual('success', sio.getvalue().decode())
    
    @util.only_python3
    def test_write_to_stringio(self):
        self.curl.setopt(pycurl.URL, 'http://localhost:8380/success')
        # stringio in python 3
        sio = util.StringIO()
        self.curl.setopt(pycurl.WRITEFUNCTION, sio.write)
        try:
            self.curl.perform()
            
            self.fail('Should have received a write error')
        except pycurl.error:
            err, msg = sys.exc_info()[1].args
            # we expect pycurl.E_WRITE_ERROR as the response
            assert pycurl.E_WRITE_ERROR == err

########NEW FILE########
__FILENAME__ = winbuild
# Bootstrap python binary:
# http://www.python.org/ftp/python/3.3.4/python-3.3.4.msi
# http://www.python.org/ftp/python/3.3.4/python-3.3.4.amd64.msi
# msvc9/vs2008 express:
# http://go.microsoft.com/?linkid=7729279
# msvc10/vs2010 express:
# http://go.microsoft.com/?linkid=9709949

# work directory for downloading dependencies and building everything
root = 'c:/dev/build-pycurl'
# where msysgit is installed
git_root = 'c:/program files/git'
# which versions of python to build against
python_versions = ['2.6.6', '2.7.6', '3.2.5', '3.3.4']
# where pythons are installed
python_path_template = 'c:/python%s/python'
vc_paths = {
    # where msvc 9 is installed, for python 2.6 through 3.2
    'vc9': 'c:/program files/microsoft visual studio 9.0',
    # where msvc 10 is installed, for python 3.3
    'vc10': 'c:/program files/microsoft visual studio 10.0',
}
# whether to link libcurl against zlib
use_zlib = False
# which version of zlib to use, will be downloaded from internet
zlib_version = '1.2.8'
# which version of libcurl to use, will be downloaded from the internet
libcurl_version = '7.35.0'
# pycurl version to build, we should know this ourselves
pycurl_version = '7.19.3.1'

import os, os.path, sys, subprocess, shutil, contextlib

archives_path = os.path.join(root, 'archives')
state_path = os.path.join(root, 'state')
git_bin_path = os.path.join(git_root, 'bin')
git_path = os.path.join(git_bin_path, 'git')
rm_path = os.path.join(git_bin_path, 'rm')
tar_path = os.path.join(git_bin_path, 'tar')
for key in vc_paths:
    vc_paths[key] = {
        'root': vc_paths[key],
        'vsvars': os.path.join(vc_paths[key], 'common7/tools/vsvars32.bat'),
    }
python_vc_versions = {
    '2.6': 'vc9',
    '2.7': 'vc9',
    '3.2': 'vc9',
    '3.3': 'vc10',
}
vc_versions = vc_paths.keys()

try:
    from urllib.request import urlopen
except ImportError:
    from urllib import urlopen

def fetch(url, archive=None):
    if archive is None:
        archive = os.path.basename(url)
    if not os.path.exists(archive):
        sys.stdout.write("Fetching %s\n" % url)
        io = urlopen(url)
        with open('.tmp.%s' % archive, 'wb') as f:
            while True:
                chunk = io.read(65536)
                if len(chunk) == 0:
                    break
                f.write(chunk)
        os.rename('.tmp.%s' % archive, archive)

@contextlib.contextmanager
def in_dir(dir):
    old_cwd = os.getcwd()
    try:
        os.chdir(dir)
        yield
    finally:
        os.chdir(old_cwd)

@contextlib.contextmanager
def step(step_fn, *args):
    step = step_fn.__name__
    if args:
        step +=  '-' + '-'.join(args)
    if not os.path.exists(state_path):
        os.makedirs(state_path)
    state_file_path = os.path.join(state_path, step)
    if not os.path.exists(state_file_path):
        step_fn(*args)
    with open(state_file_path, 'w') as f:
        pass

def untar(basename):
    if os.path.exists(basename):
        shutil.rmtree(basename)
    subprocess.check_call([tar_path, 'xf', '%s.tar.gz' % basename])

def rename_for_vc(basename, vc_version):
    suffixed_dir = '%s-%s' % (basename, vc_version)
    if os.path.exists(suffixed_dir):
        shutil.rmtree(suffixed_dir)
    os.rename(basename, suffixed_dir)
    return suffixed_dir

def build():
    os.environ['PATH'] += ";%s" % git_bin_path
    if not os.path.exists(archives_path):
        os.makedirs(archives_path)
    with in_dir(archives_path):
        def build_zlib(vc_version):
            fetch('http://downloads.sourceforge.net/project/libpng/zlib/%s/zlib-%s.tar.gz' % (zlib_version, zlib_version))
            untar('zlib-%s' % zlib_version)
            zlib_dir = rename_for_vc('zlib-%s' % zlib_version, vc_version)
            with in_dir(zlib_dir):
                with open('doit.bat', 'w') as f:
                    f.write("call \"%s\"\n" % vc_paths[vc_version]['vsvars'])
                    f.write("nmake /f win32/Makefile.msc\n")
                subprocess.check_call(['doit.bat'])
        
        def build_curl(vc_version):
            fetch('http://curl.haxx.se/download/curl-%s.tar.gz' % libcurl_version)
            untar('curl-%s' % libcurl_version)
            curl_dir = rename_for_vc('curl-%s' % libcurl_version, vc_version)
            with in_dir(os.path.join(curl_dir, 'winbuild')):
                with open('doit.bat', 'w') as f:
                    f.write("call \"%s\"\n" % vc_paths[vc_version]['vsvars'])
                    f.write("set include=%%include%%;%s\n" % os.path.join(archives_path, 'zlib-%s-%s' % (zlib_version, vc_version)))
                    f.write("set lib=%%lib%%;%s\n" % os.path.join(archives_path, 'zlib-%s-%s' % (zlib_version, vc_version)))
                    if use_zlib:
                        extra_options = ' WITH_ZLIB=dll'
                    else:
                        extra_options = ''
                    f.write("nmake /f Makefile.vc mode=dll ENABLE_IDN=no\n")
                subprocess.check_call(['doit.bat'])
        for vc_version in vc_versions:
            if use_zlib:
                step(build_zlib, vc_version)
            step(build_curl, vc_version)
        
        def prepare_pycurl():
            #fetch('http://pycurl.sourceforge.net/download/pycurl-%s.tar.gz' % pycurl_version)
            if os.path.exists('pycurl-%s' % pycurl_version):
                #shutil.rmtree('pycurl-%s' % pycurl_version)
                subprocess.check_call([rm_path, '-rf', 'pycurl-%s' % pycurl_version])
            #subprocess.check_call([tar_path, 'xf', 'pycurl-%s.tar.gz' % pycurl_version])
            shutil.copytree('c:/dev/pycurl', 'pycurl-%s' % pycurl_version)
        
        def build_pycurl(python_version, target):
            python_path = python_path_template % python_version.replace('.', '')
            vc_version = python_vc_versions[python_version]
            
            with in_dir(os.path.join('pycurl-%s' % pycurl_version)):
                if use_zlib:
                    libcurl_build_name = 'libcurl-vc-x86-release-dll-zlib-dll-ipv6-sspi-spnego-winssl'
                else:
                    libcurl_build_name = 'libcurl-vc-x86-release-dll-ipv6-sspi-spnego-winssl'
                curl_dir = '../curl-%s-%s/builds/%s' % (libcurl_version, vc_version, libcurl_build_name)
                if not os.path.exists('build/lib.win32-%s' % python_version):
                    # exists for building additional targets for the same python version
                    os.makedirs('build/lib.win32-%s' % python_version)
                shutil.copy(os.path.join(curl_dir, 'bin', 'libcurl.dll'), 'build/lib.win32-%s' % python_version)
                with open('doit.bat', 'w') as f:
                    f.write("call \"%s\"\n" % vc_paths[vc_version]['vsvars'])
                    f.write("%s setup.py %s --curl-dir=%s --use-libcurl-dll\n" % (python_path, target, curl_dir))
                subprocess.check_call(['doit.bat'])
                if target == 'bdist':
                    os.rename('dist/pycurl-%s.win32.zip' % pycurl_version, 'dist/pycurl-%s.win32-py%s.zip' % (pycurl_version, python_version))
        
        prepare_pycurl()
        python_releases = ['.'.join(version.split('.')[:2]) for version in python_versions]
        for python_version in python_versions:
            for target in ['bdist', 'bdist_wininst', 'bdist_msi']:
                build_pycurl(python_version, target)

def download_pythons():
    try:
        from urllib.request import urlopen
    except NameError:
        from urllib import urlopen
    
    for version in python_versions:
        if os.path.exists(os.path.join(archives_path, 'python-%s.msi')):
            continue
        print('Downloading %s' % version)
        url = 'http://python.org/ftp/python/%s/python-%s.msi' % (version, version)
        io = urlopen(url)
        data = io.read()
        with open(os.path.join(archives_path, 'python-%s.msi' % version), 'wb') as f:
            f.write(data)

if len(sys.argv) > 1 and sys.argv[1] == 'download':
    download_pythons()
else:
    build()

########NEW FILE########
