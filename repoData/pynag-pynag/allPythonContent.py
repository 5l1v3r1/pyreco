__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# pynag documentation build configuration file, created by
# sphinx-quickstart on Sun Mar 16 17:21:51 2014.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.


import sys, os

sys.path.insert(0,os.path.abspath('.'))
sys.path.insert(0,os.path.abspath('..'))
# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))
from pynag import __version__

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.doctest', 'sphinx.ext.coverage']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'pynag'
copyright = u'2014, Pall Sigurdsson and Tomas Edwardsson'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = __version__
# The full version, including alpha/beta/rc tags.
release = __version__

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'pynagdoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'pynag.tex', u'pynag Documentation',
   u'Pall Sigurdsson and Tomas Edwardsson', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('pynag-command', 'pynag', u'command line front for manipulating nagios configuration',
     [u'Pall Sigurdsson and Tomas Edwardsson'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'pynag', u'pynag Documentation',
   u'Pall Sigurdsson and Tomas Edwardsson', 'pynag', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = edit_service
#!/usr/bin/python
#
# Example script on how to modify a single Nagios service

from pynag import Model
import sys

# Parse commandline arguments
if len(sys.argv) != 5:
    print '''
Usage:
  %s <host_name> <service_description> <field_name> <new_value>

Example:
  %s localhost Ping check_command 'check_ping'
''' % (sys.argv[0], sys.argv[0])
    sys.exit(1)

host_name = sys.argv[1]
service_description = sys.argv[2]
field_name = sys.argv[3]
new_value = sys.argv[4]


# Get a list of all services that fit our search pattern
search_results = Model.Service.objects.filter(host_name=host_name, service_description=service_description)

if len(search_results) == 0:
    print "no service found for host_name=%s and service_description=%s" % ( host_name, service_description )

my_service = search_results[0]
my_service.set_attribute(field_name,new_value)
my_service.save()



########NEW FILE########
__FILENAME__ = list_all_hostgroups
#!/usr/bin/python

import sys
sys.path.insert(1, '/opt/pynag')
from pynag import Model


# If your nagios config is in an unusal place, uncomment this:
# Model.cfg_file = '/etc/nagios/nagios.cfg'

hostgroups = Model.Hostgroup.objects.all

for hostgroup in hostgroups:
    print hostgroup['hostgroup_name']


########NEW FILE########
__FILENAME__ = list_all_services
#!/usr/bin/python

import sys
sys.path.insert(1, '/opt/pynag')
from pynag import Model


# If your nagios config is in an unusal place, uncomment this:
# Model.cfg_file = '/etc/nagios/nagios.cfg'

services = Model.Service.objects.all

print "%-30s  %-30s" % ("Hostname", "Service_description")
for service in services:
    print "%-30s  %-30s" % ( service['host_name'], service['service_description'] )

########NEW FILE########
__FILENAME__ = list_services_for_one_host
#!/usr/bin/python

import sys
sys.path.insert(1, '/opt/pynag')
from pynag import Model


# If your nagios config is in an unusal place, uncomment this:
# Model.cfg_file = '/etc/nagios/nagios.cfg'


# Lets find all services that belong to the host "localhost"
host_name = "localhost"

services = Model.Service.objects.filter(host_name='localhost')

print "%-30s  %-30s" % ("Hostname", "Service_description")
for service in services:
    print "%-30s  %-30s" % ( service['host_name'], service['service_description'] )

########NEW FILE########
__FILENAME__ = parse-configmain
#!/usr/bin/python

# This script parses the configmain.html file from the Nagios project and tries
# to extract information regarding options.

import re
from pprint import pprint

f = open('configmain.html')

k = None
p = False
doc = ""
format = ""
examples = []
options = []
title = ""
info = {}

for l in f.readlines():
    # no newline
    l = l[:-1]

    # Empty line
    if not len(l):
        continue

    # no config key and we are not at the start of a config key section
    if k is None and l.startswith('<a name=') is False:
        continue
    # Find the start of a key section
    m = re.match(r'<a name="(?P<key>.+?)"', l)
    if m:
        # New config key, storing the last one
        if k:
            info[k] = {
                'title': title,
                'doc': doc,
                'format': format,
                'examples': examples,
                'options': options
            }

            # Reset variables
            k = None
            p = False
            options = []
            doc = ""
            format = ""
            title = ""
            examples = []
        # We are not on this config key
        k = m.group('key')
        continue

    # Get the Format string
    m = re.match(r'.*<td><strong>(?P<format>.+?)</strong>', l)
    if m:
        format = m.group('format')
        continue

    # This config key has examples
    m = re.match(r'.*<font color="red"><strong>(?P<example>.+?)</strong>', l)
    if m:
        examples.append(m.group('example'))
        continue

    # More descriptive title for the config key
    m = re.match(r'.*<td bgcolor="#cbcbcb"><strong>(?P<title>.+?)</strong>', l)
    if m:
        title = m.group('title')
        continue

    # Here starts the main doc string
    if l == "<p>":
        p = True
        continue

    # Here ends the doc string
    if l == "</p>":
        p = False
        continue

    # Description of the options
    if l[:4] == '<li>':
        options.append(l[4:])

    # We are in the main doc section
    if p and k:
        doc += "%s " % (l)

# Save the last config key
info[k] = {
    'title': title,
    'doc': doc,
    'format': format,
    'examples': examples,
    'options': options
}

for k in info:
    if info[k]['format'].endswith('=&lt;0/1&gt;'):
        info[k]['type']='boolean'
    elif info[k]['format'].endswith('=&lt;seconds&gt;'):
        info[k]['type']='seconds'
    elif info[k]['format'].endswith('=&lt;percent&gt;'):
        info[k]['type']='percent'
    elif info[k]['format'].endswith('=&lt;file_name&gt;'):
        info[k]['type']='file_name'
    elif info[k]['format'].endswith('=&lt;minutes&gt;'):
        info[k]['type']='minutes'
    elif info[k]['format'].endswith('=&lt;#&gt;'):
        info[k]['type']='integer'
    elif info[k]['format'].endswith('=&lt;command&gt;'):
        info[k]['type']='command'
    else:
        info[k]['type']='unclassified'
# PrettyPrint
pprint(info)
# vim: smartindent tabstop=4 shiftwidth=4 expandtab

########NEW FILE########
__FILENAME__ = remove_empty_configfiles
#!/usr/bin/python
#
# This script looks for files in your configuration that have no objects in them.
#
#
import os
import pynag.Model

# Load pynag cache
all_objects = pynag.Model.ObjectDefinition.objects.all

for i in pynag.Model.config.get_cfg_files():
    objects = pynag.Model.ObjectDefinition.objects.filter(filename=i)
    if len(objects) == 0: # No objects found in that file
        # Objects defined via cfg_file= should not be removed because nagios will not reload
        # after you remove the file
        for k,v, in pynag.Model.config.maincfg_values:
            if k == 'cfg-file' and v == i:
                continue
        print "Empty config file: %s" % i
        # os.remove(i)

########NEW FILE########
__FILENAME__ = restructure_config_files
#!/usr/bin/env python
#
# This pynag script will parse all your nagios configuration
# And write a copy of every single object to /tmp/nagios/conf.d
#
# This can be very handy if your configuration files are a mess
# or if you are thinking about splitting a big file of services
# into one file per host
#
# The script will only write the copy to /tmp so you will
# have to manually remove old objects before you copy this
# into your /etc/nagios/conf.d or wherever you want to keep
# your objects



import pynag.Model
from pynag.Model import ObjectDefinition
import os
import os.path

# cfg_file is where our main nagios config file is
pynag.Model.cfg_file = '/etc/nagios3/nagios.cfg'

# pynag_directory is where the new objects will be saved
pynag.Model.pynag_directory = '/tmp/nagios/conf.d'

all_objects = ObjectDefinition.objects.all
# Use this instead if you only want to clean up a single directory
# all_objects = ObjectDefinition.objects.filter(filename__contains='/etc/nagios/all_the_services.cfg')

for i in all_objects:
    print "Saving", i.object_type, i.get_description(), "...",
    # Set a new filename for our object, None means
    # That pynag decides where it goes
    new_filename = i.get_suggested_filename()
    print new_filename
    continue
    # Alternative:
    # if i.object.type == 'host' and i.host_name is not None:
    #     new_filename = '/tmp/nagios/conf.d/hosts/%s" % i.host_name
    
    dirname = os.path.dirname(new_filename)
    if not os.path.exists(dirname):
        os.makedirs(dirname)
    with open(new_filename, 'a') as f:
        data = "\n" + str(i)
        f.write(data)
    print  new_filename


########NEW FILE########
__FILENAME__ = working_with_fields
#!/usr/bin/python
#
# This example shows how to work with attributes in nagios that
# Are in a comma-seperated form. Like this:
#
# define service {
#    contact_groups      +admins,webmasters,hostmasters
#    host_name           host.example.com
#    service_description Test Service
# }
#

import pynag.Model

# First create a test object
my_service = pynag.Model.Service()
my_service['host_name'] = 'examplehost'
my_service['service_description'] = 'Test Service'
my_service['contact_groups'] = '+admins,webmasters,hostmasters'

print "*** Created a demo servicecheck that looks like this:"
print my_service



print "\n--- Removing with attribute_removefield()"
my_service.attribute_removefield('contact_groups', 'hostmasters')
print "my_service.contact_groups = ", my_service.contact_groups



print "\n--- Add a new contact_group with attribute_appendfield()"
my_service.attribute_appendfield('contact_groups', "mycontactgroup")
print "my_service.contact_groups = ", my_service.contact_groups

print "\n-- Replacing a contact_group midfield with attribute_replacefield()"
my_service.attribute_replacefield('contact_groups', "webmasters", "hostmaster")
print "my_service.contact_groups = ", my_service.contact_groups


# A more advanced example. Find all services that inherit from "generic-service" and
# Replace it with "my-specific-service":

print "\n--- More advanced example, editing multiple objects at once..."
my_services = pynag.Model.Service.objects.filter(use__hasfield='generic-service')

for service in my_services:
    service.attribute_replacefield('use','generic-service','my-specific-service')
    # service.save()



########NEW FILE########
__FILENAME__ = find_orphans
#!/usr/bin/python
import sys

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()

## These are top level items.  We don't care if they dont' have a parent.
## Things like datacenters should be displayed here
top_level_items = ['main data center']



orphan_hosts = []
print "The following hosts do not have parent items:"

for host in nc['all_host']:
    use_attr = ''
    for attribute in ['host_name', 'name', 'alias']:
        if host.has_key(attribute):
            use_attr = attribute
    
    if not host.has_key('parents') or not host['parents']:
        if  host[use_attr] not in top_level_items:
		orphan_hosts.append(host)
        	print "%-12s %-32s (%s)" % (use_attr, host[use_attr], host['meta']['filename'])

if not len(orphan_hosts):
    print "No ophaned hosts found"

########NEW FILE########
__FILENAME__ = get_command
#!/usr/bin/python
import sys

if len(sys.argv) != 2:
    sys.stderr.write("Usage:  %s 'Command Name'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

target_item = sys.argv[1]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()


item = nc.get_command(target_item)

if not item:
    sys.stderr.write("Item not found: %s\n" % item)
    sys.exit(2)

print nc.print_conf(item)

########NEW FILE########
__FILENAME__ = get_contact
#!/usr/bin/python
import sys

if len(sys.argv) != 2:
    sys.stderr.write("Usage:  %s 'Contact Name'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

target_item = sys.argv[1]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()


item = nc.get_contact(target_item)

if not item:
    sys.stderr.write("Item not found: %s\n" % item)
    sys.exit(2)

print nc.print_conf(item)

########NEW FILE########
__FILENAME__ = get_contactgroup
#!/usr/bin/python
import sys

if len(sys.argv) != 2:
    sys.stderr.write("Usage:  %s 'Contactgroup Name'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

target_item = sys.argv[1]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()


item = nc.get_contactgroup(target_item)

if not item:
    sys.stderr.write("Item not found: %s\n" % item)
    sys.exit(2)

print nc.print_conf(item)

########NEW FILE########
__FILENAME__ = get_host
#!/usr/bin/python
import sys

if len(sys.argv) != 2:
    sys.stderr.write("Usage:  %s 'Host Name'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

target_host = sys.argv[1]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
#nc.parse()
nc.extended_parse()


host = nc.get_host(target_host)

if not host:
    sys.stderr.write("Host not found: %s\n" % host)
    sys.exit(2)

print nc.print_conf(host)

########NEW FILE########
__FILENAME__ = get_hostgroup
#!/usr/bin/python
import sys

if len(sys.argv) != 2:
    sys.stderr.write("Usage:  %s 'Hostgroup'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

target_host = sys.argv[1]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()


hostgroup = nc.get_hostgroup(target_host)

if not hostgroup:
    sys.stderr.write("Hostgroup not found: %s\n" % hostgroup)
    sys.exit(2)

print nc.print_conf(hostgroup)


########NEW FILE########
__FILENAME__ = get_service
#!/usr/bin/python
import sys

if len(sys.argv) != 3:
    sys.stderr.write("Usage:  %s 'Service Description' 'Host Name'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

service_description = sys.argv[1]
target_host = sys.argv[2]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
#nc.parse()
nc.parse()

service = nc.get_service(target_host, service_description)

if not service:
    sys.stderr.write("Service not found: %s %s\n" % (service_description, target_host))
    sys.exit(2)

print nc.print_conf(service)


########NEW FILE########
__FILENAME__ = get_servicegroup
#!/usr/bin/python
import sys

if len(sys.argv) != 2:
    sys.stderr.write("Usage:  %s 'Servicegroup Name'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

target_servicegroup = sys.argv[1]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()


item = nc.get_servicegroup(target_servicegroup)

if not item:
    sys.stderr.write("Item not found: %s\n" % item)
    sys.exit(2)

print nc.print_conf(item)

########NEW FILE########
__FILENAME__ = get_service_info
#!/usr/bin/python
import sys

if len(sys.argv) != 3:
    sys.stderr.write("Usage:  %s 'Host Name' 'Service Description'\n" % (sys.argv[0]))
    sys.exit(2)


## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config


## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()

service = nc.get_service(sys.argv[1],sys.argv[2])

print nc.print_conf(service)

########NEW FILE########
__FILENAME__ = get_timeperiod
#!/usr/bin/python
import sys

if len(sys.argv) != 2:
    sys.stderr.write("Usage:  %s 'Timeperiod Name'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

target_item = sys.argv[1]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()


item = nc.get_timeperiod(target_item)

if not item:
    sys.stderr.write("Item not found: %s\n" % item)
    sys.exit(2)

print nc.print_conf(item)

########NEW FILE########
__FILENAME__ = list_hosts_groups
#!/usr/bin/python
import sys

if len(sys.argv) != 2:
    sys.stderr.write("Usage:  %s 'Host Alias'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

target_host = sys.argv[1]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
#nc.parse()
nc.extended_parse()

## Find services that this host belongs to
for hostgroup in nc.get_host(target_host)['meta']['hostgroup_list']:
    ## Check to see if this is the only host in this service
    #return_item = nc.get_service(target_host, service_description)
    print hostgroup
#    print return_item['service_description']

########NEW FILE########
__FILENAME__ = list_services
#!/usr/bin/python
import sys

if len(sys.argv) != 2:
    sys.stderr.write("Usage:  %s 'Host Alias'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

target_host = sys.argv[1]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
#nc.parse()
nc.extended_parse()

## Find services that this host belongs to
for service in nc.get_host(target_host)['meta']['service_list']:
    ## Check to see if this is the only host in this service
    #return_item = nc.get_service(target_host, service_description)
    print service
#    print return_item['service_description']

########NEW FILE########
__FILENAME__ = optimize_config
#!/usr/bin/python
import sys

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

def is_ip(ip_address):
    import socket
    try:
        socket.inet_aton(ip_address)
        return True # We got through that call without an error, so it is valid
    except socket.error:
        return False # There was an error, so it is invalid

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.extended_parse()

nc.flag_all_commit()

nc.commit()

########NEW FILE########
__FILENAME__ = parse_files
#!/usr/bin/python
import sys

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()
#nc._post_parse()
for host in nc['all_host']:
    print nc.print_conf(host)

########NEW FILE########
__FILENAME__ = remove_host
#!/usr/bin/python
import sys

if len(sys.argv) != 2:
    sys.stderr.write("Usage:  %s 'Host Alias'\n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

target_host = sys.argv[1]

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.extended_parse()

nc.cleanup()

## Find services that this host belongs to
if not nc.get_host(target_host):
    sys.stderr.write("%s does not exist\n" % target_host)
    sys.exit(2)


for service_description in nc.get_host(target_host)['meta']['service_list']:
    service = nc.get_service(target_host, service_description)

    ## Check to see if this is the only host in this service
    host_list = []
    if service.has_key('host_name'):
        for host in nc._get_list(service, 'host_name'):
            if host[0] != "!":
                host_list.append(host)
    else:
        continue

    ## Ignore if this host isn't listed
    if len(host_list) == 0:
        continue


    if len(host_list) > 1:
        print "Removing %s from %s" % (target_host, service['service_description'])
        new_item = nc.get_service(service['service_description'], target_host)
        host_list.remove(target_host)
        host_string = ",".join(host_list)
        print "New Value: %s" % host_string
        nc.edit_service(target_host, service['service_description'], 'host_name',host_string)
    elif (len(host_list) == 1) and not service.has_key('hostgroup_name'):
        print "Deleting %s" % service['service_description']
        nc.delete_service(service['service_description'], target_host)
    elif (len(host_list) == 1) and (host_list[0] is target_host):
        print "Deleting %s" % service['service_description']
        nc.delete_service(service['service_description'], target_host)
    else:
        print "Unknown Action"
        sys.exit(2)
    nc.commit()

## Delete from groups
host_obj = nc.get_host(target_host)
for hostgroup in host_obj['meta']['hostgroup_list']:
    print "Removing %s from hostgroup %s" % (target_host, hostgroup)
    hostgroup_obj = nc.get_hostgroup(hostgroup)

    ## Get the list
    #hostgroup_obj['members'] = nc._get_list(hostgroup_obj, 'members').remove(target_host)

    ## Remove the original objct
    member_list = nc._get_list(hostgroup_obj, 'members')
    member_list.remove(target_host)

    nc['all_hostgroup'].remove(hostgroup_obj)
    hostgroup_obj['meta']['needs_commit'] = True
    member_string = ",".join(member_list)
    hostgroup_obj['members'] = ",".join(member_list)
    nc['all_hostgroup'].append(hostgroup_obj)
    
    nc.commit()

## Delete a host
result = nc.delete_object('host',target_host)
if result:
    print "Deleted host"

## Delete hostextinfo
result = nc.delete_object('hostextinfo',target_host)
if result:
    print "Deleted hostextinfo"

nc.commit()
nc.cleanup()

########NEW FILE########
__FILENAME__ = remove_host_from_group
#!/usr/bin/python

import sys

if len(sys.argv) != 3:
    sys.stderr.write("Usage:  %s 'Host Name' 'Hostgroup Name' \n" % (sys.argv[0]))
    sys.exit(2)

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()


target_host = sys.argv[1]
target_group = sys.argv[2]


## Get the host object
host_obj = nc.get_host(target_host)
if not host_obj:
    sys.stderr.write("host_name '%s' does not exist\n" % target_host)
    sys.exit(2)

## Find the hostgroup from our global dictionaries
group_obj = nc.get_hostgroup(target_group)
if not group_obj:
    sys.stderr.write("%s does not exist\n" % target_group)
    sys.exit(2)

## Get a list of the host_name's in this group
existing_list = group_obj['members'].split(",")
if target_host not in existing_list:
    sys.stderr.write("%s is not in the group\n" % target_host)
    sys.exit(2)
else:
    existing_list.remove(target_host)

print "Removing %s from %s" % (target_host, target_group)

## Alphabetize the list, for easier readability (and to make it pretty)
existing_list.sort()

## Remove old group
nc['all_hostgroup'].remove(group_obj)

## Save the new member list
group_obj['members'] = ",".join(existing_list)

## Mark the commit flag for the group
group_obj['meta']['needs_commit'] = True

## Add the group back in with new members
nc['all_hostgroup'].append(group_obj)

## Commit the changes to file
nc.commit()

########NEW FILE########
__FILENAME__ = suggest_optimizations
#!/usr/bin/python
import sys

## This is for the custom nagios module
sys.path.insert(1, '../')
from pynag.Parsers import config

def is_ip(ip_address):
    import socket
    try:
        socket.inet_aton(ip_address)
        return True # We got through that call without an error, so it is valid
    except socket.error:
        return False # There was an error, so it is invalid

## Create the plugin option
nc = config('/etc/nagios/nagios.cfg')
nc.parse()


print "Checking hosts using dns names instead of ip addresses in the 'address' field"
for host in nc['all_host']:
    if host.has_key('address'):
        if not is_ip(host['address']):
            print "%s has a name instead of ip in the address field (%s)" % (host['alias'], host['address'])


print "Checking for weird service definitions"
for service in nc['all_service']:
    if service.has_key('register') and service['register'] == 0:
        continue
    if not service.has_key('host_name'):
        print nc.print_conf( service )

########NEW FILE########
__FILENAME__ = check_cpu
#!/usr/bin/python
import os,sys

## Import plugin from nagios Module
from pynag.Plugins import simple as Plugin


## Create the plugin option
np = Plugin()

## Add a command line argument
np.add_arg("l","load-file", "Enter a load average file", required=None)

## This starts the actual plugin activation
np.activate()

## Use a custom load average file, if specified to
if np['load-file']:
    load_file = np['load-file']
else:
    load_file = "/proc/loadavg"

if not os.path.isfile(load_file):
    np.nagios_exit("UNKNOWN", "Missing Load average file %s" % load_file)

## Get the check value
current_load = open(load_file).readline().split()[0]

## Add the perdata
np.add_perfdata("1min", current_load)

np.check_range(current_load)

########NEW FILE########
__FILENAME__ = check_dns
# check_dns.py -- Returns OK if a hostname resolves to any ip address

# check_dns plugin will need some system libraries for DNS lookup
from _socket import gaierror
import socket
import time

# Import PluginHelper and some utility constants from the Plugins module
from pynag.Plugins import PluginHelper,ok,warning,critical,unknown

# Create an instance of PluginHelper()
my_plugin = PluginHelper()

# Our Plugin will need -H and -a attributes and we will use PluginHelpers wrapper around optparse for this:
my_plugin.parser.add_option('-H', help="Hostname or ip address", dest="hostname")
my_plugin.parser.add_option('-a', help="Expected Address", dest="address")

# When parse_arguments is called some default options like --threshold and --no-longoutput are automatically added
my_plugin.parse_arguments()


#
# Here starts Plugin-specific logic
#

# Get the hostname and expected address that was provided on the command-line
# address will be optional, but we will throw and error if hostname is not provided
hostname = my_plugin.options.hostname
address = my_plugin.options.address
if hostname is None:
    my_plugin.parser.error('-H argument is required')


# Here comes the specific check logic
try:
    start_time = time.time()
    result = socket.gethostbyname( hostname ) # result will contain the ip address resolved
    end_time = time.time()

    # If no address was specified with -a, then we return
    # OK if hostname resolved to anything at all
    if address is None or address == result:
        my_plugin.status(ok)
        my_plugin.add_summary("%s resolves to %s" % (hostname, result))
    else:
        my_plugin.status(critical)
        my_plugin.add_summary("%s resolves to %s but should resolve to %s" % (hostname,result,address))

    # Add run_time metric, so we can also alert if lookup takes to long
    run_time = end_time - start_time
    my_plugin.add_metric('run_time', run_time)
except gaierror:
    # If any exceptions happened in the code above, lets return a critical status
    my_plugin.status(critical)
    my_plugin.add_summary('Could not resolve host "%s"' % hostname )

# when check_all_metrics() is run, any metrics we have added with add_metric() will be processed against
# Thresholds (like --threshold). This part will allow our plugin users to alert on lookup_time
my_plugin.check_all_metrics()

# Print status output and exit
my_plugin.exit()

########NEW FILE########
__FILENAME__ = check_load
# check_load.py - Check load average. Thresholds can be specified from the commandline

# Import PluginHelper and some utility constants from the Plugins module
from pynag.Plugins import PluginHelper,ok,warning,critical,unknown

# Create an instance of PluginHelper()
helper = PluginHelper()

# Optionally, let helper handle command-line arguments for us for example --threshold
# Note: If your plugin needs any commandline arguments on its own (like --hostname) you should add them
# before this step with helper.parser.add_option()
helper.parse_arguments()


# Here starts our plugin specific logic. Lets try to read /proc/loadavg
# And if it fails, we exit immediately with UNKNOWN status
try:
    content = open('/proc/loadavg').read()
except Exception, e:
    helper.exit(summary="Could not read /proc/loadavg", long_output=str(e), exit_code=unknown, perfdata='')


# We have read the contents of loadavg file. Lets put it in the summary of our plugin output:
helper.add_summary("Load: %s" % content)


# Read metrics from /proc/loadavg and add them as performance metrics
load1,load5,load15,processes,last_proc_id = content.split()
running,total = processes.split('/')

# If we so desire we can set default thresholds by adding warn attribute here
# However we decide that there are no thresholds by default and they have to be
# applied on runtime with the --threshold option
helper.add_metric(label='load1',value=load1)
helper.add_metric(label='load5',value=load5)
helper.add_metric(label='load15',value=load15)
helper.add_metric(label='running_processes',value=running)
helper.add_metric(label='total_processes',value=total)

# By default assume everything is ok. Any thresholds specified with --threshold can overwrite this status:
helper.status(ok)

# Here all metrics will be checked against thresholds that are either
# built-in or added via --threshold from the command-line
helper.check_all_metrics()

# Print out plugin information and exit nagios-style
helper.exit()

########NEW FILE########
__FILENAME__ = check_stuff
# check_stuff.py Takes any arguments from the command_line and treats them as performance metrics.


from pynag.Plugins import PluginHelper

my_plugin = PluginHelper()
my_plugin.parse_arguments()

# Any perfdatastring added as argument will be treated as a performance metric
for i in my_plugin.arguments:
    my_plugin.add_metric(perfdatastring=i)


my_plugin.check_all_metrics()
my_plugin.exit()

########NEW FILE########
__FILENAME__ = autogenerated_commands

def add_host_comment(host_name, 
                     persistent, 
                     author, 
                     comment, 
                     command_file=None, 
                     timestamp=0):
    """
    Adds a comment to a particular host.  If the "persistent" field
    is set to zero (0), the comment will be deleted the next time
    Nagios is restarted.  Otherwise, the comment will persist across
    program restarts until it is deleted manually.
    """
    return send_command("ADD_HOST_COMMENT",
                        command_file,
                        timestamp,
                        host_name, 
                        persistent, 
                        author, 
                        comment)

def shutdown_program(command_file=None, 
                     timestamp=0):
    """
    Shuts down the Nagios process.
    """
    return send_command("SHUTDOWN_PROGRAM",
                        command_file,
                        timestamp,
                        )

def disable_servicegroup_passive_svc_checks(servicegroup_name, 
                                            command_file=None, 
                                            timestamp=0):
    """
    Disables the acceptance and processing of passive checks for all
    services in a particular servicegroup.
    """
    return send_command("DISABLE_SERVICEGROUP_PASSIVE_SVC_CHECKS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def enable_servicegroup_passive_host_checks(servicegroup_name, 
                                            command_file=None, 
                                            timestamp=0):
    """
    Enables the acceptance and processing of passive checks for all
    hosts that have services that are members of a particular
    service group.
    """
    return send_command("ENABLE_SERVICEGROUP_PASSIVE_HOST_CHECKS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def disable_servicegroup_passive_host_checks(servicegroup_name, 
                                             command_file=None, 
                                             timestamp=0):
    """
    Disables the acceptance and processing of passive checks for all
    hosts that have services that are members of a particular
    service group.
    """
    return send_command("DISABLE_SERVICEGROUP_PASSIVE_HOST_CHECKS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def change_global_host_event_handler(event_handler_command, 
                                     command_file=None, 
                                     timestamp=0):
    """
    Changes the global host event handler command to be that
    specified by the "event_handler_command" option.  The
    "event_handler_command" option specifies the short name of the
    command that should be used as the new host event handler.  The
    command must have been configured in Nagios before it was last
    (re)started.
    """
    return send_command("CHANGE_GLOBAL_HOST_EVENT_HANDLER",
                        command_file,
                        timestamp,
                        event_handler_command)

def change_global_svc_event_handler(event_handler_command, 
                                    command_file=None, 
                                    timestamp=0):
    """
    Changes the global service event handler command to be that
    specified by the "event_handler_command" option.  The
    "event_handler_command" option specifies the short name of the
    command that should be used as the new service event handler.
    The command must have been configured in Nagios before it was
    last (re)started.
    """
    return send_command("CHANGE_GLOBAL_SVC_EVENT_HANDLER",
                        command_file,
                        timestamp,
                        event_handler_command)

def change_host_event_handler(host_name, 
                              event_handler_command, 
                              command_file=None, 
                              timestamp=0):
    """
    Changes the event handler command for a particular host to be
    that specified by the "event_handler_command" option.  The
    "event_handler_command" option specifies the short name of the
    command that should be used as the new host event handler.  The
    command must have been configured in Nagios before it was last
    (re)started.
    """
    return send_command("CHANGE_HOST_EVENT_HANDLER",
                        command_file,
                        timestamp,
                        host_name, 
                        event_handler_command)

def change_svc_event_handler(host_name, 
                             service_description, 
                             event_handler_command, 
                             command_file=None, 
                             timestamp=0):
    """
    Changes the event handler command for a particular service to be
    that specified by the "event_handler_command" option.  The
    "event_handler_command" option specifies the short name of the
    command that should be used as the new service event handler.
    The command must have been configured in Nagios before it was
    last (re)started.
    """
    return send_command("CHANGE_SVC_EVENT_HANDLER",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        event_handler_command)

def change_host_check_command(host_name, 
                              check_command, 
                              command_file=None, 
                              timestamp=0):
    """
    Changes the check command for a particular host to be that
    specified by the "check_command" option.  The "check_command"
    option specifies the short name of the command that should be
    used as the new host check command.  The command must have been
    configured in Nagios before it was last (re)started.
    """
    return send_command("CHANGE_HOST_CHECK_COMMAND",
                        command_file,
                        timestamp,
                        host_name, 
                        check_command)

def change_svc_check_command(host_name, 
                             service_description, 
                             check_command, 
                             command_file=None, 
                             timestamp=0):
    """
    Changes the check command for a particular service to be that
    specified by the "check_command" option.  The "check_command"
    option specifies the short name of the command that should be
    used as the new service check command.  The command must have
    been configured in Nagios before it was last (re)started.
    """
    return send_command("CHANGE_SVC_CHECK_COMMAND",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        check_command)

def change_normal_host_check_interval(host_name, 
                                      check_interval, 
                                      command_file=None, 
                                      timestamp=0):
    """
    Changes the normal (regularly scheduled) check interval for a
    particular host.
    """
    return send_command("CHANGE_NORMAL_HOST_CHECK_INTERVAL",
                        command_file,
                        timestamp,
                        host_name, 
                        check_interval)

def enable_svc_notifications(host_name, 
                             service_description, 
                             command_file=None, 
                             timestamp=0):
    """
    Enables notifications for a particular service.  Notifications
    will be sent out for the service only if notifications are
    enabled on a program-wide basis as well.
    """
    return send_command("ENABLE_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def change_normal_svc_check_interval(host_name, 
                                     service_description, 
                                     check_interval, 
                                     command_file=None, 
                                     timestamp=0):
    """
    Changes the normal (regularly scheduled) check interval for a
    particular service
    """
    return send_command("CHANGE_NORMAL_SVC_CHECK_INTERVAL",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        check_interval)

def change_retry_svc_check_interval(host_name, 
                                    service_description, 
                                    check_interval, 
                                    command_file=None, 
                                    timestamp=0):
    """
    Changes the retry check interval for a particular service.
    """
    return send_command("CHANGE_RETRY_SVC_CHECK_INTERVAL",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        check_interval)

def change_max_host_check_attempts(host_name, 
                                   check_attempts, 
                                   command_file=None, 
                                   timestamp=0):
    """
    Changes the maximum number of check attempts (retries) for a
    particular host.
    """
    return send_command("CHANGE_MAX_HOST_CHECK_ATTEMPTS",
                        command_file,
                        timestamp,
                        host_name, 
                        check_attempts)

def change_max_svc_check_attempts(host_name, 
                                  service_description, 
                                  check_attempts, 
                                  command_file=None, 
                                  timestamp=0):
    """
    Changes the maximum number of check attempts (retries) for a
    particular service.
    """
    return send_command("CHANGE_MAX_SVC_CHECK_ATTEMPTS",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        check_attempts)

def process_service_check_result(host_name, 
                                 service_description, 
                                 return_code, 
                                 plugin_output, 
                                 command_file=None, 
                                 timestamp=0):
    """
    This is used to submit a passive check result for a particular
    service.  The "return_code" field should be one of the
    following: 0=OK, 1=WARNING, 2=CRITICAL, 3=UNKNOWN.  The
    "plugin_output" field contains text output from the service
    check, along with optional performance data.
    """
    return send_command("PROCESS_SERVICE_CHECK_RESULT",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        return_code, 
                        plugin_output)

def process_host_check_result(host_name, 
                              status_code, 
                              plugin_output, 
                              command_file=None, 
                              timestamp=0):
    """
    This is used to submit a passive check result for a particular
    host.  The "status_code" indicates the state of the host check
    and should be one of the following: 0=UP, 1=DOWN, 2=UNREACHABLE.
    The "plugin_output" argument contains the text returned from the
    host check, along with optional performance data.
    """
    return send_command("PROCESS_HOST_CHECK_RESULT",
                        command_file,
                        timestamp,
                        host_name, 
                        status_code, 
                        plugin_output)

def remove_host_acknowledgement(host_name, 
                                command_file=None, 
                                timestamp=0):
    """
    This removes the problem acknowledgement for a particular host.
    Once the acknowledgement has been removed, notifications can
    once again be sent out for the given host.
    """
    return send_command("REMOVE_HOST_ACKNOWLEDGEMENT",
                        command_file,
                        timestamp,
                        host_name)

def remove_svc_acknowledgement(host_name, 
                               service_description, 
                               command_file=None, 
                               timestamp=0):
    """
    This removes the problem acknowledgement for a particular
    service.  Once the acknowledgement has been removed,
    notifications can once again be sent out for the given service.
    """
    return send_command("REMOVE_SVC_ACKNOWLEDGEMENT",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def schedule_host_downtime(host_name, 
                           start_time, 
                           end_time, 
                           fixed, 
                           trigger_id, 
                           duration, 
                           author, 
                           comment, 
                           command_file=None, 
                           timestamp=0):
    """
    Schedules downtime for a specified host.  If the "fixed"
    argument is set to one (1), downtime will start and end at the
    times specified by the "start" and "end" arguments.  Otherwise,
    downtime will begin between the "start" and "end" times and last
    for "duration" seconds.  The "start" and "end" arguments are
    specified in time_t format (seconds since the UNIX epoch).  The
    specified host downtime can be triggered by another downtime
    entry if the "trigger_id" is set to the ID of another scheduled
    downtime entry.  Set the "trigger_id" argument to zero (0) if
    the downtime for the specified host should not be triggered by
    another downtime entry.
    """
    return send_command("SCHEDULE_HOST_DOWNTIME",
                        command_file,
                        timestamp,
                        host_name, 
                        start_time, 
                        end_time, 
                        fixed, 
                        trigger_id, 
                        duration, 
                        author, 
                        comment)

def schedule_svc_downtime(host_name, 
                          service_description, 
                          start_time, 
                          end_time, 
                          fixed, 
                          trigger_id, 
                          duration, 
                          author, 
                          comment, 
                          command_file=None, 
                          timestamp=0):
    """
    Schedules downtime for a specified service.  If the "fixed"
    argument is set to one (1), downtime will start and end at the
    times specified by the "start" and "end" arguments.  Otherwise,
    downtime will begin between the "start" and "end" times and last
    for "duration" seconds.  The "start" and "end" arguments are
    specified in time_t format (seconds since the UNIX epoch).  The
    specified service downtime can be triggered by another downtime
    entry if the "trigger_id" is set to the ID of another scheduled
    downtime entry.  Set the "trigger_id" argument to zero (0) if
    the downtime for the specified service should not be triggered
    by another downtime entry.
    """
    return send_command("SCHEDULE_SVC_DOWNTIME",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        start_time, 
                        end_time, 
                        fixed, 
                        trigger_id, 
                        duration, 
                        author, 
                        comment)

def disable_svc_notifications(host_name, 
                              service_description, 
                              command_file=None, 
                              timestamp=0):
    """
    Disables notifications for a particular service.
    """
    return send_command("DISABLE_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def schedule_servicegroup_svc_downtime(servicegroup_name, 
                                       start_time, 
                                       end_time, 
                                       fixed, 
                                       trigger_id, 
                                       duration, 
                                       author, 
                                       comment, 
                                       command_file=None, 
                                       timestamp=0):
    """
    Schedules downtime for all services in a specified servicegroup.
    If the "fixed" argument is set to one (1), downtime will start
    and end at the times specified by the "start" and "end"
    arguments.  Otherwise, downtime will begin between the "start"
    and "end" times and last for "duration" seconds.  The "start"
    and "end" arguments are specified in time_t format (seconds
    since the UNIX epoch).  The service downtime entries can be
    triggered by another downtime entry if the "trigger_id" is set
    to the ID of another scheduled downtime entry.  Set the
    "trigger_id" argument to zero (0) if the downtime for the
    services should not be triggered by another downtime entry.
    """
    return send_command("SCHEDULE_SERVICEGROUP_SVC_DOWNTIME",
                        command_file,
                        timestamp,
                        servicegroup_name, 
                        start_time, 
                        end_time, 
                        fixed, 
                        trigger_id, 
                        duration, 
                        author, 
                        comment)

def schedule_servicegroup_host_downtime(servicegroup_name, 
                                        start_time, 
                                        end_time, 
                                        fixed, 
                                        trigger_id, 
                                        duration, 
                                        author, 
                                        comment, 
                                        command_file=None, 
                                        timestamp=0):
    """
    Schedules downtime for all hosts that have services in a
    specified servicegroup.  If the "fixed" argument is set to one
    (1), downtime will start and end at the times specified by the
    "start" and "end" arguments.  Otherwise, downtime will begin
    between the "start" and "end" times and last for "duration"
    seconds.  The "start" and "end" arguments are specified in
    time_t format (seconds since the UNIX epoch).  The host downtime
    entries can be triggered by another downtime entry if the
    "trigger_id" is set to the ID of another scheduled downtime
    entry.  Set the "trigger_id" argument to zero (0) if the
    downtime for the hosts should not be triggered by another
    downtime entry.
    """
    return send_command("SCHEDULE_SERVICEGROUP_HOST_DOWNTIME",
                        command_file,
                        timestamp,
                        servicegroup_name, 
                        start_time, 
                        end_time, 
                        fixed, 
                        trigger_id, 
                        duration, 
                        author, 
                        comment)

def schedule_host_svc_downtime(host_name, 
                               start_time, 
                               end_time, 
                               fixed, 
                               trigger_id, 
                               duration, 
                               author, 
                               comment, 
                               command_file=None, 
                               timestamp=0):
    """
    Schedules downtime for all services associated with a particular
    host.  If the "fixed" argument is set to one (1), downtime will
    start and end at the times specified by the "start" and "end"
    arguments.  Otherwise, downtime will begin between the "start"
    and "end" times and last for "duration" seconds.  The "start"
    and "end" arguments are specified in time_t format (seconds
    since the UNIX epoch).  The service downtime entries can be
    triggered by another downtime entry if the "trigger_id" is set
    to the ID of another scheduled downtime entry.  Set the
    "trigger_id" argument to zero (0) if the downtime for the
    services should not be triggered by another downtime entry.
    """
    return send_command("SCHEDULE_HOST_SVC_DOWNTIME",
                        command_file,
                        timestamp,
                        host_name, 
                        start_time, 
                        end_time, 
                        fixed, 
                        trigger_id, 
                        duration, 
                        author, 
                        comment)

def schedule_hostgroup_host_downtime(hostgroup_name, 
                                     start_time, 
                                     end_time, 
                                     fixed, 
                                     trigger_id, 
                                     duration, 
                                     author, 
                                     comment, 
                                     command_file=None, 
                                     timestamp=0):
    """
    Schedules downtime for all hosts in a specified hostgroup.  If
    the "fixed" argument is set to one (1), downtime will start and
    end at the times specified by the "start" and "end" arguments.
    Otherwise, downtime will begin between the "start" and "end"
    times and last for "duration" seconds.  The "start" and "end"
    arguments are specified in time_t format (seconds since the UNIX
    epoch).  The host downtime entries can be triggered by another
    downtime entry if the "trigger_id" is set to the ID of another
    scheduled downtime entry.  Set the "trigger_id" argument to zero
    (0) if the downtime for the hosts should not be triggered by
    another downtime entry.
    """
    return send_command("SCHEDULE_HOSTGROUP_HOST_DOWNTIME",
                        command_file,
                        timestamp,
                        hostgroup_name, 
                        start_time, 
                        end_time, 
                        fixed, 
                        trigger_id, 
                        duration, 
                        author, 
                        comment)

def schedule_hostgroup_svc_downtime(hostgroup_name, 
                                    start_time, 
                                    end_time, 
                                    fixed, 
                                    trigger_id, 
                                    duration, 
                                    author, 
                                    comment, 
                                    command_file=None, 
                                    timestamp=0):
    """
    Schedules downtime for all services associated with hosts in a
    specified servicegroup.  If the "fixed" argument is set to one
    (1), downtime will start and end at the times specified by the
    "start" and "end" arguments.  Otherwise, downtime will begin
    between the "start" and "end" times and last for "duration"
    seconds.  The "start" and "end" arguments are specified in
    time_t format (seconds since the UNIX epoch).  The service
    downtime entries can be triggered by another downtime entry if
    the "trigger_id" is set to the ID of another scheduled downtime
    entry.  Set the "trigger_id" argument to zero (0) if the
    downtime for the services should not be triggered by another
    downtime entry.
    """
    return send_command("SCHEDULE_HOSTGROUP_SVC_DOWNTIME",
                        command_file,
                        timestamp,
                        hostgroup_name, 
                        start_time, 
                        end_time, 
                        fixed, 
                        trigger_id, 
                        duration, 
                        author, 
                        comment)

def del_host_downtime(downtime_id, 
                      command_file=None, 
                      timestamp=0):
    """
    Deletes the host downtime entry that has an ID number matching
    the "downtime_id" argument.  If the downtime is currently in
    effect, the host will come out of scheduled downtime (as long as
    there are no other overlapping active downtime entries).
    """
    return send_command("DEL_HOST_DOWNTIME",
                        command_file,
                        timestamp,
                        downtime_id)

def del_svc_downtime(downtime_id, 
                     command_file=None, 
                     timestamp=0):
    """
    Deletes the service downtime entry that has an ID number
    matching the "downtime_id" argument.  If the downtime is
    currently in effect, the service will come out of scheduled
    downtime (as long as there are no other overlapping active
    downtime entries).
    """
    return send_command("DEL_SVC_DOWNTIME",
                        command_file,
                        timestamp,
                        downtime_id)

def schedule_host_check(host_name, 
                        check_time, 
                        command_file=None, 
                        timestamp=0):
    """
    Schedules the next active check of a particular host at
    "check_time".  The "check_time" argument is specified in time_t
    format (seconds since the UNIX epoch).  Note that the host may
    not actually be checked at the time you specify.  This could
    occur for a number of reasons: active checks are disabled on a
    program-wide or service-specific basis, the host is already
    scheduled to be checked at an earlier time, etc.  If you want to
    force the host check to occur at the time you specify, look at
    the SCHEDULE_FORCED_HOST_CHECK command.
    """
    return send_command("SCHEDULE_HOST_CHECK",
                        command_file,
                        timestamp,
                        host_name, 
                        check_time)

def schedule_forced_host_check(host_name, 
                               check_time, 
                               command_file=None, 
                               timestamp=0):
    """
    Schedules a forced active check of a particular host at
    "check_time".  The "check_time" argument is specified in time_t
    format (seconds since the UNIX epoch).   Forced checks are
    performed regardless of what time it is (e.g. timeperiod
    restrictions are ignored) and whether or not active checks are
    enabled on a host-specific or program-wide basis.
    """
    return send_command("SCHEDULE_FORCED_HOST_CHECK",
                        command_file,
                        timestamp,
                        host_name, 
                        check_time)

def schedule_forced_svc_check(host_name, 
                              service_description, 
                              check_time, 
                              command_file=None, 
                              timestamp=0):
    """
    Schedules a forced active check of a particular service at
    "check_time".  The "check_time" argument is specified in time_t
    format (seconds since the UNIX epoch).   Forced checks are
    performed regardless of what time it is (e.g. timeperiod
    restrictions are ignored) and whether or not active checks are
    enabled on a service-specific or program-wide basis.
    """
    return send_command("SCHEDULE_FORCED_SVC_CHECK",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        check_time)

def del_all_host_comments(host_name, 
                          command_file=None, 
                          timestamp=0):
    """
    Deletes all comments assocated with a particular host.
    """
    return send_command("DEL_ALL_HOST_COMMENTS",
                        command_file,
                        timestamp,
                        host_name)

def schedule_forced_host_svc_checks(host_name, 
                                    check_time, 
                                    command_file=None, 
                                    timestamp=0):
    """
    Schedules a forced active check of all services associated with
    a particular host at "check_time".  The "check_time" argument is
    specified in time_t format (seconds since the UNIX epoch).
    Forced checks are performed regardless of what time it is (e.g.
    timeperiod restrictions are ignored) and whether or not active
    checks are enabled on a service-specific or program-wide basis.
    """
    return send_command("SCHEDULE_FORCED_HOST_SVC_CHECKS",
                        command_file,
                        timestamp,
                        host_name, 
                        check_time)

def process_file(file_name, 
                 delete, 
                 command_file=None, 
                 timestamp=0):
    """
    Directs Nagios to process all external commands that are found
    in the file specified by the <file_name> argument.  If the
    <delete> option is non-zero, the file will be deleted once it
    has been processes.  If the <delete> option is set to zero, the
    file is left untouched.
    """
    return send_command("PROCESS_FILE",
                        command_file,
                        timestamp,
                        file_name, 
                        delete)

def change_host_check_timeperiod(host_name, 
                                 check_timeperod, 
                                 command_file=None, 
                                 timestamp=0):
    """
    Changes the check timeperiod for a particular host to what is
    specified by the "check_timeperiod" option.  The
    "check_timeperiod" option should be the short name of the
    timeperod that is to be used as the host check timeperiod.  The
    timeperiod must have been configured in Nagios before it was
    last (re)started.
    """
    return send_command("CHANGE_HOST_CHECK_TIMEPERIOD",
                        command_file,
                        timestamp,
                        host_name, 
                        check_timeperod)

def send_custom_host_notification(host_name, 
                                  options, 
                                  author, 
                                  comment, 
                                  command_file=None, 
                                  timestamp=0):
    """
    Allows you to send a custom host notification.  Very useful in
    dire situations, emergencies or to communicate with all admins
    that are responsible for a particular host.  When the host
    notification is sent out, the $NOTIFICATIONTYPE$ macro will be
    set to "CUSTOM".  The <options> field is a logical OR of the
    following integer values that affect aspects of the notification
    that are sent out: 0 = No option (default), 1 = Broadcast (send
    notification to all normal and all escalated contacts for the
    host), 2 = Forced (notification is sent out regardless of
    current time, whether or not notifications are enabled, etc.), 4
    = Increment current notification # for the host (this is not
    done by default for custom notifications).  The comment field
    can be used with the
    $NOTIFICATIONCOMMENT$ macro in notification commands.
    """
    return send_command("SEND_CUSTOM_HOST_NOTIFICATION",
                        command_file,
                        timestamp,
                        host_name, 
                        options, 
                        author, 
                        comment)

def send_custom_svc_notification(host_name, 
                                 service_description, 
                                 options, 
                                 author, 
                                 comment, 
                                 command_file=None, 
                                 timestamp=0):
    """
    Allows you to send a custom service notification.  Very useful
    in dire situations, emergencies or to communicate with all
    admins that are responsible for a particular service.  When the
    service notification is sent out, the $NOTIFICATIONTYPE$ macro
    will be set to "CUSTOM".  The <options> field is a logical OR of
    the following integer values that affect aspects of the
    notification that are sent out: 0 = No option (default), 1 =
    Broadcast (send notification to all normal and all escalated
    contacts for the service), 2 = Forced (notification is sent out
    regardless of current time, whether or not notifications are
    enabled, etc.), 4 = Increment current notification # for the
    service(this is not done by default for custom notifications).
    The comment field can be used with the
    $NOTIFICATIONCOMMENT$ macro in notification commands.
    """
    return send_command("SEND_CUSTOM_SVC_NOTIFICATION",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        options, 
                        author, 
                        comment)

def change_retry_host_check_interval(host_name, 
                                     service_description, 
                                     check_interval, 
                                     command_file=None, 
                                     timestamp=0):
    """
    Changes the retry check interval for a particular host.
    """
    return send_command("CHANGE_RETRY_HOST_CHECK_INTERVAL",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        check_interval)

def change_svc_check_timeperiod(host_name, 
                                service_description, 
                                check_timeperiod, 
                                command_file=None, 
                                timestamp=0):
    """
    Changes the check timeperiod for a particular service to what is
    specified by the "check_timeperiod" option.  The
    "check_timeperiod" option should be the short name of the
    timeperod that is to be used as the service check timeperiod.
    The timeperiod must have been configured in Nagios before it was
    last (re)started.
    """
    return send_command("CHANGE_SVC_CHECK_TIMEPERIOD",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        check_timeperiod)

def change_custom_host_var(host_name, 
                           varname, 
                           varvalue, 
                           command_file=None, 
                           timestamp=0):
    """
    Changes the value of a custom host variable.
    """
    return send_command("CHANGE_CUSTOM_HOST_VAR",
                        command_file,
                        timestamp,
                        host_name, 
                        varname, 
                        varvalue)

def del_all_svc_comments(host_name, 
                         service_description, 
                         command_file=None, 
                         timestamp=0):
    """
    Deletes all comments associated with a particular service.
    """
    return send_command("DEL_ALL_SVC_COMMENTS",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def change_custom_svc_var(host_name, 
                          service_description, 
                          varname, 
                          varvalue, 
                          command_file=None, 
                          timestamp=0):
    """
    Changes the value of a custom service variable.
    """
    return send_command("CHANGE_CUSTOM_SVC_VAR",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        varname, 
                        varvalue)

def change_custom_contact_var(contact_name, 
                              varname, 
                              varvalue, 
                              command_file=None, 
                              timestamp=0):
    """
    Changes the value of a custom contact variable.
    """
    return send_command("CHANGE_CUSTOM_CONTACT_VAR",
                        command_file,
                        timestamp,
                        contact_name, 
                        varname, 
                        varvalue)

def enable_contact_host_notifications(contact_name, 
                                      command_file=None, 
                                      timestamp=0):
    """
    Enables host notifications for a particular contact.
    """
    return send_command("ENABLE_CONTACT_HOST_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        contact_name)

def disable_contact_host_notifications(contact_name, 
                                       command_file=None, 
                                       timestamp=0):
    """
    Disables host notifications for a particular contact.
    """
    return send_command("DISABLE_CONTACT_HOST_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        contact_name)

def enable_contact_svc_notifications(contact_name, 
                                     command_file=None, 
                                     timestamp=0):
    """
    Disables service notifications for a particular contact.
    """
    return send_command("ENABLE_CONTACT_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        contact_name)

def disable_contact_svc_notifications(contact_name, 
                                      command_file=None, 
                                      timestamp=0):
    """
    Disables service notifications for a particular contact.
    """
    return send_command("DISABLE_CONTACT_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        contact_name)

def enable_contactgroup_host_notifications(contactgroup_name, 
                                           command_file=None, 
                                           timestamp=0):
    """
    Enables host notifications for all contacts in a particular
    contactgroup.
    """
    return send_command("ENABLE_CONTACTGROUP_HOST_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        contactgroup_name)

def disable_contactgroup_host_notifications(contactgroup_name, 
                                            command_file=None, 
                                            timestamp=0):
    """
    Disables host notifications for all contacts in a particular
    contactgroup.
    """
    return send_command("DISABLE_CONTACTGROUP_HOST_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        contactgroup_name)

def enable_contactgroup_svc_notifications(contactgroup_name, 
                                          command_file=None, 
                                          timestamp=0):
    """
    Enables service notifications for all contacts in a particular
    contactgroup.
    """
    return send_command("ENABLE_CONTACTGROUP_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        contactgroup_name)

def disable_contactgroup_svc_notifications(contactgroup_name, 
                                           command_file=None, 
                                           timestamp=0):
    """
    Disables service notifications for all contacts in a particular
    contactgroup.
    """
    return send_command("DISABLE_CONTACTGROUP_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        contactgroup_name)

def enable_host_notifications(host_name, 
                              command_file=None, 
                              timestamp=0):
    """
    Enables notifications for a particular host.  Notifications will
    be sent out for the host only if notifications are enabled on a
    program-wide basis as well.
    """
    return send_command("ENABLE_HOST_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        host_name)

def disable_svc_flap_detection(host_name, 
                               service_description, 
                               command_file=None, 
                               timestamp=0):
    """
    Disables flap detection for the specified service.
    """
    return send_command("DISABLE_SVC_FLAP_DETECTION",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def change_svc_notification_timeperiod(host_name, 
                                       service_description, 
                                       notification_timeperiod, 
                                       command_file=None, 
                                       timestamp=0):
    """
    Changes the notification timeperiod for a particular service to
    what is specified by the "notification_timeperiod" option.  The
    "notification_timeperiod" option should be the short name of the
    timeperiod that is to be used as the service notification
    timeperiod.  The timeperiod must have been configured in Nagios
    before it was last (re)started.
    """
    return send_command("CHANGE_SVC_NOTIFICATION_TIMEPERIOD",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        notification_timeperiod)

def change_contact_svc_notification_timeperiod(contact_name, 
                                               notification_timeperiod, 
                                               command_file=None, 
                                               timestamp=0):
    """
    Changes the service notification timeperiod for a particular
    contact to what is specified by the "notification_timeperiod"
    option.  The "notification_timeperiod" option should be the
    short name of the timeperiod that is to be used as the contact's
    service notification timeperiod.  The timeperiod must have been
    configured in Nagios before it was last (re)started.
    """
    return send_command("CHANGE_CONTACT_SVC_NOTIFICATION_TIMEPERIOD",
                        command_file,
                        timestamp,
                        contact_name, 
                        notification_timeperiod)

def change_contact_host_notification_timeperiod(contact_name, 
                                                notification_timeperiod, 
                                                command_file=None, 
                                                timestamp=0):
    """
    Changes the host notification timeperiod for a particular
    contact to what is specified by the "notification_timeperiod"
    option.  The "notification_timeperiod" option should be the
    short name of the timeperiod that is to be used as the contact's
    host notification timeperiod.  The timeperiod must have been
    configured in Nagios before it was last (re)started.
    """
    return send_command("CHANGE_CONTACT_HOST_NOTIFICATION_TIMEPERIOD",
                        command_file,
                        timestamp,
                        contact_name, 
                        notification_timeperiod)

def change_host_modattr(host_name, 
                        value, 
                        command_file=None, 
                        timestamp=0):
    """
    This command changes the modified attributes value for the
    specified host.  Modified attributes values are used by Nagios
    to determine which object properties should be retained across
    program restarts.  Thus, modifying the value of the attributes
    can affect data retention.  This is an advanced option and
    should only be used by people who are intimately familiar with
    the data retention logic in Nagios.
    """
    return send_command("CHANGE_HOST_MODATTR",
                        command_file,
                        timestamp,
                        host_name, 
                        value)

def change_svc_modattr(host_name, 
                       service_description, 
                       value, 
                       command_file=None, 
                       timestamp=0):
    """
    This command changes the modified attributes value for the
    specified service.  Modified attributes values are used by
    Nagios to determine which object properties should be retained
    across program restarts.  Thus, modifying the value of the
    attributes can affect data retention.  This is an advanced
    option and should only be used by people who are intimately
    familiar with the data retention logic in Nagios.
    """
    return send_command("CHANGE_SVC_MODATTR",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        value)

def change_contact_modattr(contact_name, 
                           value, 
                           command_file=None, 
                           timestamp=0):
    """
    This command changes the modified attributes value for the
    specified contact.  Modified attributes values are used by
    Nagios to determine which object properties should be retained
    across program restarts.  Thus, modifying the value of the
    attributes can affect data retention.  This is an advanced
    option and should only be used by people who are intimately
    familiar with the data retention logic in Nagios.
    """
    return send_command("CHANGE_CONTACT_MODATTR",
                        command_file,
                        timestamp,
                        contact_name, 
                        value)

def change_contact_modhattr(contact_name, 
                            value, 
                            command_file=None, 
                            timestamp=0):
    """
    This command changes the modified host attributes value for the
    specified contact.  Modified attributes values are used by
    Nagios to determine which object properties should be retained
    across program restarts.  Thus, modifying the value of the
    attributes can affect data retention.  This is an advanced
    option and should only be used by people who are intimately
    familiar with the data retention logic in Nagios.
    """
    return send_command("CHANGE_CONTACT_MODHATTR",
                        command_file,
                        timestamp,
                        contact_name, 
                        value)

def change_contact_modsattr(contact_name, 
                            value, 
                            command_file=None, 
                            timestamp=0):
    """
    This command changes the modified service attributes value for
    the specified contact.  Modified attributes values are used by
    Nagios to determine which object properties should be retained
    across program restarts.  Thus, modifying the value of the
    attributes can affect data retention.  This is an advanced
    option and should only be used by people who are intimately
    familiar with the data retention logic in Nagios.
    """
    return send_command("CHANGE_CONTACT_MODSATTR",
                        command_file,
                        timestamp,
                        contact_name, 
                        value)

def disable_host_notifications(host_name, 
                               command_file=None, 
                               timestamp=0):
    """
    Disables notifications for a particular host.
    """
    return send_command("DISABLE_HOST_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        host_name)

def enable_all_notifications_beyond_host(host_name, 
                                         command_file=None, 
                                         timestamp=0):
    """
    Enables notifications for all hosts and services "beyond" (e.g.
    on all child hosts of) the specified host.  The current
    notification setting for the specified host is not affected.
    Notifications will only be sent out for these hosts and services
    if notifications are also enabled on a program-wide basis.
    """
    return send_command("ENABLE_ALL_NOTIFICATIONS_BEYOND_HOST",
                        command_file,
                        timestamp,
                        host_name)

def disable_all_notifications_beyond_host(host_name, 
                                          command_file=None, 
                                          timestamp=0):
    """
    Disables notifications for all hosts and services "beyond" (e.g.
    on all child hosts of) the specified host.  The current
    notification setting for the specified host is not affected.
    """
    return send_command("DISABLE_ALL_NOTIFICATIONS_BEYOND_HOST",
                        command_file,
                        timestamp,
                        host_name)

def enable_host_and_child_notifications(host_name, 
                                        command_file=None, 
                                        timestamp=0):
    """
    Enables notifications for the specified host, as well as all
    hosts "beyond" (e.g. on all child hosts of) the specified host.
    Notifications will only be sent out for these hosts if
    notifications are also enabled on a program-wide basis.
    """
    return send_command("ENABLE_HOST_AND_CHILD_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        host_name)

def add_svc_comment(host_name, 
                    service_description, 
                    persistent, 
                    author, 
                    comment, 
                    command_file=None, 
                    timestamp=0):
    """
    Adds a comment to a particular service.  If the "persistent"
    field is set to zero (0), the comment will be deleted the next
    time Nagios is restarted.  Otherwise, the comment will persist
    across program restarts until it is deleted manually.
    """
    return send_command("ADD_SVC_COMMENT",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        persistent, 
                        author, 
                        comment)

def disable_host_and_child_notifications(host_name, 
                                         command_file=None, 
                                         timestamp=0):
    """
    Disables notifications for the specified host, as well as all
    hosts "beyond" (e.g. on all child hosts of) the specified host.
    """
    return send_command("DISABLE_HOST_AND_CHILD_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        host_name)

def set_host_notification_number(host_name, 
                                 notification_number, 
                                 command_file=None, 
                                 timestamp=0):
    """
    Sets the current notification number for a particular host.  A
    value of 0 indicates that no notification has yet been sent for
    the current host problem.  Useful for forcing an escalation
    (based on notification number) or replicating notification
    information in redundant monitoring environments. Notification
    numbers greater than zero have no noticeable affect on the
    notification process if the host is currently in an UP state.
    """
    return send_command("SET_HOST_NOTIFICATION_NUMBER",
                        command_file,
                        timestamp,
                        host_name, 
                        notification_number)

def set_svc_notification_number(host_name, 
                                service_description, 
                                notification_number, 
                                command_file=None, 
                                timestamp=0):
    """
    Sets the current notification number for a particular service.
    A value of 0 indicates that no notification has yet been sent
    for the current service problem.  Useful for forcing an
    escalation (based on notification number) or replicating
    notification information in redundant monitoring environments.
    Notification numbers greater than zero have no noticeable affect
    on the notification process if the service is currently in an OK
    state.
    """
    return send_command("SET_SVC_NOTIFICATION_NUMBER",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        notification_number)

def enable_service_freshness_checks(command_file=None, 
                                    timestamp=0):
    """
    Enables freshness checks of all services on a program-wide
    basis.  Individual services that have freshness checks disabled
    will not be checked for freshness.
    """
    return send_command("ENABLE_SERVICE_FRESHNESS_CHECKS",
                        command_file,
                        timestamp,
                        )

def enable_host_freshness_checks(command_file=None, 
                                 timestamp=0):
    """
    Enables freshness checks of all hosts on a program-wide basis.
    Individual hosts that have freshness checks disabled will not be
    checked for freshness.
    """
    return send_command("ENABLE_HOST_FRESHNESS_CHECKS",
                        command_file,
                        timestamp,
                        )

def disable_service_freshness_checks(command_file=None, 
                                     timestamp=0):
    """
    Disables freshness checks of all services on a program-wide
    basis.
    """
    return send_command("DISABLE_SERVICE_FRESHNESS_CHECKS",
                        command_file,
                        timestamp,
                        )

def disable_host_freshness_checks(command_file=None, 
                                  timestamp=0):
    """
    Disables freshness checks of all hosts on a program-wide basis.
    """
    return send_command("DISABLE_HOST_FRESHNESS_CHECKS",
                        command_file,
                        timestamp,
                        )

def schedule_and_propagate_triggered_host_downtime(host_name, 
                                                   start_time, 
                                                   end_time, 
                                                   fixed, 
                                                   trigger_id, 
                                                   duration, 
                                                   author, 
                                                   comment, 
                                                   command_file=None, 
                                                   timestamp=0):
    """
    Schedules downtime for a specified host and all of its children
    (hosts).  If the "fixed" argument is set to one (1), downtime
    will start and end at the times specified by the "start" and
    "end" arguments.  Otherwise, downtime will begin between the
    "start" and "end" times and last for "duration" seconds.  The
    "start" and "end" arguments are specified in time_t format
    (seconds since the UNIX epoch).  Downtime for child hosts are
    all set to be triggered by the downtime for the specified
    (parent) host.  The specified (parent) host downtime can be
    triggered by another downtime entry if the "trigger_id" is set
    to the ID of another scheduled downtime entry.  Set the
    "trigger_id" argument to zero (0) if the downtime for the
    specified (parent) host should not be triggered by another
    downtime entry.
    """
    return send_command("SCHEDULE_AND_PROPAGATE_TRIGGERED_HOST_DOWNTIME",
                        command_file,
                        timestamp,
                        host_name, 
                        start_time, 
                        end_time, 
                        fixed, 
                        trigger_id, 
                        duration, 
                        author, 
                        comment)

def schedule_and_propagate_host_downtime(host_name, 
                                         start_time, 
                                         end_time, 
                                         fixed, 
                                         trigger_id, 
                                         duration, 
                                         author, 
                                         comment, 
                                         command_file=None, 
                                         timestamp=0):
    """
    Schedules downtime for a specified host and all of its children
    (hosts).  If the "fixed" argument is set to one (1), downtime
    will start and end at the times specified by the "start" and
    "end" arguments.  Otherwise, downtime will begin between the
    "start" and "end" times and last for "duration" seconds.  The
    "start" and "end" arguments are specified in time_t format
    (seconds since the UNIX epoch).  The specified (parent) host
    downtime can be triggered by another downtime entry if the
    "trigger_id" is set to the ID of another scheduled downtime
    entry.  Set the "trigger_id" argument to zero (0) if the
    downtime for the specified (parent) host should not be triggered
    by another downtime entry.
    """
    return send_command("SCHEDULE_AND_PROPAGATE_HOST_DOWNTIME",
                        command_file,
                        timestamp,
                        host_name, 
                        start_time, 
                        end_time, 
                        fixed, 
                        trigger_id, 
                        duration, 
                        author, 
                        comment)

def schedule_svc_check(host_name, 
                       service_description, 
                       check_time, 
                       command_file=None, 
                       timestamp=0):
    """
    Schedules the next active check of a specified service at
    "check_time".  The "check_time" argument is specified in time_t
    format (seconds since the UNIX epoch).  Note that the service
    may not actually be checked at the time you specify.  This could
    occur for a number of reasons: active checks are disabled on a
    program-wide or service-specific basis, the service is already
    scheduled to be checked at an earlier time, etc.  If you want to
    force the service check to occur at the time you specify, look
    at the SCHEDULE_FORCED_SVC_CHECK command.
    """
    return send_command("SCHEDULE_SVC_CHECK",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        check_time)

def del_host_comment(comment_id, 
                     command_file=None, 
                     timestamp=0):
    """
    Deletes a host comment.  The id number of the comment that is to
    be deleted must be specified.
    """
    return send_command("DEL_HOST_COMMENT",
                        command_file,
                        timestamp,
                        comment_id)

def schedule_host_svc_checks(host_name, 
                             check_time, 
                             command_file=None, 
                             timestamp=0):
    """
    Schedules the next active check of all services on a particular
    host at "check_time".  The "check_time" argument is specified in
    time_t format (seconds since the UNIX epoch).  Note that the
    services may not actually be checked at the time you specify.
    This could occur for a number of reasons: active checks are
    disabled on a program-wide or service-specific basis, the
    services are already scheduled to be checked at an earlier time,
    etc.  If you want to force the service checks to occur at the
    time you specify, look at the SCHEDULE_FORCED_HOST_SVC_CHECKS
    command.
    """
    return send_command("SCHEDULE_HOST_SVC_CHECKS",
                        command_file,
                        timestamp,
                        host_name, 
                        check_time)

def save_state_information(command_file=None, 
                           timestamp=0):
    """
    Causes Nagios to save all current monitoring status information
    to the state retention file.  Normally, state retention
    information is saved before the Nagios process shuts down and
    (potentially) at regularly scheduled intervals.  This command
    allows you to force Nagios to save this information to the state
    retention file immediately.  This does not affect the current
    status information in the Nagios process.
    """
    return send_command("SAVE_STATE_INFORMATION",
                        command_file,
                        timestamp,
                        )

def read_state_information(command_file=None, 
                           timestamp=0):
    """
    Causes Nagios to load all current monitoring status information
    from the state retention file.  Normally, state retention
    information is loaded when the Nagios process starts up and
    before it starts monitoring.  WARNING: This command will cause
    Nagios to discard all current monitoring status information and
    use the information stored in state retention file!  Use with
    care.
    """
    return send_command("READ_STATE_INFORMATION",
                        command_file,
                        timestamp,
                        )

def enable_host_svc_checks(host_name, 
                           command_file=None, 
                           timestamp=0):
    """
    Enables active checks of all services on the specified host.
    """
    return send_command("ENABLE_HOST_SVC_CHECKS",
                        command_file,
                        timestamp,
                        host_name)

def disable_host_svc_checks(host_name, 
                            command_file=None, 
                            timestamp=0):
    """
    Enables active checks of all services on the specified host.
    """
    return send_command("DISABLE_HOST_SVC_CHECKS",
                        command_file,
                        timestamp,
                        host_name)

def enable_host_svc_notifications(host_name, 
                                  command_file=None, 
                                  timestamp=0):
    """
    Enables notifications for all services on the specified host.
    Note that notifications will not be sent out if notifications
    are disabled on a program-wide basis.
    """
    return send_command("ENABLE_HOST_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        host_name)

def disable_host_svc_notifications(host_name, 
                                   command_file=None, 
                                   timestamp=0):
    """
    Disables notifications for all services on the specified host.
    """
    return send_command("DISABLE_HOST_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        host_name)

def delay_svc_notification(host_name, 
                           service_description, 
                           notification_time, 
                           command_file=None, 
                           timestamp=0):
    """
    Delays the next notification for a parciular service until
    "notification_time".  The "notification_time" argument is
    specified in time_t format (seconds since the UNIX epoch).  Note
    that this will only have an affect if the service stays in the
    same problem state that it is currently in.  If the service
    changes to another state, a new notification may go out before
    the time you specify in the "notification_time" argument.
    """
    return send_command("DELAY_SVC_NOTIFICATION",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        notification_time)

def delay_host_notification(host_name, 
                            notification_time, 
                            command_file=None, 
                            timestamp=0):
    """
    Delays the next notification for a parciular service until
    "notification_time".  The "notification_time" argument is
    specified in time_t format (seconds since the UNIX epoch).  Note
    that this will only have an affect if the service stays in the
    same problem state that it is currently in.  If the service
    changes to another state, a new notification may go out before
    the time you specify in the "notification_time" argument.
    """
    return send_command("DELAY_HOST_NOTIFICATION",
                        command_file,
                        timestamp,
                        host_name, 
                        notification_time)

def acknowledge_host_problem(host_name, 
                             sticky, 
                             notify, 
                             persistent, 
                             author, 
                             comment, 
                             command_file=None, 
                             timestamp=0):
    """
    Allows you to acknowledge the current problem for the specified
    host.  By acknowledging the current problem, future
    notifications (for the same host state) are disabled.  If the
    "sticky" option is set to one (1), the acknowledgement will
    remain until the host returns to an UP state.  Otherwise the
    acknowledgement will automatically be removed when the host
    changes state.  If the "notify" option is set to one (1), a
    notification will be sent out to contacts indicating that the
    current host problem has been acknowledged.  If the "persistent"
    option is set to one (1), the comment associated with the
    acknowledgement will survive across restarts of the Nagios
    process.  If not, the comment will be deleted the next time
    Nagios restarts.
    """
    return send_command("ACKNOWLEDGE_HOST_PROBLEM",
                        command_file,
                        timestamp,
                        host_name, 
                        sticky, 
                        notify, 
                        persistent, 
                        author, 
                        comment)

def del_svc_comment(comment_id, 
                    command_file=None, 
                    timestamp=0):
    """
    Deletes a service comment.  The id number of the comment that is
    to be deleted must be specified.
    """
    return send_command("DEL_SVC_COMMENT",
                        command_file,
                        timestamp,
                        comment_id)

def acknowledge_svc_problem(host_name, 
                            service_description, 
                            sticky, 
                            notify, 
                            persistent, 
                            author, 
                            comment, 
                            command_file=None, 
                            timestamp=0):
    """
    Allows you to acknowledge the current problem for the specified
    service.  By acknowledging the current problem, future
    notifications (for the same servicestate) are disabled.  If the
    "sticky" option is set to one (1), the acknowledgement will
    remain until the service returns to an OK state.  Otherwise the
    acknowledgement will automatically be removed when the service
    changes state.  If the "notify" option is set to one (1), a
    notification will be sent out to contacts indicating that the
    current service problem has been acknowledged.  If the
    "persistent" option is set to one (1), the comment associated
    with the acknowledgement will survive across restarts of the
    Nagios process.  If not, the comment will be deleted the next
    time Nagios restarts.
    """
    return send_command("ACKNOWLEDGE_SVC_PROBLEM",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description, 
                        sticky, 
                        notify, 
                        persistent, 
                        author, 
                        comment)

def start_executing_svc_checks(command_file=None, 
                               timestamp=0):
    """
    Enables active checks of services on a program-wide basis.
    """
    return send_command("START_EXECUTING_SVC_CHECKS",
                        command_file,
                        timestamp,
                        )

def stop_executing_svc_checks(command_file=None, 
                              timestamp=0):
    """
    Disables active checks of services on a program-wide basis.
    """
    return send_command("STOP_EXECUTING_SVC_CHECKS",
                        command_file,
                        timestamp,
                        )

def start_accepting_passive_svc_checks(command_file=None, 
                                       timestamp=0):
    """
    Enables passive service checks on a program-wide basis.
    """
    return send_command("START_ACCEPTING_PASSIVE_SVC_CHECKS",
                        command_file,
                        timestamp,
                        )

def stop_accepting_passive_svc_checks(command_file=None, 
                                      timestamp=0):
    """
    Disables passive service checks on a program-wide basis.
    """
    return send_command("STOP_ACCEPTING_PASSIVE_SVC_CHECKS",
                        command_file,
                        timestamp,
                        )

def enable_passive_svc_checks(host_name, 
                              service_description, 
                              command_file=None, 
                              timestamp=0):
    """
    Enables passive checks for the specified service.
    """
    return send_command("ENABLE_PASSIVE_SVC_CHECKS",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def disable_passive_svc_checks(host_name, 
                               service_description, 
                               command_file=None, 
                               timestamp=0):
    """
    Disables passive checks for the specified service.
    """
    return send_command("DISABLE_PASSIVE_SVC_CHECKS",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def enable_event_handlers(command_file=None, 
                          timestamp=0):
    """
    Enables host and service event handlers on a program-wide basis.
    """
    return send_command("ENABLE_EVENT_HANDLERS",
                        command_file,
                        timestamp,
                        )

def disable_event_handlers(command_file=None, 
                           timestamp=0):
    """
    Disables host and service event handlers on a program-wide
    basis.
    """
    return send_command("DISABLE_EVENT_HANDLERS",
                        command_file,
                        timestamp,
                        )

def enable_host_event_handler(host_name, 
                              command_file=None, 
                              timestamp=0):
    """
    Enables the event handler for the specified host.
    """
    return send_command("ENABLE_HOST_EVENT_HANDLER",
                        command_file,
                        timestamp,
                        host_name)

def enable_svc_check(host_name, 
                     service_description, 
                     command_file=None, 
                     timestamp=0):
    """
    Enables active checks for a particular service.
    """
    return send_command("ENABLE_SVC_CHECK",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def disable_host_event_handler(host_name, 
                               command_file=None, 
                               timestamp=0):
    """
    Disables the event handler for the specified host.
    """
    return send_command("DISABLE_HOST_EVENT_HANDLER",
                        command_file,
                        timestamp,
                        host_name)

def enable_svc_event_handler(host_name, 
                             service_description, 
                             command_file=None, 
                             timestamp=0):
    """
    Enables the event handler for the specified service.
    """
    return send_command("ENABLE_SVC_EVENT_HANDLER",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def disable_svc_event_handler(host_name, 
                              service_description, 
                              command_file=None, 
                              timestamp=0):
    """
    Disables the event handler for the specified service.
    """
    return send_command("DISABLE_SVC_EVENT_HANDLER",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def enable_host_check(host_name, 
                      command_file=None, 
                      timestamp=0):
    """
    Enables (regularly scheduled and on-demand) active checks of the
    specified host.
    """
    return send_command("ENABLE_HOST_CHECK",
                        command_file,
                        timestamp,
                        host_name)

def disable_host_check(host_name, 
                       command_file=None, 
                       timestamp=0):
    """
    Disables (regularly scheduled and on-demand) active checks of
    the specified host.
    """
    return send_command("DISABLE_HOST_CHECK",
                        command_file,
                        timestamp,
                        host_name)

def start_obsessing_over_svc_checks(command_file=None, 
                                    timestamp=0):
    """
    Enables processing of service checks via the OCSP command on a
    program-wide basis.
    """
    return send_command("START_OBSESSING_OVER_SVC_CHECKS",
                        command_file,
                        timestamp,
                        )

def stop_obsessing_over_svc_checks(command_file=None, 
                                   timestamp=0):
    """
    Disables processing of service checks via the OCSP command on a
    program-wide basis.
    """
    return send_command("STOP_OBSESSING_OVER_SVC_CHECKS",
                        command_file,
                        timestamp,
                        )

def start_obsessing_over_host_checks(command_file=None, 
                                     timestamp=0):
    """
    Enables processing of host checks via the OCHP command on a
    program-wide basis.
    """
    return send_command("START_OBSESSING_OVER_HOST_CHECKS",
                        command_file,
                        timestamp,
                        )

def stop_obsessing_over_host_checks(command_file=None, 
                                    timestamp=0):
    """
    Disables processing of host checks via the OCHP command on a
    program-wide basis.
    """
    return send_command("STOP_OBSESSING_OVER_HOST_CHECKS",
                        command_file,
                        timestamp,
                        )

def start_obsessing_over_host(host_name, 
                              command_file=None, 
                              timestamp=0):
    """
    Enables processing of host checks via the OCHP command for the
    specified host.
    """
    return send_command("START_OBSESSING_OVER_HOST",
                        command_file,
                        timestamp,
                        host_name)

def disable_svc_check(host_name, 
                      service_description, 
                      command_file=None, 
                      timestamp=0):
    """
    Disables active checks for a particular service.
    """
    return send_command("DISABLE_SVC_CHECK",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def stop_obsessing_over_host(host_name, 
                             command_file=None, 
                             timestamp=0):
    """
    Disables processing of host checks via the OCHP command for the
    specified host.
    """
    return send_command("STOP_OBSESSING_OVER_HOST",
                        command_file,
                        timestamp,
                        host_name)

def start_obsessing_over_svc(host_name, 
                             service_description, 
                             command_file=None, 
                             timestamp=0):
    """
    Enables processing of service checks via the OCSP command for
    the specified service.
    """
    return send_command("START_OBSESSING_OVER_SVC",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def stop_obsessing_over_svc(host_name, 
                            service_description, 
                            command_file=None, 
                            timestamp=0):
    """
    Disables processing of service checks via the OCSP command for
    the specified service.
    """
    return send_command("STOP_OBSESSING_OVER_SVC",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def enable_failure_prediction(command_file=None, 
                              timestamp=0):
    """
    Enables failure prediction on a program-wide basis.  This
    feature is not currently implemented in Nagios.
    """
    return send_command("ENABLE_FAILURE_PREDICTION",
                        command_file,
                        timestamp,
                        )

def disable_failure_prediction(command_file=None, 
                               timestamp=0):
    """
    Disables failure prediction on a program-wide basis.  This
    feature is not currently implemented in Nagios.
    """
    return send_command("DISABLE_FAILURE_PREDICTION",
                        command_file,
                        timestamp,
                        )

def enable_performance_data(command_file=None, 
                            timestamp=0):
    """
    Enables the processing of host and service performance data on a
    program-wide basis.
    """
    return send_command("ENABLE_PERFORMANCE_DATA",
                        command_file,
                        timestamp,
                        )

def disable_performance_data(command_file=None, 
                             timestamp=0):
    """
    Disables the processing of host and service performance data on
    a program-wide basis.
    """
    return send_command("DISABLE_PERFORMANCE_DATA",
                        command_file,
                        timestamp,
                        )

def start_executing_host_checks(command_file=None, 
                                timestamp=0):
    """
    Enables active host checks on a program-wide basis.
    """
    return send_command("START_EXECUTING_HOST_CHECKS",
                        command_file,
                        timestamp,
                        )

def stop_executing_host_checks(command_file=None, 
                               timestamp=0):
    """
    Disables active host checks on a program-wide basis.
    """
    return send_command("STOP_EXECUTING_HOST_CHECKS",
                        command_file,
                        timestamp,
                        )

def start_accepting_passive_host_checks(command_file=None, 
                                        timestamp=0):
    """
    Enables acceptance and processing of passive host checks on a
    program-wide basis.
    """
    return send_command("START_ACCEPTING_PASSIVE_HOST_CHECKS",
                        command_file,
                        timestamp,
                        )

def disable_notifications(command_file=None, 
                          timestamp=0):
    """
    Disables host and service notifications on a program-wide basis.
    """
    return send_command("DISABLE_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        )

def stop_accepting_passive_host_checks(command_file=None, 
                                       timestamp=0):
    """
    Disables acceptance and processing of passive host checks on a
    program-wide basis.
    """
    return send_command("STOP_ACCEPTING_PASSIVE_HOST_CHECKS",
                        command_file,
                        timestamp,
                        )

def enable_passive_host_checks(host_name, 
                               command_file=None, 
                               timestamp=0):
    """
    Enables acceptance and processing of passive host checks for the
    specified host.
    """
    return send_command("ENABLE_PASSIVE_HOST_CHECKS",
                        command_file,
                        timestamp,
                        host_name)

def disable_passive_host_checks(host_name, 
                                command_file=None, 
                                timestamp=0):
    """
    Disables acceptance and processing of passive host checks for
    the specified host.
    """
    return send_command("DISABLE_PASSIVE_HOST_CHECKS",
                        command_file,
                        timestamp,
                        host_name)

def enable_flap_detection(command_file=None, 
                          timestamp=0):
    """
    Enables host and service flap detection on a program-wide basis.
    """
    return send_command("ENABLE_FLAP_DETECTION",
                        command_file,
                        timestamp,
                        )

def disable_flap_detection(command_file=None, 
                           timestamp=0):
    """
    Disables host and service flap detection on a program-wide
    basis.
    """
    return send_command("DISABLE_FLAP_DETECTION",
                        command_file,
                        timestamp,
                        )

def enable_host_flap_detection(host_name, 
                               command_file=None, 
                               timestamp=0):
    """
    Enables flap detection for the specified host.  In order for the
    flap detection algorithms to be run for the host, flap detection
    must be enabled on a program-wide basis as well.
    """
    return send_command("ENABLE_HOST_FLAP_DETECTION",
                        command_file,
                        timestamp,
                        host_name)

def enable_svc_flap_detection(host_name, 
                              service_description, 
                              command_file=None, 
                              timestamp=0):
    """
    Enables flap detection for the specified service.  In order for
    the flap detection algorithms to be run for the service, flap
    detection must be enabled on a program-wide basis as well.
    """
    return send_command("ENABLE_SVC_FLAP_DETECTION",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def disable_host_flap_detection(host_name, 
                                command_file=None, 
                                timestamp=0):
    """
    Disables flap detection for the specified host.
    """
    return send_command("DISABLE_HOST_FLAP_DETECTION",
                        command_file,
                        timestamp,
                        host_name)

def disable_service_flap_detection(host_name, 
                                   service_description, 
                                   command_file=None, 
                                   timestamp=0):
    """
    Disables flap detection for the specified service.
    """
    return send_command("DISABLE_SERVICE_FLAP_DETECTION",
                        command_file,
                        timestamp,
                        host_name, 
                        service_description)

def enable_hostgroup_svc_notifications(hostgroup_name, 
                                       command_file=None, 
                                       timestamp=0):
    """
    Enables notifications for all services that are associated with
    hosts in a particular hostgroup.  This does not enable
    notifications for the hosts in the hostgroup - see the
    ENABLE_HOSTGROUP_HOST_NOTIFICATIONS command for that.  In order
    for notifications to be sent out for these services,
    notifications must be enabled on a program-wide basis as well.
    """
    return send_command("ENABLE_HOSTGROUP_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def enable_notifications(command_file=None, 
                         timestamp=0):
    """
    Enables host and service notifications on a program-wide basis.
    """
    return send_command("ENABLE_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        )

def disable_hostgroup_svc_notifications(hostgroup_name, 
                                        command_file=None, 
                                        timestamp=0):
    """
    Disables notifications for all services associated with hosts in
    a particular hostgroup.  This does not disable notifications for
    the hosts in the hostgroup - see the
    DISABLE_HOSTGROUP_HOST_NOTIFICATIONS command for that.
    """
    return send_command("DISABLE_HOSTGROUP_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def enable_hostgroup_host_notifications(hostgroup_name, 
                                        command_file=None, 
                                        timestamp=0):
    """
    Enables notifications for all hosts in a particular hostgroup.
    This does not enable notifications for the services associated
    with the hosts in the hostgroup - see the
    ENABLE_HOSTGROUP_SVC_NOTIFICATIONS command for that.  In order
    for notifications to be sent out for these hosts, notifications
    must be enabled on a program-wide basis as well.
    """
    return send_command("ENABLE_HOSTGROUP_HOST_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def disable_hostgroup_host_notifications(hostgroup_name, 
                                         command_file=None, 
                                         timestamp=0):
    """
    Disables notifications for all hosts in a particular hostgroup.
    This does not disable notifications for the services associated
    with the hosts in the hostgroup - see the
    DISABLE_HOSTGROUP_SVC_NOTIFICATIONS command for that.
    """
    return send_command("DISABLE_HOSTGROUP_HOST_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def enable_hostgroup_svc_checks(hostgroup_name, 
                                command_file=None, 
                                timestamp=0):
    """
    Enables active checks for all services associated with hosts in
    a particular hostgroup.
    """
    return send_command("ENABLE_HOSTGROUP_SVC_CHECKS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def disable_hostgroup_svc_checks(hostgroup_name, 
                                 command_file=None, 
                                 timestamp=0):
    """
    Disables active checks for all services associated with hosts in
    a particular hostgroup.
    """
    return send_command("DISABLE_HOSTGROUP_SVC_CHECKS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def enable_hostgroup_host_checks(hostgroup_name, 
                                 command_file=None, 
                                 timestamp=0):
    """
    Enables active checks for all hosts in a particular hostgroup.
    """
    return send_command("ENABLE_HOSTGROUP_HOST_CHECKS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def disable_hostgroup_host_checks(hostgroup_name, 
                                  command_file=None, 
                                  timestamp=0):
    """
    Disables active checks for all hosts in a particular hostgroup.
    """
    return send_command("DISABLE_HOSTGROUP_HOST_CHECKS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def enable_hostgroup_passive_host_checks(hostgroup_name, 
                                         command_file=None, 
                                         timestamp=0):
    """
    Enables passive checks for all hosts in a particular hostgroup.
    """
    return send_command("ENABLE_HOSTGROUP_PASSIVE_HOST_CHECKS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def disable_hostgroup_passive_host_checks(hostgroup_name, 
                                          command_file=None, 
                                          timestamp=0):
    """
    Disables passive checks for all hosts in a particular hostgroup.
    """
    return send_command("DISABLE_HOSTGROUP_PASSIVE_HOST_CHECKS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def enable_hostgroup_passive_svc_checks(hostgroup_name, 
                                        command_file=None, 
                                        timestamp=0):
    """
    Enables passive checks for all services associated with hosts in
    a particular hostgroup.
    """
    return send_command("ENABLE_HOSTGROUP_PASSIVE_SVC_CHECKS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def restart_program(command_file=None, 
                    timestamp=0):
    """
    Restarts the Nagios process.
    """
    return send_command("RESTART_PROGRAM",
                        command_file,
                        timestamp,
                        )

def disable_hostgroup_passive_svc_checks(hostgroup_name, 
                                         command_file=None, 
                                         timestamp=0):
    """
    Disables passive checks for all services associated with hosts
    in a particular hostgroup.
    """
    return send_command("DISABLE_HOSTGROUP_PASSIVE_SVC_CHECKS",
                        command_file,
                        timestamp,
                        hostgroup_name)

def enable_servicegroup_svc_notifications(servicegroup_name, 
                                          command_file=None, 
                                          timestamp=0):
    """
    Enables notifications for all services that are members of a
    particular servicegroup.  In order for notifications to be sent
    out for these services, notifications must also be enabled on a
    program-wide basis.
    """
    return send_command("ENABLE_SERVICEGROUP_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def disable_servicegroup_svc_notifications(servicegroup_name, 
                                           command_file=None, 
                                           timestamp=0):
    """
    Disables notifications for all services that are members of a
    particular servicegroup.
    """
    return send_command("DISABLE_SERVICEGROUP_SVC_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def enable_servicegroup_host_notifications(servicegroup_name, 
                                           command_file=None, 
                                           timestamp=0):
    """
    Enables notifications for all hosts that have services that are
    members of a particular servicegroup.  In order for
    notifications to be sent out for these hosts, notifications must
    also be enabled on a program-wide basis.
    """
    return send_command("ENABLE_SERVICEGROUP_HOST_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def disable_servicegroup_host_notifications(servicegroup_name, 
                                            command_file=None, 
                                            timestamp=0):
    """
    Disables notifications for all hosts that have services that are
    members of a particular servicegroup.
    """
    return send_command("DISABLE_SERVICEGROUP_HOST_NOTIFICATIONS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def enable_servicegroup_svc_checks(servicegroup_name, 
                                   command_file=None, 
                                   timestamp=0):
    """
    Enables active checks for all services in a particular
    servicegroup.
    """
    return send_command("ENABLE_SERVICEGROUP_SVC_CHECKS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def disable_servicegroup_svc_checks(servicegroup_name, 
                                    command_file=None, 
                                    timestamp=0):
    """
    Disables active checks for all services in a particular
    servicegroup.
    """
    return send_command("DISABLE_SERVICEGROUP_SVC_CHECKS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def enable_servicegroup_host_checks(servicegroup_name, 
                                    command_file=None, 
                                    timestamp=0):
    """
    Enables active checks for all hosts that have services that are
    members of a particular hostgroup.
    """
    return send_command("ENABLE_SERVICEGROUP_HOST_CHECKS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def disable_servicegroup_host_checks(servicegroup_name, 
                                     command_file=None, 
                                     timestamp=0):
    """
    Disables active checks for all hosts that have services that are
    members of a particular hostgroup.
    """
    return send_command("DISABLE_SERVICEGROUP_HOST_CHECKS",
                        command_file,
                        timestamp,
                        servicegroup_name)

def enable_servicegroup_passive_svc_checks(servicegroup_name, 
                                           command_file=None, 
                                           timestamp=0):
    """
    Enables the acceptance and processing of passive checks for all
    services in a particular servicegroup.
    """
    return send_command("ENABLE_SERVICEGROUP_PASSIVE_SVC_CHECKS",
                        command_file,
                        timestamp,
                        servicegroup_name)

########NEW FILE########
__FILENAME__ = generate_external_command
#!/usr/bin/python
#
# This script will autogenerate python functions to communicate with the python command file.
# input to the program is the documentation from nagios

import BeautifulSoup
import sys
import textwrap

for filename in sys.argv[1:]:
    html = open(filename).read()

    soup = BeautifulSoup.BeautifulSoup(html,  convertEntities='html')

    # First get the command format we need:
    tmp = soup.find('td', {'class':'MediumBold'})
    command_format = tmp.findNext().getText()

    # command_format should look something like this:
    # u'ENABLE_SVC_EVENT_HANDLER;&lt;host_name&gt;;&lt;service_description&gt;'

    # there is a bug in the documentation, where one semicolon is missing, lets adjust:
    command_format = command_format.replace('><','>;<')
    command_format = command_format.replace('service_desription','service_description')
    

    command_format = command_format.replace('<', '',).replace('>','')
    command_format = command_format.split(';')
    func = command_format[0]
    # Lets convert function name to lowercase to be polite
    args = command_format[1:]


    # Now we have the command format, lets find the description text
    description = tmp.findParent().findNextSibling().findNextSibling().findNextSibling().findNextSibling().getText()
    
    # Let's PEP8 the description
    wrapper = textwrap.TextWrapper()
    wrapper.initial_indent = '    '
    wrapper.subsequent_indent = '    '
    wrapper.width = 68
    description = '\n'.join(['\n'.join(wrapper.wrap(block)) for block in description.splitlines()])


    strFunction = """
def %s(%s):
    \"\"\"
%s
    \"\"\"
    return send_command("%s",
                        command_file,
                        timestamp,
                        %s)"""
    args.extend(['command_file=None', 'timestamp=0'])
    defSpaces = ' ' * (5 + len(func))
    returnSpaces = ' ' * 24
    argSplitter = ', \n' + defSpaces
    strFunction = strFunction % (func.lower(), argSplitter.join(args), description, func, ', \n                        '.join(args[0:-2]))
    strFunction = strFunction.replace('(, ','(')
    print strFunction

########NEW FILE########
__FILENAME__ = all_attributes
# These are gathered from Nagios Object Definition documentation (Version 3.2.3)

object_definitions = {}
object_definitions["any"] = {}
object_definitions["any"]["use"] = { "name":"use", "required":"optional", "value":"use" }
object_definitions["any"]["register"] = { "name":"register", "required":"optional", "value":"register" }
object_definitions["any"]["name"] = { "name":"name", "required":"optional", "value":"name" }
object_definitions["host"] = {}
object_definitions["host"]["host_name"] = { "name":"host_name", "required":"required", "value":"host_name" }
object_definitions["host"]["alias"] = { "name":"alias", "required":"required", "value":"alias" }
object_definitions["host"]["display_name"] = { "name":"display_name", "required":"optional", "value":"display_name" }
object_definitions["host"]["address"] = { "name":"address", "required":"required", "value":"address" }
object_definitions["host"]["parents"] = { "name":"parents", "required":"optional", "value":"host_names" }
object_definitions["host"]["hostgroups"] = { "name":"hostgroups", "required":"optional", "value":"hostgroup_names" }
object_definitions["host"]["check_command"] = { "name":"check_command", "required":"optional", "value":"command_name" }
object_definitions["host"]["initial_state"] = { "name":"initial_state", "required":"optional", "value":"[o,d,u]" }
object_definitions["host"]["max_check_attempts"] = { "name":"max_check_attempts", "required":"required", "value":"#" }
object_definitions["host"]["check_interval"] = { "name":"check_interval", "required":"optional", "value":"#" }
object_definitions["host"]["retry_interval"] = { "name":"retry_interval", "required":"optional", "value":"#" }
object_definitions["host"]["active_checks_enabled"] = { "name":"active_checks_enabled", "required":"optional", "value":"[0/1]" }
object_definitions["host"]["passive_checks_enabled"] = { "name":"passive_checks_enabled", "required":"optional", "value":"[0/1]" }
object_definitions["host"]["check_period"] = { "name":"check_period", "required":"required", "value":"timeperiod_name" }
object_definitions["host"]["obsess_over_host"] = { "name":"obsess_over_host", "required":"optional", "value":"[0/1]" }
object_definitions["host"]["check_freshness"] = { "name":"check_freshness", "required":"optional", "value":"[0/1]" }
object_definitions["host"]["freshness_threshold"] = { "name":"freshness_threshold", "required":"optional", "value":"#" }
object_definitions["host"]["event_handler"] = { "name":"event_handler", "required":"optional", "value":"command_name" }
object_definitions["host"]["event_handler_enabled"] = { "name":"event_handler_enabled", "required":"optional", "value":"[0/1]" }
object_definitions["host"]["low_flap_threshold"] = { "name":"low_flap_threshold", "required":"optional", "value":"#" }
object_definitions["host"]["high_flap_threshold"] = { "name":"high_flap_threshold", "required":"optional", "value":"#" }
object_definitions["host"]["flap_detection_enabled"] = { "name":"flap_detection_enabled", "required":"optional", "value":"[0/1]" }
object_definitions["host"]["flap_detection_options"] = { "name":"flap_detection_options", "required":"optional", "value":"[o,d,u]" }
object_definitions["host"]["process_perf_data"] = { "name":"process_perf_data", "required":"optional", "value":"[0/1]" }
object_definitions["host"]["retain_status_information"] = { "name":"retain_status_information", "required":"optional", "value":"[0/1]" }
object_definitions["host"]["retain_nonstatus_information"] = { "name":"retain_nonstatus_information", "required":"optional", "value":"[0/1]" }
object_definitions["host"]["contacts"] = { "name":"contacts", "required":"required", "value":"contacts" }
object_definitions["host"]["contact_groups"] = { "name":"contact_groups", "required":"required", "value":"contact_groups" }
object_definitions["host"]["notification_interval"] = { "name":"notification_interval", "required":"required", "value":"#" }
object_definitions["host"]["first_notification_delay"] = { "name":"first_notification_delay", "required":"optional", "value":"#" }
object_definitions["host"]["notification_period"] = { "name":"notification_period", "required":"required", "value":"timeperiod_name" }
object_definitions["host"]["notification_options"] = { "name":"notification_options", "required":"optional", "value":"[d,u,r,f,s]" }
object_definitions["host"]["notifications_enabled"] = { "name":"notifications_enabled", "required":"optional", "value":"[0/1]" }
object_definitions["host"]["stalking_options"] = { "name":"stalking_options", "required":"optional", "value":"[o,d,u]" }
object_definitions["host"]["notes"] = { "name":"notes", "required":"optional", "value":"note_string" }
object_definitions["host"]["notes_url"] = { "name":"notes_url", "required":"optional", "value":"url" }
object_definitions["host"]["action_url"] = { "name":"action_url", "required":"optional", "value":"url" }
object_definitions["host"]["icon_image"] = { "name":"icon_image", "required":"optional", "value":"image_file" }
object_definitions["host"]["icon_image_alt"] = { "name":"icon_image_alt", "required":"optional", "value":"alt_string" }
object_definitions["host"]["vrml_image"] = { "name":"vrml_image", "required":"optional", "value":"image_file" }
object_definitions["host"]["statusmap_image"] = { "name":"statusmap_image", "required":"optional", "value":"image_file" }
object_definitions["host"]["2d_coords"] = { "name":"2d_coords", "required":"optional", "value":"x_coord,y_coord" }
object_definitions["host"]["3d_coords"] = { "name":"3d_coords", "required":"optional", "value":"x_coord,y_coord,z_coord" }
object_definitions["hostgroup"] = {}
object_definitions["hostgroup"]["hostgroup_name"] = { "name":"hostgroup_name", "required":"required", "value":"hostgroup_name" }
object_definitions["hostgroup"]["alias"] = { "name":"alias", "required":"required", "value":"alias" }
object_definitions["hostgroup"]["members"] = { "name":"members", "required":"optional", "value":"hosts" }
object_definitions["hostgroup"]["hostgroup_members"] = { "name":"hostgroup_members", "required":"optional", "value":"hostgroups" }
object_definitions["hostgroup"]["notes"] = { "name":"notes", "required":"optional", "value":"note_string" }
object_definitions["hostgroup"]["notes_url"] = { "name":"notes_url", "required":"optional", "value":"url" }
object_definitions["hostgroup"]["action_url"] = { "name":"action_url", "required":"optional", "value":"url" }
object_definitions["service"] = {}
object_definitions["service"]["host_name"] = { "name":"host_name", "required":"required", "value":"host_name" }
object_definitions["service"]["hostgroup_name"] = { "name":"hostgroup_name", "required":"optional", "value":"hostgroup_name" }
object_definitions["service"]["service_description"] = { "name":"service_description", "required":"required", "value":"service_description" }
object_definitions["service"]["display_name"] = { "name":"display_name", "required":"optional", "value":"display_name" }
object_definitions["service"]["servicegroups"] = { "name":"servicegroups", "required":"optional", "value":"servicegroup_names" }
object_definitions["service"]["is_volatile"] = { "name":"is_volatile", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["check_command"] = { "name":"check_command", "required":"required", "value":"command_name" }
object_definitions["service"]["initial_state"] = { "name":"initial_state", "required":"optional", "value":"[o,w,u,c]" }
object_definitions["service"]["max_check_attempts"] = { "name":"max_check_attempts", "required":"required", "value":"#" }
object_definitions["service"]["check_interval"] = { "name":"check_interval", "required":"required", "value":"#" }
object_definitions["service"]["retry_interval"] = { "name":"retry_interval", "required":"required", "value":"#" }
object_definitions["service"]["active_checks_enabled"] = { "name":"active_checks_enabled", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["passive_checks_enabled"] = { "name":"passive_checks_enabled", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["check_period"] = { "name":"check_period", "required":"required", "value":"timeperiod_name" }
object_definitions["service"]["obsess_over_service"] = { "name":"obsess_over_service", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["check_freshness"] = { "name":"check_freshness", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["freshness_threshold"] = { "name":"freshness_threshold", "required":"optional", "value":"#" }
object_definitions["service"]["event_handler"] = { "name":"event_handler", "required":"optional", "value":"command_name" }
object_definitions["service"]["event_handler_enabled"] = { "name":"event_handler_enabled", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["low_flap_threshold"] = { "name":"low_flap_threshold", "required":"optional", "value":"#" }
object_definitions["service"]["high_flap_threshold"] = { "name":"high_flap_threshold", "required":"optional", "value":"#" }
object_definitions["service"]["flap_detection_enabled"] = { "name":"flap_detection_enabled", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["flap_detection_options"] = { "name":"flap_detection_options", "required":"optional", "value":"[o,w,c,u]" }
object_definitions["service"]["process_perf_data"] = { "name":"process_perf_data", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["retain_status_information"] = { "name":"retain_status_information", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["retain_nonstatus_information"] = { "name":"retain_nonstatus_information", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["notification_interval"] = { "name":"notification_interval", "required":"required", "value":"#" }
object_definitions["service"]["first_notification_delay"] = { "name":"first_notification_delay", "required":"optional", "value":"#" }
object_definitions["service"]["notification_period"] = { "name":"notification_period", "required":"required", "value":"timeperiod_name" }
object_definitions["service"]["notification_options"] = { "name":"notification_options", "required":"optional", "value":"[w,u,c,r,f,s]" }
object_definitions["service"]["notifications_enabled"] = { "name":"notifications_enabled", "required":"optional", "value":"[0/1]" }
object_definitions["service"]["contacts"] = { "name":"contacts", "required":"required", "value":"contacts" }
object_definitions["service"]["contact_groups"] = { "name":"contact_groups", "required":"required", "value":"contact_groups" }
object_definitions["service"]["stalking_options"] = { "name":"stalking_options", "required":"optional", "value":"[o,w,u,c]" }
object_definitions["service"]["notes"] = { "name":"notes", "required":"optional", "value":"note_string" }
object_definitions["service"]["notes_url"] = { "name":"notes_url", "required":"optional", "value":"url" }
object_definitions["service"]["action_url"] = { "name":"action_url", "required":"optional", "value":"url" }
object_definitions["service"]["icon_image"] = { "name":"icon_image", "required":"optional", "value":"image_file" }
object_definitions["service"]["icon_image_alt"] = { "name":"icon_image_alt", "required":"optional", "value":"alt_string" }
object_definitions["servicegroup"] = {}
object_definitions["servicegroup"]["servicegroup_name"] = { "name":"servicegroup_name", "required":"required", "value":"servicegroup_name" }
object_definitions["servicegroup"]["alias"] = { "name":"alias", "required":"required", "value":"alias" }
object_definitions["servicegroup"]["members"] = { "name":"members", "required":"optional", "value":"services" }
object_definitions["servicegroup"]["servicegroup_members"] = { "name":"servicegroup_members", "required":"optional", "value":"servicegroups" }
object_definitions["servicegroup"]["notes"] = { "name":"notes", "required":"optional", "value":"note_string" }
object_definitions["servicegroup"]["notes_url"] = { "name":"notes_url", "required":"optional", "value":"url" }
object_definitions["servicegroup"]["action_url"] = { "name":"action_url", "required":"optional", "value":"url" }
object_definitions["contact"] = {}
object_definitions["contact"]["contact_name"] = { "name":"contact_name", "required":"required", "value":"contact_name" }
object_definitions["contact"]["alias"] = { "name":"alias", "required":"optional", "value":"alias" }
object_definitions["contact"]["contactgroups"] = { "name":"contactgroups", "required":"optional", "value":"contactgroup_names" }
object_definitions["contact"]["host_notifications_enabled"] = { "name":"host_notifications_enabled", "required":"required", "value":"[0/1]" }
object_definitions["contact"]["service_notifications_enabled"] = { "name":"service_notifications_enabled", "required":"required", "value":"[0/1]" }
object_definitions["contact"]["host_notification_period"] = { "name":"host_notification_period", "required":"required", "value":"timeperiod_name" }
object_definitions["contact"]["service_notification_period"] = { "name":"service_notification_period", "required":"required", "value":"timeperiod_name" }
object_definitions["contact"]["host_notification_options"] = { "name":"host_notification_options", "required":"required", "value":"[d,u,r,f,s,n]" }
object_definitions["contact"]["service_notification_options"] = { "name":"service_notification_options", "required":"required", "value":"[w,u,c,r,f,s,n]" }
object_definitions["contact"]["host_notification_commands"] = { "name":"host_notification_commands", "required":"required", "value":"command_name" }
object_definitions["contact"]["service_notification_commands"] = { "name":"service_notification_commands", "required":"required", "value":"command_name" }
object_definitions["contact"]["email"] = { "name":"email", "required":"optional", "value":"email_address" }
object_definitions["contact"]["pager"] = { "name":"pager", "required":"optional", "value":"pager_number or pager_email_gateway" }
object_definitions["contact"]["address"] = { "name":"address", "required":"optional", "value":"additional_contact_address" }
object_definitions["contact"]["can_submit_commands"] = { "name":"can_submit_commands", "required":"optional", "value":"[0/1]" }
object_definitions["contact"]["retain_status_information"] = { "name":"retain_status_information", "required":"optional", "value":"[0/1]" }
object_definitions["contact"]["retain_nonstatus_information"] = { "name":"retain_nonstatus_information", "required":"optional", "value":"[0/1]" }
object_definitions["contactgroup"] = {}
object_definitions["contactgroup"]["contactgroup_name"] = { "name":"contactgroup_name", "required":"required", "value":"contactgroup_name" }
object_definitions["contactgroup"]["alias"] = { "name":"alias", "required":"required", "value":"alias" }
object_definitions["contactgroup"]["members"] = { "name":"members", "required":"optional", "value":"contacts" }
object_definitions["contactgroup"]["contactgroup_members"] = { "name":"contactgroup_members", "required":"optional", "value":"contactgroups" }
object_definitions["timeperiod"] = {}
object_definitions["timeperiod"]["timeperiod_name"] = { "name":"timeperiod_name", "required":"required", "value":"timeperiod_name" }
object_definitions["timeperiod"]["alias"] = { "name":"alias", "required":"required", "value":"alias" }
object_definitions["timeperiod"]["[weekday]"] = { "name":"[weekday]", "required":"optional", "value":"timeranges" }
object_definitions["timeperiod"]["[exception]"] = { "name":"[exception]", "required":"optional", "value":"timeranges" }
object_definitions["timeperiod"]["exclude"] = { "name":"exclude", "required":"optional", "value":"]" }
object_definitions["command"] = {}
object_definitions["command"]["command_name"] = { "name":"command_name", "required":"required", "value":"command_name" }
object_definitions["command"]["command_line"] = { "name":"command_line", "required":"required", "value":"command_line" }
object_definitions["servicedependency"] = {}
object_definitions["servicedependency"]["dependent_host_name"] = { "name":"dependent_host_name", "required":"required", "value":"host_name" }
object_definitions["servicedependency"]["dependent_hostgroup_name"] = { "name":"dependent_hostgroup_name", "required":"optional", "value":"hostgroup_name" }
object_definitions["servicedependency"]["dependent_service_description"] = { "name":"dependent_service_description", "required":"required", "value":"service_description" }
object_definitions["servicedependency"]["host_name"] = { "name":"host_name", "required":"required", "value":"host_name" }
object_definitions["servicedependency"]["hostgroup_name"] = { "name":"hostgroup_name", "required":"optional", "value":"hostgroup_name" }
object_definitions["servicedependency"]["service_description"] = { "name":"service_description", "required":"required", "value":"service_description" }
object_definitions["servicedependency"]["inherits_parent"] = { "name":"inherits_parent", "required":"optional", "value":"[0/1]" }
object_definitions["servicedependency"]["execution_failure_criteria"] = { "name":"execution_failure_criteria", "required":"optional", "value":"[o,w,u,c,p,n]" }
object_definitions["servicedependency"]["notification_failure_criteria"] = { "name":"notification_failure_criteria", "required":"optional", "value":"[o,w,u,c,p,n]" }
object_definitions["servicedependency"]["dependency_period"] = { "name":"dependency_period", "required":"optional", "value":"timeperiod_name" }
object_definitions["serviceescalation"] = {}
object_definitions["serviceescalation"]["host_name"] = { "name":"host_name", "required":"required", "value":"host_name" }
object_definitions["serviceescalation"]["hostgroup_name"] = { "name":"hostgroup_name", "required":"optional", "value":"hostgroup_name" }
object_definitions["serviceescalation"]["service_description"] = { "name":"service_description", "required":"required", "value":"service_description" }
object_definitions["serviceescalation"]["contacts"] = { "name":"contacts", "required":"required", "value":"contacts" }
object_definitions["serviceescalation"]["contact_groups"] = { "name":"contact_groups", "required":"required", "value":"contactgroup_name" }
object_definitions["serviceescalation"]["first_notification"] = { "name":"first_notification", "required":"required", "value":"#" }
object_definitions["serviceescalation"]["last_notification"] = { "name":"last_notification", "required":"required", "value":"#" }
object_definitions["serviceescalation"]["notification_interval"] = { "name":"notification_interval", "required":"required", "value":"#" }
object_definitions["serviceescalation"]["escalation_period"] = { "name":"escalation_period", "required":"optional", "value":"timeperiod_name" }
object_definitions["serviceescalation"]["escalation_options"] = { "name":"escalation_options", "required":"optional", "value":"[w,u,c,r]" }
object_definitions["hostdependency"] = {}
object_definitions["hostdependency"]["dependent_host_name"] = { "name":"dependent_host_name", "required":"required", "value":"host_name" }
object_definitions["hostdependency"]["dependent_hostgroup_name"] = { "name":"dependent_hostgroup_name", "required":"optional", "value":"hostgroup_name" }
object_definitions["hostdependency"]["host_name"] = { "name":"host_name", "required":"required", "value":"host_name" }
object_definitions["hostdependency"]["hostgroup_name"] = { "name":"hostgroup_name", "required":"optional", "value":"hostgroup_name" }
object_definitions["hostdependency"]["inherits_parent"] = { "name":"inherits_parent", "required":"optional", "value":"[0/1]" }
object_definitions["hostdependency"]["execution_failure_criteria"] = { "name":"execution_failure_criteria", "required":"optional", "value":"[o,d,u,p,n]" }
object_definitions["hostdependency"]["notification_failure_criteria"] = { "name":"notification_failure_criteria", "required":"optional", "value":"[o,d,u,p,n]" }
object_definitions["hostdependency"]["dependency_period"] = { "name":"dependency_period", "required":"optional", "value":"timeperiod_name" }
object_definitions["hostescalation"] = {}
object_definitions["hostescalation"]["host_name"] = { "name":"host_name", "required":"required", "value":"host_name" }
object_definitions["hostescalation"]["hostgroup_name"] = { "name":"hostgroup_name", "required":"optional", "value":"hostgroup_name" }
object_definitions["hostescalation"]["contacts"] = { "name":"contacts", "required":"required", "value":"contacts" }
object_definitions["hostescalation"]["contact_groups"] = { "name":"contact_groups", "required":"required", "value":"contactgroup_name" }
object_definitions["hostescalation"]["first_notification"] = { "name":"first_notification", "required":"required", "value":"#" }
object_definitions["hostescalation"]["last_notification"] = { "name":"last_notification", "required":"required", "value":"#" }
object_definitions["hostescalation"]["notification_interval"] = { "name":"notification_interval", "required":"required", "value":"#" }
object_definitions["hostescalation"]["escalation_period"] = { "name":"escalation_period", "required":"optional", "value":"timeperiod_name" }
object_definitions["hostescalation"]["escalation_options"] = { "name":"escalation_options", "required":"optional", "value":"[d,u,r]" }
object_definitions["hostextinfo"] = {}
object_definitions["hostextinfo"]["host_name"] = { "name":"host_name", "required":"required", "value":"host_name" }
object_definitions["hostextinfo"]["notes"] = { "name":"notes", "required":"optional", "value":"note_string" }
object_definitions["hostextinfo"]["notes_url"] = { "name":"notes_url", "required":"optional", "value":"url" }
object_definitions["hostextinfo"]["action_url"] = { "name":"action_url", "required":"optional", "value":"url" }
object_definitions["hostextinfo"]["icon_image"] = { "name":"icon_image", "required":"optional", "value":"image_file" }
object_definitions["hostextinfo"]["icon_image_alt"] = { "name":"icon_image_alt", "required":"optional", "value":"alt_string" }
object_definitions["hostextinfo"]["vrml_image"] = { "name":"vrml_image", "required":"optional", "value":"image_file" }
object_definitions["hostextinfo"]["statusmap_image"] = { "name":"statusmap_image", "required":"optional", "value":"image_file" }
object_definitions["hostextinfo"]["2d_coords"] = { "name":"2d_coords", "required":"optional", "value":"x_coord,y_coord" }
object_definitions["hostextinfo"]["3d_coords"] = { "name":"3d_coords", "required":"optional", "value":"x_coord,y_coord,z_coord" }
object_definitions["serviceextinfo"] = {}
object_definitions["serviceextinfo"]["host_name"] = { "name":"host_name", "required":"required", "value":"host_name" }
object_definitions["serviceextinfo"]["service_description"] = { "name":"service_description", "required":"required", "value":"service_description" }
object_definitions["serviceextinfo"]["notes"] = { "name":"notes", "required":"optional", "value":"note_string" }
object_definitions["serviceextinfo"]["notes_url"] = { "name":"notes_url", "required":"optional", "value":"url" }
object_definitions["serviceextinfo"]["action_url"] = { "name":"action_url", "required":"optional", "value":"url" }
object_definitions["serviceextinfo"]["icon_image"] = { "name":"icon_image", "required":"optional", "value":"image_file" }
object_definitions["serviceextinfo"]["icon_image_alt"] = { "name":"icon_image_alt", "required":"optional", "value":"alt_string" }
# Generated via examples/Model/parse-configmain.py
main_config = {'accept_passive_host_checks': {'doc': 'This option determines whether or not Nagios will accept <a href="passivechecks.html">passive host checks</a> when it initially (re)starts.  If this option is disabled, Nagios will not accept any passive host checks.  Note: If you have <a href="#retain_state_information">state retention</a> enabled, Nagios will ignore this setting when it (re)starts and use the last known setting for this option (as stored in the <a href="#state_retention_file">state retention file</a>), <i>unless</i> you disable the <a href="#use_retained_program_state">use_retained_program_state</a> option.  If you want to change this option when state retention is active (and the <a href="#use_retained_program_state">use_retained_program_state</a> is enabled), you\'ll have to use the appropriate <a href="extcommands.html">external command</a> or change it via the web interface.  Values are as follows: ',
                                'examples': ['accept_passive_host_checks=1'],
                                'format': 'accept_passive_host_checks=&lt;0/1&gt;',
                                'options': ["0 = Don't accept passive host checks",
                                            '1 = Accept passive host checks (default)'],
                                'title': 'Passive Host Check Acceptance Option'},
 'accept_passive_service_checks': {'doc': 'This option determines whether or not Nagios will accept <a href="passivechecks.html">passive service checks</a> when it initially (re)starts.  If this option is disabled, Nagios will not accept any passive service checks.  Note: If you have <a href="#retain_state_information">state retention</a> enabled, Nagios will ignore this setting when it (re)starts and use the last known setting for this option (as stored in the <a href="#state_retention_file">state retention file</a>), <i>unless</i> you disable the <a href="#use_retained_program_state">use_retained_program_state</a> option.  If you want to change this option when state retention is active (and the <a href="#use_retained_program_state">use_retained_program_state</a> is enabled), you\'ll have to use the appropriate <a href="extcommands.html">external command</a> or change it via the web interface.  Values are as follows: ',
                                   'examples': ['accept_passive_service_checks=1'],
                                   'format': 'accept_passive_service_checks=&lt;0/1&gt;',
                                   'options': ["0 = Don't accept passive service checks",
                                               '1 = Accept passive service checks (default)'],
                                   'title': 'Passive Service Check Acceptance Option'},
 'additional_freshness_latency': {'doc': 'This option determines the number of seconds Nagios will add to any host or services freshness threshold it automatically calculates (e.g. those not specified explicity by the user).  More information on freshness checking can be found <a href="freshness.html">here</a>. ',
                                  'examples': ['additional_freshness_latency=15'],
                                  'format': 'additional_freshness_latency=&lt;#&gt;',
                                  'options': [],
                                  'title': 'Additional Freshness Threshold Latency Option'},
 'admin_email': {'doc': 'This is the email address for the administrator of the local machine (i.e. the one that Nagios is running on). This value can be used in notification commands by using the <b>$ADMINEMAIL$</b> <a href="macros.html">macro</a>. ',
                 'examples': ['admin_email=root@localhost.localdomain'],
                 'format': 'admin_email=&lt;email_address&gt;',
                 'options': [],
                 'title': 'Administrator Email Address'},
 'admin_pager': {'doc': 'This is the pager number (or pager email gateway) for the administrator of the local machine (i.e. the one that Nagios is running on). The pager number/address can be used in notification commands by using the <b>$ADMINPAGER$</b> <a href="macros.html">macro</a>. ',
                 'examples': ['admin_pager=pageroot@localhost.localdomain'],
                 'format': 'admin_pager=&lt;pager_number_or_pager_email_gateway&gt;',
                 'options': [],
                 'title': 'Administrator Pager'},
 'auto_reschedule_checks': {'doc': 'This option determines whether or not Nagios will attempt to automatically reschedule active host and service checks to  "smooth" them out over time.  This can help to balance the load on the monitoring server, as it will attempt to keep the time between consecutive checks consistent, at the expense of executing checks on a more rigid schedule. <strong>WARNING:</strong>  THIS IS AN EXPERIMENTAL FEATURE AND MAY BE REMOVED IN FUTURE VERSIONS.  ENABLING THIS OPTION CAN DEGRADE PERFORMANCE - RATHER THAN INCREASE IT - IF USED IMPROPERLY! ',
                            'examples': ['auto_reschedule_checks=1'],
                            'format': 'auto_reschedule_checks=&lt;0/1&gt;',
                            'options': [],
                            'title': 'Auto-Rescheduling Option'},
 'auto_rescheduling_interval': {'doc': 'This option determines how often (in seconds) Nagios will attempt to automatically reschedule checks.  This option only has an effect if the <a href="#auto_reschedule_checks">auto_reschedule_checks</a> option is enabled.  Default is 30 seconds. <strong>WARNING:</strong>  THIS IS AN EXPERIMENTAL FEATURE AND MAY BE REMOVED IN FUTURE VERSIONS.  ENABLING THE AUTO-RESCHEDULING OPTION CAN DEGRADE PERFORMANCE - RATHER THAN INCREASE IT - IF USED IMPROPERLY! ',
                                'examples': ['auto_rescheduling_interval=30'],
                                'format': 'auto_rescheduling_interval=&lt;seconds&gt;',
                                'options': [],
                                'title': 'Auto-Rescheduling Interval'},
 'auto_rescheduling_window': {'doc': 'This option determines the "window" of time (in seconds) that Nagios will look at when automatically rescheduling checks. Only host and service checks that occur in the next X seconds (determined by this variable) will be rescheduled.  This option only has an effect if the <a href="#auto_reschedule_checks">auto_reschedule_checks</a> option is enabled.  Default is 180 seconds (3 minutes). <strong>WARNING:</strong>  THIS IS AN EXPERIMENTAL FEATURE AND MAY BE REMOVED IN FUTURE VERSIONS.  ENABLING THE AUTO-RESCHEDULING OPTION CAN DEGRADE PERFORMANCE - RATHER THAN INCREASE IT - IF USED IMPROPERLY! ',
                              'examples': ['auto_rescheduling_window=180'],
                              'format': 'auto_rescheduling_window=&lt;seconds&gt;',
                              'options': [],
                              'title': 'Auto-Rescheduling Window'},
 'bare_update_checks': {'doc': 'This option deterines what data Nagios will send to api.nagios.org when it checks for updates.  By default, Nagios will send information on the current version of Nagios you have installed, as well as an indicator as to whether this was a new installation or not.  Nagios Enterprises uses this data to determine the number of users running specific version of Nagios.  Enable this option if you do not wish for this information to be sent. ',
                        'examples': ['bare_update_checks'],
                        'format': 'bare_update_checks=&lt;0/1&gt;',
                        'options': [],
                        'title': 'Bare Update Checks'},
 'broker_module': {'doc': 'This directive is used to specify an event broker module that should by loaded by Nagios at startup.  Use multiple directives if you want to load more than one module.  Arguments that should be passed to the module at startup are seperated from the module path by a space. !!! WARNING !!! Do NOT overwrite modules while they are being used by Nagios or Nagios will crash in a fiery display of SEGFAULT glory.  This is a bug/limitation either in dlopen(), the kernel, and/or the filesystem.  And maybe Nagios... The correct/safe way of updating a module is by using one of these methods: ',
                   'examples': ['broker_module=/usr/local/nagios/bin/ndomod.o cfg_file=/usr/local/nagios/etc/ndomod.cfg'],
                   'format': 'broker_module=&lt;modulepath&gt; [moduleargs]',
                   'options': ['Shutdown Nagios, replace the module file, restart Nagios</li>',
                               'While Nagios is running... delete the original module file, move the new module file into place, restart Nagios</li>'],
                   'title': 'Event Broker Modules'},
 'cached_host_check_horizon': {'doc': 'This option determines the maximum amount of time (in seconds) that the state of a previous host check is considered current.  Cached host states (from host checks that were performed more recently than the time specified by this value) can improve host check performance immensely.  Too high of a value for this option may result in (temporarily) inaccurate host states, while a low value may result in a performance hit for host checks.  Use a value of 0 if you want to disable host check caching.  More information on cached checks can be found <a href="cachedchecks.html">here</a>. ',
                               'examples': ['cached_host_check_horizon=15'],
                               'format': 'cached_host_check_horizon=&lt;seconds&gt;',
                               'options': [],
                               'title': 'Cached Host Check Horizon'},
 'cached_service_check_horizon': {'doc': 'This option determines the maximum amount of time (in seconds) that the state of a previous service check is considered current.  Cached service states (from service checks that were performed more recently than the time specified by this value) can improve service check performance when a lot of <a href="objectdefinitions.html#servicedependency">service dependencies</a> are used.  Too high of a value for this option may result in inaccuracies in the service dependency logic.  Use a value of 0 if you want to disable service check caching.  More information on cached checks can be found <a href="cachedchecks.html">here</a>. ',
                                  'examples': ['cached_service_check_horizon=15'],
                                  'format': 'cached_service_check_horizon=&lt;seconds&gt;',
                                  'options': [],
                                  'title': 'Cached Service Check Horizon'},
 'cfg_dir': {'doc': 'This directive is used to specify a directory which contains <a href="configobject.html">object configuration files</a> that Nagios should use for monitoring.  All files in the directory with a <i>.cfg</i> extension are processed as object config files.  Additionally, Nagios will recursively process all config files in subdirectories of the directory you specify here.  You can seperate your configuration files into different directories and specify multiple <i>cfg_dir=</i> statements to have all config files in each directory processed. ',
             'examples': ['cfg_dir=/usr/local/nagios/etc/commands',
                          'cfg_dir=/usr/local/nagios/etc/services',
                          'cfg_dir=/usr/local/nagios/etc/hosts'],
             'format': 'cfg_dir=&lt;directory_name&gt;',
             'options': [],
             'title': 'Object Configuration Directory'},
 'cfg_file': {'doc': 'This directive is used to specify an <a href="configobject.html">object configuration file</a> containing object definitions that Nagios should use for monitoring.  Object configuration files contain definitions for hosts, host groups, contacts, contact groups, services, commands, etc.  You can seperate your configuration information into several files and specify multiple <i>cfg_file=</i> statements to have each of them processed. ',
              'examples': ['cfg_file=/usr/local/nagios/etc/hosts.cfg',
                           'cfg_file=/usr/local/nagios/etc/services.cfg',
                           'cfg_file=/usr/local/nagios/etc/commands.cfg'],
              'format': 'cfg_file=&lt;file_name&gt;',
              'options': [],
              'title': 'Object Configuration File'},
 'check_external_commands': {'doc': 'This option determines whether or not Nagios will check the <a href="#command_file">command file</a> for  commands that should be executed.  This option must be enabled if you plan on using the <a href="cgis.html#cmd_cgi">command CGI</a> to issue commands via the web interface. More information on external commands can be found <a href="extcommands.html">here</a>. ',
                             'examples': ['check_external_commands=1'],
                             'format': 'check_external_commands=&lt;0/1&gt;',
                             'options': ["0 = Don't check external commands",
                                         '1 = Check external commands (default)'],
                             'title': 'External Command Check Option'},
 'check_for_orphaned_hosts': {'doc': 'This option allows you to enable or disable checks for orphaned hoste checks. Orphaned host checks are checks which have been executed and have been removed from the event queue, but have not had any results reported in a long time.  Since no results have come back in for the host, it is not rescheduled in the event queue.  This can cause host checks to stop being executed.  Normally it is very rare for this to happen - it might happen if an external user or process killed off the process that was being used to execute a host check.  If this option is enabled and Nagios finds that results for a particular host check have not come back, it will log an error message and reschedule the host check.  If you start seeing host checks that never seem to get rescheduled, enable this option and see if you notice any log messages about orphaned hosts. ',
                              'examples': ['check_for_orphaned_hosts=1'],
                              'format': 'check_for_orphaned_hosts=&lt;0/1&gt;',
                              'options': ["0 = Don't check for orphaned host checks",
                                          '1 = Check for orphaned host checks (default)'],
                              'title': 'Orphaned Host Check Option'},
 'check_for_orphaned_services': {'doc': 'This option allows you to enable or disable checks for orphaned service checks. Orphaned service checks are checks which have been executed and have been removed from the event queue, but have not had any results reported in a long time.  Since no results have come back in for the service, it is not rescheduled in the event queue.  This can cause service checks to stop being executed.  Normally it is very rare for this to happen - it might happen if an external user or process killed off the process that was being used to execute a service check.  If this option is enabled and Nagios finds that results for a particular service check have not come back, it will log an error message and reschedule the service check.  If you start seeing service checks that never seem to get rescheduled, enable this option and see if you notice any log messages about orphaned services. ',
                                 'examples': ['check_for_orphaned_services=1'],
                                 'format': 'check_for_orphaned_services=&lt;0/1&gt;',
                                 'options': ["0 = Don't check for orphaned service checks",
                                             '1 = Check for orphaned service checks (default)'],
                                 'title': 'Orphaned Service Check Option'},
 'check_for_updates': {'doc': 'This option determines whether Nagios will automatically check to see if new updates (releases) are available.  It is recommend that you enable this option to ensure that you stay on top of the latest critical patches to Nagios.  Nagios is critical to you - make sure you keep it in good shape.  Nagios will check once a day for new updates. Data collected by Nagios Enterprises from the update check is processed in accordance  with our privacy policy - see <a href="http://api.nagios.org">http://api.nagios.org</a> for details. ',
                       'examples': ['check_for_updates=1'],
                       'format': 'check_for_updates=&lt;0/1&gt;',
                       'options': [],
                       'title': 'Update Checks'},
 'check_host_freshness': {'doc': 'This option determines whether or not Nagios will periodically check the "freshness" of host checks.  Enabling this option is useful for helping to ensure that <a href="passivechecks.html">passive host checks</a> are received in a timely manner.  More information on freshness checking can be found <a href="freshness.html">here</a>. ',
                          'examples': ['check_host_freshness=0'],
                          'format': 'check_host_freshness=&lt;0/1&gt;',
                          'options': ["0 = Don't check host freshness",
                                      '1 = Check host freshness (default)'],
                          'title': 'Host Freshness Checking Option'},
 'check_result_path': {'doc': 'This options determines which directory Nagios will use to temporarily store host and service check results before they are processed.  This directory should not be used to store any other files, as Nagios will periodically clean this directory of old file (see the <a href="#max_check_result_file_age">max_check_result_file_age</a> option for more information). Note: Make sure that only a single instance of Nagios has access to the check result path.  If multiple instances of Nagios have their check result path set to the same directory, you will run into problems with check results being processed (incorrectly) by the wrong instance of Nagios! ',
                       'examples': ['check_result_path=/var/spool/nagios/checkresults'],
                       'format': 'check_result_path=&lt;path&gt;',
                       'options': [],
                       'title': 'Check Result Path'},
 'check_result_reaper_frequency': {'doc': 'This option allows you to control the frequency <i>in seconds</i> of check result "reaper" events.  "Reaper" events process the results from host and service checks that have finished executing.  These events consitute the core of the monitoring logic in Nagios. ',
                                   'examples': ['check_result_reaper_frequency=5'],
                                   'format': 'check_result_reaper_frequency=&lt;frequency_in_seconds&gt;',
                                   'options': [],
                                   'title': 'Check Result Reaper Frequency'},
 'check_service_freshness': {'doc': 'This option determines whether or not Nagios will periodically check the "freshness" of service checks.  Enabling this option is useful for helping to ensure that <a href="passivechecks.html">passive service checks</a> are received in a timely manner.  More information on freshness checking can be found <a href="freshness.html">here</a>. ',
                             'examples': ['check_service_freshness=0'],
                             'format': 'check_service_freshness=&lt;0/1&gt;',
                             'options': ["0 = Don't check service freshness",
                                         '1 = Check service freshness (default)'],
                             'title': 'Service Freshness Checking Option'},
 'child_processes_fork_twice': {'doc': 'This option determines whether or not Nagios will fork() child processes twice when it executes host and service checks.  By default, Nagios fork()s twice.  However, if the <a href="#use_large_installation_tweaks">use_large_installation_tweaks</a> option is enabled, it will only fork() once.  By defining this option in your configuration file, you are able to override things to get the behavior you want. ',
                                'examples': ['child_processes_fork_twice=0'],
                                'format': 'child_processes_fork_twice=&lt;0/1&gt;',
                                'options': ['0 = Fork() just once',
                                            '1 = Fork() twice'],
                                'title': 'Child Processes Fork Twice'},
 'command_check_interval': {'doc': 'If you specify a number with an "s" appended to it (i.e. 30s), this is the number of <i>seconds</i> to wait between external command checks.  If you leave off the "s", this is the number of "time units" to wait between external command checks. Unless you\'ve changed the <a href="#interval_length">interval_length</a> value (as defined below) from the default value of 60, this number will mean minutes.   Note: By setting this value to <b>-1</b>, Nagios will check for external commands as often as possible.  Each time Nagios checks for external commands it will read and process all commands present in the <a href="#command_file">command file</a> before continuing on with its other duties.  More information on external commands can be found <a href="extcommands.html">here</a>. ',
                            'examples': ['command_check_interval=1'],
                            'format': 'command_check_interval=&lt;xxx&gt;[s]',
                            'options': [],
                            'title': 'External Command Check Interval'},
 'command_file': {'doc': 'This is the file that Nagios will check for external commands to process.  The <a href="cgis.html#cmd_cgi">command CGI</a> writes commands to this file.  The external command file is implemented as a named pipe (FIFO), which is created when Nagios starts and removed when it shuts down.  If the file exists when Nagios starts, the Nagios process will terminate with an error message.  More information on external commands can be found <a href="extcommands.html">here</a>. ',
                  'examples': ['command_file=/usr/local/nagios/var/rw/nagios.cmd'],
                  'format': 'command_file=&lt;file_name&gt;',
                  'options': [],
                  'title': 'External Command File'},
 'date_format': {'doc': 'This option allows you to specify what kind of date/time format Nagios should use in the web interface and date/time <a href="macros.html">macros</a>.  Possible options (along with example output) include: ',
                 'examples': ['date_format=us'],
                 'format': 'date_format=&lt;option&gt;',
                 'options': [],
                 'title': 'Date Format'},
 'debug_file': {'doc': 'This option determines where Nagios should write debugging information.  What (if any) information is written is determined by the <a href="#debug_level">debug_level</a> and <a href="#debug_verbosity">debug_verbosity</a> options.  You can have Nagios automaticaly rotate the debug file when it reaches a certain size by using the <a href="#max_debug_file_size">max_debug_file_size</a> option. ',
                'examples': ['debug_file=/usr/local/nagios/var/nagios.debug'],
                'format': 'debug_file=&lt;file_name&gt;',
                'options': [],
                'title': 'Debug File'},
 'debug_level': {'doc': 'This option determines what type of information Nagios should write to the <a href="#debug_file">debug_file</a>.  This value is a logical OR of the values below. ',
                 'examples': ['debug_level=24'],
                 'format': 'debug_level=&lt;#&gt;',
                 'options': ['-1 = Log everything',
                             '0 = Log nothing (default)',
                             '1 = Function enter/exit information',
                             '2 = Config information',
                             '4 = Process information',
                             '8 = Scheduled event information',
                             '16 = Host/service check information',
                             '32 = Notification information',
                             '64 = Event broker information'],
                 'title': 'Debug Level'},
 'debug_verbosity': {'doc': 'This option determines how much debugging information Nagios should write to the <a href="#debug_file">debug_file</a>. ',
                     'examples': ['debug_verbosity=1'],
                     'format': 'debug_verbosity=&lt;#&gt;',
                     'options': ['0 = Basic information',
                                 '1 = More detailed information (default)',
                                 '2 = Highly detailed information'],
                     'title': 'Debug Verbosity'},
 'enable_embedded_perl': {'doc': 'This setting determines whether or not the embedded Perl interpreter is enabled on a program-wide basis.  Nagios must be compiled with support for embedded Perl for this option to have an effect.  More information on the embedded Perl interpreter can be found <a href="embeddedperl.html">here</a>. ',
                          'examples': ['enable_embedded_perl=1'],
                          'format': 'enable_embedded_perl=&lt;0/1&gt;',
                          'options': [],
                          'title': 'Embedded Perl Interpreter Option'},
 'enable_environment_macros': {'doc': 'This option determines whether or not the Nagios daemon will make all standard <a href="macrolist.html">macros</a> available as environment variables to your check, notification, event hander, etc. commands.  In large Nagios installations this can be problematic because it takes additional memory and (more importantly) CPU to compute the values of all macros and make them available to the environment. ',
                               'examples': ['enable_environment_macros=0'],
                               'format': 'enable_environment_macros=&lt;0/1&gt;',
                               'options': ["0 = Don't make macros available as environment variables",
                                           '1 = Make macros available as environment variables (default)'],
                               'title': 'Environment Macros Option'},
 'enable_event_handlers': {'doc': 'This option determines whether or not Nagios will run <a href="eventhandlers.html">event handlers</a> when it initially (re)starts.  If this option is disabled, Nagios will not run any host or service event handlers.  Note: If you have <a href="#retain_state_information">state retention</a> enabled, Nagios will ignore this setting when it (re)starts and use the last known setting for this option (as stored in the <a href="#state_retention_file">state retention file</a>), <i>unless</i> you disable the <a href="#use_retained_program_state">use_retained_program_state</a> option.  If you want to change this option when state retention is active (and the <a href="#use_retained_program_state">use_retained_program_state</a> is enabled), you\'ll have to use the appropriate <a href="extcommands.html">external command</a> or change it via the web interface.  Values are as follows: ',
                           'examples': ['enable_event_handlers=1'],
                           'format': 'enable_event_handlers=&lt;0/1&gt;',
                           'options': ['0 = Disable event handlers',
                                       '1 = Enable event handlers (default)'],
                           'title': 'Event Handler Option'},
 'enable_flap_detection': {'doc': 'This option determines whether or not Nagios will try and detect hosts and services that are "flapping".  Flapping occurs when a host or service changes between states too frequently, resulting in a barrage of notifications being sent out.  When Nagios detects that a host or service is flapping, it will temporarily suppress notifications for that host/service until it stops flapping.  Flap detection is very experimental at this point, so use this feature with caution!  More information on how flap detection and handling works can be found <a href="flapping.html">here</a>.     Note: If you have <a href="#retain_state_information">state retention</a> enabled, Nagios will ignore this setting when it (re)starts and use the last known setting for this option (as stored in the <a href="#state_retention_file">state retention file</a>), <i>unless</i> you disable the <a href="#use_retained_program_state">use_retained_program_state</a> option.  If you want to change this option when state retention is active (and the <a href="#use_retained_program_state">use_retained_program_state</a> is enabled), you\'ll have to use the appropriate <a href="extcommands.html">external command</a> or change it via the web interface. ',
                           'examples': ['enable_flap_detection=0'],
                           'format': 'enable_flap_detection=&lt;0/1&gt;',
                           'options': ["0 = Don't enable flap detection (default)",
                                       '1 = Enable flap detection'],
                           'title': 'Flap Detection Option'},
 'enable_notifications': {'doc': 'This option determines whether or not Nagios will send out <a href="notifications.html">notifications</a> when it initially (re)starts.  If this option is disabled, Nagios will not send out notifications for any host or service.  Note: If you have <a href="#retain_state_information">state retention</a> enabled, Nagios will ignore this setting when it (re)starts and use the last known setting for this option (as stored in the <a href="#state_retention_file">state retention file</a>), <i>unless</i> you disable the <a href="#use_retained_program_state">use_retained_program_state</a> option.  If you want to change this option when state retention is active (and the <a href="#use_retained_program_state">use_retained_program_state</a> is enabled), you\'ll have to use the appropriate <a href="extcommands.html">external command</a> or change it via the web interface.  Values are as follows: ',
                          'examples': ['enable_notifications=1'],
                          'format': 'enable_notifications=&lt;0/1&gt;',
                          'options': ['0 = Disable notifications',
                                      '1 = Enable notifications (default)'],
                          'title': 'Notifications Option'},
 'enable_predictive_host_dependency_checks': {'doc': 'This option determines whether or not Nagios will execute predictive checks of hosts that are being depended upon (as defined in <a href="objectdefinitions.html#hostdependency">host dependencies</a>) for a particular host when it changes state.  Predictive checks help ensure that the dependency logic is as accurate as possible.  More information on how predictive checks work can be found <a href="dependencychecks.html">here</a>. ',
                                              'examples': ['enable_predictive_host_dependency_checks=1'],
                                              'format': 'enable_predictive_host_dependency_checks=&lt;0/1&gt;',
                                              'options': ['0 = Disable predictive checks',
                                                          '1 = Enable predictive checks (default)'],
                                              'title': 'Predictive Host Dependency Checks Option'},
 'enable_predictive_service_dependency_checks': {'doc': 'This option determines whether or not Nagios will execute predictive checks of services that are being depended upon (as defined in <a href="objectdefinitions.html#servicedependency">service dependencies</a>) for a particular service when it changes state.  Predictive checks help ensure that the dependency logic is as accurate as possible.  More information on how predictive checks work can be found <a href="dependencychecks.html">here</a>. ',
                                                 'examples': ['enable_predictive_service_dependency_checks=1'],
                                                 'format': 'enable_predictive_service_dependency_checks=&lt;0/1&gt;',
                                                 'options': ['0 = Disable predictive checks',
                                                             '1 = Enable predictive checks (default)'],
                                                 'title': 'Predictive Service Dependency Checks Option'},
 'event_broker_options': {'doc': 'This option controls what (if any) data gets sent to the event broker and, in turn, to any loaded event broker modules.   This is an advanced option.  When in doubt, either broker nothing (if not using event broker modules) or broker everything (if using event broker modules). Possible values are shown below. ',
                          'examples': ['event_broker_options=-1'],
                          'format': 'event_broker_options=&lt;#&gt;',
                          'options': ['0 = Broker nothing',
                                      '-1 = Broker everything',
                                      "# = See BROKER_* definitions in source code (include/broker.h) for other values that can be OR'ed together"],
                          'title': 'Event Broker Options'},
 'event_handler_timeout': {'doc': 'This is the maximum number of seconds that Nagios will allow <a href="eventhandlers.html">event handlers</a> to be run.  If an event handler exceeds this time limit it will be killed and a warning will be logged. There is often widespread confusion as to what this option really does.  It is meant to be used as a last ditch mechanism to kill off commands which are misbehaving and not exiting in a timely manner.  It should be set to something high (like 60 seconds or more), so that each event handler command normally finishes executing within this time limit.  If an event handler runs longer than this limit, Nagios will kill it off thinking it is a runaway processes. ',
                           'examples': ['event_handler_timeout=60'],
                           'format': 'event_handler_timeout=&lt;seconds&gt;',
                           'options': [],
                           'title': 'Event Handler Timeout'},
 'execute_host_checks': {'doc': 'This option determines whether or not Nagios will execute on-demand and regularly scheduled host checks when it initially (re)starts.  If this option is disabled, Nagios will not actively execute any host checks, although it can still accept <a href="passivechecks.html">passive host checks</a> unless you\'ve <a href="#accept_passive_host_checks">disabled them</a>).   This option is most often used when configuring backup monitoring servers, as described in the documentation on <a href="redundancy.html">redundancy</a>, or when setting up a <a href="distributed.html">distributed</a> monitoring environment.  Note: If you have <a href="#retain_state_information">state retention</a> enabled, Nagios will ignore this setting when it (re)starts and use the last known setting for this option (as stored in the <a href="#state_retention_file">state retention file</a>), <i>unless</i> you disable the <a href="#use_retained_program_state">use_retained_program_state</a> option.  If you want to change this option when state retention is active (and the <a href="#use_retained_program_state">use_retained_program_state</a> is enabled), you\'ll have to use the appropriate <a href="extcommands.html">external command</a> or change it via the web interface.  Values are as follows: ',
                         'examples': ['execute_host_checks=1'],
                         'format': 'execute_host_checks=&lt;0/1&gt;',
                         'options': ["0 = Don't execute host checks",
                                     '1 = Execute host checks (default)'],
                         'title': 'Host Check Execution Option'},
 'execute_service_checks': {'doc': 'This option determines whether or not Nagios will execute service checks when it initially (re)starts.  If this option is disabled, Nagios will not actively execute any service checks and will remain in a sort of "sleep" mode (it can still accept <a href="passivechecks.html">passive checks</a> unless you\'ve <a href="#accept_passive_service_checks">disabled them</a>).   This option is most often used when configuring backup monitoring servers, as described in the documentation on <a href="redundancy.html">redundancy</a>, or when setting up a <a href="distributed.html">distributed</a> monitoring environment.  Note: If you have <a href="#retain_state_information">state retention</a> enabled, Nagios will ignore this setting when it (re)starts and use the last known setting for this option (as stored in the <a href="#state_retention_file">state retention file</a>), <i>unless</i> you disable the <a href="#use_retained_program_state">use_retained_program_state</a> option.  If you want to change this option when state retention is active (and the <a href="#use_retained_program_state">use_retained_program_state</a> is enabled), you\'ll have to use the appropriate <a href="extcommands.html">external command</a> or change it via the web interface.  Values are as follows: ',
                            'examples': ['execute_service_checks=1'],
                            'format': 'execute_service_checks=&lt;0/1&gt;',
                            'options': ["0 = Don't execute service checks",
                                        '1 = Execute service checks (default)'],
                            'title': 'Service Check Execution Option'},
 'external_command_buffer_slots': {'doc': 'Note: This is an advanced feature. This option determines how many buffer slots Nagios will reserve for caching external commands that have been read from the external command file by a worker thread, but have not yet been processed by the main thread of the Nagios deamon.  Each slot can hold one external command, so this option essentially determines how many commands can be buffered.  For installations where you process a large number of passive checks (e.g. <a href="distributed.html">distributed setups</a>), you may need to increase this number.  You should consider using MRTG to graph Nagios\' usage of external command buffers.  You can read more on how to configure graphing <a href="mrtggraphs.html">here</a>. ',
                                   'examples': ['external_command_buffer_slots=512'],
                                   'format': 'external_command_buffer_slots=&lt;#&gt;',
                                   'options': [],
                                   'title': 'External Command Buffer Slots'},
 'free_child_process_memory': {'doc': 'This option determines whether or not Nagios will free memory in child processes when they are fork()ed off from the main process.  By default, Nagios frees memory.  However, if the <a href="#use_large_installation_tweaks">use_large_installation_tweaks</a> option is enabled, it will not.  By defining this option in your configuration file, you are able to override things to get the behavior you want. ',
                               'examples': ['free_child_process_memory=0'],
                               'format': 'free_child_process_memory=&lt;0/1&gt;',
                               'options': ["0 = Don't free memory",
                                           '1 = Free memory'],
                               'title': 'Child Process Memory Option'},
 'global_host_event_handler': {'doc': 'This option allows you to specify a host event handler command that is to be run for every host state change.  The global event handler is executed immediately prior to the event handler that you have optionally specified in each host definition.  The <i>command</i> argument is the short name of a command that you define in your <a href="configobject.html">object configuration file</a>.  The maximum amount of time that this command can run is controlled by the <a href="#event_handler_timeout">event_handler_timeout</a> option.  More information on event handlers can be found <a href="eventhandlers.html">here</a>. ',
                               'examples': ['global_host_event_handler=log-host-event-to-db'],
                               'format': 'global_host_event_handler=&lt;command&gt;',
                               'options': [],
                               'title': 'Global Host Event Handler Option'},
 'global_service_event_handler': {'doc': 'This option allows you to specify a service event handler command that is to be run for every service state change.  The global event handler is executed immediately prior to the event handler that you have optionally specified in each service definition.  The <i>command</i> argument is the short name of a command that you define in your <a href="configobject.html">object configuration file</a>.  The maximum amount of time that this command can run is controlled by the <a href="#event_handler_timeout">event_handler_timeout</a> option.  More information on event handlers can be found <a href="eventhandlers.html">here</a>. ',
                                  'examples': ['global_service_event_handler=log-service-event-to-db'],
                                  'format': 'global_service_event_handler=&lt;command&gt;',
                                  'options': [],
                                  'title': 'Global Service Event Handler Option'},
 'high_host_flap_threshold': {'doc': 'This option is used to set the high threshold for detection of host flapping.  For more information on how flap detection and handling works (and how this option affects things) read <a href="flapping.html">this</a>. ',
                              'examples': ['high_host_flap_threshold=50.0'],
                              'format': 'high_host_flap_threshold=&lt;percent&gt;',
                              'options': [],
                              'title': 'High Host Flap Threshold'},
 'high_service_flap_threshold': {'doc': 'This option is used to set the high threshold for detection of service flapping.  For more information on how flap detection and handling works (and how this option affects things) read <a href="flapping.html">this</a>. ',
                                 'examples': ['high_service_flap_threshold=50.0'],
                                 'format': 'high_service_flap_threshold=&lt;percent&gt;',
                                 'options': [],
                                 'title': 'High Service Flap Threshold'},
 'host_check_timeout': {'doc': 'This is the maximum number of seconds that Nagios will allow host checks to run.  If checks exceed this limit, they are killed and a CRITICAL state is returned and the host will be assumed to be DOWN.  A timeout error will also be logged. There is often widespread confusion as to what this option really does.  It is meant to be used as a last ditch mechanism to kill off plugins which are misbehaving and not exiting in a timely manner.  It should be set to something high (like 60 seconds or more), so that each host check normally finishes executing within this time limit.  If a host check runs longer than this limit, Nagios will kill it off thinking it is a runaway processes. ',
                        'examples': ['host_check_timeout=60'],
                        'format': 'host_check_timeout=&lt;seconds&gt;',
                        'options': [],
                        'title': 'Host Check Timeout'},
 'host_freshness_check_interval': {'doc': 'This setting determines how often (in seconds) Nagios will periodically check the "freshness" of host check results.  If you have disabled host freshness checking (with the <a href="#check_host_freshness">check_host_freshness</a> option), this option has no effect.  More information on freshness checking can be found <a href="freshness.html">here</a>. ',
                                   'examples': ['host_freshness_check_interval=60'],
                                   'format': 'host_freshness_check_interval=&lt;seconds&gt;',
                                   'options': [],
                                   'title': 'Host Freshness Check Interval'},
 'host_inter_check_delay_method': {'doc': 'This option allows you to control how host checks <i>that are scheduled to be checked on a regular basis</i> are initially "spread out" in the event queue.  Using a "smart" delay calculation (the default) will cause Nagios to calculate an average check interval and spread initial checks of all hosts out over that interval, thereby helping to eliminate CPU load spikes.  Using no delay is generally <i>not</i> recommended.  Using no delay will cause all host checks to be scheduled for execution at the same time.  More information on how to estimate how the inter-check delay affects host check scheduling can be found <a href="checkscheduling.html#host_inter_check_delay">here</a>.Values are as follows: ',
                                   'examples': ['host_inter_check_delay_method=s'],
                                   'format': 'host_inter_check_delay_method=&lt;n/d/s/x.xx&gt;',
                                   'options': ["n = Don't use any delay - schedule all host checks to run immediately (i.e. at the same time!)",
                                               'd = Use a "dumb" delay of 1 second between host checks',
                                               's = Use a "smart" delay calculation to spread host checks out evenly (default)',
                                               'x.xx = Use a user-supplied inter-check delay of x.xx seconds'],
                                   'title': 'Host Inter-Check Delay Method'},
 'host_perfdata_command': {'doc': 'This option allows you to specify a command to be run after <i>every</i> host check to process host <a href="perfdata.html">performance data</a> that may be returned from the check.  The <i>command</i> argument is the short name of a <a href="objectdefinitions.html#command">command definition</a> that you define in your object configuration file.  This command is only executed if the <a href="#process_performance_data">process_performance_data</a> option is enabled globally and if the <i>process_perf_data</i> directive in the <a href="objectdefinitions.html#host">host definition</a> is enabled. ',
                           'examples': ['host_perfdata_command=process-host-perfdata'],
                           'format': 'host_perfdata_command=&lt;command&gt;',
                           'options': [],
                           'title': 'Host Performance Data Processing Command'},
 'host_perfdata_file': {'doc': 'This option allows you to specify a file to which host <a href="perfdata.html">performance data</a> will be written after every host check.  Data will be written to the performance file as specified by the <a href="#host_perfdata_file_template">host_perfdata_file_template</a> option.  Performance data is only written to this file if the <a href="#process_performance_data">process_performance_data</a> option is enabled globally and if the <i>process_perf_data</i> directive in the <a href="objectdefinitions.html#host">host definition</a> is enabled. ',
                        'examples': ['host_perfdata_file=/usr/local/nagios/var/host-perfdata.dat'],
                        'format': 'host_perfdata_file=&lt;file_name&gt;',
                        'options': [],
                        'title': 'Host Performance Data File'},
 'host_perfdata_file_mode': {'doc': 'This option determines how the <a href="#host_perfdata_file">host performance data file</a> is opened.  Unless the file is a named pipe you\'ll probably want to use the default mode of append. ',
                             'examples': ['host_perfdata_file_mode=a'],
                             'format': 'host_perfdata_file_mode=&lt;mode&gt;',
                             'options': ['a = Open file in append mode (default)',
                                         'w = Open file in write mode',
                                         'p = Open in non-blocking read/write mode (useful when writing to pipes)'],
                             'title': 'Host Performance Data File Mode'},
 'host_perfdata_file_processing_command': {'doc': 'This option allows you to specify the command that should be executed to process the <a href="#host_perfdata_file">host performance data file</a>.  The <i>command</i> argument is the short name of a <a href="objectdefinitions.html#command">command definition</a> that you define in your object configuration file.  The interval at which this command is executed is determined by the <a href="#host_perfdata_file_processing_interval">host_perfdata_file_processing_interval</a> directive. ',
                                           'examples': ['host_perfdata_file_processing_command=process-host-perfdata-file'],
                                           'format': 'host_perfdata_file_processing_command=&lt;command&gt;',
                                           'options': [],
                                           'title': 'Host Performance Data File Processing Command'},
 'host_perfdata_file_processing_interval': {'doc': 'This option allows you to specify the interval (in seconds) at which the <a href="#host_perfdata_file">host performance data file</a> is processed using the <a href="#host_perfdata_file_processing_command">host performance data file processing command</a>.  A value of 0 indicates that the performance data file should not be processed at regular intervals. ',
                                            'examples': ['host_perfdata_file_processing_interval=0'],
                                            'format': 'host_perfdata_file_processing_interval=&lt;seconds&gt;',
                                            'options': [],
                                            'title': 'Host Performance Data File Processing Interval'},
 'host_perfdata_file_template': {'doc': 'This option determines what (and how) data is written to the <a href="#host_perfdata_file">host performance data file</a>.  The template may contain <a href="macros.html">macros</a>, special characters (\\t for tab, \\r for carriage return, \\n for newline) and plain text.  A newline is automatically added after each write to the performance data file. ',
                                 'examples': ['host_perfdata_file_template=[HOSTPERFDATA]\\t$TIMET$\\t$HOSTNAME$\\t$HOSTEXECUTIONTIME$\\t$HOSTOUTPUT$\\t$HOSTPERFDATA$'],
                                 'format': 'host_perfdata_file_template=&lt;template&gt;',
                                 'options': [],
                                 'title': 'Host Performance Data File Template'},
 'illegal_macro_output_chars': {'doc': 'This option allows you to specify illegal characters that should be stripped from <a href="macros.html">macros</a> before being used in notifications, event handlers, and other commands.  This DOES NOT affect macros used in service or host check commands.  You can choose to not strip out the characters shown in the example above, but I recommend you do not do this.  Some of these characters are interpreted by the shell (i.e. the backtick) and can lead to security problems.  The following macros are stripped of the characters you specify:  <b>$HOSTOUTPUT$</b>, <b>$HOSTPERFDATA$</b>, <b>$HOSTACKAUTHOR$</b>, <b>$HOSTACKCOMMENT$</b>, <b>$SERVICEOUTPUT$</b>, <b>$SERVICEPERFDATA$</b>, <b>$SERVICEACKAUTHOR$</b>, and <b>$SERVICEACKCOMMENT$</b> ',
                                'examples': ['illegal_macro_output_chars=`~$^&amp;"|\'&lt;&gt;'],
                                'format': 'illegal_macro_output_chars=&lt;chars...&gt;',
                                'options': [],
                                'title': 'Illegal Macro Output Characters'},
 'illegal_object_name_chars': {'doc': 'This option allows you to specify illegal characters that cannot be used in host names, service descriptions, or names of other object types.  Nagios will allow you to use most characters in object definitions, but I recommend not using the characters shown in the example above.  Doing may give you problems in the web interface, notification commands, etc. ',
                               'examples': ['illegal_object_name_chars=`~!$%^&amp;*"|\'&lt;&gt;?,()='],
                               'format': 'illegal_object_name_chars=&lt;chars...&gt;',
                               'options': [],
                               'title': 'Illegal Object Name Characters'},
 'interval_length': {'doc': 'This is the number of seconds per "unit interval" used for timing in the scheduling queue, re-notifications, etc. "Units intervals" are used in the object configuration file to determine how often to run a service check, how often to re-notify a contact, etc. <strong>Important:</strong>  The default value for this is set to 60, which means that a "unit value" of 1 in the object configuration file will mean 60 seconds (1 minute).  I have not really tested other values for this variable, so proceed at your own risk if you decide to do so! ',
                     'examples': ['interval_length=60'],
                     'format': 'interval_length=&lt;seconds&gt;',
                     'options': [],
                     'title': 'Timing Interval Length'},
 'lock_file': {'doc': 'This option specifies the location of the lock file that Nagios should create when it runs as a daemon (when started with the -d command line argument).  This file contains the process id (PID) number of the running Nagios process. ',
               'examples': ['lock_file=/tmp/nagios.lock'],
               'format': 'lock_file=&lt;file_name&gt;',
               'options': [],
               'title': 'Lock File'},
 'log_archive_path': {'doc': 'This is the directory where Nagios should place log files that have been rotated.  This option is ignored if you choose to not use the <a href="#log_rotation_method">log rotation</a> functionality. ',
                      'examples': ['log_archive_path=/usr/local/nagios/var/archives/'],
                      'format': 'log_archive_path=&lt;path&gt;',
                      'options': [],
                      'title': 'Log Archive Path'},
 'log_event_handlers': {'doc': 'This variable determines whether or not service and host <a href="eventhandlers.html">event handlers</a> are logged. Event handlers are optional commands that can be run whenever a service or hosts changes state.  Logging event handlers is most useful when debugging Nagios or first trying out your event handler scripts. ',
                        'examples': ['log_event_handlers=1'],
                        'format': 'log_event_handlers=&lt;0/1&gt;',
                        'options': ["0 = Don't log event handlers",
                                    '1 = Log event handlers'],
                        'title': 'Event Handler Logging Option'},
 'log_external_commands': {'doc': 'This variable determines whether or not Nagios will log <a href="extcommands.html">external commands</a> that it receives from the <a href="#command_file">external command file</a>.  Note: This option does not control whether or not <a href="passivechecks.html">passive service checks</a> (which are a type of external command) get logged.  To enable or disable logging of passive checks, use the <a href="#log_passive_checks">log_passive_checks</a> option. ',
                           'examples': ['log_external_commands=1'],
                           'format': 'log_external_commands=&lt;0/1&gt;',
                           'options': ["0 = Don't log external commands",
                                       '1 = Log external commands (default)'],
                           'title': 'External Command Logging Option'},
 'log_file': {'doc': 'This variable specifies where Nagios should create its main log file.  This should be the first variable that you define in your configuration file, as Nagios will try to write errors that it finds in the rest of your configuration data to this file.  If you have <a href="#log_rotation_method">log rotation</a> enabled, this file will automatically be rotated every hour, day, week, or month. ',
              'examples': ['log_file=/usr/local/nagios/var/nagios.log'],
              'format': 'log_file=&lt;file_name&gt;',
              'options': [],
              'title': 'Log File'},
 'log_host_retries': {'doc': 'This variable determines whether or not host check retries are logged.  Logging host check retries is mostly useful when attempting to debug Nagios or test out host <a href="eventhandlers.html">event handlers</a>. ',
                      'examples': ['log_host_retries=1'],
                      'format': 'log_host_retries=&lt;0/1&gt;',
                      'options': ["0 = Don't log host check retries",
                                  '1 = Log host check retries'],
                      'title': 'Host Check Retry Logging Option'},
 'log_initial_states': {'doc': 'This variable determines whether or not Nagios will force all initial host and service states to be logged, even if they result in an OK state.  Initial service and host states are normally only logged when there is a problem on the first check.  Enabling this option is useful if you are using an application that scans the log file to determine long-term state statistics for services and hosts. ',
                        'examples': ['log_initial_states=1'],
                        'format': 'log_initial_states=&lt;0/1&gt;',
                        'options': ["0 = Don't log initial states (default)",
                                    '1 = Log initial states'],
                        'title': 'Initial States Logging Option'},
 'log_notifications': {'doc': 'This variable determines whether or not notification messages are logged.  If you have a lot of contacts or regular service failures your log file will grow relatively quickly.  Use this option to keep contact notifications from being logged. ',
                       'examples': ['log_notifications=1'],
                       'format': 'log_notifications=&lt;0/1&gt;',
                       'options': ["0 = Don't log notifications",
                                   '1 = Log notifications'],
                       'title': 'Notification Logging Option'},
 'log_passive_checks': {'doc': 'This variable determines whether or not Nagios will log <a href="passivechecks.html">passive host and service checks</a> that it receives from the <a href="#command_file">external command file</a>.  If you are setting up a <a href="distributed.html">distributed monitoring environment</a> or plan on handling a large number of passive checks on a regular basis, you may wish to disable this option so your log file doesn\'t get too large. ',
                        'examples': ['log_passive_checks=1'],
                        'format': 'log_passive_checks=&lt;0/1&gt;',
                        'options': ["0 = Don't log passive checks",
                                    '1 = Log passive checks (default)'],
                        'title': 'Passive Check Logging Option'},
 'log_rotation_method': {'doc': 'This is the rotation method that you would like Nagios to use for your log file.  Values are as follows: ',
                         'examples': ['log_rotation_method=d'],
                         'format': 'log_rotation_method=&lt;n/h/d/w/m&gt;',
                         'options': ["n = None (don't rotate the log - this is the default)",
                                     'h = Hourly (rotate the log at the top of each hour)',
                                     'd = Daily (rotate the log at midnight each day)',
                                     'w = Weekly (rotate the log at midnight on Saturday)',
                                     'm = Monthly (rotate the log at midnight on the last day of the month)'],
                         'title': 'Log Rotation Method'},
 'log_service_retries': {'doc': 'This variable determines whether or not service check retries are logged.  Service check retries occur when a service check results in a non-OK state, but you have configured Nagios to retry the service more than once before responding to the error.  Services in this situation are considered to be in "soft" states.  Logging service check retries is mostly useful when attempting to debug Nagios or test out service <a href="eventhandlers.html">event handlers</a>. ',
                         'examples': ['log_service_retries=1'],
                         'format': 'log_service_retries=&lt;0/1&gt;',
                         'options': ["0 = Don't log service check retries",
                                     '1 = Log service check retries'],
                         'title': 'Service Check Retry Logging Option'},
 'low_host_flap_threshold': {'doc': 'This option is used to set the low threshold for detection of host flapping.  For more information on how flap detection and handling works (and how this option affects things) read <a href="flapping.html">this</a>. ',
                             'examples': ['low_host_flap_threshold=25.0'],
                             'format': 'low_host_flap_threshold=&lt;percent&gt;',
                             'options': [],
                             'title': 'Low Host Flap Threshold'},
 'low_service_flap_threshold': {'doc': 'This option is used to set the low threshold for detection of service flapping.  For more information on how flap detection and handling works (and how this option affects things) read <a href="flapping.html">this</a>. ',
                                'examples': ['low_service_flap_threshold=25.0'],
                                'format': 'low_service_flap_threshold=&lt;percent&gt;',
                                'options': [],
                                'title': 'Low Service Flap Threshold'},
 'max_check_result_file_age': {'doc': 'This options determines the maximum age in seconds that Nagios will consider check result files found in the <a href="#check_result_path">check_result_path</a> directory to be valid.  Check result files that are older that this threshold will be deleted by Nagios and the check results they contain will not be processed.  By using a value of zero (0) with this option, Nagios will process all check result files - even if they\'re older than your hardware :-). ',
                               'examples': ['max_check_result_file_age=3600'],
                               'format': 'max_check_result_file_age=&lt;seconds&gt;',
                               'options': [],
                               'title': 'Max Check Result File Age'},
 'max_check_result_reaper_time': {'doc': 'This option allows you to control the maximum amount of time <i>in seconds</i> that host and service check result "reaper" events are allowed to run.  "Reaper" events process the results from host and service checks that have finished executing.  If there are a lot of results to process, reaper events may take a long time to finish, which might delay timely execution of new host and service checks.  This variable allows you to limit the amount of time that an individual reaper event will run before it hands control back over to Nagios for other portions of the monitoring logic. ',
                                  'examples': ['max_check_result_reaper_time=30'],
                                  'format': 'max_check_result_reaper_time=&lt;seconds&gt;',
                                  'options': [],
                                  'title': 'Maximum Check Result Reaper Time'},
 'max_concurrent_checks': {'doc': 'This option allows you to specify the maximum number of service checks that can be run in parallel at any given time.  Specifying a value of 1 for this variable essentially prevents any service checks from being run in parallel.  Specifying a value of 0 (the default) does not place any restrictions on the number of concurrent checks.  You\'ll have to modify this value based on the system resources you have available on the machine that runs Nagios, as it directly affects the maximum load that will be imposed on the system (processor utilization, memory, etc.).  More information on how to estimate how many concurrent checks you should allow can be found <a href="checkscheduling.html#max_concurrent_checks">here</a>. ',
                           'examples': ['max_concurrent_checks=20'],
                           'format': 'max_concurrent_checks=&lt;max_checks&gt;',
                           'options': [],
                           'title': 'Maximum Concurrent Service Checks'},
 'max_debug_file_size': {'doc': 'This option determines the maximum size (in bytes) of the <a href="#debug_file">debug file</a>.  If the file grows larger than this size, it will be renamed with a .old  extension.  If a file already exists with a .old extension it will automatically be deleted.  This helps ensure your disk space usage doesn\'t get out of control when debugging Nagios. ',
                         'examples': ['max_debug_file_size=1000000'],
                         'format': 'max_debug_file_size=&lt;#&gt;',
                         'options': [],
                         'title': 'Maximum Debug File Size'},
 'max_host_check_spread': {'doc': 'This option determines the maximum number of minutes from when Nagios starts that all hosts (that are scheduled to be regularly checked) are checked.  This option will automatically adjust the <a href="#host_inter_check_delay_method">host inter-check delay method</a> (if necessary) to ensure that the initial checks of all hosts occur within the timeframe you specify.  In general, this option will not have an affect on host check scheduling if scheduling information is being retained using the <a href="#use_retained_scheduling_info">use_retained_scheduling_info</a> option.  Default value is <b>30</b> (minutes). ',
                           'examples': ['max_host_check_spread=30'],
                           'format': 'max_host_check_spread=&lt;minutes&gt;',
                           'options': [],
                           'title': 'Maximum Host Check Spread'},
 'max_service_check_spread': {'doc': 'This option determines the maximum number of minutes from when Nagios starts that all services (that are scheduled to be regularly checked) are checked.  This option will automatically adjust the <a href="#service_inter_check_delay_method">service inter-check delay method</a> (if necessary) to ensure that the initial checks of all services occur within the timeframe you specify.  In general, this option will not have an affect on service check scheduling if scheduling information is being retained using the <a href="#use_retained_scheduling_info">use_retained_scheduling_info</a> option.  Default value is <b>30</b> (minutes). ',
                              'examples': ['max_service_check_spread=30'],
                              'format': 'max_service_check_spread=&lt;minutes&gt;',
                              'options': [],
                              'title': 'Maximum Service Check Spread'},
 'nagios_group': {'doc': 'This is used to set the effective group that the Nagios process should run as.  After initial program startup and before starting to monitor anything, Nagios will drop its effective privileges and run as this group.  You may specify either a groupname or a GID. ',
                  'examples': ['nagios_group=nagios'],
                  'format': 'nagios_group=&lt;groupname/GID&gt;',
                  'options': [],
                  'title': 'Nagios Group'},
 'nagios_user': {'doc': 'This is used to set the effective user that the Nagios process should run as.  After initial program startup and before starting to monitor anything, Nagios will drop its effective privileges and run as this user.  You may specify either a username or a UID. ',
                 'examples': ['nagios_user=nagios'],
                 'format': 'nagios_user=&lt;username/UID&gt;',
                 'options': [],
                 'title': 'Nagios User'},
 'notification_timeout': {'doc': 'This is the maximum number of seconds that Nagios will allow notification commands to be run.  If a notification command exceeds this time limit it will be killed and a warning will be logged. There is often widespread confusion as to what this option really does.  It is meant to be used as a last ditch mechanism to kill off commands which are misbehaving and not exiting in a timely manner.  It should be set to something high (like 60 seconds or more), so that each notification command finishes executing within this time limit.  If a notification command runs longer than this limit, Nagios will kill it off thinking it is a runaway processes. ',
                          'examples': ['notification_timeout=60'],
                          'format': 'notification_timeout=&lt;seconds&gt;',
                          'options': [],
                          'title': 'Notification Timeout'},
 'object_cache_file': {'doc': 'This directive is used to specify a file in which a cached copy of <a href="configobject.html">object definitions</a> should be stored.  The cache file is (re)created every time Nagios is (re)started and is used by the CGIs.   It is intended to speed up config file caching in the CGIs and allow you to edit the source <a href="#cfg_file">object config files</a> while Nagios is running without affecting the output displayed in the CGIs. ',
                       'examples': ['object_cache_file=/usr/local/nagios/var/objects.cache'],
                       'format': 'object_cache_file=&lt;file_name&gt;',
                       'options': [],
                       'title': 'Object Cache File'},
 'obsess_over_hosts': {'doc': 'This value determines whether or not Nagios will "obsess" over host checks results and run the <a href="#ochp_command">obsessive compulsive host processor command</a> you define.  I know - funny name, but it was all I could think of.  This option is useful for performing <a href="distributed.html">distributed monitoring</a>.  If you\'re not doing distributed monitoring, don\'t enable this option. ',
                       'examples': ['obsess_over_hosts=1'],
                       'format': 'obsess_over_hosts=&lt;0/1&gt;',
                       'options': ["0 = Don't obsess over hosts (default)",
                                   '1 = Obsess over hosts'],
                       'title': 'Obsess Over Hosts Option'},
 'obsess_over_services': {'doc': 'This value determines whether or not Nagios will "obsess" over service checks results and run the <a href="#ocsp_command">obsessive compulsive service processor command</a> you define.  I know - funny name, but it was all I could think of.  This option is useful for performing <a href="distributed.html">distributed monitoring</a>.  If you\'re not doing distributed monitoring, don\'t enable this option. ',
                          'examples': ['obsess_over_services=1'],
                          'format': 'obsess_over_services=&lt;0/1&gt;',
                          'options': ["0 = Don't obsess over services (default)",
                                      '1 = Obsess over services'],
                          'title': 'Obsess Over Services Option'},
 'ochp_command': {'doc': 'This option allows you to specify a command to be run after <i>every</i> host check, which can be useful in <a href="distributed.html">distributed monitoring</a>.  This command is executed after any <a href="eventhandlers.html">event handler</a> or <a href="notifications.html">notification</a> commands.  The <i>command</i> argument is the short name of a <a href="objectdefinitions.html#command">command definition</a> that you define in your object configuration file.  The maximum amount of time that this command can run is controlled by the <a href="#ochp_timeout">ochp_timeout</a> option.   More information on distributed monitoring can be found <a href="distributed.html">here</a>.  This command is only executed if the <a href="#obsess_over_hosts">obsess_over_hosts</a> option is enabled globally and if the <i>obsess_over_host</i> directive in the <a href="objectdefinitions.html#host">host definition</a> is enabled. ',
                  'examples': ['ochp_command=obsessive_host_handler'],
                  'format': 'ochp_command=&lt;command&gt;',
                  'options': [],
                  'title': 'Obsessive Compulsive Host Processor Command'},
 'ochp_timeout': {'doc': 'This is the maximum number of seconds that Nagios will allow an <a href="#ochp_command">obsessive compulsive host processor command</a> to be run.  If a command exceeds this time limit it will be killed and a warning will be logged. ',
                  'examples': ['ochp_timeout=5'],
                  'format': 'ochp_timeout=&lt;seconds&gt;',
                  'options': [],
                  'title': 'Obsessive Compulsive Host Processor Timeout'},
 'ocsp_command': {'doc': 'This option allows you to specify a command to be run after <i>every</i> service check, which can be useful in <a href="distributed.html">distributed monitoring</a>.  This command is executed after any <a href="eventhandlers.html">event handler</a> or <a href="notifications.html">notification</a> commands.  The <i>command</i> argument is the short name of a <a href="objectdefinitions.html#command">command definition</a> that you define in your object configuration file.  The maximum amount of time that this command can run is controlled by the <a href="#ocsp_timeout">ocsp_timeout</a> option.   More information on distributed monitoring can be found <a href="distributed.html">here</a>.  This command is only executed if the <a href="#obsess_over_services">obsess_over_services</a> option is enabled globally and if the <i>obsess_over_service</i> directive in the <a href="objectdefinitions.html#service">service definition</a> is enabled. ',
                  'examples': ['ocsp_command=obsessive_service_handler'],
                  'format': 'ocsp_command=&lt;command&gt;',
                  'options': [],
                  'title': 'Obsessive Compulsive Service Processor Command'},
 'ocsp_timeout': {'doc': 'This is the maximum number of seconds that Nagios will allow an <a href="#ocsp_command">obsessive compulsive service processor command</a> to be run.  If a command exceeds this time limit it will be killed and a warning will be logged. ',
                  'examples': ['ocsp_timeout=5'],
                  'format': 'ocsp_timeout=&lt;seconds&gt;',
                  'options': [],
                  'title': 'Obsessive Compulsive Service Processor Timeout'},
 'passive_host_checks_are_soft': {'doc': 'This option determines whether or not Nagios will treat <a href="passivechecks.html">passive host checks</a> as HARD states or SOFT states.  By default, a passive host check result will put a host into a <a href="statetypes.html">HARD state type</a>.  You can change this behavior by enabling this option. ',
                                  'examples': ['passive_host_checks_are_soft=1'],
                                  'format': 'passive_host_checks_are_soft=&lt;0/1&gt;',
                                  'options': ['0 = Passive host checks are HARD (default)',
                                              '1 = Passive host checks are SOFT'],
                                  'title': 'Passive Host Checks Are SOFT Option'},
 'perfdata_timeout': {'doc': 'This is the maximum number of seconds that Nagios will allow a <a href="#host_perfdata_command">host performance data processor command</a> or <a href="#service_perfdata_command">service performance data processor command</a> to be run.  If a command exceeds this time limit it will be killed and a warning will be logged. ',
                      'examples': ['perfdata_timeout=5'],
                      'format': 'perfdata_timeout=&lt;seconds&gt;',
                      'options': [],
                      'title': 'Performance Data Processor Command Timeout'},
 'precached_object_file': {'doc': 'This directive is used to specify a file in which a pre-processed, pre-cached copy of <a href="configobject.html">object definitions</a> should be stored.  This file can be used to drastically improve startup times in large/complex Nagios installations.  Read more information on how to speed up start times <a href="faststartup.html">here</a>. ',
                           'examples': ['precached_object_file=/usr/local/nagios/var/objects.precache'],
                           'format': 'precached_object_file=&lt;file_name&gt;',
                           'options': [],
                           'title': 'Precached Object File'},
 'process_performance_data': {'doc': 'This value determines whether or not Nagios will process host and service check <a href="perfdata.html">performance data</a>. ',
                              'examples': ['process_performance_data=1'],
                              'format': 'process_performance_data=&lt;0/1&gt;',
                              'options': ["0 = Don't process performance data (default)",
                                          '1 = Process performance data'],
                              'title': 'Performance Data Processing Option'},
 'resource_file': {'doc': 'This is used to specify an optional resource file that can contain $USERn$ <a href="macros.html">macro</a> definitions.  $USERn$ macros are useful for storing usernames, passwords, and items commonly used in command definitions (like directory paths).  The CGIs will <i>not</i> attempt to read resource files, so you can set restrictive permissions (600 or 660) on them to protect sensitive information.  You can include multiple resource files by adding multiple resource_file statements to the main config file - Nagios will process them all.  See the sample resource.cfg file in the <i>sample-config/</i> subdirectory of the Nagios distribution for an example of how to define $USERn$ macros. ',
                   'examples': ['resource_file=/usr/local/nagios/etc/resource.cfg'],
                   'format': 'resource_file=&lt;file_name&gt;',
                   'options': [],
                   'title': 'Resource File'},
 'retain_state_information': {'doc': 'This option determines whether or not Nagios will retain state information for hosts and services between program restarts.  If you enable this option, you should supply a value for the <a href="#state_retention_file">state_retention_file</a> variable.  When enabled, Nagios will save all state information for hosts and service before it shuts down (or restarts) and will read in previously saved state information when it starts up again. ',
                              'examples': ['retain_state_information=1'],
                              'format': 'retain_state_information=&lt;0/1&gt;',
                              'options': ["0 = Don't retain state information",
                                          '1 = Retain state information (default)'],
                              'title': 'State Retention Option'},
 'retained_contact_host_attribute_mask': {'doc': '',
                                          'examples': [],
                                          'format': '',
                                          'options': [],
                                          'title': ''},
 'retained_contact_service_attribute_mask': {'doc': 'WARNING: This is an advanced feature.  You\'ll need to read the Nagios source code to use this option effectively. These options determine which contact attributes are NOT retained across program restarts.  There are two masks because there are often separate host and service contact attributes that can be changed.  The values for these options are a bitwise AND of values specified by the "MODATTR_" definitions in the include/common.h source code file.  By default, all process attributes are retained. ',
                                             'examples': ['retained_contact_host_attribute_mask=0',
                                                          'retained_contact_service_attribute_mask=0'],
                                             'format': '',
                                             'options': [],
                                             'title': 'Retained Contact Attribute Masks'},
 'retained_host_attribute_mask': {'doc': '',
                                  'examples': [],
                                  'format': '',
                                  'options': [],
                                  'title': ''},
 'retained_process_host_attribute_mask': {'doc': '',
                                          'examples': [],
                                          'format': '',
                                          'options': [],
                                          'title': ''},
 'retained_process_service_attribute_mask': {'doc': 'WARNING: This is an advanced feature.  You\'ll need to read the Nagios source code to use this option effectively. These options determine which process attributes are NOT retained across program restarts.  There are two masks because there are often separate host and service process attributes that can be changed.  For example, host checks can be disabled at the program level, while service checks are still enabled.  The values for these options are a bitwise AND of values specified by the "MODATTR_" definitions in the include/common.h source code file.  By default, all process attributes are retained. ',
                                             'examples': ['retained_process_host_attribute_mask=0',
                                                          'retained_process_service_attribute_mask=0'],
                                             'format': '',
                                             'options': [],
                                             'title': 'Retained Process Attribute Masks'},
 'retained_service_attribute_mask': {'doc': 'WARNING: This is an advanced feature.  You\'ll need to read the Nagios source code to use this option effectively. These options determine which host or service attributes are NOT retained across program restarts.  The values for these options are a bitwise AND of values specified by the "MODATTR_" definitions in the include/common.h source code file.  By default, all host and service attributes are retained. ',
                                     'examples': ['retained_host_attribute_mask=0',
                                                  'retained_service_attribute_mask=0'],
                                     'format': '',
                                     'options': [],
                                     'title': 'Retained Host and Service Attribute Masks'},
 'retention_update_interval': {'doc': 'This setting determines how often (in minutes) that Nagios will automatically save retention data during normal operation.  If you set this value to 0, Nagios will not save retention data at regular intervals, but it will still save retention data before shutting down or restarting.  If you have disabled state retention (with the <a href="#retain_state_information">retain_state_information</a> option), this option has no effect. ',
                               'examples': ['retention_update_interval=60'],
                               'format': 'retention_update_interval=&lt;minutes&gt;',
                               'options': [],
                               'title': 'Automatic State Retention Update Interval'},
 'service_check_timeout': {'doc': 'This is the maximum number of seconds that Nagios will allow service checks to run.  If checks exceed this limit, they are killed and a CRITICAL state is returned.   A timeout error will also be logged. There is often widespread confusion as to what this option really does.  It is meant to be used as a last ditch mechanism to kill off plugins which are misbehaving and not exiting in a timely manner.  It should be set to something high (like 60 seconds or more), so that each service check normally finishes executing within this time limit.  If a service check runs longer than this limit, Nagios will kill it off thinking it is a runaway processes. ',
                           'examples': ['service_check_timeout=60'],
                           'format': 'service_check_timeout=&lt;seconds&gt;',
                           'options': [],
                           'title': 'Service Check Timeout'},
 'service_freshness_check_interval': {'doc': 'This setting determines how often (in seconds) Nagios will periodically check the "freshness" of service check results.  If you have disabled service freshness checking (with the <a href="#check_service_freshness">check_service_freshness</a> option), this option has no effect.  More information on freshness checking can be found <a href="freshness.html">here</a>. ',
                                      'examples': ['service_freshness_check_interval=60'],
                                      'format': 'service_freshness_check_interval=&lt;seconds&gt;',
                                      'options': [],
                                      'title': 'Service Freshness Check Interval'},
 'service_inter_check_delay_method': {'doc': 'This option allows you to control how service checks are initially "spread out" in the event queue.  Using a "smart" delay calculation (the default) will cause Nagios to calculate an average check interval and spread initial checks of all services out over that interval, thereby helping to eliminate CPU load spikes.  Using no delay is generally <i>not</i> recommended, as it will cause all service checks to be scheduled for execution at the same time.  This means that you will generally have large CPU spikes when the services are all executed in parallel.   More information on how to estimate how the inter-check delay affects service check scheduling can be found <a href="checkscheduling.html#service_inter_check_delay">here</a>.  Values are as follows: ',
                                      'examples': ['service_inter_check_delay_method=s'],
                                      'format': 'service_inter_check_delay_method=&lt;n/d/s/x.xx&gt;',
                                      'options': ["n = Don't use any delay - schedule all service checks to run immediately (i.e. at the same time!)",
                                                  'd = Use a "dumb" delay of 1 second between service checks',
                                                  's = Use a "smart" delay calculation to spread service checks out evenly (default)',
                                                  'x.xx = Use a user-supplied inter-check delay of x.xx seconds'],
                                      'title': 'Service Inter-Check Delay Method'},
 'service_interleave_factor': {'doc': 'This variable determines how service checks are interleaved. Interleaving allows for a more even distribution of service checks, reduced load on remote hosts, and faster overall detection of host problems.  Setting this value to 1 is equivalent to not interleaving the service checks (this is how versions of Nagios previous to 0.0.5 worked).  Set this value to <b>s</b> (smart) for automatic calculation of the interleave factor unless you have a specific reason to change it.  The best way to understand how interleaving works is to watch the <a href="cgis.html#status_cgi">status CGI</a> (detailed view) when Nagios is just starting.  You should see that the service check results are spread out as they begin to appear.  More information on how interleaving works can be found <a href="checkscheduling.html#service_interleaving">here</a>. <ul> <li><i>x</i> = A number greater than or equal to 1 that specifies the interleave factor to use.  An interleave factor of 1 is equivalent to not interleaving the service checks. <li>s = Use a "smart" interleave factor calculation (default) </ul> ',
                               'examples': ['service_interleave_factor=s'],
                               'format': 'service_interleave_factor=&lt;s|<i>x</i>&gt;',
                               'options': ['<i>x</i> = A number greater than or equal to 1 that specifies the interleave factor to use.  An interleave factor of 1 is equivalent to not interleaving the service checks.',
                                           's = Use a "smart" interleave factor calculation (default)'],
                               'title': 'Service Interleave Factor'},
 'service_perfdata_command': {'doc': 'This option allows you to specify a command to be run after <i>every</i> service check to process service <a href="perfdata.html">performance data</a> that may be returned from the check.  The <i>command</i> argument is the short name of a <a href="objectdefinitions.html#command">command definition</a> that you define in your object configuration file.  This command is only executed if the <a href="#process_performance_data">process_performance_data</a> option is enabled globally and if the <i>process_perf_data</i> directive in the <a href="objectdefinitions.html#service">service definition</a> is enabled. ',
                              'examples': ['service_perfdata_command=process-service-perfdata'],
                              'format': 'service_perfdata_command=&lt;command&gt;',
                              'options': [],
                              'title': 'Service Performance Data Processing Command'},
 'service_perfdata_file': {'doc': 'This option allows you to specify a file to which service <a href="perfdata.html">performance data</a> will be written after every service check.  Data will be written to the performance file as specified by the <a href="#service_perfdata_file_template">service_perfdata_file_template</a> option.  Performance data is only written to this file if the <a href="#process_performance_data">process_performance_data</a> option is enabled globally and if the <i>process_perf_data</i> directive in the <a href="objectdefinitions.html#service">service definition</a> is enabled. ',
                           'examples': ['service_perfdata_file=/usr/local/nagios/var/service-perfdata.dat'],
                           'format': 'service_perfdata_file=&lt;file_name&gt;',
                           'options': [],
                           'title': 'Service Performance Data File'},
 'service_perfdata_file_mode': {'doc': 'This option determines how the <a href="#service_perfdata_file">service performance data file</a> is opened.  Unless the file is a named pipe you\'ll probably want to use the default mode of append. ',
                                'examples': ['service_perfdata_file_mode=a'],
                                'format': 'service_perfdata_file_mode=&lt;mode&gt;',
                                'options': ['a = Open file in append mode (default)',
                                            'w = Open file in write mode',
                                            'p = Open in non-blocking read/write mode (useful when writing to pipes)'],
                                'title': 'Service Performance Data File Mode'},
 'service_perfdata_file_processing_command': {'doc': 'This option allows you to specify the command that should be executed to process the <a href="#service_perfdata_file">service performance data file</a>.  The <i>command</i> argument is the short name of a <a href="objectdefinitions.html#command">command definition</a> that you define in your object configuration file.  The interval at which this command is executed is determined by the <a href="#service_perfdata_file_processing_interval">service_perfdata_file_processing_interval</a> directive. ',
                                              'examples': ['service_perfdata_file_processing_command=process-service-perfdata-file'],
                                              'format': 'service_perfdata_file_processing_command=&lt;command&gt;',
                                              'options': [],
                                              'title': 'Service Performance Data File Processing Command'},
 'service_perfdata_file_processing_interval': {'doc': 'This option allows you to specify the interval (in seconds) at which the <a href="#service_perfdata_file">service performance data file</a> is processed using the <a href="#service_perfdata_file_processing_command">service performance data file processing command</a>.  A value of 0 indicates that the performance data file should not be processed at regular intervals. ',
                                               'examples': ['service_perfdata_file_processing_interval=0'],
                                               'format': 'service_perfdata_file_processing_interval=&lt;seconds&gt;',
                                               'options': [],
                                               'title': 'Service Performance Data File Processing Interval'},
 'service_perfdata_file_template': {'doc': 'This option determines what (and how) data is written to the <a href="#service_perfdata_file">service performance data file</a>.  The template may contain <a href="macros.html">macros</a>, special characters (\\t for tab, \\r for carriage return, \\n for newline) and plain text.  A newline is automatically added after each write to the performance data file. ',
                                    'examples': ['service_perfdata_file_template=[SERVICEPERFDATA]\\t$TIMET$\\t$HOSTNAME$\\t$SERVICEDESC$\\t$SERVICEEXECUTIONTIME$\\t$SERVICELATENCY$\\t$SERVICEOUTPUT$\\t$SERVICEPERFDATA$'],
                                    'format': 'service_perfdata_file_template=&lt;template&gt;',
                                    'options': [],
                                    'title': 'Service Performance Data File Template'},
 'sleep_time': {'doc': 'This is the number of seconds that Nagios will sleep before checking to see if the next service or host check in the scheduling queue should be executed.  Note that Nagios will only sleep after it "catches up" with queued service checks that have fallen behind. ',
                'examples': ['sleep_time=1'],
                'format': 'sleep_time=&lt;seconds&gt;',
                'options': [],
                'title': 'Inter-Check Sleep Time'},
 'soft_state_dependencies': {'doc': 'This option determines whether or not Nagios will use soft state information when checking <a href="dependencies.html">host and service dependencies</a>.  Normally Nagios will only use the latest hard host or service state when checking dependencies.  If you want it to use the latest state (regardless of whether its a soft or hard <a href="statetypes.html">state type</a>), enable this option. ',
                             'examples': ['soft_state_dependencies=0'],
                             'format': 'soft_state_dependencies=&lt;0/1&gt;',
                             'options': ["0 = Don't use soft state dependencies (default)",
                                         '1 = Use soft state dependencies'],
                             'title': 'Soft State Dependencies Option'},
 'state_retention_file': {'doc': 'This is the file that Nagios will use for storing status, downtime, and comment information before it shuts down.  When Nagios is restarted it will use the information stored in this file for setting the initial states of services and hosts before it starts monitoring anything.   In order to make Nagios retain state information between program restarts, you must enable the <a href="#retain_state_information">retain_state_information</a> option. ',
                          'examples': ['state_retention_file=/usr/local/nagios/var/retention.dat'],
                          'format': 'state_retention_file=&lt;file_name&gt;',
                          'options': [],
                          'title': 'State Retention File'},
 'status_file': {'doc': '',
                 'examples': [],
                 'format': '',
                 'options': [],
                 'title': ''},
 'status_log': {'doc': 'This is the file that Nagios uses to store the current status, comment, and downtime information.  This file is used by the CGIs so that current monitoring status can be reported via a web interface.  The CGIs must have read access to this file in order to function properly.  This file is deleted every time Nagios stops and recreated when it starts. ',
                'examples': ['status_file=/usr/local/nagios/var/status.dat'],
                'format': 'status_file=&lt;file_name&gt;',
                'options': [],
                'title': 'Status File'},
 'status_update_interval': {'doc': 'This setting determines how often (in seconds) that Nagios will update status data in the <a href="#status_file">status file</a>.  The minimum update interval is 1 second. ',
                            'examples': ['status_update_interval=15'],
                            'format': 'status_update_interval=&lt;seconds&gt;',
                            'options': [],
                            'title': 'Status File Update Interval'},
 'temp_file': {'doc': 'This is a temporary file that Nagios periodically creates to use when updating comment data, status data, etc.  The file is deleted when it is no longer needed. ',
               'examples': ['temp_file=/usr/local/nagios/var/nagios.tmp'],
               'format': 'temp_file=&lt;file_name&gt;',
               'options': [],
               'title': 'Temp File'},
 'temp_path': {'doc': 'This is a directory that Nagios can use as scratch space for creating temporary files used during the monitoring process.  You should run <i>tmpwatch</i>, or a similiar utility, on this directory occassionally to delete files older than 24 hours. ',
               'examples': ['temp_path=/tmp'],
               'format': 'temp_path=&lt;dir_name&gt;',
               'options': [],
               'title': 'Temp Path'},
 'translate_passive_host_checks': {'doc': 'This option determines whether or not Nagios will translate DOWN/UNREACHABLE passive host check results to their "correct" state from the viewpoint of the local Nagios instance.  This can be very useful in distributed and failover monitoring installations.  More information on passive check state translation can be found <a href="passivestatetranslation.html">here</a>. ',
                                   'examples': ['translate_passive_host_checks=1'],
                                   'format': 'translate_passive_host_checks=&lt;0/1&gt;',
                                   'options': ['0 = Disable check translation (default)',
                                               '1 = Enable check translation'],
                                   'title': 'Translate Passive Host Checks Option'},
 'use_aggressive_host_checking': {'doc': 'Nagios tries to be smart about how and when it checks the status of hosts.  In general, disabling this option will allow Nagios to make some smarter decisions and check hosts a bit faster.  Enabling this option will increase the amount of time required to check hosts, but may improve reliability a bit.  Unless you have problems with Nagios not recognizing that a host recovered, I would suggest <b>not</b> enabling this option. ',
                                  'examples': ['use_aggressive_host_checking=0'],
                                  'format': 'use_aggressive_host_checking=&lt;0/1&gt;',
                                  'options': ["0 = Don't use aggressive host checking (default)",
                                              '1 = Use aggressive host checking'],
                                  'title': 'Aggressive Host Checking Option'},
 'use_agressive_host_checking': {'doc': '',
                                 'examples': [],
                                 'format': '',
                                 'options': [],
                                 'title': ''},
 'use_embedded_perl_implicitly': {'doc': 'This setting determines whether or not the embedded Perl interpreter should be used for Perl plugins/scripts that do not explicitly enable/disable it.  Nagios must be compiled with support for embedded Perl for this option to have an effect.  More information on the embedded Perl interpreter and the effect of this setting can be found <a href="embeddedperl.html">here</a>. ',
                                  'examples': ['use_embedded_perl_implicitly=1'],
                                  'format': 'use_embedded_perl_implicitly=&lt;0/1&gt;',
                                  'options': [],
                                  'title': 'Embedded Perl Implicit Use Option'},
 'use_large_installation_tweaks': {'doc': 'This option determines whether or not the Nagios daemon will take several shortcuts to improve performance.  These shortcuts result in the loss of a few features, but larger installations will likely see a lot of benefit from doing so.  More information on what optimizations are taken when you enable this option can be found <a href="largeinstalltweaks.html">here</a>. ',
                                   'examples': ['use_large_installation_tweaks=0'],
                                   'format': 'use_large_installation_tweaks=&lt;0/1&gt;',
                                   'options': ["0 = Don't use tweaks (default)",
                                               '1 = Use tweaks'],
                                   'title': 'Large Installation Tweaks Option'},
 'use_regexp_matching': {'doc': 'This option determines whether or not various directives in your <a href="configobject.html">object definitions</a> will be processed as regular expressions.  More information on how this works can be found <a href="objecttricks.html">here</a>. ',
                         'examples': ['use_regexp_matching=0'],
                         'format': 'use_regexp_matching=&lt;0/1&gt;',
                         'options': ["0 = Don't use regular expression matching (default)",
                                     '1 = Use regular expression matching'],
                         'title': 'Regular Expression Matching Option'},
 'use_retained_program_state': {'doc': 'This setting determines whether or not Nagios will set various program-wide state variables based on the values saved in the retention file.  Some of these program-wide state variables that are normally saved across program restarts if state retention is enabled include the <a href="#enable_notifications">enable_notifications</a>, <a href="#enable_flap_detection">enable_flap_detection</a>, <a href="#enable_event_handlers">enable_event_handlers</a>, <a href="#execute_service_checks">execute_service_checks</a>, and <a href="#accept_passive_service_checks">accept_passive_service_checks</a> options. If you do not have <a href="#retain_state_information">state retention</a> enabled, this option has no effect. ',
                                'examples': ['use_retained_program_state=1'],
                                'format': 'use_retained_program_state=&lt;0/1&gt;',
                                'options': ["0 = Don't use retained program state",
                                            '1 = Use retained program state (default)'],
                                'title': 'Use Retained Program State Option'},
 'use_retained_scheduling_info': {'doc': 'This setting determines whether or not Nagios will retain scheduling info (next check times) for hosts and services when it restarts.  If you are adding a large number (or percentage) of hosts and services, I would recommend disabling this option when you first restart Nagios, as it can adversely skew the spread of initial checks.  Otherwise you will probably want to  leave it enabled. ',
                                  'examples': ['use_retained_scheduling_info=1'],
                                  'format': 'use_retained_scheduling_info=&lt;0/1&gt;',
                                  'options': ["0 = Don't use retained scheduling info",
                                              '1 = Use retained scheduling info (default)'],
                                  'title': 'Use Retained Scheduling Info Option'},
 'use_syslog': {'doc': 'This variable determines whether messages are logged to the syslog facility on your local host.  Values are as follows: ',
                'examples': ['use_syslog=1'],
                'format': 'use_syslog=&lt;0/1&gt;',
                'options': ["0 = Don't use syslog facility",
                            '1 = Use syslog facility'],
                'title': 'Syslog Logging Option'},
 'use_timezone': {'doc': 'This option allows you to override the default timezone that this instance of Nagios runs in.  Useful if you have multiple instances of Nagios that need to run from the same server, but have different local times associated with them.  If not specified, Nagios will use the system configured timezone. <img src="images/note.gif" border="0" align="bottom" alt="Note" title="Note"> Note: If you use this option to specify a custom timezone, you will also need to alter the Apache configuration directives for the CGIs to specify the timezone you want.  Example: ',
                  'examples': ['use_timezone=US/Mountain'],
                  'format': 'use_timezone=&lt;tz&gt;',
                  'options': [],
                  'title': 'Timezone Option'},
 'use_true_regexp_matching': {'doc': 'If you\'ve enabled regular expression matching of various object directives using the <a href="#use_regexp_matching">use_regexp_matching</a> option, this option will determine when object directives are treated as regular expressions.  If this option is disabled (the default), directives will only be treated as regular expressions if they contain <b>*</b>, <b>?</b>, <b>+</b>, or <b>\\.</b>.  If this option is enabled, all appropriate directives will be treated as regular expression - be careful when enabling this!  More information on how this works can be found <a href="objecttricks.html">here</a>. ',
                              'examples': ['use_true_regexp_matching=0'],
                              'format': 'use_true_regexp_matching=&lt;0/1&gt;',
                              'options': ["0 = Don't use true regular expression matching (default)",
                                          '1 = Use true regular expression matching'],
                              'title': 'True Regular Expression Matching Option'}}

########NEW FILE########
__FILENAME__ = macros
# -*- coding: utf-8 -*-
#
# pynag - Python Nagios plug-in and configuration environment
# Copyright (C) 2010 Pall Sigurdsson
# 
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.

"""
This file contains a dict object that maps Nagios Standard macronames to specific values.

i.e. macros['$HOSTADDR$'] should return 'address'
"""

# TODO: This hash map is incomplete, someone should type everything from the documentation to here:
# See: http://nagios.sourceforge.net/docs/3_0/macrolist.html

_standard_macros = {
                   '$HOSTADDRESS$':'address',
                   '$HOSTNAME$':'host_name',
                   '$SERVICEDESC$':'service_description',
                   '$CONTACTEMAIL$':'email',
                   }

########NEW FILE########
__FILENAME__ = new_threshold_syntax
# -*- coding: utf-8 -*-
#
# pynag - Python Nagios plug-in and configuration environment
# Copyright (C) 2012 Pall Sigurdsson
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.

"""
These are helper functions and implementation of proposed new threshold format for nagios plugins
according to: http://nagiosplugins.org/rfc/new_threshold_syntax

In short, plugins should implement a --threshold option which takes argument in form of:
  # metric={metric},ok={range},warn={range},crit={range},unit={unit}prefix={SI prefix}

Example:
  --treshold metric=load1,ok=0..5,warning=5..10,critical=10..inf

"""

from __future__ import print_function
from __future__ import unicode_literals
from __future__ import absolute_import

import pynag.Plugins
from pynag.Utils import PynagError


def check_threshold(value, ok=None, warning=None, critical=None):
    """ Checks value against warning/critical and returns Nagios exit code.

    Format of range_threshold is according to:
    http://nagiosplugins.org/rfc/new_threshold_syntax

    This function returns (in order of appearance):
        int(0) - If no levels are specified, return OK
        int(3) - If any invalid input provided, return UNKNOWN
        int(0) - If an ok level is specified and value is within range, return OK
        int(2) - If a critical level is specified and value is within range, return CRITICAL
        int(1) - If a warning level is specified and value is within range, return WARNING
        int(2) - If an ok level is specified, return CRITICAL
        int(0) - Otherwise return OK

    Arguments:
        value    -- value to check
        ok       -- ok range
        warning  -- warning range
        critical -- critical range



    # Example Usage:
    >>> check_threshold(88, warning="90..95", critical="95..100")
    0
    >>> check_threshold(92, warning="90..95", critical="95..100")
    1
    >>> check_threshold(96, warning="90..95", critical="95..100")
    2
    """
    try:
        # 1 - If no levels are specified, return OK
        if not ok and not warning and not critical:
            return pynag.Plugins.OK
        # 2 - If an ok level is specified and value is within range, return OK
        if ok and check_range(value, ok):
            return pynag.Plugins.OK
        # 3 - If a critical level is specified and value is within range, return CRITICAL
        if critical and check_range(value, critical):
            return pynag.Plugins.CRITICAL
        # 4 - If a warning level is specified and value is within range, return WARNING
        if warning and check_range(value, warning):
            return pynag.Plugins.WARNING
        # 5 - If an ok level is specified, return CRITICAL
        if ok:
            return pynag.Plugins.CRITICAL
        # 6 - Otherwise return OK
        return pynag.Plugins.OK
    except Exception:
        # Return unknown if any problem occurs, including invalid input
        return pynag.Plugins.UNKNOWN


def check_range(value, range):
    """ Returns True if value is within range, else False

    Arguments:
      value -- Numerical value to check, can be any number
      range -- string in the format of "start..end"
    Examples:
    >>> check_range(5, "0..10")
    True
    >>> check_range(11, "0..10")
    False
    """

    if not isinstance(range, basestring) or range == '':
        raise PynagError('range must be a string')

    # value must be numeric, so we try to convert it to float
    value = float(value)

    # If range does not contain ".." then we assume its the older style of
    # ranges (either a plain number or the start:end syntax)
    if '..' not in range:
        return not pynag.Plugins.check_range(value=value, range_threshold=range)
    # If range starts with ^ we the conditions are inverted
    if range[0] == '^':
        return not check_range(value, range[1:])

    # Start and end must be defined
    tmp = range.split('..')
    if len(tmp) != 2:
        raise PynagError('Invalid Format for threshold range: "%s"' % range)
    start, end = tmp

    if not start in ('inf', '-inf'):
        start = float(start)
        if start > value:
            return False
    if not end == 'inf':
        end = float(end)
        if end < value:
            return False
    return True


def parse_threshold(threshold):
    """ takes a threshold string as an input and returns a hash map of options and values

    Examples:
        >>> parse_threshold('metric=disk_usage,ok=0..90,warning=90..95,critical=95.100')
        {'thresholds': [(0, '0..90'), (1, '90..95'), (2, '95.100')], 'metric': 'disk_usage'}
    """
    tmp = threshold.lower().split(',')
    parsed_thresholds = []
    results = {}
    results['thresholds'] = parsed_thresholds
    for i in tmp:
        if i.find('=') < 1:
            raise PynagError("Invalid input: '%s' is not of the format key=value" % i)
        key, value = i.split('=', 1)
        if key in pynag.Plugins.state.keys():
            parsed_thresholds.append((pynag.Plugins.state[key], value))
        else:
            results[key] = value
    return results

########NEW FILE########
__FILENAME__ = misc
# -*- coding: utf-8 -*-

""" miscellaneous utils classes and function.

 The reason they don't live in in pynag.Utils is that they have more requirements, and they do on occation import
 pynag.Model og pynag.Parsers
"""


import tempfile
import os
import time
import pynag.Parsers
import pynag.Model
from pynag.Utils import PynagError


class FakeNagiosEnvironment(object):
    """ Creates a fake nagios environment with minimal configs in /tmp/

    Example:
        >>> nagios = FakeNagiosEnvironment()
        >>> nagios.create_minimal_environment()  # Create temporary director with minimal config
        >>> nagios.update_model()  # Update the global variables in pynag.Model
        >>> nagios.configure_livestatus()  # Configure a livestatus socket
        >>> result, stdout, stderr = nagios.start()  # Start up nagios
        >>> config = nagios.get_config()   # Returns Parsers.Config instance
        >>> livestatus = nagios.get_livestatus()  # Returns Parsers.Livestatus instance
        >>> result, stdout, sdterr = nagios.stop()  # Stop nagios
        >>> nagios.terminate()  # Stops nagios and cleans up everything
    """
    def __init__(self, global_config_file=None, p1_file=None, livestatus=False):
        self.global_config_file = global_config_file
        self.p1_file = p1_file
        self._model_is_dirty = False
        self.livestatus_module_path = livestatus
        self.livestatus_object = None
        self.config = None

        self.tempdir = tempfile.mkdtemp('nagios-environment') + "/"
        path_to_socket = self.tempdir + "/livestatus.socket"
        self.livestatus_socket_path = path_to_socket

    def get_config(self):
        if not self.config:
            self.create_minimal_environment()
        return self.config

    def get_livestatus(self):
        if not self.livestatus_object:
            self.configure_livestatus()
        return self.livestatus_object

    def update_model(self):
        """ Update the global variables in pynag.Model to point to our config """
        self.original_objects_dir = pynag.Model.pynag_directory
        self.original_cfg_file = pynag.Model.cfg_file
        self.original_config = pynag.Model.config

        pynag.Model.config = self.get_config()
        pynag.Model.cfg_file = self.config.cfg_file
        pynag.Model.pynag_directory = self.objects_dir
        pynag.Model.eventhandlers = []

        self._model_is_dirty = True

    def open_decorator(self, func):
        """ Safety decorator aroundaround self.config.open()

         It wraps around self.config.open() and raises error if the fake
         nagios environment tries to open file outside the sandbox.
        """
        def wrap(filename, *args, **kwargs):
            if filename.startswith(self.tempdir):
                return func(filename, *args, **kwargs)
            else:
                raise PynagError("FakeNagiosEnvironment tried to open file outside its sandbox: %s" % (filename, ))
        wrap.__name__ = func.__name__
        wrap.__module__ = func.__module__
        return wrap

    def restore_model(self):
        """ Restores the global variables in pynag.Model """
        pynag.Model.config = self.original_config
        pynag.Model.cfg_file = self.original_cfg_file
        pynag.Model.pynag_directory = self.original_objects_dir
        self._model_is_dirty = False

    def create_minimal_environment(self):
        """ Starts a nagios server with empty config in an isolated environment """
        t = self.tempdir
        cfg_file = self.cfg_file = t + "/nagios.cfg"
        open(cfg_file, 'w').write('')

        objects_dir = self.objects_dir = t + "/conf.d"
        os.mkdir(objects_dir)

        check_result_path = os.path.join(self.tempdir, 'checkresults')
        os.mkdir(check_result_path)

        log_dir = os.path.join(self.tempdir, 'log')
        archive_dir = os.path.join(log_dir, 'archive')
        os.mkdir(log_dir)
        os.mkdir(archive_dir)

        with open(objects_dir + "/minimal_config.cfg", 'w') as f:
            f.write(minimal_config)

        config = self.config = pynag.Parsers.config(cfg_file=cfg_file)
        self.config.open = self.open_decorator(self.config.open)
        config.parse()
        config._edit_static_file(attribute='log_archive_path', new_value=t + "log/archive")
        config._edit_static_file(attribute='log_file', new_value=t + "log/nagios.log")
        config._edit_static_file(attribute='object_cache_file', new_value=t + "objects.cache")
        config._edit_static_file(attribute='precached_object_file', new_value=t + "/objects.precache")
        config._edit_static_file(attribute='lock_file', new_value=t + "nagios.pid")
        config._edit_static_file(attribute='command_file', new_value=t + "nagios.cmd")
        config._edit_static_file(attribute='state_retention_file', new_value=t + "retention.dat")
        config._edit_static_file(attribute='status_file', new_value=t + "status.dat")
        config._edit_static_file(attribute='cfg_dir', new_value=objects_dir)
        config._edit_static_file(attribute='log_initial_states', new_value="1")
        config._edit_static_file(attribute='enable_embedded_perl', new_value='0')
        config._edit_static_file(attribute='event_broker_options', new_value='-1')
        config._edit_static_file(attribute='illegal_macro_output_chars', new_value='''~$&|<>''')
        config._edit_static_file(attribute='check_result_path', new_value=check_result_path)

    def clean_up(self):
        """ Clean up all temporary directories """
        command = ['rm', '-rf', self.tempdir]
        pynag.Utils.runCommand(command=command, shell=False)

    def terminate(self):
        """ Stop the nagios environment and remove all temporary files """
        self.stop()
        if self._model_is_dirty:
            self.restore_model()
        self.clean_up()

    def start(self, start_command=None):
        self.configure_p1_file()
        if not start_command:
            nagios_binary = self.config.guess_nagios_binary()
            start_command = "%s -d %s" % (nagios_binary, self.config.cfg_file)
        result = pynag.Utils.runCommand(command=start_command)
        code, stdout, stderr = result
        if result[0] != 0:
            if os.path.exists(self.tempdir + "nagios.log"):
                log_file_output = open(self.tempdir + "nagios.log").read()
            else:
                log_file_output = "No log file found."
            message = "Failed to start Nagios."
            message += "Command: {start_command}\n"
            message += "Exit Code: {code}\n"
            message += "============\nStandard out\n{stdout}\n"
            message += "=============\nStandard Err\n{stderr}\n"
            message += "=============\nLog File output\n{log_file_output}\n"
            message = message.format(**locals())
            raise Exception(message)
        return result

    def stop(self, stop_command=None):
        pid_file = self.tempdir + "nagios.pid"
        if not os.path.exists(pid_file):
            return
        pid = open(pid_file).read()

        if not stop_command:
            stop_command = "kill -9 %s" % pid
        result = pynag.Utils.runCommand(stop_command)
        time.sleep(0.5)
        return result

    def configure_livestatus(self):
        if not self.livestatus_module_path:
            self.livestatus_module_path = self.guess_livestatus_path()
        line = "%s %s" % (self.livestatus_module_path, self.livestatus_socket_path)
        config = self.get_config()
        config._edit_static_file(attribute="broker_module", new_value=line)
        self.livestatus_object = pynag.Parsers.Livestatus(
            nagios_cfg_file=config.cfg_file,
        )

    def guess_p1_file(self):
        global_config = pynag.Parsers.config(cfg_file=self.global_config_file)
        global_config.parse_maincfg()
        for k, v in global_config.maincfg_values:
            if k == 'p1_file':
                return v

    def configure_p1_file(self):
        if not self.p1_file:
            self.p1_file = self.guess_p1_file()
        config = self.get_config()
        config._edit_static_file(attribute='p1_file', new_value=self.p1_file)

    def guess_livestatus_path(self):
        """ Tries to guess a path to mk-livestatus

        Returns:
            string containing full path to mk-livestatus broker_module
        """
        # Find mk_livestatus broker module
        global_config = pynag.Parsers.config(cfg_file=self.global_config_file)
        global_config.parse_maincfg()
        for k, v in global_config.maincfg_values:
            if k == 'broker_module' and 'livestatus' in v:
                livestatus_module = v.split()[0]
                return livestatus_module

    def import_config(self, path):
        """ Copies any file or directory into our environment and include it in object configuration

        Args:
            path:   full path to a nagios cfg file or a directory of cfg files

        Raises:
            Exception if path is not found
        """
        destination = self.objects_dir
        command = "cp -r '{path}' '{destination}/'".format(**locals())
        return os.system(command)


minimal_config = r"""
    define timeperiod {
      alias                          24 Hours A Day, 7 Days A Week
      friday          00:00-24:00
      monday          00:00-24:00
      saturday        00:00-24:00
      sunday          00:00-24:00
      thursday        00:00-24:00
      timeperiod_name                24x7
      tuesday         00:00-24:00
      wednesday       00:00-24:00
    }

    define timeperiod {
      alias                          24x7 Sans Holidays
      friday          00:00-24:00
      monday          00:00-24:00
      saturday        00:00-24:00
      sunday          00:00-24:00
      thursday        00:00-24:00
      timeperiod_name                24x7_sans_holidays
      tuesday         00:00-24:00
      use		us-holidays		; Get holiday exceptions from other timeperiod
      wednesday       00:00-24:00
    }

    define contactgroup {
      alias                          Nagios Administrators
      contactgroup_name              admins
      members                        nagiosadmin
    }

    define command {
      command_line                   $USER1$/check_ping -H $HOSTADDRESS$ -w 3000.0,80% -c 5000.0,100% -p 5
      command_name                   check-host-alive
    }

    define command {
      command_line                   $USER1$/check_dhcp $ARG1$
      command_name                   check_dhcp
    }

    define command {
      command_line                   $USER1$/check_ftp -H $HOSTADDRESS$ $ARG1$
      command_name                   check_ftp
    }

    define command {
      command_line                   $USER1$/check_hpjd -H $HOSTADDRESS$ $ARG1$
      command_name                   check_hpjd
    }

    define command {
      command_line                   $USER1$/check_http -I $HOSTADDRESS$ $ARG1$
      command_name                   check_http
    }

    define command {
      command_line                   $USER1$/check_imap -H $HOSTADDRESS$ $ARG1$
      command_name                   check_imap
    }

    define command {
      command_line                   $USER1$/check_disk -w $ARG1$ -c $ARG2$ -p $ARG3$
      command_name                   check_local_disk
    }

    define command {
      command_line                   $USER1$/check_load -w $ARG1$ -c $ARG2$
      command_name                   check_local_load
    }

    define command {
      command_line                   $USER1$/check_mrtgtraf -F $ARG1$ -a $ARG2$ -w $ARG3$ -c $ARG4$ -e $ARG5$
      command_name                   check_local_mrtgtraf
    }

    define command {
      command_line                   $USER1$/check_procs -w $ARG1$ -c $ARG2$ -s $ARG3$
      command_name                   check_local_procs
    }

    define command {
      command_line                   $USER1$/check_swap -w $ARG1$ -c $ARG2$
      command_name                   check_local_swap
    }

    define command {
      command_line                   $USER1$/check_users -w $ARG1$ -c $ARG2$
      command_name                   check_local_users
    }

    define command {
      command_line                   $USER1$/check_nt -H $HOSTADDRESS$ -p 12489 -v $ARG1$ $ARG2$
      command_name                   check_nt
    }

    define command {
      command_line                   $USER1$/check_ping -H $HOSTADDRESS$ -w $ARG1$ -c $ARG2$ -p 5
      command_name                   check_ping
    }

    define command {
      command_line                   $USER1$/check_pop -H $HOSTADDRESS$ $ARG1$
      command_name                   check_pop
    }

    define command {
      command_line                   $USER1$/check_smtp -H $HOSTADDRESS$ $ARG1$
      command_name                   check_smtp
    }

    define command {
      command_line                   $USER1$/check_snmp -H $HOSTADDRESS$ $ARG1$
      command_name                   check_snmp
    }

    define command {
      command_line                   $USER1$/check_ssh $ARG1$ $HOSTADDRESS$
      command_name                   check_ssh
    }

    define command {
      command_line                   $USER1$/check_tcp -H $HOSTADDRESS$ -p $ARG1$ $ARG2$
      command_name                   check_tcp
    }

    define command {
      command_line                   $USER1$/check_udp -H $HOSTADDRESS$ -p $ARG1$ $ARG2$
      command_name                   check_udp
    }

    define contact {
      name                           generic-contact
      host_notification_commands     notify-host-by-email
      host_notification_options      d,u,r,f,s
      host_notification_period       24x7
      register                       0
      service_notification_commands  notify-service-by-email
      service_notification_options   w,u,c,r,f,s
      service_notification_period    24x7
    }

    define host {
      name                           generic-host
      event_handler_enabled          1
      failure_prediction_enabled     1
      flap_detection_enabled         1
      notification_period            24x7
      notifications_enabled          1
      process_perf_data              1
      register                       0
      retain_nonstatus_information   1
      retain_status_information      1
      max_check_attempts             3
    }

    define host {
      name                           generic-printer
      use                            generic-host
      check_command                  check-host-alive
      check_interval                 5
      check_period                   24x7
      contact_groups                 admins
      max_check_attempts             10
      notification_interval          30
      notification_options           d,r
      notification_period            workhours
      register                       0
      retry_interval                 1
      statusmap_image                printer.png
    }

    define host {
      name                           generic-router
      use                            generic-switch
      register                       0
      statusmap_image                router.png
    }

    define service {
      name                           generic-service
      action_url                     /pnp4nagios/graph?host=$HOSTNAME$&srv=$SERVICEDESC$
      active_checks_enabled          1
      check_freshness                0
      check_period                   24x7
      event_handler_enabled          1
      failure_prediction_enabled     1
      flap_detection_enabled         1
      icon_image                     unknown.gif
      is_volatile                    0
      max_check_attempts             3
      normal_check_interval          10
      notes_url                      /adagios/objectbrowser/edit_object/object_type=service/shortname=$HOSTNAME$/$SERVICEDESC$
      notification_interval          60
      notification_options           w,u,c,r
      notification_period            24x7
      notifications_enabled          1
      obsess_over_service            1
      parallelize_check              1
      passive_checks_enabled         1
      process_perf_data              1
      register                       0
      retain_nonstatus_information   1
      retain_status_information      1
      retry_check_interval           2
    }

    define host {
      name                           generic-switch
      use                            generic-host
      check_command                  check-host-alive
      check_interval                 5
      check_period                   24x7
      contact_groups                 admins
      max_check_attempts             10
      notification_interval          30
      notification_options           d,r
      notification_period            24x7
      register                       0
      retry_interval                 1
      statusmap_image                switch.png
    }

    define host {
      name                           linux-server
      use                            generic-host
      check_command                  check-host-alive
      check_interval                 5
      check_period                   24x7
      contact_groups                 admins
      max_check_attempts             10
      notification_interval          120
      notification_options           d,u,r
      notification_period            workhours
      register                       0
      retry_interval                 1
    }

    define service {
      name                           local-service
      use                            generic-service
      max_check_attempts             4
      normal_check_interval          5
      register                       0
      retry_check_interval           1
    }

    define contact {
      use                            generic-contact
      alias                          Nagios Admin
      contact_name                   nagiosadmin
      email                          nagios@localhost
    }

    define timeperiod {
      alias                          No Time Is A Good Time
      timeperiod_name                none
    }

    define command {
      command_line                   /usr/bin/printf "%b" "***** Nagios *****\n\nNotification Type: $NOTIFICATIONTYPE$\nHost: $HOSTNAME$\nState: $HOSTSTATE$\nAddress: $HOSTADDRESS$\nInfo: $HOSTOUTPUT$\n\nDate/Time: $LONGDATETIME$\n" | /bin/mail -s "** $NOTIFICATIONTYPE$ Host Alert: $HOSTNAME$ is $HOSTSTATE$ **" $CONTACTEMAIL$
      command_name                   notify-host-by-email
    }

    define command {
      command_line                   /usr/bin/printf "%b" "***** Nagios *****\n\nNotification Type: $NOTIFICATIONTYPE$\n\nService: $SERVICEDESC$\nHost: $HOSTALIAS$\nAddress: $HOSTADDRESS$\nState: $SERVICESTATE$\n\nDate/Time: $LONGDATETIME$\n\nAdditional Info:\n\n$SERVICEOUTPUT$\n" | /bin/mail -s "** $NOTIFICATIONTYPE$ Service Alert: $HOSTALIAS$/$SERVICEDESC$ is $SERVICESTATE$ **" $CONTACTEMAIL$
      command_name                   notify-service-by-email
    }

    define command {
      command_line                   /usr/bin/printf "%b" "$LASTHOSTCHECK$\t$HOSTNAME$\t$HOSTSTATE$\t$HOSTATTEMPT$\t$HOSTSTATETYPE$\t$HOSTEXECUTIONTIME$\t$HOSTOUTPUT$\t$HOSTPERFDATA$\n" >> /var/log/nagios/host-perfdata.out
      command_name                   process-host-perfdata
    }

    define command {
      command_line                   /usr/bin/printf "%b" "$LASTSERVICECHECK$\t$HOSTNAME$\t$SERVICEDESC$\t$SERVICESTATE$\t$SERVICEATTEMPT$\t$SERVICESTATETYPE$\t$SERVICEEXECUTIONTIME$\t$SERVICELATENCY$\t$SERVICEOUTPUT$\t$SERVICEPERFDATA$\n" >> /var/log/nagios/service-perfdata.out
      command_name                   process-service-perfdata
    }

    define timeperiod {
      alias                          U.S. Holidays
      december 25             00:00-00:00     ; Christmas
      january 1               00:00-00:00     ; New Years
      july 4                  00:00-00:00     ; Independence Day
      monday -1 may           00:00-00:00     ; Memorial Day (last Monday in May)
      monday 1 september      00:00-00:00     ; Labor Day (first Monday in September)
      name			us-holidays
      thursday 4 november     00:00-00:00     ; Thanksgiving (4th Thursday in November)
      timeperiod_name                us-holidays
    }

    define host {
      name                           windows-server
      use                            generic-host
      check_command                  check-host-alive
      check_interval                 5
      check_period                   24x7
      contact_groups                 admins
      hostgroups
      max_check_attempts             10
      notification_interval          30
      notification_options           d,r
      notification_period            24x7
      register                       0
      retry_interval                 1
    }

    define hostgroup {
      alias                          Windows Servers
      hostgroup_name                 windows-servers
    }

    define timeperiod {
      alias                 Normal Work Hours
      friday                09:00-17:00
      monday                09:00-17:00
      thursday              09:00-17:00
      timeperiod_name       workhours
      tuesday               09:00-17:00
      wednesday             09:00-17:00
    }

    define command {
        command_name    check_dummy
        command_line    $USER1$/check_dummy!$ARG1$!$ARG2$
    }


    define host {
        host_name           ok_host
        use                 generic-host
        address	            ok_host
        max_check_attempts	1
        check_command       check_dummy!0!Everything seems to be okay
    }


    define service {
        host_name           ok_host
        use                 generic-service
        service_description ok service 1
        check_command       check_dummy!0!Everything seems to be okay
    }

    """

########NEW FILE########
__FILENAME__ = fakeplugin
#!/usr/bin/python

import os.path
import sys

pynagbase = os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir))
sys.path[0] = pynagbase

# Standard init
import pynag.Plugins
from pynag.Plugins import WARNING, CRITICAL, OK, UNKNOWN, simple as Plugin

np = Plugin()

# Feed fake data for range checking
np.add_arg('F', 'fakedata', 'fake data to test thresholds', required=True)

# Activate
np.activate()

# Test supplied fake data against thresholds
np.check_range(int(np['fakedata']))


########NEW FILE########
__FILENAME__ = fakepluginhelper
#!/usr/bin/python

import os.path
import sys

pynagbase = os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir))
sys.path[0] = pynagbase

# Standard init
from pynag.Plugins import PluginHelper, ok

# Create an instance of PluginHelper()
my_plugin = PluginHelper()

# Feed fake data for range checking
my_plugin.parser.add_option('-F', dest='fakedata', help='fake data to test thresholds')

# Activate
my_plugin.parse_arguments()

# Check if -F was provided
if my_plugin.options.fakedata is None:
    my_plugin.parser.error("Specify some value with -F")

my_plugin.add_status(ok)
my_plugin.add_summary(my_plugin.options.fakedata)
my_plugin.add_metric('fakedata', my_plugin.options.fakedata)

my_plugin.check_all_metrics()

my_plugin.exit()

########NEW FILE########
__FILENAME__ = fakepluginnothres
#!/usr/bin/python

import os.path
import sys

pynagbase = os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir))
sys.path[0] = pynagbase

# Standard init
import pynag.Plugins
from pynag.Plugins import WARNING, CRITICAL, OK, UNKNOWN, simple as Plugin

np = Plugin(must_threshold=False)

# Feed fake data for range checking
np.add_arg('F', 'fakedata', 'fake data to test thresholds', required=True)

# Activate
np.activate()

# Test supplied fake data against thresholds
np.check_range(int(np['fakedata']))


########NEW FILE########
__FILENAME__ = build-test
#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# pynag - Python Nagios plug-in and configuration environment
# Copyright (C) 2013 Pall Sigurdsson
# 
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
# 
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
# 
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.


# Varios test that must be passed in order for build process to complete


########NEW FILE########
__FILENAME__ = test
#!/usr/bin/env python
import os
import sys

# Make sure we import from working tree
pynagbase = os.path.dirname(os.path.realpath(__file__ + "/.."))
sys.path.insert(0, pynagbase)

import unittest2
import doctest
import mock

# Make sure all tests run from a fixed path, this also makes sure
# That pynag in local directory is imported before any system-wide
# installs of pynag
from tests import tests_dir

import pynag.Model
import pynag.Parsers
import pynag.Plugins
import pynag.Control
import pynag.Utils


def load_tests(loader=None, tests=None, pattern=None):
    """ Discover and load all unit tests in all files named ``*_test.py`` in ``./src/`` """
    suite = unittest2.TestSuite()

    # Add all doctests to our suite
    suite.addTest(doctest.DocTestSuite(pynag.Model, setUp=setUpDocTests))
    suite.addTest(doctest.DocTestSuite(pynag.Parsers, setUp=setUpDocTests))
    suite.addTest(doctest.DocTestSuite(pynag.Plugins))
    suite.addTest(doctest.DocTestSuite(pynag.Control))
    suite.addTest(doctest.DocTestSuite(pynag.Model))
    suite.addTest(doctest.DocTestSuite(pynag.Utils))

    # Load unit tests from all files starting with test_*
    for all_test_suite in unittest2.defaultTestLoader.discover('.', pattern='test_*.py'):
        for test_suite in all_test_suite:
            suite.addTests(test_suite)
    return suite


def setUpDocTests(doctest):
    """ For doctests that require a valid config to function, we point them
        to dataset01
    """
    os.chdir(os.path.join(tests_dir, 'dataset01'))
    pynag.Model.config = pynag.Parsers.config(cfg_file="./nagios/nagios.cfg")

if __name__ == "__main__":
    unittest2.main()

# vim: sts=4 expandtab autoindent

########NEW FILE########
__FILENAME__ = testmultithreads
#!/usr/bin/python
# This should go into pynag's unit testing at some point
# This script tries multithreaded writes to the pynag Model
# and prints error to screen if any writes fail


import pynag.Model
from multiprocessing import Pool
from multiprocessing.pool import ThreadPool


def change(host):
  host.address = "127.0.0.1"
  host.save()
  pynag.Model.ObjectDefinition.objects.get_all()
  print "Set address", host.address, "to", host.host_name
    

if __name__ == '__main__':
    hosts = pynag.Model.Host.objects.filter(host_name__startswith="web04")
    for i in hosts:
      i.address = "127.0.0.2"
      i.save()
    hosts = pynag.Model.Host.objects.filter(host_name__startswith="web04")

    p = ThreadPool(4)
    p.map(change, hosts)


    hosts = pynag.Model.Host.objects.filter(host_name__startswith="web04")
    for i in hosts:
      if i.address != "127.0.0.1":
        print "ERROR", i.host_name, "has address", i.address

########NEW FILE########
__FILENAME__ = test_command
import os
import sys

# Make sure we import from working tree
pynagbase = os.path.dirname(os.path.realpath(__file__ + "/.."))
sys.path.insert(0, pynagbase)

from tests import tests_dir
import unittest2 as unittest
from mock import MagicMock, patch, __version__

try:
    # open_mock comes with mock 1.0.1
    from mock import mock_open
except ImportError:
    def mock_open(mock=None, data=None):
        file_spec = file
        if mock is None:
            mock = MagicMock(spec=file_spec)

        handle = MagicMock(spec=file_spec)
        handle.write.return_value = None
        if data is None:
            handle.__enter__.return_value = handle
        else:
            handle.__enter__.return_value = data
        mock.return_value = handle
        return mock

from pynag.Control import Command

def is_mock_to_old():
    major, minor, patch = __version__.split('.')
    if int(major) == 0 and int(minor) < 8:
        return True
    else:
        return False


class testCommandsToCommandFile(unittest.TestCase):
    def setUp(self):
        self.command_file = '/tmp/cmdfile'
        self.timestamp = 1368219495
        self.testhost = 'hosttest.example.com'
        self.testauthor = 'user@example.com'
        self.test_svc_desc = 'Test Service'
        self.test_svc_group = 'TestSVCGroup'
        self.test_check_command = 'test_check_command'
        self.test_event_handler_command = 'test_event_handler'
        self.check_interval = 50

        self.command = Command

        # Setup patching for open()
        self.command_open_mock = mock_open()
        self.patcher1 = patch('pynag.Control.Command.open',
            self.command_open_mock, create=True)
        self.patcher1.start()

    def tearDown(self):
        self.patcher1.stop()

    def test_add_host_comment(self):
        persistent = 0
        comment = 'Test Comment!'
        self.command.add_host_comment(
                host_name=self.testhost,
                persistent=persistent,
                author=self.testauthor,
                comment=comment,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected_nagios_command = '[%s] ADD_HOST_COMMENT;%s;%s;%s;%s' % (
                self.timestamp, self.testhost, persistent,
                self.testauthor, comment
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected_nagios_command+'\n')

    def test_shutdown_program(self):
        self.command.shutdown_program(
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] SHUTDOWN_PROGRAM;' % self.timestamp
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_disable_service_group_passive_svc_checks(self):
        self.command.disable_servicegroup_passive_svc_checks(
                servicegroup_name=self.test_svc_group,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] DISABLE_SERVICEGROUP_PASSIVE_SVC_CHECKS;%s' % (
                self.timestamp, self.test_svc_group
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_enable_service_group_passive_host_checks(self):
        self.command.enable_servicegroup_passive_host_checks(
                servicegroup_name=self.test_svc_group,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] ENABLE_SERVICEGROUP_PASSIVE_HOST_CHECKS;%s' % (
                self.timestamp, self.test_svc_group
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_disable_servicegroup_passive_host_checks(self):
        self.command.disable_servicegroup_passive_host_checks(
                servicegroup_name=self.test_svc_group,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] DISABLE_SERVICEGROUP_PASSIVE_HOST_CHECKS;%s' % (
                self.timestamp, self.test_svc_group
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_change_global_host_event_handler(self):
        self.command.change_global_host_event_handler(
                event_handler_command=self.test_event_handler_command,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_GLOBAL_HOST_EVENT_HANDLER;%s' % (
                self.timestamp, self.test_event_handler_command
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_change_global_svc_event_handler(self):
        self.command.change_global_svc_event_handler(
                event_handler_command=self.test_event_handler_command,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_GLOBAL_SVC_EVENT_HANDLER;%s' % (
                self.timestamp, self.test_event_handler_command
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_change_host_event_handler(self):
        self.command.change_host_event_handler(
                host_name=self.testhost,
                event_handler_command=self.test_event_handler_command,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_HOST_EVENT_HANDLER;%s;%s' % (
                self.timestamp, self.testhost, self.test_event_handler_command
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')
        
    def test_change_svc_event_handler(self):
        self.command.change_svc_event_handler(
                host_name=self.testhost,
                service_description=self.test_svc_desc,
                event_handler_command= self.test_event_handler_command,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_SVC_EVENT_HANDLER;%s;%s;%s' % (
                self.timestamp, self.testhost, self.test_svc_desc,
                self.test_event_handler_command
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_change_host_check_command(self):
        self.command.change_host_check_command(
                host_name=self.testhost,
                check_command=self.test_check_command,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_HOST_CHECK_COMMAND;%s;%s' % (
                self.timestamp, self.testhost, self.test_check_command
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_change_svc_check_command(self):
        self.command.change_svc_check_command(
                host_name=self.testhost,
                service_description=self.test_svc_desc,
                check_command=self.test_check_command,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_SVC_CHECK_COMMAND;%s;%s;%s' % (
                self.timestamp, self.testhost, self.test_svc_desc,
                self.test_check_command
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_change_normal_host_check_interval(self):
        self.command.change_normal_host_check_interval(
                host_name=self.testhost,
                check_interval=self.check_interval,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_NORMAL_HOST_CHECK_INTERVAL;%s;%s' % (
                self.timestamp, self.testhost, self.check_interval
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_enable_svc_notifications(self):
        self.command.enable_svc_notifications(
                host_name=self.testhost,
                service_description=self.test_svc_desc,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] ENABLE_SVC_NOTIFICATIONS;%s;%s' % (
                self.timestamp, self.testhost, self.test_svc_desc
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')
        
    def test_change_normal_svc_check_interval(self):
        self.command.change_normal_svc_check_interval(
                host_name=self.testhost,
                service_description=self.test_svc_desc,
                check_interval=self.check_interval,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_NORMAL_SVC_CHECK_INTERVAL;%s;%s;%s' % (
                self.timestamp, self.testhost, self.test_svc_desc,
                self.check_interval
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')
        
    def test_change_retry_svc_check_interval(self):
        self.command.change_retry_svc_check_interval(
                host_name=self.testhost,
                service_description=self.test_svc_desc,
                check_interval=self.check_interval,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_RETRY_SVC_CHECK_INTERVAL;%s;%s;%s' % (
                self.timestamp, self.testhost, self.test_svc_desc,
                self.check_interval
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')
        
    def test_change_max_host_check_attempts(self):
        max_attempts = 30
        self.command.change_max_host_check_attempts(
                host_name=self.testhost,
                check_attempts=max_attempts,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_MAX_HOST_CHECK_ATTEMPTS;%s;%s' % (
                self.timestamp, self.testhost, max_attempts
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_change_max_svc_check_attempts(self):
        max_attempts = 30
        self.command.change_max_svc_check_attempts(
                host_name=self.testhost,
                service_description=self.test_svc_desc,
                check_attempts=max_attempts,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] CHANGE_MAX_SVC_CHECK_ATTEMPTS;%s;%s;%s' % (
                self.timestamp, self.testhost, self.test_svc_desc, max_attempts
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')

    def test_process_service_check_result(self):
        return_code = 2
        plugin_output = 'output'
        self.command.process_service_check_result(
                host_name=self.testhost,
                service_description=self.test_svc_desc,
                return_code=return_code,
                plugin_output=plugin_output,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = '[%s] PROCESS_SERVICE_CHECK_RESULT;%s;%s;%s;%s' % (
                self.timestamp, self.testhost, self.test_svc_desc,
                return_code, plugin_output
            )
        self.command_open_mock.assert_called_with(self.command_file, 'a')
        handle = self.command_open_mock()
        handle.write.assert_called_once_with(expected + '\n')


@unittest.skipIf(is_mock_to_old(), "Our version of mock is to old to run this test")
class testCommandsToLivestatus(unittest.TestCase):
    def setUp(self):
        self.command_file = '/tmp/cmdfile'
        self.timestamp = 1368219495
        self.testhost = 'hosttest.example.com'
        self.testauthor = 'user@example.com'
        self.test_svc_desc = 'Test Service'
        self.test_svc_group = 'TestSVCGroup'
        self.test_host_group = 'TestHostGroup'
        self.test_check_command = 'test_check_command'
        self.test_event_handler_command = 'test_event_handler'
        self.check_interval = 50
        self.livestatus_command_suffix = '\nResponseHeader: fixed16\nOutputFormat: python\nColumnHeaders: on\n'

        self.command = Command

        # Setup patching for command file exception
        self.patcher1 = patch('pynag.Control.Command._write_to_command_file', side_effect=Exception('Want to go to Livestatus'))
        self.comm_write_to_comm_file = self.patcher1.start()

        # Mock socket.connect
        self.patcher2 = patch('pynag.Parsers.socket.socket', spec=True)
        self.livestatus_socket = self.patcher2.start()

        # Change to mock config directory
        os.chdir(tests_dir)
        os.chdir('mocklivestatuscfg')

    def tearDown(self):
        self.patcher1.stop()
        self.patcher2.stop()

    """
    def get_mock_command(self):
        command = Command
        # Make writing to command file throw exception so we send to livestatus
        command._write_to_command_file = MagicMock(
                side_effect=Exception('Want to go to Livestatus')
            )
        command._write_to_livestatus = MagicMock()
        return command
    """

    def test_process_host_check_result(self):
        status_code = 2
        plugin_output = 'output'
        self.command.process_host_check_result(
                host_name=self.testhost,
                status_code=2,
                plugin_output=plugin_output,
                command_file=self.command_file, timestamp=self.timestamp
            )
        expected = 'COMMAND [%s] PROCESS_HOST_CHECK_RESULT;%s;%s;%s' % (self.timestamp, self.testhost, status_code, plugin_output)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)
        
    def test_remove_host_acknowledgement(self):
        self.command.remove_host_acknowledgement(
                host_name = self.testhost,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] REMOVE_HOST_ACKNOWLEDGEMENT;%s' % (self.timestamp, self.testhost)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)
        
    def test_remove_svc_acknowledgement(self):
        self.command.remove_svc_acknowledgement(
                host_name = self.testhost,
                service_description = self.test_svc_desc,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] REMOVE_SVC_ACKNOWLEDGEMENT;%s;%s' % (self.timestamp, self.testhost, self.test_svc_desc)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_schedule_host_downtime(self):
        start_time = self.timestamp + 1000
        end_time = self.timestamp + 2000
        fixed = 0
        trigger_id = 0
        duration = 0
        comment = 'Downtime!'
        self.command.schedule_host_downtime(
                host_name = self.testhost,
                start_time = start_time,
                end_time = end_time,
                fixed = fixed,
                trigger_id = trigger_id,
                duration = duration,
                author = self.testauthor,
                comment = comment,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_HOST_DOWNTIME;%s;%s;%s;%s;%s;%s;%s;%s' % (self.timestamp, self.testhost,
                start_time, end_time, fixed, trigger_id, duration, self.testauthor, comment)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)
                
    def test_schedule_svc_downtime(self):
        start_time = self.timestamp + 1000
        end_time = self.timestamp + 2000
        fixed = 0
        trigger_id = 0
        duration = 0
        comment = 'Downtime!'
        self.command.schedule_svc_downtime(
                host_name = self.testhost,
                service_description = self.test_svc_desc,
                start_time = start_time,
                end_time = end_time,
                fixed = fixed,
                trigger_id = trigger_id,
                duration = duration,
                author = self.testauthor,
                comment = comment,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_SVC_DOWNTIME;%s;%s;%s;%s;%s;%s;%s;%s;%s' % (self.timestamp, self.testhost,
                self.test_svc_desc, start_time, end_time, fixed, trigger_id, duration, self.testauthor, comment)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)
                
    def test_disable_svc_notifications(self):
        self.command.disable_svc_notifications(
                host_name = self.testhost,
                service_description = self.test_svc_desc,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] DISABLE_SVC_NOTIFICATIONS;%s;%s' % (self.timestamp, self.testhost, self.test_svc_desc)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)
        
    def test_schedule_servicegroup_svc_downtime(self):
        start_time = self.timestamp + 1000
        end_time = self.timestamp + 2000
        fixed = 0
        trigger_id = 0
        duration = 0
        comment = 'Downtime!'
        self.command.schedule_servicegroup_svc_downtime(
                servicegroup_name = self.test_svc_group,
                start_time = start_time,
                end_time = end_time,
                fixed = fixed,
                trigger_id = trigger_id,
                duration = duration,
                author = self.testauthor,
                comment = comment,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_SERVICEGROUP_SVC_DOWNTIME;%s;%s;%s;%s;%s;%s;%s;%s' % (self.timestamp, self.test_svc_group,
                start_time, end_time, fixed, trigger_id, duration, self.testauthor, comment)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_schedule_servicegroup_host_downtime(self):
        start_time = self.timestamp + 1000
        end_time = self.timestamp + 2000
        fixed = 0
        trigger_id = 0
        duration = 0
        comment = 'Downtime!'
        self.command.schedule_servicegroup_host_downtime(
                servicegroup_name = self.test_svc_group,
                start_time = start_time,
                end_time = end_time,
                fixed = fixed,
                trigger_id = trigger_id,
                duration = duration,
                author = self.testauthor,
                comment = comment,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_SERVICEGROUP_HOST_DOWNTIME;%s;%s;%s;%s;%s;%s;%s;%s' % (self.timestamp, self.test_svc_group,
                start_time, end_time, fixed, trigger_id, duration, self.testauthor, comment)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_schedule_host_svc_downtime(self):
        start_time = self.timestamp + 1000
        end_time = self.timestamp + 2000
        fixed = 0
        trigger_id = 0
        duration = 0
        comment = 'Downtime!'
        self.command.schedule_host_svc_downtime(
                host_name = self.testhost,
                start_time = start_time,
                end_time = end_time,
                fixed = fixed,
                trigger_id = trigger_id,
                duration = duration,
                author = self.testauthor,
                comment = comment,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_HOST_SVC_DOWNTIME;%s;%s;%s;%s;%s;%s;%s;%s' % (self.timestamp, self.testhost,
                start_time, end_time, fixed, trigger_id, duration, self.testauthor, comment)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_schedule_hostgroup_host_downtime(self):
        start_time = self.timestamp + 1000
        end_time = self.timestamp + 2000
        fixed = 0
        trigger_id = 0
        duration = 0
        comment = 'Downtime!'
        self.command.schedule_hostgroup_host_downtime(
                hostgroup_name = self.test_host_group,
                start_time = start_time,
                end_time = end_time,
                fixed = fixed,
                trigger_id = trigger_id,
                duration = duration,
                author = self.testauthor,
                comment = comment,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_HOSTGROUP_HOST_DOWNTIME;%s;%s;%s;%s;%s;%s;%s;%s' % (self.timestamp, self.test_host_group,
                start_time, end_time, fixed, trigger_id, duration, self.testauthor, comment)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_schedule_hostgroup_svc_downtime(self):
        start_time = self.timestamp + 1000
        end_time = self.timestamp + 2000
        fixed = 0
        trigger_id = 0
        duration = 0
        comment = 'Downtime!'
        self.command.schedule_hostgroup_svc_downtime(
                hostgroup_name = self.test_host_group,
                start_time = start_time,
                end_time = end_time,
                fixed = fixed,
                trigger_id = trigger_id,
                duration = duration,
                author = self.testauthor,
                comment = comment,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_HOSTGROUP_SVC_DOWNTIME;%s;%s;%s;%s;%s;%s;%s;%s' % (self.timestamp, self.test_host_group,
                start_time, end_time, fixed, trigger_id, duration, self.testauthor, comment)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_del_host_downtime(self):
        downtime_id = 100
        self.command.del_host_downtime(
                downtime_id = downtime_id,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] DEL_HOST_DOWNTIME;%s' % (self.timestamp, downtime_id)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_del_svc_downtime(self):
        downtime_id = 100
        self.command.del_svc_downtime(
                downtime_id = downtime_id,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] DEL_SVC_DOWNTIME;%s' % (self.timestamp, downtime_id)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_schedule_host_check(self):
        self.command.schedule_host_check(
                host_name = self.testhost,
                check_time = self.timestamp,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_HOST_CHECK;%s;%s' % (self.timestamp, self.testhost, self.timestamp)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_schedule_forced_host_check(self):
        self.command.schedule_forced_host_check(
                host_name = self.testhost,
                check_time = self.timestamp,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_FORCED_HOST_CHECK;%s;%s' % (self.timestamp, self.testhost, self.timestamp)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_schedule_forced_svc_check(self):
        self.command.schedule_forced_svc_check(
                host_name = self.testhost,
                service_description = self.test_svc_desc,
                check_time = self.timestamp,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_FORCED_SVC_CHECK;%s;%s;%s' % (self.timestamp, self.testhost, self.test_svc_desc, self.timestamp)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_del_all_host_comments(self):
        self.command.del_all_host_comments(
                host_name = self.testhost,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] DEL_ALL_HOST_COMMENTS;%s' % (self.timestamp, self.testhost)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_schedule_forced_host_svc_checks(self):
        self.command.schedule_forced_host_svc_checks(
                host_name = self.testhost,
                check_time = self.timestamp,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] SCHEDULE_FORCED_HOST_SVC_CHECKS;%s;%s' % (self.timestamp, self.testhost, self.timestamp)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)

    def test_process_file(self):
        file_name = '/tmp/testfile'
        delete = 1
        self.command.process_file(
                file_name = file_name,
                delete = delete,
                command_file = self.command_file, timestamp = self.timestamp
            )
        expected = 'COMMAND [%s] PROCESS_FILE;%s;%s' % (self.timestamp, file_name, delete)
        sock = self.livestatus_socket()
        sock.send.assert_called_with(expected + self.livestatus_command_suffix)


if __name__ == "__main__":
    unittest.main()

# vim: sts=4 expandtab autoindent

########NEW FILE########
__FILENAME__ = test_control
#!/usr/bin/env python

import os
import sys

# Make sure we import from working tree
pynagbase = os.path.dirname(os.path.realpath(__file__ + "/.."))
sys.path.insert(0, pynagbase)

import unittest2 as unittest
from mock import MagicMock, patch, Mock

import pynag.Control
from pynag.Parsers import config

import warnings

class testControl(unittest.TestCase):
    def setUp(self):
        """
        Set to the current defaults of the control.daemon() class
        It's probably dangerous to read these variables from the class object itself
        """
        self.config = config()

        # Ignore futurewarnings for nagios_init
        warnings.simplefilter("ignore", FutureWarning)

        self.nagios_bin=self.config.guess_nagios_binary()
        self.nagios_cfg='/etc/nagios/nagios.cfg'
        self.service_name = 'nagios'
        self.nagios_init = "service nagios"

        # Save reference to mocked functions
        self.runCommand = pynag.Control.runCommand
        self.osexists = os.path.exists

        self.control = pynag.Control.daemon(
                nagios_bin=self.nagios_bin,
                nagios_cfg=self.nagios_cfg,
                nagios_init=self.nagios_init,
                service_name=self.service_name)

    def tearDown(self):
        # Restore potentially mocked functions
        pynag.Control.runCommand = self.runCommand
        os.path.exists = self.osexists

    def test_verify_config_success(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "", ""]

        # Run the actual daemon.verify_config
        result = self.control.verify_config()

        # Should verify correctly
        self.assertTrue(result)

        # Make sure runCommand is called correctly
        pynag.Control.runCommand.assert_called_once_with(["sudo", self.nagios_bin, "-v", self.nagios_cfg],
            shell=False
            )

    def test_verify_config_failure(self):
        # Patch all calls to Popen, make calls return exit code 1
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [2, "", "Permission denied"]

        # Run the actual daemon.verify_config
        result = self.control.verify_config()

        # Should return None on verify error
        self.assertEqual(result, None)

        # Make sure runCommand is called correctly
        pynag.Control.runCommand.assert_called_once()
        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", self.nagios_bin, "-v", self.nagios_cfg],
            shell=False)

    def test_restart_script(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "OK Restarted", ""]

        self.control.method = self.control.SYSV_INIT_SCRIPT
        result = self.control.restart()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", self.nagios_init, "restart"], shell=False)

    def test_restart_service(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "OK Restarted", ""]

        self.control.method = self.control.SYSV_INIT_SERVICE
        result = self.control.restart()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", "service", self.service_name, "restart"], shell=False)

    def test_restart_systemd(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "", ""]

        self.control.method = self.control.SYSTEMD
        result = self.control.restart()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", "service", self.service_name, "restart"], shell=False)

    def test_status_script(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "OK Running just fine", ""]

        self.control.method = self.control.SYSV_INIT_SCRIPT
        result = self.control.status()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", self.nagios_init, "status"], shell=False)

    def test_status_service(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "OK Running just fine", ""]

        self.control.method = self.control.SYSV_INIT_SERVICE
        result = self.control.status()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", "service", self.service_name, "status"], shell=False)

    def test_status_systemd(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "", ""]

        self.control.method = self.control.SYSTEMD
        result = self.control.status()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", "service", self.service_name, "status"], shell=False)

    def test_reload_script(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "OK Reloaded just fine", ""]

        self.control.method = self.control.SYSV_INIT_SCRIPT
        self.control.reload()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", self.nagios_init, "reload"], shell=False)

    def test_reload_service(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "OK Reloaded just fine", ""]

        self.control.method = self.control.SYSV_INIT_SERVICE
        self.control.reload()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", "service", self.service_name, "reload"], shell=False)

    def test_reload_systemd(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "", ""]

        self.control.method = self.control.SYSTEMD
        self.control.reload()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", "service", self.service_name, "reload"], shell=False)

    def test_stop_script(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "OK Stopped service", ""]

        self.control.method = self.control.SYSV_INIT_SCRIPT
        self.control.stop()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", self.nagios_init, "stop"], shell=False)

    def test_stop_service(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "OK Stopped service", ""]

        self.control.method = self.control.SYSV_INIT_SERVICE
        self.control.stop()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", "service", self.service_name, "stop"], shell=False)

    def test_stop_systemd(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "", ""]

        self.control.method = self.control.SYSTEMD
        self.control.stop()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", "service", self.service_name, "stop"], shell=False)

    def test_start_script(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "OK Started service", ""]

        self.control.method = self.control.SYSV_INIT_SCRIPT
        self.control.start()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", self.nagios_init, "start"], shell=False)

    def test_start_service(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "OK Started service", ""]

        self.control.method = self.control.SYSV_INIT_SERVICE
        self.control.start()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", "service", self.service_name, "start"], shell=False)

    def test_start_systemd(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "", ""]

        self.control.method = self.control.SYSTEMD
        self.control.start()

        pynag.Control.runCommand.assert_called_once_with(
            ["sudo", "service", self.service_name, "start"], shell=False)

    def test_running_script(self):
        pynag.Parsers.config._get_pid = MagicMock()
        pynag.Parsers.config._get_pid.return_value = 1024

        self.control.method = self.control.SYSV_INIT_SCRIPT
        running = self.control.running()

        self.assertEqual(running, True)
        pynag.Parsers.config._get_pid.assert_called_once_with()

    def test_running_service(self):
        pynag.Parsers.config._get_pid = MagicMock()
        pynag.Parsers.config._get_pid.return_value = 1024

        self.control.method = self.control.SYSV_INIT_SERVICE
        running = self.control.running()

        self.assertEqual(running, True)
        pynag.Parsers.config._get_pid.assert_called_once_with()

    def test_running_systemd(self):
        pynag.Control.runCommand = MagicMock()
        pynag.Control.runCommand.return_value = [0, "", ""]

        self.control.method = self.control.SYSTEMD
        running = self.control.running()

        self.assertEqual(running, True)
        pynag.Control.runCommand.assert_called_once_with(
            ["systemctl", "is-active", self.service_name], shell=False)

    def test_running_failed_script(self):
        pynag.Parsers.config._get_pid = MagicMock()
        pynag.Parsers.config._get_pid.return_value = None

        self.control.method = self.control.SYSV_INIT_SCRIPT
        running = self.control.running()

        self.assertEqual(running, False)
        pynag.Parsers.config._get_pid.assert_called_once_with()

    def test_method_initscript_sudo(self):
        os.path.exists = MagicMock()
        os.path.exists.return_value = True

        self.control.nagios_init = "sudo /etc/init.d/nagios"
        self.control.sudo = False

        self.control._deprecate_sudo()
        method = self.control._guess_method()

        self.assertEqual(method, self.control.SYSV_INIT_SCRIPT)
        self.assertEqual(self.control.nagios_init, "/etc/init.d/nagios")
        self.assertEqual(self.control.sudo, True)

    def test_method_initscript_nosudo(self):
        os.path.exists = MagicMock()
        os.path.exists.return_value = True

        self.control.nagios_init = "/etc/init.d/nagios"
        self.control.sudo = False

        self.control._deprecate_sudo()
        method = self.control._guess_method()

        self.assertEqual(method, self.control.SYSV_INIT_SCRIPT)
        self.assertEqual(self.control.nagios_init, "/etc/init.d/nagios")
        self.assertEqual(self.control.sudo, False)

    def test_method_init_service_sudo(self):
        self.control.nagios_init = "sudo service nagios"
        self.control.sudo = False

        self.control._deprecate_sudo()
        method = self.control._guess_method()

        self.assertEqual(method, self.control.SYSV_INIT_SERVICE)
        self.assertEqual(self.control.service_name, "nagios")
        self.assertEqual(self.control.sudo, True)

    def test_method_init_fullpath_service_sudo(self):
        self.control.nagios_init = "/usr/bin/sudo /sbin/service nagios"
        self.control.sudo = False

        self.control._deprecate_sudo()
        method = self.control._guess_method()

        self.assertEqual(method, self.control.SYSV_INIT_SERVICE)
        self.assertEqual(self.control.service_name, "nagios")
        self.assertEqual(self.control.sudo, True)


if __name__ == "__main__":
    unittest.main()

# vim: sts=4 expandtab autoindent

########NEW FILE########
__FILENAME__ = test_defaultdict
"""Unit tests for collections.defaultdict."""

import os
import sys

# Make sure we import from working tree
pynagbase = os.path.dirname(os.path.realpath(__file__ + "/.."))
sys.path.insert(0, pynagbase)


import copy
import tempfile
import unittest2 as unittest

from pynag.Utils import defaultdict

def foobar():
    return list

class TestDefaultDict(unittest.TestCase):

    def test_basic(self):
        d1 = defaultdict()
        self.assertEqual(d1.default_factory, None)
        d1.default_factory = list
        d1[12].append(42)
        self.assertEqual(d1, {12: [42]})
        d1[12].append(24)
        self.assertEqual(d1, {12: [42, 24]})
        d1[13]
        d1[14]
        self.assertEqual(d1, {12: [42, 24], 13: [], 14: []})
        self.assertTrue(d1[12] is not d1[13] is not d1[14])
        d2 = defaultdict(list, foo=1, bar=2)
        self.assertEqual(d2.default_factory, list)
        self.assertEqual(d2, {"foo": 1, "bar": 2})
        self.assertEqual(d2["foo"], 1)
        self.assertEqual(d2["bar"], 2)
        self.assertEqual(d2[42], [])
        self.assertIn("foo", d2)
        self.assertIn("foo", d2.keys())
        self.assertIn("bar", d2)
        self.assertIn("bar", d2.keys())
        self.assertIn(42, d2)
        self.assertIn(42, d2.keys())
        self.assertNotIn(12, d2)
        self.assertNotIn(12, d2.keys())
        d2.default_factory = None
        self.assertEqual(d2.default_factory, None)
        try:
            d2[15]
        except KeyError, err:
            self.assertEqual(err.args, (15,))
        else:
            self.fail("d2[15] didn't raise KeyError")
        self.assertRaises(TypeError, defaultdict, 1)

    def test_missing(self):
        d1 = defaultdict()
        self.assertRaises(KeyError, d1.__missing__, 42)
        d1.default_factory = list
        self.assertEqual(d1.__missing__(42), [])

    def test_repr(self):
        d1 = defaultdict()
        self.assertEqual(d1.default_factory, None)
        self.assertEqual(repr(d1), "defaultdict(None, {})")
        self.assertEqual(eval(repr(d1)), d1)
        d1[11] = 41
        self.assertEqual(repr(d1), "defaultdict(None, {11: 41})")
        d2 = defaultdict(int)
        self.assertEqual(d2.default_factory, int)
        d2[12] = 42
        self.assertEqual(repr(d2), "defaultdict(<type 'int'>, {12: 42})")
        def foo(): return 43
        d3 = defaultdict(foo)
        self.assertTrue(d3.default_factory is foo)
        d3[13]
        self.assertEqual(repr(d3), "defaultdict(%s, {13: 43})" % repr(foo))

    def test_print(self):
        d1 = defaultdict()
        def foo(): return 42
        d2 = defaultdict(foo, {1: 2})
        # NOTE: We can't use tempfile.[Named]TemporaryFile since this
        # code must exercise the tp_print C code, which only gets
        # invoked for *real* files.
        tfn = tempfile.mktemp()
        try:
            f = open(tfn, "w+")
            try:
                print >>f, d1
                print >>f, d2
                f.seek(0)
                self.assertEqual(f.readline(), repr(d1) + "\n")
                self.assertEqual(f.readline(), repr(d2) + "\n")
            finally:
                f.close()
        finally:
            os.remove(tfn)

    def test_copy(self):
        d1 = defaultdict()
        d2 = d1.copy()
        self.assertEqual(type(d2), defaultdict)
        self.assertEqual(d2.default_factory, None)
        self.assertEqual(d2, {})
        d1.default_factory = list
        d3 = d1.copy()
        self.assertEqual(type(d3), defaultdict)
        self.assertEqual(d3.default_factory, list)
        self.assertEqual(d3, {})
        d1[42]
        d4 = d1.copy()
        self.assertEqual(type(d4), defaultdict)
        self.assertEqual(d4.default_factory, list)
        self.assertEqual(d4, {42: []})
        d4[12]
        self.assertEqual(d4, {42: [], 12: []})

        # Issue 6637: Copy fails for empty default dict
        d = defaultdict()
        d['a'] = 42
        e = d.copy()
        self.assertEqual(e['a'], 42)

    def test_shallow_copy(self):
        d1 = defaultdict(foobar, {1: 1})
        d2 = copy.copy(d1)
        self.assertEqual(d2.default_factory, foobar)
        self.assertEqual(d2, d1)
        d1.default_factory = list
        d2 = copy.copy(d1)
        self.assertEqual(d2.default_factory, list)
        self.assertEqual(d2, d1)

    def test_deep_copy(self):
        d1 = defaultdict(foobar, {1: [1]})
        d2 = copy.deepcopy(d1)
        self.assertEqual(d2.default_factory, foobar)
        self.assertEqual(d2, d1)
        self.assertTrue(d1[1] is not d2[1])
        d1.default_factory = list
        d2 = copy.deepcopy(d1)
        self.assertEqual(d2.default_factory, list)
        self.assertEqual(d2, d1)

    def test_keyerror_without_factory(self):
        d1 = defaultdict()
        try:
            d1[(1,)]
        except KeyError, err:
            self.assertEqual(err.args[0], (1,))
        else:
            self.fail("expected KeyError")

    @unittest.skip("This fails")
    def test_recursive_repr(self):
        # Issue2045: stack overflow when default_factory is a bound method
        class sub(defaultdict):
            def __init__(self):
                self.default_factory = self._factory
            def _factory(self):
                return []
        d = sub()
        self.assertTrue(repr(d).startswith(
            "defaultdict(<bound method sub._factory of defaultdict(..."))

        # NOTE: printing a subclass of a builtin type does not call its
        # tp_print slot. So this part is essentially the same test as above.
        tfn = tempfile.mktemp()
        try:
            f = open(tfn, "w+")
            try:
                print >>f, d
            finally:
                f.close()
        finally:
            os.remove(tfn)

if __name__ == "__main__":
    unittest.main()

# vim: sts=4 expandtab autoindent

########NEW FILE########
__FILENAME__ = test_model
import os
import sys

# Make sure we import from working tree
pynagbase = os.path.dirname(os.path.realpath(__file__ + "/.."))
sys.path.insert(0, pynagbase)

import unittest2 as unittest
import tempfile
import os
import shutil
import string
import random
import mock
import time
import sys

import pynag.Model
import pynag.Model.EventHandlers
import pynag.Utils.misc
from tests import tests_dir

os.chdir(tests_dir)


class Model(unittest.TestCase):
    """
    Basic Unit Tests that relate to saving objects
    """
    def setUp(self):
        """ Basic setup before test suite starts
        """
        self.tmp_dir = tempfile.mkdtemp()  # Will be deleted after test runs

        os.chdir(tests_dir)
        os.chdir('dataset01')
        pynag.Model.cfg_file = "./nagios/nagios.cfg"
        pynag.Model.config = None
        pynag.Model.pynag_directory = self.tmp_dir
        pynag.Model.ObjectDefinition.objects.get_all()
        pynag.Model.config._edit_static_file(attribute='cfg_dir', new_value=self.tmp_dir)

    def tearDown(self):
        """ Clean up after test suite has finished
        """
        shutil.rmtree(self.tmp_dir, ignore_errors=True)
        pynag.Model.ObjectDefinition.objects.get_all()
        pynag.Model.config._edit_static_file(attribute='cfg_dir',old_value=self.tmp_dir,new_value=None)

    def testSuggestedFileName(self):
        """ Test get_suggested_filename feature in pynag.Model
        """
        s1 = pynag.Model.Service()
        s1.service_description = 'Service without host_name'

        s2 = pynag.Model.Service()
        s2.service_description = 'Service with host_name'
        s2.host_name = 'host.example.com'

        s3 = pynag.Model.Service()
        s3.service_description = 'Service with Generic Name'
        s3.name = 'generic-test-service'

        s1_expected = '%s/services/Servicewithouthost_name.cfg' % pynag.Model.pynag_directory
        s2_expected = '%s/services/Servicewithhost_name.cfg' % pynag.Model.pynag_directory
        s3_expected = '%s/services/generic-test-service.cfg' % pynag.Model.pynag_directory

        self.assertEqual(s1_expected, s1.get_suggested_filename())
        self.assertEqual(s2_expected, s2.get_suggested_filename())
        self.assertEqual(s3_expected, s3.get_suggested_filename())

    def testChangeAttribute(self):
        """ Change a single attribute in a pynag Model object
        """

        s = pynag.Model.Service()
        service_description = "Test Service Description"
        host_name = "testhost.example.com"
        macro = "This is a test macro"
        check_command = "my_check_command"

        # Assign the regular way
        s.service_description = service_description

        # Assign with set_attribute
        s.set_attribute('check_command', check_command)

        # Assign hashmap style
        s['host_name'] = host_name

        # Assign a macro
        s['__TEST_MACRO'] = macro

        self.assertEqual(service_description, s['service_description'])
        self.assertEqual(host_name, s.host_name)
        self.assertEqual(macro, s['__TEST_MACRO'])
        self.assertEqual(check_command, s.get_attribute('check_command'))

    def testServicegroupMembership(self):
        """ Loads servicegroup definitions from testdata01 and checks if get_effective_services works as expected
        """

        # service1 and service2 should both belong to group but they are defined differently
        group = pynag.Model.Servicegroup.objects.get_by_shortname('group-2')
        service1 = pynag.Model.Service.objects.get_by_shortname('node-1/cpu')
        service2 = pynag.Model.Service.objects.get_by_shortname('node-1/cpu2')
        self.assertEqual([group], service1.get_effective_servicegroups())
        self.assertEqual([group], service2.get_effective_servicegroups())
        self.assertEqual(sorted([service1, service2]), sorted(group.get_effective_services()))

    def testHostDelete(self):
        """ Create a test object and then delete it. """
        host = pynag.Model.Host()

        all_hosts = pynag.Model.Host.objects.get_all()
        all_hostnames = map(lambda x: x.host_name, all_hosts)

        # generate a random hostname for our new host
        chars = string.letters + string.digits
        host_name = "host-delete-test"  + ''.join([random.choice(chars) for i in xrange(10)])

        # Produce an error if our randomly generated host already exists in config
        self.assertTrue(host_name not in all_hostnames)

        # Save our new host and reload our config if we somehow failed to create the
        # host we will get an exception here.
        host.host_name = host_name
        host.save()
        host = pynag.Model.Host.objects.get_by_shortname(host_name)

        # Host has been created. Lets delete it.
        host.delete()

        # Lets get all hosts again, and make sure the list is the same as when we started
        # If it is the same, the host was surely deleted
        all_hosts_after_delete = pynag.Model.Host.objects.get_all()
        self.assertEqual(all_hosts,all_hosts_after_delete)

    def testSaveNewObject(self):
        """ Test creating a new object with the model """
        hostname1 = "new_host1"
        hostname2 = "new_host2"

        # First of all, make sure the new hosts do not exist in the config before we save.
        hostlist1 = pynag.Model.Host.objects.filter(host_name=hostname1)
        hostlist2 = pynag.Model.Host.objects.filter(host_name=hostname2)

        self.assertEqual([], hostlist1)
        self.assertEqual([], hostlist2)

        # Save a new object, let pynag decide where it is saved.
        host = pynag.Model.Host(host_name=hostname1)
        host.save()
        hostlist1 = pynag.Model.Host.objects.filter(host_name=hostname1)
        self.assertEqual(1, len(hostlist1))

        # Save a new object, this time lets specify a filename for it
        host = pynag.Model.Host(host_name=hostname2)
        dest_file = "%s/newhost2.cfg" % pynag.Model.pynag_directory
        host.set_filename(dest_file)
        host.save()
        hostlist2 = pynag.Model.Host.objects.filter(host_name=hostname2)
        self.assertEqual(1, len(hostlist2))
        host = hostlist2[0]
        self.assertEqual(dest_file, host.get_filename())

    def testSaveExistingObjects(self):
        """ Test saving existing objects to both same file and a new file
        """
        # Save our host
        host_name = "testhost"
        use = 'generic-host'
        host = pynag.Model.Host(host_name=host_name, use=use)
        host.save()
        origin_filename = host.get_filename()

        # Parse again and see if we find the same host:
        host = pynag.Model.Host.objects.get_by_shortname(host_name)
        self.assertEqual(host_name, host.host_name)
        self.assertEqual(use, host.use)
        self.assertEqual(origin_filename, host.get_filename())
        self.assertFalse(host.is_dirty())

        # Change host a little bit, and save to a new file:
        new_host_name = host_name + "2"
        new_filename = origin_filename + "-saveagain.cfg"
        host.host_name = new_host_name
        self.assertTrue(host.is_dirty())
        host.set_filename(new_filename)
        host.save()

        # Parse again and see if we find the same host:
        host = pynag.Model.Host.objects.get_by_shortname(new_host_name)
        self.assertEqual(new_host_name, host.host_name)
        self.assertEqual(use, host.use)
        self.assertEqual(new_filename, host.get_filename())

        # Save it for the third time, this time using parameter to save()
        new_new_host_name = host.host_name + "-2"
        new_new_filename = host.get_filename() + "-new.cfg"
        host.host_name = new_new_host_name
        host.save(filename=new_new_filename)

        new_host = pynag.Model.Host.objects.get_by_shortname(new_new_host_name)
        self.assertEqual(new_new_filename, new_host.get_filename())
        self.assertEqual(new_new_host_name, new_host.host_name)

    def testMoveObject(self):
        """ Test ObjectDefinition.move() """

        file1 = pynag.Model.pynag_directory + "/file1.cfg"
        file2 = pynag.Model.pynag_directory + "/file2.cfg"
        host_name="movable_host"
        new_object = pynag.Model.Host(host_name=host_name)
        new_object.set_filename(file1)
        new_object.save()

        # Reload config, and see if new object is saved where we wanted it to be
        search_results = pynag.Model.Host.objects.filter(host_name=host_name)
        self.assertEqual(1, len(search_results))

        host = search_results[0]
        self.assertEqual(file1, host.get_filename())

        # Move the host to a new file and make sure it is moved.
        host.move(file2)

        search_results = pynag.Model.Host.objects.filter(host_name=host_name)
        self.assertEqual(1, len(search_results))

        host = search_results[0]
        self.assertEqual(file2, host.get_filename())

    def testMacroResolving(self):
        """ Test the get_macro and get_all_macros commands of services """

        service1 = pynag.Model.Service.objects.get_by_name('macroservice')
        macros = service1.get_all_macros()
        expected_macrokeys = ['$USER1$', '$ARG2$', '$_SERVICE_empty$', '$_HOST_nonexistant$', '$_SERVICE_nonexistant$', '$_SERVICE_macro1$', '$ARG1$', '$_HOST_macro1$', '$_HOST_empty$', '$HOSTADDRESS$', '$_SERVICE_not_used$']
        self.assertEqual(sorted(expected_macrokeys),  sorted(macros.keys()))

        self.assertEqual('/path/to/user1', macros['$USER1$'])
        self.assertEqual('/path/to/user1', macros['$ARG2$'])
        self.assertEqual('hostaddress', macros['$HOSTADDRESS$'])

        self.assertEqual('macro1', macros['$_SERVICE_macro1$'])
        self.assertEqual('macro1', macros['$ARG1$'])
        self.assertEqual('macro1', macros['$_HOST_macro1$'])
        self.assertEqual('this.macro.is.not.used', macros['$_SERVICE_not_used$'])

        self.assertEqual(None, macros['$_HOST_nonexistant$'])
        self.assertEqual(None, macros['$_SERVICE_nonexistant$'])

        self.assertEqual('', macros['$_SERVICE_empty$'])
        self.assertEqual('', macros['$_HOST_empty$'])

        expected_command_line = "/path/to/user1/macro -H 'hostaddress' host_empty='' service_empty='' host_macro1='macro1' arg1='macro1' host_nonexistant='' service_nonexistant='' escaped_dollarsign=$$ user1_as_argument=/path/to/user1"
        actual_command_line = service1.get_effective_command_line()

        self.assertEqual(expected_command_line, actual_command_line)

    def testParenting(self):
        """ Test the use of get_effective_parents and get_effective_children
        """

        # Get host named child, check its parents
        h = pynag.Model.Host.objects.get_by_name('child')
        expected_result = ['parent01', 'parent02', 'parent-of-all']
        hosts = h.get_effective_parents(recursive=True)
        host_names = map(lambda x: x.name, hosts)
        self.assertEqual(expected_result, host_names)

        # Get host named parent-of-all, get its children
        h = pynag.Model.Host.objects.get_by_name('parent-of-all')
        expected_result = ['parent01', 'parent02', 'parent03', 'child']
        hosts = h.get_effective_children(recursive=True)
        host_names = map(lambda x: x.name, hosts)
        self.assertEqual(expected_result, host_names)

    def test_hostgroup_with_regex_members(self):
        """ Test parsing a hostgroup with regex members. """
        prod_servers = pynag.Model.Hostgroup.objects.get_by_shortname('prod-servers')
        # prod_server.members = "prod-[a-zA-Z0-9]+"

        prod_api1 = pynag.Model.Host.objects.get_by_shortname('prod-api-1')
        prod_api2 = pynag.Model.Host.objects.get_by_shortname('prod-api-2')
        dev_api2 = pynag.Model.Host.objects.get_by_shortname('dev-api-1')

        service = pynag.Model.Service.objects.get_by_name('short-term-load')
        hosts = service.get_effective_hosts()

        self.assertTrue(prod_api1 in hosts)  # prod-api-1 matches the regex
        self.assertTrue(prod_api2 in hosts)  # prod-api-2 matches the regex
        self.assertFalse(dev_api2 in hosts)  # dev-api-1 does not match

        # Hostgroup.get_effective_hosts() should match the same regex:
        self.assertEqual(hosts, prod_servers.get_effective_hosts())

    def test_rewrite(self):
        """ Test usage on ObjectDefinition.rewrite() """
        h = pynag.Model.Host()
        expect_new_host = 'define host {\n}\n'
        self.assertEqual(str(h), expect_new_host)

        raw_definition2 = 'define host {\nhost_name brand_new_host\n}\n'
        h.rewrite(raw_definition2)
        h2 = pynag.Model.Host.objects.get_by_shortname('brand_new_host')
        self.assertEqual(h2, h)

        raw_definition3 = 'define host {\nhost_name brand_new_host3\n}\n'
        h2.rewrite(raw_definition3)
        h3 = pynag.Model.Host.objects.get_by_shortname('brand_new_host3')
        self.assertEqual(h3, h2)

    def test_get_related_objects(self):
        """ Test objectdefinition.get_related_objects()
        """
        host1 = pynag.Model.Host(name='a-host-template', use='generic-host')
        host1.save()

        host2 = pynag.Model.Host(host_name='server', use='a-host-template')
        host2.save()

        self.assertEqual(host1.get_related_objects(), [host2])

    def test_attribute_is_empty(self):
        """Test if pynag properly determines if an attribute is empty"""

        #creating test object
        host =  pynag.Model.Host()
        host['host_name']   = "+"
        host['address']     = "not empty"
        host['contacts']    = "!"
        host['hostgroups']  = "                                             "
        host['contact_groups']="-"

        self.assertEqual(True,host.attribute_is_empty("host_name"))
        self.assertEqual(True,host.attribute_is_empty("contacts"))
        self.assertEqual(True,host.attribute_is_empty("hostgroups"))
        self.assertEqual(True,host.attribute_is_empty("contact_groups"))
        self.assertEqual(True,host.attribute_is_empty("_non_existing_attribute"))

        self.assertEqual(False,host.attribute_is_empty("address"))

    def test_contactgroup_delete_recursive_cleanup(self):
        """Test if the right objects are removed when a contactgroup is deleted"""
        """ => test with delete(recursive=True,cleanup_related_items=True) """
        all_contactgroups = pynag.Model.Contactgroup.objects.get_all()
        all_contactgroup_names = map(lambda x: x.name, all_contactgroups)

        #creating test object
        chars = string.letters + string.digits
        cg_name = "cg_to_be_deleted_recursive_cleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        cg =  pynag.Model.Contactgroup()
        # Produce an error if our randomly generated contactgroup already exists in config
        self.assertTrue(cg_name not in all_contactgroup_names)
        cg['contactgroup_name']   = cg_name
        cg.save() # an object has to be saved before we can delete it!

        # since the contactgroup is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(contacts="contact_STAYS", contact_groups=cg_name,      name="stay").save()
        hostesc_del  = pynag.Model.HostEscalation(contacts=None,            contact_groups="+"+cg_name,  name="del").save()
        hostesc_del2 = pynag.Model.HostEscalation(contacts='',              contact_groups=cg_name,      name="del2").save()
        host         = pynag.Model.Host(          contacts="contact_STAYS", contact_groups=cg_name,      name="hoststay").save()
        contact      = pynag.Model.Contact(       contactgroups=cg_name,                                 contact_name="contactstay").save()

        cg.delete(recursive=True,cleanup_related_items=True)

        all_contactgroups_after_delete = pynag.Model.Contactgroup.objects.get_all()
        self.assertEqual(all_contactgroups,all_contactgroups_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("contact_groups"))
        self.assertEqual(1,len(pynag.Model.Host.objects.filter(name="hoststay")))
        self.assertTrue(pynag.Model.Host.objects.filter(name="hoststay")[0].attribute_is_empty("contact_groups"))
        self.assertEqual(1,len(pynag.Model.Contact.objects.filter(contact_name="contactstay")))
        self.assertTrue(pynag.Model.Contact.objects.filter(contact_name="contactstay")[0].attribute_is_empty("contactgroups"))
        self.assertEqual(0,len(pynag.Model.HostEscalation.objects.filter(name="del")))
        self.assertEqual(0,len(pynag.Model.HostEscalation.objects.filter(name="del2")))

    def test_contactgroup_delete_nonRecursive_cleanup(self):
        """Test if the right objects are _NOT_ removed when a contactgroup is deleted with recursive=False"""
        """ => test with delete(recursive=False,cleanup_related_items=True) """
        all_contactgroups = pynag.Model.Contactgroup.objects.get_all()
        all_contactgroup_names = map(lambda x: x.name, all_contactgroups)

        #creating test object
        chars = string.letters + string.digits
        cg_name = "cg_to_be_deleted_nonRecursive_cleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        cg =  pynag.Model.Contactgroup()
        # Produce an error if our randomly generated contactgroup already exists in config
        self.assertTrue(cg_name not in all_contactgroup_names)
        cg['contactgroup_name']   = cg_name
        cg.save() # an object has to be saved before we can delete it!

        # since the contactgroup is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(contacts="contact_STAYS", contact_groups=cg_name,      name="stay").save()
        hostesc_stay2= pynag.Model.HostEscalation(contacts=None,            contact_groups="+"+cg_name,  name="stay2").save()
        hostesc_stay3= pynag.Model.HostEscalation(contacts='',              contact_groups=cg_name,      name="stay3").save()

        cg.delete(recursive=False,cleanup_related_items=True)

        all_contactgroups_after_delete = pynag.Model.Contactgroup.objects.get_all()
        self.assertEqual(all_contactgroups,all_contactgroups_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("contact_groups"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay2")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay2")[0].attribute_is_empty("contact_groups"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay3")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay3")[0].attribute_is_empty("contact_groups"))

    def test_contactgroup_delete_nonRecursive_nonCleanup(self):
        """Test if the no changes are made to related items if contactgroup is deleted"""
        """ => test with delete(recursive=False,cleanup_related_items=False) """

        all_contactgroups = pynag.Model.Contactgroup.objects.get_all()
        all_contactgroup_names = map(lambda x: x.name, all_contactgroups)

        #creating test object
        chars = string.letters + string.digits
        cg_name = "cg_to_be_deleted_nonRecursive_nonCleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        cg =  pynag.Model.Contactgroup()
        # Produce an error if our randomly generated contactgroup already exists in config
        self.assertTrue(cg_name not in all_contactgroup_names)
        cg['contactgroup_name']   = cg_name
        cg.save() # an object has to be saved before we can delete it!

        # since the contactgroup is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(contacts="contact_STAYS", contact_groups=cg_name,      name="stay").save()
        hostesc_stay2= pynag.Model.HostEscalation(contacts=None,            contact_groups="+"+cg_name,  name="stay2").save()
        hostesc_stay3= pynag.Model.HostEscalation(contacts='',              contact_groups=cg_name,      name="stay3").save()
        cg.delete(recursive=False,cleanup_related_items=False)

        all_contactgroups_after_delete = pynag.Model.Contactgroup.objects.get_all()
        self.assertEqual(all_contactgroups,all_contactgroups_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("contact_groups"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay2")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay2")[0].attribute_is_empty("contact_groups"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay3")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay3")[0].attribute_is_empty("contact_groups"))

    def test_contactgroup_delete_recursive_nonCleanup(self):
        """Test if the no changes are made to related items if contactgroup is deleted - no deletion should happen even with recursive=True"""
        """ => test with delete(recursive=True,cleanup_related_items=False) """
        """ should have the same results as  test_contactgroup_delete_nonRecursive_nonCleanup()"""

        all_contactgroups = pynag.Model.Contactgroup.objects.get_all()
        all_contactgroup_names = map(lambda x: x.name, all_contactgroups)

        #creating test object
        chars = string.letters + string.digits
        cg_name = "cg_to_be_deleted_recursive_nonCleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        cg =  pynag.Model.Contactgroup()
        # Produce an error if our randomly generated contactgroup already exists in config
        self.assertTrue(cg_name not in all_contactgroup_names)
        cg['contactgroup_name']   = cg_name
        cg.save() # an object has to be saved before we can delete it!

        # since the contactgroup is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(contacts="contact_STAYS", contact_groups=cg_name,      name="stay").save()
        hostesc_stay2= pynag.Model.HostEscalation(contacts=None,            contact_groups="+"+cg_name,  name="stay2").save()
        hostesc_stay3= pynag.Model.HostEscalation(contacts='',              contact_groups=cg_name,      name="stay3").save()

        cg.delete(recursive=True,cleanup_related_items=False)

        all_contactgroups_after_delete = pynag.Model.Contactgroup.objects.get_all()
        self.assertEqual(all_contactgroups,all_contactgroups_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("contact_groups"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay2")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay2")[0].attribute_is_empty("contact_groups"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay3")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay3")[0].attribute_is_empty("contact_groups"))

    def test_contact_delete_recursive_cleanup(self):
        """Test if the right objects are removed when a contact is deleted"""
        """ => test with delete(recursive=True,cleanup_related_items=True) """
        all_contacts = pynag.Model.Contact.objects.get_all()
        all_contact_names = map(lambda x: x.name, all_contacts)

        #creating test object
        chars = string.letters + string.digits
        c_name = "c_to_be_deleted_recursive_cleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        c =  pynag.Model.Contact()
        # Produce an error if our randomly generated contact already exists in config
        self.assertTrue(c_name not in all_contact_names)
        c['contact_name']   = c_name
        c.save() # an object has to be saved before we can delete it!

        # since the contact is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(contact_groups="contactgroup_STAYS", contacts=c_name,      name="stay").save()
        hostesc_del  = pynag.Model.HostEscalation(contact_groups=None,                 contacts="+"+c_name,  name="del").save()
        hostesc_del2 = pynag.Model.HostEscalation(contact_groups='',                   contacts=c_name,      name="del2").save()
        contactGroup = pynag.Model.Contactgroup(  contactgroup_name="cgstay",          members=c_name                   ).save()

        c.delete(recursive=True,cleanup_related_items=True)

        all_contacts_after_delete = pynag.Model.Contact.objects.get_all()
        self.assertEqual(all_contacts,all_contacts_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("contacts"))
        self.assertEqual(1,len(pynag.Model.Contactgroup.objects.filter(contactgroup_name="cgstay")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("members"))
        self.assertEqual(0,len(pynag.Model.HostEscalation.objects.filter(name="del")))
        self.assertEqual(0,len(pynag.Model.HostEscalation.objects.filter(name="del2")))

    def test_contact_delete_nonRecursive_cleanup(self):
        """Test if the right objects are _NOT_ removed when a contact is deleted with recursive=False"""
        """ => test with delete(recursive=False,cleanup_related_items=True) """
        all_contacts = pynag.Model.Contact.objects.get_all()
        all_contact_names = map(lambda x: x.name, all_contacts)

        #creating test object
        chars = string.letters + string.digits
        c_name = "c_to_be_deleted_nonRecursive_cleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        c =  pynag.Model.Contact()
        # Produce an error if our randomly generated contact already exists in config
        self.assertTrue(c_name not in all_contact_names)
        c['contact_name']   = c_name
        c.save() # an object has to be saved before we can delete it!

        # since the contact is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(contact_groups="contactgroup_STAYS", contacts=c_name,      name="stay").save()
        hostesc_del  = pynag.Model.HostEscalation(contact_groups=None,                 contacts="+"+c_name,  name="stay2").save()
        hostesc_del2 = pynag.Model.HostEscalation(contact_groups='',                   contacts=c_name,      name="stay3").save()

        c.delete(recursive=False,cleanup_related_items=True)

        all_contacts_after_delete = pynag.Model.Contact.objects.get_all()
        self.assertEqual(all_contacts,all_contacts_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("contacts"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay2")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay2")[0].attribute_is_empty("contacts"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay3")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay3")[0].attribute_is_empty("contacts"))

    def test_contact_delete_nonRecursive_nonCleanup(self):
        """Test if the no changes are made to related items if contact is deleted"""
        """ => test with delete(recursive=False,cleanup_related_items=False) """

        all_contacts = pynag.Model.Contact.objects.get_all()
        all_contact_names = map(lambda x: x.name, all_contacts)

        #creating test object
        chars = string.letters + string.digits
        c_name = "c_to_be_deleted_nonRecursive_nonCleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        c =  pynag.Model.Contact()
        # Produce an error if our randomly generated contact already exists in config
        self.assertTrue(c_name not in all_contact_names)
        c['contact_name']   = c_name
        c.save() # an object has to be saved before we can delete it!

        # since the contact is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(contact_groups="contactgroup_STAYS", contacts=c_name,      name="stay").save()
        hostesc_del  = pynag.Model.HostEscalation(contact_groups=None,                 contacts="+"+c_name,  name="stay2").save()
        hostesc_del2 = pynag.Model.HostEscalation(contact_groups='',                   contacts=c_name,      name="stay3").save()
        c.delete(recursive=False,cleanup_related_items=False)

        all_contacts_after_delete = pynag.Model.Contact.objects.get_all()
        self.assertEqual(all_contacts,all_contacts_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("contacts"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay2")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay2")[0].attribute_is_empty("contacts"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay3")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay3")[0].attribute_is_empty("contacts"))

    def test_contact_delete_recursive_nonCleanup(self):
        """Test if the no changes are made to related items if contact is deleted - no deletion should happen even with recursive=True"""
        """ => test with delete(recursive=True,cleanup_related_items=False) """
        """ should have the same results as  test_contact_delete_nonRecursive_nonCleanup()"""

        all_contacts = pynag.Model.Contact.objects.get_all()
        all_contact_names = map(lambda x: x.name, all_contacts)

        #creating test object
        chars = string.letters + string.digits
        c_name = "c_to_be_deleted_recursive_nonCleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        c =  pynag.Model.Contact()
        # Produce an error if our randomly generated contact already exists in config
        self.assertTrue(c_name not in all_contact_names)
        c['contact_name']   = c_name
        c.save() # an object has to be saved before we can delete it!

        # since the contact is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(contact_groups="contactgroup_STAYS", contacts=c_name,      name="stay").save()
        hostesc_del  = pynag.Model.HostEscalation(contact_groups=None,                 contacts="+"+c_name,  name="stay2").save()
        hostesc_del2 = pynag.Model.HostEscalation(contact_groups='',                   contacts=c_name,      name="stay3").save()

        c.delete(recursive=True,cleanup_related_items=False)

        all_contacts_after_delete = pynag.Model.Contact.objects.get_all()
        self.assertEqual(all_contacts,all_contacts_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("contacts"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay2")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay2")[0].attribute_is_empty("contacts"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay3")))
        self.assertFalse(pynag.Model.HostEscalation.objects.filter(name="stay3")[0].attribute_is_empty("contacts"))

    def test_hostgroup_delete_recursive_cleanup(self):
        """Test if the right objects are removed when a hostgroup is deleted"""
        """ => test with delete(recursive=True,cleanup_related_items=True) """
        all_hostgroups = pynag.Model.Hostgroup.objects.get_all()
        all_hostgroup_names = map(lambda x: x.name, all_hostgroups)

        #creating test object
        chars = string.letters + string.digits
        hg_name = "hg_to_be_deleted_recursive_cleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        hg =  pynag.Model.Hostgroup()
        # Produce an error if our randomly generated hostgroup already exists in config
        self.assertTrue(hg_name not in all_hostgroup_names)
        hg['hostgroup_name']   = hg_name
        hg.save() # an object has to be saved before we can delete it!

        # since the hostgroup is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(host_name="host_STAYS", hostgroup_name=hg_name,           name="stay").save()
        hostesc_del  = pynag.Model.HostEscalation(host_name=None,            hostgroup_name="+"+hg_name,         name="del").save()


        hostdep_stay = pynag.Model.HostDependency(host_name='host_STAYS',dependent_host_name="host_stays", hostgroup_name=hg_name, name="stay").save()
        hostdep_del  = pynag.Model.HostDependency(host_name='host_STAYS',dependent_hostgroup_name=hg_name,          name="del").save()
        hostdep_unrl = pynag.Model.HostDependency(dependent_host_name='foobar',hostgroup_name="unrelated_hg",    name="stays_because_its_not_related_to_deleted_hg").save()

        hoststay     = pynag.Model.Host(host_name="host_STAYS",    hostgroups=hg_name,                      name="hoststay").save()

        svcEscdel    = pynag.Model.ServiceEscalation(hostgroup_name=hg_name,                                name="svcEscdel").save()

        hg.delete(recursive=True,cleanup_related_items=True)

        all_hostgroups_after_delete = pynag.Model.Hostgroup.objects.get_all()
        self.assertEqual(all_hostgroups,all_hostgroups_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("hostgroup_name"))
        self.assertEqual(0,len(pynag.Model.HostEscalation.objects.filter(name="del")))

        self.assertEqual(1,len(pynag.Model.HostDependency.objects.filter(name="stay")))
        self.assertEqual(0,len(pynag.Model.HostDependency.objects.filter(name="del")))
        self.assertEqual(1,len(pynag.Model.HostDependency.objects.filter(name="stays_because_its_not_related_to_deleted_hg")))

        self.assertEqual(1,len(pynag.Model.Host.objects.filter(name="hoststay")))
        self.assertTrue(pynag.Model.Host.objects.filter(name="hoststay")[0].attribute_is_empty("hostgroup_name"))

        self.assertEqual(0,len(pynag.Model.ServiceEscalation.objects.filter(name="svcEscdel")))

    def test_hostgroup_delete_nonRecursive_cleanup(self):
        """Test if the right objects are cleaned up when a hostgroup is deleted"""
        """ => test with delete(recursive=False,cleanup_related_items=True) """
        all_hostgroups = pynag.Model.Hostgroup.objects.get_all()
        all_hostgroup_names = map(lambda x: x.name, all_hostgroups)

        #creating test object
        chars = string.letters + string.digits
        hg_name = "hg_to_be_deleted_nonRecursive_cleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        hg =  pynag.Model.Hostgroup()
        # Produce an error if our randomly generated hostgroup already exists in config
        self.assertTrue(hg_name not in all_hostgroup_names)
        hg['hostgroup_name']   = hg_name
        hg.save() # an object has to be saved before we can delete it!

        # since the hostgroup is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(host_name="host_STAYS", hostgroup_name=hg_name,           name="stay").save()
        hostesc_stay2= pynag.Model.HostEscalation(host_name=None,         hostgroup_name="+"+hg_name,       name="stay2").save()

        hostdep_stay = pynag.Model.HostDependency(host_name='host_STAYS',dependent_host_name="host_stays", hostgroup_name=hg_name, name="stay").save()
        hostdep_stay2= pynag.Model.HostDependency(host_name='host_STAYS',dependent_hostgroup_name=hg_name,                         name="stay2").save()

        svcEscstay    = pynag.Model.ServiceEscalation(hostgroup_name=hg_name,                                name="svcEscstay").save()

        hg.delete(recursive=False,cleanup_related_items=True)

        all_hostgroups_after_delete = pynag.Model.Hostgroup.objects.get_all()
        self.assertEqual(all_hostgroups,all_hostgroups_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("hostgroup_name"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay2")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay2")[0].attribute_is_empty("hostgroup_name"))

        self.assertEqual(1,len(pynag.Model.HostDependency.objects.filter(name="stay")))
        self.assertTrue(pynag.Model.HostDependency.objects.filter(name="stay")[0].attribute_is_empty("hostgroup_name"))
        self.assertEqual(1,len(pynag.Model.HostDependency.objects.filter(name="stay2")))
        self.assertTrue(pynag.Model.HostDependency.objects.filter(name="stay2")[0].attribute_is_empty("dependent_hostgroup_name"))

        self.assertEqual(1,len(pynag.Model.ServiceEscalation.objects.filter(name="svcEscstay")))
        self.assertTrue(pynag.Model.ServiceEscalation.objects.filter(name="svcEscstay")[0].attribute_is_empty("hostgroup_name"))

    def test_host_delete_recursive_cleanup(self):
        """Test if the right objects are removed when a host is deleted"""
        """ => test with delete(recursive=True,cleanup_related_items=True) """
        all_hosts = pynag.Model.Host.objects.get_all()
        all_host_names = map(lambda x: x.name, all_hosts)

        #creating test object
        chars = string.letters + string.digits
        h_name = "h_to_be_deleted_recursive_cleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        h =  pynag.Model.Host()
        # Produce an error if our randomly generated host already exists in config
        self.assertTrue(h_name not in all_host_names)
        h['host_name']   = h_name
        h.save() # an object has to be saved before we can delete it!

        # since the host is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(hostgroup_name="hostgroup_STAYS", host_name=h_name,           name="stay").save()
        hostesc_del  = pynag.Model.HostEscalation(hostgroup_name=None,            host_name="+"+h_name,         name="del").save()


        hostdep_stay = pynag.Model.HostDependency(hostgroup_name='hostgroup_STAYS',dependent_host_name="host_stays", host_name=h_name, name="stay").save()
        hostdep_del  = pynag.Model.HostDependency(hostgroup_name='hostgroup_STAYS',dependent_host_name=h_name,          name="del").save()

        svcEscdel    = pynag.Model.ServiceEscalation(host_name=h_name,                                name="svcEscdel").save()

        h.delete(recursive=True,cleanup_related_items=True)

        all_hosts_after_delete = pynag.Model.Host.objects.get_all()
        self.assertEqual(all_hosts,all_hosts_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("host_name"))
        self.assertEqual(0,len(pynag.Model.HostEscalation.objects.filter(name="del")))

        self.assertEqual(1,len(pynag.Model.HostDependency.objects.filter(name="stay")))
        self.assertEqual(0,len(pynag.Model.HostDependency.objects.filter(name="del")))

        self.assertEqual(0,len(pynag.Model.ServiceEscalation.objects.filter(name="svcEscdel")))

    def test_host_delete_nonRecursive_cleanup(self):
        """Test if the right objects are cleaned up when a host is deleted"""
        """ => test with delete(recursive=False,cleanup_related_items=True) """
        all_hosts = pynag.Model.Host.objects.get_all()
        all_host_names = map(lambda x: x.name, all_hosts)

        #creating test object
        chars = string.letters + string.digits
        h_name = "h_to_be_deleted_nonRecursive_cleanup" + ''.join([random.choice(chars) for i in xrange(10)])
        h =  pynag.Model.Host()
        # Produce an error if our randomly generated host already exists in config
        self.assertTrue(h_name not in all_host_names)
        h['host_name']   = h_name
        h.save() # an object has to be saved before we can delete it!

        # since the host is unique as per the check above, the dependent escalations will consequently be unique as well
        hostesc_stay = pynag.Model.HostEscalation(hostgroup_name="hostgroup_STAYS", host_name=h_name,           name="stay").save()
        hostesc_stay2= pynag.Model.HostEscalation(hostgroup_name=None,         host_name="+"+h_name,       name="stay2").save()

        hostdep_stay = pynag.Model.HostDependency(hostgroup_name='hostgroup_STAYS',dependent_host_name="host_stays", host_name=h_name, name="stay").save()
        hostdep_stay2= pynag.Model.HostDependency(hostgroup_name='hostgroup_STAYS',dependent_host_name=h_name,                         name="stay2").save()

        svcEscstay    = pynag.Model.ServiceEscalation(host_name=h_name,                                name="svcEscstay").save()

        h.delete(recursive=False,cleanup_related_items=True)

        all_hosts_after_delete = pynag.Model.Host.objects.get_all()
        self.assertEqual(all_hosts,all_hosts_after_delete)

        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay")[0].attribute_is_empty("host_name"))
        self.assertEqual(1,len(pynag.Model.HostEscalation.objects.filter(name="stay2")))
        self.assertTrue(pynag.Model.HostEscalation.objects.filter(name="stay2")[0].attribute_is_empty("host_name"))

        self.assertEqual(1,len(pynag.Model.HostDependency.objects.filter(name="stay")))
        self.assertTrue(pynag.Model.HostDependency.objects.filter(name="stay")[0].attribute_is_empty("host_name"))
        self.assertEqual(1,len(pynag.Model.HostDependency.objects.filter(name="stay2")))
        self.assertTrue(pynag.Model.HostDependency.objects.filter(name="stay2")[0].attribute_is_empty("dependent_host_name"))

        self.assertEqual(1,len(pynag.Model.ServiceEscalation.objects.filter(name="svcEscstay")))
        self.assertTrue(pynag.Model.ServiceEscalation.objects.filter(name="svcEscstay")[0].attribute_is_empty("host_name"))

    def test_add_hosts_to_hostgroups(self):
        """ Test pynag.Model.Host.add_to_hostgroup """
        host_name = "testhost1"
        hostgroup_name = "testhostgroup1"
        hostgroup = pynag.Model.Hostgroup(hostgroup_name=hostgroup_name)
        hostgroup.save()
        host1 = pynag.Model.Host(host_name=host_name)
        host1.save()

        message = "Newly created host should not belong to any hostgroups"
        self.assertEqual(False, hostgroup_name in pynag.Utils.AttributeList(host1.hostgroups), message)
        self.assertEqual(False, host_name in pynag.Utils.AttributeList(hostgroup.members), message)

        message = "Host should belong to hostgroup after we specificly add it"
        host1.add_to_hostgroup(hostgroup_name)
        self.assertEqual(True, hostgroup_name in pynag.Utils.AttributeList(host1.hostgroups), message)
        self.assertEqual(False, host_name in pynag.Utils.AttributeList(hostgroup.members), message)

        message = "Host should not belong to hostgroup after we have removed it"
        host1.remove_from_hostgroup(hostgroup_name)
        self.assertEqual(False, hostgroup_name in pynag.Utils.AttributeList(host1.hostgroups), message)
        self.assertEqual(False, host_name in pynag.Utils.AttributeList(hostgroup.members), message)

        # Lets try the same via the hostgroup:
        message = "Host should belong to hostgroup after we have specifically added host to that hostgroup"
        hostgroup.add_host(host_name)
        host1 = pynag.Model.Host.objects.get_by_shortname(host_name)
        self.assertEqual(True, hostgroup_name in pynag.Utils.AttributeList(host1.hostgroups), message)
        self.assertEqual(False, host_name in pynag.Utils.AttributeList(hostgroup.members), message)

        message = "Hostgroup should not have host after we specifically remove the host"
        hostgroup.remove_host(host_name)
        host1 = pynag.Model.Host.objects.get_by_shortname(host_name)
        self.assertEqual(False, hostgroup_name in pynag.Utils.AttributeList(host1.hostgroups), message)
        self.assertEqual(False, host_name in pynag.Utils.AttributeList(hostgroup.members), message)

    def test_effective_hostgroups(self):
        """ Test get_effective_hostgroups() against stuff in dataset01 """
        production_servers = pynag.Model.Hostgroup.objects.get_by_shortname('production_servers')
        production_server1 = pynag.Model.Host.objects.get_by_shortname('production_server1')

        development_servers = pynag.Model.Hostgroup.objects.get_by_shortname('development_servers')
        development_server1 = pynag.Model.Host.objects.get_by_shortname('development_server1')

        prod_and_dev = pynag.Model.Hostgroup.objects.get_by_shortname('prod_and_dev')

        production_service = pynag.Model.Service.objects.get_by_shortname('prod_service')

        groups_for_production_server1 = production_server1.get_effective_hostgroups()
        groups_for_development_server1 = development_server1.get_effective_hostgroups()

        self.assertEqual([prod_and_dev, production_servers], groups_for_production_server1)
        self.assertEqual([development_servers, prod_and_dev], groups_for_development_server1)

        self.assertEqual([], development_servers.get_effective_hostgroups())
        self.assertEqual([], production_servers.get_effective_hostgroups())
        self.assertEqual([development_servers, production_servers], prod_and_dev.get_effective_hostgroups())

        self.assertEqual([development_server1], development_servers.get_effective_hosts())
        self.assertEqual([production_server1], production_servers.get_effective_hosts())
        self.assertEqual([development_server1, production_server1], prod_and_dev.get_effective_hosts())

        self.assertEqual(production_servers.get_effective_services(), [production_service])
        self.assertEqual(prod_and_dev.get_effective_services(), [])
        self.assertEqual(development_servers.get_effective_services(), [])

        self.assertEqual(production_service.get_effective_hostgroups(), [production_servers])

class Model2(unittest.TestCase):
    """ Another class for testing pynag.Model. Should replace Model at some point.

    The reason methods here are in a new class is because we are moving to a new set of tests
    that use Utils.misc.FakeNagiosEnvironment. It's not a bad idea to migrate tests from the old
    class into this one here, one at a time.
    """
    def setUp(self):
        self.environment = pynag.Utils.misc.FakeNagiosEnvironment()
        self.environment.create_minimal_environment()
        self.environment.update_model()

    def tearDown(self):
        self.environment.terminate()

    def test_rename(self):
        """ Generic test of Model.*.rename()
        """
        old = "host1"
        new = "host2"
        host = pynag.Model.Host(host_name=old)
        host.save()

        host = pynag.Model.Host.objects.get_by_shortname(old)
        self.assertTrue(host.host_name == old)
        host.rename(new)

        host = pynag.Model.Host.objects.get_by_shortname(new)
        self.assertTrue(host.host_name == new)

        hosts_with_old_name = pynag.Model.Host.objects.filter(host_name=old)
        self.assertFalse(hosts_with_old_name, "There should be no hosts with the old name")

    def test_rename_contact(self):
        """ test Model.*.rename() function """
        # Create a contact, and contactgroup. Put the contact in the contactgroup
        contact_name1 = "some contact"
        contact_name2 = "new name for contact"
        contactgroup_name = "contactgroup1"
        contact = pynag.Model.Contact(contact_name=contact_name1)
        contact.save()
        contactgroup = pynag.Model.Contactgroup(contactgroup_name=contactgroup_name, members=contact_name1)
        contactgroup.save()

        # Verify the contact is in our contactgroup
        c = pynag.Model.Contactgroup.objects.get_by_shortname(contactgroup_name)
        self.assertTrue(c.members == contact_name1)

        # Rename the contact, doublecheck that the contactgroup changed.
        contact.rename(contact_name2)
        c = pynag.Model.Contactgroup.objects.get_by_shortname(contactgroup_name)
        self.assertTrue(c.members == contact_name2)

    @unittest.skipIf(os.getenv('TRAVIS', None) == 'true', "Running in Travis")  # Doesnt work in travis for some reason
    def test_get_current_status(self):
        """ Test Model.*.get_current_status """
        self.environment.start()

        # status.dat takes a while to get created, so we have to wait a little bit
        time_start = time.time()
        timeout = 3000  # Give nagios 10sec to create a status.dat file
        status_file = self.environment.config.get_cfg_value('status_file')
        while not os.path.exists(status_file):
            time.sleep(0.1)
            time_now = time.time()
            time_elapsed = time_now - time_start
            if time_elapsed > timeout:
                raise Exception("Timed out while waiting for nagios to create status.dat" % (status_file))
        # Fetch host, and get its current status
        host = pynag.Model.Host.objects.get_by_shortname("ok_host")
        host_status = host.get_current_status()
        self.assertTrue(host_status, "Trying to find host ok_host")
        self.assertTrue('current_state' in host_status)

        # Do the same for service
        service = host.get_effective_services()[0]
        service_status = service.get_current_status()
        self.assertTrue(service_status)
        self.assertTrue('current_state' in service_status)

class NagiosReloadHandler(unittest.TestCase):
    """ Test Eventhandler NagiosReloadHandler
    """
    def setUp(self):
        self.handler = pynag.Model.EventHandlers.NagiosReloadHandler(nagios_init="/bin/ls")
        self.handler._reload = mock.MagicMock()

    def test_write(self):
        self.handler.write(None, None)

    def test_save(self):
        self.handler.pre_save(None, None)
        self.handler.save(None, None)


class ObjectRelations(unittest.TestCase):
    """ Test pynag.Model.ObjectRelations """
    def setUp(self):
        pass

    def test_get_subgroups(self):
        c = pynag.Utils.defaultdict(set)
        c['everything'] = set(['admins', 'nonadmins', 'operators', 'users'])
        c['nonadmins'] = set(['users'])
        c['users'] = set()
        c['admins'] = set(['sysadmins', 'network-admins', 'database-admins'])
        c['nonadmins'] = set(['users'])
        members_of_everything_actual = pynag.Model.ObjectRelations._get_subgroups('everything', c)
        members_of_everything_expected = set(['users', 'operators', 'sysadmins', 'network-admins', 'admins', 'nonadmins', 'database-admins'])
        self.assertEqual(members_of_everything_actual, members_of_everything_expected)


if __name__ == "__main__":
    unittest.main()

# vim: sts=4 expandtab autoindent

########NEW FILE########
__FILENAME__ = test_other
import os
import sys

# Make sure we import from working tree
pynagbase = os.path.dirname(os.path.realpath(__file__ + "/.."))
sys.path.insert(0, pynagbase)

import unittest2 as unittest
import tempfile
import shutil

from tests import tests_dir

os.chdir(tests_dir)
import pynag.Model

# Exported to pynag command
pynagbase = os.path.realpath("%s/%s" % (tests_dir, os.path.pardir))

class testDatasetParsing(unittest.TestCase):
    """ Parse any dataset in the tests directory starting with "testdata" """
    def setUp(self):
        """ Basic setup before test suite starts
        """
        os.chdir(tests_dir)
        self.tmp_dir = tempfile.mkdtemp()  # Will be deleted after test runs
        #os.mkdir(self.tmp_dir)
        pynag.Model.pynag_directory = self.tmp_dir

    def tearDown(self):
        """ Clean up after test suite has finished
        """
        shutil.rmtree(self.tmp_dir, ignore_errors=True)

    def testParseDatasets(self):
        """ Parse every testdata*/nagios/nagios.cfg
        Output will be compared with testdata*/expectedoutput.txt
        """
        test_dirs = []
        for i in os.listdir('.'):
            if i.startswith('testdata') and os.path.isdir(i) and os.path.isfile(i + "/nagios/nagios.cfg"):
                test_dirs.append(i)

        for directory in test_dirs:
            os.chdir(directory)
            pynag.Model.cfg_file = "./nagios/nagios.cfg"
            pynag.Model.config = None
            actualOutput = ''
            for i in pynag.Model.ObjectDefinition.objects.all:
                actualOutput += str(i)
                # Write our parsed data to tmpfile so we have an easy diff later:
            tmp_file = self.tmp_dir + "/" + os.path.basename(directory) + "_actual_output.txt"
            open(tmp_file, 'w').write(actualOutput)
            diff_output = pynag.Utils.runCommand("diff -uwB expected_output.txt '%s'" % tmp_file)[1]
            self.assertEqual('', diff_output)


class testsFromCommandLine(unittest.TestCase):
    """ Various commandline scripts
    """
    def setUp(self):
        # Import pynag.Model so that at the end we can see if configuration changed at all
        pynag.Model.ObjectDefinition.objects.get_all()

    def tearDown(self):
        # Check if any configuration changed while we were running tests:
        self.assertEqual(False, pynag.Model.config.needs_reparse(), "Seems like nagios configuration changed while running the unittests. Some of the tests might have made changes!")

    def testCommandPluginTest(self):
        """ Run Tommi's plugintest script to test pynag plugin threshold parameters
        """
        expected_output = (0, '', '')  # Expect exit code 0 and no output
        actual_output = pynag.Utils.runCommand(pynagbase + '/scripts/plugintest')
        self.assertEqual(expected_output, actual_output)

    def testCommandPynag(self):
        """ Various command line tests on the pynag command  """
        pynag_script = pynagbase + '/scripts/pynag'
        # ok commands, bunch of commandline commands that we execute just to see
        # if an unhandled exception appears,
        # Ideally none of these commands should modify any configuration
        ok_commands = [
            "%s list" % pynag_script,
            "%s list where host_name=localhost and object_type=host" % pynag_script,
            "%s update where nonexistantfield=test set nonexistentfield=pynag_unit_testing" % pynag_script,
            "%s config --get cfg_dir" % pynag_script,
        ]
        for i in ok_commands:
            exit_code, stdout, stderr = pynag.Utils.runCommand(i,
                                            env={'PYTHONPATH': pynagbase})
            self.assertEqual(0, exit_code, "Error when running command %s\nexit_code: %s\noutput: %s\nstderr: %s" % (i, exit_code, stdout, stderr))

if __name__ == "__main__":
    unittest.main()

# vim: sts=4 expandtab autoindent

########NEW FILE########
__FILENAME__ = test_parsers
__author__ = 'palli'

import os
import sys

# Make sure we import from working tree
pynagbase = os.path.dirname(os.path.realpath(__file__ + "/.."))
sys.path.insert(0, pynagbase)

import unittest2 as unittest
import doctest
import tempfile
import shutil
import string
import random

from tests import tests_dir
import pynag.Parsers
import pynag.Utils.misc


class Config(unittest.TestCase):
    """ Test pynag.Parsers.config """
    def setUp(self):
        self.environment = pynag.Utils.misc.FakeNagiosEnvironment()
        self.environment.create_minimal_environment()

        self.tempdir = self.environment.tempdir
        self.config = self.environment.get_config()
        self.objects_file = self.environment.objects_dir + "/new_objects.cfg"

    def tearDown(self):
        self.environment.terminate()

    def test_parse(self):
        """ Smoketest config.parse() """
        self.config.parse()
        self.assertTrue(len(self.config.data) > 0, "pynag.Parsers.config.parse() ran and afterwards we see no objects. Empty configuration?")

    def test_parse_string_backslashes(self):
        """ Test parsing nagios object files with lines that end with backslash
        """
        c = self.config
        str1 = "define service {\nhost_name testhost\n}\n"
        str2 = "define service {\nhost_na\\\nme testhost\n}\n"

        parse1 = c.parse_string(str1)[0]
        parse2 = c.parse_string(str2)[0]

        # Remove metadata because stuff like line numbers has changed
        del parse1['meta']
        del parse2['meta']

        self.assertEqual(parse1, parse2)

    def test_edit_static_file(self):
        """ Test pynag.Parsers.config._edit_static_file() """
        fd, filename = tempfile.mkstemp()
        c = pynag.Parsers.config(cfg_file=filename)

        # Lets add some attributes to our new file
        c._edit_static_file(attribute='first', new_value='first_test')
        c._edit_static_file(attribute='appended', new_value='first_append', append=True)
        c._edit_static_file(attribute='appended', new_value='second_append', append=True)
        c._edit_static_file(attribute='appended', new_value='third_append', append=True)

        c.parse_maincfg()

        # Sanity check, are our newly added attributes in the file
        self.assertEqual('first_test', c.get_cfg_value('first'))
        self.assertEqual('first_append', c.get_cfg_value('appended'))
        self.assertEqual(None, c.get_cfg_value('non_existant_value'))

        # Make some changes, see if everything is still as it is supposed to
        c._edit_static_file(attribute='first', new_value='first_test_changed')
        c._edit_static_file(attribute='appended', old_value='second_append', new_value='second_append_changed')

        c.parse_maincfg()
        self.assertEqual('first_test_changed', c.get_cfg_value('first'))
        self.assertEqual('first_append', c.get_cfg_value('appended'))

        # Try a removal
        c._edit_static_file(attribute='appended', old_value='first_append', new_value=None)
        c.parse_maincfg()

        # first append should be gone, and second one should be changed:
        self.assertEqual('second_append_changed', c.get_cfg_value('appended'))

        os.remove(filename)

    def test_item_add(self):
        filename = self.objects_file
        object_type = 'hostgroup'
        object_name = object_type + "-" + filename
        new_item = self.config.get_new_item(object_type, filename=filename)
        new_item['hostgroup_name'] = object_name
        self.config.item_add(new_item, filename=filename)
        self.config.parse()
        item_after_parse = self.config.get_hostgroup(object_name)
        del item_after_parse['meta']
        del new_item['meta']
        self.assertEqual(new_item, item_after_parse)

    def test_parse_string(self):
        """ test config.parse_string()
        """
        items = self.config.parse_string(minimal_config)
        self.assertEqual(items[11]['command_line'], '$USER1$/check_mrtgtraf -F $ARG1$ -a $ARG2$ -w $ARG3$ -c $ARG4$ -e $ARG5$')
        self.assertEqual(items[11]['command_name'], 'check_local_mrtgtraf')
    
    def test_invalid_chars_in_item_edit(self):
        """ Test what happens when a user enters invalid characters attribute value """
        field_name = "test_field"
        field_value = "test_value"
        host_name = "ok_host"

        # Change field_name of our host
        self.config.parse()
        host = self.config.get_host(host_name)
        self.config.item_edit_field(host, field_name, field_value)

        # check if field_name matches what we saved it as
        self.config.parse()
        host = self.config.get_host(host_name)
        self.assertEqual(host.get(field_name), field_value)

        # Try to put new line as an attribute value:
        try:
            self.config.item_edit_field(host, field_name, "value with \n line breaks")
            self.assertEqual(False, True, "item_edit_field() should have raised an exception")
        except ValueError:
            self.assertEqual(True, True)

    def test_line_continuations(self):
        """ More tests for configs that have \ at an end of a line """
        definition = r"""
            define contactgroup {
            contactgroup_name portal-sms
            members \
            armin.gruner.sms, \

            }
            """
        with open(self.objects_file, 'a') as f:
            f.write(definition)
        c = self.config
        c.parse()
        item = c.get_object('contactgroup', 'portal-sms')
        self.assertTrue(item)
        # Change the members variable of our group, make sure the changes look ok
        c.item_edit_field(item, 'members', 'root')
        c.parse()
        item = c.get_object('contactgroup', 'portal-sms')

        self.assertTrue(item['members'] == 'root')
        self.assertFalse('armin.gruner.sms' in item['meta']['raw_definition'])

    def test_missing_end_of_object(self):
        """ Test parsing of a config with missing '}'
        """
        os.chdir(tests_dir)
        config = pynag.Parsers.Config()
        items = config.parse_file('dataset01/nagios/conf.d/missing.end.of.object.cfg')
        self.assertEqual(1, len(config.errors), "There should be exactly 1 config error")
        self.assertEqual(1, len(items), "there should be exactly 1 parsed items")


class ExtraOptsParser(unittest.TestCase):
    """ Test pynag.Parsers.ExtraOptsParser """
    def testExtraOptsParser(self):
        """ Smoke-test Parsers.ExtraOptsParser """
        os.chdir(tests_dir)
        e = pynag.Parsers.ExtraOptsParser(section_name='main', config_file='dataset01/extraopts/other.ini')
        self.assertEqual('other.ini', e.get('filename'))

        # Test if default value works as expected:
        try:
            e.get('does not exist')
            self.assertTrue(False, "Code above should have raised an error")
        except ValueError:
            pass
        self.assertEqual("test", e.get('does not exist', "test"))

        # See if extraopts picks up on the NAGIOS_CONFIG_PATH variable
        os.environ['NAGIOS_CONFIG_PATH'] = "dataset01/extraopts/"
        e = pynag.Parsers.ExtraOptsParser(section_name='main')
        self.assertEqual('plugins.ini', e.get('filename'))

        # Using same config as above, test the getlist method
        self.assertEqual(['plugins.ini'], e.getlist('filename'))


class Livestatus(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        nagios = pynag.Utils.misc.FakeNagiosEnvironment()
        nagios.create_minimal_environment()
        nagios.configure_livestatus()
        nagios.start()
        cls.nagios = nagios
        cls.livestatus = nagios.livestatus_object

    @classmethod
    def tearDownClass(cls):
        cls.nagios.terminate()

    def testLivestatus(self):
        """ Smoketest livestatus integration """
        requests = self.livestatus.query('GET status', 'Columns: requests')
        self.assertEqual(1, len(requests), "Could not get status.requests from livestatus")

    def testParseMaincfg(self):
        """ Test parsing of different broker_module declarations """
        path = "/var/lib/nagios/rw/livestatus"  # Path to the livestatus socket

        # Test plain setup with no weird arguments
        fd, filename = tempfile.mkstemp()
        os.write(fd, 'broker_module=./livestatus.o /var/lib/nagios/rw/livestatus')
        status = pynag.Parsers.mk_livestatus(nagios_cfg_file=filename)
        self.assertEqual(path, status.livestatus_socket_path)
        os.close(fd)

        # Test what happens if arguments are provided
        fd, filename = tempfile.mkstemp()
        os.write(fd, 'broker_module=./livestatus.o /var/lib/nagios/rw/livestatus hostgroups=t')
        status = pynag.Parsers.mk_livestatus(nagios_cfg_file=filename)
        self.assertEqual(path, status.livestatus_socket_path)
        os.close(fd)

        # Test what happens if arguments are provided before and after file socket path
        fd, filename = tempfile.mkstemp()
        os.write(fd, 'broker_module=./livestatus.o  num_client_threads=20 /var/lib/nagios/rw/livestatus hostgroups=t')
        status = pynag.Parsers.mk_livestatus(nagios_cfg_file=filename)
        self.assertEqual(path, status.livestatus_socket_path)
        os.close(fd)

        # Test what happens if livestatus socket path cannot be found
        try:
            fd, filename = tempfile.mkstemp()
            os.write(fd, 'broker_module=./livestatus.o  num_client_threads=20')
            status = pynag.Parsers.mk_livestatus(nagios_cfg_file=filename)
            self.assertEqual(path, status.livestatus_socket_path)
            os.close(fd)
            self.assertEqual(True, "Above could should have raised exception")
        except pynag.Parsers.ParserError:
            pass

    def testConnection(self):
        """ Test the livestatus.test() method """
        # Check if our newly created nagios environment has a working livestatus test:
        self.assertTrue(self.livestatus.test(), "Livestatus is supposed to work in FakeNagiosEnvironment")

        # Create a dummy livestatus instance and test connection to that:
        broken_livestatus = pynag.Parsers.Livestatus(livestatus_socket_path="does not exist")
        self.assertFalse(
            broken_livestatus.test(raise_error=False),
            "Dummy livestatus instance was supposed to be nonfunctional"
        )


class ObjectCache(unittest.TestCase):
    """ Tests for pynag.Parsers.objectcache
    """
    @unittest.skipIf(os.getenv('TRAVIS', None) == 'true', "Running in Travis")
    def testObjectCache(self):
        """Test pynag.Parsers.object_cache"""
        o = pynag.Parsers.object_cache()
        o.parse()
        self.assertTrue(len(o.data.keys()) > 0, 'Object cache seems to be empty')


class LogFiles(unittest.TestCase):
    """ Test pynag.Parsers.LogFiles
    """
    def setUp(self):
        os.chdir(tests_dir)
        os.chdir('dataset01')
        cfg_file = "./nagios/nagios.cfg"
        self.log = pynag.Parsers.LogFiles(maincfg=cfg_file)

    def testLogFileParsing(self):
        expected_no_of_logentries = 63692
        expected_no_for_app01 = 127
        len_state_history = 14301

        log = self.log.get_log_entries(start_time=0)
        self.assertEqual(expected_no_of_logentries, len(log))

        app01 = self.log.get_log_entries(start_time=0, host_name='app01.acme.com')
        self.assertEqual(expected_no_for_app01, len(app01))

        state_history = self.log.get_state_history(start_time=0)
        self.assertEqual(len_state_history, len(state_history))

    def testGetLogFiles(self):
        logfiles = self.log.get_logfiles()
        self.assertEqual(2, len(logfiles))
        self.assertEqual('./nagios/log/nagios.log', logfiles[0])
        self.assertEqual('./nagios/log/archives/archivelog1.log', logfiles[1])


class Status(unittest.TestCase):
    @unittest.skipIf(os.getenv('TRAVIS', None) == 'true', "Running in Travis")
    def testStatus(self):
        """Unit test for pynag.Parsers.status()"""

        s = pynag.Parsers.status()
        try:
            s.parse()
        except IOError:
            self.skipTest("IOError, probably no nagios running")
        # Get info part from status.dat file
        info = s.data['info']

        # It only has one object so..
        info = info[0]

        # Try to get current version of nagios
        version = info['version']


class MultiSite(Livestatus):
    """ Tests for pynag.Parsers.MultiSite
    """
    def testAddBackend(self):
        livestatus = pynag.Parsers.MultiSite()
        backend1 = "local autodiscovered"
        backend2 = "local autodiscovered2"

        # Add a backend, and make sure we are getting hosts out of it
        livestatus.add_backend(path=self.nagios.livestatus_socket_path, name=backend1)
        hosts = livestatus.get_hosts()
        self.assertTrue(len(hosts) > 0)

        # Add the same backend under a new name, and check if number of hosts
        # doubles
        livestatus.add_backend(path=self.nagios.livestatus_socket_path, name=backend2)
        hosts2 = livestatus.get_hosts()
        self.assertEqual(len(hosts) * 2, len(hosts2))

        # Get hosts from one specific backend
        hosts_backend1 = livestatus.get_hosts(backend=backend1)
        hosts_backend2 = livestatus.get_hosts(backend=backend2)

        self.assertEqual(len(hosts), len(hosts_backend1))

@unittest.skip("Not ready for production yet")
class SshConfig(Config):
    def setUp(self):
        self.instance = pynag.Parsers.SshConfig(host="localhost", username='palli')

    def tearDown(self):
        pass

    def testParseMaincfg(self):
        self.instance.parse_maincfg()

    def testParse(self):
        self.instance.parse()
        host = self.instance.get_host('localhost')
        print host['__test']
        self.instance.item_edit_field(host, '__test', host['__test'] + '+')

    def testOpenFile(self):
        self.instance.open('/etc/nagios3/nagios.cfg').read()

    def testPathWrappers(self):
        """ Test our os.path wrappers
        """
        ftp = self.instance.ftp
        i = ftp.stat('/')
        self.assertTrue(self.instance.isdir('/'))



minimal_config = r"""
define timeperiod {
  alias                          24 Hours A Day, 7 Days A Week
  friday          00:00-24:00
  monday          00:00-24:00
  saturday        00:00-24:00
  sunday          00:00-24:00
  thursday        00:00-24:00
  timeperiod_name                24x7
  tuesday         00:00-24:00
  wednesday       00:00-24:00
}

define timeperiod {
  alias                          24x7 Sans Holidays
  friday          00:00-24:00
  monday          00:00-24:00
  saturday        00:00-24:00
  sunday          00:00-24:00
  thursday        00:00-24:00
  timeperiod_name                24x7_sans_holidays
  tuesday         00:00-24:00
  use		us-holidays		; Get holiday exceptions from other timeperiod
  wednesday       00:00-24:00
}

define contactgroup {
  alias                          Nagios Administrators
  contactgroup_name              admins
  members                        nagiosadmin
}

define command {
  command_line                   $USER1$/check_ping -H $HOSTADDRESS$ -w 3000.0,80% -c 5000.0,100% -p 5
  command_name                   check-host-alive
}

define command {
  command_line                   $USER1$/check_dhcp $ARG1$
  command_name                   check_dhcp
}

define command {
  command_line                   $USER1$/check_ftp -H $HOSTADDRESS$ $ARG1$
  command_name                   check_ftp
}

define command {
  command_line                   $USER1$/check_hpjd -H $HOSTADDRESS$ $ARG1$
  command_name                   check_hpjd
}

define command {
  command_line                   $USER1$/check_http -I $HOSTADDRESS$ $ARG1$
  command_name                   check_http
}

define command {
  command_line                   $USER1$/check_imap -H $HOSTADDRESS$ $ARG1$
  command_name                   check_imap
}

define command {
  command_line                   $USER1$/check_disk -w $ARG1$ -c $ARG2$ -p $ARG3$
  command_name                   check_local_disk
}

define command {
  command_line                   $USER1$/check_load -w $ARG1$ -c $ARG2$
  command_name                   check_local_load
}

define command {
  command_line                   $USER1$/check_mrtgtraf -F $ARG1$ -a $ARG2$ -w $ARG3$ -c $ARG4$ -e $ARG5$
  command_name                   check_local_mrtgtraf
}

define command {
  command_line                   $USER1$/check_procs -w $ARG1$ -c $ARG2$ -s $ARG3$
  command_name                   check_local_procs
}

define command {
  command_line                   $USER1$/check_swap -w $ARG1$ -c $ARG2$
  command_name                   check_local_swap
}

define command {
  command_line                   $USER1$/check_users -w $ARG1$ -c $ARG2$
  command_name                   check_local_users
}

define command {
  command_line                   $USER1$/check_nt -H $HOSTADDRESS$ -p 12489 -v $ARG1$ $ARG2$
  command_name                   check_nt
}

define command {
  command_line                   $USER1$/check_ping -H $HOSTADDRESS$ -w $ARG1$ -c $ARG2$ -p 5
  command_name                   check_ping
}

define command {
  command_line                   $USER1$/check_pop -H $HOSTADDRESS$ $ARG1$
  command_name                   check_pop
}

define command {
  command_line                   $USER1$/check_smtp -H $HOSTADDRESS$ $ARG1$
  command_name                   check_smtp
}

define command {
  command_line                   $USER1$/check_snmp -H $HOSTADDRESS$ $ARG1$
  command_name                   check_snmp
}

define command {
  command_line                   $USER1$/check_ssh $ARG1$ $HOSTADDRESS$
  command_name                   check_ssh
}

define command {
  command_line                   $USER1$/check_tcp -H $HOSTADDRESS$ -p $ARG1$ $ARG2$
  command_name                   check_tcp
}

define command {
  command_line                   $USER1$/check_udp -H $HOSTADDRESS$ -p $ARG1$ $ARG2$
  command_name                   check_udp
}

define contact {
  name                           generic-contact
  host_notification_commands     notify-host-by-email
  host_notification_options      d,u,r,f,s
  host_notification_period       24x7
  register                       0
  service_notification_commands  notify-service-by-email
  service_notification_options   w,u,c,r,f,s
  service_notification_period    24x7
}

define host {
  name                           generic-host
  event_handler_enabled          1
  failure_prediction_enabled     1
  flap_detection_enabled         1
  notification_period            24x7
  notifications_enabled          1
  process_perf_data              1
  register                       0
  retain_nonstatus_information   1
  retain_status_information      1
}

define host {
  name                           generic-printer
  use                            generic-host
  check_command                  check-host-alive
  check_interval                 5
  check_period                   24x7
  contact_groups                 admins
  max_check_attempts             10
  notification_interval          30
  notification_options           d,r
  notification_period            workhours
  register                       0
  retry_interval                 1
  statusmap_image                printer.png
}

define host {
  name                           generic-router
  use                            generic-switch
  register                       0
  statusmap_image                router.png
}

define service {
  name                           generic-service
  action_url                     /pnp4nagios/graph?host=$HOSTNAME$&srv=$SERVICEDESC$
  active_checks_enabled          1
  check_freshness                0
  check_period                   24x7
  event_handler_enabled          1
  failure_prediction_enabled     1
  flap_detection_enabled         1
  icon_image                     unknown.gif
  is_volatile                    0
  max_check_attempts             3
  normal_check_interval          10
  notes_url                      /adagios/objectbrowser/edit_object/object_type=service/shortname=$HOSTNAME$/$SERVICEDESC$
  notification_interval          60
  notification_options           w,u,c,r
  notification_period            24x7
  notifications_enabled          1
  obsess_over_service            1
  parallelize_check              1
  passive_checks_enabled         1
  process_perf_data              1
  register                       0
  retain_nonstatus_information   1
  retain_status_information      1
  retry_check_interval           2
}

define host {
  name                           generic-switch
  use                            generic-host
  check_command                  check-host-alive
  check_interval                 5
  check_period                   24x7
  contact_groups                 admins
  max_check_attempts             10
  notification_interval          30
  notification_options           d,r
  notification_period            24x7
  register                       0
  retry_interval                 1
  statusmap_image                switch.png
}

define host {
  name                           linux-server
  use                            generic-host
  check_command                  check-host-alive
  check_interval                 5
  check_period                   24x7
  contact_groups                 admins
  max_check_attempts             10
  notification_interval          120
  notification_options           d,u,r
  notification_period            workhours
  register                       0
  retry_interval                 1
}

define service {
  name                           local-service
  use                            generic-service
  max_check_attempts             4
  normal_check_interval          5
  register                       0
  retry_check_interval           1
}

define contact {
  use                            generic-contact
  alias                          Nagios Admin
  contact_name                   nagiosadmin
  email                          nagios@localhost
}

define timeperiod {
  alias                          No Time Is A Good Time
  timeperiod_name                none
}

define command {
  command_line                   /usr/bin/printf "%b" "***** Nagios *****\n\nNotification Type: $NOTIFICATIONTYPE$\nHost: $HOSTNAME$\nState: $HOSTSTATE$\nAddress: $HOSTADDRESS$\nInfo: $HOSTOUTPUT$\n\nDate/Time: $LONGDATETIME$\n" | /bin/mail -s "** $NOTIFICATIONTYPE$ Host Alert: $HOSTNAME$ is $HOSTSTATE$ **" $CONTACTEMAIL$
  command_name                   notify-host-by-email
}

define command {
  command_line                   /usr/bin/printf "%b" "***** Nagios *****\n\nNotification Type: $NOTIFICATIONTYPE$\n\nService: $SERVICEDESC$\nHost: $HOSTALIAS$\nAddress: $HOSTADDRESS$\nState: $SERVICESTATE$\n\nDate/Time: $LONGDATETIME$\n\nAdditional Info:\n\n$SERVICEOUTPUT$\n" | /bin/mail -s "** $NOTIFICATIONTYPE$ Service Alert: $HOSTALIAS$/$SERVICEDESC$ is $SERVICESTATE$ **" $CONTACTEMAIL$
  command_name                   notify-service-by-email
}

define command {
  command_line                   /usr/bin/printf "%b" "$LASTHOSTCHECK$\t$HOSTNAME$\t$HOSTSTATE$\t$HOSTATTEMPT$\t$HOSTSTATETYPE$\t$HOSTEXECUTIONTIME$\t$HOSTOUTPUT$\t$HOSTPERFDATA$\n" >> /var/log/nagios/host-perfdata.out
  command_name                   process-host-perfdata
}

define command {
  command_line                   /usr/bin/printf "%b" "$LASTSERVICECHECK$\t$HOSTNAME$\t$SERVICEDESC$\t$SERVICESTATE$\t$SERVICEATTEMPT$\t$SERVICESTATETYPE$\t$SERVICEEXECUTIONTIME$\t$SERVICELATENCY$\t$SERVICEOUTPUT$\t$SERVICEPERFDATA$\n" >> /var/log/nagios/service-perfdata.out
  command_name                   process-service-perfdata
}

define timeperiod {
  alias                          U.S. Holidays
  december 25             00:00-00:00     ; Christmas
  january 1               00:00-00:00     ; New Years
  july 4                  00:00-00:00     ; Independence Day
  monday -1 may           00:00-00:00     ; Memorial Day (last Monday in May)
  monday 1 september      00:00-00:00     ; Labor Day (first Monday in September)
  name			us-holidays
  thursday 4 november     00:00-00:00     ; Thanksgiving (4th Thursday in November)
  timeperiod_name                us-holidays
}

define host {
  name                           windows-server
  use                            generic-host
  check_command                  check-host-alive
  check_interval                 5
  check_period                   24x7
  contact_groups                 admins
  hostgroups
  max_check_attempts             10
  notification_interval          30
  notification_options           d,r
  notification_period            24x7
  register                       0
  retry_interval                 1
}

define hostgroup {
  alias                          Windows Servers
  hostgroup_name                 windows-servers
}

define timeperiod {
  alias                          Normal Work Hours
  friday		09:00-17:00
  monday		09:00-17:00
  thursday	09:00-17:00
  timeperiod_name                workhours
  tuesday		09:00-17:00
  wednesday	09:00-17:00
}

define command {
	command_name	check_dummy
	command_line	$USER1$/check_dummy!$ARG1$!$ARG2$
}


define host {
	host_name		ok_host
	use			generic-host
	address			ok_host
	max_check_attempts	1
	check_command		check_dummy!0!Everything seems to be okay
}


define service {
	host_name		ok_host
	use			generic-service
	service_description	ok service 1
	check_command		check_dummy!0!Everything seems to be okay
}

"""


if __name__ == "__main__":
    unittest.main()

# vim: sts=4 expandtab autoindent

########NEW FILE########
__FILENAME__ = test_plugins

from __future__ import print_function
from __future__ import unicode_literals
from __future__ import absolute_import

import os
import sys


# Make sure we import from working tree
pynagbase = os.path.dirname(os.path.realpath(__file__ + "/.."))
sys.path.insert(0, pynagbase)

import unittest2 as unittest
import time

import pynag.Utils
import pynag.Plugins
import signal
# Some of the methods here print directly to stdout but we
# dont want to spam the output of the unittests. Lets do a temp
# blocking of stdout and stderr
from cStringIO import StringIO
original_stdout = sys.stdout
original_stderr = sys.stderr


class PluginParams(unittest.TestCase):
    def setUp(self):
        self.argv_store = sys.argv
        from pynag.Plugins import simple as Plugin
        self.np = Plugin(must_threshold=False)
        sys.stdout = StringIO()

    def tearDown(self):
        sys.argv = [sys.argv[0]]
        sys.stdout = original_stdout

    def create_params(self, *args):
        sys.argv.extend(args)

    def test_default_verbose(self):
        #sys.argv = [sys.argv[0]] + ['-v', '10']
        self.create_params('-v', '10')
        self.np.activate()
        self.assertEquals(self.np.data['verbosity'], 0)

    def test_verbose(self):
        self.create_params('-v', '3')
        self.np.activate()
        self.assertEquals(self.np.data['verbosity'], 3)

    def test_set_hostname(self):
        self.create_params('-H', 'testhost.example.com')
        self.np.activate()
        self.assertEquals(self.np.data['host'], 'testhost.example.com')

    def test_set_timeout(self):
        self.create_params('-t', '100')
        self.np.activate()
        self.assertEquals(self.np.data['timeout'], '100')

    def test_default_timeout(self):
        self.np.activate()
        self.assertEquals(self.np.data['timeout'], None)

    def test_shortname(self):
        from pynag.Plugins import simple as Plugin
        np = Plugin(shortname='testcase')
        self.assertEquals(np.data['shortname'], 'testcase')


class PluginNoThreshold(unittest.TestCase):
    def setUp(self):
        self.argv_store = sys.argv
        from pynag.Plugins import simple as Plugin
        self.np = Plugin(must_threshold=False)
        sys.stdout = StringIO()

    def tearDown(self):
        sys.argv = self.argv_store
        sys.stdout = original_stdout

    def run_expect(self, case, expected_exit, value):
        sys.argv = [sys.argv[0]] + case.split()
        self.np.activate()
        try:
            self.np.check_range(value)
        except SystemExit, e:
            self.assertEquals(type(e), type(SystemExit()))
            self.assertEquals(e.code, expected_exit)
        except Exception, e:
            self.fail('unexpected exception: %s' % e)
        else:
            self.fail('SystemExit exception expected')

    """
    All tests return OK since thresholds are not required
    """
    def test_number_1(self):
        case = ''
        self.run_expect(case, 0, -23)

    def test_number_2(self):
        case = ''
        self.run_expect(case, 0, 0)

    def test_number_3(self):
        case = ''
        self.run_expect(case, 0, 2)

    def test_number_4(self):
        case = ''
        self.run_expect(case, 0, 10)

    def test_number_5(self):
        case = ''
        self.run_expect(case, 0, 15)


class PluginHelper(unittest.TestCase):
    def setUp(self):
        self.argv_store = sys.argv
        from pynag.Plugins import PluginHelper
        self.my_plugin = PluginHelper()
        self.my_plugin.parser.add_option('-F',
                                         dest='fakedata',
                                         help='fake data to test thresholds')
        sys.stdout = StringIO()
    def tearDown(self):
        sys.argv = self.argv_store
        sys.stdout = original_stdout

    def run_expect(self, case, value, expected_exit):
        sys.argv = [sys.argv[0]] + case.split() + ('-F %s' % value).split()
        self.my_plugin.parse_arguments()
        self.my_plugin.add_status(pynag.Plugins.ok)
        self.my_plugin.add_summary(self.my_plugin.options.fakedata)
        self.my_plugin.add_metric('fakedata', self.my_plugin.options.fakedata)
        try:
            self.my_plugin.check_all_metrics()
            self.my_plugin.exit()
        except SystemExit, e:
            self.assertEquals(type(e), type(SystemExit()))
            self.assertEquals(e.code, expected_exit)
        except Exception, e:
            self.fail('unexpected exception: %s' % e)
        else:
            self.fail('SystemExit exception expected')
        finally:
            signal.alarm(0)

    """
    Critical if "stuff" is over 20, else warn if over 10
    (will be critical if "stuff" is less than 0)
    """
    def test_number_1(self):
        case = '--th=metric=fakedata,ok=0..10,warn=10..20'
        self.run_expect(case, -23, 2)

    def test_number_2(self):
        case = '--th=metric=fakedata,ok=0..10,warn=10..20'
        self.run_expect(case, 3, 0)

    def test_number_3(self):
        case = '--th=metric=fakedata,ok=0..10,warn=10..20'
        self.run_expect(case, 13, 1)

    def test_number_4(self):
        case = '--th=metric=fakedata,ok=0..10,warn=10..20'
        self.run_expect(case, 23, 2)

    """
    Same as above. Negative "stuff" is OK
    """
    def test_number_5(self):
        case = '--th=metric=fakedata,ok=inf..10,warn=10..20'
        self.run_expect(case, '-23', 0)

    def test_number_6(self):
        case = '--th=metric=fakedata,ok=inf..10,warn=10..20'
        self.run_expect(case, '3', 0)

    def test_number_7(self):
        case = '--th=metric=fakedata,ok=inf..10,warn=10..20'
        self.run_expect(case, '13', 1)

    def test_number_8(self):
        case = '--th=metric=fakedata,ok=inf..10,warn=10..20'
        self.run_expect(case, '23', 2)

    """
    Critical if "stuff" is over 20, else warn if "stuff" is below 10
    (will be critical if "stuff" is less than 0)
    """
    def test_number_9(self):
        case = '--th=metric=fakedata,warn=0..10,crit=20..inf'
        self.run_expect(case, '-23', 0)

    def test_number_10(self):
        case = '--th=metric=fakedata,warn=0..10,crit=20..inf'
        self.run_expect(case, '3', 1)

    def test_number_11(self):
        case = '--th=metric=fakedata,warn=0..10,crit=20..inf'
        self.run_expect(case, '13', 0)

    def test_number_12(self):
        case = '--th=metric=fakedata,warn=0..10,crit=20..inf'
        self.run_expect(case, '23', 2)

    """
    Critical if "stuff" is less than 1
    """
    def test_number_13(self):
        case = '--th=metric=fakedata,ok=1..inf'
        self.run_expect(case, '-23', 2)

    def test_number_14(self):
        case = '--th=metric=fakedata,ok=1..inf'
        self.run_expect(case, '0', 2)

    def test_number_15(self):
        case = '--th=metric=fakedata,ok=1..inf'
        self.run_expect(case, '13', 0)

    def test_number_16(self):
        case = '--th=metric=fakedata,ok=1..inf'
        self.run_expect(case, '23', 0)

    """
    1-9 is warning, negative or above 10 is critical
    """
    def test_number_17(self):
        case = '--th=metric=fakedata,warn=1..9,crit=^0..10'
        self.run_expect(case, '-23', 2)

    def test_number_18(self):
        case = '--th=metric=fakedata,warn=1..9,crit=^0..10'
        self.run_expect(case, '0', 0)

    def test_number_19(self):
        case = '--th=metric=fakedata,warn=1..9,crit=^0..10'
        self.run_expect(case, '7', 1)

    def test_number_20(self):
        case = '--th=metric=fakedata,warn=1..9,crit=^0..10'
        self.run_expect(case, '23', 2)

    """
    The only noncritical range is 5:6
    """
    def test_number_21(self):
        case = '--th=metric=fakedata,ok=5..6'
        self.run_expect(case, '-23', 2)

    def test_number_22(self):
        case = '--th=metric=fakedata,ok=5..6'
        self.run_expect(case, '0', 2)

    def test_number_23(self):
        case = '--th=metric=fakedata,ok=5..6'
        self.run_expect(case, '2', 2)

    def test_number_24(self):
        case = '--th=metric=fakedata,ok=5..6'
        self.run_expect(case, '5', 0)

    def test_number_25(self):
        case = '--th=metric=fakedata,ok=5..6'
        self.run_expect(case, '6', 0)

    def test_number_26(self):
        case = '--th=metric=fakedata,ok=5..6'
        self.run_expect(case, '7', 2)

    """
    Critical if "stuff" is 10 to 20
    """
    def test_number_27(self):
        case = '--th=metric=fakedata,ok=^10..20'
        self.run_expect(case, '-23', 0)

    def test_number_28(self):
        case = '--th=metric=fakedata,ok=^10..20'
        self.run_expect(case, '0', 0)

    def test_number_29(self):
        case = '--th=metric=fakedata,ok=^10..20'
        self.run_expect(case, '2', 0)

    def test_number_30(self):
        case = '--th=metric=fakedata,ok=^10..20'
        self.run_expect(case, '10', 2)

    def test_number_31(self):
        case = '--th=metric=fakedata,ok=^10..20'
        self.run_expect(case, '15', 2)

    def test_number_32(self):
        case = '--th=metric=fakedata,ok=^10..20'
        self.run_expect(case, '20', 2)

    def test_number_33(self):
        case = '--th=metric=fakedata,ok=^10..20'
        self.run_expect(case, '23', 0)

    """
    Cmdline thresholds pass but we insert a "hardcoded" metric with thresholds
    which will also be evaluated
    """
    def test_number_34(self):
        # Extra case with hardcoded thresholds
        self.my_plugin.add_metric('fakedata2', value='15',
                                  warn='0..10', crit='10..inf')
        case = '--th=metric=fakedata,ok=0..10,warn=10..20'
        self.run_expect(case, 3, 2)

    def test_number_35(self):
        # Extra case with hardcoded thresholds
        self.my_plugin.add_metric('fakedata2', value='9',
                                  warn='0..10', crit='10..inf')
        case = '--th=metric=fakedata,ok=0..10,warn=10..20'
        self.run_expect(case, 3, 1)

    def test_number_36(self):
        # Extra case with hardcoded thresholds
        self.my_plugin.add_metric('fakedata2', value='-4',
                                  warn='0..10', crit='10..inf')
        case = '--th=metric=fakedata,ok=0..10,warn=10..20'
        self.run_expect(case, 3, 0)

    def testTimeout(self):
        try:
            self.my_plugin.set_timeout(1)
            time.sleep(1)
            self.assertTrue(False, "Code should have timed out by now")
        except SystemExit, e:
            self.assertEquals(type(e), type(SystemExit()))
            self.assertEquals(e.code, pynag.Plugins.unknown)
        self.assertTrue(True, "Timeout occured in plugin, just like expected.")




class Plugin(unittest.TestCase):
    def setUp(self):
        self.argv_store = sys.argv
        from pynag.Plugins import simple as Plugin
        self.np = Plugin()
        sys.stdout = StringIO()
        sys.stderr = StringIO()
    def tearDown(self):
        sys.argv = self.argv_store
        sys.stdout = original_stdout
        sys.stderr = original_stderr

    def run_expect(self, case, expected_exit, value):
        sys.argv = [sys.argv[0]] + case.split()
        self.np.activate()
        try:
            self.np.add_perfdata('fake', value, uom='fakes',
                                 warn=10, crit=20, minimum=-100, maximum=100)
            perfdata_string = self.np.perfdata_string()
            print(perfdata_string)
            self.assertEquals(perfdata_string, "| '%s'=%s%s;%s;%s;%s;%s" % (
                              'fake', value, 'fakes', 10, 20, -100, 100))
            self.np.add_message('OK', 'Some message')
            self.assertEquals(self.np.data['messages'][0], ['Some message'])
            self.np.check_range(value)
        except SystemExit, e:
            self.assertEquals(type(e), type(SystemExit()))
            self.assertEquals(e.code, expected_exit)
        except Exception, e:
            import traceback
            print(traceback.format_exc())
            self.fail('unexpected exception: %s' % e)
        else:
            self.fail('SystemExit exception expected')


    """
    Throws SystemExit, required parameter not set when activating
    """
    def test_add_arg_req_missing(self):
        self.np.add_arg('F', 'fakedata',
                        'fake data to test thresholds', required=True)
        self.assertRaises(SystemExit, self.np.activate)

    def test_add_arg_req(self):
        self.np.add_arg('F', 'fakedata',
                        'fake data to test thresholds', required=True)
        sys.argv = [sys.argv[0]] + '-F 100 -w 1 -c 2'.split()
        self.np.activate()

    def test_add_arg(self):
        self.np.add_arg('F', 'fakedata',
                        'fake data to test thresholds', required=False)
        sys.argv = [sys.argv[0]] + '-w 1 -c 2'.split()
        self.np.activate()

    def test_codestring_to_int(self):
        code = self.np.code_string2int('OK')
        self.assertEquals(code, 0, "OK did not map to 0")

        code = self.np.code_string2int('WARNING')
        self.assertEquals(code, 1, "WARNING did not map to 1")

        code = self.np.code_string2int('CRITICAL')
        self.assertEquals(code, 2, "CRITICAL did not map to 2")

        code = self.np.code_string2int('UNKNOWN')
        self.assertEquals(code, 3, "UNKNOWN did not map to 3")

    """
    Critical if "stuff" is over 20, else warn if over 10
    (will be critical if "stuff" is less than 0)
    """
    def test_number_1(self):
        case = '-w 10 -c 20'
        self.run_expect(case, 2, -23)

    def test_number_2(self):
        case = '-w 10 -c 20'
        self.run_expect(case, 0, 3)

    def test_number_3(self):
        case = '-w 10 -c 20'
        self.run_expect(case, 1, 13)

    def test_number_4(self):
        case = '-w 10 -c 20'
        self.run_expect(case, 2, 23)

    """
    Same as above. Negative "stuff" is OK
    """
    def test_number_5(self):
        case = '-w ~:10 -c ~:20'
        self.run_expect(case, 0, -23)

    def test_number_6(self):
        case = '-w ~:10 -c ~:20'
        self.run_expect(case, 0, 3)

    def test_number_7(self):
        case = '-w ~:10 -c ~:20'
        self.run_expect(case, 1, 13)

    def test_number_8(self):
        case = '-w ~:10 -c ~:20'
        self.run_expect(case, 2, 23)

    """
    Critical if "stuff" is over 20, else warn if "stuff" is below 10
    (will be critical if "stuff" is less than 0)
    """
    def test_number_9(self):
        case = '-w 10: -c 20'
        self.run_expect(case, 2, -23)

    def test_number_10(self):
        case = '-w 10: -c 20'
        self.run_expect(case, 1, 3)

    def test_number_11(self):
        case = '-w 10: -c 20'
        self.run_expect(case, 0, 13)

    def test_number_12(self):
        case = '-w 10: -c 20'
        self.run_expect(case, 2, 23)

    """
    Critical if "stuff" is less than 1
    """
    def test_number_13(self):
        case = '-c 1:'
        self.run_expect(case, 2, -23)

    def test_number_14(self):
        case = '-c 1:'
        self.run_expect(case, 2, 0)

    def test_number_15(self):
        case = '-c 1:'
        self.run_expect(case, 0, 13)

    def test_number_16(self):
        case = '-c 1:'
        self.run_expect(case, 0, 23)

    """
    1-9 is warning, negative or above 10 is critical
    """
    def test_number_17(self):
        case = '-w ~:0 -c 10'
        self.run_expect(case, 2, -23)

    def test_number_18(self):
        case = '-w ~:0 -c 10'
        self.run_expect(case, 0, 0)

    def test_number_19(self):
        case = '-w ~:0 -c 10'
        self.run_expect(case, 1, 7)

    def test_number_20(self):
        case = '-w ~:0 -c 10'
        self.run_expect(case, 2, 23)

    """
    The only noncritical range is 5:6
    """
    def test_number_21(self):
        case = '-c 5:6'
        self.run_expect(case, 2, -23)

    def test_number_22(self):
        case = '-c 5:6'
        self.run_expect(case, 2, 0)

    def test_number_23(self):
        case = '-c 5:6'
        self.run_expect(case, 2, 2)

    def test_number_24(self):
        case = '-c 5:6'
        self.run_expect(case, 0, 5)

    def test_number_25(self):
        case = '-c 5:6'
        self.run_expect(case, 0, 6)

    """
    Critical if "stuff" is 10 to 20
    """
    def test_number_26(self):
        case = '-c @10:20'
        self.run_expect(case, 0, -23)

    def test_number_27(self):
        case = '-c @10:20'
        self.run_expect(case, 0, 0)

    def test_number_28(self):
        case = '-c @10:20'
        self.run_expect(case, 0, 2)

    def test_number_29(self):
        case = '-c @10:20'
        self.run_expect(case, 2, 10)

    def test_number_30(self):
        case = '-c @10:20'
        self.run_expect(case, 2, 15)

    def test_number_31(self):
        case = '-c @10:20'
        self.run_expect(case, 2, 20)

    def test_number_32(self):
        case = '-c @10:20'
        self.run_expect(case, 0, 23)


class NewPluginThresholdSyntax(unittest.TestCase):
    """ Unit tests for pynag.Plugins.new_threshold_syntax """
    def test_check_threshold(self):
        """ Test check_threshold() with different parameters

        Returns (in order of appearance):
        0 - Unknown on invalid input
        1 - If no levels are specified, return OK
        2 - If an ok level is specified and value is within range, return OK
        3 - If a critical level is specified and value is within range, return CRITICAL
        4 - If a warning level is specified and value is within range, return WARNING
        5 - If an ok level is specified, return CRITICAL
        6 - Otherwise return OK
        """
        from pynag.Plugins.new_threshold_syntax import check_threshold
        from pynag.Plugins import ok, warning, critical, unknown

        # 0 - return unknown on invalid input
        self.assertEqual(unknown, check_threshold(1, warning='invalid input'))

        # 1 - If no levels are specified, return OK
        self.assertEqual(ok, check_threshold(1))

        # 2 - If an ok level is specified and value is within range, return OK
        self.assertEqual(ok, check_threshold(1, ok="0..10"))
        self.assertEqual(ok, check_threshold(1, ok="0..10", warning="0..10"))
        self.assertEqual(ok, check_threshold(1, ok="0..10", critical="0..10"))

        # 3 - If a critical level is specified and value is within range, return CRITICAL
        self.assertEqual(critical, check_threshold(1, critical="0..10"))

        # 4 - If a warning level is specified and value is within range, return WARNING
        self.assertEqual(warning, check_threshold(1, warning="0..10"))

        # 5 - If an ok level is specified, return CRITICAL
        self.assertEqual(critical, check_threshold(1, ok="10..20"))

        # 6 - Otherwise return OK
        # ... we pass only warning, then only critical, then both, but value is always outside ranges
        self.assertEqual(ok, check_threshold(1, warning="10..20"))
        self.assertEqual(ok, check_threshold(1, critical="10..20"))
        self.assertEqual(ok, check_threshold(1, warning="10..20", critical="20..30"))

    def test_invalid_range(self):
        from pynag.Plugins.new_threshold_syntax import check_range
        from pynag.Utils import PynagError

        self.assertRaises(PynagError, check_range, 1, '')
        self.assertRaises(PynagError, check_range, 1, None)

    def test_invalid_threshold(self):
        from pynag.Plugins.new_threshold_syntax import parse_threshold
        from pynag.Utils import PynagError

        self.assertRaises(PynagError, parse_threshold, '')
        self.assertRaises(AttributeError, parse_threshold, None)
        self.assertRaises(PynagError, parse_threshold, 'string')

if __name__ == "__main__":
    unittest.main()

# vim: sts=4 expandtab autoindent

########NEW FILE########
__FILENAME__ = test_utils
import os
import sys

# Make sure we import from working tree
pynagbase = os.path.dirname(os.path.realpath(__file__ + "/.."))
sys.path.insert(0, pynagbase)

import unittest2 as unittest
from mock import patch
import shutil
import tempfile
import pynag.Utils as utils
import pynag.Model
from pynag.Utils import PynagError
from tests import tests_dir
import pynag.Utils.misc


class testUtils(unittest.TestCase):

    def setUp(self):
        # Utils should work fine with just about any data, but lets use
        # testdata01
        os.chdir(tests_dir)
        os.chdir('dataset01')
        pynag.Model.config = None
        pynag.Model.cfg_file = './nagios/nagios.cfg'
        pynag.Model.ObjectDefinition.objects.get_all()
        self.tmp_dir = tempfile.mkdtemp()  # Will be deleted after test runs

    def tearDown(self):
        shutil.rmtree(self.tmp_dir, ignore_errors=True)

    def testCompareFilterWithGrep(self):
        """ test pynag.Utils.grep() by comparing it with pynag.Model.Service.objects.filter()

        # TODO: Currently  pynag.Model.Service.objects.filter() has some bugs, so some tests here fail.
        """
        self._compare_search_expressions(use='generic-service')

        self._compare_search_expressions(register=1, use='generic-service')

        self._compare_search_expressions(host_name__exists=True)

        self._compare_search_expressions(host_name__exists=False)

        self._compare_search_expressions(host_name__notcontains='l')

        self._compare_search_expressions(host_name__notcontains='this value cannot possibly exist')

        self._compare_search_expressions(host_name__startswith='l')

        self._compare_search_expressions(host_name__endswith='m')

        self._compare_search_expressions(host_name__isnot='examplehost for testing purposes')

    def testGrep(self):
        """ Test cases based on gradecke's testing """
        host = pynag.Model.string_to_class['host']()
        host['use'] = "generic-host"
        host['name'] = "ABC"
        host['_code'] = "ABC"
        host['_function'] = "Server,Production"

        host2 = pynag.Model.string_to_class['host']()
        host2['use'] = "generic-host"
        host2['name'] = "XYZ"
        host2['_code'] = "XYZ"
        host2['_function'] = "Switch,Production"

        hosts = host, host2

        result = pynag.Utils.grep(hosts, **{'_code__contains': 'ABC'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__contains': 'BC'})
        self.assertEqual(1, len(result))

        # Check that contains does not match nonexisting values
        result = pynag.Utils.grep(hosts, **{'_code__contains': ''})
        self.assertEqual(2, len(result))

        result = pynag.Utils.grep(hosts, **{'nonexistant__contains': ''})
        self.assertEqual(0, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__notcontains': 'ABC'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__notcontains': 'BC'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__startswith': 'ABC'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__startswith': 'AB'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__notstartswith': 'AB'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__endswith': 'ABC'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__endswith': 'BC'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__notendswith': 'YZ'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__exists': True})
        self.assertEqual(2, len(result))

        result = pynag.Utils.grep(hosts, **{'_code__exists': False})
        self.assertEqual(0, len(result))

        result = pynag.Utils.grep(hosts, **{'_function__has_field': 'Server'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(
            hosts, **{'_function__has_field': 'Production'})
        self.assertEqual(2, len(result))

        result = pynag.Utils.grep(hosts, **{'name__notcontains': 'A'})
        self.assertEqual(1, len(result))

        result = pynag.Utils.grep(hosts, **{'name__regex': 'A.C'})
        self.assertEqual(1, len(result))
        self.assertEqual('ABC', result[0].name)

        result = pynag.Utils.grep(hosts, **{'name__in': ['ABC', 'BCD']})
        self.assertEqual(1, len(result))
        self.assertEqual('ABC', result[0].name)

        result = pynag.Utils.grep(hosts, **{'name__notin': ['ABC', 'BCD']})
        self.assertEqual(1, len(result))
        self.assertEqual('XYZ', result[0].name)

        result = pynag.Utils.grep(hosts, **{'search': 'Switch'})
        self.assertEqual(1, len(result))
        self.assertEqual('XYZ', result[0].name)

    def _compare_search_expressions(self, **expression):
        # print "Testing search expression %s" % expression
        all_services = pynag.Model.Service.objects.all
        result1 = pynag.Model.Service.objects.filter(**expression)
        result2 = pynag.Utils.grep(all_services, **expression)
        self.assertEqual(
            result1, result2, msg="Search output from pynag.Utils.grep() does not match pynag.Model.Service.objects.filter() when using parameters %s\nFilter: %s\nGrep: %s" %
            (expression, result1, result2))
        return len(result1)

    def test_run_command_file_not_found(self):
        command = '/bin/doesnotexist'
        expected_msg = '\* Could not run command \(return code= %s\)\n' % 127
        expected_msg += '\* Error was:\n.*: %s: (not found|No such file or directory)\n' % command
        expected_msg += '\* Command was:\n%s\n' % command
        expected_msg += '\* Output was:\n\n'
        expected_msg += 'Check if y/our path is correct: %s' % os.getenv(
            'PATH')
        self.assertRaisesRegexp(
            utils.PynagError, expected_msg, utils.runCommand, command, raise_error_on_fail=True)

    def test_gitrepo_init_empty(self):
        from getpass import getuser
        from platform import node
        repo = utils.GitRepo(
            directory=self.tmp_dir,
            auto_init=True,
            author_name=None,
            author_email=None
        )
        self.assertEquals(repo.author_name, 'Pynag User')
        expected_email = '<%s@%s>' % (getuser(), node())
        self.assertEquals(repo.author_email, expected_email)

    def test_gitrepo_init_with_author(self):
        tempfile.mkstemp(dir=self.tmp_dir)
        author_name = 'Git Owner'
        author_email = 'git@localhost.local'
        repo = utils.GitRepo(
            directory=self.tmp_dir,
            auto_init=True,
            author_name=author_name,
            author_email=author_email
        )
        self.assertEquals(repo.author_name, author_name)
        self.assertEquals(repo.author_email, author_email)
        self.assertEquals(len(repo.log()), 1)
        self.assertEquals(repo.log()[0]['author_name'], author_name)
        self.assertEquals(repo.log()[0]['author_email'], author_email)

    def test_gitrepo_init_with_files(self):
        tempfile.mkstemp(dir=self.tmp_dir)
        # If pynag defaults will fail, correctly, adjust for test
        author_email = None
        from getpass import getuser
        from platform import node
        nodename = node()
        if nodename.endswith('.(none)'):
            nodename[:-7] + '.example.com'
            author_email = '%s@%s' % (getuser(), nodename)
        repo = utils.GitRepo(
            directory=self.tmp_dir,
            auto_init=True,
            author_name=None,
            author_email=author_email
        )
        # Check that there is an initial commit
        expected_email = '%s@%s' % (getuser(), nodename)
        self.assertEquals(len(repo.log()), 1)
        self.assertEquals(repo.log()[0]['comment'], 'Initial Commit')
        self.assertEquals(repo.log()[0]['author_name'], 'Pynag User')
        self.assertEquals(repo.log()[0]['author_email'], expected_email)
        # Test kwargs functionality
        self.assertEquals(
            repo.log(author_email=expected_email)[0]['author_email'], expected_email)
        self.assertEquals(
            repo.log(comment__contains='Initial')[0]['comment'], 'Initial Commit')
        self.assertEquals(len(repo.log(comment__contains='nothing')), 0)
        # Test show method
        initial_hash = repo.log()[0]['hash']
        initial_hash_valid_commits = repo.get_valid_commits()[0]
        self.assertEquals(initial_hash, initial_hash_valid_commits)

        gitrunpatcher = patch('pynag.Utils.GitRepo._run_command')
        validcommitspatcher = patch('pynag.Utils.GitRepo.get_valid_commits')
        gitrunpatch = gitrunpatcher.start()
        validcommitspatch = validcommitspatcher.start()
        validcommitspatch.return_value = [initial_hash]
        repo.show(initial_hash)
        gitrunpatch.assert_called_once_with('git show %s' % initial_hash)
        gitrunpatcher.stop()
        validcommitspatcher.stop()

        self.assertRaisesRegexp(
            PynagError, '%s is not a valid commit id' % initial_hash)
        # Add file
        tempfile.mkstemp(dir=self.tmp_dir)
        self.assertEquals(len(repo.get_uncommited_files()), 1)
        self.assertEquals(repo.is_up_to_date(), False)
        # Commit file
        repo.commit(filelist=repo.get_uncommited_files()[0]['filename'])
        self.assertEquals(repo.is_up_to_date(), True)
        self.assertEquals(len(repo.get_uncommited_files()), 0)
        self.assertEquals(len(repo.get_valid_commits()), 2)
        log_entry = repo.log()[0]
        self.assertEquals(log_entry['comment'], 'commited by pynag')

    def test_gitrepo_deprecated_methods(self):
        """
        Delete this class as deprecated methods are removed.
        """
        repo = utils.GitRepo(directory=self.tmp_dir, auto_init=True)
        testfilename = 'testfile.name.txt'

        add_method_patcher = patch('pynag.Utils.GitRepo.add')
        add_method_patch = add_method_patcher.start()
        repo._git_add(testfilename)
        add_method_patch.assert_called_once_with(testfilename)
        add_method_patcher.stop()

        commit_method_mocker = patch('pynag.Utils.GitRepo.commit')
        commit_method_mock = commit_method_mocker.start()
        repo._git_commit(filename=testfilename, message='test')
        commit_method_mock.assert_called_once_with(
            message='test', filelist=[testfilename])
        commit_method_mock.reset_mock()
        repo._git_commit(
            filename=None, message='test', filelist=[testfilename])
        commit_method_mock.assert_called_once_with(
            message='test', filelist=[testfilename])
        commit_method_mock.reset_mock()
        repo._git_commit(
            filename=testfilename, message='test', filelist=[testfilename])
        commit_method_mock.assert_called_once_with(
            message='test', filelist=[testfilename, testfilename])
        commit_method_mocker.stop()

    def test_gitrepo_diff(self):
        """ Test git diff works as expected  """
        # Create repo and write one test commit
        git = utils.GitRepo(directory=self.tmp_dir, auto_init=True)
        tmp_filename = "%s/%s" % (self.tmp_dir, 'testfile.txt')
        open(tmp_filename, 'w').write('test data\n')
        git.commit()

        # First try diff with no changes made:
        diff = git.diff()
        self.assertEquals(diff, '')

        # Now append to our file and see the difference:
        extra_data = 'extra data\n'
        open(tmp_filename, 'a').write(extra_data)

        # Call diff with no params, check if extra_data is in the diff
        diff = git.diff()

        self.assertTrue(diff.find(extra_data) > 0)

        # Call diff with filename as parameter, check if extra_data is in the
        # diff
        diff = git.diff(commit_id_or_filename=tmp_filename)
        self.assertTrue(diff.find(extra_data) > 0)

        # Call commit again and confirm there is no diff
        git.commit()
        diff = git.diff()
        self.assertEquals(diff, '')

        # Call a diff against first commit, see if we find our changes in the
        # commit.
        all_commits = git.get_valid_commits()
        first_commit = all_commits.pop()
        diff = git.diff(commit_id_or_filename=first_commit)
        self.assertTrue(diff.find(extra_data) > 0)

        # Revert latest change, and make sure diff is gone.
        last_commit = all_commits.pop(0)
        git.revert(last_commit)
        diff = git.diff(commit_id_or_filename=first_commit)
        self.assertTrue(diff.find(extra_data) == -1)

        # At last try to diff against an invalid commit id
        try:
            git.diff('invalid commit id')
            self.assertTrue(
                False, "we wanted exception when calling diff on invalid commit id")
        except PynagError:
            pass

    def test_send_nsca(self):
        """ test pynag.Utils.send_nsca

        By its very nature, send_nsca binary itself does not allow for much testing,
        however we can still test if the function is working as expected
        """

        # Run send_nsca normally for a smoke test (we don't know much about what send_nsca will do with out packet)
        # This test will only fail if there are unhandled tracebacks in the
        # code somewhere
        try:
            pynag.Utils.send_nsca(code=0, message="test", nscahost="localhost")
        except OSError, e:
            # We don't care about the result if we have error because send_nsca
            # is not installed
            if e.errno != 2:
                raise e

        result = pynag.Utils.send_nsca(
            code=0, message="match", nscahost="match", hostname="test", service=None, nscabin="/bin/grep", nscaconf="-")
        self.assertEqual(0, result[0])
        self.assertEqual('(standard input):1\n', result[1])

        result = pynag.Utils.send_nsca(
            code=0, message="match", nscahost="nomatch", hostname="test", service=None, nscabin="/bin/grep", nscaconf="-")
        self.assertEqual(1, result[0])
        self.assertEqual('(standard input):0\n', result[1])


class testFakeNagiosEnvironment(unittest.TestCase):

    def setUp(self):
        self.environment = pynag.Utils.misc.FakeNagiosEnvironment()
        self.environment.create_minimal_environment()

    def tearDown(self):
        self.environment.terminate()

    def testMinimal(self):
        """ Minimal Test of our FakeNagiosEnvironment """
        nagios = pynag.Utils.misc.FakeNagiosEnvironment()
        nagios.create_minimal_environment()
        nagios.config.parse()
        self.assertTrue(os.path.isfile(nagios.config.cfg_file))
        self.assertTrue(os.path.isdir(nagios.objects_dir))

    def testModelUpdates(self):
        """ Test backup and restores of Model global variables """
        nagios = self.environment
        original_config = pynag.Model.config
        original_cfg_file = pynag.Model.cfg_file
        original_dir = pynag.Model.pynag_directory

        # Update model, and check if updates succeeded
        nagios.update_model()
        self.assertEqual(pynag.Model.config, nagios.config)
        self.assertEqual(pynag.Model.cfg_file, nagios.config.cfg_file)
        self.assertEqual(pynag.Model.pynag_directory, nagios.objects_dir)

        # See if we can restore our model
        nagios.restore_model()
        self.assertEqual(pynag.Model.config, original_config)
        self.assertEqual(pynag.Model.cfg_file, original_cfg_file)
        self.assertEqual(pynag.Model.pynag_directory, original_dir)

    def testStartStop(self):
        """ Try to start and stop our nagios environment  """
        self.environment.start()
        pid = open(self.environment.tempdir + "nagios.pid").read()
        pid = int(pid)
        try:
            os.kill(pid, 0)
        except OSError:
            self.assertTrue(False, "Did not find a running process with process_id=%s" % pid)
        self.environment.stop()
        try:
            os.kill(pid, 0)
            self.assertTrue(False, "Seems like process with process_id=%s is still running" % pid)
        except OSError:
            pass

    def testOpenDecorator(self):
        """ Makes sure the fake nagios environment cannot go outside its directory """
        # Try to open a regular file
        self.environment.config.open(self.environment.config.cfg_file).close()
        self.assertTrue(True, "Successfully opened nagios.cfg")
        try:
            self.environment.config.open("/etc/passwd").close()
            self.assertTrue(False, "I was able to open a file outside my tempdir!")
        except PynagError:
            pass

    def testUpdateModel_NoRestore(self):
        self.environment.update_model()

    def testLivestatus(self):
        host_name = "localhost"
        self.environment.update_model()
        pynag.Model.Host(host_name=host_name, use="generic-host").save()

        self.environment.guess_livestatus_path()
        self.environment.configure_livestatus()
        self.environment.start()
        livestatus = self.environment.get_livestatus()
        hosts = livestatus.get_hosts(name=host_name)
        self.assertTrue(hosts, "Could not find a host called %s" % (host_name))

    def testImports(self):
        """ Test FakeNagiosEnvironment.import_config()  """
        host1 = "host1"
        host2 = "host2"
        tempdir = tempfile.mkdtemp()
        tempfile1 = tempfile.mktemp(suffix='.cfg')
        tempfile2 = os.path.join(tempdir, 'file2.cfg')

        with open(tempfile1, 'w') as f:
            f.write("define host {\nname host1\n}")
        with open(tempfile2, 'w') as f:
            f.write("define host {\nname host2\n}")

        self.environment.import_config(tempdir)
        self.environment.import_config(tempfile1)

        self.environment.update_model()
        host1 = pynag.Model.Host.objects.filter(name=host1)
        host2 = pynag.Model.Host.objects.filter(name=host2)
        self.assertTrue(host1)
        self.assertTrue(host2)

if __name__ == "__main__":
    unittest.main()

# vim: sts=4 expandtab autoindent

########NEW FILE########
