__FILENAME__ = buildrelease
import os
import sys
from datetime import datetime, date

import setup
import clean

clean.run()
script = os.path.abspath(setup.__file__)

assert setup.mod.VERSION[3] == 'final'

with open('CHANGELOG.rst', 'r') as f:
    changelog = f.read()

top = changelog.split('\n')[0]
version_date = top.split(' - ')
assert len(version_date) == 2, 'Top of CHANGELOG.rst must be version and date'
version, datestr = version_date
dt = datetime.strptime(datestr, '%Y-%b-%d').date()
assert dt == date.today()

assert version == 'Ver. %s' % setup.mod.__version__

argv = [script, 'sdist'] + sys.argv[1:]
setup.run(argv=argv)


print('%s %s ready!' % (setup.package_name, setup.mod.__version__))

########NEW FILE########
__FILENAME__ = clean
import os
import shutil

remove_dirs = ('dist', 'build', 'pulsar.egg-info')

def rmgeneric(path, __func__):
    try:
        __func__(path)
        #print 'Removed ', path
        return 1
    except OSError as e:
        print('Could not remove {0}, {1}'.format(path, e))
        return 0


def rmfiles(path=None, *extensions):
    path = path or os.curdir
    if not os.path.isdir(path):
        return 0
    assert extensions
    for ext in extensions:
        assert ext
    trem = 0
    tall = 0
    files = os.listdir(path)
    for name in files:
        fullpath = os.path.join(path, name)
        if os.path.isfile(fullpath):
            sf = name.split('.')
            if len(sf) == 2 and sf[1] in extensions:
                tall += 1
                trem += rmgeneric(fullpath, os.remove)
        elif name == '__pycache__':
            shutil.rmtree(fullpath)
            tall += 1
        elif os.path.isdir(fullpath) and not name.startswith('.'):
            r, ra = rmfiles(fullpath, *extensions)
            trem += r
            tall += ra
    return trem, tall


def run():
    for path in remove_dirs:
        if os.path.isdir(path):
            print('Removing %s' % path)
            shutil.rmtree(path)
    removed, allfiles = rmfiles(os.curdir, 'pyc', 'DS_Store')
    print('removed {0} pyc files out of {1}'.format(removed, allfiles))


if __name__ == '__main__':
    run()

########NEW FILE########
__FILENAME__ = covrun
'''
Script for running test on travis-ci.org
'''
import sys
import os
import platform

from runtests import run


if __name__ == '__main__':
    if platform.python_implementation() == 'PyPy' and '--pep8' in sys.argv:
        sys.exit(0)     # don't run pep8 on pypy
    if sys.version_info > (3, 3):
        run(coverage=True, show_leaks=2)
    else:
        run()

########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
import sys
import os
from datetime import date
os.environ['BUILDING-PULSAR-DOCS'] = 'yes'
p = lambda x : os.path.split(x)[0]
source_dir = p(os.path.abspath(__file__))
ext_dir = os.path.join(source_dir,'_ext')
docs_dir = p(source_dir)
base_dir = p(docs_dir)
#sys.path.append(os.path.join(source_dir, "_ext"))
sys.path.insert(0, base_dir)
sys.path.insert(0, ext_dir)
import pulsar
import runtests # so that it import stdnet if available

year = date.today().year
version = pulsar.__version__
release = version

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

extensions = ['sphinx.ext.autodoc',
              'sphinx.ext.coverage',
              'sphinx.ext.extlinks',
              'sphinx.ext.intersphinx',
              'sphinx.ext.viewcode',
              'pulsarext',
              'redisext']

# Beta version is published in github pages
if pulsar.VERSION[3] == 'beta':
    extensions.append('sphinxtogithub')
html_context = {'release_version': pulsar.VERSION[3] == 'final'}
# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = 'pulsar'
copyright = '2011-%s, %s' % (year, pulsar.__author__)

html_theme = 'pulsar'
pygments_style = 'sphinx'
templates_path = ['_templates']
html_static_path = ['_static']
html_theme_path = ["_theme"]
exclude_trees = ['_build']
html_sidebars = {
    'index': ['sidebarlogo.html', 'sidebarintro.html',
              'sourcelink.html', 'searchbox.html'],
    '**': ['sidebarlogo.html', 'localtoc.html', 'relations.html',
           'sourcelink.html', 'searchbox.html'],
}
exclude_trees = []
html_additional_pages = {
#    'index': 'index.html',
}

# -- Options for HTML output ---------------------------------------------------


# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
html_favicon = 'favicon.ico'

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'pulsardoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'pulsar.tex', 'Pulsar Documentation',
   'Luca Sbardella', 'manual'),
]

intersphinx_mapping = {
    'python': ('http://python.readthedocs.org/en/latest/', None),
}

########NEW FILE########
__FILENAME__ = pulsarext
'''Sphinx extension for displaying Setting information
'''
from inspect import isfunction

from sphinx.util.compat import Directive
from docutils import nodes, statemachine

from pulsar.utils.config import ordered_settings, section_docs
import pulsar.apps.wsgi
import pulsar.apps.tasks
import pulsar.apps.test

targetid = "pulsar_settings"


class pulsar_settings(nodes.General, nodes.Element):
    pass


class PulsarSettings(Directive):
    has_content = False
    required_arguments = 0

    def sections(self):
        sec = {}
        sections = []
        for sett in ordered_settings():
            s = sett.section
            if s not in sec:
                sections.append(s)
                sec[s] = [sett]
            else:
                sec[s].append(sett)
        for s in sections:
            yield s, sec[s]

    def text(self):
        for section, settings in self.sections():
            if section is None:
                continue
            s = section.lower().replace(' ', '-')
            yield '.. _setting-section-{0}:\n\n\
{1}\n=====================================\n\n'.format(s, section)
            section_doc = section_docs.get(section)
            if section_doc:
                yield section_doc
                yield '\n'
            for sett in settings:
                desc = sett.desc.strip()
                yield '.. _setting-{0}:\n\n\
{0}\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n'.format(sett.name)
                if sett.app:
                    yield '*Application namespace*: ``%s``\n' % sett.app
                yield '*Config name*: ``%s``\n' % sett.name
                if sett.flags:
                    yield '*Command line*: %s\n' %\
                                ', '.join('``%s``' % f for f in sett.flags)
                if isfunction(sett.default):
                    default = ':func:`%s`' % sett.default.__name__
                else:
                    default = '``%r``' % sett.default
                yield '*Default*: %s\n' % default
                yield desc + '\n'

    def run(self):
        env = self.state.document.settings.env
        rawdocs = '\n'.join(self.text())

        source = self.state_machine.input_lines.source(
            self.lineno - self.state_machine.input_offset - 1)

        encoding = self.options.get(
            'encoding', self.state.document.settings.input_encoding)
        tab_width = self.options.get(
            'tab-width', self.state.document.settings.tab_width)


        if 'literal' in self.options:
            # Convert tabs to spaces, if `tab_width` is positive.
            if tab_width >= 0:
                text = rawtext.expandtabs(tab_width)
            else:
                text = rawtext
            literal_block = nodes.literal_block(rawtext, text, source=path)
            literal_block.line = 1
            return [literal_block]
        else:
            include_lines = statemachine.string2lines(
                rawdocs, tab_width, convert_whitespace=1)
            self.state_machine.insert_input(include_lines, targetid)
            return []


def setup(app):
    app.add_directive(targetid, PulsarSettings)

########NEW FILE########
__FILENAME__ = redisext
'''Sphinx extension for displaying Setting information
'''
from inspect import isfunction

from sphinx.util.compat import Directive
from docutils import nodes, statemachine

from pulsar.apps.ds import COMMANDS_INFO
from pulsar.utils.structures import OrderedDict

targetid = "redis_commands"


class redis_commands(nodes.General, nodes.Element):
    pass


class RedisCommands(Directive):
    has_content = False
    required_arguments = 0

    def sections(self):
        sec = {}
        unsupported = []
        sections = OrderedDict()
        for info in COMMANDS_INFO.values():
            if info.group not in sections:
                sections[info.group] = []
            group = sections[info.group]
            if info.supported:
                group.append(info)
            else:
                unsupported.append(info)
        return unsupported, sections

    def text(self):
        unsupported, sections = self.sections()
        if unsupported:
            yield '**Commands not yet supported**: %s' % self.links(unsupported)
            yield '\n'
        for section, commands in sections.items():
            s = section.lower().replace(' ', '-')
            yield ('.. _redis-{0}:\n\n''{1}\n'
                   '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n\n').format(s, section)
            yield self.links(commands)
            yield '\n'

    def links(self, commands):
        return ', '.join(('`%s <%s>`_' % (command.name, command.url) for
                          command in sorted(commands, key=lambda x: x.name)))

    def run(self):
        env = self.state.document.settings.env
        rawdocs = '\n'.join(self.text())

        source = self.state_machine.input_lines.source(
            self.lineno - self.state_machine.input_offset - 1)

        encoding = self.options.get(
            'encoding', self.state.document.settings.input_encoding)
        tab_width = self.options.get(
            'tab-width', self.state.document.settings.tab_width)


        if 'literal' in self.options:
            # Convert tabs to spaces, if `tab_width` is positive.
            if tab_width >= 0:
                text = rawtext.expandtabs(tab_width)
            else:
                text = rawtext
            literal_block = nodes.literal_block(rawtext, text, source=path)
            literal_block.line = 1
            return [literal_block]
        else:
            include_lines = statemachine.string2lines(
                rawdocs, tab_width, convert_whitespace=1)
            self.state_machine.insert_input(include_lines, targetid)
            return []


def setup(app):
    app.add_directive(targetid, RedisCommands)

########NEW FILE########
__FILENAME__ = sphinxtogithub
#! /usr/bin/env python 
from optparse import OptionParser
import os
import sys
import shutil


class NoDirectoriesError(Exception):
    "Error thrown when no directories starting with an underscore are found"


class DirHelper(object):

    def __init__(self, is_dir, list_dir, walk, rmtree):
        self.is_dir = is_dir
        self.list_dir = list_dir
        self.walk = walk
        self.rmtree = rmtree


class FileSystemHelper(object):

    def __init__(self, open_, path_join, move, exists):
        self.open_ = open_
        self.path_join = path_join
        self.move = move
        self.exists = exists


class Replacer(object):
    "Encapsulates a simple text replace"

    def __init__(self, from_, to):
        self.from_ = from_
        self.to = to

    def process(self, text):

        return text.replace( self.from_, self.to )


class FileHandler(object):
    "Applies a series of replacements the contents of a file inplace"

    def __init__(self, name, replacers, opener):
        self.name = name
        self.replacers = replacers
        self.opener = opener

    def process(self):
        text = self.opener(self.name).read()
        for replacer in self.replacers:
            text = replacer.process( text )

        self.opener(self.name, "w").write(text)


class Remover(object):

    def __init__(self, exists, remove):
        self.exists = exists
        self.remove = remove

    def __call__(self, name):
        if self.exists(name):
            self.remove(name)


class ForceRename(object):

    def __init__(self, renamer, remove):
        self.renamer = renamer
        self.remove = remove

    def __call__(self, from_, to):
        self.remove(to)
        self.renamer(from_, to)
        
        
class VerboseRename(object):

    def __init__(self, renamer, stream):
        self.renamer = renamer
        self.stream = stream

    def __call__(self, from_, to):
        self.stream.write(
                "Renaming directory '%s' -> '%s'\n"
                    % (os.path.basename(from_), os.path.basename(to))
                )

        self.renamer(from_, to)


class DirectoryHandler(object):
    "Encapsulates renaming a directory by removing its first character"

    def __init__(self, name, root, renamer):
        self.name = name
        self.new_name = name[1:]
        self.root = root + os.sep
        self.renamer = renamer

    def path(self):
        return os.path.join(self.root, self.name)

    def relative_path(self, directory, filename):
        path = directory.replace(self.root, "", 1)
        return os.path.join(path, filename)

    def new_relative_path(self, directory, filename):
        path = self.relative_path(directory, filename)
        return path.replace(self.name, self.new_name, 1)

    def process(self):
        from_ = os.path.join(self.root, self.name)
        to = os.path.join(self.root, self.new_name)
        self.renamer(from_, to)


class HandlerFactory(object):

    def create_file_handler(self, name, replacers, opener):
        return FileHandler(name, replacers, opener)

    def create_dir_handler(self, name, root, renamer):
        return DirectoryHandler(name, root, renamer)


class OperationsFactory(object):

    def create_force_rename(self, renamer, remover):
        return ForceRename(renamer, remover)

    def create_verbose_rename(self, renamer, stream):

        return VerboseRename(renamer, stream)

    def create_replacer(self, from_, to):

        return Replacer(from_, to)

    def create_remover(self, exists, remove):

        return Remover(exists, remove)


class Layout(object):
    """
    Applies a set of operations which result in the layout
    of a directory changing
    """

    def __init__(self, directory_handlers, file_handlers):
        self.directory_handlers = directory_handlers
        self.file_handlers = file_handlers

    def process(self):
        for handler in self.file_handlers:
            handler.process()

        for handler in self.directory_handlers:
            handler.process()


class LayoutFactory(object):
    "Creates a layout object"

    def __init__(self, operations_factory, handler_factory, file_helper,
                 dir_helper, verbose, stream, force):
        self.operations_factory = operations_factory
        self.handler_factory = handler_factory
        self.file_helper = file_helper
        self.dir_helper = dir_helper
        self.verbose = verbose
        self.output_stream = stream
        self.force = force

    def create_layout(self, path):
        contents = self.dir_helper.list_dir(path)

        renamer = self.file_helper.move

        if self.force:
            remove = self.operations_factory.create_remover(self.file_helper.exists, self.dir_helper.rmtree)
            renamer = self.operations_factory.create_force_rename(renamer, remove) 

        if self.verbose:
            renamer = self.operations_factory.create_verbose_rename(renamer, self.output_stream) 

        # Build list of directories to process
        directories = [d for d in contents if self.is_underscore_dir(path, d)]
        underscore_directories = [
                self.handler_factory.create_dir_handler(d, path, renamer)
                    for d in directories
                ]

        if not underscore_directories:
            raise NoDirectoriesError()

        # Build list of files that are in those directories
        replacers = []
        for handler in underscore_directories:
            for directory, dirs, files in self.dir_helper.walk(handler.path()):
                for f in files:
                    replacers.append(
                            self.operations_factory.create_replacer(
                                handler.relative_path(directory, f),
                                handler.new_relative_path(directory, f)
                                )
                            )

        # Build list of handlers to process all files
        filelist = []
        for root, dirs, files in self.dir_helper.walk(path):
            for f in files:
                if f.endswith(".html"):
                    filelist.append(
                            self.handler_factory.create_file_handler(
                                self.file_helper.path_join(root, f),
                                replacers,
                                self.file_helper.open_)
                            )
                if f.endswith(".js"):
                    filelist.append(
                            self.handler_factory.create_file_handler(
                                self.file_helper.path_join(root, f),
                                [self.operations_factory.create_replacer("'_sources/'", "'sources/'")],
                                self.file_helper.open_
                                )
                            )

        return Layout(underscore_directories, filelist)

    def is_underscore_dir(self, path, directory):

        return (self.dir_helper.is_dir(self.file_helper.path_join(path, directory))
            and directory.startswith("_"))



def sphinx_extension(app, exception):
    "Wrapped up as a Sphinx Extension"
    if not app.builder.name in ("html", "dirhtml"):
        return

    if not app.config.sphinx_to_github:
        if app.config.sphinx_to_github_verbose:
            print("Sphinx-to-github: Disabled, doing nothing.")
        return

    if exception:
        if app.config.sphinx_to_github_verbose:
            print("Sphinx-to-github: Exception raised in main build, doing nothing.")
        return

    dir_helper = DirHelper(
            os.path.isdir,
            os.listdir,
            os.walk,
            shutil.rmtree
            )

    file_helper = FileSystemHelper(
            open,
            os.path.join,
            shutil.move,
            os.path.exists
            )
    
    operations_factory = OperationsFactory()
    handler_factory = HandlerFactory()

    layout_factory = LayoutFactory(
            operations_factory,
            handler_factory,
            file_helper,
            dir_helper,
            app.config.sphinx_to_github_verbose,
            sys.stdout,
            force=True
            )

    layout = layout_factory.create_layout(app.outdir)
    layout.process()


def setup(app):
    "Setup function for Sphinx Extension"
    app.add_config_value("sphinx_to_github", True, '')
    app.add_config_value("sphinx_to_github_verbose", True, '')
    app.connect("build-finished", sphinx_extension)



########NEW FILE########
__FILENAME__ = manage
'''\
This is a a :ref:`JSON-RPC <apps-rpc>` server with some simple functions.
To run the server type::

    python manage.py

Open a new shell and launch python and type::

    >>> from pulsar.apps import rpc
    >>> p = rpc.JsonProxy('http://localhost:8060')
    >>> p.ping()
    'pong'
    >>> p.functions_list()
    [[...
    >>> p.calc.add(3,4)
    7.0

Implementation
-----------------

The calculator rpc functions are implemented by the :class:`Calculator`
handler, while the :class:`Root` handler exposes utility methods from
the :class:`.PulsarServerCommands` handler.

.. autoclass:: Calculator
   :members:
   :member-order: bysource

.. autoclass:: Root
   :members:
   :member-order: bysource

.. autoclass:: Site
   :members:
   :member-order: bysource

'''
try:
    import pulsar
except ImportError:  # pragma nocover
    import sys
    sys.path.append('../../')

from random import normalvariate

from pulsar import coroutine_return
from pulsar.apps import rpc, wsgi
from pulsar.utils.httpurl import JSON_CONTENT_TYPES
from pulsar.utils.pep import range


def divide(request, a, b):
    '''Divide two numbers.

    This method illustrate how to use the :func:`.rpc_method` decorator.'''
    return float(a)/float(b)


def request_handler(request, format, kwargs):
    '''Dummy request handler for test coverage
    '''
    return kwargs


def randompaths(request, num_paths=1, size=250, mu=0, sigma=1):
    '''Lists of random walks.'''
    r = []
    for p in range(num_paths):
        v = 0
        path = [v]
        r.append(path)
        for t in range(size):
            v += normalvariate(mu, sigma)
            path.append(v)
    return r


class RequestCheck:

    def __call__(self, request, name):
        data = yield request.body_data()
        assert(data['method'] == name)
        coroutine_return(True)


class Root(rpc.PulsarServerCommands):
    '''Add two rpc methods for testing to the :class:`.PulsarServerCommands`
    handler.
    '''
    def rpc_dodgy_method(self, request):
        '''This method will fails because the return object is not
        json serializable.'''
        return Calculator

    rpc_check_request = RequestCheck()


class Calculator(rpc.JSONRPC):
    '''A :class:`.JSONRPC` handler which implements few simple
    remote methods.
    '''
    def rpc_add(self, request, a, b):
        '''Add two numbers'''
        return float(a) + float(b)

    def rpc_subtract(self, request, a, b):
        '''Subtract two numbers'''
        return float(a) - float(b)

    def rpc_multiply(self, request, a, b):
        '''Multiply two numbers'''
        return float(a) * float(b)

    rpc_divide = rpc.rpc_method(divide, request_handler=request_handler)
    rpc_randompaths = rpc.rpc_method(randompaths)


class Site(wsgi.LazyWsgi):
    '''WSGI handler for the RPC server'''
    def setup(self, environ):
        '''Called once to setup the list of wsgi middleware.'''
        json_handler = Root().putSubHandler('calc', Calculator())
        middleware = wsgi.Router('/', post=json_handler,
                                 accept_content_types=JSON_CONTENT_TYPES)
        response = [wsgi.GZipMiddleware(200)]
        return wsgi.WsgiHandler(middleware=[middleware],
                                response_middleware=response)


def server(callable=None, **params):
    return wsgi.WSGIServer(Site(), **params)


if __name__ == '__main__':  # pragma nocover
    server().start()

########NEW FILE########
__FILENAME__ = tests
'''Tests the RPC "calculator" example.'''
import unittest

from pulsar import send, new_event_loop, coroutine_return
from pulsar.apps import rpc
from pulsar.apps.test import dont_run_with_thread

from .manage import server, Root, Calculator


class TestRpcOnThread(unittest.TestCase):
    app_cfg = None
    concurrency = 'thread'
    # used for both keep-alive and timeout in JsonProxy
    # long enough to allow to wait for tasks
    rpc_timeout = 500

    @classmethod
    def setUpClass(cls):
        name = 'calc_' + cls.concurrency
        s = server(bind='127.0.0.1:0', name=name, concurrency=cls.concurrency)
        cls.app_cfg = yield send('arbiter', 'run', s)
        cls.uri = 'http://{0}:{1}'.format(*cls.app_cfg.addresses[0])
        cls.p = rpc.JsonProxy(cls.uri, timeout=cls.rpc_timeout)
        cls.sync = rpc.JsonProxy(cls.uri, loop=new_event_loop())

    @classmethod
    def tearDownClass(cls):
        if cls.app_cfg:
            return send('arbiter', 'kill_actor', cls.app_cfg.name)

    def setUp(self):
        self.assertEqual(self.p.url, self.uri)
        self.assertTrue(str(self.p))
        proxy = self.p.bla
        self.assertEqual(proxy.name, 'bla')
        self.assertEqual(proxy.url, self.uri)
        self.assertEqual(proxy._client, self.p)
        self.assertEqual(str(proxy), 'bla')

    def test_wsgi_handler(self):
        cfg = self.app_cfg
        self.assertTrue(cfg.callable)
        wsgi_handler = cfg.callable.handler({})
        self.assertEqual(len(wsgi_handler.middleware), 1)
        router = wsgi_handler.middleware[0]
        self.assertEqual(router.route.path, '/')
        root = router.post
        self.assertEqual(len(root.subHandlers), 1)
        hnd = root.subHandlers['calc']
        self.assertFalse(hnd.isroot())
        self.assertEqual(hnd.subHandlers, {})

    # Pulsar server commands
    def test_ping(self):
        response = yield self.p.ping()
        self.assertEqual(response, 'pong')

    def test_functions_list(self):
        result = yield self.p.functions_list()
        self.assertTrue(result)
        d = dict(result)
        self.assertTrue('ping' in d)
        self.assertTrue('echo' in d)
        self.assertTrue('functions_list' in d)
        self.assertTrue('calc.add' in d)
        self.assertTrue('calc.divide' in d)

    def test_time_it(self):
        '''Ping server 5 times'''
        bench = yield self.p.timeit('ping', 5)
        self.assertTrue(len(bench.result), 5)
        self.assertTrue(bench.taken)

    # Test Object method
    def test_check_request(self):
        result = yield self.p.check_request('check_request')
        self.assertTrue(result)

    def test_add(self):
        response = yield self.p.calc.add(3, 7)
        self.assertEqual(response, 10)

    def test_subtract(self):
        response = yield self.p.calc.subtract(546, 46)
        self.assertEqual(response, 500)

    def test_multiply(self):
        response = yield self.p.calc.multiply(3, 9)
        self.assertEqual(response, 27)

    def test_divide(self):
        response = yield self.p.calc.divide(50, 25)
        self.assertEqual(response, 2)

    def test_info(self):
        response = yield self.p.server_info()
        self.assertTrue('server' in response)
        server = response['server']
        self.assertTrue('version' in server)
        app = response['monitors'][self.app_cfg.name]
        if self.concurrency == 'thread':
            self.assertFalse(app['workers'])
            worker = app
        else:
            workers = app['workers']
            self.assertEqual(len(workers), 1)
            worker = workers[0]
        name = '%sserver' % self.app_cfg.name
        if name in worker:
            self._check_tcpserver(worker[name]['server'])

    def _check_tcpserver(self, server):
        sockets = server['sockets']
        if sockets:
            self.assertEqual(len(sockets), 1)
            sock = sockets[0]
            self.assertEqual(sock['address'],
                             '%s:%s' % self.app_cfg.addresses[0])

    def test_invalid_params(self):
        self.async.assertRaises(rpc.InvalidParams, self.p.calc.add, 50, 25, 67)

    def test_invalid_params_fromApi(self):
        self.async.assertRaises(rpc.InvalidParams, self.p.calc.divide,
                                50, 25, 67)

    def test_invalid_function(self):
        p = self.p
        yield self.async.assertRaises(rpc.NoSuchFunction, p.foo, 'ciao')
        yield self.async.assertRaises(rpc.NoSuchFunction,
                                      p.blabla)
        yield self.async.assertRaises(rpc.NoSuchFunction,
                                      p.blabla.foofoo)
        yield self.async.assertRaises(rpc.NoSuchFunction,
                                      p.blabla.foofoo.sjdcbjcb)

    def testInternalError(self):
        self.async.assertRaises(rpc.InternalError, self.p.calc.divide,
                                'ciao', 'bo')

    def testCouldNotserialize(self):
        self.async.assertRaises(rpc.InternalError, self.p.dodgy_method)

    def testpaths(self):
        '''Fetch a sizable ammount of data'''
        response = yield self.p.calc.randompaths(num_paths=20, size=100,
                                                 mu=1, sigma=2)
        self.assertTrue(response)

    def test_echo(self):
        response = yield self.p.echo('testing echo')
        self.assertEqual(response, 'testing echo')

    # Synchronous client
    def test_sync_ping(self):
        self.assertEqual(self.sync.ping(), 'pong')
        self.assertEqual(self.sync.ping(), 'pong')

    def test_docs(self):
        handler = Root({'calc': Calculator})
        self.assertEqual(handler.parent, None)
        self.assertEqual(handler.root, handler)
        self.assertRaises(rpc.NoSuchFunction, handler.get_handler,
                          'cdscsdcscd')
        calc = handler.subHandlers['calc']
        self.assertEqual(calc.parent, handler)
        self.assertEqual(calc.root, handler)
        docs = handler.docs()
        self.assertTrue(docs)
        response = yield self.p.documentation()
        self.assertEqual(response, docs)


@dont_run_with_thread
class TestRpcOnProcess(TestRpcOnThread):
    concurrency = 'process'

########NEW FILE########
__FILENAME__ = manage
'''This example is web-based chat application which exposes three different
:ref:`wsgi routers <wsgi-routing>`:

* A :class:`.Router` to render the web page
* A :class:`.WebSocket` with the :class:`Chat` handler
* A :class:`.Router` with the :class:`Rpc` handler
  for exposing a :ref:`JSON-RPC <apps-rpc>` api.

To run the server::

    python manage.py

and open web browsers at http://localhost:8060

To send messages from the JSON RPC open a python shell and::

    >>> from pulsar.apps import rpc
    >>> p = rpc.JsonProxy('http://127.0.0.1:8060/rpc')
    >>> p.message('Hi from rpc')
    'OK'

This example uses the pulsar :ref:`Publish/Subscribe handler <apps-pubsub>`
to synchronise messages in a multiprocessing web server.

Implementation
===========================

.. autoclass:: Chat
   :members:
   :member-order: bysource

.. autoclass:: Rpc
   :members:
   :member-order: bysource

.. autoclass:: WebChat
   :members:
   :member-order: bysource
'''
import os
import sys
import time
try:
    import pulsar
except ImportError:  # pragma nocover
    sys.path.append('../../')

from pulsar import get_actor
from pulsar.apps.wsgi import Router, WsgiHandler, LazyWsgi, WSGIServer
from pulsar.apps.ws import WS, WebSocket
from pulsar.apps.rpc import PulsarServerCommands
from pulsar.apps.data import create_store, PubSubClient
from pulsar.apps.ds import pulsards_url
from pulsar.utils.system import json
from pulsar.utils.pep import to_string

CHAT_DIR = os.path.dirname(__file__)


class ChatClient(PubSubClient):
    __slots__ = ('connection', 'channel')

    def __init__(self, connection, channel):
        self.connection = connection
        self.channel = channel

    def __call__(self, channel, message):
        self.connection.write(message)


class Protocol:

    def encode(self, message):
        '''Encode a message when publishing.'''
        if not isinstance(message, dict):
            message = {'message': message}
        message['time'] = time.time()
        return json.dumps(message)

    def decode(self, message):
        return to_string(message)


#    Web Socket Chat handler
class Chat(WS):
    '''The websocket handler (:class:`.WS`) managing the chat application.

    .. attribute:: pubsub

        The :ref:`publish/subscribe handler <apps-pubsub>` created by the wsgi
        application in the :meth:`WebChat.setup` method.
    '''
    def __init__(self, pubsub, channel):
        self.pubsub = pubsub
        self.channel = channel

    def on_open(self, websocket):
        '''When a new websocket connection is established it creates a
        new :class:`ChatClient` and adds it to the set of clients of the
        :attr:`pubsub` handler.'''
        self.pubsub.add_client(ChatClient(websocket, self.channel))

    def on_message(self, websocket, msg):
        '''When a new message arrives, it publishes to all listening clients.
        '''
        if msg:
            lines = []
            for l in msg.split('\n'):
                l = l.strip()
                if l:
                    lines.append(l)
            msg = ' '.join(lines)
            if msg:
                self.pubsub.publish(self.channel, msg)


#    RPC MIDDLEWARE To publish messages
class Rpc(PulsarServerCommands):

    def __init__(self, pubsub, channel, **kwargs):
        self.pubsub = pubsub
        self.channel = channel
        super(Rpc, self).__init__(**kwargs)

    def rpc_message(self, request, message):
        '''Publish a message via JSON-RPC'''
        self.pubsub.publish(self.channel, message)
        return 'OK'


class WebChat(LazyWsgi):
    '''This is the :ref:`wsgi application <wsgi-handlers>` for this
    web-chat example.'''
    def __init__(self, server_name):
        self.name = server_name

    def setup(self, environ):
        '''Called once only to setup the WSGI application handler.

        Check :ref:`lazy wsgi handler <wsgi-lazy-handler>`
        section for further information.
        '''
        cfg = environ['pulsar.cfg']
        loop = environ['pulsar.connection']._loop
        self.store = create_store(cfg.data_store, loop=loop)
        pubsub = self.store.pubsub(protocol=Protocol())
        channel = '%s_webchat' % self.name
        pubsub.subscribe(channel)
        return WsgiHandler([Router('/', get=self.home_page),
                            WebSocket('/message', Chat(pubsub, channel)),
                            Router('/rpc', post=Rpc(pubsub, channel))])

    def home_page(self, request):
        data = open(os.path.join(CHAT_DIR, 'chat.html')).read()
        request.response.content_type = 'text/html'
        request.response.content = to_string(data % request.environ)
        return request.response


def server(callable=None, name=None, data_store=None, **params):
    name = name or 'wsgi'
    if not data_store:
        actor = get_actor()
        if actor:
            data_store = actor.cfg.data_store
        data_store = pulsards_url(data_store)
    return WSGIServer(callable=WebChat(name), name=name,
                      data_store=data_store, **params)


if __name__ == '__main__':  # pragma nocover
    server().start()

########NEW FILE########
__FILENAME__ = tests
'''Tests the websocket middleware in pulsar.apps.ws.'''
import unittest
from asyncio import Queue

from pulsar import send
from pulsar.apps import rpc, http, ws
from pulsar.apps.test import dont_run_with_thread
from pulsar.utils.httpurl import HTTPError
from pulsar.utils.system import json

from .manage import server


class Message(ws.WS):

    def __init__(self, loop):
        self.queue = Queue(loop=loop)

    def get(self):
        return self.queue.get()

    def on_message(self, websocket, message):
        self.queue.put_nowait(message)


class TestWebChat(unittest.TestCase):
    app_cfg = None
    concurrency = 'thread'

    @classmethod
    def setUpClass(cls):
        s = server(bind='127.0.0.1:0', name=cls.__name__.lower(),
                   concurrency=cls.concurrency)
        cls.app_cfg = yield send('arbiter', 'run', s)
        cls.uri = 'http://%s:%s' % cls.app_cfg.addresses[0]
        cls.ws = 'ws://%s:%s/message' % cls.app_cfg.addresses[0]
        cls.rpc = rpc.JsonProxy('%s/rpc' % cls.uri)
        cls.http = http.HttpClient()

    @classmethod
    def tearDownClass(cls):
        if cls.app_cfg is not None:
            yield send('arbiter', 'kill_actor', cls.app_cfg.name)

    def test_home(self):
        response = yield self.http.get(self.uri)
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.headers['content-type'],
                         'text/html; charset=utf-8')

    def test_handshake(self):
        ws = yield self.http.get(self.ws)
        response = ws.handshake
        self.assertEqual(ws.status_code, 101)
        self.assertEqual(ws.headers['upgrade'], 'websocket')
        self.assertEqual(response.connection, ws.connection)
        self.assertTrue(ws.connection)
        #
        # The connection should not be in the connection pool
        pool = self.http.connection_pools.get(ws._request.key)
        self.assertIsInstance(pool, self.http.connection_pool)
        self.assertFalse(ws.connection in pool)

    def test_rpc(self):
        '''Send a message to the rpc'''
        loop = self.http._loop
        ws = yield self.http.get(self.ws, websocket_handler=Message(loop))
        self.assertEqual(ws.status_code, 101)
        ws.write('Hello there!')
        data = yield ws.handler.get()
        data = json.loads(data)
        self.assertEqual(data['message'], 'Hello there!')
        result = yield self.rpc.message('Hi!')
        self.assertEqual(result, 'OK')
        data = yield ws.handler.get()
        data = json.loads(data)
        self.assertEqual(data['message'], 'Hi!')

    def test_invalid_method(self):
        p = rpc.JsonProxy(self.uri)
        try:
            yield p.message('ciao')
        except HTTPError as e:
            self.assertEqual(e.code, 405)
        else:
            assert False, '405 not raised'


@dont_run_with_thread
class TestWebChatProcess(TestWebChat):
    concurrency = 'process'

########NEW FILE########
__FILENAME__ = models

########NEW FILE########
__FILENAME__ = settings
# Django settings for djangotest project.
import platform
PRODUCTION_MODE = platform.node().startswith('http')

DEBUG = True
TEMPLATE_DEBUG = DEBUG

ADMINS = (
    ('lsbardel', 'luca.sbardella@gmail.com'),
)

MANAGERS = ADMINS

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': 'test.db',
    }
}

TIME_ZONE = 'America/Chicago'

LANGUAGE_CODE = 'en-us'

SITE_ID = 1

USE_I18N = True

USE_L10N = True

MEDIA_ROOT = ''

MEDIA_URL = ''

STATIC_ROOT = ''

STATIC_URL = '/static/'

ADMIN_MEDIA_PREFIX = '/static/admin/'

STATICFILES_DIRS = (
)

STATICFILES_FINDERS = (
    'django.contrib.staticfiles.finders.FileSystemFinder',
    'django.contrib.staticfiles.finders.AppDirectoriesFinder',
)

SECRET_KEY = 'c-u@jrg$dy)g7%)=jg)c40d0)4z0b%mltvtu)85l1&*(zwau(f'

TEMPLATE_LOADERS = (
    'django.template.loaders.filesystem.Loader',
    'django.template.loaders.app_directories.Loader',
)

MIDDLEWARE_CLASSES = (
    'django.middleware.common.CommonMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'chat.views.middleware'
)

TEMPLATE_CONTEXT_PROCESSORS = (
    'django.core.context_processors.debug',
    'django.core.context_processors.i18n',
    'django.core.context_processors.media',
    'django.core.context_processors.static',
    'django.contrib.auth.context_processors.auth',
    'django.contrib.messages.context_processors.messages',
)

FILE_UPLOAD_HANDLERS = (
    "django.core.files.uploadhandler.TemporaryFileUploadHandler",
)

ROOT_URLCONF = 'chat.urls'

TEMPLATE_DIRS = ()

INSTALLED_APPS = (
    'django.contrib.auth',
    'django.contrib.admin',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.sites',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    'pulsar.apps.pulse',
    'chat',
)

LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'filters': {
        'require_debug_false': {
            '()': 'django.utils.log.RequireDebugFalse'
        }
    },
    'handlers': {
        'mail_admins': {
            'level': 'ERROR',
            'filters': ['require_debug_false'],
            'class': 'django.utils.log.AdminEmailHandler'
        }
    },
    'loggers': {
        'django.request': {
            'handlers': ['mail_admins'],
            'level': 'ERROR',
            'propagate': True,
        },
    }
}

########NEW FILE########
__FILENAME__ = urls
from django.conf.urls import patterns, url, include
from django.contrib import admin
from django.contrib.staticfiles.urls import staticfiles_urlpatterns


admin.autodiscover()


urlpatterns = patterns(
    '',
    url(r'^$', 'chat.views.home'),
    url(r'^admin/', include(admin.site.urls))
)


urlpatterns += staticfiles_urlpatterns()

########NEW FILE########
__FILENAME__ = views
import time

from pulsar import HttpException
from pulsar.apps import ws
from pulsar.apps.data import PubSubClient, create_store
from pulsar.utils.system import json
from pulsar.utils.security import random_string


def home(request):
    from django.shortcuts import render_to_response
    from django.template import RequestContext
    return render_to_response('home.html', {
        'HOST': request.get_host()
        }, RequestContext(request))


class ChatClient(PubSubClient):

    def __init__(self, websocket):
        self.joined = time.time()
        self.websocket = websocket

    def __call__(self, channel, message):
        # The message is an encoded JSON string
        self.websocket.write(message, opcode=1)


class Chat(ws.WS):
    ''':class:`.WS` handler managing the chat application.'''
    _store = None
    _pubsub = None
    _client = None

    def get_pubsub(self, websocket):
        '''Create the pubsub handler if not already available'''
        if not self._store:
            cfg = websocket.cfg
            self._store = create_store(cfg.data_store)
            self._client = self._store.client()
            self._pubsub = self._store.pubsub()
            webchat = '%s:webchat' % cfg.exc_id
            chatuser = '%s:chatuser' % cfg.exc_id
            self._pubsub.subscribe(webchat, chatuser)
        return self._pubsub

    def on_open(self, websocket):
        '''A new websocket connection is established.

        Add it to the set of clients listening for messages.
        '''
        self.get_pubsub(websocket).add_client(ChatClient(websocket))
        user, _ = self.user(websocket)
        users_key = 'webchatusers:%s' % websocket.cfg.exc_id
        # add counter to users
        registered = yield self._client.hincrby(users_key, user, 1)
        if registered == 1:
            self.publish(websocket, 'chatuser', 'joined')

    def on_close(self, websocket):
        '''Leave the chat room
        '''
        user, _ = self.user(websocket)
        users_key = 'webchatusers:%s' % websocket.cfg.exc_id
        registered = yield self._client.hincrby(users_key, user, -1)
        if not registered:
            self.publish(websocket, 'chatuser', 'gone')
        if registered <= 0:
            self._client.hdel(users_key, user)

    def on_message(self, websocket, msg):
        '''When a new message arrives, it publishes to all listening clients.
        '''
        if msg:
            lines = []
            for l in msg.split('\n'):
                l = l.strip()
                if l:
                    lines.append(l)
            msg = ' '.join(lines)
            if msg:
                self.publish(websocket, 'webchat', msg)

    def user(self, websocket):
        user = websocket.handshake.get('django.user')
        if user.is_authenticated():
            return user.username, True
        else:
            session = websocket.handshake.get('django.session')
            user = session.get('chatuser')
            if not user:
                user = 'an_%s' % random_string(length=6).lower()
                session['chatuser'] = user
            return user, False

    def publish(self, websocket, channel, message=''):
        user, authenticated = self.user(websocket)
        msg = {'message': message,
               'user': user,
               'authenticated': authenticated,
               'channel': channel}
        channel = '%s:%s' % (websocket.cfg.exc_id, channel)
        return self._pubsub.publish(channel, json.dumps(msg))


class middleware(object):
    '''Django middleware for serving the Chat websocket.'''
    def __init__(self):
        self._web_socket = ws.WebSocket('/message', Chat())

    def process_request(self, request):
        from django.http import HttpResponse
        environ = request.META
        environ['django.user'] = request.user
        environ['django.session'] = request.session
        try:
            response = self._web_socket(environ)
        except HttpException as e:
            return HttpResponse(status=e.status)
        if response is not None:
            # we have a response, this is the websocket upgrade.
            # Convert to django response
            resp = HttpResponse(status=response.status_code,
                                content_type=response.content_type)
            for header, value in response.headers:
                resp[header] = value
            return resp
        else:
            environ.pop('django.user')
            environ.pop('django.session')

########NEW FILE########
__FILENAME__ = config
# Config file for pulsar server

# set the datastore for the pubsub
data_store = 'pulsar://127.0.0.1:6410/1'
# data_store = 'redis://127.0.0.1:6379/1'

########NEW FILE########
__FILENAME__ = manage
#!/usr/bin/env python
'''This is a web chat application which illustrates how to run a django
site with pulsar and how to include pulsar asynchronous request middlewares
into django.
Requires django 1.4 or above. To run::

    python manage.py pulse

If running for the first time, issue the::

    python manage.py syncdb

command and create the super user.

This example uses the :ref:`django pulse <apps-pulse>` application.

Message and data backend
============================

By default, messages from connected (websocket) clients are synchronised via
the :ref:`pulsar data store <pulsar-data-store>` which starts when the django
site starts. It is possible to specify a different data store via the
:ref:`data-store option <setting-data_store>`.

For example, it is possible to use redis_ as an alternative data store
simply by issuing the following start up command::

    python manage.py pulse --data-store redis://127.0.0.1:6379/3


Views and Middleware
==========================

Check the :mod:`examples.djangoapp.chat.settings` module to see how this
classes are used.

.. automodule:: examples.djangoapp.chat.views
   :members:
   :member-order: bysource


.. _redis: http://redis.io/
'''
import os
try:
    import pulsar
except ImportError:     # pragma nocover
    import sys
    sys.path.append('../../')

os.environ["DJANGO_SETTINGS_MODULE"] = "chat.settings"
from django.core.management import execute_from_command_line


if __name__ == "__main__":
    execute_from_command_line()

########NEW FILE########
__FILENAME__ = app
'''Tests django chat application.'''
import unittest
from asyncio import Queue

from pulsar import send, get_application, coroutine_return
from pulsar.utils.path import Path
from pulsar.apps import http, ws
from pulsar.apps.test import dont_run_with_thread
from pulsar.utils.security import gen_unique_id
from pulsar.utils.system import json

try:
    manage = Path(__file__).add2python('manage', up=1)
except ImportError:
    manage = None


def start_server(actor, name, argv):
    manage.execute_from_command_line(argv)
    app = yield get_application(name)
    coroutine_return(app.cfg)


class MessageHandler(ws.WS):

    def __init__(self):
        self.queue = Queue()

    def get(self):
        return self.queue.get()

    def on_message(self, websocket, message):
        return self.queue.put(message)


@unittest.skipUnless(manage, 'Requires django')
class TestDjangoChat(unittest.TestCase):
    concurrency = 'thread'
    app_cfg = None

    @classmethod
    def setUpClass(cls):
        cls.exc_id = gen_unique_id()[:8]
        name = cls.__name__.lower()
        argv = [__file__, 'pulse',
                '--bind', '127.0.0.1:0',
                '--concurrency', cls.concurrency,
                '--exc-id', cls.exc_id,
                '--pulse-app-name', name,
                '--data-store', cls.data_store()]
        cls.app_cfg = yield send('arbiter', 'run', start_server, name, argv)
        assert cls.app_cfg.exc_id == cls.exc_id, "Bad execution id"
        addr = cls.app_cfg.addresses[0]
        cls.uri = 'http://{0}:{1}'.format(*addr)
        cls.ws = 'ws://{0}:{1}/message'.format(*addr)
        cls.http = http.HttpClient()

    @classmethod
    def tearDownClass(cls):
        if cls.app_cfg:
            return send('arbiter', 'kill_actor', cls.app_cfg.name)

    @classmethod
    def data_store(cls):
        return 'pulsar://127.0.0.1:0/8'

    def test_home(self):
        result = yield self.http.get(self.uri)
        self.assertEqual(result.status_code, 200)

    def test_404(self):
        result = yield self.http.get('%s/bsjdhcbjsdh' % self.uri)
        self.assertEqual(result.status_code, 404)

    def test_websocket(self):
        ws = yield self.http.get(self.ws, websocket_handler=MessageHandler())
        response = ws.handshake
        self.assertEqual(response.status_code, 101)
        self.assertEqual(response.headers['upgrade'], 'websocket')
        self.assertEqual(response.connection, ws.connection)
        self.assertTrue(ws.connection)
        self.assertIsInstance(ws.handler, MessageHandler)
        #
        data = yield ws.handler.get()
        data = json.loads(data)
        self.assertEqual(data['message'], 'joined')
        #
        ws.write('Hello there!')
        data = yield ws.handler.get()
        data = json.loads(data)
        self.assertEqual(data['message'], 'Hello there!')


@dont_run_with_thread
class TestDjangoChat_Process(TestDjangoChat):
    concurrency = 'process'

########NEW FILE########
__FILENAME__ = pulse
'''Tests the pulse Command.'''
import unittest

try:
    from pulsar.apps.pulse.management.commands.pulse import Command
except ImportError:
    Command = None
from pulsar.apps import wsgi


@unittest.skipUnless(Command, 'Requires django')
class pulseCommandTest(unittest.TestCase):

    def test_pulse(self):
        cmnd = Command()
        hnd = cmnd.handle(dryrun=True)
        self.assertTrue(isinstance(hnd, wsgi.LazyWsgi))

########NEW FILE########
__FILENAME__ = manage
'''
This example illustrates how to write a simple TCP Echo server and client pair.
The example is simple because the client and server protocols are symmetrical
and therefore the :class:`EchoProtocol` will also be used as based class for
:class:`EchoServerProtocol`.
The code for this example is located in the :mod:`examples.echo.manage`
module.

Run The example
====================

To run the server::

    python manage.py

Open a new shell, in this directory, launch python and type::

    >>> from manage import Echo
    >>> echo = Echo(('localhost',8060))
    >>> echo(b'Hello!')
    b'Hello!'

Writing the Client
=========================
The first step is to write a small class handling a connection
pool with the remote server. The :class:`Echo` class does just that,
it subclass the handy :class:`.AbstractClient` and uses
the asynchronous :class:`.Pool` of connections as backbone.

The second step is the implementation of the :class:`.EchoProtocol`,
a subclass of :class:`.ProtocolConsumer`.
The :class:`EchoProtocol` is needed for two reasons:

* It encodes and sends the request to the remote server via the
  :meth:`~EchoProtocol.start_request` method.
* It listens for incoming data from the remote server via the
  :meth:`~EchoProtocol.data_received` method.



Implementation
==================

Echo Client Protocol
~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: EchoProtocol
   :members:
   :member-order: bysource

Echo Server Protocol
~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: EchoServerProtocol
   :members:
   :member-order: bysource

Echo Client
~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: Echo
   :members:
   :member-order: bysource

   .. automethod:: __call__

Echo Server
~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autofunction:: server

'''
from functools import partial

try:
    import pulsar
except ImportError:     # pragma nocover
    import sys
    sys.path.append('../../')
    import pulsar

from pulsar import coroutine_return, Pool, task, Connection, AbstractClient
from pulsar.apps.socket import SocketServer


class EchoProtocol(pulsar.ProtocolConsumer):
    '''An echo :class:`~.ProtocolConsumer` for client and servers.

    The only difference between client and server is the implementation
    of the :meth:`response` method.
    '''
    separator = b'\r\n\r\n'
    '''A separator for messages.'''
    buffer = b''
    '''The buffer for long messages'''

    def data_received(self, data):
        '''Implements the :meth:`~.ProtocolConsumer.data_received` method.

        It simply search for the :attr:`separator` and, if found, it invokes
        the :meth:`response` method with the value of the message.
        '''
        idx = data.find(self.separator)
        if idx >= 0:    # we have a full message
            idx += len(self.separator)
            data, rest = data[:idx], data[idx:]
            self.buffer = self.response(self.buffer+data)
            self.finished()
            return rest
        else:
            self.buffer = self.buffer + data

    def start_request(self):
        '''Override :meth:`~.ProtocolConsumer.start_request` to write
        the message ended by the :attr:`separator` into the transport.
        '''
        self.transport.write(self._request + self.separator)

    def response(self, data):
        '''Clients return the message so that the
        :attr:`.ProtocolConsumer.on_finished` is called back with the
        message value, while servers sends the message back to the client.
        '''
        return data[:-len(self.separator)]


class EchoServerProtocol(EchoProtocol):
    '''The :class:`EchoProtocol` used by the echo :func:`server`.
    '''
    def response(self, data):
        '''Override :meth:`~EchoProtocol.response` method by writing the
        ``data`` received back to the client.
        '''
        self.transport.write(data)
        data = data[:-len(self.separator)]
        # If we get a QUIT message, close the transport.
        # Used by the test suite.
        if data == b'QUIT':
            self.transport.close()
        return data


class Echo(AbstractClient):
    '''A client for the echo server.

    :param address: set the :attr:`address` attribute
    :param full_response: set the :attr:`full_response` attribute
    :param pool_size: used when initialising the connetion :attr:`pool`.
    :param loop: Optional event loop to set the :attr:`_loop` attribute.

    .. attribute:: _loop

        The event loop used by the client IO requests.

        The event loop is stored at this attribute so that asynchronous
        method decorators such as :func:`.task` can be used.

    .. attribute:: address

        remote server TCP address.

    .. attribute:: pool

        Asynchronous connection :class:`.Pool`.

    .. attribute:: full_response

        Flag indicating if the callable method should return the
        :class:`EchoProtocol` handling the request (``True``) or
        the server response message (``False``).

        Default: ``False``
    '''
    protocol_factory = partial(Connection, EchoProtocol)

    def __init__(self, address, full_response=False, pool_size=10, loop=None):
        super(Echo, self).__init__(loop)
        self.address = address
        self.full_response = full_response
        self.pool = Pool(self.connect, pool_size, self._loop)

    def connect(self):
        return self.create_connection(self.address)

    @task
    def __call__(self, message):
        '''Send a ``message`` to the server and wait for a response.

        :return: a :class:`.Future`
        '''
        connection = yield self.pool.connect()
        with connection:
            consumer = connection.current_consumer()
            consumer.start(message)
            result = yield consumer.on_finished
            result = consumer if self.full_response else consumer.buffer
            coroutine_return(result)


def server(name=None, description=None, **kwargs):
    '''Create the :class:`.SocketServer` with :class:`EchoServerProtocol`
    as protocol factory.
    '''
    name = name or 'echoserver'
    description = description or 'Echo Server'
    return SocketServer(EchoServerProtocol, name=name,
                        description=description, **kwargs)


if __name__ == '__main__':  # pragma nocover
    server().start()

########NEW FILE########
__FILENAME__ = tests
import unittest

from pulsar import send, multi_async, new_event_loop, get_application
from pulsar.utils.pep import range
from pulsar.apps.test import dont_run_with_thread, run_on_arbiter

from .manage import server, Echo, EchoServerProtocol


class TestEchoServerThread(unittest.TestCase):
    concurrency = 'thread'
    server_cfg = None

    @classmethod
    def setUpClass(cls):
        s = server(name=cls.__name__.lower(), bind='127.0.0.1:0',
                   backlog=1024, concurrency=cls.concurrency)
        cls.server_cfg = yield send('arbiter', 'run', s)
        cls.client = Echo(cls.server_cfg.addresses[0])

    @classmethod
    def tearDownClass(cls):
        if cls.server_cfg:
            return send('arbiter', 'kill_actor', cls.server_cfg.name)

    def sync_client(self):
        return Echo(self.server_cfg.addresses[0], loop=new_event_loop())

    #    TEST THE SERVER APPLICATION
    @run_on_arbiter
    def test_server_on_arbiter(self):
        app = yield get_application(self.__class__.__name__.lower())
        cfg = app.cfg
        self.assertTrue(cfg.addresses)
        self.assertTrue(cfg.address)
        self.assertNotEqual(cfg.addresses[0], cfg.address)

    def test_server(self):
        server = self.server_cfg.app()
        self.assertTrue(server)
        self.assertEqual(server.cfg.callable, EchoServerProtocol)
        self.assertTrue(server.cfg.addresses)

    #    TEST CLIENT INTERACTION
    def test_ping(self):
        result = yield self.client(b'ciao luca')
        self.assertEqual(result, b'ciao luca')

    def test_large(self):
        '''Echo a 3MB message'''
        msg = b''.join((b'a' for x in range(2**13)))
        result = yield self.client(msg)
        self.assertEqual(result, msg)

    def test_multi(self):
        result = yield multi_async((self.client(b'ciao'),
                                    self.client(b'pippo'),
                                    self.client(b'foo')))
        self.assertEqual(len(result), 3)
        self.assertTrue(b'ciao' in result)
        self.assertTrue(b'pippo' in result)
        self.assertTrue(b'foo' in result)

    # TESTS FOR PROTOCOLS AND CONNECTIONS
    def test_client(self):
        yield self.test_multi()
        c = self.client
        self.assertTrue(c.pool.available)

    def test_info(self):
        info = yield send(self.server_cfg.name, 'info')
        self.assertIsInstance(info, dict)
        self.assertEqual(info['actor']['name'], self.server_cfg.name)
        self.assertEqual(info['actor']['concurrency'], self.concurrency)

    def test_connection(self):
        client = Echo(self.server_cfg.addresses[0], full_response=True)
        response = yield client(b'test connection')
        self.assertEqual(response.buffer, b'test connection')
        connection = response.connection
        self.assertTrue(str(connection))

    def test_connection_pool(self):
        '''Test the connection pool. A very important test!'''
        client = Echo(self.server_cfg.addresses[0], pool_size=2)
        self.assertEqual(client.pool.pool_size, 2)
        self.assertEqual(client.pool.in_use, 0)
        self.assertEqual(client.pool.available, 0)
        self.assertEqual(client.sessions, 0)
        self.assertEqual(client._requests_processed, 0)
        #
        response = yield client(b'test connection')
        self.assertEqual(response, b'test connection')
        self.assertEqual(client.pool.in_use, 0)
        self.assertEqual(client.pool.available, 1)
        self.assertEqual(client.sessions, 1)
        self.assertEqual(client._requests_processed, 1)
        #
        response = yield client(b'test connection 2')
        self.assertEqual(response, b'test connection 2')
        self.assertEqual(client.pool.in_use, 0)
        self.assertEqual(client.pool.available, 1)
        self.assertEqual(client.sessions, 1)
        self.assertEqual(client._requests_processed, 2)
        #
        result = yield multi_async((client(b'ciao'),
                                    client(b'pippo'),
                                    client(b'foo')))
        self.assertEqual(len(result), 3)
        self.assertTrue(b'ciao' in result)
        self.assertTrue(b'pippo' in result)
        self.assertTrue(b'foo' in result)
        self.assertEqual(client.pool.in_use, 0)
        self.assertEqual(client.pool.available, 2)
        self.assertEqual(client.sessions, 2)
        self.assertEqual(client._requests_processed, 5)
        #
        # drop a connection
        conn1 = client.pool._queue.get_nowait()
        conn1.close()
        conn2 = client.pool._queue.get_nowait()
        client.pool._queue.put_nowait(conn1)
        client.pool._queue.put_nowait(conn2)
        #
        result = yield multi_async((client(b'ciao'),
                                    client(b'pippo'),
                                    client(b'foo')))
        self.assertEqual(len(result), 3)
        self.assertEqual(client.pool.in_use, 0)
        self.assertEqual(client.pool.available, 2)
        self.assertEqual(client.sessions, 3)
        self.assertEqual(client._requests_processed, 8)
        #
        client.pool.close()
        self.assertEqual(client.pool.in_use, 0)
        self.assertEqual(client.pool.available, 0)
        self.assertEqual(client.sessions, 3)
        self.assertEqual(client._requests_processed, 8)

    #    TEST SYNCHRONOUS CLIENT
    def test_sync_echo(self):
        echo = self.sync_client()
        self.assertEqual(echo(b'ciao!'), b'ciao!')
        self.assertEqual(echo(b'fooooooooooooo!'),  b'fooooooooooooo!')

    def __test_sync_close(self):
        # TODO: fix this. Issue #96
        echo = self.sync_client()
        self.assertEqual(echo(b'ciao!'), b'ciao!')
        self.assertEqual(echo.sessions, 1)
        self.assertEqual(echo(b'QUIT'), b'QUIT')
        self.assertEqual(echo.sessions, 1)
        self.assertEqual(echo(b'ciao!'), b'ciao!')
        self.assertEqual(echo.sessions, 2)


@dont_run_with_thread
class TestEchoServerProcess(TestEchoServerThread):
    concurrency = 'process'

########NEW FILE########
__FILENAME__ = manage
'''
This example illustrates how to write a UDP Echo server and client pair.
The code for this example is located in the :mod:`examples.echoudp.manage`
module.

Run The example
====================

To run the server::

    python manage.py

Open a new shell, in this directory, launch python and type::

    >>> from manage import Echo
    >>> echo = Echo(('localhost',8060))
    >>> echo(b'Hello!')
    b'Hello!'

Writing the Client
=========================

The first step is to write a small class handling a connection
pool with the remote server. The :class:`Echo` class does just that,
it subclass the handy :class:`.AbstractUdpClient` and uses
the asynchronous :class:`.Pool` of connections as backbone.

The second step is the implementation of the :class:`EchoUdpProtocol`,
a subclass of :class:`.DatagramProtocol`.
The :class:`EchoUdpProtocol` is needed for two reasons:

* It encodes and sends the request to the remote server
* It listens for incoming data from the remote server via the
  :meth:`~EchoUdpProtocol.datagram_received` method.



Implementation
==================

Echo Udp Protocol
~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: EchoUdpProtocol
   :members:
   :member-order: bysource


Echo Client
~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: Echo
   :members:
   :member-order: bysource

   .. automethod:: __call__

Echo Server
~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autofunction:: server

'''
try:
    import pulsar
except ImportError:     # pragma nocover
    import sys
    sys.path.append('../../')
    import pulsar

from pulsar import coroutine_return, Pool, Future, DatagramProtocol, task
from pulsar.utils.pep import to_bytes
from pulsar.apps.socket import UdpSocketServer


class EchoUdpProtocol(DatagramProtocol):
    '''A base :class:`.DatagramProtocol` for UDP echo clients and servers.

    The only difference between client and server is the implementation
    of the :meth:`response` method.
    '''
    separator = b'\r\n\r\n'
    '''A separator for messages.'''
    buffer = None
    '''The buffer for long messages'''

    def popbuffer(self, addr):
        if self.buffer:
            return self.buffer.pop(addr, None)

    def datagram_received(self, data, addr):
        '''Handle data from ``addr``.
        '''
        while data:
            idx = data.find(self.separator)
            if idx >= 0:    # we have a full message
                idx += len(self.separator)
                chunk, data = data[:idx], data[idx:]
                buffer = self.popbuffer(addr)
                self.response(buffer + chunk if buffer else chunk, addr)
            else:
                if self.buffer is None:
                    self.buffer = {}
                if addr in self.buffer:
                    self.buffer[addr] += data
                else:
                    self.buffer[addr] = data

    def response(self, data, addr):
        '''Abstract response handler'''
        raise NotImplementedError


class EchoUdpClientProtocol(EchoUdpProtocol):
    _waiting = None

    def send(self, message):
        assert self._waiting is None
        self._waiting = d = Future(loop=self._loop)
        self._transport.sendto(to_bytes(message)+self.separator)
        return d

    def response(self, data, addr):
        '''Got a full response'''
        d, self._waiting = self._waiting, None
        if d:
            d.set_result(data[:-len(self.separator)])


class EchoUdpServerProtocol(EchoUdpProtocol):
    '''The :class:`EchoUdpProtocol` used by the echo udp :func:`server`.
    '''
    def response(self, data, addr):
        '''Override :meth:`~EchoProtocol.response` method by writing the
        ``data`` received back to the client.
        '''
        self._transport.sendto(data, addr)


class Echo(pulsar.AbstractUdpClient):
    '''A client for the echo server.

    :param address: set the :attr:`address` attribute
    :param pool_size: used when initialising the connetion :attr:`pool`.
    :param loop: Optional event loop to set the :attr:`_loop` attribute.

    .. attribute:: _loop

        The event loop used by the client IO requests.

        The event loop is stored at this attribute so that asynchronous
        method decorators such as :func:`.task` can be used.

    .. attribute:: address

        remote server UDP address.

    .. attribute:: pool

        Asynchronous client protocol :class:`.Pool`.
    '''
    protocol_factory = EchoUdpClientProtocol

    def __init__(self, address, pool_size=5, loop=None):
        super(Echo, self).__init__(loop)
        self.address = address
        self.pool = Pool(self.create_endpoint, pool_size, self._loop)

    def create_endpoint(self):
        return self.create_datagram_endpoint(remote_addr=self.address)

    @task
    def __call__(self, message):
        '''Send a ``message`` to the server and wait for a response.

        :return: a :class:`.Future`
        '''
        protocol = yield self.pool.connect()
        with protocol:
            result = yield protocol.send(message)
            coroutine_return(result)


def server(name=None, description=None, **kwargs):
    '''Create the :class:`.UdpSocketServer`.
    '''
    name = name or 'echoudpserver'
    description = description or 'Echo Udp Server'
    return UdpSocketServer(EchoUdpServerProtocol, name=name,
                           description=description, **kwargs)


if __name__ == '__main__':  # pragma nocover
    server().start()

########NEW FILE########
__FILENAME__ = tests
import unittest

from pulsar import send, multi_async, new_event_loop, get_application
from pulsar.utils.pep import range
from pulsar.apps.test import dont_run_with_thread, run_on_arbiter

from .manage import server, Echo, EchoUdpServerProtocol


class TestEchoUdpServerThread(unittest.TestCase):
    concurrency = 'thread'
    server_cfg = None

    @classmethod
    def setUpClass(cls):
        s = server(name=cls.__name__.lower(), bind='127.0.0.1:0',
                   concurrency=cls.concurrency)
        cls.server_cfg = yield send('arbiter', 'run', s)
        cls.client = Echo(cls.server_cfg.addresses[0])

    @classmethod
    def tearDownClass(cls):
        if cls.server_cfg:
            return send('arbiter', 'kill_actor', cls.server_cfg.name)

    def sync_client(self):
        return Echo(self.server_cfg.addresses[0], loop=new_event_loop())

    #    TEST THE SERVER APPLICATION
    @run_on_arbiter
    def test_server_on_arbiter(self):
        app = yield get_application(self.__class__.__name__.lower())
        cfg = app.cfg
        self.assertTrue(cfg.addresses)
        self.assertTrue(cfg.address)
        self.assertNotEqual(cfg.addresses[0], cfg.address)

    def test_server(self):
        server = self.server_cfg.app()
        self.assertTrue(server)
        self.assertEqual(server.cfg.callable, EchoUdpServerProtocol)
        self.assertTrue(server.cfg.addresses)

    #    TEST CLIENT INTERACTION
    def test_ping(self):
        result = yield self.client(b'ciao luca')
        self.assertEqual(result, b'ciao luca')

    def test_large(self):
        '''Echo a 3MB message'''
        msg = b''.join((b'a' for x in range(2**13)))
        result = yield self.client(msg)
        self.assertEqual(result, msg)

    #    TEST SYNCHRONOUS CLIENT
    def test_sync_echo(self):
        echo = self.sync_client()
        self.assertEqual(echo(b'ciao!'), b'ciao!')
        self.assertEqual(echo(b'fooooooooooooo!'),  b'fooooooooooooo!')


@dont_run_with_thread
class TestEchoUdpServerProcess(TestEchoUdpServerThread):
    concurrency = 'process'

########NEW FILE########
__FILENAME__ = manage
'''This example is a simple WSGI_ script which displays
the ``Hello World!`` message. To run the script type::

    python manage.py

To see all options available type::

    python manage.py -h

.. autofunction:: hello

.. autofunction:: server

.. _WSGI: http://www.python.org/dev/peps/pep-3333/
'''
try:
    from pulsar import MethodNotAllowed
except ImportError:  # pragma nocover
    import sys
    sys.path.append('../../')
    from pulsar import MethodNotAllowed

from pulsar.apps import wsgi


def hello(environ, start_response):
    '''The WSGI_ application handler which returns an iterable
    over the "Hello World!" message.'''
    if environ['REQUEST_METHOD'] == 'GET':
        data = b'Hello World!\n'
        status = '200 OK'
        response_headers = [
            ('Content-type', 'text/plain'),
            ('Content-Length', str(len(data)))
        ]
        start_response(status, response_headers)
        return iter([data])
    else:
        raise MethodNotAllowed


def server(description=None, **kwargs):
    '''Create the :class:`.WSGIServer` running :func:`hello`.'''
    description = description or 'Pulsar Hello World Application'
    return wsgi.WSGIServer(hello, description=description, **kwargs)


if __name__ == '__main__':  # pragma nocover
    server().start()

########NEW FILE########
__FILENAME__ = tests
'''Tests the "helloworld" example.'''
import unittest

from pulsar import send, SERVER_SOFTWARE, get_application, get_actor
from pulsar.apps.http import HttpClient
from pulsar.apps.test import run_on_arbiter, dont_run_with_thread

from .manage import server


class TestHelloWorldThread(unittest.TestCase):
    app_cfg = None
    concurrency = 'thread'

    @classmethod
    def name(cls):
        return 'helloworld_' + cls.concurrency

    @classmethod
    def setUpClass(cls):
        s = server(name=cls.name(), concurrency=cls.concurrency,
                   bind='127.0.0.1:0')
        cls.app_cfg = yield send('arbiter', 'run', s)
        cls.uri = 'http://{0}:{1}'.format(*cls.app_cfg.addresses[0])
        cls.client = HttpClient()

    @classmethod
    def tearDownClass(cls):
        if cls.app_cfg is not None:
            yield send('arbiter', 'kill_actor', cls.app_cfg.name)

    @run_on_arbiter
    def testMeta(self):
        app = yield get_application(self.name())
        self.assertEqual(app.name, self.name())
        monitor = get_actor().get_actor(app.name)
        self.assertTrue(monitor.is_running())
        self.assertEqual(app, monitor.app)
        self.assertEqual(str(app), app.name)
        self.assertEqual(app.cfg.bind, '127.0.0.1:0')

    def testResponse(self):
        c = self.client
        response = yield c.get(self.uri)
        self.assertEqual(response.status_code, 200)
        content = response.get_content()
        self.assertEqual(content, b'Hello World!\n')
        headers = response.headers
        self.assertTrue(headers)
        self.assertEqual(headers['content-type'], 'text/plain')
        self.assertEqual(headers['server'], SERVER_SOFTWARE)

    def testTimeIt(self):
        c = self.client
        b = yield c.timeit('get', 5, self.uri)
        self.assertTrue(b.taken >= 0)


@dont_run_with_thread
class TestHelloWorldProcess(TestHelloWorldThread):
    concurrency = 'process'

########NEW FILE########
__FILENAME__ = manage
'''Pulsar HTTP test application::

    python manage.py

Implementation
======================

.. autoclass:: HttpBin
   :members:
   :member-order: bysource
'''
import os
import sys
import string
from random import choice, random

try:
    from pulsar.utils.pep import ispy3k, range
except ImportError:     # pragma    nocover
    sys.path.append('../../')
    from pulsar.utils.pep import ispy3k, range

from pulsar import (HttpRedirect, HttpException, version, JAPANESE,
                    coroutine_return)
from pulsar.utils.httpurl import Headers, ENCODE_URL_METHODS
from pulsar.utils.html import escape
from pulsar.apps import wsgi, ws
from pulsar.apps.wsgi import route, Html, Json, HtmlDocument, GZipMiddleware
from pulsar.utils.structures import MultiValueDict
from pulsar.utils.system import json

pyversion = '.'.join(map(str, sys.version_info[:3]))
ASSET_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'assets')
FAVICON = os.path.join(ASSET_DIR, 'favicon.ico')

if ispy3k:  # pragma nocover
    characters = string.ascii_letters + string.digits
else:   # pragma nocover
    characters = string.letters + string.digits


def template():
    name = os.path.join(ASSET_DIR, 'template.html')
    with open(name, 'r') as file:
        return file.read()


class HttpBin(wsgi.Router):

    def bind_server_event(self, request, event, handler):
        consumer = request.environ['pulsar.connection'].current_consumer()
        consumer.bind_event(event, handler)

    def get(self, request):
        '''The home page of this router'''
        ul = Html('ul')
        for router in sorted(self.routes, key=lambda r: r.creation_count):
            a = router.link(escape(router.route.path))
            li = Html('li', a, ' %s' % router.parameters.get('title', ''))
            ul.append(li)
        title = 'Pulsar HttpBin'
        html = request.html_document
        html.head.title = title
        html.head.links.append('/media/httpbin.css')
        html.head.scripts.append('//code.jquery.com/jquery.min.js')
        html.head.scripts.append('/media/httpbin.js')
        ul = ul.render(request)
        body = template() % (title, version, ul, pyversion, JAPANESE)
        html.body.append(body)
        return html.http_response(request)

    @route('get', title='Returns GET data')
    def _get(self, request):
        return self.info_data_response(request)

    @route('post', method='post', title='Returns POST data')
    def _post(self, request):
        return self.info_data_response(request)

    @route('patch', method='patch', title='Returns PATCH data')
    def _patch(self, request):
        return self.info_data_response(request)

    @route('put', method='put', title='Returns PUT data')
    def _put(self, request):
        return self.info_data_response(request)

    @route('delete', method='delete', title='Returns DELETE data')
    def _delete(self, request):
        return self.info_data_response(request)

    @route('redirect/<int(min=1,max=10):times>', defaults={'times': 5},
           title='302 Redirect n times')
    def redirect(self, request):
        num = request.urlargs['times'] - 1
        if num:
            raise HttpRedirect('/redirect/%s' % num)
        else:
            raise HttpRedirect('/get')

    @route('getsize/<int(min=1,max=8388608):size>', defaults={'size': 150000},
           title='Returns a preset size of data (limit at 8MB)')
    def getsize(self, request):
        size = request.urlargs['size']
        data = {'size': size,
                'data': ''.join(('d' for n in range(size)))}
        return self.info_data_response(request, **data)

    @route('gzip', title='Returns gzip encoded data')
    def gzip(self, request):
        response = yield self.info_data_response(request, gzipped=True)
        coroutine_return(GZipMiddleware(10)(request.environ, response))

    @route('cookies', title='Returns cookie data')
    def cookies(self, request):
        response = request.response
        cookies = dict(((c.key, c.value) for c in response.cookies.values()))
        return Json({'cookies': cookies}).http_response(request)

    @route('cookies/set/<name>/<value>', title='Sets a simple cookie',
           defaults={'name': 'package', 'value': 'pulsar'})
    def request_cookies_set(self, request):
        key = request.urlargs['name']
        value = request.urlargs['value']
        request.response.set_cookie(key, value=value)
        request.response.status_code = 302
        request.response.headers['location'] = '/cookies'
        return request.response

    @route('status/<int(min=100,max=505):status>',
           title='Returns given HTTP Status code',
           defaults={'status': 418})
    def status(self, request):
        request.response.content_type = 'text/html'
        raise HttpException(status=request.urlargs['status'])

    @route('response-headers', title='Returns response headers')
    def response_headers(self, request):
        class Gen:
            headers = None

            def __call__(self, server, **kw):
                self.headers = server.headers

            def generate(self):
                # yield a byte so that headers are sent
                yield b''
                # we must have the headers now
                yield json.dumps(dict(self.headers))
        gen = Gen()
        self.bind_server_event(request, 'on_headers', gen)
        request.response.content = gen.generate()
        request.response.content_type = 'application/json'
        return request.response

    @route('basic-auth/<username>/<password>',
           title='Challenges HTTPBasic Auth',
           defaults={'username': 'username', 'password': 'password'})
    def challenge_auth(self, request):
        auth = request.get('http.authorization')
        if auth and auth.authenticated(request.environ, **request.urlargs):
            return Json({'authenticated': True,
                         'username': auth.username}).http_response(request)
        raise wsgi.HttpAuthenticate('basic')

    @route('digest-auth/<username>/<password>/<qop>',
           title='Challenges HTTP Digest Auth',
           defaults={'username': 'username',
                     'password': 'password',
                     'qop': 'auth'})
    def challenge_digest_auth(self, request):
        auth = request.get('http.authorization')
        if auth and auth.authenticated(request.environ, **request.urlargs):
            return Json({'authenticated': True,
                         'username': auth.username}).http_response(request)
        raise wsgi.HttpAuthenticate('digest', qop=[request.urlargs['qop']])

    @route('stream/<int(min=1):m>/<int(min=1):n>',
           title='Stream m chunk of data n times',
           defaults={'m': 300, 'n': 20})
    def request_stream(self, request):
        m = request.urlargs['m']
        n = request.urlargs['n']
        if m*n > 8388608:
            # limit at 8 megabytes of total data
            raise HttpException(status=403)
        stream = ('Chunk %s\n%s\n\n' % (i+1, ''.join((
            choice(characters) for _ in range(m)))) for i in range(n))
        request.response.content = stream
        return request.response

    @route('websocket', title='A web socket graph')
    def request_websocket(self, request):
        data = open(os.path.join(os.path.dirname(__file__),
                                 'assets', 'websocket.html')).read()
        scheme = 'wss' if request.is_secure else 'ws'
        host = request.get('HTTP_HOST')
        data = data % {'address': '%s://%s/graph-data' % (scheme, host)}
        request.response.content_type = 'text/html'
        request.response.content = data
        return request.response

    @route('stats', title='Live server statistics')
    def request_stats(self, request):
        '''Live stats for the server.

        Try sending lots of requests
        '''
        # scheme = 'wss' if request.is_secure else 'ws'
        # host = request.get('HTTP_HOST')
        # address = '%s://%s/stats' % (scheme, host)
        doc = HtmlDocument(title='Live server stats', media_path='/assets/')
        # docs.head.scripts
        return doc.http_response(request)

    @route('expect', method='post', title='Expectation Failed')
    def expectation_failure(self, request):
        stream = request.get('wsgi.input')
        stream.fail()
        return self.info_data_response(request)

    ########################################################################
    #    BENCHMARK ROUTES
    @route('json')
    def bench_json(self, request):
        return Json({'message': "Hello, World!"}).http_response(request)

    @route('plaintext')
    def bench_text(self, request):
        r = request.response
        r.content = 'Hello, World!'
        r.content_type = 'text/plain; charset=utf-8'
        return r

    ########################################################################
    #    INTERNALS
    def info_data_response(self, request, **params):
        data = self.info_data(request, **params)
        return Json(data).http_response(request)

    def info_data(self, request, **params):
        headers = self.getheaders(request)
        data = {'method': request.method,
                'headers': headers,
                'pulsar': self.pulsar_info(request)}
        if request.method in ENCODE_URL_METHODS:
            data['args'] = dict(request.url_data)
        else:
            args, files = yield request.data_and_files()
            jfiles = MultiValueDict()
            for name, parts in files.lists():
                for part in parts:
                    try:
                        part = part.string()
                    except UnicodeError:
                        part = part.base64()
                    jfiles[name] = part
            data.update((('args', dict(args)),
                         ('files', dict(jfiles))))
        data.update(params)
        coroutine_return(data)

    def getheaders(self, request):
        headers = Headers(kind='client')
        for k in request.environ:
            if k.startswith('HTTP_'):
                headers[k[5:].replace('_', '-')] = request.environ[k]
        return dict(headers)

    def pulsar_info(self, request):
        return request.get('pulsar.connection').info()


class Graph(ws.WS):

    def on_message(self, websocket, msg):
        websocket.write(json.dumps([(i, random()) for i in range(100)]))


class Site(wsgi.LazyWsgi):

    def setup(self, environ):
        router = HttpBin('/')
        return wsgi.WsgiHandler([wsgi.clean_path_middleware,
                                 wsgi.authorization_middleware,
                                 wsgi.FileRouter('/favicon.ico', FAVICON),
                                 wsgi.MediaRouter('media', ASSET_DIR,
                                                  show_indexes=True),
                                 ws.WebSocket('/graph-data', Graph()),
                                 router])


def server(description=None, **kwargs):
    description = description or 'Pulsar HttpBin'
    return wsgi.WSGIServer(Site(), description=description, **kwargs)


if __name__ == '__main__':  # pragma    nocover
    server().start()

########NEW FILE########
__FILENAME__ = manage
'''
The dining philosophers_ problem is an example problem often used in
concurrent algorithm design to illustrate synchronisation issues and
techniques for resolving them.

The problem
===================

Five silent philosophers sit at a round table with each a bowl of spaghetti.
A fork ``f`` is placed between each pair of adjacent philosophers ``P``::


         P     P
         O  f  O
        f       f
     P O         O P
         f     f
            O
            P

Each philosopher ``P`` must alternately think and eat from his bowl ``O``.
Eating is not limited by the amount of spaghetti left: assume an infinite
supply.

However, a philosopher can only eat while holding both the fork ``f`` to
the left and the fork to the right.
Each philosopher can pick up an adjacent fork, when available, and put it down,
when holding it. These are separate actions: forks must be picked up and put
down one by one.

This implementation will just work. No starvation or dead-lock.

There are two parameters:

* Average eating period, the higher the more time is spend eating.
* Average waiting period, the higher the more frequent philosophers
  get a chance to eat.

To run the example, type::

    pulsar manage.py

Implementation
=====================

.. autoclass:: DiningPhilosophers
   :members:
   :member-order: bysource


.. _philosophers: http://en.wikipedia.org/wiki/Dining_philosophers_problem

'''
import os
import random
import json
try:
    import pulsar
except ImportError:
    import sys
    sys.path.append('../../')
    import pulsar
from pulsar import command, async
from pulsar.apps import wsgi, ws, data, ds

# WEB INTERFACE
media_libraries = {
    "d3": "//cdnjs.cloudflare.com/ajax/libs/d3/3.4.2/d3",
    "jquery": "//code.jquery.com/jquery-1.11.0",
    "require": "//cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require"
    }
ASSET_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'assets')
FAVICON = os.path.join(ASSET_DIR, 'favicon.ico')


class WsProtocol:

    def encode(self, message):
        return json.dumps(message)

    def decode(self, message):
        return json.loads(message)


###########################################################################
#    EXTRA COMMAND LINE PARAMETERS
class Eating_Period(pulsar.Setting):
    flags = ["--eating-period"]
    validator = pulsar.validate_pos_float
    default = 2
    desc = """The average period of eating for a philosopher."""


class Waiting_Period(pulsar.Setting):
    flags = ["--waiting-period"]
    validator = pulsar.validate_pos_float
    default = 2
    desc = """The average period of waiting for a missing fork."""


###########################################################################
#    PULSAR COMMANDS FOR DINING PHILOSOPHERS
@command(ack=False)
def putdown_fork(request, fork):
    self = request.actor.app
    try:
        self.not_available_forks.remove(fork)
    except KeyError:
        self.logger.error('Putting down a fork which was already available')


@command()
def pickup_fork(request, fork_right):
    self = request.actor.app
    num_philosophers = self.cfg.workers
    fork_left = fork_right - 1
    if fork_left == 0:
        fork_left = num_philosophers
    for fork in (fork_right, fork_left):
        if fork not in self.not_available_forks:
            # Fork is available, send it to the philosopher
            self.not_available_forks.add(fork)
            return fork


############################################################################
#    DINING PHILOSOPHERS APP
class DiningPhilosophers(pulsar.Application):
    description = ('Dining philosophers sit at a table around a bowl of '
                   'spaghetti and waits for available forks.')
    cfg = pulsar.Config(workers=5)

    def monitor_start(self, monitor):
        self.not_available_forks = set()

    def worker_start(self, philosopher, exc=None):
        self._loop = philosopher._loop
        self.eaten = 0
        self.thinking = 0
        self.started_waiting = 0
        self.forks = []
        philosopher._loop.call_soon(self.take_action, philosopher)

    def worker_info(self, philosopher, info=None):
        '''Override :meth:`~.Application.worker_info` to provide
        information about the philosopher.'''
        info['philosopher'] = {'number': philosopher.number,
                               'eaten': self.eaten}

    def take_action(self, philosopher):
        '''The ``philosopher`` performs one of these two actions:

        * eat, if it has both forks and than :meth:`release_forks`.
        * try to :meth:`pickup_fork`, if he has less than 2 forks.
        '''
        loop = philosopher._loop
        forks = self.forks
        if forks:
            #
            # Two forks. Eat!
            if len(forks) == 2:
                self.thinking = 0
                self.eaten += 1
                philosopher.logger.info("eating... So far %s times",
                                        self.eaten)
                eat_time = 2*self.cfg.eating_period*random.random()
                return loop.call_later(eat_time, self.release_forks,
                                       philosopher)
            #
            # One fork only! release fork or try to pick one up one
            elif len(forks) == 1:
                waiting_period = 2*self.cfg.waiting_period*random.random()
                if self.started_waiting == 0:
                    self.started_waiting = loop.time()
                elif loop.time() - self.started_waiting > waiting_period:
                    philosopher.logger.debug("tired of waiting")
                    return self.release_forks(philosopher)
            #
            # this should never happen
            elif len(forks) > 2:    # pragma    nocover
                philosopher.logger.critical('more than 2 forks!!!')
                return self.release_forks(philosopher)
        else:
            if not self.thinking:
                philosopher.logger.warning('%s thinking...', philosopher.name)
            self.thinking += 1
        async(self.pickup_fork(philosopher), loop=loop)

    def pickup_fork(self, philosopher):
        '''The philosopher has less than two forks.

        Check if forks are available.
        '''
        fork = yield philosopher.send(philosopher.monitor, 'pickup_fork',
                                      philosopher.number)
        if fork:
            forks = self.forks
            if fork in forks:
                philosopher.logger.error('Got fork %s. I already have it',
                                         fork)
            else:
                philosopher.logger.debug('Got fork %s.', fork)
                forks.append(fork)
        philosopher._loop.call_soon(self.take_action, philosopher)

    def release_forks(self, philosopher):
        '''The ``philosopher`` has just eaten and is ready to release both
        forks.

        This method release them, one by one, by sending the ``put_down``
        action to the monitor.
        '''
        forks = self.forks
        self.forks = []
        self.started_waiting = 0
        for fork in forks:
            philosopher.logger.debug('Putting down fork %s', fork)
            philosopher.send('monitor', 'putdown_fork', fork)
        philosopher._loop.call_later(self.cfg.waiting_period, self.take_action,
                                     philosopher)

    def actorparams(self, monitor, params):
        avail = set(range(1, monitor.cfg.workers+1))
        for philosopher in monitor.managed_actors.values():
            info = philosopher.info
            if info:
                avail.discard(info['philosopher']['number'])
            else:
                avail = None
                break
        number = min(avail) if avail else len(monitor.managed_actors) + 1
        params.update({'name': 'Philosopher %s' % number, 'number': number})


class PhilosophersWsgi(wsgi.LazyWsgi):
    '''This is the :ref:`wsgi application <wsgi-handlers>` for this
    web-chat example.'''
    def __init__(self, server_name):
        self.name = server_name

    def setup(self, environ):
        '''Called once only to setup the WSGI application handler.

        Check :ref:`lazy wsgi handler <wsgi-lazy-handler>`
        section for further information.
        '''
        cfg = environ['pulsar.cfg']
        loop = environ['pulsar.connection']._loop
        self.store = data.create_store(cfg.data_store, loop=loop)
        pubsub = self.store.pubsub(protocol=WsProtocol())
        channel = '%s_messages' % self.name
        pubsub.subscribe(channel)
        middleware = [wsgi.Router('/', get=self.home_page),
                      ws.WebSocket('/message', PhilosopherWs(pubsub, channel)),
                      wsgi.FileRouter('/favicon.ico', FAVICON),
                      wsgi.MediaRouter('media', ASSET_DIR)]
        return wsgi.WsgiHandler(middleware)

    def home_page(self, request):
        doc = wsgi.HtmlDocument(media_path='/media/',
                                known_libraries=media_libraries)
        doc.head.scripts.append('require')
        doc.head.scripts.require('jquery', 'd3', 'philosophers.js')
        doc.head.links.append('bootstrap')
        doc.body.append(wsgi.Html('div', cn='philosophers'))
        return doc.http_response(request)


class PhilosopherWs(ws.WS):

    def __init__(self, pubsub, channel):
        self.pubsub = pubsub
        self.channel = channel

    def on_open(self, websocket):
        '''When a new websocket connection is established it creates a
        new :class:`ChatClient` and adds it to the set of clients of the
        :attr:`pubsub` handler.'''
        self.pubsub.add_client(WsClient(websocket, self.channel))


class WsClient(data.PubSubClient):

    def __init__(self, connection, channel):
        self.connection = connection
        self.channel = channel

    def __call__(self, channel, message):
        self.connection.write(message)


class server(pulsar.MultiApp):
    '''Build a multi-app consisting of

    * The :class:`.DiningPhilosophers` application
    * A wsgi server for displaying actions on the browser
    '''
    cfg = pulsar.Config('Dining philosophers sit at a table around a bowl of '
                        'spaghetti and waits for available forks.',
                        data_store=ds.pulsards_url())

    def build(self):
        yield self.new_app(DiningPhilosophers)
        # yield self.new_app(wsgi.WSGIServer, prefix='wsgi',
        #                    callable=PhilosophersWsgi(self.name))
        # yield self.new_app(wsgi.WSGIServer,
        #                    callable=PhilosophersWsgi(self.name))


if __name__ == '__main__':
    server('philosophers').start()

########NEW FILE########
__FILENAME__ = tests
import unittest

from pulsar import send

from .manage import DiningPhilosophers


class TestPhylosophers(unittest.TestCase):
    app_cfg = None
    concurrency = 'thread'

    @classmethod
    def setUpClass(cls):
        app = DiningPhilosophers(name='plato',
                                 concurrency=cls.concurrency)
        cls.app_cfg = yield send('arbiter', 'run', app)

    def test_info(self):
        while True:
            philo = []
            while len(philo) < 5:
                info = yield send('plato', 'info')
                philo = info.get('workers', [])
            all = []
            for data in philo:
                p = data.get('philosopher')
                if p:
                    all.append(p)
            if len(all) == 5:
                break

    @classmethod
    def tearDownClass(cls):
        if cls.app_cfg is not None:
            return send('arbiter', 'kill_actor', cls.app_cfg.name)

########NEW FILE########
__FILENAME__ = manage
'''An asynchronous multi-process `HTTP proxy server`_. It works for both
``http`` and ``https`` (tunneled) requests.


Managing Headers
=====================
It is possible to add middleware to manipulate the original request headers.
If the header middleware is
an empty list, the proxy passes requests and responses unmodified.
This is an implementation for a forward-proxy which can be used
to retrieve any type of source from the Internet.

To run the server::

    python manage.py

An header middleware is a callable which receives the wsgi *environ* and
the list of request *headers*. By default the example uses:

.. autofunction:: x_forwarded_for

To run with different headers middleware create a new script and do::

    from proxyserver.manage import server

    if __name__ == '__main__':
        server(headers_middleware=[...]).start()

Implemenation
===========================

.. autoclass:: ProxyServerWsgiHandler
   :members:
   :member-order:


.. _`HTTP proxy server`: http://en.wikipedia.org/wiki/Proxy_server
'''
import io
import sys
import logging
from functools import partial
from asyncio import Queue, QueueEmpty

try:
    import pulsar
except ImportError:
    sys.path.append('../../')
    import pulsar

from pulsar import HttpException, async, coroutine_return, add_errback
from pulsar.apps import wsgi, http
from pulsar.utils.httpurl import Headers
from pulsar.utils.log import LocalMixin, local_property


SERVER_SOFTWARE = 'Pulsar-proxy-server/%s' % pulsar.version
ENVIRON_HEADERS = ('content-type', 'content-length')
USER_AGENT = SERVER_SOFTWARE
logger = logging.getLogger('pulsar.proxyserver')


def x_forwarded_for(environ, headers):
    '''Add *x-forwarded-for* header'''
    headers.add_header('x-forwarded-for', environ['REMOTE_ADDR'])


class user_agent:
    '''Override user-agent header'''
    def __init__(self, agent):
        self.agent = agent

    def __call__(self, environ, headers):
        headers['user-agent'] = self.agent


class ProxyServerWsgiHandler(LocalMixin):
    '''WSGI middleware for an asynchronous proxy server.

    To perform processing on headers you can pass a list of
    ``headers_middleware``.
    An headers middleware is a callable which accepts two parameters, the wsgi
    *environ* dictionary and the *headers* container.
    '''
    def __init__(self, headers_middleware=None):
        self.headers_middleware = headers_middleware or []

    @local_property
    def http_client(self):
        '''The :class:`.HttpClient` used by this proxy middleware for
        accessing upstream resources'''
        return http.HttpClient(decompress=False, store_cookies=False)

    def __call__(self, environ, start_response):
        # The WSGI thing
        loop = environ['pulsar.connection']._loop
        return async(self._call(environ, start_response, loop), loop)

    def _call(self, environ, start_response, loop):
        uri = environ['RAW_URI']
        logger.debug('new request for %r' % uri)
        if not uri or uri.startswith('/'):  # No proper uri, raise 404
            raise HttpException(status=404)
        if environ.get('HTTP_EXPECT') != '100-continue':
            stream = environ.get('wsgi.input') or io.BytesIO()
            data = yield stream.read()
        else:
            data = None
        request_headers = self.request_headers(environ)
        method = environ['REQUEST_METHOD']

        if method == 'CONNECT':
            response = ProxyTunnel(environ, start_response)
        else:
            response = ProxyResponse(environ, start_response)
        request = self.http_client.request(method, uri, data=data,
                                           headers=request_headers,
                                           version=environ['SERVER_PROTOCOL'],
                                           pre_request=response.pre_request)
        add_errback(request, response.error)
        coroutine_return(response)

    def request_headers(self, environ):
        '''Fill request headers from the environ dictionary and
        modify the headers via the list of :attr:`headers_middleware`.
        The returned headers will be sent to the target uri.'''
        headers = Headers(kind='client')
        for k in environ:
            if k.startswith('HTTP_'):
                head = k[5:].replace('_', '-')
                headers[head] = environ[k]
        for head in ENVIRON_HEADERS:
            k = head.replace('-', '_').upper()
            v = environ.get(k)
            if v:
                headers[head] = v
        for middleware in self.headers_middleware:
            middleware(environ, headers)
        return headers


############################################################################
#    RESPONSE OBJECTS
class ProxyResponse(object):
    '''Asynchronous wsgi response.
    '''
    _started = False
    _headers = None
    _done = False

    def __init__(self, environ, start_response):
        self._loop = environ['pulsar.connection']._loop
        self.environ = environ
        self.start_response = start_response
        self.queue = Queue()

    def __iter__(self):
        while True:
            if self._done:
                try:
                    yield self.queue.get_nowait()
                except QueueEmpty:
                    break
            else:
                yield async(self.queue.get(), loop=self._loop)

    def pre_request(self, response, exc=None):
        self._started = True
        response.bind_event('data_processed', self.data_processed)
        return response

    def error(self, exc):
        if not self._started:
            request = wsgi.WsgiRequest(self.environ)
            content_type = request.content_types.best_match(
                ('text/html', 'text/plain'))
            uri = self.environ['RAW_URI']
            msg = 'Could not find %s' % uri
            logger.info(msg=msg)
            if content_type == 'text/html':
                html = wsgi.HtmlDocument(title=msg)
                html.body.append('<h1>%s</h1>' % msg)
                data = html.render()
                resp = wsgi.WsgiResponse(504, data, content_type='text/html')
            elif content_type == 'text/plain':
                resp = wsgi.WsgiResponse(504, msg, content_type='text/html')
            else:
                resp = wsgi.WsgiResponse(504, '')
            self.start_response(resp.status, resp.get_headers())
            self._done = True
            self.queue.put_nowait(resp.content[0])

    def data_processed(self, response, exc=None, **kw):
        '''Receive data from the requesting HTTP client.'''
        status = response.get_status()
        if status == '100 Continue':
            stream = self.environ.get('wsgi.input') or io.BytesIO()
            body = yield stream.read()
            response.transport.write(body)
        if response.parser.is_headers_complete():
            if self._headers is None:
                headers = self.remove_hop_headers(response.headers)
                self._headers = Headers(headers, kind='server')
                # start the response
                self.start_response(status, list(self._headers))
            body = response.recv_body()
            if response.parser.is_message_complete():
                self._done = True
            self.queue.put_nowait(body)

    def remove_hop_headers(self, headers):
        for header, value in headers:
            if header.lower() not in wsgi.HOP_HEADERS:
                yield header, value


class ProxyTunnel(ProxyResponse):

    def pre_request(self, response, exc=None):
        '''Start the tunnel.

        This is a callback fired once a connection with upstream server is
        established.

        Write back to the client the 200 Connection established message.
        After this the downstream connection consumer will upgrade to the
        DownStreamTunnel.
        '''
        # Upgrade downstream protocol consumer
        # set the request to None so that start_request is not called
        assert response._request.method == 'CONNECT'
        self._started = True
        response._request = None
        upstream = response._connection
        dostream = self.environ['pulsar.connection']
        #
        dostream.upgrade(partial(StreamTunnel, upstream))
        upstream.upgrade(partial(StreamTunnel, dostream))
        response.finished()
        self.start_response('200 Connection established', [])
        # send empty byte so that headers are sent
        self.queue.put_nowait(b'')
        self._done = True
        return response


class StreamTunnel(pulsar.ProtocolConsumer):
    ''':class:`ProtocolConsumer` handling encrypted messages from
    downstream client and upstream server.

    This consumer is created as an upgrade of the standard Http protocol
    consumer.

    .. attribute:: tunnel

        Connection to the downstream client or upstream server.
    '''
    headers = None
    status_code = None

    def __init__(self, tunnel):
        super(StreamTunnel, self).__init__()
        self.tunnel = tunnel

    def connection_made(self, connection):
        connection.bind_event('connection_lost', self._close_tunnel)

    def data_received(self, data):
        try:
            self.tunnel._transport.write(data)
        except Exception:
            if not self.tunnel.closed:
                raise

    def _close_tunnel(self, arg, exc=None):
        if not self.tunnel.closed:
            self.tunnel._loop.call_soon(self.tunnel.close)


def server(name='proxy-server', headers_middleware=None,
           server_software=None, **kwargs):
    '''Function to Create a WSGI Proxy Server.'''
    if headers_middleware is None:
        # headers_middleware = [user_agent(USER_AGENT), x_forwarded_for]
        headers_middleware = [x_forwarded_for]
    wsgi_proxy = ProxyServerWsgiHandler(headers_middleware)
    kwargs['server_software'] = server_software or SERVER_SOFTWARE
    return wsgi.WSGIServer(wsgi_proxy, name=name, **kwargs)


if __name__ == '__main__':
    server().start()

########NEW FILE########
__FILENAME__ = pshell
'''\
Pulsar Python Shell example::

    python pshell.py
'''
try:
    from pulsar.apps.shell import PulsarShell
except ImportError:  # pragma nocover
    import sys
    sys.path.append('../../')
    from pulsar.apps.shell import PulsarShell


if __name__ == '__main__':  # pragma nocover
    PulsarShell().start()

########NEW FILE########
__FILENAME__ = tests
import unittest
import time

from pulsar import async_while, send, get_actor
from pulsar.apps.test import run_on_arbiter
from pulsar.apps.shell import InteractiveConsole, decode_line, PulsarShell


class DummyConsole(InteractiveConsole):

    def setup(self):
        pass

    def interact(self, timeout):
        time.sleep(timeout)


def start(actor):
    shell = PulsarShell(console_class=DummyConsole, workers=2)
    return shell(actor)


class TestShell(unittest.TestCase):
    app_cfg = None

    @classmethod
    def setUpClass(cls):
        cls.app_cfg = yield send('arbiter', 'run', start)

    @classmethod
    def tearDownClass(cls):
        if cls.app_cfg is not None:
            return send('arbiter', 'kill_actor', cls.app_cfg.name)

    def test_app(self):
        cfg = self.app_cfg
        self.assertEqual(cfg.name, 'shell')
        self.assertEqual(cfg.callable, None)
        self.assertEqual(cfg.console_class, DummyConsole)
        self.assertEqual(cfg.workers, 0)
        self.assertEqual(cfg.thread_workers, 1)
        self.assertEqual(cfg.concurrency, 'thread')
        self.assertEqual(decode_line('bla'), 'bla')

    @run_on_arbiter
    def test_test_worker(self):
        arbiter = get_actor()
        monitor = arbiter.get_actor('shell')
        yield async_while(2, lambda: not monitor.managed_actors)
        self.assertEqual(len(monitor.managed_actors), 0)

########NEW FILE########
__FILENAME__ = manage
'''\
Pulsar key-value store server. To run the server type::

    python manage.py

Open a new shell and launch python and type::

    >>> from pulsar.apps.data import create_store
    >>> store = create_store('pulsar://localhost:6410')
    >>> client = store.client()
    >>> client.ping()
    True
    >>> client.echo('Hello!')
    b'Hello!'
    >>> client.set('bla', 'foo')
    True
    >>> client.get('bla')
    b'foo'
    >>> client.dbsize()
    1

'''
try:
    import pulsar
except ImportError:  # pragma nocover
    import sys
    sys.path.append('../../')

from pulsar.apps.ds import PulsarDS


if __name__ == '__main__':  # pragma nocover
    PulsarDS().start()

########NEW FILE########
__FILENAME__ = greeter
from pulsar import arbiter, task, command, spawn, send

names = ['john', 'luca', 'jo', 'alex']


@command()
def greetme(request, message):
    echo = 'Hello {}!'.format(message['name'])
    request.actor.logger.info(echo)
    return echo


class Greeter:

    def __init__(self):
        a = arbiter()
        self._loop = a._loop
        self._loop.call_later(1, self)
        a.start()

    @task
    def __call__(self, a=None):
        if a is None:
            a = yield spawn(name='greeter')
        if names:
            name = names.pop()
            send(a, 'greetme', {'name': name})
            self._loop.call_later(1, self, a)
        else:
            arbiter().stop()


if __name__ == '__main__':
    Greeter()

########NEW FILE########
__FILENAME__ = hello
'''Write Hello there! every second
'''
from pulsar import arbiter


def hello(actor, **kw):
    print('Hello there!')
    actor._loop.call_later(1, hello, actor)


if __name__ == '__main__':
    arbiter(start=hello).start()

########NEW FILE########
__FILENAME__ = manage
'''This example creates two :ref:`pulsar applications <apps-framework>`
performing different duties. The first application is a distributed
a :ref:`task queue <apps-taskqueue>` for processing tasks implemented
in the :mod:`examples.taskqueue.simpletasks` module.
The second application is a :ref:`WSGI server <apps-wsgi>` which
exposes the task queue functionalities via a :ref:`JSON-RPC api <apps-rpc>`.

To run the server type::

    python manage.py

Open a new shell and launch python and type::

    >>> from pulsar.apps import rpc
    >>> p = rpc.JsonProxy('http://localhost:8060')
    >>> p.ping()
    'pong'
    >>> p.calc.add(3,4)
    7.0
    >>>

Implementation
====================

.. autoclass:: RpcRoot
   :members:
   :member-order: bysource

.. autoclass:: server
   :members:
   :member-order: bysource
'''
try:
    import pulsar
except ImportError:  # pragma    nocover
    import sys
    sys.path.append('../../')
    import pulsar

from pulsar.apps import rpc, tasks, wsgi

TASK_PATHS = ['sampletasks.*']


class RpcRoot(rpc.PulsarServerCommands, tasks.TaskQueueRpcMixin):
    '''The :class:`.JSONRPC` handler which communicates with the task queue.
    '''


class Rpc(wsgi.LazyWsgi):

    def __init__(self, tqname):
        self.tqname = tqname

    def setup(self, environ):
        # only post allowed by the JSON RPC handler
        request = [wsgi.Router('/', post=RpcRoot(self.tqname))]
        response = [wsgi.GZipMiddleware(200)]
        return wsgi.WsgiHandler(middleware=request,
                                response_middleware=response)


def dummy():
    # Just a dummy callable for testing coverage.
    # A callable is invoked when the taskqueue starts
    pass


class server(pulsar.MultiApp):
    '''Build a multi-app consisting on a taskqueue and a JSON-RPC server.

    This class shows how to use the :class:`.MultiApp` utility for
    starting several :ref:`pulsar applications <apps-framework>` at once.
    '''
    cfg = pulsar.Config('Taskqueue with JSON-RPC API example')

    def build(self):
        yield self.new_app(tasks.TaskQueue, callable=dummy,
                           task_paths=TASK_PATHS)
        yield self.new_app(wsgi.WSGIServer, prefix='rpc',
                           callable=Rpc(self.name))


if __name__ == '__main__':  # pragma    nocover
    server('taskqueue').start()

########NEW FILE########
__FILENAME__ = periodic
import sys
from datetime import timedelta

from pulsar.apps.tasks import PeriodicJob,  anchorDate


class TestPeriodicJob(PeriodicJob):
    abstract = True
    run_every = timedelta(hours=1)


class TestPeriodic(TestPeriodicJob):
    run_every = timedelta(seconds=5)

    def __call__(self, consumer):
        return 'OK'


class TestPeriodicError(TestPeriodicJob):
    run_every = timedelta(seconds=60)

    def __call__(self, consumer):
        raise Exception('kaputt')


class AnchoredEveryHour(TestPeriodicJob):
    anchor = anchorDate(minute=25)

    def __call__(self, consumer):   # pragma    nocover
        pass

########NEW FILE########
__FILENAME__ = sampletasks
import time
import math
from datetime import timedelta
from random import random
from functools import reduce
from asyncio import sleep

from pulsar import get_request_loop, coroutine_return
from pulsar.apps import tasks


class RunPyCode(tasks.Job):
    '''execute python code in *code*. There must be a *task_function*
function defined which accept key-valued parameters only.'''
    timeout = timedelta(seconds=60)

    def __call__(self, consumer, code, **kwargs):
        code_local = compile(code, '<string>', 'exec')
        ns = {}
        exec(code_local, ns)
        func = ns['task_function']
        return func(**kwargs)


class Addition(tasks.Job):
    timeout = timedelta(seconds=60)

    def __call__(self, consumer, a=0, b=0):
        return a + b


class Asynchronous(tasks.Job):

    def __call__(self, consumer, lag=1):
        start = time.time()
        yield sleep(lag)
        coroutine_return(time.time() - start)


class NotOverLap(tasks.Job):
    can_overlap = False

    def __call__(self, consumer, lag=1):
        start = time.time()
        yield sleep(lag)
        coroutine_return(time.time() - start)


class CheckWorker(tasks.Job):

    def __call__(self, consumer):
        worker = consumer.worker
        backend = worker.app.backend
        return {'tasks': list(backend.concurrent_tasks)}


class StandardDeviation(tasks.Job):

    def can_overlap(self, inputs=None, **kwargs):
        return inputs is not None

    def __call__(self, consumer, inputs=None, sample=10, size=100):
        if inputs is None:
            for n in range(sample):
                inputs = [random() for i in range(size)]
                self.queue_task(consumer, self.name, inputs=inputs)
            return 'produced %s new tasks' % sample
        else:
            time.sleep(0.1)
            v2 = reduce(lambda x, y: x+y,
                        map(lambda x: x*x, inputs))/len(inputs)
            return math.sqrt(v2)

########NEW FILE########
__FILENAME__ = test_pulsards
'''Tests the taskqueue local backend.'''
import unittest
from random import random

from pulsar import send, multi_async
from pulsar.apps import tasks, rpc
from pulsar.apps.test import dont_run_with_thread

from .manage import server


CODE_TEST = '''\
import time
def task_function(N = 10, lag = 0.1):
    time.sleep(lag)
    return N*N
'''


class TaskQueueBase(object):
    concurrency = 'thread'
    schedule_periodic = True
    # used for both keep-alive and timeout in JsonProxy
    # long enough to allow to wait for tasks
    rpc_timeout = 500
    concurrent_tasks = 6
    tq = None
    rpc = None

    @classmethod
    def name(cls):
        return cls.__name__.lower()

    @classmethod
    def task_backend(cls):
        return None

    @classmethod
    def rpc_name(cls):
        return 'rpc_%s' % cls.name()

    @classmethod
    def setUpClass(cls):
        # The name of the task queue application
        s = server(name=cls.name(),
                   rpc_bind='127.0.0.1:0',
                   concurrent_tasks=cls.concurrent_tasks,
                   concurrency=cls.concurrency,
                   rpc_concurrency=cls.concurrency,
                   rpc_keep_alive=cls.rpc_timeout,
                   task_backend=cls.task_backend(),
                   script=__file__,
                   schedule_periodic=cls.schedule_periodic)
        cfgs = yield send('arbiter', 'run', s)
        cls.tq = cfgs[0].app()
        cls.rpc = cfgs[1].app()
        # make sure the time out is high enough (bigger than test-timeout)
        cls.proxy = rpc.JsonProxy('http://%s:%s' % cls.rpc.cfg.addresses[0],
                                  timeout=cls.rpc_timeout)
        # Now flush the task queue
        backend = cls.tq.get_backend()
        yield backend.flush()

    @classmethod
    def tearDownClass(cls):
        yield multi_async((send('arbiter', 'kill_actor', a.name)
                           for a in (cls.tq, cls.rpc) if a is not None))


class TestTaskQueueOnThread(TaskQueueBase, unittest.TestCase):

    def test_run_new_simple_task(self):
        r = yield self.proxy.queue_task(jobname='addition', a=40, b=50)
        r = yield self.proxy.wait_for_task(r)
        self.assertEqual(r['status'], tasks.SUCCESS)
        self.assertEqual(r['result'], 90)

    def test_ping_store(self):
        tq = self.tq
        self.assertTrue(tq.backend)
        backend = tq.backend
        store = backend.store
        client = store.client()
        self.async.assertEqual(client.ping(), True)

    def test_pickled_app(self):
        tq = self.tq
        self.assertEqual(tq.name, self.name())
        self.assertTrue(tq.backend)
        backend = tq.backend
        self.assertEqual(backend.poll_timeout, 2)
        self.assertEqual(backend.num_concurrent_tasks, 0)
        self.assertEqual(backend.backlog, self.concurrent_tasks)

    def test_meta(self):
        '''Tests meta attributes of taskqueue'''
        app = self.tq
        self.assertTrue(app)
        self.assertEqual(app.name, self.name())
        self.assertFalse(app.cfg.address)
        self.assertEqual(app.cfg.concurrent_tasks, self.concurrent_tasks)
        self.assertEqual(app.backend.backlog, self.concurrent_tasks)
        self.assertTrue(app.backend.registry)
        self.assertEqual(app.cfg.concurrency, self.concurrency)
        job = app.backend.registry['runpycode']
        self.assertEqual(job.type, 'regular')
        self.assertTrue(job.can_overlap)
        id, oid = app.backend.generate_task_ids(job, {})
        self.assertTrue(id)
        self.assertFalse(oid)
        id1, oid = app.backend.generate_task_ids(job, {})
        self.assertNotEqual(id, id1)
        self.assertFalse(oid)

    def __test_pubsub(self):
        '''Tests pubsub handler'''
        app = self.tq
        pubsub = app.backend.pubsub()
        self.assertEqual(pubsub.store, app.backend.store)

    def test_rpc_meta(self):
        app = self.rpc
        cfg = app.cfg
        self.assertTrue(app)
        self.assertEqual(app.name, self.rpc_name())
        self.assertEqual(cfg.address, ('127.0.0.1', 0))
        self.assertNotEqual(cfg.addresses[0], cfg.address)
        self.assertEqual(cfg.concurrency, self.concurrency)
        wsgi_handler = cfg.callable.handler()
        self.assertEqual(len(wsgi_handler.middleware), 1)
        router = wsgi_handler.middleware[0]
        self.assertTrue(router.post)
        root = router.post
        tq = root.taskqueue
        self.assertEqual(tq, self.name())

    def test_registry(self):
        app = self.tq
        self.assertTrue(isinstance(app.backend.registry, dict))
        regular = app.backend.registry.regular()
        periodic = app.backend.registry.periodic()
        self.assertTrue(regular)
        self.assertTrue(periodic)

    def test_queue_task_asynchronous_from_test(self):
        app = self.tq
        r = yield app.backend.queue_task('asynchronous', lag=3)
        r = yield self.proxy.wait_for_task(r)
        self.assertEqual(r['status'], tasks.SUCCESS)
        time = r['result']
        self.assertTrue(time > 3)

    def test_queue_task_asynchronous(self):
        r = yield self.proxy.queue_task(jobname='asynchronous', lag=3)
        r = yield self.proxy.wait_for_task(r)
        self.assertEqual(r['status'], tasks.SUCCESS)
        time = r['result']
        self.assertTrue(time > 3)

    def test_queue_task_asynchronous_wait_on_test(self):
        app = self.tq
        r = yield self.proxy.queue_task(jobname='asynchronous', lag=3)
        r = yield app.backend.wait_for_task(r)
        self.assertEqual(r['status'], tasks.SUCCESS)
        time = r['result']
        self.assertTrue(time > 3)

    def test_queue_task_expiry(self):
        r = yield self.proxy.queue_task(jobname='addition', a=40, b=50,
                                        expiry=0)
        self.assertTrue(r)
        r = yield self.proxy.wait_for_task(r)
        self.assertEqual(r['status'], tasks.REVOKED)

    def test_run_new_simple_task_from_test(self):
        app = self.tq
        r = yield app.backend.queue_task('addition', a=1, b=2)
        r = yield self.proxy.wait_for_task(r)
        self.assertEqual(r['status'], tasks.SUCCESS)
        self.assertEqual(r['result'], 3)

    def test_not_overlap(self):
        sec = 2 + random()
        app = self.tq
        self.assertEqual(app.name, app.backend.name)
        self.assertTrue('notoverlap' in app.backend.registry)
        r1 = yield app.backend.queue_task('notoverlap', lag=sec)
        self.assertTrue(r1)
        r2 = yield app.backend.queue_task('notoverlap', lag=sec)
        self.assertFalse(r2)
        # We need to make sure the first task is completed
        r1 = yield app.backend.wait_for_task(r1)
        self.assertEqual(r1['status'], tasks.SUCCESS)
        self.assertTrue(r1['result'] > sec)

    def test_queue_task_error(self):
        yield self.async.assertRaises(rpc.InvalidParams,
                                      self.proxy.queue_task)
        yield self.async.assertRaises(rpc.InternalError,
                                      self.proxy.queue_task,
                                      jobname='xxxx', bla='foo')

    def test_queue_task_run_py_code(self):
        '''Run a new task from the *runpycode* task factory.'''
        r = yield self.proxy.queue_task(jobname='runpycode',
                                        code=CODE_TEST, N=3)
        self.assertTrue(r)
        r = yield self.proxy.wait_for_task(r)
        self.assertEqual(r['status'], tasks.SUCCESS)
        self.assertEqual(r['result'], 9)

    def test_queue_task_periodicerror(self):
        r = yield self.proxy.queue_task(jobname='testperiodicerror')
        r = yield self.proxy.wait_for_task(r)
        self.assertEqual(r['status'], tasks.FAILURE)
        self.assertTrue('kaputt' in r['result'])

    def __test_delete_task(self):
        # ISSUE #56
        app = self.tq
        id = yield app.backend.queue_task(jobname='addition', a=1, b=4)
        r1 = yield app.backend.wait_for_task(id)
        self.assertEqual(r1.result, 5)
        deleted = yield app.backend.delete_tasks([r1.id, 'kjhbkjb'])
        self.assertEqual(len(deleted), 1)
        r1 = yield app.backend.get_task(r1.id)
        self.assertFalse(r1)

    def test_run_producerconsumer(self):
        '''A task which produce other tasks'''
        sample = 5
        r = yield self.proxy.queue_task(jobname='standarddeviation',
                                        sample=sample, size=100)
        self.assertTrue(r)
        r = yield self.proxy.wait_for_task(r)
        self.assertEqual(r['status'], tasks.SUCCESS)
        self.assertEqual(r['result'], 'produced %s new tasks' % sample)
        self.assertTrue(tasks.nice_task_message(r))
        # We check for the tasks created
        # TODO: not available
        # created = yield self.proxy.get_tasks(from_task=r['id'])
        # self.assertEqual(len(created), sample)
        # stasks = []
        # for task in created:
        #     stasks.append(self.proxy.wait_for_task(task['id']))
        # created = yield multi_async(stasks)
        # self.assertEqual(len(created), sample)
        # for task in created:
        #     self.assertEqual(task['status'], tasks.SUCCESS)

    #    RPC TESTS
    def test_check_next_run(self):
        app = self.tq
        backend = app.backend
        backend.tick()
        # self.assertTrue(backend.next_run > now)

    def test_rpc_ping(self):
        yield self.async.assertEqual(self.proxy.ping(), 'pong')

    def test_rpc_job_list(self):
        jobs = yield self.proxy.job_list()
        self.assertTrue(jobs)
        self.assertTrue(isinstance(jobs, list))
        d = dict(jobs)
        pycode = d['runpycode']
        self.assertEqual(pycode['type'], 'regular')

    def test_rpc_job_list_with_names(self):
        jobs = yield self.proxy.job_list(jobnames=['runpycode'])
        self.assertEqual(len(jobs), 1)
        jobs = yield self.proxy.job_list(jobnames=['xxxxxx'])
        self.assertEqual(len(jobs), 0)

    def test_rpc_next_scheduled_tasks(self):
        next = yield self.proxy.next_scheduled_tasks()
        self.assertTrue(next)
        self.assertEqual(len(next), 2)
        next = yield self.proxy.next_scheduled_tasks(jobnames=['testperiodic'])
        self.assertTrue(next)
        self.assertEqual(len(next), 2)
        self.assertEqual(next[0], 'testperiodic')
        self.assertTrue(next[1] >= 0)

    def test_id_not_overlap(self):
        '''Check `generate_task_ids` when `can_overlap` attribute is set to
        False.'''
        app = self.tq
        job = app.backend.registry['notoverlap']
        self.assertEqual(job.type, 'regular')
        self.assertFalse(job.can_overlap)
        #
        id1, oid1 = app.backend.generate_task_ids(job, {})
        self.assertTrue(oid1)
        id2, oid2 = app.backend.generate_task_ids(job, {})
        self.assertTrue(oid2)
        self.assertNotEqual(id2, id1)
        self.assertEqual(oid2, oid1)
        #
        id3, oid3 = app.backend.generate_task_ids(job, {'p': 45})
        self.assertTrue(oid3)
        self.assertNotEqual(id3, id2)
        self.assertNotEqual(oid3, oid2)
        id4, oid4 = app.backend.generate_task_ids(job, {'p': 45})
        self.assertNotEqual(id4, id3)
        self.assertEqual(oid4, oid3)
        #
        id5, oid5 = app.backend.generate_task_ids(job, {'p': 45, 'c': 'bla'})
        self.assertTrue(oid5)
        id6, oid6 = app.backend.generate_task_ids(job, {'p': 45, 'c': 'bla'})
        id7, oid7 = app.backend.generate_task_ids(job, {'p': 45, 'd': 'bla'})
        id8, oid8 = app.backend.generate_task_ids(job, {'p': 45, 'c': 'blas'})
        #
        self.assertEqual(oid5, oid6)
        self.assertNotEqual(oid5, oid7)
        self.assertNotEqual(oid5, oid8)


@dont_run_with_thread
class TestTaskQueueOnProcess(TestTaskQueueOnThread):
    concurrency = 'process'

########NEW FILE########
__FILENAME__ = test_redis
'''Tests the taskqueue redis backend.'''
import unittest

from pulsar.apps.test import check_server

from . import test_pulsards

OK = check_server('redis')


@unittest.skipUnless(OK, 'Requires a running redis server')
class TestRedisTaskQueueOnThread(test_pulsards.TestTaskQueueOnThread):
    # schedule_periodic = False

    @classmethod
    def task_backend(cls):
        return 'redis://%s' % cls.cfg.redis_server


@unittest.skipUnless(OK, 'Requires a running redis server')
class TestRedisTaskQueueOnProcess(test_pulsards.TestTaskQueueOnProcess):

    @classmethod
    def task_backend(cls):
        return 'redis://%s' % cls.cfg.redis_server

########NEW FILE########
__FILENAME__ = test_restart
import time
import unittest

from pulsar.apps import tasks

from .test_pulsards import TaskQueueBase


# class TestTaskQueueRestart(TaskQueueBase, unittest.TestCase):
# TODO: fix this test

class a:    # pragma    nocover
    def info(self):
        info = yield self.proxy.server_info()
        # get the task queue
        yield info['monitors'][self.name()]

    def test_kill_task_workers(self):
        tq = yield self.info()
        killed = set()
        for worker in tq['workers']:
            a = worker['actor']
            aid = a['actor_id']
            self.assertEqual(a['is_process'], self.concurrency == 'process')
            r = yield self.proxy.kill_actor(aid)
            killed.add(aid)
            self.assertTrue(r)
        # lets get the info again
        start = time.time()
        workers = None
        while time.time() - start < 5:
            info = yield self.proxy.server_info()
            tq = info['monitors'][self.name()]
            workers = tq['workers']
            if workers:
                break
        self.assertTrue(workers)
        for w in workers:
            a = w['actor']
            self.assertFalse(a['actor_id'] in killed)

    def __test_check_worker(self):
        # TODO, this test fails sometimes
        r = yield self.proxy.run_new_task(jobname='checkworker')
        self.assertTrue(r)
        r = yield self.proxy.wait_for_task(r)
        self.assertEqual(r['status'], tasks.SUCCESS)
        result = r['result']
        concurrent = result['tasks']
        self.assertTrue(r['id'] in concurrent)

########NEW FILE########
__FILENAME__ = winservice
import os
import sys
p = lambda x: os.path.split(x)[0]
path = p(p(p(os.path.abspath(__file__))))
sys.path.insert(0, path)

import pulsar
from pulsar.utils.system import winservice

from manage import server


class TasqueueService(winservice.PulsarService):
    _svc_name_ = 'TASKSQUEUE'
    _svc_display_name_ = "PULSAR TASKSQUEUE server"
    _svc_description_ = "Pulsar asynchronous task queue server"

    def setup(self):
        server(parse_console=False, concurrency='process')


if __name__ == '__main__':
    TasqueueService.run()

########NEW FILE########
__FILENAME__ = manage
'''The example is a :ref:`WSGI application <apps-wsgi>`
with a :ref:`websocket middleware <apps-ws>` which connects to an
IMAP4 server to retrieve and send emails.

The connection with the IMAP4 server is obtained using the IMAP4 API in
twisted 12.3 or later. The example uses
:ref:`pulsar-twisted integration <tutorials-twisted>` module.

To run the server you need to create a :mod:`config.py` file in the
the :mod:`examples.webmail` directory containing::

    # the adress of your mail server
    mail_incoming ='ssl:host=imap.gmail.com:port=993'
    # mail_username & mail_password
    mail_username=
    mail_password=

And type::

    python manage.py

Open a web browser at http://localhost:8060 and you should see the web app.

For information on twisted IMAP4 client library check this example:

http://twistedmatrix.com/documents/current/mail/examples/imap4client.py

Other python examples of webmail:

* https://github.com/khamidou/kite

Implementation
==================

.. autoclass:: WsMail
   :members:
   :member-order: bysource

'''
import os
import sys

from pulsar import coroutine_return
from pulsar.apps import ws, wsgi
from pulsar.utils.log import process_global
from pulsar.utils.system import json
try:
    from pulsar.apps.tx import twisted
    from twisted.internet import protocol, endpoints, reactor
    from twisted.mail import imap4
except ImportError:  # pragma    nocover
    twisted = None    # This is for when we build docs

ASSET_DIR = os.path.join(os.path.dirname(__file__), 'assets')


def mail_client(cfg, timeout=10):
    '''Create a new mail client using twisted IMAP4 library.'''
    key = (cfg.mail_incoming, cfg.mail_username, cfg.mail_password)
    client = process_global(key)
    if not client:
        endpoint = endpoints.clientFromString(reactor, cfg.mail_incoming)
        endpoint._timeout = timeout
        factory = protocol.Factory()
        factory.protocol = imap4.IMAP4Client
        client = yield endpoint.connect(factory)
        yield client.login(cfg.mail_username, cfg.mail_password)
        yield client.select('INBOX')
        process_global(key, client, True)
    coroutine_return(client)
    # info = yield client.fetchEnvelope(imap4.MessageSet(1))
    # print 'First message subject:', info[1]['ENVELOPE'][1]


class WsMail(ws.WS):
    '''A :class:`.WS` handler for fetching and sending mail via the
    twisted IMAP4 library
    '''
    def on_open(self, websocket):
        '''When the websocket starts, it create a new mail client.'''
        request = websocket.handshake
        client = yield mail_client(request.cfg)
        # add the mail client to the environ cache
        request.cache.mailclient = client
        # retrieve the list of mailboxes and them to the client
        yield self._send_mailboxes(websocket)

    def on_message(self, websocket, msg):
        request = websocket.request
        client = request.cache.mailclient
        if msg and client:
            msg = json.loads(msg)
            if 'mailbox' in msg:
                mailbox = yield client.examine(msg['mailbox'])
                self.write(request, json.dumps({'mailbox': mailbox}))

    def _send_mailboxes(self, websocket):
        request = websocket.handshake
        result = yield request.cache.mailclient.list("", "*")
        result = sorted([e[2] for e in result])
        websocket.write(json.dumps({'list': result}))


class WebMail(wsgi.LazyWsgi):

    def setup(self, environ):
        return wsgi.WsgiHandler([ws.WebSocket('/message', WsMail()),
                                 wsgi.MediaRouter('/media', ASSET_DIR),
                                 wsgi.Router('/', get=self.home)])

    def home(self, request):
        data = open(os.path.join(ASSET_DIR, 'mail.html')).read()
        response = request.response
        request.response.content = data % request.environ
        request.response.content_type = 'text/html'
        return response


def server(name='webmail', callable=None, **kwargs):
    return wsgi.WSGIServer(name=name, callable=WebMail(), **kwargs)


if __name__ == '__main__':  # pragma nocover
    server().start()

########NEW FILE########
__FILENAME__ = test_tx
'''Test twisted integration'''
import unittest

import pulsar
from pulsar import multi_async
from pulsar.utils.pep import to_bytes, to_string
from pulsar.utils.security import gen_unique_id

from examples.echo.manage import server, EchoProtocol

try:
    # This import must be done before importing twisted
    from pulsar.apps.tx import twisted
    from twisted.internet.protocol import Factory, Protocol
    from twisted.internet.defer import Deferred
    from twisted.internet.endpoints import TCP4ClientEndpoint
    from twisted.internet import reactor

    class EchoClient(Protocol):
        '''Twisted client to the Echo server in the examples.echo module'''
        separator = EchoProtocol.separator
        connected = False

        def __init__(self):
            self.buffer = b''
            self.requests = {}

        def connectionMade(self):
            self.connected = True

        def __call__(self, msg):
            id = to_bytes(gen_unique_id()[:8])
            self.requests[id] = d = Deferred()
            self.transport.write(id + to_bytes(msg) + self.separator)
            return d

        def dataReceived(self, data):
            sep = self.separator
            idx = data.find(sep)
            if idx >= 0:
                if self.buffer:
                    msg = self.buffer + msg
                    self.buffer = b''
                id, msg, data = data[:8], data[8:idx], data[idx+len(sep):]
                d = self.requests.pop(id)
                d.callback(to_string(msg))
                if data:
                    self.dataReceived(data)
            else:
                self.buffer += data

    class EchoClientFactory(Factory):
        protocol = EchoClient

    def get_client(address):
        point = TCP4ClientEndpoint(reactor, *address)
        return point.connect(EchoClientFactory())

except ImportError:
    twisted = None


@unittest.skipUnless(twisted, 'Requires twisted')
class TestTwistedIntegration(unittest.TestCase):
    server_cfg = None

    @classmethod
    def setUpClass(cls):
        s = server(name=cls.__name__.lower(), bind='127.0.0.1:0')
        cls.server_cfg = yield pulsar.send('arbiter', 'run', s)
        cls.address = cls.server_cfg.addresses[0]

    @classmethod
    def tearDownClass(cls):
        if cls.server_cfg:
            return pulsar.send('arbiter', 'kill_actor', cls.server_cfg.name)

    def test_echo_client(self):
        client = yield get_client(self.address)
        self.assertTrue(client.connected)
        result = yield client('Hello')
        self.assertEqual(result, 'Hello')
        result = yield client('Ciao')
        self.assertEqual(result, 'Ciao')

    def test_multi_requests(self):
        client = yield get_client(self.address)
        results = yield multi_async((client('Msg%s' % n) for n in range(20)))
        self.assertEqual(len(results), 20)
        for n, result in enumerate(results):
            self.assertEqual(result, 'Msg%s' % n)


@unittest.skipUnless(twisted, 'Requires twisted')
class TestPulsarReactor(unittest.TestCase):

    def test_meta(self):
        self.assertTrue(reactor.running)
        self.assertEqual(reactor.threadpool, None)
        self.assertEqual(reactor.waker, None)

    def test_switched_off_methods(self):
        self.assertRaises(NotImplementedError, reactor.spawnProcess)

########NEW FILE########
__FILENAME__ = test_webmail
'''Test twisted integration'''
import unittest

from .manage import twisted, mail_client


@unittest.skipUnless(twisted, 'Requires twisted and a config file')
class TestWebMail(unittest.TestCase):
    concurrency = 'thread'
    server = None

    def testMailCient(self):
        client = yield mail_client(self.cfg, timeout=5)
        self.assertTrue(client)

########NEW FILE########
__FILENAME__ = manage
'''\
A very Simple Web-Socket example.
To run the server type::

    python manage.py

and open a web browser at http://localhost:8060
'''
import os
import sys
from random import random
try:
    import pulsar
except ImportError:  # pragma nocover
    sys.path.append('../../')
    import pulsar

from pulsar.apps import ws, wsgi
from pulsar.utils.pep import range
from pulsar.utils.system import json


class Graph(ws.WS):

    def on_open(self, websocket):
        self.on_message(websocket, '')

    def on_message(self, websocket, msg):
        websocket.write(json.dumps([(i, random()) for i in range(100)]))


class Echo(ws.WS):

    def on_message(self, websocket, msg):
        if msg.startswith('send ping '):
            websocket.ping(msg[10:])
        elif msg.startswith('send close '):
            websocket.write_close(int(msg[11:]))
        else:
            websocket.write(msg)


class Site(wsgi.LazyWsgi):

    def setup(self, environ):
        return wsgi.WsgiHandler([wsgi.Router('/', get=self.home),
                                 ws.WebSocket('/data', Graph()),
                                 ws.WebSocket('/echo', Echo())])

    def home(self, request):
        data = open(os.path.join(os.path.dirname(__file__),
                                 'websocket.html')).read()
        data = data % request.environ
        request.response.content_type = 'text/html'
        request.response.content = data
        return request.response


def server(**kwargs):
    return wsgi.WSGIServer(callable=Site(), **kwargs)


if __name__ == '__main__':  # pragma nocover
    server().start()

########NEW FILE########
__FILENAME__ = tests
'''Tests the websocket middleware in pulsar.apps.ws.'''
import unittest
from asyncio import Queue

from pulsar import send, new_event_loop
from pulsar.apps.ws import WebSocket, WS
from pulsar.apps.http import HttpClient
from pulsar.apps.test import dont_run_with_thread

from .manage import server


class Echo(WS):

    def __init__(self, loop=None):
        self.queue = Queue(loop=loop)

    def get(self):
        return self.queue.get()

    def on_message(self, ws, message):
        self.queue.put_nowait(message)

    def on_ping(self, ws, body):
        ws.pong(body)
        self.queue.put_nowait('PING: %s' % body.decode('utf-8'))

    def on_pong(self, ws, body):
        self.queue.put_nowait('PONG: %s' % body.decode('utf-8'))

    def on_close(self, ws):
        self.queue.put_nowait('CLOSE')


class TestWebSocketThread(unittest.TestCase):
    app_cfg = None
    concurrency = 'thread'

    @classmethod
    def setUpClass(cls):
        s = server(bind='127.0.0.1:0', name=cls.__name__,
                   concurrency=cls.concurrency)
        cls.app_cfg = yield send('arbiter', 'run', s)
        addr = cls.app_cfg.addresses[0]
        cls.uri = 'http://{0}:{1}'.format(*addr)
        cls.ws_uri = 'ws://{0}:{1}/data'.format(*addr)
        cls.ws_echo = 'ws://{0}:{1}/echo'.format(*addr)

    @classmethod
    def tearDownClass(cls):
        if cls.app_cfg is not None:
            yield send('arbiter', 'kill_actor', cls.app_cfg.name)

    def testHyBiKey(self):
        w = WebSocket('/', None)
        v = w.challenge_response('dGhlIHNhbXBsZSBub25jZQ==')
        self.assertEqual(v, "s3pPLMBiTxaQ9kYGzzhZRbK+xOo=")

    def testBadRequests(self):
        c = HttpClient()
        response = yield c.post(self.ws_uri)
        self.assertEqual(response.status_code, 405)
        #
        response = yield c.get(self.ws_uri,
                               headers=[('Sec-Websocket-Key', 'x')])
        self.assertEqual(response.status_code, 400)
        #
        response = yield c.get(self.ws_uri,
                               headers=[('Sec-Websocket-Key', 'bla')])
        self.assertEqual(response.status_code, 400)
        #
        response = yield c.get(self.ws_uri,
                               headers=[('Sec-Websocket-version', 'xxx')])
        self.assertEqual(response.status_code, 400)

    def test_upgrade(self):
        c = HttpClient()
        handler = Echo()
        ws = yield c.get(self.ws_echo, websocket_handler=handler)
        response = ws.handshake
        self.assertEqual(response.status_code, 101)
        self.assertEqual(response.headers['upgrade'], 'websocket')
        self.assertEqual(ws.connection, response.connection)
        self.assertEqual(ws.handler, handler)
        #
        # on_finished
        self.assertTrue(response.on_finished.done())
        self.assertFalse(ws.on_finished.done())
        # Send a message to the websocket
        ws.write('Hi there!')
        message = yield handler.get()
        self.assertEqual(message, 'Hi there!')

    def test_ping(self):
        c = HttpClient()
        handler = Echo()
        ws = yield c.get(self.ws_echo, websocket_handler=handler)
        #
        # ASK THE SERVER TO SEND A PING FRAME
        ws.write('send ping TESTING PING')
        message = yield handler.get()
        self.assertEqual(message, 'PING: TESTING PING')

    def test_pong(self):
        c = HttpClient()
        handler = Echo()
        ws = yield c.get(self.ws_echo, websocket_handler=handler)
        #
        ws.ping('TESTING CLIENT PING')
        message = yield handler.get()
        self.assertEqual(message, 'PONG: TESTING CLIENT PING')

    def test_close(self):
        c = HttpClient()
        handler = Echo()
        ws = yield c.get(self.ws_echo, websocket_handler=handler)
        self.assertEqual(ws.event('post_request').fired(), 0)
        ws.write('send close 1001')
        message = yield handler.get()
        self.assertEqual(message, 'CLOSE')
        self.assertTrue(ws.close_reason)
        self.assertEqual(ws.close_reason[0], 1001)
        self.assertTrue(ws._connection.closed)

    def test_close_sync(self):
        loop = new_event_loop()
        c = HttpClient(loop=loop)
        handler = Echo(loop)
        ws = c.get(self.ws_echo, websocket_handler=handler)
        self.assertEqual(ws.event('post_request').fired(), 0)
        self.assertEqual(ws._loop, loop)
        self.assertFalse(ws._loop.is_running())
        ws.write('send close 1001')
        message = ws._loop.run_until_complete(handler.get())
        self.assertEqual(message, 'CLOSE')
        self.assertTrue(ws.close_reason)
        self.assertEqual(ws.close_reason[0], 1001)
        self.assertTrue(ws._connection.closed)


@dont_run_with_thread
class TestWebSocketProcess(TestWebSocketThread):
    concurrency = 'process'

########NEW FILE########
__FILENAME__ = luatest
from pulsar.utils.lua import Lua


class Handler():

    def call(self, *args):
        '''A simple function to call from lua'''
        return args


lua = Lua()
print('registering')
lua.register('pytest', Handler(), 'call')
print('testing')
print(lua.execute('return type(pytest)'))
print(lua.execute('return type(pytest.call)'))
result = lua.execute('return pytest.call("ciao")')
print(result)

########NEW FILE########
__FILENAME__ = fields
import pickle
from functools import partial
from base64 import b64encode
from datetime import date, datetime

from pulsar.utils.html import UnicodeMixin
from pulsar.utils.numbers import date2timestamp

from .manager import (OneToManyRelatedManager, load_relmodel, LazyForeignKey,
                      OdmError)


NONE_EMPTY = (None, '', b'')


class FieldError(OdmError):
    pass


class FieldValueError(ValueError):
    pass


class Field(UnicodeMixin):
    '''Base class of all :mod:`.odm` Fields.

    Each field is specified as a :class:`.Model` class attribute.

    .. attribute:: index

        Some data stores requires to create indexes when performing specific
        queries.

        Default ``False``.

    .. attribute:: unique

        If ``True``, the field must be unique throughout the model.
        In this case :attr:`~Field.index` is also ``True``.

        Default ``False``.

    .. attribute:: primary_key

        If ``True``, this field is the primary key for the model.

        A primary key field has the following properties:

        * :attr:`~Field.unique` is also ``True``
        * There can be only one in a model
        * If not specified a :class:`.AutoIdField` will be added

        Default ``False``.

    .. attribute:: required

        If ``False``, the field is allowed to be null.

        Default ``True``.

    .. attribute:: default

        Default value for this field. It can be a callable attribute.

        Default ``None``.

    .. attribute:: name

        Field name, created by the ``odm`` at runtime.

    .. attribute:: store_name

        The name for the field, created by the :meth:`get_store_name`
        method at runtime. For most field, its value is the same as the
        :attr:`name`. It is the field stored in the backend database.

    .. attribute:: _meta

        The :class:`.ModelMeta` holding the field.
        Created by the ``odm`` at runtime.

    .. attribute:: charset

        The charset used for encoding decoding text.

    .. attribute:: hidden

        If ``True`` the field will be hidden from search algorithms.

        Default ``False``.

    .. attribute:: python_type

        The python ``type`` for the :class:`Field`.

    .. attribute:: as_cache

        If ``True`` the field contains data which is considered cache and
        therefore always reproducible. Field marked as cache, have
        :attr:`required` always ``False``.

        This attribute is used by the :class:`.Model.fieldvalue_pairs` method
        which returns a dictionary of field names and values.

        Default ``False``.
    '''
    repr_type = 'unknown'
    primary_key = False
    required = True
    to_python = None
    index = False
    _default = None
    creation_counter = 0

    def __init__(self, unique=False, primary_key=None, required=None,
                 index=None, hidden=False, as_cache=False, **extras):
        self.foreign_keys = ()
        self.primary_key = (self.primary_key if primary_key is None else
                            primary_key)
        if required is None:
            required = self.required
        index = index if index is not None else self.index
        if self.primary_key:
            self.unique = True
            self.required = True
            self.index = True
            self.as_cache = False
            extras['default'] = None
        else:
            self.unique = unique
            self.required = required
            self.as_cache = as_cache
            self.index = True if unique else index
        if self.as_cache:
            self.required = False
            self.unique = False
            self.index = False
        self._meta = None
        self.name = None
        self.hidden = hidden
        self._default = extras.pop('default', self._default)
        self._handle_extras(**extras)
        self.creation_counter = Field.creation_counter
        Field.creation_counter += 1

    def register_with_model(self, name, model):
        '''Called during the creation of a the :class:`StdModel`
        class when :class:`Metaclass` is initialised. It fills
        :attr:`Field.name` and :attr:`Field.model`. This is an internal
        function users should never call.'''
        assert not self.name, 'Field %s is already registered' % self
        self.name = name
        self.store_name = self.get_store_name()
        self._meta = meta = model._meta
        meta.dfields[name] = self
        if self.to_python:
            meta.converters[name] = self.to_python
        if self.primary_key:
            meta.pk = self
        self.add_to_fields()

    def add_to_fields(self):
        '''Add this :class:`Field` to the fields of :attr:`model`.
        '''
        self._meta.scalarfields.append(self)
        if self.index:
            self._meta.indexes.append(self)

    def get_store_name(self):
        '''Generate the :attr:`store_name` at runtime'''
        return self.name

    def get_value(self, instance, value):
        return value

    def to_store(self, value, store=None):
        if value in NONE_EMPTY:
            return self.get_default()
        else:
            return value

    def to_json(self, value, store=None):
        return value

    def get_default(self):
        '''Default value for this :class:`.Field`
        '''
        if hasattr(self._default, '__call__'):
            return self._default()
        else:
            return self._default

    def _handle_extras(self, **extras):
        '''Callback to hadle extra arguments during initialization.'''
        self.error_extras(extras)

    def error_extras(self, extras):
        keys = list(extras)
        if keys:
            raise TypeError(("__init__() got an unexepcted keyword argument "
                             "'{0}'".format(keys[0])))


class CharField(Field):
    repr_type = 'text'

    def to_python(self, value, store=None):
        if isinstance(value, bytes):
            return value.decode('utf-8', 'ignore')
        elif value is not None:
            return str(value)
    to_store = to_python
    to_json = to_python


class AutoIdField(Field):
    primary_key = True


class IntegerField(Field):
    index = True
    repr_type = 'numeric'

    def to_python(self, value, store=None):
        try:
            return int(value)
        except Exception:
            return None

    def to_store(self, value, store=None):
        if value not in NONE_EMPTY:
            return int(value)
        else:
            return self.get_default()

    to_json = to_python


class BooleanField(Field):
    index = True
    repr_type = 'bool'

    def to_python(self, value, store=None):
        try:
            return bool(int(value))
        except Exception:
            return None
    to_json = to_python

    def to_store(self, value, store):
        if value in NONE_EMPTY:
            value = self.get_default()
        return store.encode_bool(value)


class FloatField(Field):
    index = True
    repr_type = 'numeric'

    def to_python(self, value, store=None):
        try:
            return float(value)
        except Exception:
            return None
    to_json = to_python

    def to_store(self, value, store=None):
        if value not in NONE_EMPTY:
            return float(value)
        else:
            return self.get_default()


class DateField(Field):
    repr_type = 'numeric'

    def to_python(self, value, backend=None):
        if value not in NONE_EMPTY:
            if isinstance(value, date):
                if isinstance(value, datetime):
                    value = value.date()
            else:
                value = datetime.fromtimestamp(float(value)).date()
            return value
        else:
            return self.get_default()

    def to_store(self, value, backend=None):
        if value in NONE_EMPTY:
            value = self.get_default()
        if isinstance(value, date):
            return date2timestamp(value)
        elif value not in NONE_EMPTY:
            raise FieldValueError('%s not a valid date' % value)
    to_json = to_store

    def _handle_extras(self, auto_now=False, **extras):
        self.auto_now = auto_now
        super(DateField, self)._handle_extras(**extras)


class DateTimeField(DateField):

    def to_python(self, value, backend=None):
        if value not in NONE_EMPTY:
            if isinstance(value, date):
                if not isinstance(value, datetime):
                    value = datetime(value.year, value.month, value.day)
            else:
                value = datetime.fromtimestamp(float(value))
            return value
        else:
            return self.get_default()


class PickleField(Field):
    repr_type = 'bytes'
    required = False
    index = False

    def to_python(self, value, store=None):
        if value is not None:
            if store:
                value = store.decode_bytes(value)
            if isinstance(value, bytes):
                return pickle.loads(value)
            else:
                return value

    def to_store(self, value, store=None):
        if value is not None:
            try:
                value = pickle.dumps(value, protocol=2)
                if store:
                    value = store.encode_bytes(value)
                return value
            except Exception:
                return None

    def to_json(self, value, store=None):
        if isinstance(value, (int, float, str, tuple, list, dict)):
            return value
        else:
            value = self.to_store(value)
            if value is not None:
                return b64encode(value).decode('utf-8')


class JSONField(CharField):
    '''A JSON field which implements automatic conversion to
    and from an object and a JSON string.

    It is the responsability of the
    user making sure the object is JSON serializable.

    There are few extra parameters which can be used to customize the
    behaviour and how the field is stored in the back-end server.

    :parameter encoder_class: The JSON class used for encoding.

        Default: :class:`stdnet.utils.jsontools.JSONDateDecimalEncoder`.

    :parameter decoder_hook: A JSON decoder function.

        Default: :class:`stdnet.utils.jsontools.date_decimal_hook`.

    :parameter as_string: Set the :attr:`as_string` attribute.

        Default ``True``.

    .. attribute:: as_string

        A boolean indicating if data should be serialized
        into a single JSON string or it should be used to create several
        fields prefixed with the field name and the double underscore ``__``.

        Default ``True``.

        Effectively, a :class:`JSONField` with ``as_string`` attribute set to
        ``False`` is a multifield, in the sense that it generates several
        field-value pairs. For example, lets consider the following::

            class MyModel(odm.StdModel):
                name = odm.SymbolField()
                data = odm.JSONField(as_string=False)

        And::

            >>> m = MyModel(name='bla',
            ...             data={'pv': {'': 0.5, 'mean': 1, 'std': 3.5}})
            >>> m.cleaned_data
            {'name': 'bla', 'data__pv': 0.5, 'data__pv__mean': '1',
             'data__pv__std': '3.5', 'data': '""'}
            >>>

        The reason for setting ``as_string`` to ``False`` is to allow
        the :class:`JSONField` to define several fields at runtime,
        without introducing new :class:`Field` in your model class.
        These fields behave exactly like standard fields and therefore you
        can, for example, sort queries with respect to them::

            >>> MyModel.objects.query().sort_by('data__pv__std')
            >>> MyModel.objects.query().sort_by('-data__pv')

        which can be rather useful feature.
    '''
    required = False
    index = False

    def to_store(self, value, store):
        if value is NONE_EMPTY:
            value = self.get_default()
        return store.encode_json(value)

    def to_python(self, value, store=None):
        if value is None:
            return self.get_default()
        if isinstance(value, str):
            try:
                return json.loads(value)
            except TypeError:
                return None
        else:
            return value

    def serialise(self, value, lookup=None):
        if lookup:
            value = range_lookups[lookup](value)
        return self.encoder.dumps(value)

    def value_from_data(self, instance, data):
        if self.as_string:
            return data.pop(self.store_name, None)
        else:
            return flat_to_nested(data, instance=instance,
                                  store_name=self.store_name,
                                  loads=self.encoder.loads)

    def get_sorting(self, name, errorClass):
        pass

    def get_lookup(self, name, errorClass):
        if self.as_string:
            return super(JSONField, self).get_lookup(name, errorClass)
        else:
            if name:
                name = JSPLITTER.join((self.store_name, name))
            return (name, None)


class ForeignKey(Field):
    '''A :class:`.Field` defining a :ref:`one-to-many <one-to-many>`
    objects relationship.

    It requires a positional argument representing the :class:`.Model`
    to which the model containing this field is related. For example::

        class Folder(odm.Model):
            name = odm.CharField()

        class File(odm.Model):
            folder = odm.ForeignKey(Folder, related_name='files')

    To create a recursive relationship, an object that has a many-to-one
    relationship with itself use::

        odm.ForeignKey('self')

    Behind the scenes, the :ref:`odm <odm>` appends ``_id`` to the field
    name to create
    its field name in the back-end data-server. In the above example,
    the database field for the ``File`` model will have a ``folder_id`` field.

    .. attribute:: related_name

        Optional name to use for the relation from the related object
        back to ``self``.
    '''
    index = True
    proxy_class = LazyForeignKey
    related_manager_class = OneToManyRelatedManager

    def __init__(self, model, related_name=None, related_manager_class=None,
                 **kwargs):
        if related_manager_class:
            self.related_manager_class = related_manager_class
        if not model:
            raise FieldError('Model not specified')
        super(ForeignKey, self).__init__(**kwargs)
        self.relmodel = model
        self.related_name = related_name

    def register_with_related_model(self):
        # add the RelatedManager proxy to the model holding the field
        setattr(self._meta.model, self.name, self.proxy_class(self))
        # self._meta.related[self.name] =
        load_relmodel(self, self._set_relmodel)

    def _set_relmodel(self, relmodel, **kw):
        self._relmeta = meta = relmodel._meta
        if not self.related_name:
            self.related_name = '%s_%s_set' % (self._meta.name, self.name)
        if (self.related_name not in meta.related and
                self.related_name not in meta.dfields):
            self._relmeta.related[self.related_name] = self
        else:
            raise FieldError('Duplicated related name "{0} in model "{1}" '
                             'and field {2}'.format(self.related_name,
                                                    meta, self))

    def get_store_name(self):
        return '%s_id' % self.name

    def get_value(self, instance, value):
        if isinstance(value, self.relmodel):
            id = value.id
            if id:
                instance['_%s' % self.name] = value
            return id
        else:
            return value

    def to_store(self, value, store):
        if isinstance(value, self.relmodel):
            return value.id
        else:
            return value

    def register_with_model(self, name, model):
        super(ForeignKey, self).register_with_model(name, model)
        if not model._meta.abstract:
            self.register_with_related_model()


class CompositeIdField(Field):
    '''This field can be used when an instance of a model is uniquely
    identified by a combination of two or more :class:`Field` in the model
    itself. It requires a number of positional arguments greater or equal 2.
    These arguments must be fields names in the model where the
    :class:`CompositeIdField` is defined.

    .. attribute:: fields

        list of :class:`Field` names which are used to uniquely identify a
        model instance

    Check the :ref:`composite id tutorial <tutorial-compositeid>` for more
    information and tips on how to use it.
    '''
    primary_key = True

    def __init__(self, *fields, **kwargs):
        super(CompositeIdField, self).__init__(**kwargs)
        self.fields = fields
        if len(self.fields) < 2:
            raise FieldError('At least two fields are required by composite '
                             'CompositeIdField')

    def register_with_model(self, name, model):
        fields = []
        for field in self.fields:
            if field not in model._meta.dfields:
                raise FieldError(
                    'Composite id field "%s" not in in "%s" model.' %
                    (field, model._meta))
            field = model._meta.dfields[field]
            fields.append(field)
        self.fields = tuple(fields)
        return super(CompositeIdField, self).register_with_model(name, model)


class ManyToManyField(Field):
    '''A :ref:`many-to-many <many-to-many>` relationship.
Like :class:`ForeignKey`, it requires a positional argument, the class
to which the model is related and it accepts **related_name** as extra
argument.

.. attribute:: related_name

    Optional name to use for the relation from the related object
    back to ``self``. For example::

        class Group(odm.StdModel):
            name = odm.SymbolField(unique=True)

        class User(odm.StdModel):
            name = odm.SymbolField(unique=True)
            groups = odm.ManyToManyField(Group, related_name='users')

    To use it::

        >>> g = Group(name='developers').save()
        >>> g.users.add(User(name='john').save())
        >>> u.users.add(User(name='mark').save())

    and to remove::

        >>> u.following.remove(User.objects.get(name='john'))

.. attribute:: through

    An optional :class:`StdModel` to use for creating the many-to-many
    relationship can be passed to the constructor, via the **through** keyword.
    If such a model is not passed, under the hood, a :class:`ManyToManyField`
    creates a new *model* with name constructed from the field name
    and the model holding the field. In the example above it would be
    *group_user*.
    This model contains two :class:`ForeignKeys`, one to model holding the
    :class:`ManyToManyField` and the other to the *related_model*.

'''
    def __init__(self, model, through=None, related_name=None, **kwargs):
        self.through = through
        self.relmodel = model
        self.related_name = related_name
        super(ManyToManyField, self).__init__(model, **kwargs)

    def register_with_model(self, name, model):
        super(ManyToManyField, self).register_with_model(name, model)
        if not model._meta.abstract:
            load_relmodel(self, self._set_relmodel)

    def _set_relmodel(self, relmodel):
        relmodel._manytomany_through_model(self)

    def get_store_name(self):
        return None

    def todelete(self):
        return False

    def add_to_fields(self):
        # A many to many field is a dummy field. All it does it provides a
        # proxy for the through model. Remove it from the fields dictionary
        # and addit to the list of many_to_many
        self._meta.dfields.pop(self.name)
        self._meta.manytomany.append(self.name)

########NEW FILE########
__FILENAME__ = manager
from pulsar import Event, wait_complete, chain_future, add_callback, task

from .query import AbstractQuery, Query, QueryError, ModelNotFound
from ..store import Command


RECURSIVE_RELATIONSHIP_CONSTANT = 'self'

pending_lookups = {}

class_prepared = Event()


def do_pending_lookups(model, **kwargs):
    """Handle any pending relations to the sending model.
Sent from class_prepared."""
    key = (model._meta.app_label, model._meta.name)
    for callback in pending_lookups.pop(key, []):
        callback(model)


class_prepared.bind(do_pending_lookups)


class OdmError(RuntimeError):
    pass


class ManyToManyError(OdmError):
    pass


class Manager(AbstractQuery):
    '''Used by the :class:`.Mapper` to link a data :class:`.Store` collection
    with a :class:`.Model`.

    For example::

        from pulsar.apps.data import odm

        class MyModel(odm.Model):
            group = odm.SymbolField()
            flag = odm.BooleanField()

        models = odm.Mapper()
        models.register(MyModel)

        manager = models[MyModel]

    A :class:`.Model` can specify a :ref:`custom manager <custom-manager>` by
    creating a :class:`Manager` subclass with additional methods::

        class MyModelManager(odm.Manager):

            def special_query(self, **kwargs):
                ...

    At this point we need to tell the model about the custom manager, and we do
    so by setting the ``manager_class`` class attribute in the
    :class:`.Model`::

        class MyModel(odm.Model):
            ...

            manager_class = MyModelManager

    .. attribute:: _model

        The :class:`.Model` associated with this manager

    .. attribute:: _store

        The :class:`.Store` associated with this manager

    .. attribute:: _read_store

        The :class:`.Store` associated with this manager for
        read-only operations

    .. attribute:: _mapper

        The :class:`.Mapper` where this :class:`.Manager` is registered
    '''
    query_class = Query

    def __init__(self, model, store=None, read_store=None, mapper=None):
        self._model = model
        self._store = store
        self._read_store = read_store or store
        self._mapper = mapper

    @property
    def _meta(self):
        return self._model._meta

    @property
    def _loop(self):
        return self._store._loop

    def __str__(self):
        if self._store:
            return '{0}({1} - {2})'.format(self.__class__.__name__,
                                           self._meta,
                                           self._store)
        else:
            return '{0}({1})'.format(self.__class__.__name__, self._meta)
    __repr__ = __str__

    def __call__(self, *args, **kwargs):
        '''Create a new model without commiting to database.
        '''
        instance = self._model(*args, **kwargs)
        instance['_mapper'] = self._mapper
        return instance

    @task
    def create_table(self, remove_existing=False):
        '''Create the table/collection for the :attr:`_model`
        '''
        yield self._store.create_table(self._model,
                                       remove_existing=remove_existing)
        if self._mapper.search_engine:
            yield self._mapper.search_engine.create_table(self)

    def drop_table(self):
        '''Drop the table/collection for the :attr:`_model`
        '''
        return self._store.drop_table(self._model)

    #    QUERY IMPLEMENTATION
    def query(self):
        '''Build a :class:`.Query` object
        '''
        return self.query_class(self)

    @wait_complete
    def get(self, *args, **kw):
        '''Get a single model
        '''
        if len(args) == 1:
            return self._read_store.get_model(self, args[0])
        elif args:
            raise QueryError("'get' expected at most 1 argument, %s given" %
                             len(args))
        else:
            return chain_future(self.filter(**kw).all(), self._get)

    def filter(self, **kwargs):
        '''Build a :class:`.Query` object with filtering clauses
        '''
        return self.query().filter(**kwargs)

    def exclude(self, **kwargs):
        return self.query().exclude(**kwargs)

    def union(self, *queries):
        return self.query().exclude(*queries)

    def intersect(self, *queries):
        return self.query().intersect(*queries)

    def where(self, *expressions):
        return self.query().where(*expressions)

    def count(self):
        return self.query().count()

    def all(self):
        return self.query().all()

    def begin(self):
        '''Begin a new :class:`.Transaction`.'''
        return self._mapper.begin()

    @wait_complete
    def create(self, *args, **kwargs):
        '''Create a new instance of :attr:`_model` and commit to server.
        '''
        with self._mapper.begin() as t:
            model = t.add(self(*args, **kwargs))
        return t.wait(lambda t: model)
    new = create
    insert = new

    @wait_complete
    def update(self, *instance, **kwargs):
        '''Update an existing ``instance`` of :attr:`_model`.

        The instance must have already contain the primary key.
        '''
        if instance:
            if len(instance) > 1:
                raise TypeError('expected at most 1 arguments, got %s' %
                                len(instance))
            instance = instance[0]
            instance.update(kwargs)
        else:
            instance = self(**kwargs)
        if not instance.id:
            raise ValueError('Cannot update. No primary key in %s' % instance)
        with self._mapper.begin() as t:
            t.add(instance, Command.UPDATE)
        return t.wait(lambda t: instance)

    @wait_complete
    def save(self, instance):
        '''Save an ``instance`` of :attr:`_model`.
        '''
        with self._mapper.begin() as t:
            t.add(instance)
        return t.wait(lambda t: instance)

    @wait_complete
    def delete(self, instance):
        '''Delete an existing ``instance`` of :attr:`_model`
        '''
        with self._mapper.begin() as t:
            t.add(instance, Command.DELETE)
        return t.wait(lambda t: instance)

    # INTERNALS
    def _get(self, data):
        if len(data) == 1:
            return data[0]
        elif data:
            raise QueryError('Expected one model got %s' % len(data))
        else:
            raise ModelNotFound


def load_relmodel(field, callback):
    relmodel = None
    relation = field.relmodel
    if relation == RECURSIVE_RELATIONSHIP_CONSTANT:
        relmodel = field.model
    else:
        try:
            app_label, model_name = relation.lower().split(".")
        except ValueError:
            # If we can't split, assume a model in current app
            app_label = field.model._meta.app_label
            model_name = relation.lower()
        except AttributeError:
            relmodel = relation
    if relmodel:
        callback(relmodel)
    else:
        key = (app_label, model_name)
        if key not in pending_lookups:
            pending_lookups[key] = []
        pending_lookups[key].append(callback)


class LazyProxy(object):
    '''Base class for lazy descriptors.

    .. attribute:: field

        The :class:`Field` which create this descriptor. Either a
        :class:`ForeignKey` or a :class:`StructureField`.
    '''
    def __init__(self, field):
        self.field = field

    def __repr__(self):
        return self.field.name
    __str__ = __repr__

    @property
    def name(self):
        return self.field.name

    def load(self, instance, session):
        '''Load the lazy data for this descriptor.'''
        raise NotImplementedError

    def load_from_manager(self, manager):
        raise NotImplementedError('cannot access %s from manager' % self)

    def __get__(self, instance, instance_type=None):
        if instance is None:
            return self
        return self.load(instance)


class LazyForeignKey(LazyProxy):
    '''Descriptor for a :class:`.ForeignKey` field.
    '''
    def load(self, instance):
        field = self.field
        key = '_%s' % field.name
        if field.store_name in instance:
            pk = instance[field.store_name]
            value = instance.get(key)
            if value is not None:
                if value.id == pk:
                    return value
                else:
                    instance.pop(key)
            mapper = instance.get('_mapper')
            if mapper:
                return add_callback(mapper[field.relmodel].get(pk),
                                    lambda value: instance.set(key, value))

    def __set__(self, instance, value):
        if instance is None:
            raise AttributeError("%s must be accessed via instance" %
                                 self.field.name)
        field = self.field
        key = '_%s' % field.name
        if value is not None and not isinstance(value, field.relmodel):
            raise ValueError(
                'Cannot assign "%r": "%s" must be a "%s" instance.' %
                (value, field, field.relmodel._meta.name))
        instance.pop(key, None)
        if isinstance(value, field.relmodel):
            instance[field.store_name] = value
            instance[key] = value.id
        else:
            instance.pop(field.store_name)
            instance.pop(key)


class RelatedManager(Manager):
    '''A :class:`.Manager` handling relationships between models.

    .. attribute:: relmodel

        The :class:`.Model` this related manager relates to.

    .. attribute:: related_instance

        An instance of the :attr:`relmodel`.
    '''
    def __init__(self, field, model=None, instance=None):
        self.field = field
        model = model or field.model
        super(RelatedManager, self).__init__(model)
        self.related_instance = instance

    def __get__(self, instance, instance_type=None):
        return self.__class__(self.field, self.model, instance)


class OneToManyRelatedManager(RelatedManager):
    '''A specialised :class:`.RelatedManager` for handling one-to-many
    relationships.

    If a model has a :class:`ForeignKey` field, instances of
    that model will have access to the related (foreign) objects
    via a simple attribute of the model.
    '''
    @property
    def relmodel(self):
        return self.field.relmodel

    def query(self, session=None):
        # Override query method to account for related instance if available
        query = super(OneToManyRelatedManager, self).query(session)
        if self.related_instance is not None:
            kwargs = {self.field.name: self.related_instance}
            return query.filter(**kwargs)
        else:
            return query

    def query_from_query(self, query, params=None):
        if params is None:
            params = query
        return query.session.query(self.model, fargs={self.field.name: params})


#    MANY2MANY MANAGER

class ManyToManyRelatedManager(OneToManyRelatedManager):
    '''A specialized :class:`.OneToManyRelatedManager` for handling
    many-to-many relationships under the hood.

    When a model has a :class:`ManyToManyField`, instances
    of that model will have access to the related objects via a simple
    attribute of the model.'''
    def session_instance(self, name, value, session, **kwargs):
        if self.related_instance is None:
            raise ManyToManyError('Cannot use "%s" method from class' % name)
        elif not self.related_instance.id:
            raise ManyToManyError('Cannot use "%s" method on a non persistent '
                                  'instance.' % name)
        elif not isinstance(value, self.formodel):
            raise ManyToManyError(
                '%s is not an instance of %s' % (value, self.formodel._meta))
        elif not value.id:
            raise ManyToManyError('Cannot use "%s" a non persistent instance.'
                                  % name)
        kwargs.update({self.name_formodel: value,
                       self.name_relmodel: self.related_instance})
        return self.session(session), self.model(**kwargs)

    def add(self, value, session=None, **kwargs):
        '''Add ``value``, an instance of :attr:`formodel` to the
:attr:`through` model. This method can only be accessed by an instance of the
model for which this related manager is an attribute.'''
        s, instance = self.session_instance('add', value, session, **kwargs)
        return s.add(instance)

    def remove(self, value, session=None):
        '''Remove *value*, an instance of ``self.model`` from the set of
elements contained by the field.'''
        s, instance = self.session_instance('remove', value, session)
        # update state so that the instance does look persistent
        instance.get_state(iid=instance.id, action='update')
        return s.delete(instance)

    def throughquery(self, session=None):
        '''Return a :class:`Query` on the ``throughmodel``, the model
used to hold the :ref:`many-to-many relationship <many-to-many>`.'''
        return super(ManyToManyRelatedManager, self).query(session)

    def query(self, session=None):
        # Return a query for the related model
        ids = self.throughquery(session).get_field(self.name_formodel)
        pkey = self.formodel.pk().name
        fargs = {pkey: ids}
        return self.session(session).query(self.formodel).filter(**fargs)


def makeManyToManyRelatedManager(formodel, name_relmodel, name_formodel):
    '''formodel is the model which the manager .'''

    class _ManyToManyRelatedManager(ManyToManyRelatedManager):
        pass

    _ManyToManyRelatedManager.formodel = formodel
    _ManyToManyRelatedManager.name_relmodel = name_relmodel
    _ManyToManyRelatedManager.name_formodel = name_formodel
    return _ManyToManyRelatedManager

########NEW FILE########
__FILENAME__ = mapper
from inspect import ismodule

from pulsar import EventHandler, multi_async, wait_complete
from pulsar.utils.pep import native_str
from pulsar.utils.importer import import_module

from .transaction import Transaction, ModelDictionary
from .model import ModelType
from .manager import Manager
from . import query
from ..store import create_store


class Mapper(EventHandler):
    '''A mapper is a mapping of :class:`.Model` to a :class:`.Manager`.

    The :class:`.Manager` are registered with a :class:`.Store`::

        from asyncstore import odm

        models = odm.Mapper(store)
        models.register(MyModel, ...)

        # dictionary Notation
        query = models[MyModel].query()

        # or dotted notation (lowercase)
        query = models.mymodel.query()

    The ``models`` instance in the above snippet can be set globally if
    one wishes to do so.

    A :class:`.Mapper` has four events:

    * ``pre_commit``: fired before instances are committed::

            models.bind_event('pre_commit', callback)

    * ``pre_delete``: fired before instances are deleted::

            models.bind_event('pre_delete', callback)

    * ``pre_commit``: fired after instances are committed::

            models.bind_event('post_commit', callback)

    * ``post_delete``: fired after instances are deleted::

            models.bind_event('post_delete', callback)
    '''
    MANY_TIMES_EVENTS = ('pre_commit', 'pre_delete',
                         'post_commit', 'post_delete')
    ModelNotFound = query.ModelNotFound

    def __init__(self, default_store, **kw):
        super(Mapper, self).__init__()
        self._registered_models = ModelDictionary()
        self._registered_names = {}
        self._default_store = create_store(default_store, **kw)
        self._loop = self._default_store._loop
        self._search_engine = None

    @property
    def default_store(self):
        '''The default :class:`.Store` for this :class:`.Mapper`.

        Used when calling the :meth:`register` method without explicitly
        passing a :class:`.Store`.
        '''
        return self._default_store

    @property
    def registered_models(self):
        '''List of registered :class:`.Model`.'''
        return list(self._registered_models)

    @property
    def search_engine(self):
        '''The :class:`.SearchEngine` for this :class:`.Mapper`.

        This must be created by users and intalled on a mapper via the
        :meth:`set_search_engine` method.
        Check :ref:`full text search <odm-search>`
        tutorial for information.
        '''
        return self._search_engine

    def __repr__(self):
        return '%s %s' % (self.__class__.__name__, self._registered_models)

    def __str__(self):
        return str(self._registered_models)

    def __contains__(self, model):
        return model in self._registered_models

    def __iter__(self):
        return iter(self._registered_models)

    def __getitem__(self, model):
        return self._registered_models[model]

    def __getattr__(self, name):
        if name in self._registered_names:
            return self._registered_names[name]
        raise AttributeError('No model named "%s"' % name)

    def begin(self):
        '''Begin a new :class:`.Transaction`
        '''
        return Transaction(self)

    def set_search_engine(self, engine):
        '''Set the :class:`.SearchEngine` for this :class:`.Mapper`.

        Check :ref:`full text search <odm-search>`
        tutorial for information.
        '''
        self._search_engine = engine
        if engine:
            self._search_engine.set_mapper(self)

    def register(self, *models, **params):
        '''Register one or several :class:`.Model` with this :class:`Mapper`.

        If a model was already registered it does nothing.

        :param models: a list of :class:`.Model`
        :param store: a :class:`.Store` or a connection string.
        :param read_store: Optional :class:`.Store` for read
            operations. This is useful when the server has a master/slave
            configuration, where the master accept write and read operations
            and the ``slave`` read only operations (Redis).
        :param include_related: ``True`` if related models to ``model``
            needs to be registered.
            Default ``True``.
        :param params: Additional parameters for the :func:`.create_store`
            function.
        :return: a list models registered or a single model if there
            was only one
        '''
        include_related = params.pop('include_related', True)
        store = params.pop('store', None) or self._default_store
        read_store = params.pop('read_store', None)
        store = create_store(store, **params)
        if read_store:
            read_store = create_store(read_store, *params)
        registered = []
        for model in models:
            for model in self.models_from_model(
                    model, include_related=include_related):
                if model in self._registered_models:
                    continue
                registered.append(model)
                default_manager = store.default_manager or Manager
                manager_class = getattr(model, 'manager_class',
                                        default_manager)
                manager = manager_class(model, store, read_store, self)
                self._registered_models[model] = manager
                if model._meta.name not in self._registered_names:
                    self._registered_names[model._meta.name] = manager
        return registered[0] if len(registered) == 1 else registered

    def from_uuid(self, uuid, session=None):
        '''Retrieve a :class:`.Model` from its universally unique identifier
``uuid``. If the ``uuid`` does not match any instance an exception will raise.
'''
        elems = uuid.split('.')
        if len(elems) == 2:
            model = get_model_from_hash(elems[0])
            if not model:
                raise Model.DoesNotExist(
                    'model id "{0}" not available'.format(elems[0]))
            if not session or session.mapper is not self:
                session = self.session()
            return session.query(model).get(id=elems[1])
        raise Model.DoesNotExist('uuid "{0}" not recognized'.format(uuid))

    def flush(self, exclude=None, include=None, dryrun=False):
        '''Flush :attr:`registered_models`.

        :param exclude: optional list of model names to exclude.
        :param include: optional list of model names to include.
        :param dryrun: Doesn't remove anything, simply collect managers
            to flush.
        :return:
        '''
        exclude = exclude or []
        results = []
        for manager in self._registered_models.values():
            m = manager._meta
            if include is not None and not (m.table_name in include or
                                            m.app_label in include):
                continue
            if not (m.table_name in exclude or m.app_label in exclude):
                if dryrun:
                    result = yield manager.query().count()
                else:
                    result = yield manager.query().delete()
                results.append((manager, result))
        coroutine_return(results)

    def unregister(self, model=None):
        '''Unregister a ``model`` if provided, otherwise it unregister all
        registered models.

        Return a list of unregistered model managers or ``None``
        if no managers were removed.'''
        if model is not None:
            try:
                manager = self._registered_models.pop(model)
            except KeyError:
                return
            if self._registered_names.get(manager._meta.name) == manager:
                self._registered_names.pop(manager._meta.name)
            return [manager]
        else:
            managers = list(self._registered_models.values())
            self._registered_models.clear()
            return managers

    def register_applications(self, applications, models=None, stores=None):
        '''A higher level registration method for group of models located
        on application modules.

        It uses the :meth:`model_iterator` method to iterate
        through all :class:`.Model` available in ``applications``
        and :meth:`register` them.

        :parameter applications: A String or a list of strings representing
            python dotted paths where models are implemented. Can also be
            a module or a list of modules.
        :parameter models: Optional list of models to include. If not provided
            all models found in *applications* will be included.
        :parameter stores: optional dictionary which map a model or an
            application to a store
            :ref:`connection string <connection-string>`.
        :rtype: A list of registered :class:`.Model`.

        For example::


            mapper.register_applications('mylib.myapp')
            mapper.register_applications(['mylib.myapp', 'another.path'])
            mapper.register_applications(pythonmodule)
            mapper.register_applications(['mylib.myapp', pythonmodule])

        '''
        return list(self._register_applications(applications, models,
                                                stores))

    @wait_complete
    def search(self, *kw):
        raise NotImplementedError

    @wait_complete
    def create_tables(self, remove_existing=False):
        '''Loop though :attr:`registered_models` and issue the
        :meth:`.Manager.create_table` method.'''
        executed = []
        search_engine = self.search_engine
        for manager in self._registered_models.values():
            executed.append(manager.create_table(remove_existing))
        return multi_async(executed, loop=self._loop)

    @wait_complete
    def drop_tables(self):
        '''Loop though :attr:`registered_models` and issue the
        :meth:`.Manager.drop_table` method.'''
        executed = []
        for manager in self._registered_models.values():
            executed.append(manager.drop_table())
        return multi_async(executed, loop=self._loop)

    # PRIVATE METHODS
    def _register_applications(self, applications, models, stores):
        stores = stores or {}
        for model in self.model_iterator(applications):
            name = str(model._meta)
            if models and name not in models:
                continue
            if name not in stores:
                name = model._meta.app_label
            kwargs = stores.get(name, self._default_store)
            if not isinstance(kwargs, dict):
                kwargs = {'backend': kwargs}
            else:
                kwargs = kwargs.copy()
            if self.register(model, include_related=False, **kwargs):
                yield model

    def valid_model(self, model):
        if isinstance(model, ModelType):
            return not model._meta.abstract
        return False

    def models_from_model(self, model, include_related=False, exclude=None):
        '''Generator of all model in model.

        :param model: a :class:`.Model`
        :param include_related: if ``True`` al related models to ``model``
            are included
        :param exclude: optional set of models to exclude
        '''
        if exclude is None:
            exclude = set()
        if self.valid_model(model) and model not in exclude:
            exclude.add(model)
            yield model
            if include_related:
                for column in model._meta.dfields.values():
                    for fk in column.foreign_keys:
                        for model in (fk.column.table,):
                            for m in self.models_from_model(
                                    model, include_related=include_related,
                                    exclude=exclude):
                                yield m

    def model_iterator(self, application, include_related=True, exclude=None):
        '''A generator of :class:`.Model` classes found in *application*.

        :parameter application: A python dotted path or an iterable over
            python dotted-paths where models are defined.

        Only models defined in these paths are considered.
        '''
        if exclude is None:
            exclude = set()
        application = native_str(application)
        if ismodule(application) or isinstance(application, str):
            if ismodule(application):
                mod, application = application, application.__name__
            else:
                try:
                    mod = import_module(application)
                except ImportError:
                    # the module is not there
                    mod = None
            if mod:
                label = application.split('.')[-1]
                try:
                    mod_models = import_module('.models', application)
                except ImportError:
                    mod_models = mod
                label = getattr(mod_models, 'app_label', label)
                models = set()
                for name in dir(mod_models):
                    value = getattr(mod_models, name)
                    for model in self.models_from_model(
                            value, include_related=include_related,
                            exclude=exclude):
                        if (model._meta.app_label == label
                                and model not in models):
                            models.add(model)
                            yield model
        else:
            for app in application:
                for m in self.model_iterator(app,
                                             include_related=include_related,
                                             exclude=exclude):
                    yield m

########NEW FILE########
__FILENAME__ = model
import sys
from inspect import isclass
from copy import copy
from base64 import b64encode
from collections import Mapping

from pulsar import ImproperlyConfigured
from pulsar.utils.structures import OrderedDict
from pulsar.utils.pep import ispy3k, iteritems

try:
    from pulsar.utils.libs import Model as CModelBase
except ImportError:
    CModelBase = None

from .manager import class_prepared, makeManyToManyRelatedManager
from .fields import (Field, AutoIdField, ForeignKey, CompositeIdField,
                     FieldError, NONE_EMPTY)
from .query import OdmError

from ..store import Command


primary_keys = ('id', 'ID', 'pk', 'PK')


def is_private_field(field):
    return field.startswith('_') or field == 'Type'


def get_fields(bases, attrs):
    #
    fields = []
    for name, field in list(attrs.items()):
        if isinstance(field, Field):
            fields.append((name, attrs.pop(name)))
    #
    fields = sorted(fields, key=lambda x: x[1].creation_counter)
    #
    for base in bases:
        if hasattr(base, '_meta'):
            fields = list((name, copy(field)) for name, field
                          in base._meta.dfields.items()) + fields
    #
    return OrderedDict(fields)


def make_app_label(new_class, app_label=None):
    if app_label is None:
        model_module = sys.modules[new_class.__module__]
        try:
            bits = model_module.__name__.split('.')
            app_label = bits.pop()
            if app_label == 'models':
                app_label = bits.pop()
        except:
            app_label = ''
    return app_label


class ModelMeta(object):
    '''A class for storing meta data for a :class:`.Model` class.
    To override default behaviour you can specify the ``Meta`` class
    as an inner class of :class:`.Model` in the following way::

        from pulsar.apps.data import odm

        class MyModel(odm.Model):
            timestamp = odm.FloatField()
            ...

            class Meta:
                name = 'custom'


    :parameter register: if ``True`` (default), this :class:`ModelMeta` is
        registered in the global models hashtable.
    :parameter abstract: Check the :attr:`abstract` attribute.
    :parameter app_label: Check the :attr:`app_label` attribute.
    :parameter name: Check the :attr:`name` attribute.
    :parameter table_name: Check the :attr:`table_name` attribute

    This is the list of attributes and methods available. All attributes,
    but the ones mentioned above, are initialised by the object relational
    mapper.

    .. attribute:: abstract

        If ``True``, This is an abstract Meta class.

    .. attribute:: model

        :class:`Model` for which this instance is the database metadata
        container.

    .. attribute:: name

        Usually it is the :class:`.Model` class name in lower-case, but it
        can be customised.

    .. attribute:: app_label

        Unless specified it is the name of the directory or file
        (if at top level) containing the :class:`.Model` definition.
        It can be customised.

    .. attribute:: table_name

        The table_name which is by default given by ``<app_label>_<name>``.

    .. attribute:: dfields

        dictionary of all :class:`.Field` in :attr:`model`

    .. attribute:: scalarfields

        Ordered list of all :class:`Field` which are not
        :class:`.StructureField`.
        The order is the same as in the :class:`Model` definition.

    .. attribute:: indexes

        List of :class:`.Field` which are indexes (:attr:`~.Field.index`
        attribute set to ``True``).

    .. attribute:: pk

        The :class:`.Field` representing the primary key.

    .. attribute:: related

        Dictionary of :class:`.RelatedManager` for the :attr:`model`.
        It is created at runtime by the object data mapper.

    .. attribute:: manytomany

        List of :class:`ManyToManyField` names for the :attr:`model`. This
        information is useful during registration.
    '''
    def __init__(self, model, fields, app_label=None, table_name=None,
                 name=None, register=True, pkname=None, abstract=False,
                 **kwargs):
        self.model = model
        self.abstract = abstract
        self.scalarfields = []
        self.manytomany = []
        self.indexes = []
        self.manytomany = []
        self.dfields = {}
        self.converters = {}
        self.related = {}
        self.model._meta = self
        self.app_label = make_app_label(model, app_label)
        self.name = (name or model.__name__).lower()
        if not table_name:
            if self.app_label:
                table_name = '%s_%s' % (self.app_label, self.name)
            else:
                table_name = self.name
        self.table_name = table_name
        #
        # Check if PK field exists
        pk = None
        pkname = pkname or primary_keys[0]
        scalarfields = []
        for name in fields:
            field = fields[name]
            if is_private_field(name):
                raise FieldError("%s is a reserved field name" % name)
            if field.primary_key:
                if pk is not None:
                    raise FieldError("Primary key already available %s."
                                     % name)
                pk = field
                pkname = name
            elif name in primary_keys:
                raise FieldError('%s is a reserved field name for primary keys'
                                 % name)
        if pk is None and not self.abstract:
            # ID field not available, create one
            pk = AutoIdField()
        if not self.abstract:
            fields.pop(pkname, None)
            for name, field in fields.items():
                field.register_with_model(name, model)
            pk.register_with_model(pkname, model)

    def __repr__(self):
        return self.table_name

    def __str__(self):
        return self.__repr__()

    @property
    def _meta(self):
        return self

    def pkname(self):
        '''Primary key name. A shortcut for ``self.pk.name``.'''
        return self.pk.name

    def pk_to_python(self, value, backend):
        '''Convert the primary key ``value`` to a valid python representation.
        '''
        return self.pk.to_python(value, backend)

    def store_data(self, instance, store, action):
        '''Generator of ``field, value`` pair for the data ``store``.

        Perform validation for ``instance`` and can raise :class:`.FieldError`
        if invalid values are stored in ``instance``.
        '''
        fields = instance._meta.dfields
        if action == Command.INSERT:
            for field in fields.values():
                name = field.store_name
                value = field.to_store(instance.get_raw(name), store)
                if ((value in NONE_EMPTY) and field.required and
                        not isinstance(field, AutoIdField)):
                    raise FieldError("Field '%s' is required for '%s'." %
                                     (name, self))
                if value is not None:
                    yield name, value
            for name in (set(instance) - set(fields)):
                if not is_private_field(name):
                    value = instance[name]
                    if value is not None:
                        yield name, value
        else:
            for name in instance:
                if not is_private_field(name):
                    value = instance[name]
                    if name in fields:
                        value = fields[name].to_store(value, store)
                    if value is not None:
                        yield name, value


class ModelType(type(dict)):
    '''Model metaclass'''
    def __new__(cls, name, bases, attrs):
        meta = attrs.pop('Meta', None)
        if isclass(meta):
            meta = dict(((k, v) for k, v in meta.__dict__.items()
                         if not k.startswith('__')))
        else:
            meta = meta or {}
        cls.extend_meta(meta, attrs)
        fields = get_fields(bases, attrs)
        attrs['__slots__'] = ('_access_cache', '_modified')
        new_class = super(ModelType, cls).__new__(cls, name, bases, attrs)
        ModelMeta(new_class, fields, **meta)
        class_prepared.fire(new_class)
        return new_class

    @classmethod
    def extend_meta(cls, meta, attrs):
        for name in ('register', 'abstract'):
            if name in attrs:
                meta[name] = attrs.pop(name)


class Model(ModelType('ModelBase', (dict,), {'abstract': True})):
    '''A model is a python ``dict`` which represents and item/row
    in a data-store collection/table.

    Fields values can be accessed via the dictionary interface::

        model['field1']

    or the dotted interface::

        model.field1

    which is equivalent to::

        model.get('field1')

    .. attribute:: _meta

        Class attribute which represents the :class:`.ModelMeta`
        for this model.
    '''
    abstract = True

    def __init__(self, *args, **kwargs):
        self._access_cache = set()
        self._modified = None
        self.update(*args, **kwargs)
        self._modified = set()

    def __getitem__(self, field):
        field = mstr(field)
        if field in primary_keys:
            field = self._meta.pkname()
        value = super(Model, self).__getitem__(field)
        if field not in self._access_cache:
            self._access_cache.add(field)
            if field in self._meta.converters:
                value = self._meta.converters[field](value)
                super(Model, self).__setitem__(field, value)
        return value

    def __setitem__(self, field, value):
        field, value = self._get_field_value(field, value)
        super(Model, self).__setitem__(field, value)

    def __getattr__(self, field):
        try:
            return self.__getitem__(field)
        except KeyError as e:
            return None

    def __eq__(self, other):
        if other.__class__ == self.__class__:
            return self.id == other.id
        else:
            return False

    def __ne__(self, other):
        return not self.__eq__(other)

    def get(self, field, default=None):
        try:
            return self.__getitem__(field)
        except KeyError:
            return default

    def set(self, field, value, modify=True):
        '''Set the ``value`` at ``field``

        If ``modify`` is ``True``, this method is equivalent to::

            model[field] = value
        '''
        if modify:
            self[field] = value
        else:
            super(Model, self).__setitem__(field, value)

    def get_raw(self, field, default=None):
        '''Get the raw value at ``field``

        This function does not apply field conversion.
        '''
        try:
            return super(Model, self).__getitem__(field)
        except KeyError:
            return default

    def update(self, *args, **kwargs):
        if len(args) == 1:
            iterable = args[0]
            super(Model, self).update(self._update_modify(iterable))
        elif args:
            raise TypeError('expected at most 1 arguments, got %s' % len(args))
        if kwargs:
            super(Model, self).update(self._update_modify(kwargs))

    def to_json(self):
        '''Return a JSON serialisable dictionary representation.
        '''
        return dict(self._to_json())

    def save(self):
        '''Commit changes to backend data store.
        '''
        mapper = self.get('_mapper')
        if mapper:
            return mapper[self._meta].save(self)
        else:
            raise OdmError('_mapper not available in %s' % self)

    def delete(self):
        '''Delete this model from backend data store
        '''
        mapper = self.get('_mapper')
        if mapper:
            return mapper[self._meta].delete(self)
        else:
            raise OdmError('_mapper not available in %s' % self)

    #    INTERNALS
    def _to_json(self):
        pk = self.get('id')
        if pk:
            yield self._meta.pk.name, pk
            for key in self:
                if not is_private_field(key):
                    value = self[key]
                    if value is not None:
                        if key in self._meta.dfields:
                            value = self._meta.dfields[key].to_json(value)
                        elif isinstance(value, bytes):
                            try:
                                value = value.decode('utf-8')
                            except Exception:
                                value = b64encode(value).decode('utf-8')
                        yield key, value

    def _update_modify(self, iterable):
        if isinstance(iterable, Mapping):
            iterable = iteritems(iterable)
        for field, value in iterable:
            yield self._get_field_value(field, value)

    def _get_field_value(self, field, value):
        field = mstr(field)
        if not is_private_field(field):
            if field in primary_keys:
                field = self._meta.pkname()
            if field in self._meta.dfields:
                f = self._meta.dfields[field]
                value = f.get_value(self, value)
                field = f.store_name
            if self._modified is not None:
                self._access_cache.discard(field)
                if field in self:
                    if super(Model, self).__getitem__(field) != value:
                        self._modified.add(field)
                else:
                    self._modified.add(field)
        return field, value

    @classmethod
    def _many2many_through_model(cls, field):
        field.relmodel = cls
        if not field.related_name:
            field.related_name = '%s_set' % field.model._meta.name
        name_model = field.model._meta.name
        name_relmodel = field.relmodel._meta.name
        # The two models are the same.
        if name_model == name_relmodel:
            name_relmodel += '2'
        through = field.through
        # Create the through model
        if through is None:
            name = '{0}_{1}'.format(name_model, name_relmodel)

            class Meta:
                app_label = field.model._meta.app_label
            through = ModelType(name, (StdModel,), {'Meta': Meta})
            field.through = through
        # The first field
        field1 = ForeignKey(field.model,
                            related_name=field.name,
                            related_manager_class=makeManyToManyRelatedManager(
                                field.relmodel,
                                name_model,
                                name_relmodel)
                            )
        field1.register_with_model(name_model, through)
        # The second field
        field2 = ForeignKey(field.relmodel,
                            related_name=field.related_name,
                            related_manager_class=makeManyToManyRelatedManager(
                                field.model,
                                name_relmodel,
                                name_model)
                            )
        field2.register_with_model(name_relmodel, through)
        pk = CompositeIdField(name_model, name_relmodel)
        pk.register_with_model('id', through)


PyModel = Model


def create_model(name, **params):
    '''Create a :class:`.Model` class.

    :param name: Name of the model class.
    :param params: key-valued parameter to pass to the :class:`ModelMeta`
        constructor.
    :return: a local :class:`Model` class.
    '''
    return ModelType(name, (Model,), params)


if ispy3k:
    def mstr(s):
        if isinstance(s, bytes):
            return s.decode('utf-8')
        elif not isinstance(s, str):
            return str(s)
        else:
            return s

else:
    def mstr(s):
        if isinstance(s, (bytes, unicode)):
            return s
        else:
            return str(s)

########NEW FILE########
__FILENAME__ = query
from collections import namedtuple

from pulsar import wait_complete
from pulsar.utils.pep import to_string, iteritems


def int_or_float(v):
    v = float(v)
    i = int(v)
    return i if v == i else v


JSPLITTER = '__'
pass_through = lambda x: x
str_lower_case = lambda x: to_string(x).lower()
range_lookups = {
    'gt': int_or_float,
    'ge': int_or_float,
    'lt': int_or_float,
    'le': int_or_float,
    'contains': pass_through,
    'startswith': pass_through,
    'endswith': pass_through,
    'icontains': str_lower_case,
    'istartswith': str_lower_case,
    'iendswith': str_lower_case}

lookup_value = namedtuple('lookup_value', 'type value')


class OdmError(Exception):
    pass


class QueryError(OdmError):
    pass


class ModelNotFound(QueryError):
    '''Raised when a :meth:`.Manager.get` method does not find any model
    '''
    pass


class AbstractQuery(object):
    _meta = None

    def filter(self, **kwargs):
        raise NotImplementedError

    def exclude(self, **kwargs):
        raise NotImplementedError

    def union(self, *queries):
        raise NotImplementedError

    def intersect(self, *queries):
        raise NotImplementedError

    def where(self, *expressions):
        raise NotImplementedError

    def count(self):
        raise NotImplementedError

    def all(self):
        raise NotImplementedError


def query_op(f):
    '''Decorator for a :class:`Query` operation.
    '''
    name = f.__name__

    def _(self, *args, **kwargs):
        if self._store.has_query(name):
            q = self._clone()
            return f(q, *args, **kwargs)
        else:
            raise QueryError('Cannot use "%s" query with %s' %
                             (name, self._store))

    _.__doc__ = f.__doc__
    _.__name__ = name
    return _


def update_dict(a, b):
    if a is None:
        a = {}
    a.update(b)
    return a


def update_tuple(a, b):
    if a is None:
        a = ()
    return a + b


class Query(object):
    '''A query for data in a model store.

    A :class:`Query` is produced in terms of a given :class:`.Manager`,
    using the :meth:`~.Manager.query` method.
    '''
    _filters = None
    _joins = None
    _excludes = None
    _unions = None
    _intersections = None
    _where = None
    _compiled = None

    def __init__(self, manager, store=None):
        self._manager = manager
        self._store = store or manager._read_store

    @property
    def _meta(self):
        return self._manager._meta

    @property
    def _mapper(self):
        return self._manager._mapper

    @property
    def _loop(self):
        return self._store._loop

    @query_op
    def filter(self, **kwargs):
        '''Create a new :class:`Query` with additional clauses.

        The clauses corresponds to ``where`` or ``limit`` in a
        ``SQL SELECT`` statement.

        :params kwargs: dictionary of limiting clauses.

        For example::

            qs = manager.query().filter(group='planet')
        '''
        if kwargs:
            self._filters = update_dict(self._filters, kwargs)
        return self

    @query_op
    def exclude(self, **kwargs):
        '''Create a new :class:`Query` with additional clauses.

        The clauses correspond to ``EXCEPT`` in a ``SQL SELECT`` statement.

        Using an equivalent example to the :meth:`filter` method::

            qs = manager.query()
            result1 = qs.exclude(group='planet')
            result2 = qs.exclude(group=('planet','stars'))

        '''
        if kwargs:
            self._excludes = update_dict(self._excludes, kwargs)
        return self

    @query_op
    def union(self, *queries):
        '''Create a new :class:`Query` obtained form unions.

        :param queries: positional :class:`Query` parameters to create an
            union with.
        For example, lets say we want to have the union
        of two queries obtained from the :meth:`filter` method::

            query = mymanager.query()
            qs = query.filter(field1='bla').union(query.filter(field2='foo'))
        '''
        if queries:
            self._unions = update(self._unions, queries)
        return self

    @query_op
    def intersect(self, *queries):
        '''Create a new :class:`Query` obtained form intersection.

        :param queries: positional :class:`Query` parameters to create an
            intersection with.
        For example, lets say we want to have the intersection
        of two queries obtained from the :meth:`filter` method::

            query = mymanager.query()
            q1 = query.filter(field2='foo')
            qs = query.filter(field1='bla').intersect(q1)
        '''
        if queries:
            self._intersections = update(self._intersections, queries)
        return self

    @query_op
    def where(self, *expressions):
        if expressions:
            self._where = update(self._where, expressions)
        return self

    @query_op
    def join(self):
        raise NotImplementedError

    def load_related(self, related, *fields):
        '''It returns a new :class:`Query` that automatically
        follows the foreign-key relationship ``related``'''
        return self

    @wait_complete
    def count(self):
        '''Count the number of objects selected by this :class:`Query`.

        This method is efficient since the :class:`Query` does not
        receive any data from the server apart from the number of
        matched elements.'''
        return self.compiled().count()

    @wait_complete
    def all(self):
        '''All objects selected by this :class:`Query`.
        '''
        return self.compiled().all()

    @wait_complete
    def delete(self):
        '''Delete all objects selected by this :class:`.Query`.
        '''
        return self.compiled().delete()

    # INTERNALS
    def compiled(self):
        if not self._compiled:
            self._compiled = self._manager._read_store.compile_query(self)
        return self._compiled

    def _clone(self):
        cls = self.__class__
        q = cls.__new__(cls)
        d = q.__dict__
        for name, value in self.__dict__.items():
            if name not in ('_compiled',):
                if isinstance(value, (list, dict)):
                    value = copy(value)
                d[name] = value
        return q


class CompiledQuery(object):
    '''A signature class for implementing a :class:`.Query` in a
    pulsar data :class:`.Store`.

    .. attribute:: _query

        The underlying :class:`.Query`

    .. attribute:: _store

        The :class:`.Store` executing the :attr:`query`
    '''
    def __init__(self, store, query):
        self._store = store
        self._query = query
        self._build()

    @property
    def _meta(self):
        return self._query._meta

    @property
    def _manager(self):
        return self._query._manager

    @property
    def _mapper(self):
        return self._query._mapper

    def count(self):
        '''Count the number of elements matching the :attr:`query`.
        '''
        raise NotImplementedError

    def all(self):
        '''Fetch all matching elements from the server.

        Return a :class:`~asyncio.Future`
        '''
        raise NotImplementedError

    def delete(self):
        '''Delete all matching elements from the server.

        Return a :class:`~asyncio.Future`
        '''
        raise NotImplementedError

    def models(self, data):
        '''Build a list of models from a list of dictionaries.

        Uses the :meth:`.Store.build_model` method

        :param data: list of dictionaries
        :return: a list of models
        '''
        build = self._store.build_model
        manager = self._manager
        return [build(manager, params) for params in data]

    def _build(self):
        '''Compile the :attr:`query`
        '''
        raise NotImplementedError

    def aggregate(self, kwargs):
        '''Aggregate lookup parameters.'''
        meta = self._meta
        store = self._store
        fields = meta.dfields
        field_lookups = {}
        for name, value in iteritems(kwargs):
            bits = name.split(JSPLITTER)
            field_name = bits.pop(0)
            if field_name not in fields:
                raise QueryError(('Could not filter on model "%s". Field '
                                  '"%s" does not exist.' % (meta, field_name)))
            field = fields[field_name]
            store_name = field.store_name
            lookup = None
            if bits:
                bits = [n.lower() for n in bits]
                if bits[-1] == 'in':
                    bits.pop()
                elif bits[-1] in range_lookups:
                    lookup = bits.pop()
                remaining = JSPLITTER.join(bits)
                if lookup:  # this is a range lookup
                    store_name, nested = field.get_lookup(remaining,
                                                          QueryError)
                    lookups = get_lookups(store_name, field_lookups)
                    lookups.append(lookup_value(lookup, (value, nested)))
                    continue
                elif remaining:   # Not a range lookup, must be a nested filter
                    value = field.filter(self.session, remaining, value)
            lookups = get_lookups(store_name, field_lookups)
            if not isinstance(value, (list, tuple, set)):
                value = (value,)
            for v in value:
                if isinstance(v, Query):
                    v = lookup_value('query', v.compiled())
                else:
                    v = lookup_value('value', field.to_store(v, store))
                lookups.append(v)
            return field_lookups


def get_lookups(store_name, field_lookups):
    lookups = field_lookups.get(store_name)
    if lookups is None:
        lookups = []
        field_lookups[store_name] = lookups
    return lookups

########NEW FILE########
__FILENAME__ = searchengine
from pulsar import get_event_loop, new_event_loop
from pulsar.apps.data import Store, parse_store_url
from pulsar.utils.exceptions import ImproperlyConfigured, InvalidOperation
from pulsar.utils.importer import module_attribute


search_engines = {}


class IndexTransaction(object):
    __slots__ = ('_engine', '_items', '_executed')

    def __init__(self, engine):
        self._engine = engine
        self._items = []
        self._executed = None

    def add(self, model):
        self._items.append(model)

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        if type is None:
            self.commit()

    def commit(self):
        if self._executed is None:
            self._executed = self.engine.upload(self._items)
            return self._executed
        else:
            raise InvalidOperation('Transaction already executed.')


class SearchEngine(Store):
    '''Interface class for a full text search engine
    '''
    _mapper = None

    def set_mapper(self, mapper):
        '''Set the :class:`.Mapper` for this search engine.
        '''
        self._mapper = mapper
        mapper.bind_event('post_commit', self.index_model)
        mapper.bind_event('post_delete', self.deindex_model)

    def begin(self):
        return IndexTransaction(self)

    def upload(self, items):
        '''Upload items to the search engine'''
        raise NotImplementedError

    def index_model(self, *args, **kw):
        pass

    def deindex_model(self, *args, **kw):
        pass

    def create_table(self, manager):
        '''Invoked when a :class:`.Manager` creates the data store tables.

        By default it does nothing, some search engine implementation
        may need to do something here
        '''


def register_searchengine(name, engine_class):
    search_engines[name] = engine_class


def search_engine(url, loop=None, **kw):
    if isinstance(url, SearchEngine):
        return url
    if isinstance(url, dict):
        extra = url.copy()
        url = extra.pop('url', None)
        extra.update(kw)
        kw = extra
    scheme, address, params = parse_store_url(url)
    dotted_path = search_engines.get(scheme)
    if not dotted_path:
        raise ImproperlyConfigured('%s search engine not available' % scheme)
    loop = loop or get_event_loop()
    if not loop:
        loop = new_event_loop(logger=logging.getLogger(dotted_path))
    engine_class = module_attribute(dotted_path)
    params.update(kw)
    return engine_class(scheme, address, loop, **params)

########NEW FILE########
__FILENAME__ = transaction
from pulsar import (EventHandler, coroutine_return, InvalidOperation,
                    chain_future, multi_async)
from pulsar.utils.pep import iteritems

from .model import Model

from ..store import Command


class ModelDictionary(dict):

    def __contains__(self, model):
        return super(ModelDictionary, self).__contains__(self.meta(model))

    def __getitem__(self, model):
        return super(ModelDictionary, self).__getitem__(self.meta(model))

    def __setitem__(self, model, value):
        super(ModelDictionary, self).__setitem__(self.meta(model), value)

    def get(self, model, default=None):
        return super(ModelDictionary, self).get(self.meta(model), default)

    def pop(self, model, *args):
        return super(ModelDictionary, self).pop(self.meta(model), *args)

    def meta(self, model):
        return getattr(model, '_meta', model)


class TransactionStore(object):
    '''Transaction for a given :class:`.Store`
    '''
    def __init__(self, store):
        self._store = store
        self.commands = []


class Transaction(EventHandler):
    '''Transaction class for pipelining commands to a :class:`.Store`.

    A :class:`Transaction` is usually obtained via the :meth:`.Mapper.begin`
    method::

        t = models.begin()

    or using the ``with`` context manager::

        with models.begin() as t:
            ...

    .. attribute:: name

        Optional :class:`Transaction` name

    .. attribute:: mapper

        the :class:`.Mapper` which initialised this transaction.

    .. attribute:: _commands

        dictionary of commands for each :class:`.Store` in this transaction.

    .. attribute:: deleted

        Dictionary of list of ids deleted from the backend server after a
        commit operation. This dictionary is only available once the
        transaction has :attr:`finished`.

    .. attribute:: saved

        Dictionary of list of ids saved in the backend server after a commit
        operation. This dictionary is only available once the transaction has
        :attr:`finished`.
    '''
    MANY_TIMES_EVENTS = ('pre_commit', 'pre_delete',
                         'post_commit', 'post_delete')

    def __init__(self, mapper, name=None):
        super(Transaction, self).__init__()
        self._loop = mapper._loop
        self.name = name or 'transaction'
        self.mapper = mapper
        self._commands = {}
        self._executed = None
        self.copy_many_times_events(mapper)

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        if type is None:
            self.commit()

    def execute(self, *args, **kw):
        '''Queue a command in the default data store.

        This method does not use the object data mapper.
        '''
        ts = self.tstore(kw.get('store') or self.mapper._default_store)
        ts.commands.append(Command(args))
        return self

    def add(self, model, action=None):
        '''Add a ``model`` to the transaction.

        :param model: a :class:`.Model` instance. It must be registered
            with the :attr:`mapper` which created this :class:`Transaction`.
        :param action: Optional CRUD action to perform
        :return: the ``model``.
        '''
        manager = self.mapper[model]
        ts = self.tstore(manager._store)
        if not action:
            if '_rev' in model:
                action = Command.UPDATE
            else:
                action = Command.INSERT
        ts.commands.append(Command(model, action))
        return model

    def update(self, instance_or_query, **kw):
        '''Update an ``instance`` or a ``query``'''
        if isinstance(instance_or_query, Model):
            pkvalue = instance_or_query.id
            data = dict(instance_or_query)
            data.update(kw)
        manager = self.mapper[model]
        store = manager._store
        if store not in self._commands:
            self._commands[store] = []
        self._commands[store].append(Command(instance_or_query,
                                             Command.UPDATE))

    def tstore(self, store):
        '''Returns the :class:`TransactionStore` for ``store``
        '''
        if store not in self._commands:
            self._commands[store] = TransactionStore(store)
        return self._commands[store]

    def commit(self):
        '''Commit the transaction.

        This method can be invoked once only otherwise an
        :class:`.InvalidOperation` occurs.

        :return: a :class:`~asyncio.Future` which results in the list
            of  transaction
        '''
        if self._executed is None:
            executed = dict(((store, store.execute_transaction(commands)) for
                             store, commands in iteritems(self._commands)))
            self._executed = multi_async(executed, loop=self._loop)
            return self._executed
        else:
            raise InvalidOperation('Transaction already executed.')

    def wait(self, callback=None):
        '''Waits for the transaction have finished.

        :param callback: optional function called back once the transaction
            has finished. The function receives one parameter only, the
            transaction.
        :return: a :class:`~asyncio.Future`
        '''
        if self._executed is None:
            self.commit()
        if callback:
            return chain_future(self._executed, callback)
        else:
            return self._executed

########NEW FILE########
__FILENAME__ = store
'''
Tha main component for pulsar datastore clients is the :class:`.Store`
class which encapsulates the essential API for communicating and executing
commands on remote servers.
A :class:`.Store` can also implement several methods for managing
the higher level :ref:`object data mapper <odm>`.
'''
import logging
import socket
from functools import partial

from pulsar import (get_event_loop, ImproperlyConfigured, Pool, new_event_loop,
                    coroutine_return, get_application, in_loop, send,
                    EventHandler, Producer)
from pulsar.utils.importer import module_attribute
from pulsar.utils.pep import to_string
from pulsar.utils.system import json
from pulsar.utils.httpurl import urlsplit, parse_qsl, urlunparse, urlencode

__all__ = ['Command',
           'Store',
           'Compiler',
           'PubSub',
           'PubSubClient',
           'parse_store_url',
           'create_store',
           'register_store',
           'data_stores']

data_stores = {}


class Command(object):
    '''A command executed during a in a :meth:`~.Store.execute_transaction`

    .. attribute:: action

        Type of action:
        * 0 custom command
        * 1 equivalent to an SQL INSERT
        * 2 equivalent to an SQL DELETE
    '''
    __slots__ = ('args', 'action')
    INSERT = 1
    UPDATE = 2
    DELETE = 3

    def __init__(self, args, action=0):
        self.args = args
        self.action = action

    @classmethod
    def insert(cls, args):
        return cls(args, cls.INSERT)


class Compiler(object):
    '''Interface for :class:`Store` compilers.
    '''
    def __init__(self, store):
        self.store = store

    def compile_query(self, query):
        raise NotImplementedError

    def create_table(self, model_class):
        raise NotImplementedError


class Store(Producer):
    '''Base class for an asynchronous :ref:`data stores <data-stores>`.

    It is an :class:`.Producer` for accessing and retrieving
    data from remote data servers such as redis, couchdb and so forth.
    A :class:`Store` should not be created directly, the high level
    :func:`.create_store` function should be used instead.

    .. attribute:: _host

        The remote host, tuple or string

    .. attribute:: _user

        The user name

    .. attribute:: _password

        The user password
    '''
    _scheme = None
    compiler_class = None
    default_manager = None
    MANY_TIMES_EVENTS = ('request',)

    def __init__(self, name, host, loop, database=None,
                 user=None, password=None, encoding=None, **kw):
        super(Producer, self).__init__()
        self._name = name
        self._host = host
        self._loop = loop
        self._encoding = encoding or 'utf-8'
        self._database = database
        self._user = user
        self._password = password
        self._urlparams = {}
        self._init(**kw)
        self._dns = self._buildurl()

    @property
    def name(self):
        '''Store name'''
        return self._name

    @property
    def database(self):
        '''Database name/number associated with this store.'''
        return self._database

    @property
    def encoding(self):
        '''Store encoding (usually ``utf-8``)
        '''
        return self._encoding

    @property
    def dns(self):
        '''Domain name server'''
        return self._dns

    def __repr__(self):
        return 'Store(dns="%s")' % self._dns
    __str__ = __repr__

    def connect(self):
        '''Connect with store server
        '''
        raise NotImplementedError

    def execute(self, *args, **options):
        '''Execute a command
        '''
        raise NotImplementedError

    def ping(self):
        '''Used to check if the data server is available
        '''
        raise NotImplementedError

    def client(self):
        '''Get a client for the Store if implemented
        '''
        raise NotImplementedError

    def pubsub(self, **kw):
        '''Obtain a :class:`PubSub` handler for the Store if implemented
        '''
        raise NotImplementedError

    def create_database(self, dbname, **kw):
        '''Create a new database in this store

        By default it does nothing, stores must implement this method
        only if they support database creation.
        '''
        raise NotImplementedError

    def close(self):
        '''Close all open connections
        '''
        raise NotImplementedError

    def flush(self):
        '''Flush the store.'''
        raise NotImplementedError

    # encode/decode field values
    def encode_bytes(self, data):
        '''Encode bytes ``data``

        :param data: a bytes string
        :return: bytes or string
        '''
        return data

    def dencode_bytes(self, data):
        '''Decode bytes ``data``

        :param data: bytes or string
        :return: bytes
        '''
        return data

    def encode_bool(self, data):
        return bool(data)

    def encode_json(self, data):
        return data

    #    ODM SUPPORT
    #######################
    def create_table(self, model, remove_existing=False):
        '''Create the table for ``model``.

        This method is used by the :ref:`object data mapper <odm>`.
        By default it does nothing.
        '''

    def drop_table(self, model, remove_existing=False):
        '''Drop the table for ``model``.

        This method is used by the :ref:`object data mapper <odm>`.
        Must be implemented.
        '''
        raise NotImplementedError

    def table_info(self, model):
        '''Information about the table/collection mapping ``model``
        '''
        pass

    def execute_transaction(self, commands):
        '''Execute a list of ``commands`` in a :class:`.Transaction`.

        This method is used by the :ref:`object data mapper <odm>`.
        '''
        raise NotImplementedError

    def compile_query(self, query):
        '''Compile the :class:`.Query` ``query``.

        Method required by the :class:`Object data mapper <odm>`.

        :return: an instance of :class:`.CompiledQuery` if implemented
        '''
        raise NotImplementedError

    def get_model(self, manager, pkvalue):
        '''Fetch an instance of a ``model`` with primary key ``pkvalue``.

        This method required by the :ref:`object data mapper <odm>`.

        :param manager: the :class:`.Manager` calling this method
        :param pkvalue: the primary key of the model to retrieve
        '''
        raise NotImplementedError

    def has_query(self, query_type):
        '''Check if this :class:`.Store` supports ``query_type``.

        :param query_type: a string indicating the query type to check
            (``filter``, ``exclude``, ``search``).

        This method is used by the :ref:`object data mapper <odm>`.
        '''
        return True

    def build_model(self, manager, *args, **kwargs):
        instance = manager(*args, **kwargs)
        instance['_store'] = self
        return instance

    def model_data(self, model, action):
        '''A generator of field/value pair for the store
        '''
        fields = model._meta.dfields
        for key, value in model.items():
            if key in fields:
                value = fields[key].to_store(value, self)
            if value is not None:
                yield key, value

    def model_data(self, model, action):
        '''Generator of ``field, value`` pair for the data store.

        By default invokes the :class:`.ModelMeta.store_data` method.'''
        return model._meta.store_data(model, self, action)

    #    INTERNALS
    #######################
    def _init(self, **kw):  # pragma    nocover
        '''Internal initialisation'''
        pass

    def _buildurl(self):
        pre = ''
        if self._user:
            if not self._password:
                raise ImproperlyConfigured('user but not password')
            pre = '%s:%s@' % (self._user, self._password)
        elif self._password:
            raise ImproperlyConfigured('password but not user')
            assert self._password
        host = self._host
        if isinstance(host, tuple):
            host = '%s:%s' % host
        host = '%s%s' % (pre, host)
        path = '/%s' % self._database if self._database else ''
        query = urlencode(self._urlparams)
        scheme = self._name
        if self._scheme:
            scheme = '%s+%s' % (self._scheme, scheme)
        return urlunparse((scheme, host, path, '', query, ''))

    def _build_pool(self):
        return Pool


class PubSubClient(object):
    '''Interface for a client of :class:`PubSub` handler.

    Instances of this :class:`Client` are callable object and are
    called once a new message has arrived from a subscribed channel.
    The callable accepts two parameters:

    * ``channel`` the channel which originated the message
    * ``message`` the message
    '''
    def __call__(self, channel, message):
        raise NotImplementedError


class PubSub(object):
    '''A Publish/Subscriber interface.

    A :class:`PubSub` handler is never initialised directly, instead,
    the :meth:`~Store.pubsub` method of a data :class:`.Store`
    is used.

    To listen for messages one adds clients to the handler::

        def do_somethind(channel, message):
            ...

        pubsub = client.pubsub()
        pubsub.add_client(do_somethind)
        pubsub.subscribe('mychannel')

    You can add as many listening clients as you like. Clients are functions
    which receive two parameters only, the ``channel`` sending the message
    and the ``message``.

    A :class:`PubSub` handler can be used to publish messages too::

        pubsub.publish('mychannel', 'Hello')

    An additional ``protocol`` object can be supplied. The protocol must
    implement the ``encode`` and ``decode`` methods.
    '''

    def __init__(self, store, protocol=None):
        super(PubSub, self).__init__()
        self.store = store
        self._loop = store._loop
        self._protocol = protocol
        self._connection = None
        self._clients = set()

    def publish(self, channel, message):
        '''Publish a new ``message`` to a ``channel``.
        '''
        raise NotImplementedError

    def count(self, *channels):
        '''Returns the number of subscribers (not counting clients
        subscribed to patterns) for the specified channels.
        '''
        raise NotImplementedError

    def channels(self, pattern=None):
        '''Lists the currently active channels.

        An active channel is a Pub/Sub channel with one ore more subscribers
        (not including clients subscribed to patterns).
        If no ``pattern`` is specified, all the channels are listed,
        otherwise if ``pattern`` is specified only channels matching the
        specified glob-style pattern are listed.
        '''
        raise NotImplementedError

    def psubscribe(self, pattern, *patterns):
        '''Subscribe to a list of ``patterns``.
        '''
        raise NotImplementedError

    def punsubscribe(self, *channels):
        '''Unsubscribe from a list of ``patterns``.
        '''
        raise NotImplementedError

    def subscribe(self, channel, *channels):
        '''Subscribe to a list of ``channels``.
        '''
        raise NotImplementedError

    def unsubscribe(self, *channels):
        '''Un-subscribe from a list of ``channels``.
        '''
        raise NotImplementedError

    def close(self):
        '''Stop listening for messages.
        '''
        raise NotImplementedError

    def add_client(self, client):
        '''Add a new ``client`` to the set of all :attr:`clients`.

        Clients must be callable accepting two parameters, the channel and
        the message. When a new message is received
        from the publisher, the :meth:`broadcast` method will notify all
        :attr:`clients` via the ``callable`` method.'''
        self._clients.add(client)

    def remove_client(self, client):
        '''Remove *client* from the set of all :attr:`clients`.'''
        self._clients.discard(client)

    # INTERNALS
    def broadcast(self, response):
        '''Broadcast ``message`` to all :attr:`clients`.'''
        remove = set()
        channel = to_string(response[0])
        message = response[1]
        if self._protocol:
            message = self._protocol.decode(message)
        for client in self._clients:
            try:
                client(channel, message)
            except IOError:
                remove.add(client)
            except Exception:
                self._loop.logger.exception(
                    'Exception while processing pub/sub client. Removing it.')
                remove.add(client)
        self._clients.difference_update(remove)


def parse_store_url(url):
    assert url, 'No url given'
    scheme, host, path, query, fr = urlsplit(url)
    assert not fr, 'store url must not have fragment, found %s' % fr
    assert scheme, 'Scheme not provided'
    # pulsar://
    if scheme == 'pulsar' and not host:
        host = '127.0.0.1:0'
    bits = host.split('@')
    assert len(bits) <= 2, 'Too many @ in %s' % url
    params = dict(parse_qsl(query))
    if path:
        database = path[1:]
        assert '/' not in database, 'Unsupported database %s' % database
        params['database'] = database
    if len(bits) == 2:
        userpass, host = bits
        userpass = userpass.split(':')
        assert len(userpass) == 2,\
            'User and password not in user:password format'
        params['user'] = userpass[0]
        params['password'] = userpass[1]
    else:
        user, password = None, None
    if ':' in host:
        host = tuple(host.split(':'))
        host = host[0], int(host[1])
    return scheme, host, params


def create_store(url, loop=None, **kw):
    '''Create a new client :class:`Store` for a valid ``url``.

    A valid ``url`` takes the following forms:

    :ref:`Pulsar datastore <store_pulsar>`::

        pulsar://user:password@127.0.0.1:6410

    :ref:`Redis <store_redis>`::

        redis://user:password@127.0.0.1:6500/11?namespace=testdb

    :ref:`CouchDb <store_couchdb>`::

        couchdb://user:password@127.0.0.1:6500/testdb
        https+couchdb://user:password@127.0.0.1:6500/testdb

    :param loop: optional event loop, obtained by
        :func:`~asyncio.get_event_loop` if not provided.
        To create a synchronous client pass a new event loop created via
        the :func:`~asyncio.new_event_loop`.
        In the latter case the event loop is employed only for synchronous
        type requests via the :meth:`~asyncio.BaseEventLoop.run_until_complete`
        method.
    :param kw: additional key-valued parameters to pass to the :class:`.Store`
        initialisation method. These parameters are processed by the
        :meth:`.Store._init` method.
    :return: a :class:`Store`.
    '''
    if isinstance(url, Store):
        return url
    scheme, address, params = parse_store_url(url)
    dotted_path = data_stores.get(scheme)
    if not dotted_path:
        raise ImproperlyConfigured('%s store not available' % scheme)
    loop = loop or get_event_loop()
    if not loop:
        loop = new_event_loop(logger=logging.getLogger(dotted_path))
    store_class = module_attribute(dotted_path)
    params.update(kw)
    return store_class(scheme, address, loop, **params)


def register_store(name, dotted_path):
    '''Register a new :class:`.Store` with schema ``name`` which
    can be found at the python ``dotted_path``.
    '''
    data_stores[name] = dotted_path

########NEW FILE########
__FILENAME__ = query
from pulsar import coroutine_return
from pulsar.apps.http import HttpClient
from pulsar.apps.data import odm


DEFAULT_HEADERS = {'Accept': 'application/json, text/plain; q=0.8',
                   'content-type': 'application/json'}


class CouchDbError(Exception):

    def __init__(self, error, reason):
        self.error = error
        super(CouchDbError, self).__init__(reason)


class CouchDbNoDbError(CouchDbError):
    pass


class CouchDbNoViewError(CouchDbError):
    pass


error_classes = {'no_db_file': CouchDbNoDbError,
                 'missing_named_view': CouchDbNoViewError}


def couch_db_error(error=None, reason=None, **params):
    error_class = error_classes.get(reason, CouchDbError)
    raise error_class(error, reason)


class CouchDBMixin(object):

    def _init(self, headers=None, namespace=None, **kw):
        if not self._database:
            self._database = namespace or 'defaultdb'
        elif namespace:
            self._database = '%s_%s' % (self._database, namespace)
        bits = self._name.split('+')
        if len(bits) == 2:
            self._scheme = bits[0]
            self._name = bits[1]
        else:
            self._scheme = 'http'
        host = self._host
        if isinstance(host, tuple):
            host = '%s:%s' % host
        self._address = '%s://%s' % (self._scheme, host)
        self.headers = DEFAULT_HEADERS.copy()
        if headers:
            self.headers.update(headers)
        self._http = HttpClient(loop=self._loop, **kw)


class CauchDbQuery(odm.CompiledQuery):
    '''Implements the CompiledQuery for couchdb
    '''
    def _build(self):
        self.aggregated = None
        query = self._query
        if query._excludes:
            raise NotImplementedError
        if query._filters:
            self.aggregated = self.aggregate(query._filters)

    def count(self):
        return self._query_view(group=bool(self.aggregated))

    def all(self):
        return self._query_view(include_docs=True, reduce=False)

    def delete(self):
        return self._query_view(self._delete, reduce=False)

    def _query_view(self, callback=None, reduce=True, query_type=None, **kw):
        view = self._store.query_model_view
        keys = None
        if self.aggregated:
            view_name = None
            for field, lookups in self.aggregated.items():
                keys = []
                for lookup in lookups:
                    if lookup.type == 'value':
                        keys.append(lookup.value)
                    else:
                        raise NotImplementedError
                if view_name:
                    raise NotImplementedError
                else:
                    view_name = field
        else:
            view_name = 'id'

        if query_type:
            view_name = '%s_%s' % (view_name, query_type)
        kw['keys'] = keys
        try:
            result = yield view(self._meta, view_name, reduce=reduce, **kw)
        except CouchDbNoViewError:
            raise odm.QueryError('Couchdb view for %s not available for %s' %
                                 (view_name, self._meta))
        if callback:
            query = yield callback(result)
        elif reduce:
            query = sum((q['value'] for q in result['rows']))
        else:
            query = self.models((q['doc'] for q in result['rows']))
        coroutine_return(query)

    def _delete(self, result):
        docs = [{'_id': r['id'], '_rev': r['value'], '_deleted': True} for
                r in result['rows']]
        return self._store.update_documents(self._store._database, docs)

########NEW FILE########
__FILENAME__ = search
from pulsar.apps.data import odm
from pulsar.utils.system import json
from pulsar.apps.http import HttpClient

from .query import CouchDBMixin


def index_script(name, field):
    return "if (doc.{1}) index('{0}', doc.{1});".format(name, field)


class CouchDBLuceneSearch(CouchDBMixin, odm.SearchEngine):
    '''Search engine for CouchDB+Lucene'''
    def search(self):
        pass

    def upload(self, items):
        pass

    def create_table(self, manager):
        store = manager._read_store
        if store.dns == self.dns:
            name = manager._meta.table_name
            indexes = self._create_indexes(manager)
            if indexes:
                doc = yield store.request('get', store._database,
                                          '_design', name)
                doc['indexes'] = indexes
                response = yield store.update_document(doc)

    def _create_indexes(self, manager):
        defaults = ["function (doc) {"]
        search = {}
        for index in manager._meta.dfields.values():
            if index.repr_type == 'text':
                defaults.append(index_script('default', index.store_name))
        if len(defaults) > 1:
            defaults.append("};")
            search['default'] = {'index': '\n'.join(defaults)}
        return search

    def _init(self, headers=None, doc_url=None, **kw):
        bits = self._name.split('+')
        if len(bits) == 2:
            self._scheme = bits[0]
            self._name = bits[1]
        else:
            self._scheme = 'http'
        host = self._host
        if isinstance(host, tuple):
            host = '%s:%s' % host
        self._address = '%s://%s' % (self._scheme, host)
        self._http = HttpClient(loop=self._loop, **kw)


loc = 'pulsar.apps.data.stores.CouchDBLuceneSearch'
odm.register_searchengine('https+couchdb', loc)
odm.register_searchengine('http+couchdb', loc)
odm.register_searchengine('couchdb', loc)

########NEW FILE########
__FILENAME__ = store
'''CouchDB_ document store::

    store = create_store('http+couchdb://localhost:5984/mydb')


Models
=========

A :class:`.Model` is stored as a document in the store database, this
means instances of different models which use the same couchdb store
are stored in exactly the same database.

To differentiate and query over different types of models, the
``Type`` field is added to the document representing a model.

Queries
===========

Search
==========

https://github.com/rnewson/couchdb-lucene

CouchDBStore
=================

.. autoclass:: CouchDBStore
   :members:
   :member-order: bysource


.. _CouchDB: http://couchdb.apache.org/
'''
from base64 import b64encode, b64decode
from asyncio import Lock

from pulsar import coroutine_return, wait_complete, multi_async
from pulsar.utils.system import json
from pulsar.apps.data import Store, Command, register_store
from pulsar.utils.pep import zip

from pulsar.apps.data import odm

from .query import CauchDbQuery, CouchDbError, couch_db_error, CouchDBMixin


index_view = '''function (doc) {{
    if(doc.Type == '{0}' && doc.{1} !== undefined) emit(doc.{1}, doc._rev);
}};
'''


class CouchDBStore(CouchDBMixin, Store):
    _lock = None

    @property
    def scheme(self):
        return self._scheme

    # COUCHDB operation
    def info(self):
        '''Information about the running server
        '''
        return self.request('get')
    ping = info

    # DATABASE OPERATIONS
    def create_database(self, dbname=None, **kw):
        '''Create a new database

        :param dbname: optional database name. If not provided
            the :attr:`~Store._database` is created instead.
        '''
        return self.request('put', dbname or self._database)

    def delete_database(self, dbname=None):
        '''Delete a database ``dbname``
        '''
        return self.request('delete', dbname or self._database)

    def all_databases(self):
        '''The list of all databases
        '''
        return self.request('get', '_all_dbs')

    # DESIGN VIEWS
    def design_create(self, name, views, language=None, **kwargs):
        '''Create a new design document
        '''
        return self.request('put', self._database, '_design', name,
                            views=views,
                            language=language or 'javascript', **kwargs)

    @wait_complete
    def design_delete(self, name):
        '''Delete an existing design document at ``name``.
        '''
        response = yield self.request('head', self._database, '_design', name)
        if response.status_code == 200:
            rev = json.loads(response.headers['etag'])
            yield self.request('delete', self._database, '_design', name,
                               rev=rev)

    def design_info(self, name):
        return self.request('get', self._database, '_design', name, '_info')

    # DOCUMENTS
    def update_document(self, document):
        return self.request('post', self._database, **document)

    def update_documents(self, dbname, documents, new_edits=True):
        '''Bulk update/insert of documents in a database
        '''
        return self.request('post', dbname, '_bulk_docs', docs=documents,
                            new_edits=new_edits)

    # ODM
    def create_table(self, model, remove_existing=False):
        # Build views
        meta = model._meta
        table = meta.table_name
        if remove_existing:
            yield self.design_delete(table)
        views = {}
        for index in meta.indexes:
            name = key = index.store_name
            if index.primary_key:
                name = 'id'
                key = '_id'
            views[name] = {'map': index_view.format(table, key),
                           'reduce': '_count'}
        result = yield self.design_create(table, views)
        coroutine_return(result)

    def drop_table(self, model):
        '''Drop model table by simply removing model design views'''
        return self.design_delete(model._meta.table_name)

    def table_info(self, model):
        return self.design_info(model._meta.table_name)

    def execute_transaction(self, transaction):
        '''Execute a ``transaction``
        '''
        updates = []
        models = []
        for command in transaction.commands:
            action = command.action
            if not action:
                raise NotImplementedError
            else:
                model = command.args
                updates.append(dict(self.model_data(model, action)))
                models.append(model)
        #
        if updates:
            executed = yield self.update_documents(self._database, updates)
            errors = []
            for doc, model in zip(executed, models):
                if doc.get('ok'):
                    model['id'] = doc['id']
                    model['_rev'] = doc['rev']
                    model._modified.clear()
                elif doc.get('error'):
                    errors.append(CouchDbError(doc['error'], doc['reason']))
            if errors:
                raise errors[0]

    @wait_complete
    def get_model(self, manager, pkvalue):
        try:
            data = yield self.request('get', self._database, pkvalue)
        except CouchDbError:
            raise odm.ModelNotFound(pkvalue)
        else:
            coroutine_return(self.build_model(manager, data))

    def query_model_view(self, model, view_name, key=None, keys=None,
                         group=None, limit=None, include_docs=None,
                         reduce=True, method=None):
        '''Query an existing view

        All view parameters here:

        http://wiki.apache.org/couchdb/HTTP_view_API
        '''
        meta = model._meta
        kwargs = {}
        if key:
            kwargs['key'] = json.dumps(key)
        elif keys:
            kwargs['keys'] = json.dumps(keys)
        if group:
            kwargs['group'] = 'true'
        if limit:
            kwargs['limit'] = int(limit)
        if include_docs:
            kwargs['include_docs'] = 'true'
        if not reduce:
            kwargs['reduce'] = 'false'
        return self.request(method or 'get', self._database, '_design',
                            meta.table_name, '_view', view_name, **kwargs)

    def compile_query(self, query):
        return CauchDbQuery(self, query)

    def build_model(self, manager, *args, **kwargs):
        pkname = manager._meta.pkname()
        if args:
            params = args[0]
            if pkname not in params:
                params[pkname] = params.pop('_id')
        return super(CouchDBStore, self).build_model(manager, *args, **kwargs)

    # INTERNALS
    @wait_complete
    def request(self, method, *bits, **kwargs):
        '''Execute the HTTP request'''
        if self._password:
            try:
                lock = self._lock
                if not lock:
                    self._lock = lock = Lock(loop=self._loop)
                    yield lock.acquire()
                    url = '%s/_session' % self._address
                    response = yield self._http.post(
                        url, data={'name': self._user,
                                   'password': self._password},
                        encode_multipart=False)
                    self.fire_event('request', response)
                    if response.status_code != 200:
                        response.raise_for_status()
                        self._lock = None
                else:
                    yield lock.acquire()
            finally:
                lock.release()
        url = '%s/%s' % (self._address, '/'.join(bits))

        response = yield self._http.request(method, url, data=kwargs,
                                            headers=self.headers)
        self.fire_event('request', response)
        if response.request.method == 'HEAD':
            coroutine_return(response)
        else:
            data = response.decode_content()
            if 'error' in data:
                raise couch_db_error(**data)
            else:
                coroutine_return(data)

    def encode_bytes(self, data):
        return b64encode(data).decode(self._encoding)

    def dencode_bytes(self, data):
        return b64decode(data.encode(self._encoding))

    def model_data(self, model, action):
        '''A generator of field/value pair for the store
        '''
        meta = model._meta
        pkname = meta.pkname()
        _id = '_id'
        if action == Command.DELETE:
            yield _id, model.id
            yield '_deleted', True
        else:
            for key, value in meta.store_data(model, self, action):
                yield _id if key == pkname else key, value
            yield 'Type', meta.table_name
        if '_rev' in model:
            yield '_rev', model['_rev']


register_store("couchdb", "pulsar.apps.data.stores.CouchDBStore")
register_store("http+couchdb", "pulsar.apps.data.stores.CouchDBStore")
register_store("https+couchdb", "pulsar.apps.data.stores.CouchDBStore")

########NEW FILE########
__FILENAME__ = startds
from asyncio import Lock
try:
    from asyncio import ConnectionRefusedError
except (ImportError, NameError):
    pass

from pulsar import when_monitor_start, coroutine_return, get_application, send
from pulsar.apps.data import create_store
from pulsar.apps.ds import PulsarDS


def start_pulsar_ds(arbiter, host, workers=0):
    lock = getattr(arbiter, 'lock', None)
    if lock is None:
        arbiter.lock = lock = Lock()
    yield lock.acquire()
    try:
        app = yield get_application('pulsards')
        if not app:
            app = PulsarDS(bind=host, workers=workers)
            cfg = yield app(arbiter)
        else:
            cfg = app.cfg
        coroutine_return(cfg)
    finally:
        lock.release()


def start_store(url, workers=0, **kw):
    '''Equivalent to :func:`create_store` for most cases excepts when the
    ``url`` is for a pulsar store not yet started.

    In this case, the a :class:`.PulsarDS` is started.
    '''
    store = create_store(url, **kw)
    if store.name == 'pulsar':
        client = store.client()
        try:
            yield client.ping()
        except ConnectionRefusedError:
            host = localhost(store._host)
            if not host:
                raise
            cfg = yield send('arbiter', 'run', start_pulsar_ds, host, workers)
            store._host = cfg.addresses[0]
            dns = store._buildurl()
            store = create_store(dns, **kw)
    coroutine_return(store)


def localhost(host):
    if isinstance(host, tuple):
        if host[0] in ('127.0.0.1', ''):
            return ':'.join((str(b) for b in host))
    else:
        return host


def _start_store(monitor):
    app = monitor.app
    if not isinstance(app, PulsarDS):
        dns = app.cfg.data_store
        if dns:
            store = yield start_store(dns)
            app.cfg.set('data_store', store.dns)


when_monitor_start.append(_start_store)

########NEW FILE########
__FILENAME__ = client
from itertools import chain
from hashlib import sha1

import pulsar
from pulsar.utils.structures import mapping_iterator, Zset
from pulsar.utils.pep import native_str, zip, ispy3k, iteritems
from pulsar.apps.ds import COMMANDS_INFO

from .pubsub import PubSub


if ispy3k:
    str_or_bytes = (bytes, str)
else:   # pragma    nocover
    str_or_bytes = basestring

INVERSE_COMMANDS_INFO = dict(((i.method_name, i.name)
                              for i in COMMANDS_INFO.values()))


class CommandError(pulsar.PulsarException):
    pass


class Executor:
    __slots__ = ('client', 'command')

    def __init__(self, client, command):
        self.client = client
        self.command = command

    def __call__(self, *args, **options):
        return self.client.execute(self.command, *args, **options)


class ResponseError:
    __slots__ = ('exception',)

    def __init__(self, exception):
        self.exception = exception


def dict_merge(*dicts):
    merged = {}
    [merged.update(d) for d in dicts]
    return merged


def pairs_to_object(response, factory=None):
    it = iter(response)
    return (factory or dict)(zip(it, it))


def values_to_object(response, fields=None, factory=None):
    if fields is not None:
        return (factory or dict)(zip(fields, response))
    else:
        return response


def string_keys_to_dict(key_string, callback):
    return dict.fromkeys(key_string.split(), callback)


def parse_info(response):
    info = {}
    response = native_str(response)

    def get_value(value):
        if ',' not in value or '=' not in value:
            try:
                if '.' in value:
                    return float(value)
                else:
                    return int(value)
            except ValueError:
                return value
        else:
            sub_dict = {}
            for item in value.split(','):
                k, v = item.rsplit('=', 1)
                sub_dict[k] = get_value(v)
            return sub_dict

    for line in response.splitlines():
        if line and not line.startswith('#'):
            key, value = line.split(':', 1)
            info[key] = get_value(value)
    return info


def values_to_zset(response, withscores=False, **kw):
    if withscores:
        it = iter(response)
        return Zset(((float(score), value) for value, score in zip(it, it)))
    else:
        return response


def sort_return_tuples(response, groups=None, **options):
    """
    If ``groups`` is specified, return the response as a list of
    n-element tuples with n being the value found in options['groups']
    """
    if not response or not groups:
        return response
    return list(zip(*[response[i::groups] for i in range(groups)]))


def pubsub_callback(response, subcommand=None):
    if subcommand == 'numsub':
        it = iter(response)
        return dict(((k, int(v)) for k, v in zip(it, it)))
        return pairs_to_object(response)
    elif subcommand == 'numpat':
        return int(response)
    else:
        return response


class Consumer(pulsar.ProtocolConsumer):

    RESPONSE_CALLBACKS = dict_merge(
        string_keys_to_dict(
            'BGSAVE FLUSHALL FLUSHDB HMSET LSET LTRIM MSET RENAME RESTORE '
            'SAVE SELECT SHUTDOWN SLAVEOF SET WATCH UNWATCH',
            lambda r: r == b'OK'
        ),
        string_keys_to_dict('SORT', sort_return_tuples),
        string_keys_to_dict('BLPOP BRPOP', lambda r: r and tuple(r) or None),
        string_keys_to_dict('SMEMBERS SDIFF SINTER SUNION', set),
        string_keys_to_dict('ZINCRBY ZSCORE',
                            lambda v: float(v) if v is not None else v),
        string_keys_to_dict('ZRANGE ZRANGEBYSCORE ZREVRANGE ZREVRANGEBYSCORE',
                            values_to_zset),
        string_keys_to_dict('EXISTS EXPIRE EXPIREAT PEXPIRE PEXPIREAT '
                            'PERSIST RENAMENX',
                            lambda r: bool(r)),
        {
            'PING': lambda r: r == b'PONG',
            'PUBSUB': pubsub_callback,
            'INFO': parse_info,
            'TIME': lambda x: (int(float(x[0])), int(float(x[1]))),
            'HGETALL': pairs_to_object,
            'HINCRBYFLOAT': lambda r: float(r),
            'HMGET': values_to_object,
            'TYPE': lambda r: r.decode('utf-8')
        }
    )

    def start_request(self):
        conn = self._connection
        args = self._request[0]
        if len(self._request) == 2:
            chunk = conn.parser.pack_command(args)
        else:
            chunk = conn.parser.pack_pipeline(args)
        conn._transport.write(chunk)

    def parse_response(self, response, command, options):
        callback = self.RESPONSE_CALLBACKS.get(command.upper())
        return callback(response, **options) if callback else response

    def data_received(self, data):
        conn = self._connection
        parser = conn.parser
        parser.feed(data)
        response = parser.get()
        request = self._request
        if len(request) == 2:
            if response is not False:
                event = self.event('post_request')
                if not isinstance(response, Exception):
                    cmnd = request[0][0]
                    response = self.parse_response(response, cmnd, request[1])
                else:
                    response = ResponseError(response)
                event.fire(response)
        else:   # pipeline
            commands, raise_on_error, responses = request
            error = None
            while response is not False:
                if (isinstance(response, Exception) and raise_on_error
                        and not error):
                    error = response
                responses.append(response)
                response = parser.get()
            if len(responses) == len(commands):
                response = []
                for cmds, resp in zip(commands[1:-1], responses[-1]):
                    args, options = cmds
                    if isinstance(resp, Exception) and not error:
                        error = resp
                    resp = self.parse_response(resp, args[0], options)
                    response.append(resp)
                if error and raise_on_error:
                    response = ResponseError(error)
                self.finished(response)


class RedisClient(object):
    '''Client for :class:`.RedisStore`.

    .. attribute:: store

        The :class:`.RedisStore` for this client.
    '''
    def __init__(self, store):
        self.store = store

    def __repr__(self):
        return '%s(%s)' % (self.__class__.__name__, self.store)
    __str__ = __repr__

    def pubsub(self, **kw):
        return PubSub(self.store, **kw)

    def pipeline(self):
        '''Create a :class:`.Pipeline` for pipelining commands
        '''
        return Pipeline(self.store)

    def execute(self, command, *args, **options):
        return self.store.execute(command, *args, **options)
    execute_command = execute

    # special commands

    # STRINGS
    def decr(self, key, ammount=None):
        if ammount is None:
            return self.execute('decr', key)
        else:
            return self.execute('decrby', key, ammount)

    def incr(self, key, ammount=None):
        if ammount is None:
            return self.execute('incr', key)
        else:
            return self.execute('incrby', key, ammount)

    # HASHES
    def hmget(self, key, *fields):
        return self.execute('hmget', key, *fields, fields=fields)

    def hmset(self, key, iterable):
        args = []
        [args.extend(pair) for pair in mapping_iterator(iterable)]
        return self.execute('hmset', key, *args)

    # LISTS
    def blpop(self, keys, timeout=0):
        if timeout is None:
            timeout = 0
        if isinstance(keys, str_or_bytes):
            keys = [keys]
        else:
            keys = list(keys)
        keys.append(timeout)
        return self.execute_command('BLPOP', *keys)

    def brpop(self, keys, timeout=0):
        if timeout is None:
            timeout = 0
        if isinstance(keys, str_or_bytes):
            keys = [keys]
        else:
            keys = list(keys)
        keys.append(timeout)
        return self.execute_command('BRPOP', *keys)

    # SORTED SETS
    def zadd(self, name, *args, **kwargs):
        """
        Set any number of score, element-name pairs to the key ``name``. Pairs
        can be specified in two ways:

        As ``*args``, in the form of::

            score1, name1, score2, name2, ...

        or as ``**kwargs``, in the form of::

            name1=score1, name2=score2, ...

        The following example would add four values to the 'my-key' key::

            client.zadd('my-key', 1.1, 'name1', 2.2, 'name2',
                        name3=3.3, name4=4.4)
        """
        pieces = []
        if args:
            if len(args) % 2 != 0:
                raise vALUEeRROR("ZADD requires an equal number of "
                                 "values and scores")
            pieces.extend(args)
        for pair in iteritems(kwargs):
            pieces.append(pair[1])
            pieces.append(pair[0])
        return self.execute_command('ZADD', name, *pieces)

    def zinterstore(self, des, keys, weights=None, aggregate=None):
        numkeys = len(keys)
        pieces = list(keys)
        if weights:
            pieces.append(b'WEIGHTS')
            pieces.extend(weights)
        if aggregate:
            pieces.append(b'AGGREGATE')
            pieces.append(aggregate)
        return self.execute_command('ZINTERSTORE', des, numkeys, *pieces)

    def zunionstore(self, des, keys, weights=None, aggregate=None):
        numkeys = len(keys)
        pieces = list(keys)
        if weights:
            pieces.append(b'WEIGHTS')
            pieces.extend(weights)
        if aggregate:
            pieces.append(b'AGGREGATE')
            pieces.append(aggregate)
        return self.execute_command('ZUNIONSTORE', des, numkeys, *pieces)

    def zrange(self, key, start, stop, withscores=False):
        if withscores:
            return self.execute_command('ZRANGE', key, start, stop,
                                        b'WITHSCORES', withscores=True)
        else:
            return self.execute_command('ZRANGE', key, start, stop)

    def zrangebyscore(self, key, min, max, withscores=False, offset=None,
                      count=None):
        pieces = []
        if withscores:
            pieces.append(b'WITHSCORES')
        if offset:
            pieces.append(b'LIMIT')
            pieces.append(offset)
            pieces.append(count)
        return self.execute_command('ZRANGEBYSCORE', key, min, max, *pieces,
                                    withscores=withscores)

    def zrevrange(self, key, start, stop, withscores=False):
        if withscores:
            return self.execute_command('ZREVRANGE', key, start, stop,
                                        'WITHSCORES', withscores=True)
        else:
            return self.execute_command('ZRANGE', key, start, stop)

    def zrevrangebyscore(self, key, min, max, withscores=False, offset=None,
                         count=None):
        pieces = []
        if withscores:
            pieces.append(b'WITHSCORES')
        if offset:
            pieces.append(b'LIMIT')
            pieces.append(offset)
            pieces.append(count)
        return self.execute_command('ZREVRANGEBYSCORE', key, min, max, *pieces,
                                    withscores=withscores)

    def eval(self, script, keys=None, args=None):
        return self._eval('eval', script, keys, args)

    def evalsha(self, sha, keys=None, args=None):
        return self._eval('evalsha', sha, keys, args)

    def sort(self, key, start=None, num=None, by=None, get=None,
             desc=False, alpha=False, store=None, groups=False):
        '''Sort and return the list, set or sorted set at ``key``.

        ``start`` and ``num`` allow for paging through the sorted data

        ``by`` allows using an external key to weight and sort the items.
            Use an "*" to indicate where in the key the item value is located

        ``get`` allows for returning items from external keys rather than the
            sorted data itself.  Use an "*" to indicate where int he key
            the item value is located

        ``desc`` allows for reversing the sort

        ``alpha`` allows for sorting lexicographically rather than numerically

        ``store`` allows for storing the result of the sort into
            the key ``store``

        ``groups`` if set to True and if ``get`` contains at least two
            elements, sort will return a list of tuples, each containing the
            values fetched from the arguments to ``get``.

        '''
        if ((start is not None and num is None) or
                (num is not None and start is None)):
            raise CommandError("``start`` and ``num`` must both be specified")

        pieces = [key]
        if by is not None:
            pieces.append('BY')
            pieces.append(by)
        if start is not None and num is not None:
            pieces.append('LIMIT')
            pieces.append(start)
            pieces.append(num)
        if get is not None:
            # If get is a string assume we want to get a single value.
            # Otherwise assume it's an interable and we want to get multiple
            # values. We can't just iterate blindly because strings are
            # iterable.
            if isinstance(get, str):
                pieces.append('GET')
                pieces.append(get)
            else:
                for g in get:
                    pieces.append('GET')
                    pieces.append(g)
        if desc:
            pieces.append('DESC')
        if alpha:
            pieces.append('ALPHA')
        if store is not None:
            pieces.append('STORE')
            pieces.append(store)

        if groups:
            if not get or isinstance(get, str) or len(get) < 2:
                raise CommandError('when using "groups" the "get" argument '
                                   'must be specified and contain at least '
                                   'two keys')

        options = {'groups': len(get) if groups else None}
        return self.execute_command('SORT', *pieces, **options)

    def __getattr__(self, name):
        command = INVERSE_COMMANDS_INFO.get(name)
        if command:
            return Executor(self, command)
        else:
            raise AttributeError("'%s' object has no attribute '%s'" %
                                 (type(self), name))

    def _eval(self, command, script, keys, args):
        all = keys if keys is not None else ()
        num_keys = len(all)
        if args:
            all = tuple(chain(all, args))
        return self.execute(command, script, num_keys, *all)


class Pipeline(RedisClient):
    '''A :class:`.RedisClient` for pipelining commands
    '''
    def __init__(self, store):
        self.store = store
        self.reset()

    def execute(self, *args, **kwargs):
        self.command_stack.append((args, kwargs))
    execute_command = execute

    def reset(self):
        self.command_stack = []

    def commit(self, raise_on_error=True):
        '''Send commands to redis.
        '''
        cmds = list(chain([(('multi',), {})],
                          self.command_stack, [(('exec',), {})]))
        self.reset()
        return self.store.execute_pipeline(cmds, raise_on_error)


class RedisScriptMeta(type):

    def __new__(cls, name, bases, attrs):
        super_new = super(RedisScriptMeta, cls).__new__
        abstract = attrs.pop('abstract', False)
        new_class = super_new(cls, name, bases, attrs)
        if not abstract:
            self = new_class(new_class.script, new_class.__name__)
            _scripts[self.name] = self
        return new_class


class RedisScript(RedisScriptMeta('_RS', (object,), {'abstract': True})):
    '''Class which helps the sending and receiving lua scripts.

    It uses the ``evalsha`` command.

    .. attribute:: script

        The lua script to run

    .. attribute:: required_scripts

        A list/tuple of other :class:`RedisScript` names required by this
        script to properly execute.

    .. attribute:: sha1

        The SHA-1_ hexadecimal representation of :attr:`script` required by the
        ``EVALSHA`` redis command. This attribute is evaluated by the library,
        it is not set by the user.

    .. _SHA-1: http://en.wikipedia.org/wiki/SHA-1
    '''
    abstract = True
    script = None
    required_scripts = ()

    def __init__(self, script, name):
        if isinstance(script, (list, tuple)):
            script = '\n'.join(script)
        self.__name = name
        self.script = script
        rs = set((name,))
        rs.update(self.required_scripts)
        self.required_scripts = rs

    @property
    def name(self):
        return self.__name

    @property
    def sha1(self):
        if not hasattr(self, '_sha1'):
            self._sha1 = sha1(self.script.encode('utf-8')).hexdigest()
        return self._sha1

    def __repr__(self):
        return self.name if self.name else self.__class__.__name__
    __str__ = __repr__

    def preprocess_args(self, client, args):
        return args

    def callback(self, response, **options):
        '''Called back after script execution.

        This is the only method user should override when writing a new
        :class:`RedisScript`. By default it returns ``response``.

        :parameter response: the response obtained from the script execution.
        :parameter options: Additional options for the callback.
        '''
        return response

    def __call__(self, client, keys, args, options):
        args = self.preprocess_args(client, args)
        numkeys = len(keys)
        keys_args = tuple(keys) + args
        options.update({'script': self, 'redis_client': client})
        return client.execute_command('EVALSHA', self.sha1, numkeys,
                                      *keys_args, **options)

########NEW FILE########
__FILENAME__ = pubsub
from functools import partial

from pulsar import task, in_loop, Protocol, EventHandler, coroutine_return
from pulsar.apps import data


class PubsubProtocol(Protocol):

    def __init__(self, handler, *args, **kw):
        super(PubsubProtocol, self).__init__(*args, **kw)
        self.parser = self._producer._parser_class()
        self.handler = handler

    def execute(self, *args):
        chunk = self.parser.multi_bulk(args)
        self._transport.write(chunk)

    def data_received(self, data):
        parser = self.parser
        parser.feed(data)
        response = parser.get()
        while response is not False:
            if not isinstance(response, Exception):
                if isinstance(response, list):
                    command = response[0]
                    if command == b'message':
                        response = response[1:3]
                        self.handler.broadcast(response)
                    elif command == b'pmessage':
                        response = response[2:4]
                        self.handler.broadcast(response)
            else:
                raise response
            response = parser.get()


class PubSub(data.PubSub):
    '''Asynchronous Publish/Subscriber handler for pulsar and redis stores.
    '''
    def publish(self, channel, message):
        if self._protocol:
            message = self._protocol.encode(message)
        return self.store.execute('PUBLISH', channel, message)

    def count(self, *channels):
        kw = {'subcommand': 'numsub'}
        return self.store.execute('PUBSUB', 'NUMSUB', *channels, **kw)

    def channels(self, pattern=None):
        '''Lists the currently active channels matching ``pattern``
        '''
        if pattern:
            return self.store.execute('PUBSUB', 'CHANNELS', pattern)
        else:
            return self.store.execute('PUBSUB', 'CHANNELS')

    def psubscribe(self, pattern, *patterns):
        return self._subscribe('PSUBSCRIBE', pattern, *patterns)

    @in_loop
    def punsubscribe(self, *patterns):
        if self._connection:
            self._connection.execute('PUNSUBSCRIBE', *patterns)

    def subscribe(self, channel, *channels):
        return self._subscribe('SUBSCRIBE', channel, *channels)

    @in_loop
    def unsubscribe(self, *channels):
        '''Un-subscribe from a list of ``channels``.
        '''
        if self._connection:
            self._connection.execute('UNSUBSCRIBE', *channels)

    @in_loop
    def close(self):
        '''Stop listening for messages.
        '''
        if self._connection:
            self._connection.execute('PUNSUBSCRIBE')
            self._connection.execute('UNSUBSCRIBE')

    #    INTERNALS
    @task
    def _subscribe(self, *args):
        if not self._connection:
            protocol_factory = partial(PubsubProtocol, self,
                                       producer=self.store)
            self._connection = yield self.store.connect(protocol_factory)
            self._connection.execute(*args)
        coroutine_return()

########NEW FILE########
__FILENAME__ = store
from functools import partial

from pulsar import coroutine_return, task, Connection, Pool, get_actor
from pulsar.utils.pep import to_string
from pulsar.apps.data import register_store, Store, Command
from pulsar.apps.ds import redis_parser

from .client import RedisClient, Pipeline, Consumer, ResponseError
from .pubsub import PubSub


class RedisStoreConnection(Connection):

    def __init__(self, *args, **kw):
        super(RedisStoreConnection, self).__init__(*args, **kw)
        self.parser = self._producer._parser_class()

    def execute(self, *args, **options):
        consumer = self.current_consumer()
        consumer.start((args, options))
        return consumer.on_finished

    def execute_pipeline(self, commands, raise_on_error=True):
        consumer = self.current_consumer()
        consumer.start((commands, raise_on_error, []))
        return consumer.on_finished


class RedisStore(Store):
    '''Redis :class:`.Store` implementation.
    '''
    protocol_factory = partial(RedisStoreConnection, Consumer)
    supported_queries = frozenset(('filter', 'exclude'))

    def _init(self, namespace=None, parser_class=None, pool_size=50,
              decode_responses=False, **kwargs):
        self._decode_responses = decode_responses
        if not parser_class:
            actor = get_actor()
            pyparser = actor.cfg.redis_py_parser if actor else False
            parser_class = redis_parser(pyparser)
        self._parser_class = parser_class
        if namespace:
            self._urlparams['namespace'] = namespace
        self._pool = Pool(self.connect, pool_size=pool_size, loop=self._loop)
        self.loaded_scripts = {}

    @property
    def pool(self):
        return self._pool

    @property
    def namespace(self):
        '''The prefix namespace to append to all transaction on keys
        '''
        n = self._urlparams.get('namespace')
        return '%s:' % n if n else ''

    def key(self):
        return (self._dns, self._encoding)

    def client(self):
        '''Get a :class:`.RedisClient` for the Store'''
        return RedisClient(self)

    def pipeline(self):
        '''Get a :class:`.Pipeline` for the Store'''
        return Pipeline(self)

    def pubsub(self, protocol=None):
        return PubSub(self, protocol=protocol)

    def ping(self):
        return self.client().ping()

    @task
    def execute(self, *args, **options):
        connection = yield self._pool.connect()
        with connection:
            result = yield connection.execute(*args, **options)
            if isinstance(result, ResponseError):
                raise result.exception
            coroutine_return(result)

    @task
    def execute_pipeline(self, commands, raise_on_error=True):
        conn = yield self._pool.connect()
        with conn:
            result = yield conn.execute_pipeline(commands, raise_on_error)
            if isinstance(result, ResponseError):
                raise result.exception
            coroutine_return(result)

    def connect(self, protocol_factory=None):
        protocol_factory = protocol_factory or self.create_protocol
        if isinstance(self._host, tuple):
            host, port = self._host
            transport, connection = yield self._loop.create_connection(
                protocol_factory, host, port)
        else:
            raise NotImplementedError('Could not connect to %s' %
                                      str(self._host))
        if self._password:
            yield connection.execute('AUTH', self._password)
        if self._database:
            yield connection.execute('SELECT', self._database)
        coroutine_return(connection)

    def execute_transaction(self, transaction):
        '''Execute a :class:`.Transaction`
        '''
        pipe = self.pipeline()
        update_insert = set((Command.INSERT, Command.UPDATE))
        #
        for command in transaction.commands:
            action = command.action
            if not action:
                pipe.execute(*command.args)
            elif action in update_insert:
                model = command.args
                key = self.basekey(model._meta, model.id)
                pipe.hmset(key, self.model_data(model, action))
            else:
                raise NotImplementedError
        response = yield pipe.commit()
        for command in transaction.commands:
            if command.action == Command.INSERT:
                model = command.args
                model['_rev'] = 1

    def get_model(self, manager, pk):
        key = '%s%s:%s' % (self.namespace, manager._meta.table_name,
                           to_string(pk))
        return self.execute('hgetall', key,
                            factory=partial(self.build_model, manager))

    def compile_query(self, query):
        compiled = CompiledQuery(self.pipeline())
        return compiled

    def flush(self):
        return self.execute('flushdb')

    def close(self):
        '''Close all open connections.'''
        return self._pool.close()

    def has_query(self, query_type):
        return query_type in self.supported_queries

    def basekey(self, meta, *args):
        key = '%s%s' % (self.namespace, meta.table_name)
        postfix = ':'.join((to_string(p) for p in args if p is not None))
        return '%s:%s' % (key, postfix) if postfix else key

    def meta(self, meta):
        '''Extract model metadata for lua script stdnet/lib/lua/odm.lua'''
        indices = dict(((idx.attname, idx.unique) for idx in meta.indices))
        data = meta.as_dict()
        data['namespace'] = self.basekey(meta)
        return data


class CompiledQuery(object):

    def __init__(self, pipe, query):
        self.pipe = pipe

########NEW FILE########
__FILENAME__ = client
import time
from functools import partial

import pulsar
from pulsar.utils.structures import OrderedDict
from pulsar.utils.pep import force_native_str, to_bytes


COMMANDS_INFO = OrderedDict()


class CommandError(Exception):
    pass


def check_input(request, failed):
    if failed:
        raise CommandError("wrong number of arguments for '%s'" % request[0])


class command:
    '''Decorator for pulsar-ds server commands
    '''
    def __init__(self, group, write=False, name=None,
                 script=1, supported=True, subcommands=None):
        self.group = group
        self.write = write
        self.name = name
        self.script = script
        self.supported = supported
        self.subcommands = subcommands

    @property
    def url(self):
        return 'http://redis.io/commands/%s' % self.name

    def __call__(self, f):
        self.method_name = f.__name__
        if not self.name:
            self.name = self.method_name
        COMMANDS_INFO[self.name] = self
        f._info = self
        return f


class ClientMixin(object):

    def __init__(self, store):
        self.store = store
        self.database = 0
        self.transaction = None
        self.last_command = ''
        self.flag = 0
        self.blocked = None

    @property
    def db(self):
        return self.store.databases[self.database]

    def execute(self, request):
        '''Execute a new ``request``.
        '''
        handle = None
        if request:
            request[0] = command = force_native_str(request[0]).lower()
            info = COMMANDS_INFO.get(command)
            if info:
                handle = getattr(self.store, info.method_name)
            #
            if self.channels or self.patterns:
                if command not in self.store.SUBSCRIBE_COMMANDS:
                    return self.reply_error(self.store.PUBSUB_ONLY)
            if self.blocked:
                return self.reply_error('Blocked client cannot request')
            if self.transaction is not None and command not in 'exec':
                self.transaction.append((handle, request))
                return self._transport.write(self.store.QUEUED)
        self._execute_command(handle, request)

    def _execute_command(self, handle, request):
        try:
            if request:
                command = request[0]
                if not handle:
                    self._loop.logger.info("unknown command '%s'" % command)
                    return self.reply_error("unknown command '%s'" % command)
                if self.store._password != self.password:
                    if command != 'auth':
                        return self.reply_error(
                            'Authentication required', 'NOAUTH')
                handle(self, request, len(request) - 1)
            else:
                command = ''
                return self.reply_error("no command")
        except CommandError as e:
            self.reply_error(str(e))
        except Exception:
            self._loop.logger.exception("Server error on '%s' command",
                                        command)
            self.reply_error('Server Error')
        finally:
            self.last_command = command

    def reply_ok(self):
        raise NotImplementedError

    def reply_status(self, status):
        raise NotImplementedError

    def reply_error(self, value, prefix=None):
        raise NotImplementedError

    def reply_wrongtype(self):
        raise NotImplementedError

    def reply_int(self, value):
        raise NotImplementedError

    def reply_one(self):
        raise NotImplementedError

    def reply_zero(self):
        raise NotImplementedError

    def reply_bulk(self, value):
        raise NotImplementedError

    def reply_multi_bulk(self, value):
        raise NotImplementedError

    def reply_multi_bulk_len(self, len):
        raise NotImplementedError


class PulsarStoreClient(pulsar.Protocol, ClientMixin):
    '''Used both by client and server'''

    def __init__(self, cfg, *args, **kw):
        super(PulsarStoreClient, self).__init__(*args, **kw)
        ClientMixin.__init__(self, self._producer._key_value_store)
        self.cfg = cfg
        self.parser = self._producer._parser_class()
        self.started = time.time()
        self.channels = set()
        self.patterns = set()
        self.watched_keys = None
        self.password = b''
        self.bind_event('connection_lost',
                        partial(self.store._remove_connection, self))

    # Client Mixin Implementation
    def reply_ok(self):
        self._write(self.store.OK)

    def reply_status(self, value):
        self._write(('+%s\r\n' % value).encode('utf-8'))

    def reply_int(self, value):
        self._write((':%d\r\n' % value).encode('utf-8'))

    def reply_one(self):
        self._write(self.store.ONE)

    def reply_zero(self):
        self._write(self.store.ZERO)

    def reply_error(self, value, prefix=None):
        prefix = prefix or 'ERR'
        self._write(('-%s %s\r\n' % (prefix, value)).encode('utf-8'))

    def reply_wrongtype(self):
        # Quick wrong type method
        self._write((b'-WRONGTYPE Operation against a key holding '
                     b'the wrong kind of value\r\n'))

    def reply_bulk(self, value=None):
        if value is None:
            self._write(self.store.NIL)
        else:
            self._write(self.store._parser.bulk(value))

    def reply_multi_bulk(self, value=None):
        self._write(self.store._parser.multi_bulk(value))

    def reply_multi_bulk_len(self, value):
        self._write(self.store._parser.multi_bulk_len(value))

    # Protocol Implementaton
    def data_received(self, data):
        self.parser.feed(data)
        request = self.parser.get()
        while request is not False:
            if self.store._monitors:
                self.store._write_to_monitors(self, request)
            self.execute(request)
            request = self.parser.get()

    # Internals
    def _write(self, response):
        if self.transaction is not None:
            self.transaction.append(response)
        elif not self._transport._closing:
            self._transport.write(response)


class LuaClient(ClientMixin):
    not_allowed = ('randomkey', 'srandmember', 'time')
    request_stak = None

    # Exposed to lua script
    def call(self, *args):
        try:
            return self._call(*args)
        except Exception as e:
            return self.reply_error(str(e))

    def pcall(self, *args):
        try:
            return self._call(*args)
        except Exception as e:
            return self.reply_error(str(e))

    def error_reply(self, error_string, prefix=None):
        prefix = (prefix or 'err').lower()
        return {prefix: to_bytes(error_string)}

    def status_reply(self, status_string):
        return {'ok': to_bytes(status_string)}

    # Client implementation
    def reply_ok(self):
        self.result = self.status_reply(b'OK')

    def reply_status(self, status):
        self.result = self.status_reply(status)

    def reply_error(self, value, prefix=None):
        self.result = self.error_reply(value, prefix)

    def reply_wrongtype(self):
        self.result = self.error_reply('WRONGTYPE')

    def reply_int(self, value):
        self.result = value
    reply_bulk = reply_int
    reply_multi_bulk = reply_int

    def reply_one(self):
        self.result = 1

    def reply_zero(self):
        self.result = 0

    def _call(self, *args):
        request = list(args)
        try:
            handle = self.command_handle(request)
            if not handle:
                raise ValueError(
                    'redis.call require a valid command as first argument')
            if not handle._info.script:
                raise ValueError(
                    'This Redis command is not allowed from scripts')
            if self.request_stak is None:
                self.request_stak = []
            self.request_stak.append(request)
            self.result = None
            self.execute(handle, request)
            return self.result
        except Exception as e:
            return self.reply_error(str(e))


class Blocked:
    '''Handle blocked keys for a client
    '''
    def __init__(self, client, command, keys, timeout, dest=None):
        self.command = command
        self.keys = set(keys)
        self.dest = dest
        self._called = False
        db = client.db
        for key in self.keys:
            clients = db._blocking_keys.get(key)
            if clients is None:
                db._blocking_keys[key] = clients = set()
            clients.add(client)
        client.store._bpop_blocked_clients += 1
        if timeout:
            self.handle = client._loop.call_later(
                timeout, self.unblock, client)
        else:
            self.handle = None

    def unblock(self, client, key=None, value=None):
        if not self._called:
            self._called = True
            if self.handle:
                self.handle.cancel()
            store = client.store
            client.blocked = None
            store._bpop_blocked_clients -= 1
            #
            # make sure to remove the client from the set of blocked
            # clients in the database associated with key
            if key is None:
                bkeys = client.db._blocking_keys
                for key in self.keys:
                    clients = bkeys.get(key)
                    if clients:
                        clients.discard(client)
                        if not clients:
                            bkeys.pop(key)
            #
            # send the response
            if value is None:
                client._write(store.NULL_ARRAY)
            else:
                store._block_callback(client, self.command, key,
                                      value, self.dest)


def redis_to_py_pattern(pattern):
    return ''.join(_redis_to_py_pattern(pattern))


def _redis_to_py_pattern(pattern):
    clear, esc = False, False
    s, q, op, cp, e = '*', '?', '[', ']', '\\'

    for v in pattern:
        if v == s and not esc:
            yield '(.*)'
        elif v == q and not esc:
            yield '.'
        elif v == op and not esc:
            esc = True
            yield v
        elif v == cp and esc:
            esc = False
            yield v
        elif v == e:
            clear, esc = True
            yield v
        elif clear:
            clear, esc = False, False
            yield v
        else:
            yield v
    yield '$'

########NEW FILE########
__FILENAME__ = parser
import pulsar

from .pyparser import Parser


class ResponseError(pulsar.PulsarException):
    pass


class InvalidResponse(pulsar.PulsarException):
    pass


class NoScriptError(ResponseError):
    pass


EXCEPTION_CLASSES = {
    'ERR': ResponseError,
    'NOSCRIPT': NoScriptError,
}


def response_error(response):
    "Parse an error response"
    response = response.split(' ')
    error_code = response[0]
    if error_code not in EXCEPTION_CLASSES:
        error_code = 'ERR'
    response = ' '.join(response[1:])
    return EXCEPTION_CLASSES[error_code](response)


PyRedisParser = lambda: Parser(InvalidResponse, response_error)


if pulsar.HAS_C_EXTENSIONS:
    from pulsar.utils.lib import RedisParser as _RedisParser
    RedisParser = lambda: _RedisParser(InvalidResponse, response_error)
else:
    RedisParser = PyRedisParser


def redis_parser(py_redis_parser=False):
    return PyRedisParser if py_redis_parser else RedisParser

########NEW FILE########
__FILENAME__ = pyparser
'''A parser for redis messages
'''
import sys
from itertools import starmap

ispy3k = sys.version_info >= (3, 0)
if ispy3k:
    long = int
    string_type = str
else:   # pragma    nocover
    string_type = unicode

nil = b'$-1\r\n'
null_array = b'*-1\r\n'

REPLAY_TYPE = frozenset((b'$',   # REDIS_REPLY_STRING,
                         b'*',   # REDIS_REPLY_ARRAY,
                         b':',   # REDIS_REPLY_INTEGER,
                         b'+',   # REDIS_REPLY_STATUS,
                         b'-'))  # REDIS_REPLY_ERROR


class String(object):
    __slots__ = ('_length', 'next')

    def __init__(self, length, next):
        self._length = length
        self.next = next

    def decode(self, parser, result):
        parser._current = None
        length = self._length
        if length >= 0:
            b = parser._inbuffer
            if len(b) >= length+2:
                parser._inbuffer, chunk = b[length+2:], bytes(b[:length])
                if parser.encoding:
                    return chunk.decode(parser.encoding)
                else:
                    return chunk
            else:
                parser._current = self
                return False


class ArrayTask(object):
    __slots__ = ('_length', '_response', 'next')

    def __init__(self, length, next):
        self._length = length
        self._response = []
        self.next = next

    def decode(self, parser, result):
        parser._current = None
        length = self._length
        if length >= 0:
            response = self._response
            if result is not False:
                response.append(result)
            while len(response) < length:
                result = parser._get(self)
                if result is False:
                    break
                response.append(result)
            if len(response) == length:
                parser._current = None
                return response
            elif not parser._current:
                parser._current = self
            return False


class Parser(object):
    '''A python parser for redis.'''
    encoding = None

    def __init__(self, protocolError, responseError):
        self.protocolError = protocolError
        self.responseError = responseError
        self._current = None
        self._inbuffer = bytearray()

    def on_connect(self, connection):
        if connection.decode_responses:
            self.encoding = connection.encoding

    def on_disconnect(self):
        pass

    def feed(self, buffer):
        '''Feed new data into the buffer'''
        self._inbuffer.extend(buffer)

    def get(self):
        '''Called by the protocol consumer'''
        if self._current:
            return self._resume(self._current, False)
        else:
            return self._get(None)

    def bulk(self, value):
        if value is None:
            return nil
        else:
            return ('$%d\r\n' % len(value)).encode('utf-8') + value + b'\r\n'

    def multi_bulk_len(self, len):
        return ('*%s\r\n' % len).encode('utf-8')

    def multi_bulk(self, args):
        '''Multi bulk encoding for list/tuple ``args``
        '''
        return null_array if args is None else b''.join(self._pack(args))

    def pack_command(self, args):
        '''Encode a command to send to the server.

        Used by redis clients
        '''
        return b''.join(self._pack_command(args))

    def pack_pipeline(self, commands):
        '''Packs pipeline commands into bytes.'''
        pack = lambda *args: b''.join(self._pack_command(args))
        return b''.join(starmap(pack, (args for args, _ in commands)))

    #    INTERNALS
    def _pack_command(self, args):
        crlf = b'\r\n'
        yield ('*%d\r\n' % len(args)).encode('utf-8')
        for value in args:
            if isinstance(value, string_type):
                value = value.encode('utf-8')
            elif not isinstance(value, bytes):
                value = str(value).encode('utf-8')
            yield ('$%d\r\n' % len(value)).encode('utf-8')
            yield value
            yield crlf

    def _pack(self, args):
        crlf = b'\r\n'
        yield ('*%d\r\n' % len(args)).encode('utf-8')
        for value in args:
            if value is None:
                yield nil
            elif isinstance(value, bytes):
                yield ('$%d\r\n' % len(value)).encode('utf-8')
                yield value
                yield crlf
            elif isinstance(value, string_type):
                value = value.encode('utf-8')
                yield ('$%d\r\n' % len(value)).encode('utf-8')
                yield value
                yield crlf
            elif hasattr(value, 'items'):
                for value in self._pack(tuple(self._lua_dict(value))):
                    yield value
            elif hasattr(value, '__len__'):
                for value in self._pack(value):
                    yield value
            else:
                value = str(value).encode('utf-8')
                yield ('$%d\r\n' % len(value)).encode('utf-8')
                yield value
                yield crlf

    def _lua_dict(self, d):
        index = 0
        while True:
            index += 1
            v = d.get(index)
            if v is None:
                break
            yield v

    def _get(self, next):
        b = self._inbuffer
        length = b.find(b'\r\n')
        if length >= 0:
            self._inbuffer, response = b[length+2:], bytes(b[:length])
            rtype, response = response[:1], response[1:]
            if rtype == b'-':
                return self.responseError(response.decode('utf-8'))
            elif rtype == b':':
                return long(response)
            elif rtype == b'+':
                return response
            elif rtype == b'$':
                task = String(long(response), next)
                return task.decode(self, False)
            elif rtype == b'*':
                task = ArrayTask(long(response), next)
                return task.decode(self, False)
            else:
                # Clear the buffer and raise
                self._inbuffer = bytearray()
                raise self.protocolError('Protocol Error')
        else:
            return False

    def buffer(self):
        '''Current buffer'''
        return bytes(self._inbuffer)

    def _resume(self, task, result):
        result = task.decode(self, result)
        if result is not False and task.next:
            return self._resume(task.next, result)
        else:
            return result

########NEW FILE########
__FILENAME__ = server
'''
Pulsar-ds is a python implementation of the popular redis_
data store. It uses pulsar asynchronous framework to create a
single-threaded workers responding to TCP-requests in the same way
as redis does.

To run a stand alone server create a script with the following code::


    from pulsar.apps.data import PulsarDS

    if __name__ == '__main__':
        PulsarDS().start()


More information on the :ref:`pulsar data store example <tutorials-pulsards>`.

Check out these benchmarks_

.. _benchmarks: https://gist.github.com/lsbardel/8068579

Implementation
===========================

Pulsar Data Store Server
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: PulsarDS
   :members:
   :member-order: bysource


Storage
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: Storage
   :members:
   :member-order: bysource


.. _redis: http://redis.io/
'''
import os
import re
import time
import math
from random import choice
from hashlib import sha1
from itertools import islice, chain
from functools import partial, reduce
from collections import namedtuple
from multiprocessing import Process

import pulsar
from pulsar.apps.socket import SocketServer
from pulsar.utils.config import Global
from pulsar.utils.structures import Dict, Zset, Deque
from pulsar.utils.pep import map, range, zip, ispy3k, pickle
try:
    from pulsar.utils.lua import Lua
except ImportError:     # pragma    nocover
    Lua = None


from .parser import redis_parser
from .utils import sort_command, count_bytes, and_op, or_op, xor_op, save_data
from .client import (command, PulsarStoreClient, LuaClient, Blocked,
                     COMMANDS_INFO, check_input, redis_to_py_pattern)


DEFAULT_PULSAR_STORE_ADDRESS = '127.0.0.1:6410'


def pulsards_url(address=None, db=3):
    address = address or DEFAULT_PULSAR_STORE_ADDRESS
    return 'pulsar://%s/%s' % (address, db)


# Keyspace changes notification classes
STRING_LIMIT = 2**32

nan = float('nan')

if ispy3k:
    from itertools import zip_longest
    _ord = lambda x: x
else:   # pragma    nocover
    from itertools import izip_longest as zip_longest
    _ord = lambda x: ord(x)


class RedisParserSetting(Global):
    name = "redis_py_parser"
    flags = ["--redis-py-parser"]
    action = "store_true"
    default = False
    desc = '''\
    Use the python redis parser rather the C implementation.

    Mainly used for benchmarking purposes.
    '''


class PulsarDsSetting(pulsar.Setting):
    virtual = True
    app = 'pulsards'
    section = "Pulsar data store server"


def validate_list_of_pairs(val):
    new_val = []
    if val:
        if not isinstance(val, (list, tuple)):
            raise TypeError("Not a list: %s" % val)
        for elem in val:
            if not isinstance(elem, (list, tuple)):
                raise TypeError("Not a list: %s" % elem)
            if not len(elem) == 2:
                raise TypeError("Not a pair: %s" % str(elem))
            new_val.append((int(elem[0]), int(elem[1])))
    return new_val


# #############################################################################
# #    CONFIGURATION PARAMETERS
class KeyValueDatabases(PulsarDsSetting):
    name = "key_value_databases"
    flags = ["--key-value-databases"]
    type = int
    default = 16
    desc = 'Number of databases for the key value store.'


class KeyValuePassword(PulsarDsSetting):
    name = "key_value_password"
    flags = ["--key-value-password"]
    default = ''
    desc = 'Optional password for the database.'


class KeyValueSave(PulsarDsSetting):
    name = "key_value_save"
    default = [(900, 1), (300, 10), (60, 10000)]
    validator = validate_list_of_pairs
    desc = '''\
        List of pairs controlling data store persistence.

        Will save the DB if both the given number of seconds and the given
        number of write operations against the DB occurred.

        The default behaviour will be to save:
        after 900 sec (15 min) if at least 1 key changed
        after 300 sec (5 min) if at least 10 keys changed
        after 60 sec if at least 10000 keys changed

        You can disable saving at all by setting an empty list
    '''


class KeyValueFileName(PulsarDsSetting):
    name = "key_value_filename"
    flags = ["--key-value-filename"]
    default = 'pulsards.rdb'
    desc = '''The filename where to dump the DB.'''


class TcpServer(pulsar.TcpServer):

    def __init__(self, cfg, *args, **kwargs):
        super(TcpServer, self).__init__(*args, **kwargs)
        self.cfg = cfg
        self._parser_class = redis_parser(cfg.redis_py_parser)
        self._key_value_store = Storage(self, cfg)

    def info(self):
        info = super(TcpServer, self).info()
        info.update(self._key_value_store._info())
        return info


class PulsarDS(SocketServer):
    '''A :class:`.SocketServer` serving a pulsar datastore.
    '''
    name = 'pulsards'
    cfg = pulsar.Config(bind=DEFAULT_PULSAR_STORE_ADDRESS,
                        keep_alive=0,
                        apps=['socket', 'pulsards'])

    def server_factory(self, *args, **kw):
        return TcpServer(self.cfg, *args, **kw)

    def protocol_factory(self):
        return partial(PulsarStoreClient, self.cfg)

    def monitor_start(self, monitor):
        cfg = self.cfg
        workers = min(1, cfg.workers)
        cfg.set('workers', workers)
        return super(PulsarDS, self).monitor_start(monitor)


# #############################################################################
# #    DATA STORE
pubsub_patterns = namedtuple('pubsub_patterns', 're clients')


class Storage(object):
    '''Implement redis commands.
    '''
    def __init__(self, server, cfg):
        self.cfg = cfg
        self._password = cfg.key_value_password.encode('utf-8')
        self._filename = cfg.key_value_filename
        self._writer = None
        self._server = server
        self._loop = server._loop
        self._parser = server._parser_class()
        self._missed_keys = 0
        self._hit_keys = 0
        self._expired_keys = 0
        self._dirty = 0
        self._bpop_blocked_clients = 0
        self._last_save = int(time.time())
        self._channels = {}
        self._patterns = {}
        # The set of clients which are watching keys
        self._watching = set()
        # The set of clients which issued the monitor command
        self._monitors = set()
        self.logger = server.logger
        #
        self.NOTIFY_KEYSPACE = (1 << 0)
        self.NOTIFY_KEYEVENT = (1 << 1)
        self.NOTIFY_GENERIC = (1 << 2)
        self.NOTIFY_STRING = (1 << 3)
        self.NOTIFY_LIST = (1 << 4)
        self.NOTIFY_SET = (1 << 5)
        self.NOTIFY_HASH = (1 << 6)
        self.NOTIFY_ZSET = (1 << 7)
        self.NOTIFY_EXPIRED = (1 << 8)
        self.NOTIFY_EVICTED = (1 << 9)
        self.NOTIFY_ALL = (self.NOTIFY_GENERIC | self.NOTIFY_STRING |
                           self.NOTIFY_LIST | self.NOTIFY_SET |
                           self.NOTIFY_HASH | self.NOTIFY_ZSET |
                           self.NOTIFY_EXPIRED | self.NOTIFY_EVICTED)

        self.MONITOR = (1 << 2)
        self.MULTI = (1 << 3)
        self.BLOCKED = (1 << 4)
        self.DIRTY_CAS = (1 << 5)
        #
        self._event_handlers = {self.NOTIFY_GENERIC: self._generic_event,
                                self.NOTIFY_STRING: self._string_event,
                                self.NOTIFY_SET: self._set_event,
                                self.NOTIFY_HASH: self._hash_event,
                                self.NOTIFY_LIST: self._list_event,
                                self.NOTIFY_ZSET: self._zset_event}
        self._set_options = (b'ex', b'px', 'nx', b'xx')
        self.OK = b'+OK\r\n'
        self.QUEUED = b'+QUEUED\r\n'
        self.ZERO = b':0\r\n'
        self.ONE = b':1\r\n'
        self.NIL = b'$-1\r\n'
        self.NULL_ARRAY = b'*-1\r\n'
        self.INVALID_TIMEOUT = 'invalid expire time'
        self.PUBSUB_ONLY = ('only (P)SUBSCRIBE / (P)UNSUBSCRIBE / QUIT '
                            'allowed in this context')
        self.INVALID_SCORE = 'Invalid score value'
        self.NOT_SUPPORTED = 'Command not yet supported'
        self.OUT_OF_BOUND = 'Out of bound'
        self.SYNTAX_ERROR = 'Syntax error'
        self.SUBSCRIBE_COMMANDS = ('psubscribe', 'punsubscribe', 'subscribe',
                                   'unsubscribe', 'quit')
        self.encoder = pickle
        self.hash_type = Dict
        self.list_type = Deque
        self.zset_type = Zset
        self.data_types = (bytearray, set, self.hash_type,
                           self.list_type, self.zset_type)
        self.zset_aggregate = {b'min': min,
                               b'max': max,
                               b'sum': sum}
        self._type_event_map = {bytearray: self.NOTIFY_STRING,
                                self.hash_type: self.NOTIFY_HASH,
                                self.list_type: self.NOTIFY_LIST,
                                set: self.NOTIFY_SET,
                                self.zset_type: self.NOTIFY_ZSET}
        self._type_name_map = {bytearray: 'string',
                               self.hash_type: 'hash',
                               self.list_type: 'list',
                               set: 'set',
                               self.zset_type: 'zset'}
        self.databases = dict(((num, Db(num, self))
                               for num in range(cfg.key_value_databases)))
        # Initialise lua
        if Lua:
            self.lua = Lua()
            self.scripts = {}
            self.lua.register('redis', LuaClient(self),
                              'call', 'pcall', 'error_reply', 'status_reply')
            self.version = '2.6.16'
        else:   # pragma    nocover
            self.lua = None
            self.version = '2.4.10'
        self._loaddb()
        pulsar.call_repeatedly(self._loop, 1, self._cron)

    # #########################################################################
    # #    KEYS COMMANDS
    @command('Keys', True, name='del')
    def delete(self, client, request, N):
        check_input(request, not N)
        rem = client.db.rem
        result = reduce(lambda x, y: x + rem(y), request[1:], 0)
        client.reply_int(result)

    @command('Keys')
    def dump(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_bulk()
        else:
            client.reply_bulk(self.encoder.dumps(value))

    @command('Keys')
    def exists(self, client, request, N):
        check_input(request, N != 1)
        if client.db.exists(request[1]):
            client.reply_one()
        else:
            client.reply_zero()

    @command('Keys', True)
    def expire(self, client, request, N, m=1):
        check_input(request, N != 2)
        try:
            timeout = int(request[2])
        except ValueError:
            client.reply_error(self.INVALID_TIMEOUT)
        else:
            if timeout:
                if timeout < 0:
                    return client.reply_error(self.INVALID_TIMEOUT)
                if client.db.expire(request[1], m*timeout):
                    return client.reply_one()
            client.reply_zero()

    @command('Keys', True)
    def expireat(self, client, request, N, M=1):
        check_input(request, N != 2)
        try:
            timeout = int(request[2])
        except ValueError:
            client.reply_error(self.INVALID_TIMEOUT)
        else:
            if timeout:
                if timeout < 0:
                    return client.reply_error(self.INVALID_TIMEOUT)
                timeout = M*timeout - time.time()
                if client.db.expire(request[1], timeout):
                    return client.reply_one()
            client.reply_zero()

    @command('Keys')
    def keys(self, client, request, N):
        err = 'ignore'
        check_input(request, N != 1)
        pattern = request[1].decode('utf-8', err)
        allkeys = pattern == '*'
        gr = None
        if not allkeys:
            gr = re.compile(redis_to_py_pattern(pattern))
        result = [key for key in client.db if allkeys or
                  gr.search(key.decode('utf-8', err))]
        client.reply_multi_bulk(result)

    @command('Keys', supported=False)
    def migrate(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    @command('Keys', True)
    def move(self, client, request, N):
        check_input(request, N != 2)
        key = request[1]
        try:
            db2 = self.databases.get(int(request[2]))
            if db2 is None:
                raise ValueError
        except Exception:
            return client.reply_zero()
        db = client.db
        value = db.get(key)
        if db2.exists(key) or value is None:
            return client.reply_zero()
        assert value
        db.pop(key)
        self._signal(self.NOTIFY_GENERIC, db, 'del', key, 1)
        db2._data[key] = value
        self._signal(self._type_event_map[type(value)], db2, 'set', key, 1)
        client.reply_one()

    @command('Keys', supported=False)
    def object(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    @command('Keys', True)
    def persist(self, client, request, N):
        check_input(request, N != 1)
        if client.db.persist(request[1]):
            client.reply_one()
        else:
            client.reply_zero()

    @command('Keys', True)
    def pexpire(self, client, request, N):
        self.expire(client, request, N, 0.001)

    @command('Keys', True)
    def pexpireat(self, client, request, N, M=1):
        self.expireat(client, request, N, 0.001)

    @command('Keys')
    def pttl(self, client, request, N):
        check_input(request, N != 1)
        client.reply_int(client.db.ttl(request[1], 1000))

    @command('Keys')
    def randomkey(self, client, request, N):
        check_input(request, N)
        keys = list(client.db)
        if keys:
            client.reply_bulk(choice(keys))
        else:
            client.reply_bulk()

    @command('Keys', True)
    def rename(self, client, request, N, ex=False):
        check_input(request, N != 2)
        key1, key2 = request[1], request[2]
        db = client.db
        value = db.get(key1)
        if value is None:
            client.reply_error('Cannot rename key, not available')
        elif key1 == key2:
            client.reply_error('Cannot rename key')
        else:
            assert value
            if ex:
                if db.exists(key2):
                    return client.reply_zero()
                result = 1
            else:
                result = 0
                if db.pop(key2) is not None:
                    self._signal(self.NOTIFY_GENERIC, db, 'del', key2)
            db.pop(key1)
            event = self._type_event_map[type(value)]
            dirty = 1 if event == self.NOTIFY_STRING else len(value)
            db._data[key2] = value
            self._signal(event, db, request[0], key2, dirty)
            client.reply_one() if result else client.reply_ok()

    @command('Keys', True)
    def renamenx(self, client, request, N):
        self.rename(client, request, N, True)

    @command('Keys', True)
    def restore(self, client, request, N):
        check_input(request, N != 3)
        key = request[1]
        db = client.db
        try:
            value = self.encoder.loads(request[3])
        except Exception:
            value = None
        if not isinstance(value, self.data_types):
            return client.reply_error('Could not decode value')
        try:
            ttl = int(request[2])
        except Exception:
            return client.reply_error(self.INVALID_TIMEOUT)
        if db.pop(key) is not None:
            self._signal(self.NOTIFY_GENERIC, db, 'del', key)
        db._data[key] = value
        if ttl > 0:
            db.expire(key, ttl)
        client.reply_ok()

    @command('Keys', True)
    def sort(self, client, request, N):
        check_input(request, not N)
        value = client.db.get(request[1])
        if value is None:
            value = self.list_type()
        elif not isinstance(value, (set, self.list_type, self.zset_type)):
            return client.reply_wrongtype()
        sort_command(self, client, request, value)

    @command('Keys', True)
    def ttl(self, client, request, N):
        check_input(request, N != 1)
        client.reply_int(client.db.ttl(request[1]))

    @command('Keys', True)
    def type(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            result = 'none'
        else:
            result = self._type_name_map[type(value)]
        client.reply_status(result)

    @command('Keys', supported=False)
    def scan(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    # #########################################################################
    # #    STRING COMMANDS
    @command('Strings', True)
    def append(self, client, request, N):
        check_input(request, N != 2,)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            value = bytearray(request[2])
            db._data[key] = value
        elif not isinstance(value, bytearray):
            return client.reply_wrongtype()
        else:
            assert value
            value.extend(request[2])
        self._signal(self.NOTIFY_STRING, db, request[0], key, 1)
        client.reply_int(len(value))

    @command('Strings')
    def bitcount(self, client, request, N):
        check_input(request, N < 1 or N > 3)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            client.reply_int(0)
        elif not isinstance(value, bytearray):
            return client.reply_wrongtype()
        else:
            assert value
            if N > 1:
                start = request[2]
                end = request[3] if N == 3 else -1
                start, end = self._range_values(value, start, end)
                value = value[start:end]
            client.reply_int(count_bytes(value))

    @command('Strings', True)
    def bitop(self, client, request, N):
        check_input(request, N < 3)
        db = client.db
        op = request[1].lower()
        if op == b'and':
            reduce_op = and_op
        elif op == b'or':
            reduce_op = or_op
        elif op == b'xor':
            reduce_op = xor_op
        elif op == b'not':
            reduce_op = None
            check_input(request, N != 3)
        else:
            return client.reply_error('bad command')
        empty = bytearray()
        keys = []
        for key in request[3:]:
            value = db.get(key)
            if value is None:
                keys.append(empty)
            elif isinstance(value, bytearray):
                keys.append(value)
            else:
                return client.reply_wrongtype()
        result = bytearray()
        if reduce_op is None:
            for value in keys[0]:
                result.append(~value & 255)
        else:
            for values in zip_longest(*keys, **{'fillvalue': 0}):
                result.append(reduce(reduce_op, values))
        if result:
            dest = request[2]
            if db.pop(dest):
                self._signal(self.NOTIFY_GENERIC, db, 'del', dest)
            db._data[dest] = result
            self._signal(self.NOTIFY_STRING, db, 'set', dest, 1)
            client.reply_int(len(result))
        else:
            client.reply_zero()

    @command('Strings', True)
    def decr(self, client, request, N):
        check_input(request, N != 1)
        r = self._incrby(client, request[0], request[1], b'-1', int)
        client.reply_int(r)

    @command('Strings', True)
    def decrby(self, client, request, N):
        check_input(request, N != 2)
        try:
            val = str(-int(request[2])).encode('utf-8')
        except Exception:
            val = request[2]
        r = self._incrby(client, request[0], request[1], val, int)
        client.reply_int(r)

    @command('Strings')
    def get(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_bulk()
        elif isinstance(value, bytearray):
            assert value
            client.reply_bulk(bytes(value))
        else:
            client.reply_wrongtype()

    @command('Strings')
    def getbit(self, client, request, N):
        check_input(request, N != 2)
        try:
            bitoffset = int(request[2])
            if bitoffset < 0 or bitoffset >= STRING_LIMIT:
                raise ValueError
        except Exception:
            return client.reply_error(
                "bit offset is not an integer or out of range")
        string = client.db.get(request[1])
        if string is None:
            client.reply_zero()
        elif not isinstance(string, bytearray):
            client.reply_wrongtype()
        else:
            assert string
            byte = bitoffset >> 3
            if len(string) > byte:
                bit = 7 - (bitoffset & 7)
                v = string[byte] & (1 << bit)
                client.reply_int(1 if v else 0)
            else:
                client.reply_zero()

    @command('Strings')
    def getrange(self, client, request, N):
        check_input(request, N != 3)
        try:
            start = int(request[2])
            end = int(request[3])
        except Exception:
            return client.reply_error("Wrong offset in '%s' command" %
                                      request[0])
        string = client.db.get(request[1])
        if string is None:
            client.reply_bulk(b'')
        elif not isinstance(string, bytearray):
            client.reply_wrongtype()
        else:
            if start < 0:
                start = len(string) + start
            if end < 0:
                end = len(string) + end + 1
            else:
                end += 1
            client.reply_bulk(bytes(string[start:end]))

    @command('Strings', True)
    def getset(self, client, request, N):
        check_input(request, N != 2)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            db._data[key] = bytearray(request[2])
            self._signal(self.NOTIFY_STRING, db, 'set', key, 1)
            client.reply_bulk()
        elif isinstance(value, bytearray):
            db.pop(key)
            db._data[key] = bytearray(request[2])
            self._signal(self.NOTIFY_STRING, db, 'set', key, 1)
            client.reply_bulk(bytes(value))
        else:
            client.reply_wrongtype()

    @command('Strings', True)
    def incr(self, client, request, N):
        check_input(request, N != 1)
        r = self._incrby(client, request[0], request[1], b'1', int)
        client.reply_int(r)

    @command('Strings', True)
    def incrby(self, client, request, N):
        check_input(request, N != 2)
        r = self._incrby(client, request[0], request[1], request[2], int)
        client.reply_int(r)

    @command('Strings', True)
    def incrbyfloat(self, client, request, N):
        check_input(request, N != 2)
        r = self._incrby(client, request[0], request[1], request[2], float)
        client.reply_bulk(str(r).encode('utf-8'))

    @command('Strings')
    def mget(self, client, request, N):
        check_input(request, not N)
        get = client.db.get
        values = []
        for key in request[1:]:
            value = get(key)
            if value is None:
                values.append(value)
            elif isinstance(value, bytearray):
                values.append(bytes(value))
            else:
                return client.reply_wrongtype()
        client.reply_multi_bulk(values)

    @command('Strings', True)
    def mset(self, client, request, N):
        D = N // 2
        check_input(request, N < 2 or D * 2 != N)
        db = client.db
        for key, value in zip(request[1::2], request[2::2]):
            db.pop(key)
            db._data[key] = bytearray(value)
            self._signal(self.NOTIFY_STRING, db, 'set', key, 1)
        client.reply_ok()

    @command('Strings', True)
    def msetnx(self, client, request, N):
        D = N // 2
        check_input(request, N < 2 or D * 2 != N)
        db = client.db
        keys = request[1::2]
        exist = False
        for key in keys:
            exist = db.exists(key)
            if exist:
                break
        if exist:
            client.reply_zero()
        else:
            for key, value in zip(keys, request[2::2]):
                db._data[key] = bytearray(value)
                self._signal(self.NOTIFY_STRING, db, 'set', key, 1)
            client.reply_one()

    @command('Strings', True)
    def psetex(self, client, request, N):
        check_input(request, N != 3)
        self._set(client, request[1], request[3], milliseconds=request[2])
        client.reply_ok()

    @command('Strings', True)
    def set(self, client, request, N):
        check_input(request, N < 2 or N > 8)
        it = 2
        extra = set(self._set_options)
        seconds = 0
        milliseconds = 0
        nx = False
        xx = False
        while N > it:
            it += 1
            opt = request[it].lower()
            if opt in extra:
                extra.remove(opt)
                if opt == b'ex':
                    it += 1
                    seconds = request[it]
                elif opt == b'px':
                    it += 1
                    milliseconds = request[it]
                elif opt == b'nx':
                    nx = True
                else:
                    xx = True
        if self._set(client, request[1], request[2], seconds,
                     milliseconds, nx, xx):
            client.reply_ok()
        else:
            client.reply_bulk()

    @command('Strings', True)
    def setbit(self, client, request, N):
        check_input(request, N != 3)
        key = request[1]
        try:
            bitoffset = int(request[2])
            if bitoffset < 0 or bitoffset >= STRING_LIMIT:
                raise ValueError
        except Exception:
            return client.reply_error(
                "bit offset is not an integer or out of range")
        try:
            value = int(request[3])
            if value not in (0, 1):
                raise ValueError
        except Exception:
            return client.reply_error("bit is not an integer or out of range")
        db = client.db
        string = db.get(key)
        if string is None:
            string = bytearray()
            db._data[key] = string
        elif not isinstance(string, bytearray):
            return client.reply_wrongtype()
        else:
            assert string

        # grow value to the right if necessary
        byte = bitoffset >> 3
        num_bytes = len(string)
        if byte >= num_bytes:
            string.extend((byte + 1 - num_bytes)*b'\x00')

        # get current value
        byteval = string[byte]
        bit = 7 - (bitoffset & 7)
        bitval = byteval & (1 << bit)

        # update with new value
        byteval &= ~(1 << bit)
        byteval |= ((value & 1) << bit)
        string[byte] = byteval

        self._signal(self.NOTIFY_STRING, db, request[0], key, 1)
        client.reply_one() if bitval else client.reply_zero()

    @command('Strings', True)
    def setex(self, client, request, N):
        check_input(request, N != 3)
        self._set(client, request[1], request[3], seconds=request[2])
        client.reply_ok()

    @command('Strings', True)
    def setnx(self, client, request, N):
        check_input(request, N != 2)
        if self._set(client, request[1], request[2], nx=True):
            client.reply_one()
        else:
            client.reply_zero()

    @command('Strings', True)
    def setrange(self, client, request, N):
        check_input(request, N != 3)
        key = request[1]
        value = request[3]
        try:
            offset = int(request[2])
            T = offset + len(value)
            if offset < 0 or T >= STRING_LIMIT:
                raise ValueError
        except Exception:
            return client.reply_error("Wrong offset in '%s' command" %
                                      request[0])
        db = client.db
        string = db.get(key)
        if string is None:
            string = bytearray(b'\x00')
            db._data[key] = string
        elif not isinstance(string, bytearray):
            return client.reply_wrongtype()
        N = len(string)
        if N < T:
            string.extend((T + 1 - N)*b'\x00')
        string[offset:T] = value
        self._signal(self.NOTIFY_STRING, db, request[0], key, 1)
        client.reply_int(len(string))

    @command('Strings')
    def strlen(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_zero()
        elif isinstance(value, bytearray):
            client.reply_int(len(value))
        else:
            return client.reply_wrongtype()

    # #########################################################################
    # #    HASHES COMMANDS
    @command('Hashes', True)
    def hdel(self, client, request, N):
        check_input(request, N < 2)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            client.reply_zero()
        elif isinstance(value, self.hash_type):
            rem = 0
            for field in request[2:]:
                rem += 0 if value.pop(field, None) is None else 1
            self._signal(self.NOTIFY_HASH, db, request[0], key, rem)
            if db.pop(key, value) is not None:
                self._signal(self.NOTIFY_GENERIC, db, 'del', key)
            client.reply_int(rem)
        else:
            client.reply_wrongtype()

    @command('Hashes')
    def hexists(self, client, request, N):
        check_input(request, N != 2)
        value = client.db.get(request[1])
        if value is None:
            client.reply_zero()
        elif isinstance(value, self.hash_type):
            client.reply_int(int(request[2] in value))
        else:
            client.reply_wrongtype()

    @command('Hashes')
    def hget(self, client, request, N):
        check_input(request, N != 2)
        value = client.db.get(request[1])
        if value is None:
            client.reply_bulk()
        elif isinstance(value, self.hash_type):
            client.reply_bulk(value.get(request[2]))
        else:
            client.reply_wrongtype()

    @command('Hashes')
    def hgetall(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_multi_bulk(())
        elif isinstance(value, self.hash_type):
            client.reply_multi_bulk(value.flat())
        else:
            client.reply_wrongtype()

    @command('Hashes', True)
    def hincrby(self, client, request, N):
        result = self._hincrby(client, request, N, int)
        if result is not None:
            client.reply_int(result)

    @command('Hashes', True)
    def hincrbyfloat(self, client, request, N):
        result = self._hincrby(client, request, N, float)
        if result is not None:
            client.reply_bulk(str(result).encode('utf-8'))

    @command('Hashes')
    def hkeys(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_multi_bulk(())
        elif isinstance(value, self.hash_type):
            client.reply_multi_bulk(value)
        else:
            client.reply_wrongtype()

    @command('Hashes')
    def hlen(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_zero()
        elif isinstance(value, self.hash_type):
            client.reply_int(len(value))
        else:
            client.reply_wrongtype()

    @command('Hashes')
    def hmget(self, client, request, N):
        check_input(request, N < 3)
        value = client.db.get(request[1])
        if value is None:
            client.reply_multi_bulk(())
        elif isinstance(value, self.hash_type):
            result = value.mget(request[2:])
            client.reply_multi_bulk(result)
        else:
            client.reply_wrongtype()

    @command('Hashes', True)
    def hmset(self, client, request, N):
        D = (N - 1) // 2
        check_input(request, N < 3 or D * 2 != N - 1)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            value = self.hash_type()
            db._data[key] = value
        elif not isinstance(value, self.hash_type):
            return client.reply_wrongtype()
        it = iter(request[2:])
        value.update(zip(it, it))
        self._signal(self.NOTIFY_HASH, db, request[0], key, D)
        client.reply_ok()

    @command('Hashes', True)
    def hset(self, client, request, N):
        check_input(request, N != 3)
        key, field = request[1], request[2]
        db = client.db
        value = db.get(key)
        if value is None:
            value = self.hash_type()
            db._data[key] = value
        elif not isinstance(value, self.hash_type):
            return client.reply_wrongtype()
        avail = (field in value)
        value[field] = request[3]
        self._signal(self.NOTIFY_HASH, db, request[0], key, 1)
        client.reply_zero() if avail else client.reply_one()

    @command('Hashes', True)
    def hsetnx(self, client, request, N):
        check_input(request, N != 3)
        key, field = request[1], request[2]
        db = client.db
        value = db.get(key)
        if value is None:
            value = self.hash_type()
            db._data[key] = value
        elif not isinstance(value, self.hash_type):
            return client.reply_wrongtype()
        if field in value:
            client.reply_zero()
        else:
            value[field] = request[3]
            self._signal(self.NOTIFY_HASH, db, request[0], key, 1)
            client.reply_one()

    @command('Hashes')
    def hvals(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_multi_bulk(())
        elif isinstance(value, self.hash_type):
            client.reply_multi_bulk(tuple(value.values()))
        else:
            client.reply_wrongtype()

    @command('Hashes', supported=False)
    def hscan(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    # #########################################################################
    # #    LIST COMMANDS
    @command('Lists', True, script=0)
    def blpop(self, client, request, N):
        check_input(request, N < 2)
        try:
            timeout = max(0, int(request[-1]))
        except Exception:
            return client.reply_error(self.SYNTAX_ERROR)
        keys = request[1:-1]
        if not self._bpop(client, request, keys):
            client.blocked = Blocked(client, request[0], keys, timeout)

    @command('Lists', True, script=0)
    def brpop(self, client, request, N):
        return self.blpop(client, request, N)

    @command('Lists', True, script=0)
    def brpoplpush(self, client, request, N):
        check_input(request, N != 3)
        try:
            timeout = max(0, int(request[-1]))
        except Exception:
            return client.reply_error(self.SYNTAX_ERROR)
        key, dest = request[1:-1]
        keys = (key,)
        if not self._bpop(client, request, keys, dest):
            client.blocked = Blocked(client, request[0], keys, timeout, dest)

    @command('Lists')
    def lindex(self, client, request, N):
        check_input(request, N != 2)
        value = client.db.get(request[1])
        if value is None:
            client.reply_bulk()
        elif isinstance(value, self.list_type):
            assert value
            index = int(request[2])
            if index >= 0 and index < len(value):
                client.reply_bulk(value[index])
            else:
                client.reply_bulk()
        else:
            client.reply_wrongtype()

    @command('Lists', True)
    def linsert(self, client, request, N):
        # This method is INEFFICIENT, but redis supported so we do
        # the same here
        check_input(request, N != 4)
        db = client.db
        key = request[1]
        value = db.get(key)
        if value is None:
            client.reply_zero()
        elif not isinstance(value, self.list_type):
            client.reply_wrongtype()
        else:
            assert value
            where = request[2].lower()
            l1 = len(value)
            if where == b'before':
                value.insert_before(request[3], request[4])
            elif where == b'after':
                value.insert_after(request[3], request[4])
            else:
                return client.reply_error('cannot insert to list')
            l2 = len(value)
            if l2 - l1:
                self._signal(self.NOTIFY_LIST, db, request[0], key, 1)
                client.reply_int(l2)
            else:
                client.reply_int(-1)

    @command('Lists')
    def llen(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_zero()
        elif isinstance(value, self.list_type):
            assert value
            client.reply_int(len(value))
        else:
            client.reply_wrongtype()

    @command('Lists', True)
    def lpop(self, client, request, N):
        check_input(request, N != 1)
        db = client.db
        key = request[1]
        value = db.get(key)
        if value is None:
            client.reply_bulk()
        elif not isinstance(value, self.list_type):
            client.reply_wrongtype()
        else:
            assert value
            if request[0] == 'lpop':
                result = value.popleft()
            else:
                result = value.pop()
            self._signal(self.NOTIFY_LIST, db, request[0], key, 1)
            if db.pop(key, value) is not None:
                self._signal(self.NOTIFY_GENERIC, db, 'del', key)
            client.reply_bulk(result)

    @command('Lists', True)
    def rpop(self, client, request, N):
        return self.lpop(client, request, N)

    @command('Lists', True)
    def lpush(self, client, request, N):
        check_input(request, N < 2)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            value = self.list_type()
            db._data[key] = value
        elif not isinstance(value, self.list_type):
            return client.reply_wrongtype()
        else:
            assert value
        if request[0] == 'lpush':
            value.extendleft(request[2:])
        else:
            value.extend(request[2:])
        client.reply_int(len(value))
        self._signal(self.NOTIFY_LIST, db, request[0], key, N - 1)

    @command('Lists', True)
    def rpush(self, client, request, N):
        return self.lpush(client, request, N)

    @command('Lists', True)
    def lpushx(self, client, request, N):
        check_input(request, N != 2)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            client.reply_zero()
        elif not isinstance(value, self.list_type):
            client.reply_wrongtype()
        else:
            assert value
            if request[0] == 'lpushx':
                value.appendleft(request[2])
            else:
                value.append(request[2])
            client.reply_int(len(value))
            self._signal(self.NOTIFY_LIST, db, request[0], key, 1)

    @command('Lists', True)
    def rpushx(self, client, request, N):
        return self.lpushx(client, request, N)

    @command('Lists', True)
    def lrange(self, client, request, N):
        check_input(request, N != 3)
        db = client.db
        key = request[1]
        value = db.get(key)
        try:
            start, end = self._range_values(value, request[2], request[3])
        except Exception:
            return client.reply_error('invalid range')
        if value is None:
            client.reply_multi_bulk(())
        elif not isinstance(value, self.list_type):
            client.reply_wrongtype()
        else:
            assert value
            client.reply_multi_bulk(tuple(islice(value, start, end)))

    @command('Lists', True)
    def lrem(self, client, request, N):
        # This method is INEFFICIENT, but redis supported so we do
        # the same here
        check_input(request, N != 3)
        db = client.db
        key = request[1]
        value = db.get(key)
        if value is None:
            client.reply_zero()
        elif not isinstance(value, self.list_type):
            client.reply_wrongtype()
        else:
            assert value
            try:
                count = int(request[2])
            except Exception:
                return client.reply_error('cannot remove from list')
            removed = value.remove(request[3], count)
            if removed:
                self._signal(self.NOTIFY_LIST, db, request[0], key, removed)
            client.reply_int(removed)
            if db.pop(key, value) is not None:
                self._signal(self.NOTIFY_GENERIC, db, 'del', key)

    @command('Lists', True)
    def lset(self, client, request, N):
        check_input(request, N != 3)
        db = client.db
        key = request[1]
        value = db.get(key)
        if value is None:
            client.reply_error(self.OUT_OF_BOUND)
        elif not isinstance(value, self.list_type):
            client.reply_wrongtype()
        else:
            assert value
            try:
                index = int(request[2])
            except Exception:
                index = -1
            if index >= 0 and index < len(value):
                value[index] = request[3]
                self._signal(self.NOTIFY_LIST, db, request[0], key, 1)
                client.reply_ok()
            else:
                client.reply_error(self.OUT_OF_BOUND)

    @command('Lists', True)
    def ltrim(self, client, request, N):
        check_input(request, N != 3)
        db = client.db
        key = request[1]
        value = db.get(key)
        try:
            start, end = self._range_values(value, request[2], request[3])
        except Exception:
            return client.reply_error('invalid range')
        if value is None:
            client.reply_ok()
        elif not isinstance(value, self.list_type):
            client.reply_wrongtype()
        else:
            assert value
            start = len(value)
            value.trim(start, end)
            client.reply_ok()
            self._signal(self.NOTIFY_LIST, db, request[0], key,
                         start-len(value))
            client.reply_ok()
            if db.pop(key, value) is not None:
                self._signal(self.NOTIFY_GENERIC, db, 'del', key)

    @command('Lists', True)
    def rpoplpush(self, client, request, N):
        check_input(request, N != 2)
        key1, key2 = request[1], request[2]
        db = client.db
        orig = db.get(key1)
        dest = db.get(key2)
        if orig is None:
            client.reply_bulk()
        elif not isinstance(orig, self.list_type):
            client.reply_wrongtype()
        else:
            assert orig
            if dest is None:
                dest = self.list_type()
                db._data[key2] = dest
            elif not isinstance(dest, self.list_type):
                return client.reply_wrongtype()
            else:
                assert dest
            value = orig.pop()
            self._signal(self.NOTIFY_LIST, db, 'rpop', key1, 1)
            dest.appendleft(value)
            self._signal(self.NOTIFY_LIST, db, 'lpush', key2, 1)
            if db.pop(key1, orig) is not None:
                self._signal(self.NOTIFY_GENERIC, db, 'del', key1)
            client.reply_bulk(value)

    # #########################################################################
    # #    SETS COMMANDS
    @command('Sets', True)
    def sadd(self, client, request, N):
        check_input(request, N < 2)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            value = set()
            db._data[key] = value
        elif not isinstance(value, set):
            return client.reply_wrongtype()
        n = len(value)
        value.update(request[2:])
        n = len(value) - n
        self._signal(self.NOTIFY_SET, db, request[0], key, n)
        client.reply_int(n)

    @command('Sets')
    def scard(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_zero()
        elif not isinstance(value, set):
            client.reply_wrongtype()
        else:
            client.reply_int(len(value))

    @command('Sets')
    def sdiff(self, client, request, N):
        check_input(request, N < 1)
        self._setoper(client, 'difference', request[1:])

    @command('Sets', True)
    def sdiffstore(self, client, request, N):
        check_input(request, N < 2)
        self._setoper(client, 'difference', request[2:], request[1])

    @command('Sets')
    def sinter(self, client, request, N):
        check_input(request, N < 1)
        self._setoper(client, 'intersection', request[1:])

    @command('Sets', True)
    def sinterstore(self, client, request, N):
        check_input(request, N < 2)
        self._setoper(client, 'intersection', request[2:], request[1])

    @command('Sets')
    def sismember(self, client, request, N):
        check_input(request, N != 2)
        value = client.db.get(request[1])
        if value is None:
            client.reply_zero()
        elif not isinstance(value, set):
            client.reply_wrongtype()
        else:
            client.reply_int(int(request[2] in value))

    @command('Sets')
    def smembers(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_multi_bulk(())
        elif not isinstance(value, set):
            client.reply_wrongtype()
        else:
            client.reply_multi_bulk(value)

    @command('Sets', True)
    def smove(self, client, request, N):
        check_input(request, N != 3)
        db = client.db
        key1 = request[1]
        key2 = request[2]
        orig = db.get(key1)
        dest = db.get(key2)
        if orig is None:
            client.reply_zero()
        elif not isinstance(orig, set):
            client.reply_wrongtype()
        else:
            member = request[3]
            if member in orig:
                # we my be able to move
                if dest is None:
                    dest = set()
                    db._data[request[2]] = dest
                elif not isinstance(dest, set):
                    return client.reply_wrongtype()
                orig.remove(member)
                dest.add(member)
                self._signal(self.NOTIFY_SET, db, 'srem', key1)
                self._signal(self.NOTIFY_SET, db, 'sadd', key2, 1)
                if db.pop(key1, orig) is not None:
                    self._signal(self.NOTIFY_GENERIC, db, 'del', key1)
                client.reply_one()
            else:
                client.reply_zero()

    @command('Sets', True)
    def spop(self, client, request, N):
        check_input(request, N != 1)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            client.reply_bulk()
        elif not isinstance(value, set):
            client.reply_wrongtype()
        else:
            result = value.pop()
            self._signal(self.NOTIFY_SET, db, request[0], key, 1)
            if db.pop(key, value) is not None:
                self._signal(self.NOTIFY_GENERIC, db, 'del', key)
            client.reply_bulk(result)

    @command('Sets')
    def srandmember(self, client, request, N):
        check_input(request, N < 1 or N > 2)
        value = client.db.get(request[1])
        if value is not None and not isinstance(value, set):
            return client.reply_wrongtype()
        if N == 2:
            try:
                count = int(request[2])
            except Exception:
                return client.reply_error('Invalid count')
            if count < 0:
                count = -count
                if not value:
                    result = (None,) * count
                else:
                    result = []
                    for _ in range(count):
                        el = value.pop()
                        result.append(el)
                        value.add(el)
            elif count > 0:
                if not value:
                    result = (None,)
                elif len(value) <= count:
                    result = list(value)
                    result.extend((None,)*(count-len(value)))
                else:
                    result = []
                    for _ in range(count):
                        el = value.pop()
                        result.append(el)
                    value.update(result)
            else:
                result = []
            client.reply_multi_bulk(result)
        else:
            if not value:
                result = None
            else:
                result = value.pop()
                value.add(result)
            client.reply_bulk(result)

    @command('Sets', True)
    def srem(self, client, request, N):
        check_input(request, N < 2)
        db = client.db
        key = request[1]
        value = db.get(key)
        if value is None:
            client.reply_zero()
        elif not isinstance(value, set):
            client.reply_wrongtype()
        else:
            start = len(value)
            value.difference_update(request[2:])
            removed = start - len(value)
            self._signal(self.NOTIFY_SET, db, request[0], key, removed)
            if db.pop(key, value) is not None:
                self._signal(self.NOTIFY_GENERIC, db, 'del', key)
            client.reply_int(removed)

    @command('Sets')
    def sunion(self, client, request, N):
        check_input(request, N < 1)
        self._setoper(client, 'union', request[1:])

    @command('Sets', True)
    def sunionstore(self, client, request, N):
        check_input(request, N < 2)
        self._setoper(client, 'union', request[2:], request[1])

    @command('Sets', supported=False)
    def sscan(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    # #########################################################################
    # #    SORTED SETS COMMANDS
    @command('Sorted Sets', True)
    def zadd(self, client, request, N):
        D = (N - 1) // 2
        check_input(request, N < 3 or D * 2 != N - 1)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            value = self.zset_type()
            db._data[key] = value
        elif not isinstance(value, self.zset_type):
            return client.reply_wrongtype()
        start = len(value)
        value.update(zip(map(float, request[2::2]), request[3::2]))
        result = len(value) - start
        self._signal(self.NOTIFY_ZSET, db, request[0], key, result)
        client.reply_int(result)

    @command('Sorted Sets')
    def zcard(self, client, request, N):
        check_input(request, N != 1)
        value = client.db.get(request[1])
        if value is None:
            client.reply_zero()
        elif not isinstance(value, self.zset_type):
            client.reply_wrongtype()
        else:
            client.reply_int(len(value))

    @command('Sorted Sets')
    def zcount(self, client, request, N):
        check_input(request, N != 3)
        value = client.db.get(request[1])
        if value is None:
            client.reply_zero()
        elif not isinstance(value, self.zset_type):
            client.reply_wrongtype()
        else:
            min_value, max_value = request[2], request[3]
            include_min = include_max = True
            if min_value and _ord(min_value[0]) == 40:
                include_min = False
                min_value = min_value[1:]
            if max_value and _ord(max_value[0]) == 40:
                include_max = False
                max_value = max_value[1:]
            try:
                mmin = float(min_value)
                mmax = float(max_value)
            except Exception:
                client.reply_error(self.INVALID_SCORE)
            else:
                client.reply_int(value.count(mmin, mmax,
                                             include_min, include_max))

    @command('Sorted Sets', True)
    def zincrby(self, client, request, N):
        check_input(request, N != 3)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            db._data[key] = value = self.zset_type()
        elif not isinstance(value, self.zset_type):
            return client.reply_wrongtype()
        try:
            increment = float(request[2])
        except Exception:
            client.reply_error(self.INVALID_SCORE)
        else:
            member = request[3]
            score = value.score(member, 0) + increment
            value.add(score, member)
            self._signal(self.NOTIFY_ZSET, db, request[0], key, 1)
            client.reply_bulk(str(score).encode('utf-8'))

    @command('Sorted Sets', True)
    def zinterstore(self, client, request, N):
        self._zsetoper(client, request, N)

    @command('Sorted Sets')
    def zrange(self, client, request, N):
        check_input(request, N < 3 or N > 4)
        value = client.db.get(request[1])
        if value is None:
            client.reply_multi_bulk(())
        elif not isinstance(value, self.zset_type):
            client.reply_wrongtype()
        else:
            try:
                start, end = self._range_values(value, request[2], request[3])
            except Exception:
                return client.reply_error(self.SYNTAX_ERROR)
            reverse = (request[0] == b'zrevrange')
            if N == 4:
                if request[4].lower() == b'withscores':
                    result = []
                    [result.extend((v, score)) for score, v in
                     value.range(start, end, scores=True)]
                else:
                    return client.reply_error(self.SYNTAX_ERROR)
            else:
                result = list(value.range(start, end))
            client.reply_multi_bulk(result)

    @command('Sorted Sets')
    def zrangebyscore(self, client, request, N):
        check_input(request, N < 3 or N > 7)
        value = client.db.get(request[1])
        if value is None:
            client.reply_multi_bulk(())
        elif not isinstance(value, self.zset_type):
            client.reply_wrongtype()
        else:
            try:
                minval, include_min, maxval, include_max = self._score_values(
                    request[2], request[3])
            except Exception:
                return client.reply_error(self.SYNTAX_ERROR)
            request = request[4:]
            withscores = False
            offset = 0
            count = None
            while request:
                if request[0].lower() == b'withscores':
                    withscores = True
                    request = request[1:]
                elif request[0].lower() == b'limit':
                    try:
                        offset = int(request[1])
                        count = int(request[2])
                    except Exception:
                        return client.reply_error(self.SYNTAX_ERROR)
                    request = request[3:]
                else:
                    return client.reply_error(self.SYNTAX_ERROR)
            if withscores:
                result = []
                [result.extend((v, score)) for score, v in
                 value.range_by_score(minval, maxval, scores=True,
                                      start=offset, num=count,
                                      include_min=include_min,
                                      include_max=include_max)]
            else:
                result = list(value.range_by_score(minval, maxval,
                                                   start=offset, num=count,
                                                   include_min=include_min,
                                                   include_max=include_max))
            client.reply_multi_bulk(result)

    @command('Sorted Sets')
    def zrank(self, client, request, N):
        check_input(request, N != 2)
        value = client.db.get(request[1])
        if value is None:
            client.reply_bulk()
        elif not isinstance(value, self.zset_type):
            client.reply_wrongtype()
        else:
            rank = value.rank(request[2])
            if rank is not None:
                client.reply_int(rank)
            else:
                client.reply_bulk()

    @command('Sorted Sets', True)
    def zrem(self, client, request, N):
        check_input(request, N < 2)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            client.reply_zero()
        elif not isinstance(value, self.zset_type):
            client.reply_wrongtype()
        else:
            removed = value.remove_items(request[2:])
            if removed:
                self._signal(self.NOTIFY_ZSET, db, request[0], key, removed)
            if db.pop(key, value) is not None:
                self._signal(self.NOTIFY_GENERIC, db, 'del', key)
            client.reply_int(removed)

    @command('Sorted Sets', True)
    def zremrangebyrank(self, client, request, N):
        check_input(request, N != 3)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            client.reply_zero()
        elif not isinstance(value, self.zset_type):
            client.reply_wrongtype()
        else:
            try:
                start, end = self._range_values(value, request[2], request[3])
            except Exception:
                return client.reply_error(self.SYNTAX_ERROR)
            removed = value.remove_range(start, end)
            if removed:
                self._signal(self.NOTIFY_ZSET, db, request[0], key, removed)
            if db.pop(key, value) is not None:
                self._signal(self.NOTIFY_GENERIC, db, 'del', key)
            client.reply_int(removed)

    @command('Sorted Sets', True)
    def zremrangebyscore(self, client, request, N):
        check_input(request, N != 3)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            client.reply_zero()
        elif not isinstance(value, self.zset_type):
            client.reply_wrongtype()
        else:
            try:
                minval, include_min, maxval, include_max = self._score_values(
                    request[2], request[3])
            except Exception:
                return client.reply_error(self.SYNTAX_ERROR)
            removed = value.remove_range_by_score(minval, maxval, include_min,
                                                  include_max)
            if removed:
                self._signal(self.NOTIFY_ZSET, db, request[0], key, removed)
            if db.pop(key, value) is not None:
                self._signal(self.NOTIFY_GENERIC, db, 'del', key)
            client.reply_int(removed)

    @command('Sorted Sets', supported=False)
    def zrevrange(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    @command('Sorted Sets', supported=False)
    def zrevrangebyscore(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    @command('Sorted Sets')
    def zscore(self, client, request, N):
        check_input(request, N != 2)
        key = request[1]
        db = client.db
        value = db.get(key)
        if value is None:
            client.reply_bulk(None)
        elif not isinstance(value, self.zset_type):
            client.reply_wrongtype()
        else:
            score = value.score(request[2], None)
            if score is not None:
                score = str(score).encode('utf-8')
            client.reply_bulk(score)

    @command('Sorted Sets', True)
    def zunionstore(self, client, request, N):
        self._zsetoper(client, request, N)

    @command('Sorted Sets', supported=False)
    def zscan(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    # #########################################################################
    # #    PUBSUB COMMANDS
    @command('Pub/Sub', script=0)
    def psubscribe(self, client, request, N):
        check_input(request, not N)
        for pattern in request[1:]:
            p = self._patterns.get(pattern)
            if not p:
                pre = redis_to_py_pattern(pattern.decode('utf-8'))
                p = pubsub_patterns(re.compile(pre), set())
                self._patterns[pattern] = p
            p.clients.add(client)
            client.patterns.add(pattern)
            count = reduce(lambda x, y: x + int(client in y.clients),
                           self._patterns.values())
            client.reply_multi_bulk((b'psubscribe', pattern, count))

    @command('Pub/Sub')
    def pubsub(self, client, request, N):
        check_input(request, not N)
        subcommand = request[1].decode('utf-8').lower()
        if subcommand == 'channels':
            check_input(request, N > 2)
            if N == 2:
                pre = re.compile(redis_to_py_pattern(
                    request[2].decode('utf-8')))
                channels = []
                for channel in self._channels:
                    if pre.match(channel.decode('utf-8', 'ignore')):
                        channels.append(channel)
            else:
                channels = list(self._channels)
            client.reply_multi_bulk(channels)
        elif subcommand == 'numsub':
            count = []
            for channel in request[2:]:
                clients = self._channels.get(channel, ())
                count.extend((channel, len(clients)))
            client.reply_multi_bulk(count)
        elif subcommand == 'numpat':
            check_input(request, N > 1)
            count = reduce(lambda x, y: x + len(y.clients),
                           self._patterns.values())
            client.reply_int(count)
        else:
            client.reply_error("Unknown command 'pubsub %s'" % subcommand)

    @command('Pub/Sub')
    def publish(self, client, request, N):
        check_input(request, N != 2)
        channel, message = request[1:]
        ch = channel.decode('utf-8')
        msg = self._parser.multi_bulk((b'message', channel, message))
        count = self._publish_clients(msg, self._channels.get(channel, ()))
        for pattern in self._patterns.values():
            g = pattern.re.match(ch)
            if g:
                count += self._publish_clients(msg, pattern.clients)
        client.reply_int(count)

    @command('Pub/Sub', script=0)
    def punsubscribe(self, client, request, N):
        patterns = request[1:] if N else list(self._patterns)
        for pattern in patterns:
            if pattern in self._patterns:
                p = self._patterns[pattern]
                if client in p.clients:
                    client.patterns.discard(pattern)
                    p.clients.remove(client)
                    if not p.clients:
                        self._patterns.pop(pattern)
                    client.reply_multi_bulk((b'punsubscribe', pattern))

    @command('Pub/Sub', script=0)
    def subscribe(self, client, request, N):
        check_input(request, not N)
        for channel in request[1:]:
            clients = self._channels.get(channel)
            if not clients:
                self._channels[channel] = clients = set()
            clients.add(client)
            client.channels.add(channel)
            client.reply_multi_bulk((b'subscribe', channel, len(clients)))

    @command('Pub/Sub', script=0)
    def unsubscribe(self, client, request, N):
        channels = request[1:] if N else list(self._channels)
        for channel in channels:
            if channel in self._channels:
                clients = self._channels[channel]
                if client in clients:
                    client.channels.discard(channel)
                    clients.remove(client)
                    if not clients:
                        self._channels.pop(channel)
                    client.reply_multi_bulk((b'unsubscribe', channel))

    # #########################################################################
    # #    TRANSACTION COMMANDS
    @command('Transactions', script=0)
    def discard(self, client, request, N):
        check_input(request, N)
        if client.transaction is None:
            client.reply_error("DISCARD without MULTI")
        else:
            self._close_transaction(client)
            client.reply_ok()

    @command('Transactions', name='exec', script=0)
    def execute(self, client, request, N):
        check_input(request, N)
        if client.transaction is None:
            client.reply_error("EXEC without MULTI")
        else:
            requests = client.transaction
            if client.flag & self.DIRTY_CAS:
                self._close_transaction(client)
                client.reply_multi_bulk(())
            else:
                self._close_transaction(client)
                client.reply_multi_bulk_len(len(requests))
                for handle, request in requests:
                    client._execute_command(handle, request)

    @command('Transactions', script=0)
    def multi(self, client, request, N):
        check_input(request, N)
        if client.transaction is None:
            client.reply_ok()
            client.transaction = []
        else:
            self.error_replay("MULTI calls can not be nested")

    @command('Transactions', script=0)
    def watch(self, client, request, N):
        check_input(request, not N)
        if client.transaction is not None:
            client.reply_error("WATCH inside MULTI is not allowed")
        else:
            wkeys = client.watched_keys
            if not wkeys:
                client.watched_keys = wkeys = set()
                self._watching.add(client)
            wkeys.update(request[1:])
            client.reply_ok()

    @command('Transactions', script=0)
    def unwatch(self, client, request, N):
        check_input(request, N)
        transaction = client.transaction
        self._close_transaction(client)
        client.transaction = transaction
        client.reply_ok()

    # #########################################################################
    # #    SCRIPTING
    @command('Scripting', script=0)
    def eval(self, client, request, N):
        check_input(request, N < 2)
        if not self.lua:
            return client.reply_error(self.SYNTAX_ERROR)
        script = request[1]
        self._eval_script(client, script, request)

    @command('Scripting', script=0)
    def evalsha(self, client, request, N):
        check_input(request, N < 2)
        if not self.lua:
            return client.reply_error(self.SYNTAX_ERROR)
        script = self.scripts.get(request[2])
        if script is None:
            client.reply_error('the script is not available', 'NOSCRIPT')
        else:
            self._eval_script(client, script, request)

    @command('Scripting', script=0)
    def script(self, client, request, N):
        check_input(request, not N)
        if not self.lua:
            return client.reply_error(self.SYNTAX_ERROR)
        scripts = self.scripts
        subcommand = request[1].upper()
        if subcommand == b'EXISTS':
            check_input(request, N < 2)
            result = [int(sha in scripts) for sha in request[2:]]
            client.reply_multi_bulk(result)
        elif subcommand == b'FLUSH':
            check_input(request, N != 1)
            scripts.clear()
            client.reply_ok()
        elif subcommand == b'KILL':
            check_input(request, N != 1)
            client.reply_ok()
        elif subcommand == b'LOAD':
            check_input(request, N != 2)
            script = request[2]
            sha = sha1(script).hexdigest().encode('utf-8')
            scripts[sha] = script
            client.reply_bulk(sha)

    # #########################################################################
    # #    CONNECTION COMMANDS
    @command('Connections', script=0)
    def auth(self, client, request, N):
        check_input(request, N != 1)
        client.password = request[1]
        if client.password != client._producer.password:
            client.reply_error("wrong password")
        else:
            client.reply_ok()

    @command('Connections')
    def echo(self, client, request, N):
        check_input(request, N != 1)
        client.reply_bulk(request[1])

    @command('Connections')
    def ping(self, client, request, N):
        check_input(request, N)
        client.reply_status('PONG')

    @command('Connections', script=0)
    def quit(self, client, request, N):
        check_input(request, N)
        client.reply_ok()
        client.close()

    @command('Connections')
    def select(self, client, request, N):
        check_input(request, N != 1)
        D = len(self.databases) - 1
        try:
            num = int(request[1])
            if num < 0 or num > D:
                raise ValueError
        except ValueError:
            client.reply_error(('select requires a database number between '
                                '%s and %s' % (0, D)))
        else:
            client.database = num
            client.reply_ok()

    # #########################################################################
    # #    SERVER COMMANDS
    @command('Server', supported=False)
    def bgrewriteaof(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    @command('Server')
    def bgsave(self, client, request, N):
        check_input(request, N)
        self._save()
        client.reply_ok()

    @command('Server')
    def client(self, client, request, N):
        check_input(request, not N)
        subcommand = request[1].decode('utf-8').lower()
        if subcommand == 'list':
            check_input(request, N != 1)
            value = '\n'.join(self._client_list(client))
            client.reply_bulk(value.encode('utf-8'))
        else:
            client.reply_error("unknown command 'client %s'" % subcommand)

    @command('Server')
    def config(self, client, request, N):
        check_input(request, not N)
        subcommand = request[1].decode('utf-8').lower()
        if subcommand == 'get':
            if N != 2:
                client.reply_error("'config get' no argument")
            else:
                value = self._get_config(request[2].decode('utf-8'))
                client.reply_bulk(value)
        elif subcommand == 'rewrite':
            client.reply_ok()
        elif subcommand == 'set':
            try:
                if N != 3:
                    raise ValueError("'config set' no argument")
                self._set_config(request[2].decode('utf-8'))
            except Exception as e:
                client.reply_error(str(e))
            else:
                client.reply_ok()
        elif subcommand == 'resetstat':
            self._hit_keys = 0
            self._missed_keys = 0
            self._expired_keys = 0
            server = client._producer
            server._received = 0
            server._requests_processed = 0
            client.reply_ok()
        else:
            client.reply_error("'config %s' not valid" % subcommand)

    @command('Server')
    def dbsize(self, client, request, N):
        check_input(request, N != 0)
        client.reply_int(len(client.db))

    @command('Server', supported=False, subcommands=['object', 'segfault'])
    def debug(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    @command('Server', True)
    def flushdb(self, client, request, N):
        check_input(request, N)
        client.db.flush()
        client.reply_ok()

    @command('Server', True)
    def flushall(self, client, request, N):
        check_input(request, N)
        for db in self.databases.values():
            db.flush()
        client.reply_ok()

    @command('Server')
    def info(self, client, request, N):
        check_input(request, N)
        info = '\n'.join(self._flat_info())
        client.reply_bulk(info.encode('utf-8'))

    @command('Server')
    def lastsave(self, client, request, N):
        check_input(request, N)
        client.reply_int(self._last_save)

    @command('Server', script=0)
    def monitor(self, client, request, N):
        check_input(request, N)
        client.flag |= self.MONITOR
        self._monitors.add(client)
        client.reply_ok()

    @command('Server', script=0)
    def save(self, client, request, N):
        check_input(request, N)
        self._save(False)
        client.reply_ok()

    @command('Server', supported=False)
    def shutdown(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    @command('Server', supported=False)
    def slaveof(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    @command('Server', supported=False)
    def slowlog(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    @command('Server', supported=False)
    def sync(self, client, request, N):
        client.reply_error(self.NOT_SUPPORTED)

    @command('Server')
    def time(self, client, request, N):
        check_input(request, N != 0)
        t = time.time()
        seconds = math.floor(t)
        microseconds = int(1000000*(t-seconds))
        client.reply_multi_bulk((seconds, microseconds))

    # #########################################################################
    # #    INTERNALS
    def _cron(self):
        dirty = self._dirty
        if dirty:
            now = time.time()
            gap = now - self._last_save
            for interval, changes in self.cfg.key_value_save:
                if gap >= interval and dirty >= changes:
                    self._save()
                    break

    def _set(self, client, key, value, seconds=0, milliseconds=0,
             nx=False, xx=False):
        try:
            seconds = int(seconds)
            milliseconds = 0.000001*int(milliseconds)
            if seconds < 0 or milliseconds < 0:
                raise ValueError
        except Exception:
            return client.reply_error('invalid expire time')
        else:
            timeout = seconds + milliseconds
        db = client.db
        exists = db.exists(key)
        skip = (exists and nx) or (not exists and xx)
        if not skip:
            if exists:
                db.pop(key)
            if timeout > 0:
                db._expires[key] = (self._loop.call_later(
                    timeout, db._do_expire, key), bytearray(value))
                self._signal(self.NOTIFY_STRING, db, 'expire', key)
            else:
                db._data[key] = bytearray(value)
            self._signal(self.NOTIFY_STRING, db, 'set', key, 1)
            return True

    def _incrby(self, client, name, key, value, type):
        try:
            tv = type(value)
        except Exception:
            return client.reply_error('invalid increment')
        db = client.db
        cur = db.get(key)
        if cur is None:
            db._data[key] = bytearray(value)
        elif isinstance(cur, bytearray):
            try:
                tv += type(cur)
            except Exception:
                return client.reply_error('invalid increment')
            db._data[key] = bytearray(str(tv).encode('utf-8'))
        else:
            return client.reply_wrongtype()
        self._signal(self.NOTIFY_STRING, db, name, key, 1)
        return tv

    def _bpop(self, client, request, keys, dest=None):
        list_type = self.list_type
        db = client.db
        for key in keys:
            value = db.get(key)
            if isinstance(value, list_type):
                self._block_callback(client, request[0], key, value, dest)
                return True
            elif value is not None:
                client.reply_wrongtype()
                return True
        return False

    def _block_callback(self, client, command, key, value, dest):
        db = client.db
        if command[:2] == 'br':
            if dest is not None:
                dval = db.get(dest)
                if dval is None:
                    dval = self.list_type()
                    db._data[dest] = dval
                elif not isinstance(dval, self.list_type):
                    return client.reply_wrongtype()
            elem = value.pop()
            self._signal(self.NOTIFY_LIST, db, 'rpop', key, 1)
            if dest is not None:
                dval.appendleft(elem)
                self._signal(self.NOTIFY_LIST, db, 'lpush', dest, 1)
        else:
            elem = value.popleft()
            self._signal(self.NOTIFY_LIST, db, 'lpop', key, 1)
        if not value:
            db.pop(key)
            self._signal(self.NOTIFY_GENERIC, db, 'del', key, 1)
        if dest is None:
            client.reply_multi_bulk((key, elem))
        else:
            client.reply_bulk(elem)

    def _range_values(self, value, start, end):
        start = int(start)
        end = int(end)
        if value is not None:
            if start < 0:
                start = len(value) + start
            if end < 0:
                end = len(value) + end + 1
            else:
                end += 1
        return start, end

    def _close_transaction(self, client):
        client.transaction = None
        client.watched_keys = None
        client.flag &= ~self.DIRTY_CAS
        self._watching.discard(client)

    def _flat_info(self):
        info = self._server.info()
        info['server']['redis_version'] = self.version
        e = self._encode_info_value
        for k, values in info.items():
            if isinstance(values, dict):
                yield '#%s' % k
                for key, value in values.items():
                    if isinstance(value, (list, tuple)):
                        value = ', '.join((e(v) for v in value))
                    elif isinstance(value, dict):
                        value = ', '.join(('%s=%s' % (k, e(v))
                                           for k, v in value.items()))
                    else:
                        value = e(value)
                    yield '%s:%s' % (key, value)

    def _get_config(self, name):
        return b''

    def _set_config(self, name, value):
        pass

    def _encode_info_value(self, value):
        return str(value).replace('=',
                                  ' ').replace(',',
                                               ' ').replace('\n', ' - ')

    def _hincrby(self, client, request, N, type):
        check_input(request, N != 3)
        key, field = request[1], request[2]
        try:
            increment = type(request[3])
        except Exception:
            return client.reply_error(
                'value is not an %s or out of range' % type.__name__)
        db = client.db
        hash = db.get(key)
        if hash is None:
            hash = self.hash_type()
            db._data[key] = hash
        elif not isinstance(hash, self.hash_type):
            return client.reply_wrongtype()
        if field in hash:
            try:
                value = type(hash[field])
            except Exception:
                return client.reply_error(
                    'hash value is not an %s' % type.__name__)
            increment += value
        hash[field] = increment
        self._signal(self.NOTIFY_HASH, db, request[0], key, 1)
        return increment

    def _setoper(self, client, oper, keys, dest=None):
        db = client.db
        result = None
        for key in keys:
            value = db.get(key)
            if value is None:
                value = set()
            elif not isinstance(value, set):
                return client.reply_wrongtype()
            if result is None:
                result = value
            else:
                result = getattr(result, oper)(value)
        if dest is not None:
            db.pop(dest)
            if result:
                db._data[dest] = result
                client.reply_int(len(result))
            else:
                client.reply_zero()
        else:
            client.reply_multi_bulk(result)

    def _zsetoper(self, client, request, N):
        check_input(request, N < 3)
        db = client.db
        cmnd = request[0]
        try:
            des = request[1]
            try:
                numkeys = int(request[2])
            except Exception:
                numkeys = 0
            if numkeys <= 0:
                raise ValueError('at least 1 input key is needed for '
                                 'ZUNIONSTORE/ZINTERSTORE')
            sets = []
            for key in request[3:3+numkeys]:
                value = db.get(key)
                if value is None:
                    value = self.zset_type()
                elif not isinstance(value, self.zset_type):
                    return client.reply_wrongtype()
                sets.append(value)
            if len(sets) != numkeys:
                raise ValueError('numkeys does not match number of sets')
            op = set((b'weights', b'aggregate'))
            request = request[3+numkeys:]
            weights = None
            aggregate = sum
            while request:
                name = request[0].lower()
                if name in op:
                    op.discard(name)
                    if name == b'weights':
                        weights = [float(v) for v in request[1:1+numkeys]]
                        request = request[1+numkeys:]
                    elif len(request) > 1:
                        aggregate = self.zset_aggregate.get(request[1])
                        request = request[2:]
                else:
                    raise ValueError(self.SYNTAX_ERROR)
            if not aggregate:
                raise ValueError(self.SYNTAX_ERRO)
            if weights is None:
                weights = [1]*numkeys
            elif len(weights) != numkeys:
                raise ValueError(self.SYNTAX_ERROR)
        except Exception as e:
            return client.reply_error(str(e))
        if cmnd == b'zunionstore':
            result = self.zset_type.union(sets, weights, aggregate)
        else:
            result = self.zset_type.inter(sets, weights, aggregate)
        if db.pop(des) is not None:
            self._signal(self.NOTIFY_GENERIC, db, 'del', des, 1)
        db._data[des] = result
        self._signal(self.NOTIFY_ZSET, db, cmnd, des, len(result))
        client.reply_int(len(result))

    def _score_values(self, min_value, max_value):
        include_min = include_max = True
        if min_value and _ord(min_value[0]) == 40:
            include_min = False
            min_value = min_value[1:]
        if max_value and _ord(max_value[0]) == 40:
            include_max = False
            max_value = max_value[1:]
        return float(min_value), include_min, float(max_value), include_max

    def _info(self):
        keyspace = {}
        stats = {'keyspace_hits': self._hit_keys,
                 'keyspace_misses': self._missed_keys,
                 'expired_keys': self._expired_keys,
                 'keys_changed': self._dirty,
                 'pubsub_channels': len(self._channels),
                 'pubsub_patterns': len(self._patterns),
                 'blocked_clients': self._bpop_blocked_clients}
        persistance = {'rdb_changes_since_last_save': self._dirty,
                       'rdb_last_save_time': self._last_save}
        for db in self.databases.values():
            if len(db):
                keyspace[str(db)] = db.info()
        return {'keyspace': keyspace,
                'stats': stats,
                'persistance': persistance}

    def _client_list(self, client):
        for client in client._producer._concurrent_connections:
            yield ' '.join(self._client_info(client))

    def _client_info(self, client):
        yield 'addr=%s:%s' % client._transport.get_extra_info('addr')
        yield 'fd=%s' % client._transport._sock_fd
        yield 'age=%s' % int(time.time() - client.started)
        yield 'db=%s' % client.database
        yield 'sub=%s' % len(client.channels)
        yield 'psub=%s' % len(client.patterns)
        yield 'cmd=%s' % client.last_command

    def _save(self, async=True):
        writer = self._writer
        if writer and writer.is_alive():
            self.logger.warning('Cannot save, background saving in progress')
        else:
            data = self._dbs()
            self._dirty = 0
            self._last_save = int(time.time())
            if async:
                self.logger.debug('Saving database in background process')
                self._writer = Process(target=save_data,
                                       args=(self.cfg, self._filename, data))
                self._writer.start()
            else:
                self.logger.debug('Saving database')
                save_data(self.cfg, self._filename, data)

    def _dbs(self):
        data = [(db._num, db._data) for db in self.databases.values()
                if len(db._data)]
        return (1, data)

    def _loaddb(self):
        filename = self._filename
        if os.path.isfile(filename):
            self.logger.info('loading data from "%s"', filename)
            with open(filename, 'rb') as file:
                data = pickle.load(file)
            version, dbs = data
            for num, data in dbs:
                db = self.databases.get(num)
                if db is not None:
                    db._data = data

    def _signal(self, type, db, command, key=None, dirty=0):
        self._dirty += dirty
        self._event_handlers[type](db, key, COMMANDS_INFO[command])

    def _publish_clients(self, msg, clients):
        remove = set()
        count = 0
        for client in clients:
            try:
                client._transport.write(msg)
                count += 1
            except Exception:
                remove.add(client)
        if remove:
            clients.difference_update(remove)
        return count

    # EVENT HANDLERS
    def _modified_key(self, key):
        for client in self._watching:
            if key is None or key in client.watched_keys:
                client.flag |= self.DIRTY_CAS

    def _generic_event(self, db, key, command):
        if command.write:
            self._modified_key(key)

    _string_event = _generic_event
    _set_event = _generic_event
    _hash_event = _generic_event
    _zset_event = _generic_event

    def _list_event(self, db, key, command):
        if command.write:
            self._modified_key(key)
        # the key is blocking clients
        if key in db._blocking_keys:
            if key in db._data:
                value = db._data[key]
            elif key in self._expires:
                value = db._expires[key]
            else:
                value = None
            for client in db._blocking_keys.pop(key):
                client.blocked.unblock(client, key, value)

    def _remove_connection(self, client, _, **kw):
        # Remove a client from the server
        self._monitors.discard(client)
        self._watching.discard(client)
        for channel, clients in list(self._channels.items()):
            clients.discard(client)
            if not clients:
                self._channels.pop(channel)
        for pattern, p in list(self._patterns.items()):
            p.clients.discard(client)
            if not p.clients:
                self._patterns.pop(pattern)

    def _write_to_monitors(self, client, request):
        # addr = '%s:%s' % self._transport.get_extra_info('addr')
        cmds = b'" "'.join(request)
        message = '+%s [0 %s] "'.encode('utf-8') + cmds + b'"\r\n'
        remove = set()
        for m in self._monitors:
            try:
                m._transport.write(message)
            except Exception:
                remove.add(m)
        if remove:
            self._monitors.difference_update(remove)

    def _eval_script(self, client, script, request):
        try:
            numkeys = int(request[2])
            if numkeys > 0:
                keys = request[3:3+numkeys]
                if len(keys) < numkeys:
                    raise ValueError
            elif numkeys < 0:
                raise ValueError
            else:
                keys = []
        except Exception:
            return client.reply_error(self.SYNTAX_ERROR)
        args = request[3+numkeys:]
        self.lua.set_global('KEYS', keys)
        self.lua.set_global('ARGV', args)
        result = self.lua.execute(script)
        if isinstance(result, dict):
            if len(result) == 1:
                key = tuple(result)[0]
                keyu = key.upper()
                if keyu == b'OK':
                    return client.reply_ok()
                elif keyu == b'ERR':
                    return client.reply_error(result[key])
                else:
                    return client.reply_multi_bulk(())
            else:
                array = []
                index = 0
                while result:
                    index += 1
                    value = result.pop(index, None)
                    if value is None:
                        break
                    array.append(value)
                result = array
        if isinstance(result, list):
            client.reply_multi_bulk(result)
        elif result is True:
            client.reply_one()
        elif result is False:
            client.reply_bulk()
        elif isinstance(result, (int, float)):
            client.reply_int(int(result))
        else:
            client.reply_bulk(result)


class Db(object):
    '''The database.
    '''
    def __init__(self, num, store):
        self.store = store
        self._num = num
        self._loop = store._loop
        self._data = {}
        self._expires = {}
        self._events = {}
        self._blocking_keys = {}

    def __repr__(self):
        return 'db%s' % self._num
    __str__ = __repr__

    def __len__(self):
        return len(self._data) + len(self._expires)

    def __iter__(self):
        return chain(self._data, self._expires)

    # #########################################################################
    # #    INTERNALS
    def flush(self):
        removed = len(self._data)
        self._data.clear()
        [handle.cancel() for handle, _ in self._expires.values()]
        self._expires.clear()
        self.store._signal(self.store.NOTIFY_GENERIC, self, 'flushdb',
                           dirty=removed)

    def get(self, key, default=None):
        if key in self._data:
            self.store._hit_keys += 1
            return self._data[key]
        elif key in self._expires:
            self.store._hit_keys += 1
            return self._expires[key]
        else:
            self.store._missed_keys += 1
            return default

    def exists(self, key):
        return key in self._data or key in self._expires

    def expire(self, key, timeout):
        if key in self._expires:
            handle, value = self._expires.pop(key)
            handle.cancel()
        elif key in self._data:
            value = self._data.pop(key)
        else:
            return False
        self._expires[key] = (self._loop.call_later(
            timeout, self._do_expire, key), value)
        return True

    def persist(self, key):
        if key in self._expires:
            self.store._hit_keys += 1
            handle, value = self._expires.pop(key)
            handle.cancel()
            self._data[key] = value
            return True
        elif key in self._data:
            self.store._hit_keys += 1
        else:
            self.store._missed_keys += 1
        return False

    def ttl(self, key, m=1):
        if key in self._expires:
            self.store._hit_keys += 1
            handle, value = self._expires[key]
            return max(0, int(m*(handle._when - self._loop.time())))
        elif key in self._data:
            self.store._hit_keys += 1
            return -1
        else:
            self.store._missed_keys += 1
            return -2

    def info(self):
        return {'Keys': len(self._data),
                'expires': len(self._expires)}

    def pop(self, key, value=None):
        if not value:
            if key in self._data:
                value = self._data.pop(key)
                return value
            elif key in self._expires:
                handle, value = self._expires.pop(key)
                handle.cancel()
                return value

    def rem(self, key):
        if key in self._data:
            self.store._hit_keys += 1
            self._data.pop(key)
            self.store._signal(self.store.NOTIFY_GENERIC, self, 'del', key, 1)
            return 1
        elif key in self._expires:
            self.store._hit_keys += 1
            handle, _ = self._expires.pop(key)
            handle.cancel()
            self.store._signal(self.store.NOTIFY_GENERIC, self, 'del', key, 1)
            return 1
        else:
            self.store._missed_keys += 1
            return 0

    def _do_expire(self, key):
        if key in self._expires:
            handle, value, = self._expires.pop(key)
            handle.cancel()
            self.store._expired_keys += 1

########NEW FILE########
__FILENAME__ = utils
import shutil

from pulsar.utils.pep import pickle


def save_data(cfg, filename, data):
    logger = cfg.configured_logger('ds')
    temp = 'temp_%s' % filename
    with open(temp, 'wb') as file:
        pickle.dump(data, file, protocol=2)
    shutil.move(temp, filename)
    logger.info('wrote data into "%s"', filename)


def sort_command(store, client, request, value):
    sort_type = type(value)
    right = 0
    desc = False
    alpha = None
    start = None
    end = None
    storekey = None
    sortby = None
    dontsort = False
    getops = []
    N = len(request)
    j = 2
    while j < N:
        val = request[j].lower()
        right = N - j - 1
        if val == b'asc':
            desc = False
        elif val == b'desc':
            desc = True
        elif val == b'alpha':
            alpha = True
        elif val == b'limit' and right >= 2:
            try:
                start = max(0, int(request[j+1]))
                count = int(request[j+2])
            except Exception:
                return client.error_reply(store.SYNTAX_ERROR)
            end = len(value) if count <= 0 else start + count
            j += 2
        elif val == b'store' and right >= 1:
            storekey = request[j+1]
            j += 1
        elif val == b'by' and right >= 1:
            sortby = request[j+1]
            if b'*' not in sortby:
                dontsort = True
            j += 1
        elif val == b'get' and right >= 1:
            getops.append(request[j+1])
            j += 1
        else:
            return client.error_reply(store.SYNTAX_ERROR)
        j += 1

    db = client.db
    if sort_type is store.zset_type and dontsort:
        dontsort = False
        alpha = True
        sortby = None

    vector = []
    sortable = SortableDesc if desc else Sortable
    #
    if not dontsort:
        for val in value:
            if sortby:
                byval = lookup(store, db, sortby, val)
                if byval is None:
                    vector.append((val, null))
                    continue
            else:
                byval = val
            if not alpha:
                try:
                    byval = sortable(float(byval))
                except Exception:
                    byval = null
            else:
                byval = sortable(byval)
            vector.append((val, byval))

        vector = sorted(vector, key=lambda x: x[1])
        if start is not None:
            vector = vector[start:end]
        vector = [val for val, _ in vector]
    else:
        vector = list(value)
        if start is not None:
            vector = vector[start:end]

    if storekey is None:
        if getops:
            result = []
            for val in vector:
                for getv in getops:
                    gval = lookup(store, db, getv, val)
                    result.append(gval)
            vector = result
        client.reply_multi_bulk(vector)
    else:
        if getops:
            vals = store.list_type()
            empty = b''
            for val in vector:
                for getv in getops:
                    vals.append(lookup(store, db, getv, val) or empty)
        else:
            vals = store.list_type(vector)
        if db.pop(storekey) is not None:
            store._signal(store.NOTIFY_GENERIC, db, 'del', storekey)
        result = len(vals)
        if result:
            db._data[storekey] = vals
            store._signal(store.NOTIFY_LIST, db, 'sort', storekey, result)
        client.reply_int(result)


def lookup(store, db, pattern, repl):
    if pattern == b'#':
        return repl
    key = pattern.replace(b'*', repl)
    bits = key.split(b'->', 1)
    if len(bits) == 1:
        string = db.get(key)
        return bytes(string) if isinstance(string, bytearray) else None
    else:
        key, field = bits
        hash = db.get(key)
        return hash.get(field) if isinstance(hash, store.hash_type) else None


class Null:
    __slots__ = ()

    def __lt__(self, other):
        return False

null = Null()


class Sortable:
    __slots__ = ('value',)

    def __init__(self, value):
        self.value = value

    def __lt__(self, other):
        if other is null:
            return True
        else:
            return self.value < other.value


class SortableDesc:
    __slots__ = ('value',)

    def __init__(self, value):
        self.value = value

    def __lt__(self, other):
        if other is null:
            return True
        else:
            return self.value > other.value


def count_bytes(array):
    '''Count the number of bits in a byte ``array``.

    It uses the Hamming weight popcount algorithm
    '''
    # this algorithm can be rewritten as
    # for i in array:
    #     count += sum(b=='1' for b in bin(i)[2:])
    # but this version is almost 2 times faster
    count = 0
    for i in array:
        i = i - ((i >> 1) & 0x55555555)
        i = (i & 0x33333333) + ((i >> 2) & 0x33333333)
        count += (((i + (i >> 4)) & 0x0F0F0F0F) * 0x01010101) >> 24
    return count


and_op = lambda x, y: x & y
or_op = lambda x, y: x | y
xor_op = lambda x, y: x ^ y

########NEW FILE########
__FILENAME__ = auth
import os
import time
from hashlib import sha1
from base64 import b64encode

from pulsar.utils.httpurl import (parse_dict_header, hexmd5, hexsha1,
                                  urlparse, native_str, DEFAULT_CHARSET)

from .plugins import request_again


__all__ = ['Auth',
           'HTTPBasicAuth',
           'HTTPDigestAuth']


class Auth(object):
    '''Base class for managing authentication.
    '''
    type = None

    def __call__(self, response, exc=None):
        raise NotImplementedError

    def __str__(self):
        return self.__repr__()


class HTTPBasicAuth(Auth):
    '''HTTP Basic Authentication handler.'''
    def __init__(self, username, password, status_code=401):
        self.username = username
        self.password = password
        self.status_code = status_code

    @property
    def type(self):
        return 'basic'

    def __call__(self, response, exc=None):
        # pre_request event. Must return response instance!
        response.request.headers['Authorization'] = self.header()
        return response

    def header(self):
        b64 = b64encode(('%s:%s' % (
            self.username, self.password)).encode(DEFAULT_CHARSET))
        return 'Basic %s' % native_str(b64.strip(), DEFAULT_CHARSET)

    def __repr__(self):
        return 'Basic: %s' % self.username


class HTTPDigestAuth(Auth):
    '''HTTP Digest Authentication handler.'''
    def __init__(self, username, password=None, options=None):
        self.username = username
        self.password = password
        self.last_nonce = None
        self.options = options or {}
        self.algorithm = self.options.pop('algorithm', 'MD5')

    @property
    def type(self):
        return 'digest'

    def __call__(self, response, exc=None):
        # pre_request event. Must return response instance!
        # If we have a saved nonce, skip the 401
        if self.last_nonce:
            request = response.request
            request.headers['Authorization'] =\
                self.encode(request.method, request.full_url)
        else:
            # add post request handler
            response.bind_event('post_request', self.handle_401)
        return response

    def __repr__(self):
        return 'Digest: %s' % self.username

    def encode(self, method, uri):
        '''Called by the client to encode Authentication header.'''
        if not self.username or not self.password:
            return
        o = self.options
        qop = o.get('qop')
        realm = o.get('realm')
        nonce = o['nonce']
        entdig = None
        p_parsed = urlparse(uri)
        path = p_parsed.path
        if p_parsed.query:
            path += '?' + p_parsed.query
        KD = lambda s, d: self.hex("%s:%s" % (s, d))
        ha1 = self.ha1(realm, self.password)
        ha2 = self.ha2(qop, method, path)
        if qop == 'auth':
            if nonce == self.last_nonce:
                self.nonce_count += 1
            else:
                self.nonce_count = 1
            ncvalue = '%08x' % self.nonce_count
            s = str(self.nonce_count).encode('utf-8')
            s += nonce.encode('utf-8')
            s += time.ctime().encode('utf-8')
            s += os.urandom(8)
            cnonce = sha1(s).hexdigest()[:16]
            noncebit = "%s:%s:%s:%s:%s" % (nonce, ncvalue, cnonce, qop, ha2)
            respdig = KD(ha1, noncebit)
        elif qop is None:
            respdig = KD(ha1, "%s:%s" % (nonce, ha2))
        else:
            # XXX handle auth-int.
            return
        base = 'username="%s", realm="%s", nonce="%s", uri="%s", ' \
               'response="%s"' % (self.username, realm, nonce, path, respdig)
        opaque = o.get('opaque')
        if opaque:
            base += ', opaque="%s"' % opaque
        if entdig:
            base += ', digest="%s"' % entdig
            base += ', algorithm="%s"' % self.algorithm
        if qop:
            base += ', qop=%s, nc=%s, cnonce="%s"' % (qop, ncvalue, cnonce)
        return 'Digest %s' % (base)

    def handle_401(self, response, exc=None):
        """Takes the given response and tries digest-auth, if needed."""
        if not exc and response.status_code == 401:
            request = response.request
            response._handle_401 = getattr(response, '_handle_401', 0) + 1
            s_auth = response.headers.get('www-authenticate', '')
            if 'digest' in s_auth.lower() and response._handle_401 < 2:
                self.options = parse_dict_header(s_auth.replace('Digest ', ''))
                client = response.producer
                params = request.inp_params.copy()
                headers = params.pop('headers', [])
                headers.append(('authorization', self.encode(
                    request.method, request.full_url)))
                params['headers'] = headers
                response.request_again = request_again(request.method,
                                                       request.full_url,
                                                       params)

    def hex(self, x):
        if self.algorithm == 'MD5':
            return hexmd5(x)
        elif self.algorithm == 'SHA1':
            return hexsha1(x)
        else:
            raise ValueError('Unknown algorithm %s' % self.algorithm)

    def ha1(self, realm, password):
        return self.hex('%s:%s:%s' % (self.username, realm, password))

    def ha2(self, qop, method, uri, body=None):
        if qop == "auth" or qop is None:
            return self.hex("%s:%s" % (method, uri))
        elif qop == "auth-int":
            return self.hex("%s:%s:%s" % (method, uri, self.hex(body)))
        raise ValueError

########NEW FILE########
__FILENAME__ = plugins
import sys
from functools import partial
from collections import namedtuple
from copy import copy

from pulsar import OneTime, async, Future
from pulsar.apps.ws import WebSocketProtocol, WS
from pulsar.utils.websocket import frame_parser
from pulsar.utils.internet import is_tls
from pulsar.utils.httpurl import (REDIRECT_CODES, urlparse, urljoin,
                                  requote_uri, SimpleCookie)

from pulsar import PulsarException


class request_again(namedtuple('request_again', 'method url params')):

    @property
    def status_code(self):
        return -1

    @property
    def headers(self):
        return ()


class TooManyRedirects(PulsarException):

    def __init__(self, response):
        self.response = response


class WebSocketClient(WebSocketProtocol):
    status_code = 101

    @property
    def _request(self):
        return self.handshake._request

    @property
    def headers(self):
        return self.handshake.headers

    def __getattr__(self, name):
        if not name.startswith('__'):
            return getattr(self.handshake, name)
        else:
            raise AttributeError("'%s' object has no attribute '%s'" %
                                 (self.__class__.__name__, name))


def handle_redirect(response, exc=None):
    if not exc and (response.status_code in REDIRECT_CODES and
                    'location' in response.headers and
                    response._request.allow_redirects):
        # put at the end of the pile
        response.bind_event('post_request', _do_redirect)


def _do_redirect(response, exc=None):
    request = response.request
    client = request.client
    # done with current response
    url = response.headers.get('location')
    # Handle redirection without scheme (see: RFC 1808 Section 4)
    if url.startswith('//'):
        parsed_rurl = urlparse(request.full_url)
        url = '%s:%s' % (parsed_rurl.scheme, url)
    # Facilitate non-RFC2616-compliant 'location' headers
    # (e.g. '/path/to/resource' instead of
    # 'http://domain.tld/path/to/resource')
    if not urlparse(url).netloc:
        url = urljoin(request.full_url,
                      # Compliant with RFC3986, we percent
                      # encode the url.
                      requote_uri(url))
    history = request.history
    if history and len(history) >= request.max_redirects:
        response.request_again = TooManyRedirects(response)
    else:
        params = request.inp_params.copy()
        params['history'] = copy(history) if history else []
        params['history'].append(response)
        if response.status_code == 303:
            method = 'GET'
            params.pop('data', None)
            params.pop('files', None)
        else:
            method = request.method
        response.request_again = request_again(method, url, params)


def handle_cookies(response, exc=None):
    '''Handle response cookies.
    '''
    headers = response.headers
    request = response.request
    client = request.client
    response._cookies = c = SimpleCookie()
    if 'set-cookie' in headers or 'set-cookie2' in headers:
        for cookie in (headers.get('set-cookie2'),
                       headers.get('set-cookie')):
            if cookie:
                c.load(cookie)
        if client.store_cookies:
            client.cookies.extract_cookies(response, request)


def handle_100(response, exc=None):
    '''Handle Except: 100-continue.

    This is a pre_request hook which checks if the request headers
    have the ``Expect: 100-continue`` value. If so add a ``on_headers``
    callback to handle the response from the server.
    '''
    if not exc:
        request = response.request
        if (request.headers.has('expect', '100-continue') and
                response.status_code == 100):
            response.bind_event('on_headers', _write_body)


def _write_body(response, exc=None):
    if response.status_code == 100:
        response.request.new_parser()
        if response.request.body:
            response.transport.write(response.request.body)


def handle_101(response, exc=None):
    '''Websocket upgrade as ``on_headers`` event.'''

    if not exc and response.status_code == 101:
        connection = response.connection
        request = response._request
        handler = request.websocket_handler
        parser = frame_parser(kind=1)
        if not handler:
            handler = WS()
        connection.upgrade(partial(WebSocketClient, response, handler, parser))
        response.finished()
        response.request_again = connection.current_consumer()


class Tunneling:
    '''A pre request callback for handling proxy tunneling.

    If Tunnelling is required, it writes the CONNECT headers and abort
    the writing of the actual request until headers from the proxy server
    are received.
    '''
    def __call__(self, response, exc=None):
        # the pre_request handler
        request = response._request
        if request:
            tunnel = request._tunnel
            if tunnel:
                if getattr(request, '_apply_tunnel', False):
                    # if transport is not SSL already
                    if not is_tls(response.transport.get_extra_info('socket')):
                        response._request = tunnel
                        response.bind_event('on_headers', self.on_headers)
                else:
                    # Append self again as pre_request
                    request._apply_tunnel = True
                    response.bind_event('pre_request', self)

    def on_headers(self, response, exc=None):
        '''Called back once the headers have arrived.'''
        if not exc and response.status_code == 200:
            response.bind_event('post_request', self._tunnel_consumer)
            response.finished()

    def _tunnel_consumer(self, response, exc=None):
        if not exc:
            response.transport.pause_reading()
            # Return a coroutine which wraps the socket
            # at the next iteration loop. Important!
            return self.switch_to_ssl(response)

    def switch_to_ssl(self, prev_response):
        '''Wrap the transport for SSL communication.'''
        request = prev_response._request.request
        connection = prev_response._connection
        loop = connection._loop
        sock = connection._transport._sock
        # set a new connection_made event
        connection.events['connection_made'] = OneTime()
        connection._processed -= 1
        connection.producer._requests_processed -= 1
        waiter = Future(loop=loop)
        sslt = loop._make_ssl_transport(sock, connection, request._ssl,
                                        waiter, server_side=False,
                                        server_hostname=request._netloc)
        yield waiter
        response = connection.current_consumer()
        response.start(request)
        yield response.on_finished
        if response.request_again:
            response = response.request_again
        prev_response.request_again = response

########NEW FILE########
__FILENAME__ = pulse
# -*- coding: utf-8 -
from optparse import make_option

import pulsar
from pulsar.utils.importer import module_attribute
from pulsar.apps.wsgi import (WSGIServer, LazyWsgi, WsgiHandler,
                              wait_for_body_middleware)

from django.core.management.base import BaseCommand, CommandError
from django.core.wsgi import get_wsgi_application


PULSAR_OPTIONS = pulsar.make_optparse_options(apps=['socket'],
                                              exclude=['debug'])


pulse_app_name = make_option('--pulse-app-name',
                             dest='pulse-app-name',
                             type='string',
                             default='django_pulsar')


class Wsgi(LazyWsgi):

    def setup(self, environ=None):
        from django.conf import settings
        return WsgiHandler((wait_for_body_middleware,
                            get_wsgi_application()))


class Command(BaseCommand):
    option_list = BaseCommand.option_list + (pulse_app_name,) + PULSAR_OPTIONS
    help = "Starts a fully-functional Web server using pulsar."
    args = 'pulse --help for usage'

    # Validation is called explicitly each time the server is reloaded.
    requires_model_validation = False

    def handle(self, *args, **options):
        if args:
            raise CommandError('pulse --help for usage')
        app_name = options.get('pulse-app-name')
        callable = Wsgi()
        if options.pop('dryrun', False) is True:  # used for testing
            return callable
        callable.setup()
        cfg = pulsar.Config(apps=['socket'])
        argv = []
        for name, value in options.items():
            s = cfg.settings.get(name)
            if value is not None and s and s.flags:
                argv.extend((s.flags[0], str(value)))
        WSGIServer(callable=callable, name=app_name, argv=argv).start()

########NEW FILE########
__FILENAME__ = models

########NEW FILE########
__FILENAME__ = handlers
import inspect

from pulsar import HttpException
from pulsar.utils.tools import checkarity

__all__ = ['RpcHandler', 'rpc_method', 'InvalidRequest', 'InvalidParams',
           'NoSuchFunction', 'InternalError']

_exceptions = {}


def rpc_exception(cls):
    global _exceptions
    code = cls.fault_code
    _exceptions[code] = cls
    return cls


@rpc_exception
class InvalidRequest(HttpException):
    status = 400
    fault_code = -32600
    msg = 'Invalid RPC request'


@rpc_exception
class ParseExcetion(InvalidRequest):
    fault_code = -32700
    msg = 'Parse error'


@rpc_exception
class NoSuchFunction(InvalidRequest):
    fault_code = -32601
    msg = 'The method does not exist'


@rpc_exception
class InvalidParams(InvalidRequest):
    fault_code = -32602
    msg = 'Invalid method parameters'


@rpc_exception
class InternalError(InvalidRequest):
    fault_code = -32603
    msg = 'Internal error'


def exception(code, msg):
    global _exceptions
    cls = _exceptions.get(code, Exception)
    raise cls(msg)


def rpc_method(func, doc=None, format='json', request_handler=None):
    '''A decorator which exposes a function ``func`` as an rpc function.

    :param func: The function to expose.
    :param doc: Optional doc string. If not provided the doc string of
        ``func`` will be used.
    :param format: Optional output format.
    :param request_handler: function which takes ``request``, ``format``
        and ``kwargs`` and return a new ``kwargs`` to be passed to ``func``.
        It can be used to add additional parameters based on request and
        format.
    '''
    def _(self, *args, **kwargs):
        request = args[0]
        if request_handler:
            kwargs = request_handler(request, format, kwargs)
        request.format = kwargs.pop('format', format)
        try:
            return func(*args, **kwargs)
        except TypeError:
            msg = checkarity(func, args, kwargs)
            if msg:
                raise InvalidParams('Invalid Parameters. %s' % msg)
            else:
                raise

    _.__doc__ = doc or func.__doc__
    _.__name__ = func.__name__
    _.FromApi = True
    return _


class MetaRpcHandler(type):
    '''A metaclass for rpc handlers.

    Add a limited ammount of magic to RPC handlers.
    '''
    def __new__(cls, name, bases, attrs):
        make = super(MetaRpcHandler, cls).__new__
        if attrs.pop('virtual', None):
            return make(cls, name, bases, attrs)
        funcprefix = attrs.get('serve_as')
        if not funcprefix:
            for base in bases[::-1]:
                if isinstance(base, MetaRpcHandler):
                    funcprefix = base.serve_as
                    if funcprefix:
                        break
        if funcprefix:
            rpc = set()
            fprefix = '%s_' % funcprefix
            n = len(fprefix)
            for key, method in list(attrs.items()):
                if hasattr(method, '__call__') and key.startswith(fprefix):
                    method_name = key[n:]
                    rpc.add(method_name)
            for base in bases[::-1]:
                if hasattr(base, 'rpc_methods'):
                    rpc.update(base.rpc_methods)
            attrs['rpc_methods'] = frozenset(rpc)
        return make(cls, name, bases, attrs)


class RpcHandler(MetaRpcHandler('_RpcHandler', (object,), {'virtual': True})):
    '''Base class for classes to handle remote procedure calls.
    '''
    serve_as = 'rpc'
    '''Prefix for class methods providing remote services. Default: ``rpc``.'''
    separator = '.'
    '''HTTP method allowed by this handler.'''
    virtual = True

    def __init__(self, subhandlers=None, title=None, documentation=None):
        self._parent = None
        self.subHandlers = {}
        self.title = title or self.__class__.__name__
        self.documentation = documentation or self.__doc__
        if subhandlers:
            for prefix, handler in subhandlers.items():
                if inspect.isclass(handler):
                    handler = handler()
                self.putSubHandler(prefix, handler)

    @property
    def parent(self):
        '''The parent :class:`RpcHandler` or ``None`` if this
        is the root handler.'''
        return self._parent

    @property
    def root(self):
        '''The root :class:`RpcHandler` or ``self`` if this
        is the root handler.'''
        return self._parent.root if self._parent is not None else self

    def isroot(self):
        '''``True`` if this is the root handler.'''
        return self._parent is None

    def putSubHandler(self, prefix, handler):
        '''Add a sub :class:`RpcHandler` with prefix ``prefix``.

        :keyword prefix: a string defining the prefix of the subhandler
        :keyword handler: the sub-handler.
        '''
        self.subHandlers[prefix] = handler
        handler._parent = self
        return self

    def getSubHandler(self, prefix):
        '''Get a sub :class:`RpcHandler` at ``prefix``.'''
        return self.subHandlers.get(prefix)

    def get_handler(self, method):
        if not method:
            raise NoSuchFunction('RPC method not supplied')
        bits = method.split(self.separator, 1)
        handler = self
        method_name = bits[-1]
        for bit in bits[:-1]:
            subhandler = handler.getSubHandler(bit)
            if subhandler is None:
                method_name = method
                break
            else:
                handler = subhandler
        if method_name in handler.rpc_methods:
            return getattr(handler, '%s_%s' % (self.serve_as, method_name))
        else:
            raise NoSuchFunction('RPC method "%s" not available.' % method)

    def listFunctions(self, prefix=''):
        for name in sorted(self.rpc_methods):
            method = getattr(self, '%s_%s' % (self.serve_as, name))
            docs = method.__doc__ or 'No docs'
            doc = {'doc': ' '.join(docs.split('\n')), 'section': prefix}
            yield '%s%s' % (prefix, name), doc
        for name, handler in self.subHandlers.items():
            pfx = '%s%s%s' % (prefix, name, self.separator)
            for f, doc in handler.listFunctions(pfx):
                yield f, doc

    def _docs(self):
        for name, data in self.listFunctions():
            link = '.. _functions-{0}:'.format(name)
            title = name
            under = (2+len(title))*'-'
            yield '\n'.join((link, '', title, under, '', data['doc'], '\n'))

    def docs(self):
        return '\n'.join(self._docs())

########NEW FILE########
__FILENAME__ = jsonrpc
import sys
from functools import partial
import logging

from pulsar import AsyncObject, multi_async, task, coroutine_return
from pulsar.utils.system import json
from pulsar.utils.structures import AttributeDictionary
from pulsar.utils.security import gen_unique_id
from pulsar.utils.pep import range
from pulsar.utils.tools import checkarity
from pulsar.apps.wsgi import Json
from pulsar.apps.http import HttpClient
from pulsar.utils.httpurl import JSON_CONTENT_TYPES

from .handlers import RpcHandler, InvalidRequest, exception


__all__ = ['JSONRPC', 'JsonProxy']


logger = logging.getLogger('pulsar.jsonrpc')


class JSONRPC(RpcHandler):
    '''An :class:`.RpcHandler` for JSON-RPC services.

    Design to comply with the `JSON-RPC 2.0`_ Specification.

    JSON-RPC is a lightweight remote procedure call protocol
    designed to be simple.
    A remote method is invoked by sending a request to a remote service,
    the request is a single object serialised using JSON.

    .. _`JSON-RPC 2.0`: http://www.jsonrpc.org/specification
    '''
    version = '2.0'

    def __call__(self, request):
        return Json(self._call(request)).http_response(request)

    def _call(self, request):
        response = request.response
        data = {}
        exc_info = None
        callable = None
        try:
            try:
                data = yield request.body_data()
            except ValueError:
                raise InvalidRequest(
                    status=415, msg='Content-Type must be application/json')
            if data.get('jsonrpc') != self.version:
                raise InvalidRequest(
                    'jsonrpc must be supplied and equal to "%s"' %
                    self.version)
            params = data.get('params')
            if isinstance(params, dict):
                args, kwargs = (), params
            else:
                args, kwargs = tuple(params or ()), {}
            #
            callable = self.get_handler(data.get('method'))
            result = yield callable(request, *args, **kwargs)
        except Exception as exc:
            result = exc
            exc_info = sys.exc_info()
        #
        res = {'id': data.get('id'), "jsonrpc": self.version}
        if exc_info:
            code = getattr(result, 'fault_code', -32603)
            msg = None
            if isinstance(result, TypeError) and callable:
                msg = checkarity(callable, args, kwargs, discount=1)
            msg = msg or str(result) or 'JSON RPC exception'
            if code == -32603:
                logger.error(msg, exc_info=exc_info)
            else:
                logger.warning(msg)
            error = {'code': code,
                     'message': msg,
                     'data': getattr(result, 'data', '')}
            response.status_code = getattr(result, 'status', 500)
            res['error'] = error
        else:
            res['result'] = result
        coroutine_return(res)


class JsonCall:
    slots = ('_client', '_name')

    def __init__(self, client, name):
        self._client = client
        self._name = name

    def __repr__(self):
        return self._name
    __str__ = __repr__

    @property
    def url(self):
        return self._client.url

    @property
    def name(self):
        return self._name

    def __getattr__(self, name):
        name = "%s%s%s" % (self._name, self._client.separator, name)
        return self.__class__(self._client, name)

    def __call__(self, *args, **kwargs):
        return self._client._call(self._name, *args, **kwargs)


class JsonProxy(AsyncObject):
    '''A python Proxy class for :class:`.JSONRPC` Servers.

    :param url: server location
    :param version: JSON-RPC server version. Default ``2.0``
    :param id: optional request id, generated if not provided.
        Default ``None``.
    :param data: Extra data to include in all requests. Default ``None``.
    :param full_response: return the full Http response rather than
        just the content.
    :param http: optional http client. If provided it must have the ``request``
        method available which must be of the form::

            http.request(url, body=..., method=...)

        Default ``None``.

    Lets say your RPC server is running at ``http://domain.name.com/``::

        >>> a = JsonProxy('http://domain.name.com/')
        >>> a.add(3,4)
        7
        >>> a.ping()
        'pong'

    '''
    separator = '.'
    default_version = '2.0'
    default_timeout = 30

    def __init__(self, url, version=None, data=None,
                 full_response=False, http=None, timeout=None, **kw):
        self._url = url
        self._version = version or self.__class__.default_version
        self._full_response = full_response
        self._data = data if data is not None else {}
        if not http:
            timeout = timeout if timeout is not None else self.default_timeout
            http = HttpClient(timeout=timeout, **kw)
        http.headers['accept'] = 'application/json, text/*; q=0.5'
        http.headers['content-type'] = 'application/json'
        self._http = http

    @property
    def url(self):
        return self._url

    @property
    def version(self):
        return self._version

    @property
    def _loop(self):
        return self._http._loop

    def makeid(self):
        '''Can be re-implemented by your own Proxy'''
        return gen_unique_id()

    def __repr__(self):
        return '%s(%s)' % (self.__class__.__name__, self.__url)

    def __str__(self):
        return self.__repr__()

    def __getattr__(self, name):
        return JsonCall(self, name)

    @task
    def _call(self, name, *args, **kwargs):
        data = self._get_data(name, *args, **kwargs)
        body = json.dumps(data).encode('utf-8')
        resp = yield self._http.post(self._url, data=body)
        if self._full_response:
            coroutine_return(resp)
        else:
            content = resp.decode_content()
            if resp.is_error:
                if 'error' not in content:
                    resp.raise_for_status()
            coroutine_return(self.loads(content))

    def _get_data(self, func_name, *args, **kwargs):
        id = self.makeid()
        params = self.get_params(*args, **kwargs)
        data = {'method': func_name, 'params': params, 'id': id,
                'jsonrpc': self._version}
        return data

    def get_params(self, *args, **kwargs):
        '''
        Create an array or positional or named parameters
        Mixing positional and named parameters in one
        call is not possible.
        '''
        kwargs.update(self._data)
        if args and kwargs:
            raise ValueError('Cannot mix positional and named parameters')
        if args:
            return list(args)
        else:
            return kwargs

    def loads(self, obj):
        if isinstance(obj, dict):
            if 'error' in obj:
                error = obj['error']
                raise exception(error.get('code'), error.get('message'))
            else:
                return obj.get('result')
        return obj

########NEW FILE########
__FILENAME__ = mixins
from pulsar import send, coroutine_return

from .jsonrpc import JSONRPC


__all__ = ['PulsarServerCommands']


class PulsarServerCommands(JSONRPC):
    '''Useful commands to add to your :class:`.JSONRPC` handler.

    It exposes the following functions:'''
    def rpc_ping(self, request):
        '''Ping the server.'''
        return 'pong'

    def rpc_echo(self, request, message=''):
        '''Echo the server.'''
        return message

    def rpc_server_info(self, request):
        '''Return a dictionary of information regarding the server and workers.

        It invokes the :meth:`extra_server_info` for adding custom
        information.
        '''
        info = yield send('arbiter', 'info')
        info = yield self.extra_server_info(request, info)
        coroutine_return(info)

    def rpc_functions_list(self, request):
        '''List of (method name, method document) pair of all method exposed
        by this :class:`.JSONRPC` handler.'''
        return list(self.listFunctions())

    def rpc_documentation(self, request):
        '''Documentation in restructured text.'''
        return self.docs()

    def rpc_kill_actor(self, request, aid):
        '''Kill the actor with id equal to *aid*.'''
        return send('arbiter', 'kill_actor', aid)

    def extra_server_info(self, request, info):
        '''An internal method.

        Used by the :meth:`rpc_server_info` method to add additional
        information to the info dictionary.
        '''
        return info

########NEW FILE########
__FILENAME__ = backend
'''
The :class:`TaskBackend` is at the heart of the
:ref:`task queue application <apps-taskqueue>`. It exposes
all the functionalities for running new tasks, scheduling periodic tasks
and retrieving task information. Pulsar ships with two backends, one which uses
pulsar internals and store tasks in the arbiter domain and another which stores
tasks in redis_.

The backend is created by the :class:`.TaskQueue`
as soon as it starts. It is then passed to all task queue workers
which, in turns, invoke the :class:`TaskBackend.start` method
to start pulling tasks form the distributed task queue.

.. _task-state:

Task states
~~~~~~~~~~~~~

A :class:`Task` can have one of the following :attr:`~.Task.status` string:

* ``QUEUED = 6`` A task queued but not yet executed.
* ``STARTED = 5`` task where execution has started.
* ``RETRY = 4`` A task is retrying calculation.
* ``REVOKED = 3`` the task execution has been revoked (or timed-out).
* ``FAILURE = 2`` task execution has finished with failure.
* ``SUCCESS = 1`` task execution has finished with success.

.. _task-run-state:

**FULL_RUN_STATES**

The set of states for which a :class:`Task` has run:
``FAILURE`` and ``SUCCESS``

.. _task-ready-state:

**READY_STATES**

The set of states for which a :class:`Task` has finished:
``REVOKED``, ``FAILURE`` and ``SUCCESS``

.. _tasks-pubsub:

Task status broadcasting
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A :class:`TaskBackend` broadcast :class:`Task` state into three different
channels via the a :meth:`~.Store.pubsub` handler.


Implementation
~~~~~~~~~~~~~~~~~~~
When creating a new :class:`TaskBackend` there are three methods which must
be implemented:

* The :meth:`~TaskBackend.get_task` method, invoked when retrieving
  a :class:`Task` from the backend server.
* The :meth:`~TaskBackend.maybe_queue_task` method, invoked when a new
  class:`.Task` is created and ready to be queued.
* The :meth:`~TaskBackend.finish_task` method, invoked when a
  :class:`.Task` reaches a :ref:`ready state <task-ready-state>`.

For example::

    from pulsar.apps import tasks

    class TaskBackend(tasks.TaskBackend):
        ...

Once the custom task backend is implemented it must be registered::

    tasks.task_backends['mybackend'] = TaskBackend

And the backend will be selected via::

    --task-backend mybackend://host:port

.. _redis: http://redis.io/
'''
import sys
import time
from functools import partial
from datetime import datetime, timedelta
from hashlib import sha1

from pulsar import (task, async, EventHandler, PulsarException, get_logger,
                    Future, coroutine_return, get_request_loop)
from pulsar.utils.pep import itervalues, to_string
from pulsar.utils.security import gen_unique_id
from pulsar.apps.data import create_store, PubSubClient, odm
from pulsar.utils.log import (LocalMixin, lazyproperty, lazymethod,
                              LazyString)

from .models import JobRegistry
from . import states


__all__ = ['task_backends', 'Task', 'TaskBackend', 'TaskNotAvailable',
           'nice_task_message']

task_backends = {}


if hasattr(timedelta, "total_seconds"):
    timedelta_seconds = lambda delta: max(delta.total_seconds(), 0)

else:   # pragma    nocover
    def timedelta_seconds(delta):
        if delta.days < 0:
            return 0
        return delta.days * 86400 + delta.seconds + (delta.microseconds / 10e5)


def get_time(expiry, start):
    if isinstance(expiry, timedelta):
        return (start + 86400*expiry.days + expiry.seconds +
                0.000001*expiry.microseconds)
    else:
        return start + expiry


def format_time(dt):
    if isinstance(dt, (float, int)):
        dt = datetime.fromtimestamp(dt)
    return dt.isoformat() if dt else '?'


def nice_task_message(req, smart_time=None):
    smart_time = smart_time or format_time
    status = states.status_string(req.get('status'))
    user = req.get('user')
    ti = req.get('time_start', req.get('time_executed'))
    name = '%s (%s) ' % (req['name'], req['id'][:8])
    msg = '%s %s at %s' % (name, status, smart_time(ti))
    return '%s by %s' % (msg, user) if user else msg


class TaskNotAvailable(PulsarException):
    MESSAGE = 'Task {0} is not registered'

    def __init__(self, task_name):
        self.task_name = task_name
        super(TaskNotAvailable, self).__init__(self.MESSAGE.format(task_name))


class TaskTimeout(PulsarException):
    pass


class TaskConsumer(object):
    '''A context manager for consuming tasks.

    Instances of this consumer are created by the :class:`TaskBackend` when
    a task is executed.

    .. attribute:: _loop

        the :ref:`queue-based loop <queue-based-loop>` of the thread
        executing the task.

    .. attribute:: task_id

        the :attr:`Task.id` being consumed.

    .. attribute:: job

        the :class:`.Job` which generated the task.

    .. attribute:: worker

        the :class:`.Actor` executing the task.

    .. attribute:: backend

        The :class:`.TaskBackend`. This is useful when creating
        tasks from within a :ref:`job callable <job-callable>`.
    '''
    def __init__(self, backend, worker, task_id, job):
        self._loop = get_request_loop()
        self.logger = self._loop.logger
        self.backend = backend
        self.worker = worker
        self.job = job
        self.task_id = task_id


class Task(odm.Model):
    '''A data :class:`.Model` containing task execution data.
    '''
    id = odm.CharField(primary_key=True)
    '''Task unique identifier.
    '''
    lock_id = odm.CharField(required=False)
    name = odm.CharField(index=True)
    time_queued = odm.FloatField(default=time.time)
    time_started = odm.FloatField(required=False)
    time_ended = odm.FloatField(required=False)
    '''The timestamp indicating when this has finished.
    '''
    expiry = odm.FloatField(required=False)
    '''The timestamp indicating when this task expires.

    If the task is not started before this value it is ``REVOKED``.
    '''
    status = odm.IntegerField(index=True, default=states.QUEUED)
    '''flag indicating the :ref:`task status <task-state>`
    '''
    kwargs = odm.PickleField()
    result = odm.PickleField()

    def done(self):
        '''Return ``True`` if the :class:`Task` has finshed.

        Its status is one of :ref:`READY_STATES <task-ready-state>`.
        '''
        return self.get('status') in states.READY_STATES

    def status_string(self):
        '''A string representation of :attr:`status` code
        '''
        return states.status_string(self.get('status'))

    def info(self):
        return 'task.%s(%s)' % (self.get('name'), self.get('id'))

    def lazy_info(self):
        return LazyString(self.info)


class TaskBackend(EventHandler):
    '''A backend class for running :class:`.Task`.
    A :class:`TaskBackend` is responsible for creating tasks and put them
    into the distributed queue.
    It also schedules the run of periodic tasks if enabled to do so.

    .. attribute:: task_paths

        List of paths where to upload :ref:`jobs <app-taskqueue-job>` which
        are factory of tasks. Passed by the task-queue application
        :ref:`task paths setting <setting-task_paths>`.

    .. attribute:: schedule_periodic

        ``True`` if this :class:`TaskBackend` can schedule periodic tasks.

        Passed by the task-queue application
        :ref:`schedule-periodic setting <setting-schedule_periodic>`.

    .. attribute:: backlog

        The maximum number of concurrent tasks running on a task-queue
        for an :class:`.Actor`. A number in the order of 5 to 10 is normally
        used. Passed by the task-queue application
        :ref:`concurrent tasks setting <setting-concurrent_tasks>`.

    .. attribute:: max_tasks

        The maximum number of tasks a worker will process before restarting.
        Passed by the task-queue application
        :ref:`max requests setting <setting-max_requests>`.

    .. attribute:: poll_timeout

        The (asynchronous) timeout for polling tasks from the task queue.

        It is always a positive number and it can be specified via the
        backend connection string::

            local://?poll_timeout=3

        There shouldn't be any reason to modify the default value.

        Default: ``2``.

    .. attribute:: processed

        The number of tasks processed (so far) by the worker running this
        backend.
        This value is important in connection with the :attr:`max_tasks`
        attribute.

    '''
    task_poller = None

    def __init__(self, store, logger=None, task_paths=None,
                 schedule_periodic=False, backlog=1, max_tasks=0, name=None,
                 poll_timeout=None):
        self.store = store
        self._logger = logger
        super(TaskBackend, self).__init__(self._loop,
                                          many_times_events=('task_queued',
                                                             'task_started',
                                                             'task_done'))
        self.name = name
        self.task_paths = task_paths
        self.backlog = backlog
        self.max_tasks = max_tasks
        self.poll_timeout = max(poll_timeout or 0, 2)
        self.concurrent_tasks = set()
        self.processed = 0
        self.schedule_periodic = schedule_periodic
        self.next_run = time.time()
        self.callbacks = {}
        self.models = odm.Mapper(self.store)
        self.models.register(Task)
        self._pubsub = self.get_pubsub()

    def __repr__(self):
        if self.schedule_periodic:
            return 'task scheduler %s' % self.store.dns
        else:
            return 'task consumer %s' % self.store.dns
    __str__ = __repr__

    @property
    def _loop(self):
        '''Eventloop running this task backend'''
        return self.store._loop

    @property
    def num_concurrent_tasks(self):
        '''The number of :attr:`concurrent_tasks`.

        This number is never greater than the :attr:`backlog` attribute.
        '''
        return len(self.concurrent_tasks)

    @lazyproperty
    def entries(self):
        return self._setup_schedule()

    @lazyproperty
    def registry(self):
        '''The :class:`.JobRegistry` for this backend.
        '''
        return JobRegistry.load(self.task_paths)

    def channel(self, name):
        '''Given an event ``name`` returns the corresponding channel name.

        The event ``name`` is one of ``task_queued``, ``task_started``
        or ``task_done``
        '''
        return '%s_%s' % (self.name, name)

    def event_name(self, channel):
        return channel[len(self.name)+1:]

    @task
    def queue_task(self, jobname, meta_params=None, expiry=None, **kwargs):
        '''Try to queue a new :ref:`Task`.

        This method returns a :class:`.Future` which results in the
        task ``id`` created. If ``jobname`` is not a valid
        :attr:`.Job.name`, a ``TaskNotAvailable`` exception occurs.

        :param jobname: the name of a :class:`.Job`
            registered with the :class:`.TaskQueue` application.
        :param meta_params: Additional parameters to be passed to the
            :class:`Task` constructor (not its callable function).
        :param expiry: optional expiry timestamp to override the default
            expiry of a task.
        :param kwargs: optional dictionary used for the key-valued arguments
            in the task callable.
        :return: a :class:`.Future` resulting in a task id on success.
        '''
        pubsub = self._pubsub
        if jobname in self.registry:
            job = self.registry[jobname]
            task_id, lock_id = self.generate_task_ids(job, kwargs)
            queued = time.time()
            if expiry is not None:
                expiry = get_time(expiry, queued)
            elif job.timeout:
                expiry = get_time(job.timeout, queued)
            meta_params = meta_params or {}
            task = self.models.task(id=task_id, lock_id=lock_id, name=job.name,
                                    time_queued=queued, expiry=expiry,
                                    kwargs=kwargs, status=states.QUEUED)
            if meta_params:
                task.update(meta_params)
            task = yield self.maybe_queue_task(task)
            if task:
                pubsub.publish(self.channel('task_queued'), task['id'])
                scheduled = self.entries.get(job.name)
                if scheduled:
                    scheduled.next()
                self.logger.debug('queued %s', task.lazy_info())
                coroutine_return(task['id'])
            else:
                self.logger.debug('%s cannot queue new task. Locked', jobname)
                coroutine_return()
        else:
            raise TaskNotAvailable(jobname)

    def wait_for_task(self, task_id, timeout=None):
        '''Asynchronously wait for a task with ``task_id`` to have finished
        its execution.
        '''
        # This coroutine is run on the worker event loop
        def _(task_id):
            task = yield self.get_task(task_id)
            if task:
                task_id = task['id']
                callbacks = self.callbacks
                if task.done():  # task done, simply return it
                    done = callbacks.pop(task_id, None)
                    if done:
                        done.set_result(task)
                else:
                    done = callbacks.get(task_id)
                    if not done:
                        # No future, create one
                        callbacks[task_id] = done = Future(loop=self._loop)
                    task = yield done
                coroutine_return(task)

        fut = async(_(task_id), self._loop)
        return future_timeout(fut, timeout) if timeout else fut

    def get_tasks(self, ids):
        return self.models.task.filter(id=ids).all()

    def get_pubsub(self):
        '''Create a publish/subscribe handler from the backend :attr:`store`.
        '''
        pubsub = self.store.pubsub()
        pubsub.add_client(self)
        # pubsub channels names from event names
        channels = tuple((self.channel(name) for name in self.events))
        pubsub.subscribe(*channels)
        self.bind_event('task_done', self.task_done_callback)
        return pubsub

    # #######################################################################
    # #    ABSTRACT METHODS
    # #######################################################################
    def maybe_queue_task(self, task):
        '''Actually queue a :class:`.Task` if possible.
        '''
        raise NotImplementedError

    def get_task(self, task_id=None):
        '''Asynchronously retrieve a :class:`Task` from a ``task_id``.

        :param task_id: the ``id`` of the task to retrieve.
        :return: a :class:`Task` or ``None``.
        '''
        raise NotImplementedError

    def finish_task(self, task_id, lock_id):
        '''Invoked at the end of task execution.

        The :class:`.Task` with ``task_id`` has been executed (either
        successfully or not) or has been revoked. This method perform
        backend specific operations.

        Must be implemented by subclasses.
        '''
        raise NotImplementedError

    def flush(self):
        '''Remove all queued :class:`.Task`
        '''
        raise NotImplementedError()

    # #######################################################################
    # #    START/CLOSE METHODS FOR TASK WORKERS
    # #######################################################################
    def start(self, worker):
        '''Invoked by the task queue ``worker`` when it starts.
        '''
        assert self.task_poller is None
        self.task_poller = worker._loop.call_soon(self.may_pool_task, worker)
        self.logger.debug('started polling tasks')
        store = self.store

    def close(self):
        '''Close this :class:`TaskBackend`.

        Invoked by the :class:`.Actor` when stopping.
        '''
        if self.task_poller:
            self.task_poller.cancel()
            self.task_poller = None
            self.logger.debug('stopped polling tasks')
        self._pubsub.close()

    def generate_task_ids(self, job, kwargs):
        '''An internal method to generate task unique identifiers.

        :parameter job: The :class:`.Job` creating the task.
        :parameter kwargs: dictionary of key-valued parameters passed to the
            :ref:`job callable <job-callable>` method.
        :return: a two-elements tuple containing the unique id and an
            identifier for overlapping tasks if the :attr:`.Job.can_overlap`
            results in ``False``.

        Called by the :ref:`TaskBackend <apps-taskqueue-backend>` when
        creating a new task.
        '''
        can_overlap = job.can_overlap
        if hasattr(can_overlap, '__call__'):
            can_overlap = can_overlap(**kwargs)
        tid = gen_unique_id()
        if can_overlap:
            return tid, None
        else:
            if kwargs:
                kw = ('%s=%s' % (k, kwargs[k]) for k in sorted(kwargs))
                name = '%s %s' % (self.name, ', '.join(kw))
            else:
                name = self.name
            return tid, sha1(name.encode('utf-8')).hexdigest()

    # #######################################################################
    # #    PRIVATE METHODS
    # #######################################################################
    def tick(self, now=None):
        # Run a tick, that is one iteration of the scheduler.
        if not self.schedule_periodic:
            return
        remaining_times = []
        for entry in itervalues(self.entries):
            is_due, next_time_to_run = entry.is_due(now=now)
            if is_due:
                self.queue_task(entry.name)
            if next_time_to_run:
                remaining_times.append(next_time_to_run)
        self.next_run = now or time.time()
        if remaining_times:
            self.next_run += min(remaining_times)

    def job_list(self, jobnames=None):
        registry = self.registry
        jobnames = jobnames or registry
        all = []
        for name in jobnames:
            if name not in registry:
                continue
            job = registry[name]
            can_overlap = job.can_overlap
            if hasattr(can_overlap, '__call__'):
                can_overlap = 'maybe'
            d = {'doc': job.__doc__,
                 'doc_syntax': job.doc_syntax,
                 'type': job.type,
                 'can_overlap': can_overlap}
            if self.entries and name in self.entries:
                entry = self.entries[name]
                _, next_time_to_run = self.next_scheduled((name,))
                run_every = 86400*job.run_every.days + job.run_every.seconds
                d.update({'next_run': next_time_to_run,
                          'run_every': run_every,
                          'runs_count': entry.total_run_count})
            all.append((name, d))
        return all

    def next_scheduled(self, jobnames=None):
        if not self.schedule_periodic:
            return
        if jobnames:
            entries = (self.entries.get(name, None) for name in jobnames)
        else:
            entries = itervalues(self.entries)
        next_entry = None
        next_time = None
        for entry in entries:
            if entry is None:
                continue
            is_due, next_time_to_run = entry.is_due()
            if is_due:
                next_time = 0
                next_entry = entry
                break
            elif next_time_to_run is not None:
                if next_time is None or next_time_to_run < next_time:
                    next_time = next_time_to_run
                    next_entry = entry
        if next_entry:
            return (next_entry.name, max(next_time, 0))
        else:
            return (jobnames, None)

    @task
    def may_pool_task(self, worker):
        # Called in the ``worker`` event loop.
        #
        # It pools a new task if possible, and add it to the queue of
        # tasks consumed by the ``worker`` CPU-bound thread.'''
        next_time = 0
        if worker.is_running():
            executor = worker.executor()
            if self.num_concurrent_tasks < self.backlog:
                if self.max_tasks and self.processed >= self.max_tasks:
                    if not self.num_concurrent_tasks:
                        self.logger.warning('Processed %s tasks. Restarting.',
                                            self.processed)
                        worker._loop.stop()
                        coroutine_return()
                else:
                    task = yield self.get_task()
                    if task:    # Got a new task
                        self.processed += 1
                        self.concurrent_tasks.add(task['id'])
                        executor.submit(self._execute_task, worker, task)
            else:
                self.logger.debug('%s concurrent requests. Cannot poll.',
                                  self.num_concurrent_tasks)
                next_time = 1
        worker._loop.call_later(next_time, self.may_pool_task, worker)

    def _execute_task(self, worker, task):
        # Asynchronous execution of a Task. This method is called
        # on a separate thread of execution from the worker event loop thread.
        logger = get_logger(worker.logger)
        pubsub = self._pubsub
        task_id = task['id']
        lock_id = task.get('lock_id')
        time_ended = time.time()
        job = self.registry.get(task.get('name'))
        consumer = TaskConsumer(self, worker, task_id, job)
        task_info = task.lazy_info()
        try:
            if not consumer.job:
                raise RuntimeError('%s not in registry' % task_info)
            if task['status'] > states.STARTED:
                expiry = task.get('expiry')
                if expiry and time_ended > expiry:
                    raise TaskTimeout
                else:
                    logger.info('starting %s', task_info)
                    kwargs = task.get('kwargs') or {}
                    self.models.task.update(id=task_id, status=states.STARTED,
                                            time_started=time_ended,
                                            worker=worker.aid)
                    pubsub.publish(self.channel('task_started'), task_id)
                    # This may block for a while
                    result = yield job(consumer, **kwargs)
                    status = states.SUCCESS
            else:
                logger.error('invalid status for %s', task_info)
                self.concurrent_tasks.discard(task_id)
                coroutine_return(task_id)
        except TaskTimeout:
            logger.info('%s timed-out', task_info)
            result = None
            status = states.REVOKED
        except Exception as exc:
            logger.exception('failure in %s', task_info)
            result = str(exc)
            status = states.FAILURE
        #
        try:
            yield self.models.task.update(id=task_id, time_ended=time.time(),
                                          status=status, result=result)
        finally:
            self.concurrent_tasks.discard(task_id)
            self.finish_task(task_id, lock_id)
        #
        logger.info('finished %s', task_info)
        # publish into the task_done channel
        pubsub.publish(self.channel('task_done'), task_id)
        coroutine_return(task_id)

    def _setup_schedule(self):
        entries = {}
        if not self.schedule_periodic:
            return entries
        for name, task in self.registry.filter_types('periodic'):
            every = task.run_every
            if isinstance(every, int):
                every = timedelta(seconds=every)
            if not isinstance(every, timedelta):
                raise ValueError('Schedule %s is not a timedelta' % every)
            entries[name] = SchedulerEntry(name, every, task.anchor)
        return entries

    def task_done_callback(self, task_id, exc=None):
        # Got a task_id from the ``<name>_task_done`` channel.
        # Check if a ``callback`` is available in the :attr:`callbacks`
        # dictionary. If so fire the callback with the ``task`` instance
        # corresponsding to the input ``task_id``.
        # If a callback is not available, it must have been fired already
        self.wait_for_task(task_id)

    def __call__(self, channel, message):
        # PubSub callback
        name = self.event_name(channel)
        self.fire_event(name, message)


class SchedulerEntry(object):
    '''A class used as a schedule entry by the :class:`.TaskBackend`.

    .. attribute:: name

        Task name

    .. attribute:: run_every

        Interval in seconds

    .. attribute:: anchor

        Datetime anchor

    .. attribute:: last_run_at

        last run datetime

    .. attribute:: total_run_count

        Total number of times this periodic task has been executed by the
        :class:`.TaskBackend`.
    '''
    def __init__(self, name, run_every, anchor=None):
        self.name = name
        self.run_every = run_every
        self.anchor = anchor
        self.last_run_at = datetime.now()
        self.total_run_count = 0

    def __repr__(self):
        return self.name
    __str__ = __repr__

    @property
    def scheduled_last_run_at(self):
        '''The scheduled last run datetime.

        This is different from :attr:`last_run_at` only when
        :attr:`anchor` is set.
        '''
        last_run_at = self.last_run_at
        anchor = self.anchor
        if last_run_at and anchor:
            run_every = self.run_every
            times = int(timedelta_seconds(last_run_at - anchor)
                        / timedelta_seconds(run_every))
            if times:
                anchor += times*run_every
                while anchor <= last_run_at:
                    anchor += run_every
                while anchor > last_run_at:
                    anchor -= run_every
                self.anchor = anchor
            return anchor
        else:
            return last_run_at

    def next(self, now=None):
        '''Increase the :attr:`total_run_count` attribute by one and set the
        value of :attr:`last_run_at` to ``now``.
        '''
        self.last_run_at = now or datetime.now()
        self.total_run_count += 1

    def is_due(self, now=None):
        '''Returns tuple of two items ``(is_due, next_time_to_run)``,
        where next time to run is in seconds.

        See :meth:`unuk.contrib.tasks.models.PeriodicTask.is_due`
        for more information.
        '''
        last_run_at = self.scheduled_last_run_at
        now = now or datetime.now()
        rem_delta = last_run_at + self.run_every - now
        rem = timedelta_seconds(rem_delta)
        if rem == 0:
            return True, timedelta_seconds(self.run_every)
        return False, rem


class PulsarTaskBackend(TaskBackend):

    @lazyproperty
    def store_client(self):
        return self.store.client()

    def maybe_queue_task(self, task):
        free = True
        store = self.store
        c = self.channel
        if task['lock_id']:
            free = yield store.execute('hsetnx', c('locks'),
                                       task['lock_id'], task['id'])
        if free:
            with self.models.begin() as t:
                t.add(task)
                t.execute('lpush', c('inqueue'), task['id'])
            yield t.wait()
            coroutine_return(task)
        else:
            coroutine_return()

    def get_task(self, task_id=None):
        store = self.store
        if not task_id:
            inq = self.channel('inqueue')
            ouq = self.channel('outqueue')
            task_id = yield store.execute('brpoplpush', inq, ouq,
                                          self.poll_timeout)
            if not task_id:
                coroutine_return()
        task = yield self.models.task.get(task_id)
        coroutine_return(task or None)

    def finish_task(self, task_id, lock_id):
        store = self.store
        pipe = store.pipeline()
        if lock_id:
            pipe.hdel(self.channel('locks'), lock_id)
        # Remove the task_id from the inqueue list
        pipe.lrem(self.channel('inqueue'), 0, task_id)
        return pipe.commit()

    def get_tasks(self, ids):
        base = self.models.task._meta.table_name
        store = self.models.task._read_store
        pipeline = store.pipeline()
        for pk in ids:
            pipeline.hgetall('%s:%s' % (base, pk),
                             factory=partial(store.build_model, Task))
        return pipeline.commit()

    def flush(self):
        return self.store.flush()


task_backends['pulsar'] = PulsarTaskBackend
task_backends['redis'] = PulsarTaskBackend

########NEW FILE########
__FILENAME__ = models
'''
A :ref:`task queue <apps-taskqueue>` application implements several
:class:`Job` classes which specify the way a :class:`.Task` is run.
Each :class:`Job` class is a :class:`.Task` factory, therefore,
a :class:`.Task` is always associated
with one :class:`Job`, which can be of two types:

* standard (:class:`.Job`)
* periodic (:class:`.PeriodicJob`), a generator of scheduled tasks.

.. _job-callable:

Job callable method
~~~~~~~~~~~~~~~~~~~~~~~~~~

To define a job is simple, subclass from :class:`.Job` and implement the
**job callable method**::

    from pulsar.apps import tasks

    class Addition(tasks.Job):

        def __call__(self, consumer, a=0, b=0):
            "Add two numbers"
            return a+b

The ``consumer``, instance of :class:`.TaskConsumer`,
is passed by the :ref:`Task backend <apps-taskqueue-backend>` and should
always be the first positional parameter in the callable method.
The remaining (optional key-valued only!) parameters are needed by
your job implementation.

A :ref:`job callable <job-callable>` can also return a
:ref:`coroutine <coroutine>` if it needs to perform asynchronous IO during its
execution::

    class Crawler(tasks.Job):

        def __call__(self, consumer, sample=100, size=10):
            response = yield http.request(...)
            content = response.content
            ...

This allows for cooperative task execution.

.. _job-non-overlap:

Non overlapping Jobs
~~~~~~~~~~~~~~~~~~~~~~~~~~

The :attr:`~.Job.can_overlap` attribute controls the way tasks are generated
by a specific :class:`.Job`. By default, a :class:`.Job` creates a new task
every time the :class:`.TaskBackend` requests it.

However, when setting the :attr:`~.Job.can_overlap` attribute to ``False``,
a new task cannot be started unless a previous task of the same job
is done.

'''
from datetime import datetime, date
import logging

from pulsar.utils.pep import iteritems
from pulsar.utils.importer import import_modules


__all__ = ['JobMetaClass', 'Job', 'PeriodicJob',
           'anchorDate', 'JobRegistry']


class JobRegistry(dict):
    """Site registry for tasks."""

    def regular(self):
        """A generator of all regular jobs."""
        return self.filter_types("regular")

    def periodic(self):
        """A generator of all periodic jobs."""
        return self.filter_types("periodic")

    def register(self, job):
        """Register a job in the job registry.

        The task will be automatically instantiated if not already an
        instance.

        """
        if isinstance(job, JobMetaClass) and job.can_register:
            name = job.name
            self[name] = job()

    def filter_types(self, type):
        """Return a generator of all tasks of a specific type."""
        return ((job_name, job) for job_name, job in iteritems(self)
                if job.type == type)

    @classmethod
    def load(cls, paths):
        self = cls()
        for mod in import_modules(paths):
            for name in dir(mod):
                self.register(getattr(mod, name))
        return self


class JobMetaClass(type):

    def __new__(cls, name, bases, attrs):
        attrs['can_register'] = not attrs.pop('abstract', False)
        job_name = attrs.get("name", name).lower()
        log_prefix = attrs.get("log_prefix") or "pulsar"
        attrs["name"] = job_name
        logname = '%s.job.%s' % (log_prefix, name)
        attrs['logger'] = logging.getLogger(logname)
        return super(JobMetaClass, cls).__new__(cls, name, bases, attrs)


class Job(JobMetaClass('JobBase', (object,), {'abstract': True})):
    '''The Job class which is used in a distributed task queue.

.. attribute:: name

    The unique name which defines the Job and which can be used to retrieve
    it from the job registry. This attribute is set to the Job class name
    in lower case by default, unless a ``name`` class attribute is defined.

.. attribute:: abstract

    If set to ``True`` (default is ``False``), the :class:`.Job` won't be
    registered with the :class:`.JobRegistry`. Useful when creating a new
    base class for several other jobs.

.. attribute:: type

    Type of Job, one of ``regular`` and ``periodic``.

.. attribute:: timeout

    An instance of a datetime.timedelta or ``None``. If set, it represents the
    time lag after which a task which did not start expires.

    Default: ``None``.

.. attribute:: can_overlap

    Boolean indicating if this job can generate overlapping tasks. It can
    also be a callable which accept the same input parameters as the job
    callable function.

    Default: ``True``.

.. attribute:: doc_syntax

    The doc string syntax.

    Default: ``markdown``

.. attribute:: logger

    an instance of a logger. Created at runtime.
'''
    abstract = True
    timeout = None
    expires = None
    doc_syntax = 'markdown'
    can_overlap = True

    def __call__(self, consumer, *args, **kwargs):
        raise NotImplementedError("Jobs must implement the __call__ method.")

    @property
    def type(self):
        '''Type of Job, one of ``regular`` and ``periodic``.'''
        return 'regular'

    def queue_task(self, consumer, jobname, meta_params=None, **kwargs):
        '''Queue a new task in the task queue.

        This utility method can be used from within the
        :ref:`job callable <job-callable>` method and it allows tasks to act
        as tasks factories.

        :parameter consumer: the :class:`.TaskConsumer`
            handling the :class:`.Task`.
            Must be the same instance as the one passed to the
            :ref:`job callable <job-callable>` method.
        :parameter jobname: The name of the :class:`.Job` to run.
        :parameter kwargs: key-valued parameters for the
            :ref:`job callable <job-callable>`.
        :return: a :class:`~asyncio.Future` called back with the task id.

        This method invokes the :meth:`.TaskBackend.queue_task`
        method with the additional ``from_task`` argument equal to the
        id of the task invoking the method.
        '''
        if meta_params is None:
            meta_params = {}
        meta_params['from_task'] = consumer.task_id
        return consumer.backend.queue_task(jobname, meta_params, **kwargs)


class PeriodicJob(Job):
    '''A periodic :class:`.Job` implementation.'''
    abstract = True
    anchor = None
    '''If specified it must be a :class:`~datetime.datetime` instance.
    It controls when the periodic Job is run.
    '''
    run_every = None
    '''Periodicity as a :class:`~datetime.timedelta` instance.'''

    def __init__(self, run_every=None):
        self.run_every = run_every or self.run_every
        if self.run_every is None:
            raise NotImplementedError('Periodic Jobs must have a run_every '
                                      'attribute set, "{0}" does not have one'
                                      .format(self.name))

    @property
    def type(self):
        return 'periodic'

    def is_due(self, last_run_at):
        """Returns tuple of two items ``(is_due, next_time_to_run)``,
        where next time to run is in seconds. For example:

        * ``(True, 20)``, means the job should be run now, and the next
          time to run is in 20 seconds.

        * ``(False, 12)``, means the job should be run in 12 seconds.

        You can override this to decide the interval at runtime.
        """
        return self.run_every.is_due(last_run_at)


def anchorDate(hour=0, minute=0, second=0):
    '''Create an anchor date.'''
    td = date.today()
    return datetime(year=td.year, month=td.month, day=td.day,
                    hour=hour, minute=minute, second=second)

########NEW FILE########
__FILENAME__ = rpc
from pulsar import send, coroutine_return, get_application
from pulsar.apps import rpc

from .backend import Task, TaskNotAvailable


__all__ = ['TaskQueueRpcMixin']


def task_to_json(task):
    if task:
        if isinstance(task, (list, tuple)):
            task = [task_to_json(t) for t in task]
        elif isinstance(task, Task):
            task = task.to_json()
    return task


class TaskQueueRpcMixin(rpc.JSONRPC):
    '''A :class:`.JSONRPC` mixin for communicating with  a :class:`.TaskQueue`.

    To use it, you need to have an :ref:`RPC application <apps-rpc>`
    and a :ref:`task queue <apps-taskqueue>` application installed in the
    :class:`.Arbiter`.

    :parameter taskqueue: instance or name of the :class:`.TaskQueue`
        application which exposes the remote procedure calls.

    '''
    _task_backend = None

    def __init__(self, taskqueue, **kwargs):
        if not isinstance(taskqueue, str):
            taskqueue = taskqueue.name
        self.taskqueue = taskqueue
        super(TaskQueueRpcMixin, self).__init__(**kwargs)

    ########################################################################
    #    REMOTES
    def rpc_job_list(self, request, jobnames=None):
        '''Return the list of Jobs registered with task queue with meta
        information.

        If a list of ``jobnames`` is given, it returns only jobs
        included in the list.
        '''
        task_backend = yield self.task_backend()
        coroutine_return(task_backend.job_list(jobnames=jobnames))

    def rpc_next_scheduled_tasks(self, request, jobnames=None):
        return self._rq(request, 'next_scheduled', jobnames=jobnames)

    def rpc_queue_task(self, request, jobname=None, **kw):
        '''Queue a new ``jobname`` in the task queue.

        The task can be of any type as long as it is registered in the
        task queue registry. To check the available tasks call the
        :meth:`rpc_job_list` function.

        It returns the task :attr:`~Task.id`.
        '''
        result = yield self.queue_task(request, jobname, **kw)
        coroutine_return(task_to_json(result))

    def rpc_get_task(self, request, id=None):
        '''Retrieve a task from its id'''
        if id:
            task_backend = yield self.task_backend()
            result = yield task_backend.get_task(id)
            coroutine_return(task_to_json(result))

    def rpc_get_tasks(self, request, **filters):
        '''Retrieve a list of tasks which satisfy key-valued filters'''
        if filters:
            task_backend = yield self.task_backend()
            result = yield task_backend.get_tasks(**filters)
            coroutine_return(task_to_json(result))

    def rpc_wait_for_task(self, request, id=None, timeout=None):
        '''Wait for a task to have finished.

        :param id: the id of the task to wait for.
        :param timeout: optional timeout in seconds.
        :return: the json representation of the task once it has finished.
        '''
        if id:
            task_backend = yield self.task_backend()
            result = yield task_backend.wait_for_task(id, timeout=timeout)
            coroutine_return(task_to_json(result))

    def rpc_num_tasks(self, request):
        '''Return the approximate number of tasks in the task queue.'''
        task_backend = yield self.task_backend()
        coroutine_return(task_backend.num_tasks())

    ########################################################################
    #    INTERNALS
    def task_backend(self):
        if not self._task_backend:
            app = yield get_application(self.taskqueue)
            self._task_backend = app.get_backend()
        coroutine_return(self._task_backend)

    def queue_task(self, request, jobname, meta_data=None, **kw):
        if not jobname:
            raise rpc.InvalidParams('"jobname" is not specified!')
        meta_data = meta_data or {}
        meta_data.update(self.task_request_parameters(request))
        task_backend = yield self.task_backend()
        result = yield task_backend.queue_task(jobname, meta_data, **kw)
        coroutine_return(result)

    def task_request_parameters(self, request):
        '''**Internal function** which returns a dictionary of parameters
        to be passed to the :class:`.Task` class constructor.

        This function can be overridden to add information about
        the type of request, who made the request and so forth.
        It must return a dictionary.
        By default it returns an empty dictionary.'''
        return {}

    def _rq(self, request, action, *args, **kw):
        return send(self.taskqueue, action, *args, **kw)

########NEW FILE########
__FILENAME__ = states
SUCCESS = 1
FAILURE = 2
REVOKED = 3
RETRY = 4
STARTED = 5
QUEUED = 6

FULL_RUN_STATES = frozenset([SUCCESS, FAILURE])
READY_STATES = frozenset([SUCCESS, FAILURE, REVOKED])
EXCEPTION_STATES = frozenset([FAILURE, REVOKED])
UNREADY_STATES = frozenset([QUEUED, STARTED, RETRY])

CODES = {SUCCESS: "SUCCESS",
         FAILURE: "FAILURE",
         REVOKED: "REVOKED",
         RETRY: 'RETRY',
         STARTED: "STARTED",
         QUEUED: "QUEUED"}
UNKNOWN = 'UNKNOWN'


def status_string(status):
    return CODES.get(status, UNKNOWN)

########NEW FILE########
__FILENAME__ = case
import sys
import unittest
import logging

from pulsar import multi_async, coroutine_return
from pulsar.utils.pep import ispy3k
from pulsar.apps import tasks

from .utils import TestFunction, TestFailure, is_expected_failure

if ispy3k:
    from unittest import mock
else:  # pragma nocover
    try:
        import mock
    except ImportError:
        mock = None


class Test(tasks.Job):
    '''A :class:`.Job` for running tests on a task queue.
    '''
    def __call__(self, consumer, testcls=None, tag=None):
        runner = consumer.worker.app.new_runner()
        if not isinstance(testcls, type):
            testcls = testcls()
        testcls.tag = tag
        testcls.cfg = consumer.worker.cfg
        all_tests = runner.loadTestsFromTestCase(testcls)
        num = all_tests.countTestCases()
        if num:
            return self.run(consumer, runner, testcls, all_tests)
        else:
            return runner.result

    def create_id(self, kwargs):
        tid = super(Test, self).create_id(kwargs)
        testcls = kwargs.get('testcls')
        return '%s_%s' % (testcls.__name__, tid) if testcls else tid

    def run(self, consumer, runner, testcls, all_tests):
        '''Run all test functions from the :attr:`testcls`.

        It uses the following algorithm:

        * Run the class method ``setUpClass`` of :attr:`testcls` if defined,
          unless the test class should be skipped
        * Call :meth:`run_test` for each test functions in :attr:`testcls`
        * Run the class method ``tearDownClass`` of :attr:`testcls` if defined,
          unless the test class should be skipped.
        '''
        cfg = testcls.cfg
        loop = consumer._loop
        runner.startTestClass(testcls)
        error = None
        sequential = getattr(testcls, '_sequential_execution', cfg.sequential)
        skip_tests = getattr(testcls, '__unittest_skip__', False)
        if not skip_tests:
            error = yield self._run(runner, testcls, 'setUpClass',
                                    add_err=False)
        # run the tests
        if sequential:
            # Loop over all test cases in class
            for test in all_tests:
                yield self.run_test(test, runner, error)
        else:
            all = (self.run_test(test, runner, error) for test in all_tests)
            yield multi_async(all, loop=loop)
        if not skip_tests:
            yield self._run(runner, testcls, 'tearDownClass', add_err=False)
        runner.stopTestClass(testcls)
        coroutine_return(runner.result)

    def run_test(self, test, runner, error=None):
        '''Run a ``test`` function using the following algorithm

        * Run :meth:`_pre_setup` method if available in :attr:`testcls`.
        * Run :meth:`setUp` method in :attr:`testcls`.
        * Run the test function.
        * Run :meth:`tearDown` method in :attr:`testcls`.
        * Run :meth:`_post_teardown` method if available in :attr:`testcls`.
        '''
        error_added = False
        try:
            runner.startTest(test)
            testMethod = getattr(test, test._testMethodName)
            if (getattr(test.__class__, '__unittest_skip__', False) or
                    getattr(testMethod, '__unittest_skip__', False)):
                reason = (getattr(test.__class__,
                                  '__unittest_skip_why__', '') or
                          getattr(testMethod,
                                  '__unittest_skip_why__', ''))
                runner.addSkip(test, reason)
                error = True
            elif error:
                self.add_failure(test, runner, error)
                error_added = True
            else:
                error = yield self._run(runner, test, '_pre_setup')
                if not error:
                    error = yield self._run(runner, test, 'setUp')
                    if not error:
                        error = yield self._run(runner, test,
                                                test._testMethodName)
                    error = yield self._run(runner, test, 'tearDown', error)
                error = yield self._run(runner, test, '_post_teardown', error)
            runner.stopTest(test)
        except Exception as exc:
            if not error_added:
                self.add_failure(test, runner, exc, error)
        else:
            if not error:
                runner.addSuccess(test)

    def _run(self, runner, test, methodName, previous=None, add_err=True):
        __skip_traceback__ = True
        method = getattr(test, methodName, None)
        if method:
            # Check if a testfunction object is already available
            # Check the run_on_arbiter decorator for information
            tfunc = getattr(method, 'testfunction', None)
            # python 3.4
            expecting_failure = getattr(
                method, '__unittest_expecting_failure__', False)
            if tfunc is None:
                tfunc = TestFunction(method.__name__)
            try:
                exc = yield tfunc(test, test.cfg.test_timeout)
            except Exception as e:
                exc = e
            if exc:
                add_err = False if previous else add_err
                previous = self.add_failure(test, runner, exc, add_err,
                                            expecting_failure)
        coroutine_return(previous)

    def add_failure(self, test, runner, failure, add_err=True,
                    expecting_failure=False):
        '''Add ``error`` to the list of errors.

        :param test: the test function object where the error occurs
        :param runner: the test runner
        :param error: the python exception for the error
        :param add_err: if ``True`` the error is added to the list of errors
        :return: a tuple containing the ``error`` and the ``exc_info``
        '''
        if not isinstance(failure, TestFailure):
            failure = TestFailure(failure)
        if add_err:
            if is_expected_failure(failure.exc, expecting_failure):
                runner.addExpectedFailure(test, failure)
            elif isinstance(failure.exc, test.failureException):
                runner.addFailure(test, failure)
            else:
                runner.addError(test, failure)
        else:
            self.logger.error(''.join(failure.trace))
        return failure

########NEW FILE########
__FILENAME__ = cov
import os
import sys

from coverage.report import Reporter
from coverage import coverage

from pulsar import new_event_loop
from pulsar.apps.http import HttpClient
from pulsar.utils.system import json
from pulsar.utils.version import gitrepo


COVERALLS_URL = 'https://coveralls.io/api/v1/jobs'


class CoverallsReporter(Reporter):

    def report(self, strip_dirs, ignore_errors=False):
        ret = []
        strip_dirs = strip_dirs or []
        for cu in self.code_units:
            try:
                with open(cu.filename) as fp:
                    source = fp.readlines()
            except IOError:
                if not ignore_errors:
                    raise
            analysis = self.coverage._analyze(cu)
            coverage_list = [None for _ in source]
            for lineno, line in enumerate(source):
                if lineno + 1 in analysis.statements:
                    coverage_list[lineno] = int(lineno + 1
                                                not in analysis.missing)
            filename = cu.filename
            for dir in strip_dirs:
                if filename.startswith(dir):
                    filename = filename.replace(dir, '').lstrip('/')
                    break
            ret.append({
                'name': filename,
                'source': ''.join(source).rstrip(),
                'coverage': coverage_list,
            })
        return ret


class Coverage(coverage):

    def coveralls(self, strip_dirs, ignore_errors=False):
        reporter = CoverallsReporter(self, self.config)
        reporter.find_code_units(None)
        return reporter.report(strip_dirs, ignore_errors=ignore_errors)


def coveralls(http=None, url=None, data_file=None, repo_token=None, git=None,
              service_name=None, service_job_id=None, strip_dirs=None,
              ignore_errors=False, stream=None):
    '''Send a coverage report to coveralls.io.

    :param http: optional http client
    :param url: optional url to send data to. It defaults to ``coveralls``
        api url.
    :param data_file: optional data file to load coverage data from. By
        default, coverage uses ``.coverage``.
    :param repo_token: required when not submitting from travis.

    https://coveralls.io/docs/api
    '''
    stream = stream or sys.stdout
    coverage = Coverage(data_file=data_file)
    coverage.load()
    if http is None:
        http = HttpClient(loop=new_event_loop())

    if not git:
        try:
            git = gitrepo()
        except Exception:   # pragma    nocover
            pass

    data = {'source_files': coverage.coveralls(strip_dirs, ignore_errors)}

    if git:
        data['git'] = git

    if os.environ.get('TRAVIS'):
        data['service_name'] = service_name or 'travis-ci'
        data['service_job_id'] = os.environ.get('TRAVIS_JOB_ID')
    else:
        assert repo_token, 'Requires repo_token if not submitting from travis'

    if repo_token:
        data['repo_token'] = repo_token
    url = url or COVERALLS_URL
    stream.write('Submitting coverage report to %s\n' % url)
    response = http.post(url, files={'json_file': json.dumps(data)})
    stream.write('Response code: %s\n' % response.status_code)
    try:
        info = response.json()
        code = 0
        if 'error' in info:
            stream.write('An error occured while sending coverage'
                         ' report to coverall.io')
            code = 1
        stream.write('\n%s\n' % info['message'])
    except Exception:
        code = 1
        stream.write('Critical error %s\n' % response.status_code)
    return code

########NEW FILE########
__FILENAME__ = loader
'''
.. autoclass:: TestLoader
   :members:
   :member-order: bysource

'''
import os
import re
import sys
import unittest
from importlib import import_module

from .utils import LOGGER


__all__ = ['TestLoader']


def issubclass_safe(cls, base_cls):
    try:
        return issubclass(cls, base_cls)
    except TypeError:
        return False


class TestLoader(object):
    '''Classes used by the :class:`.TestSuite` to aggregate tests
    from a list of paths.

    The way it works is simple, you give a *root* directory and a list
    of submodules where to look for tests.

    :parameter root: root path passed by the :class:`.TestSuite`.
    :parameter modules: list (or tuple) of entries where to look for tests.
        Check :ref:`loading test documentation <apps-test-loading>` for
        more information.
    :parameter runner: The :class:`.TestRunner` passed by the test suite.
    '''
    def __init__(self, root, modules, runner, logger=None):
        self.runner = runner
        self.logger = logger or LOGGER
        self.root = root
        self.modules = []
        for mod in modules:
            if isinstance(mod, str):
                mod = (mod, None, None)
            if len(mod) < 3:
                mod = tuple(mod) + (None,) * (3 - len(mod))
            self.modules.append(mod)

    def __repr__(self):
        return self.root
    __str__ = __repr__

    def alltags(self, tag):
        bits = tag.split('.')
        tag, rest = bits[0], bits[1:]
        yield tag
        for b in rest:
            tag += '.' + b
            yield tag

    def checktag(self, tag, import_tags, exclude_tags):
        '''Return ``True`` if ``tag`` is in ``import_tags``.'''
        if exclude_tags:
            alltags = list(self.alltags(tag))
            for exclude_tag in exclude_tags:
                for bit in alltags:
                    if bit == exclude_tag:
                        return 0
        if import_tags:
            c = 0
            alltags = list(self.alltags(tag))
            for import_tag in import_tags:
                allitags = list(self.alltags(import_tag))
                for bit in alltags:
                    if bit == import_tag:
                        return 2
                    elif bit in allitags:
                        c = 1
            return c
        else:
            return 2

    def testclasses(self, tags=None, exclude_tags=None):
        pt = ', '.join(('"%s"' % t for t in tags)) if tags else 'all'
        ex = ((' excluding %s' % ', '.join(('"%s"' % t for t in exclude_tags)))
              if exclude_tags else '')
        self.logger.info('Load test classes for %s %s', pt, ex)
        for tag, mod in self.testmodules(tags, exclude_tags):
            if tags:
                skip = True
                for bit in self.alltags(tag):
                    if bit in tags:
                        skip = False
                        break
                if skip:
                    continue
            for name in dir(mod):
                obj = getattr(mod, name)
                if issubclass_safe(obj, unittest.TestCase):
                    yield tag, obj

    def testmodules(self, tags=None, exclude_tags=None):
        '''Generator of ``tag``, ``modules`` pairs.

:parameter tags: optional list of tags to include, if not available all tags
    will be included.
:parameter exclude_tags: optional list of tags to exclude. If not provided no
    tags will be excluded.'''
        d = dict(self._testmodules(tags, exclude_tags))
        return [(k, d[k]) for k in sorted(d)]

    def _testmodules(self, tags, exclude_tags):
        for name, pattern, tag in self.modules:
            names = name.split('.') if name else ()
            absolute_path = pattern_path = os.path.join(self.root, *names)
            if pattern == '*':
                pattern = None
            if pattern:
                pattern_path = os.path.join(pattern_path, pattern)
                pattern = re.compile(pattern.replace('*', '(.*)'))
            self.logger.debug('Loading from "%s"', pattern_path)
            if os.path.isdir(absolute_path):
                pathbase = os.path.dirname(absolute_path)
                if pathbase not in sys.path:
                    sys.path.append(pathbase)
                name = names[-1]
                stags = (tag,) if tag else ()
                for tag, mod in self.get_tests(absolute_path, name, pattern,
                                               import_tags=tags, tags=stags,
                                               exclude_tags=exclude_tags):
                    yield tag, mod
            elif os.path.isfile(absolute_path + '.py'):
                include, ntag = self.match(pattern,
                                           os.path.basename(absolute_path))
                if include:
                    tag = ntag or tag or name
                    mod = self.import_module(name)
                    if mod:
                        yield tag, mod
            else:
                raise ValueError('%s cannot be found in %s directory.'
                                 % (name, self.root))

    def get_tests(self, path, dotted_path, pattern, import_tags=None,
                  tags=(), exclude_tags=None, parent=None):
        '''Collect python modules for testing and return a generator of
tag,module pairs.

:parameter path: directory path where to search. Files starting with ``_``
    or ``.`` are excluded from the search, as well as non-python files.

:parameter dotted_path: the dotted python path equivalent of ``path``.

:parameter parent: the parent module for the current one. This parameter
    is passed by this function recursively.'''
        for mod_name in os.listdir(path):
            if mod_name.startswith('_') or mod_name.startswith('.'):
                continue
            mod_path = os.path.join(path, mod_name)
            is_file = os.path.isfile(mod_path)
            if is_file:
                if mod_name.endswith('.py'):
                    mod_name = mod_name.split('.')[0]
                else:
                    continue
            include, addtag = self.match(pattern, mod_name)
            if not include and is_file:  # does not match and is a file, skip.
                continue
            elif include and not is_file and pattern:
                # All modules under this directory will be included
                # regardless of pattern
                pattern = None
            # module dotted path
            if dotted_path:
                mod_dotted_path = '%s.%s' % (dotted_path, mod_name)
            else:
                tags = (mod_name,)
                mod_dotted_path = mod_name
            #
            module = self.import_module(mod_dotted_path, mod_path, parent)
            if not module:
                continue
            ctags = tags + addtag
            tag = '.'.join(ctags)
            c = self.checktag(tag, import_tags, exclude_tags)
            if not c:
                continue
            if is_file:
                yield tag, module
            else:
                counter = 0
                # Recursively import modules
                for ctag, mod in self.get_tests(mod_path, mod_dotted_path,
                                                pattern, import_tags, ctags,
                                                exclude_tags, parent=module):
                    counter += 1
                    yield ctag, mod
                # If more than one submodule, yield this tag too
                if pattern:
                    if counter > 1:
                        yield tag, module
                elif c == 2:
                    yield tag, module

    def import_module(self, name, path=None, parent=None):
        imp = True
        if path and os.path.isdir(path):
            imp = False
            # import only if it has a __init__.py file
            for sname in os.listdir(path):
                if sname == '__init__.py':
                    imp = True
                    break
        if imp:
            try:
                mod = import_module(name)
                if getattr(mod, '__test__', True):
                    return self.runner.import_module(mod, parent)
            except ImportError:
                self.logger.error('Failed to import module %s. Skipping.',
                                  name, exc_info=True)
                self.logger.debug('Full python path:\n%s', '\n'.join(sys.path))
            except Exception:
                self.logger.critical('Failed to import module %s. Skipping.',
                                     name, exc_info=True)

    def match(self, pattern, name):
        if pattern:
            p = pattern.search(name)
            if p:
                return True, p.groups(0)
            else:
                return False, (name,)
        else:
            return True, (name,)

########NEW FILE########
__FILENAME__ = pep
import sys

try:
    import pep8
except ImportError:
    pep8 = None


def pep8_run(args, paths, config_file=None, stream=None):
    '''Programmatically run ``pep8``.

    Returns a 2-elements tuple with a string message and an exit code.
    '''
    args.remove('--pep8')
    if pep8:
        stream = stream or sys.stderr
        stream.write('Running pep8\n')
        pep8style = pep8.StyleGuide(paths=paths, config_file=config_file)
        options = pep8style.options
        report = pep8style.check_files()
        if options.statistics:
            report.print_statistics()
        if options.benchmark:
            report.print_benchmark()
        if options.testsuite and not options.quiet:
            report.print_results()
        if report.total_errors:
            msg = str(report.total_errors) + '\n' if options.count else ''
            return msg, 1
        return 'OK', 0
    return 'pep8 not installed', 1

########NEW FILE########
__FILENAME__ = base
import pulsar
from pulsar.utils.httpurl import iteritems
from pulsar.apps.test.result import Plugin


__all__ = ['WrapTest', 'TestPlugin']


def as_test_setting(setting):
    setting.app = 'test'
    setting.section = "Test"
    return setting


class WrapTest(object):
    '''Wrap an underlying test case'''
    def __init__(self, test):
        self.test = test
        setattr(self, test._testMethodName, self._call)
        self.testMethod = getattr(test, test._testMethodName)

    def __str__(self):
        return self.test._testMethodName
    __repr__ = __str__

    @property
    def original_test(self):
        if isinstance(self.test, WrapTest):
            return self.test.original_test
        else:
            return self.test

    def set_test_attribute(self, name, value):
        setattr(self.original_test, name, value)

    def __getattr__(self, name):
        return getattr(self.original_test, name)

    def _call(self):
        # This is the actual function to implement
        return self.testMethod()


class TestPluginMeta(type):

    def __new__(cls, name, bases, attrs):
        settings = {}
        for base in bases:
            if isinstance(base, TestPluginMeta):
                settings.update(base.config.settings)
        for key, setting in list(iteritems(attrs)):
            if isinstance(setting, pulsar.Setting):
                attrs.pop(key)
                setting.name = setting.name or key.lower()
                settings[setting.name] = as_test_setting(setting)
        if not attrs.pop('virtual', False):
            setting_name = attrs.pop('name', name).lower()
            if setting_name:
                def_flag = '--%s' % setting_name.replace(
                    ' ', '-').replace('_', '-')
                action = attrs.pop('action', None)
                type = attrs.pop('type', None)
                default = attrs.pop('default', None)
                validator = attrs.pop('validator', None)
                nargs = attrs.pop('nargs', None)
                if (validator is None and default is None and type is None
                        and nargs is None):
                    if action is None or action == 'store_true':
                        action = 'store_true'
                        default = False
                        validator = pulsar.validate_bool
                    elif action == 'store_false':
                        default = True
                        validator = pulsar.validate_bool
                setting = pulsar.Setting(name=setting_name,
                                         desc=attrs.pop('desc', name),
                                         type=type,
                                         flags=attrs.pop('flags', [def_flag]),
                                         action=action,
                                         default=default,
                                         validator=validator,
                                         nargs=nargs)
                settings[setting.name] = as_test_setting(setting)
        attrs['config'] = pulsar.Config(settings=settings)
        return super(TestPluginMeta, cls).__new__(cls, name, bases, attrs)


class TestPlugin(TestPluginMeta('TestPluginBase',
                                (Plugin,), {'virtual': True})):
    '''Base class for :class:`.Plugin` which can be added to a
    :class:`.TestSuite` to extend its functionalities.

    If the class attribute :attr:`name` is not specified or its value validate
    as ``True``, an additional :ref:`setting <settings>` is added to the
    configuration.
    In addition, a :class:`TestPlugin` can specify several additional
    :ref:`settings <settings>` as class attributes. For example, the
    :ref:`benchmark plugin <bench-plugin>` has an additional setting
    for controlling the number of repetitions::

        class Bench(TestPlugin):
            repeat = pulsar.Setting(type=int,
                                default=1,
                                validator=pulsar.validate_pos_int,
                                desc="Default number of repetition")


    .. attribute:: name

        Class attribute used for adding the default plugin
        :ref:`setting <settings>`
        to the configuration container of the test suite application.
        If the attribute is not set, the class name in lower case is used.
        If set and validate as not ``True``, no new :ref:`setting <settings>`
        is added to the test suite configuration parameters. For example::

            class MyPlugin(TestPlugin):
                name = None

        won't add the default plugin :ref:`setting <settings>`.

    .. attribute:: desc

        Class attribute used as the description of the
        :ref:`setting <settings>`.
        If :attr:`name` is disabled, this attribute is not relevant.

    .. attribute:: config

        A :class:`.Config` container created by the :class:`TestPlugin`
        metaclass. It collects the default setting, if
        available, and any additional :ref:`settings <settings>` specified
        as class attributes.
    '''
    virtual = True

    def __new__(cls):
        o = super(TestPlugin, cls).__new__(cls)
        o.config = cls.config.copy()
        return o

    def configure(self, cfg):
        self.config = cfg

########NEW FILE########
__FILENAME__ = bench
'''
:class:`.BenchMark` is a :class:`.TestPlugin` for benchmarking test functions.

To use the plugin follow these three steps:

* Included it in the test Suite::

    from pulsar.apps.test import TestSuite
    from pulsar.apps.test.plugins import bench

    def suite():
        TestSuite(..., plugins=(..., bench.BenchMark()))

* Flag a ``unittest.TestCase`` class with the ``__benchmark__ = True``
  class attribute::

      class MyBenchmark(unittest.TestCase):
          __benchmark__ = True

          def test_mybenchmark_function1(self):
              ...

          def test_mybenchmark_function2(self):
              ...

* Run the test suite with the ``--benchmark`` command line option.

The test class can implement additional methods to fine-tune how the
benchmark plugin evaluate the perfomance and display results:

* When implemented, the ``startUp`` method is invoked before each run
  of a test function.
* The time taken to run a test once can be modified by implementing
  the ``getTime`` method which receives as only argument the time interval
  taken.
  By default it returns the same time interval.

.. autoclass:: BenchMark

'''
import sys
import time
import math

if sys.platform == "win32":  # pragma    nocover
    default_timer = time.clock
else:
    default_timer = time.time

from unittest import TestSuite

import pulsar
from pulsar.utils.pep import range

from pulsar.apps import test


BENCHMARK_TEMPLATE = ('{0[name]}: repeated {0[number]} times, '
                      'average {0[mean]} secs, stdev {0[std]}')


class BenchTest(test.WrapTest):

    def __init__(self, test, number):
        super(BenchTest, self).__init__(test)
        self.number = number

    def updateSummary(self, info, number, total_time, total_time2):
        mean = total_time/number
        std = math.sqrt((total_time2 - total_time*mean)/number)
        std = round(100*std/mean, 2)
        info.update({'number': number,
                     'mean': '%.5f' % mean,
                     'std': '{0} %'.format(std)})

    def _call(self):
        simple = lambda info, *args: info
        testMethod = self.testMethod
        testStartUp = getattr(self.test, 'startUp', lambda: None)
        testGetTime = getattr(self.test, 'getTime', lambda dt: dt)
        testGetInfo = getattr(self.test, 'getInfo', simple)
        testGetSummary = getattr(self.test, 'getSummary', simple)
        t = 0
        t2 = 0
        info = {'name': '%s.%s' % (self.test.__class__.__name__,
                                   testMethod.__name__)}
        for r in range(self.number):
            testStartUp()
            start = default_timer()
            testMethod()
            delta = default_timer() - start
            dt = testGetTime(delta)
            testGetInfo(info, delta, dt)
            t += dt
            t2 += dt*dt
        self.updateSummary(info, self.number, t, t2)
        self.set_test_attribute('bench_info',
                                testGetSummary(info, self.number, t, t2))


class BenchMark(test.TestPlugin):
    '''Benchmarking addon for pulsar test suite.'''
    desc = '''Run benchmarks function flagged with __benchmark__ attribute'''

    repeat = pulsar.Setting(flags=['--repeat'],
                            type=int,
                            default=1,
                            validator=pulsar.validate_pos_int,
                            desc=('Default number of repetition '
                                  'when benchmarking.'))

    def loadTestsFromTestCase(self, test_cls):
        bench = getattr(test_cls, '__benchmark__', False)
        if self.config.benchmark != bench:  # skip the loading
            return TestSuite()

    def before_test_function_run(self, test, local):
        if self.config.benchmark:
            method_name = getattr(test, '_testMethodName', None)
            if method_name:
                method = getattr(test, method_name, None)
                bench = getattr(test, '__benchmark__', False)
                if not bench and method:
                    bench = getattr(method, '__benchmark__', False)
                if bench:
                    number = getattr(test, '__number__', self.config.repeat)
                    return BenchTest(test, number)

    def addSuccess(self, test):
        if self.config.benchmark and self.stream:
            result = getattr(test, 'bench_info', None)
            # if result and self.stream.showAll:
            if result:
                stream = self.stream.handler('benchmark')
                template = getattr(test, 'benchmark_template',
                                   BENCHMARK_TEMPLATE)
                stream.writeln(template.format(result))
                stream.flush()
                self.result.addSuccess(test)
                return True

    def addError(self, test, err):
        msg = self._msg(test, 'ERROR')
        if msg:
            self.result.addError(test, err)
            return msg

    def addFailure(self, test, err):
        msg = self._msg(test, 'FAILURE')
        if msg:
            self.result.addFailure(test, err)
            return msg

    def addSkip(self, test, reason):
        msg = self._msg(test, 'SKIPPED')
        if msg:
            self.result.addSkip(test, reason)
            return msg

    def _msg(self, test, msg):
        if self.config.benchmark and self.stream:
            stream = self.stream.handler('benchmark')
            stream.writeln('%s: %s' % (test, msg))
            stream.flush()
            return True

########NEW FILE########
__FILENAME__ = profile
'''
:class:`Profile` is a :class:`.TestPlugin` for profiling
test cases and generating Html reports.
It uses the :mod:`cProfile` module from the standard library.

To use the plugin follow these two steps:

* Included it in the test Suite::

    from pulsar.apps.test import TestSuite
    from pulsar.apps.test.plugins import profile

    def suite():
        TestSuite(..., plugins=(..., profile.Profile()))

* Run the test suite with the ``--profile`` command line option.

.. autoclass:: Profile
   :members:
   :member-order: bysource

'''
import os
import re
import time
import shutil
import tempfile
import cProfile as profiler
import pstats
from datetime import datetime

import pulsar
from pulsar.utils.httpurl import ispy3k
from pulsar.apps import test

if ispy3k:
    from io import StringIO as Stream
else:   # pragma    nocover
    from io import BytesIO as Stream

other_filename = 'unknown'
line_func = re.compile(r'(?P<line>\d+)\((?P<func>\w+)\)')
template_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                             'htmlfiles', 'profile')
headers = (
    ('ncalls',
     'total number of calls'),
    ('primitive calls',
     'Number primitive calls (calls not induced via recursion)'),
    ('tottime',
     'Total time spent in the given function (excluding time spent '
     'in calls to sub-functions'),
    ('percall',
     'tottime over ncalls, the time spent by each call'),
    ('cumtime',
     'Total time spent in the given function including all subfunctions'),
    ('percall',
     'cumtime over primitive calls'),
    ('function', ''),
    ('lineno', ''),
    ('filename', '')
    )


def absolute_file(val):
    dir = os.getcwd()
    return os.path.join(dir, val)


def make_stat_table(data):
    yield "<thead>\n<tr>\n"
    for head, description in headers:
        yield '<th title="{1}">{0}</th>'.format(head, description)
    yield '\n</tr>\n</thead>\n<tbody>\n'
    for row in data:
        yield '<tr>\n'
        for col in row:
            yield '<td>{0}</td>'.format(col)
        yield '\n</tr>\n'
    yield '</tbody>'


def data_stream(lines, num=None):
    if num:
        lines = lines[:num]
    for line in lines:
        if not line:
            continue
        fields = [field for field in line.split() if field is not '']
        if len(fields) == 6:
            valid = True
            new_fields = fields[0].split('/')
            if len(new_fields) == 1:
                new_fields.append(new_fields[0])
            for f in fields[1:-1]:
                try:
                    float(f)
                except Exception:
                    valid = False
                    break
                new_fields.append(f)
            if not valid:
                continue
            filenames = fields[-1].split(':')
            linefunc = filenames.pop()
            match = line_func.match(linefunc)
            if match:
                lineno, func = match.groups()
                filename = ':'.join(filenames)
                filename = filename.replace('\\', '/')
                new_fields.extend((func, lineno, filename))
            else:
                new_fields.extend(('', '', other_filename))
            yield new_fields


def copy_file(filename, target, context=None):
    with open(os.path.join(template_path, filename), 'r') as file:
        stream = file.read()
    if context:
        stream = stream.format(context)
    with open(os.path.join(target, filename), 'w') as file:
        file.write(stream)


class Profile(test.TestPlugin):
    ''':class:`pulsar.apps.test.TestPlugin` for profiling test cases.'''
    desc = '''Profile tests using the cProfile module'''
    profile_stats_path = pulsar.Setting(
        flags=['--profile-stats-path'],
        default='htmlprof',
        desc='location of profile directory.',
        validator=absolute_file)

    def configure(self, cfg):
        self.config = cfg
        self.profile_stats_path = cfg.profile_stats_path
        dir, name = os.path.split(self.profile_stats_path)
        fname = '.'+name
        self.profile_temp_path = os.path.join(dir, fname)

    def before_test_function_run(self, test, local):
        # If active return a TestProfile instance wrapping the real test case.
        if self.config.profile:
            local.prof = profiler.Profile()
            local.tmp = tempfile.mktemp(dir=self.profile_temp_path)
            local.prof.enable()

    def after_test_function_run(self, test, local):
        if self.config.profile:
            local.prof.disable()
            local.prof.dump_stats(local.tmp)

    def on_start(self):
        if self.config.profile:
            self.remove_dir(self.profile_temp_path, build=True)

    def remove_dir(self, dir, build=False):
        sleep = 0
        if os.path.exists(dir):
            shutil.rmtree(dir)
            sleep = 0.2
        if build:
            time.sleep(sleep)
            os.mkdir(dir)

    def on_end(self):
        if self.config.profile:
            files = [os.path.join(self.profile_temp_path, file) for file in
                     os.listdir(self.profile_temp_path)]
            if not files:
                return
            stats = pstats.Stats(*files, **{'stream': Stream()})
            stats.sort_stats('time', 'calls')
            stats.print_stats()
            stats_str = stats.stream.getvalue()
            self.remove_dir(self.profile_temp_path)
            stats_str = stats_str.split('\n')
            run_info = 'Executed %s.' % datetime.now().isoformat()
            for n, line in enumerate(stats_str):
                b = 0
                while b < len(line) and line[b] == ' ':
                    b += 1
                line = line[b:]
                if line:
                    if line.startswith('ncalls'):
                        break
                    bits = line.split(' ')
                    try:
                        ncalls = int(bits[0])
                    except Exception:
                        continue
                    else:
                        run_info += ' ' + line
            data = ''.join(make_stat_table(data_stream(stats_str[n+1:], 100)))
            self.remove_dir(self.profile_stats_path, build=True)
            for file in os.listdir(template_path):
                if file == 'index.html':
                    copy_file(file, self.profile_stats_path,
                              {'table': data,
                               'run_info': run_info,
                               'version': pulsar.__version__})
                else:
                    copy_file(file, self.profile_stats_path)

########NEW FILE########
__FILENAME__ = populate
from datetime import date, timedelta
from random import uniform, randint, choice
import string

from pulsar.utils.pep import ispy3k

if ispy3k:
    characters = string.ascii_letters + string.digits
else:   # pragma nocover
    characters = string.letters + string.digits
    range = xrange

def_converter = lambda x: x


def populate(datatype='string', size=10, start=None, end=None,
             converter=None, choice_from=None, **kwargs):
    '''Utility function for populating lists with random data.

    Useful when populating database with data for fuzzy testing.

    Supported data-types

    * *string*
        For example::

            populate('string', 100, min_len=3, max_len=10)

        create a 100 elements list with random strings
        with random length between 3 and 10

    * *date*
        For example::

            from datetime import date
            populate('date', 200, start=date(1997,1,1), end=date.today())

        create a 200 elements list with random datetime.date objects
        between *start* and *end*

    * *integer*
        For example::

            populate('integer', 200, start=0, end=1000)

        create a 200 elements list with random integers between ``start``
        and ``end``

    * *float*
        For example::

            populate('float', 200, start=0, end=10)

        create a 200 elements list with random floats between ``start`` and
        ``end``

    * *choice* (elements of an iterable)
        For example::

            populate('choice', 200, choice_from=['pippo','pluto','blob'])

        create a 200 elements list with random elements from ``choice_from``
    '''
    data = []
    converter = converter or def_converter
    if datatype == 'date':
        date_end = end or date.today()
        date_start = start or date(1990, 1, 1)
        delta = date_end - date_start
        for s in range(size):
            data.append(converter(random_date(date_start, delta.days)))
    elif datatype == 'integer':
        start = start or 0
        end = end or 1000000
        for s in range(size):
            data.append(converter(randint(start, end)))
    elif datatype == 'float':
        start = start or 0
        end = end or 10
        for s in range(size):
            data.append(converter(uniform(start, end)))
    elif datatype == 'choice' and choice_from:
        for s in range(size):
            data.append(choice(list(choice_from)))
    else:
        for s in range(size):
            data.append(converter(random_string(**kwargs)))
    return data


def random_string(min_len=3, max_len=20, **kwargs):
    len = randint(min_len, max_len) if max_len > min_len else min_len
    return ''.join((choice(characters) for s in range(len)))


def random_date(date_start, delta):
    return date_start + timedelta(days=randint(0, delta))

########NEW FILE########
__FILENAME__ = result
import unittest
from copy import deepcopy

from pulsar import format_traceback
from pulsar.utils.structures import AttributeDictionary

from .utils import TestFailure, LOGGER


__all__ = ['Plugin',
           'TestStream',
           'TestRunner',
           'TestResult',
           'Plugin']


STDOUT_LINE = '\nStdout:\n%s'
STDERR_LINE = '\nStderr:\n%s'


class Plugin(object):
    '''Interface for all classes which are part of the :class:`.TestRunner`.

    Most classes used by the test application are plugins, for
    example the :class:`.TestRunner` itself,
    the :class:`.TestResult` and the :class:`.TestPlugin`.
    '''
    result = None
    '''An optional result'''
    stream = None
    '''handle for writing text on the default output.

    Set by the :class:`.TestRunner` at runtime.
    '''
    descriptions = None

    def configure(self, cfg):
        '''Called once just after construction of a :class:`.TestRunner`
           and **before any test class is loaded**.

        This is a chance to configure the :class:`.Plugin` or global variables
        which may affect the way tests are run.
        If it returns something other than ``None`` (for example an abort
        message) it will stop the configuration of all subsequent
        plugins and quit the test.

        :parameter cfg: a :class:`.Config`.
        :return: ``None`` unless the tests runner must be stopped.
        '''
        pass

    @property
    def name(self):
        return self.__class__.__name__.lower()

    @property
    def count(self):
        return self.result.count if self.result else 0

    @property
    def testsRun(self):
        return self.result.testsRun if self.result else 0

    def on_start(self):
        '''Called by the :class:`.TestSuite` once only at startup.

        This callback is invoked once all tests are loaded but before
        the test suite starts running them.
        '''
        pass

    def on_end(self):
        '''Called by the :class:`.TestSuite` just before it stops.
        '''
        pass

    def loadTestsFromTestCase(self, testcls):
        '''Called when loading tests from the ``testcls`` class.

        Can be used to modify the number of test functions loaded.'''
        pass

    def startTestClass(self, testcls):
        '''Called just before a ``testcls`` runs its tests.
        '''
        pass

    def stopTestClass(self, testcls):
        '''Called just after a ``testcls`` has run its tests.
        '''
        pass

    def startTest(self, test):
        '''Called just before a ``test`` function is executed.

        This is run just before ``_pre_setup`` method.
        '''
        pass

    def stopTest(self, test):
        '''Called just after a ``test`` function has finished.

        This is run just after the ``_post_teardown`` method.
        '''
        pass

    def before_test_function_run(self, test, local):
        '''Can be used by plugins to manipulate the ``test``
        behaviour in the process domain where the test run.'''
        return test

    def after_test_function_run(self, test, local):
        '''Executed in the ``test`` process domain, after the ``test`` has
        finished.'''
        pass

    def addSuccess(self, test):
        '''Called when a ``test`` function succeed
        '''
        pass

    def addFailure(self, test, err):
        '''Called when a ``test`` function as a (test) failure
        '''
        pass

    def addError(self, test, err):
        '''Called when a ``test`` function as an (unexpected) error
        '''
        pass

    def addExpectedFailure(self, test, err):
        pass

    def addSkip(self, test, reason):
        pass

    def printErrors(self):
        pass

    def printSummary(self, timeTaken):
        pass

    def import_module(self, mod, parent=None):
        return mod

    def getDescription(self, test):
        doc_first_line = test.shortDescription()
        teststr = '%s.%s' % (test.tag, test)
        if self.descriptions and doc_first_line:
            return '\n'.join((teststr, doc_first_line))
        else:
            return teststr


class TestStream(Plugin):  # pragma    nocover
    '''Handle the writing of test results'''
    separator1 = '=' * 70
    separator2 = '-' * 70

    def __init__(self, stream, result, descriptions=True):
        self._handlers = {}
        self.stream = stream
        self.result = result
        self.descriptions = descriptions
        self.showAll = False
        self.dots = True

    def configure(self, cfg):
        verbosity = cfg.verbosity
        self.showAll = verbosity > 1
        self.dots = verbosity == 1

    def handler(self, name):
        return self._handlers.get(name, self.stream)

    def startTest(self, test):
        if self.showAll:
            self.head(test, 'Started')

    def head(self, test, v):
        v = self.getDescription(test) + ' ... %s\n' % v
        self.stream.write(v)
        self.stream.flush()

    def addSuccess(self, test):
        if self.showAll:
            self.head(test, 'OK')
        elif self.dots:
            self.stream.write('.')
            self.stream.flush()

    def addError(self, test, err):
        if self.showAll:
            self.head(test, 'ERROR')
        elif self.dots:
            self.stream.write('E')
            self.stream.flush()

    def addFailure(self, test, err):
        if self.showAll:
            self.head(test, "FAIL")
        elif self.dots:
            self.stream.write('F')
            self.stream.flush()

    def addSkip(self, test, reason):
        if self.showAll:
            self.head(test, "skipped {0!r}".format(reason))
        elif self.dots:
            self.stream.write("s")
            self.stream.flush()

    def addExpectedFailure(self, test, err):
        if self.showAll:
            self.head(test, "expected failure")
        elif self.dots:
            self.stream.write("x")
            self.stream.flush()

    def addUnexpectedSuccess(self, test):
        if self.showAll:
            self.head(test, "unexpected success")
        elif self.dots:
            self.stream.write("u")
            self.stream.flush()

    def printErrors(self):
        if self.dots or self.showAll:
            self.stream.writeln()
        self.printErrorList('ERROR', self.result.errors)
        self.printErrorList('FAIL', self.result.failures)
        return True

    def printErrorList(self, flavour, errors):
        for test, err in errors:
            self.stream.writeln(self.separator1)
            self.stream.writeln("%s: %s" % (flavour, test))
            self.stream.writeln(self.separator2)
            self.stream.writeln("%s" % err)

    def printSummary(self, timeTaken):
        '''Write the summuray of tests results.'''
        stream = self.stream
        result = self.result
        self.printErrors()
        run = result.testsRun
        stream.writeln("Ran %d test%s in %.3fs" %
                       (run, run != 1 and "s" or "", timeTaken))
        stream.writeln()

        expectedFails = unexpectedSuccesses = skipped = 0
        results = map(len, (result.expectedFailures,
                            result.unexpectedSuccesses,
                            result.skipped))
        expectedFails, unexpectedSuccesses, skipped = results

        infos = []
        if not result.wasSuccessful():
            stream.write("FAILED")
            failed, errored = map(len, (result.failures, result.errors))
            if failed:
                infos.append("failures=%d" % failed)
            if errored:
                infos.append("errors=%d" % errored)
        else:
            stream.write("OK")
        if skipped:
            infos.append("skipped=%d" % skipped)
        if expectedFails:
            infos.append("expected failures=%d" % expectedFails)
        if unexpectedSuccesses:
            infos.append("unexpected successes=%d" % unexpectedSuccesses)
        if infos:
            stream.writeln(" (%s)" % (", ".join(infos),))
        else:
            stream.write("\n")

        return True


class TestResult(Plugin):
    '''A :class:`.Plugin` for collecting results/failures for test runs.

    Each :class:`.Plugin` can access the :class:`.TestRunner` ``result``
    object via the :attr:`~Plugin.result` attribute.
    '''
    def __init__(self, descriptions=True):
        self.descriptions = descriptions
        self._testsRun = 0
        self._count = 0
        self.failures = []
        self.errors = []
        self.skipped = []
        self.expectedFailures = []
        self.unexpectedSuccesses = []

    @property
    def count(self):
        return self._count

    @property
    def testsRun(self):
        return self._testsRun

    @property
    def result(self):
        return self

    def startTest(self, test):
        '''Increase the test counter
        '''
        self._testsRun += 1

    def addError(self, test, err):
        '''Called when an unexpected error has occurred.

        ``err`` is a tuple of values as returned by ``sys.exc_info()``
        '''
        self._add_error(test, err, self.errors)

    def addFailure(self, test, err):
        '''Called when an test failure has occurred.

        ``err`` is a tuple of values as returned by ``sys.exc_info()``
        '''
        self._add_error(test, err, self.failures)

    def addSkip(self, test, reason):
        """Called when a test is skipped."""
        self.skipped.append((self.getDescription(test), reason))

    def addExpectedFailure(self, test, err):
        """Called when an expected failure/error occured."""
        self._add_error(test, err, self.expectedFailures)

    def addUnexpectedSuccess(self, test):
        """Called when a test was expected to fail, but succeed."""
        self.unexpectedSuccesses.append(self.getDescription(test))

    def _add_error(self, test, exc, container):
        if not isinstance(exc, TestFailure):
            exc = TestFailure(exc)
        test = self.getDescription(test)
        container.append((test, str(exc)))

    def add(self, result):
        self._count += 1
        self._testsRun += result.testsRun
        self.failures.extend(result.failures)
        self.errors.extend(result.errors)
        self.skipped.extend(result.skipped)
        self.expectedFailures.extend(result.expectedFailures)
        self.unexpectedSuccesses.extend(result.unexpectedSuccesses)

    def wasSuccessful(self):
        "Tells whether or not this result was a success"
        return len(self.failures) == len(self.errors) == 0


def testsafe(name, return_val=None):
    if not return_val:
        return_val = lambda c: None

    def _(self, *args):
        for p in self.plugins:
            try:
                c = getattr(p, name)(*args)
                if c is not None:
                    return return_val(c)
            except Exception:
                LOGGER.exception('Unhadled error in %s.%s' % (p, name))
    return _


class TestRunner(Plugin):
    '''A :class:`.Plugin` for asynchronously running tests.
    '''
    def __init__(self, plugins, stream, writercls=None, descriptions=True,
                 logger=None):
        self.descriptions = descriptions
        self.plugins = []
        writercls = writercls or TestStream
        result = TestResult(descriptions=self.descriptions)
        stream = writercls(stream, result, descriptions=self.descriptions)
        for p in plugins:
            p = deepcopy(p)
            p.descriptions = self.descriptions
            p.result = result
            p.stream = stream
            self.plugins.append(p)
        self.plugins.append(result)
        self.plugins.append(stream)
        self.stream = stream
        self.result = result
        self.loader = unittest.TestLoader()

    configure = testsafe('configure', lambda c: c)
    on_start = testsafe('on_start')
    on_end = testsafe('on_end')
    startTestClass = testsafe('startTestClass')
    stopTestClass = testsafe('stopTestClass')
    startTest = testsafe('startTest')
    stopTest = testsafe('stopTest')
    addSuccess = testsafe('addSuccess')
    addFailure = testsafe('addFailure')
    addExpectedFailure = testsafe('addExpectedFailure')
    addError = testsafe('addError')
    addSkip = testsafe('addSkip')
    printErrors = testsafe('printErrors')
    printSummary = testsafe('printSummary')

    def loadTestsFromTestCase(self, test_cls):
        '''Load all ``test`` functions for the ``test_cls``
        '''
        c = testsafe('loadTestsFromTestCase', lambda v: v)(self, test_cls)
        if c is None:
            return self.loader.loadTestsFromTestCase(test_cls)
        else:
            return c

    def add(self, result):
        '''Add a new result to the :attr:`~.Plugin.result` container
        '''
        self.result.add(result)

    def import_module(self, mod, parent=None):
        for p in self.plugins:
            mod = p.import_module(mod, parent)
            if not mod:
                return
        return mod

    def before_test_function_run(self, test):
        '''Called just before the test is run,
        in the test process domain.'''
        test.plugins = plugins = {}
        for p in self.plugins:
            local = AttributeDictionary()
            plugins[p.name] = local
            test = p.before_test_function_run(test, local) or test
        return test

    def after_test_function_run(self, test):
        '''Called just after the test has finished,
        in the test process domain.'''
        for p in self.plugins:
            local = test.plugins.get(p.name)
            if local is not None:
                p.after_test_function_run(test, local)

########NEW FILE########
__FILENAME__ = utils
'''
run on arbiter
~~~~~~~~~~~~~~~~~~~~~~~~

.. autofunction:: run_on_arbiter


sequential
~~~~~~~~~~~~~~~~~~~~~~~~

.. autofunction:: sequential


ActorTestMixin
~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: ActorTestMixin
   :members:
   :member-order: bysource


AsyncAssert
~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: AsyncAssert
   :members:
   :member-order: bysource

run test server
~~~~~~~~~~~~~~~~~~~~~~

.. autofunction:: run_test_server

check server
~~~~~~~~~~~~~~~~~~

.. autofunction:: check_server

'''
import gc
import logging
import unittest
from inspect import isclass
from functools import partial
from contextlib import contextmanager
from asyncio import Future

try:
    from unittest.case import _ExpectedFailure as ExpectedFailure
except ImportError:
    ExpectedFailure = None

import pulsar
from pulsar import (get_actor, send, multi_async, async, future_timeout,
                    TcpServer, coroutine_return, new_event_loop,
                    format_traceback)
from pulsar.async.proxy import ActorProxyFuture
from pulsar.utils.importer import module_attribute
from pulsar.apps.data import create_store


__all__ = ['run_on_arbiter',
           'sequential',
           'NOT_TEST_METHODS',
           'ActorTestMixin',
           'AsyncAssert',
           'show_leaks',
           'hide_leaks',
           'run_test_server',
           'check_server',
           'dont_run_with_thread']


LOGGER = logging.getLogger('pulsar.test')
NOT_TEST_METHODS = ('setUp', 'tearDown', '_pre_setup', '_post_teardown',
                    'setUpClass', 'tearDownClass', 'run_test_server')


class TestFailure:

    def __init__(self, exc):
        self.exc = exc
        self.trace = format_traceback(exc)

    def __str__(self):
        return '\n'.join(self.trace)


class TestCallable(object):
    '''Responsible for actually running a test function.
    '''
    def __init__(self, test, method_name, istest, timeout):
        self.test = test
        self.method_name = method_name
        self.istest = istest
        self.timeout = timeout

    def __repr__(self):
        if isclass(self.test):
            return '%s.%s' % (self.test.__name__, self.method_name)
        else:
            return '%s.%s' % (self.test.__class__.__name__, self.method_name)
    __str__ = __repr__

    def __call__(self, actor):
        result = async(self._call(actor))
        return future_timeout(result, self.timeout) if self.timeout else result

    def _call(self, actor):
        # Coroutine to run an asynchronous test function
        __skip_traceback__ = True
        test = self.test
        if self.istest:
            test = actor.app.runner.before_test_function_run(test)
        inject_async_assert(test)
        test_function = getattr(test, self.method_name)
        failure = None
        try:
            yield test_function()
        except Exception as exc:
            failure = TestFailure(exc)
        if self.istest:
            actor.app.runner.after_test_function_run(self.test)
        coroutine_return(failure)


class SafeTest(object):
    '''Make sure the test object or class is picklable
    '''
    def __init__(self, test):
        self.test = test

    def __getattr__(self, name):
        return getattr(self.test, name)

    def __getstate__(self):
        if isclass(self.test):
            cls = self.test
            data = None
        else:
            cls = self.test.__class__
            data = self.test.__dict__.copy()
        return ('%s.%s' % (cls.__module__, cls.__name__), data)

    def __setstate__(self, state):
        mod, data = state
        test = module_attribute(mod)
        inject_async_assert(test)
        if data is not None:
            test = test.__new__(test)
            test.__dict__.update(data)
        self.test = test


class TestFunction(object):

    def __init__(self, method_name):
        self.method_name = method_name
        self.istest = self.method_name not in NOT_TEST_METHODS

    def __repr__(self):
        return self.method_name
    __str__ = __repr__

    def __call__(self, test, timeout):
        callable = TestCallable(test, self.method_name, self.istest, timeout)
        return callable(get_actor())


class TestFunctionOnArbiter(TestFunction):

    def __call__(self, test, timeout):
        test = SafeTest(test)
        callable = TestCallable(test, self.method_name, self.istest, timeout)
        actor = get_actor()
        if actor.is_monitor():
            return callable(actor)
        else:
            # send the callable to the actor monitor
            return actor.send(actor.monitor, 'run', callable)


def run_on_arbiter(f):
    '''Decorator for running a test function in the :class:`.Arbiter`
    context domain.

    This can be useful to test Arbiter mechanics.
    '''
    f.testfunction = TestFunctionOnArbiter(f.__name__)
    return f


def sequential(cls):
    '''Decorator for a :class:`~unittest.TestCase` which cause
    its test functions to run sequentially rather than in an
    asynchronous fashion.

    Typical usage::

        import unittest

        from pulsar.apps.test import sequential

        @sequenatial
        class MyTests(unittest.TestCase):
            ...

    You can also run test functions sequentially when using the
    :ref:`sequential <apps-test-sequential>` flag in the command line.
    '''
    cls._sequential_execution = True
    return cls


class AsyncAssert(object):
    '''A `descriptor`_ added by the :ref:`test-suite` to all python
    :class:`~unittest.TestCase` loaded.

    It can be used to invoke the same ``assertXXX`` methods available in
    the :class:`~unittest.TestCase` in an asynchronous fashion.

    The descriptor is available via the ``async`` attribute.
    For example::

        class MyTest(unittest.TestCase):

            def test1(self):
                yield self.async.assertEqual(3, Future().callback(3))
                ...


    .. _descriptor: http://users.rcn.com/python/download/Descriptor.htm
    '''
    def __init__(self, test=None):
        self.test = test

    def __get__(self, instance, instance_type=None):
        return AsyncAssert(instance)

    def __getattr__(self, name):
        def _(*args, **kwargs):
            __skip_traceback__ = True
            args = yield multi_async(args)
            result = yield getattr(self.test, name)(*args, **kwargs)
            coroutine_return(result)
        return _

    def assertRaises(self, error, callable, *args, **kwargs):
        try:
            yield callable(*args, **kwargs)
        except error:
            coroutine_return()
        except Exception:
            raise self.test.failureException('%s not raised by %s'
                                             % (error, callable))
        else:
            raise self.test.failureException('%s not raised by %s'
                                             % (error, callable))


class ActorTestMixin(object):
    '''A mixin for :class:`~unittest.TestCase`.

    Useful for classes testing spawning of actors.
    Make sure this is the first class you derive from, before the
    :class:`~unittest.TestCase`, so that the tearDown method is overwritten.

    .. attribute:: concurrency

        The concurrency model used to spawn actors via the :meth:`spawn`
        method.
    '''
    concurrency = 'thread'

    @property
    def all_spawned(self):
        if not hasattr(self, '_spawned'):
            self._spawned = []
        return self._spawned

    def spawn_actor(self, concurrency=None, **kwargs):
        '''Spawn a new actor and perform some tests.'''
        concurrency = concurrency or self.concurrency
        ad = pulsar.spawn(concurrency=concurrency, **kwargs)
        self.assertTrue(ad.aid)
        self.assertTrue(isinstance(ad, ActorProxyFuture))
        proxy = yield ad
        self.all_spawned.append(proxy)
        self.assertEqual(proxy.aid, ad.aid)
        self.assertEqual(proxy.proxy, proxy)
        self.assertTrue(proxy.cfg)
        coroutine_return(proxy)

    def stop_actors(self, *args):
        all = args or self.all_spawned
        if len(all) == 1:
            return send(all[0], 'stop')
        elif all:
            return multi_async((send(a, 'stop') for a in all))

    def tearDown(self):
        return self.stop_actors()


def inject_async_assert(obj):
    tcls = obj if isclass(obj) else obj.__class__
    if not hasattr(tcls, 'async'):
        tcls.async = AsyncAssert()


def show_leaks(actor, show=True):
    '''Function to show memory leaks on a processed-based actor.'''
    if not actor.is_process():
        return
    gc.collect()
    if gc.garbage:
        MAX_SHOW = 100
        write = actor.stream.writeln if show else lambda msg: None
        write('MEMORY LEAKS REPORT IN %s' % actor)
        write('Created %s uncollectable objects' % len(gc.garbage))
        for obj in gc.garbage[:MAX_SHOW]:
            write('Type: %s' % type(obj))
            write('=================================================')
            write('%s' % obj)
            write('-------------------------------------------------')
            write('')
            write('')
        if len(gc.garbage) > MAX_SHOW:
            write('And %d more' % (len(gc.garbage) - MAX_SHOW))


def hide_leaks(actor):
    show_leaks(actor, False)


@contextmanager
def run_test_server(protocol_factory, loop, address=None, **kw):
    '''A context manager for running a test server::

        with run_test_server(loop, protocol_factory) as server:
            ...

    It creates a :class:`.TcpServer` and invoke
    :meth:`~.TcpServer.stop_serving` on exit.
    '''
    address = address or ('127.0.0.1', 0)
    server = TcpServer(protocol_factory, loop, address, **kw)
    try:
        yield server
    finally:
        server.stop_serving()


def check_server(name):
    '''Check if server ``name`` is available at the address specified
    ``<name>_server`` config value.

    :rtype: boolean
    '''
    cfg = get_actor().cfg
    cfgname = '%s_server' % name
    addr = cfg.get('%s_server' % name)
    if ('%s://' % name) not in addr:
        addr = '%s://%s' % (name, addr)
    sync_store = create_store(addr, loop=new_event_loop())
    try:
        sync_store.ping()
        return True
    except Exception:
        return False


def dont_run_with_thread(obj):
    '''Decorator for disabling process based test cases when the test suite
    runs in threading, rather than processing, mode.
    '''
    actor = pulsar.get_actor()
    if actor:
        d = unittest.skipUnless(actor.cfg.concurrency == 'process',
                                'Run only when concurrency is process')
        return d(obj)
    else:
        return obj


def is_expected_failure(exc, default=False):
    if ExpectedFailure:
        return isinstance(exc, ExpectedFailure)
    else:
        return default

########NEW FILE########
__FILENAME__ = wsgi
'''Classes for testing WSGI servers using the HttpClient'''
from functools import partial

from pulsar import asyncio
from pulsar.apps import http
from pulsar.apps.wsgi import HttpServerResponse

__all__ = ['HttpTestClient']


class DummyTransport(asyncio.Transport):
    '''A class simulating a :class:`pulsar.Transport` to a :attr:`connection`

.. attribute:: client

    The :class:`pulsar.Client` using this :class:`DummyTransport`

.. attribute:: connection

    The *server* connection for this :attr:`client`
'''
    def __init__(self, client, connnection):
        self.client = client
        self.connection = connnection

    def write(self, data):
        '''Writing data means calling ``data_received`` on the
server :attr:`connection`.'''
        self.connection.data_received(data)

    @property
    def address(self):
        return self.connection.address


class DummyConnectionPool:
    '''A class for simulating a client connection with a server'''
    def get_or_create_connection(self, producer):
        client = self.connection_factory(self.address, 1, 0,
                                         producer.consumer_factory,
                                         producer)
        server = self.connection_factory(('127.0.0.1', 46387), 1, 0,
                                         producer.server_consumer,
                                         producer)
        client.connection_made(DummyTransport(producer, server))
        server.connection_made(DummyTransport(producer, client))
        return client


class HttpTestClient(http.HttpClient):
    '''Useful :class:`pulsar.apps.http.HttpClient` for wsgi server
handlers.

.. attribute:: wsgi_handler

    The WSGI server handler to test
'''
    client_version = 'Pulsar-Http-Test-Client'
    connection_pool = DummyConnectionPool

    def __init__(self, test, wsgi_handler, **kwargs):
        self.test = test
        self.wsgi_handler = wsgi_handler
        self.server_consumer = partial(HttpServerResponse, wsgi_handler,
                                       test.cfg)
        super(HttpTestClient, self).__init__(**kwargs)

    def data_received(self, connnection, data):
        pass

    def response(self, request):
        conn = self.get_connection(request)
        # build the protocol consumer
        consumer = conn.consumer_factory(conn)
        # start the request
        consumer.new_request(request)
        return consumer

########NEW FILE########
__FILENAME__ = extensions
import zlib

from pulsar.utils import websocket

############################################################################
#  x-webkit-deflate-frame     Extension
#
# http://code.google.com/p/pywebsocket/


class deflate_frame(websocket.Extension):

    def __init__(self, window_bits=None):
        self.window_bits = window_bits or zlib.MAX_WBITS

    def receive(self, frame, application_data):
        if frame.rsv1 == 1:
            application_data += b'\x00\x00\xff\xff'
            return zlib.decompress(application_data)
        else:
            return application_data

    def send(self, frame, application_data):
        application_data = self._compress.compress(application_data)
        return application_data


# websocket.WS_EXTENSIONS['x-webkit-deflate-frame'] = deflate_frame

########NEW FILE########
__FILENAME__ = websocket
import base64
import hashlib
from functools import partial

from pulsar import HttpException, ProtocolError, ProtocolConsumer, maybe_async
from pulsar.utils.pep import to_bytes, native_str
from pulsar.utils.httpurl import DEFAULT_CHARSET
from pulsar.utils.websocket import frame_parser, parse_close
from pulsar.apps import wsgi

from . import extensions

WEBSOCKET_GUID = '258EAFA5-E914-47DA-95CA-C5AB0DC85B11'
TRANSPORTS = {}


def register_transport(klass):
    TRANSPORTS[klass.name] = klass
    return klass


@register_transport
class WebSocket(wsgi.Router):
    """A :ref:`Router <wsgi-router>` for a websocket handshake.

    Once the handshake is succesful, the protocol consumer
    is upgraded to :class:`WebSocketProtocol` and messages are handled by
    the :attr:`handle` attribute, an instance of :class:`.WS`.

    See http://tools.ietf.org/html/rfc6455 for the websocket server protocol
    and http://www.w3.org/TR/websockets/ for details on the JavaScript
    interface.

    .. attribute:: parser_factory

        A factory of websocket frame parsers
    """
    parser_factory = frame_parser
    _name = 'websocket'

    def __init__(self, route, handle, parser_factory=None, **kwargs):
        super(WebSocket, self).__init__(route, **kwargs)
        self.handle = handle
        self.parser_factory = parser_factory or frame_parser

    @property
    def name(self):
        return self._name

    def get(self, request):
        headers_parser = self.handle_handshake(request.environ)
        if not headers_parser:
            raise HttpException(status=404)
        headers, parser = headers_parser
        response = request.response
        response.status_code = 101
        response.content = b''
        response.headers.update(headers)
        connection = request.environ.get('pulsar.connection')
        if not connection:
            raise HttpException(status=404)
        factory = partial(WebSocketProtocol, request, self.handle, parser)
        connection.upgrade(factory)
        return request.response

    def handle_handshake(self, environ):
        connections = environ.get(
            "HTTP_CONNECTION", '').lower().replace(' ', '').split(',')
        if environ.get("HTTP_UPGRADE", '').lower() != "websocket" or \
           'upgrade' not in connections:
            raise HttpException(status=400)
        key = environ.get('HTTP_SEC_WEBSOCKET_KEY')
        if key:
            try:
                ws_key = base64.b64decode(key.encode(DEFAULT_CHARSET))
            except Exception:
                ws_key = ''
            if len(ws_key) != 16:
                raise HttpException(msg="WebSocket key's length is invalid",
                                    status=400)
        else:
            raise HttpException(msg='Not a valid HyBi WebSocket request. '
                                    'Missing Sec-Websocket-Key header.',
                                status=400)
        # Collect supported subprotocols
        subprotocols = environ.get('HTTP_SEC_WEBSOCKET_PROTOCOL')
        ws_protocols = []
        if subprotocols:
            for s in subprotocols.split(','):
                ws_protocols.append(s.strip())
        # Collect supported extensions
        ws_extensions = []
        extensions = environ.get('HTTP_SEC_WEBSOCKET_EXTENSIONS')
        if extensions:
            for ext in extensions.split(','):
                ws_extensions.append(ext.strip())
        # Build the frame parser
        version = environ.get('HTTP_SEC_WEBSOCKET_VERSION')
        try:
            parser = self.parser_factory(version=version,
                                         protocols=ws_protocols,
                                         extensions=ws_extensions)
        except ProtocolError as e:
            raise HttpException(str(e), status=400)
        headers = [('Sec-WebSocket-Accept', self.challenge_response(key))]
        if parser.protocols:
            headers.append(('Sec-WebSocket-Protocol',
                            ', '.join(parser.protocols)))
        if parser.extensions:
            headers.append(('Sec-WebSocket-Extensions',
                            ','.join(parser.extensions)))
        return headers, parser

    def challenge_response(self, key):
        sha1 = hashlib.sha1(to_bytes(key+WEBSOCKET_GUID))
        return native_str(base64.b64encode(sha1.digest()))


class WebSocketProtocol(ProtocolConsumer):
    '''A :class:`.ProtocolConsumer` for websocket servers and clients.

    .. attribute:: handshake

        The original handshake response/request.

    .. attribute:: handler

        A websocket handler :class:`.WS`.

    .. attribute:: parser

        A websocket :class:`.FrameParser`.

    .. attribute:: close_reason

        A tuple of (``code``, ``reason``) or ``None``.

        Available when a close frame is received.
    '''
    close_reason = None

    def __init__(self, handshake, handler, parser):
        super(WebSocketProtocol, self).__init__()
        self.bind_event('post_request', self._shut_down)
        self.handshake = handshake
        self.handler = handler
        self.parser = parser

    @property
    def cfg(self):
        '''The :class:`.Config` container for this protocol.
        '''
        return self.handshake.cfg

    def connection_made(self, connection):
        connection.set_timeout(0)
        maybe_async(self.handler.on_open(self), self._loop)

    def data_received(self, data):
        frame = self.parser.decode(data)
        while frame:
            if frame.is_close:
                try:
                    self.close_reason = parse_close(frame.body)
                finally:
                    self._connection.close()
                break
            if frame.is_message:
                maybe_async(self.handler.on_message(self, frame.body))
            elif frame.is_bytes:
                maybe_async(self.handler.on_bytes(self, frame.body))
            elif frame.is_ping:
                maybe_async(self.handler.on_ping(self, frame.body))
            elif frame.is_pong:
                maybe_async(self.handler.on_pong(self, frame.body))
            frame = self.parser.decode()

    def write(self, message, opcode=None, **kw):
        '''Write a new ``message`` into the wire.

        It uses the :meth:`~.FrameParser.encode` method of the
        websocket :attr:`parser`.

        :param message: message to send, must be a string or bytes
        :param opcode: optional ``opcode``, if not supplied it is set to 1
            if ``message`` is a string, otherwise ``2`` when the message
            are bytes.
         '''
        chunk = self.parser.encode(message, opcode=opcode, **kw)
        self.transport.write(chunk)
        if opcode == 8:
            self.finish()

    def ping(self, message=None):
        '''Write a ping ``frame``.
        '''
        self.transport.write(self.parser.ping(message))

    def pong(self, message=None):
        '''Write a pong ``frame``.
        '''
        self.transport.write(self.parser.pong(message))

    def write_close(self, code=None):
        '''Write a close ``frame`` with ``code``.
        '''
        self.transport.write(self.parser.close(code))
        self._connection.close()

    def _shut_down(self, result, exc=None):
        maybe_async(self.handler.on_close(self))

########NEW FILE########
__FILENAME__ = auth
'''
Handle basic and digest authentication on the server.

HttpAuthenticate
~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: HttpAuthenticate
   :members:
   :member-order: bysource

'''
import os
import time
from base64 import b64decode

from pulsar import HttpException
from pulsar.utils.httpurl import (parse_dict_header, hexmd5, hexsha1,
                                  quote_header_value, DEFAULT_CHARSET)
from pulsar.utils.pep import iteritems, to_bytes


__all__ = ['HttpAuthenticate', 'parse_authorization_header']


_require_quoting = frozenset(['domain', 'nonce', 'opaque', 'realm'])


class HttpAuthenticate(HttpException):
    '''Exception when ``basic`` or ``digest`` authentication is required.

    This HttpException is raised with status code ``401`` and the extra
    ``WWW_Authenticate`` header if ``type`` is either ``basic`` or ``digest``.
    '''
    def __init__(self, type, realm=None, **options):
        realm = realm or 'authentication required'
        if type == 'basic':
            value = self._auth_header(type, realm=realm)
        elif type == 'digest':
            value = self.digest_auth_header(realm, **options)
        else:
            value = None
        if value:
            value = [('WWW-Authenticate', value)]
        super(HttpAuthenticate, self).__init__(status=401, headers=value)

    def digest_auth_header(self, realm=None, nonce=None, qop=None, opaque=None,
                           algorithm=None, stale=None):
        options = {}
        if nonce is None:
            nonce = hexmd5(to_bytes('%d' % time.time()) + os.urandom(10))
            if opaque is None:
                opaque = hexmd5(os.urandom(10))
        if stale:
            options['stale'] = 'TRUE'
        if opaque is not None:
            options['opaque'] = opaque
        if algorithm is not None:
            options['algorithm'] = algorithm
        if qop is None:
            qop = ('auth',)
        return self._auth_header('digest', realm=realm, nonce=nonce,
                                 qop=', '.join(qop), **options)

    def _auth_header(self, type, **options):
        """Convert the stored values into a WWW-Authenticate header."""
        return '%s %s' % (type.title(), ', '.join((
            '%s=%s' % (key, quote_header_value(
                value, allow_token=key not in _require_quoting))
            for key, value in iteritems(options)
        )))


class BasicAuth(object):
    def __init__(self, username, password):
        self.username = username
        self.password = password

    def authenticated(self, environ, username=None, password=None, **params):
        return username == self.username and password == self.password

    def __repr__(self):
        return 'Basic: %s' % self.username
    __str__ = __repr__


class DigestAuth(object):
    def __init__(self, username, password=None, options=None):
        self.username = username
        self.password = password
        self.last_nonce = None
        self.options = options or {}
        self.algorithm = self.options.pop('algorithm', 'MD5')

    def __repr__(self):
        return 'Digest: %s' % self.username
    __str__ = __repr__

    def authenticated(self, environ, username=None, password=None, **params):
        '''Called by the server to check if client is authenticated.'''
        if username != self.username:
            return False
        o = self.options
        qop = o.get('qop')
        method = environ['REQUEST_METHOD']
        uri = environ.get('PATH_INFO', '')
        ha1 = self.ha1(o['realm'], password)
        ha2 = self.ha2(qop, method, uri)
        if qop is None:
            response = hexmd5(":".join((ha1, self.nonce, ha2)))
        elif qop == 'auth' or qop == 'auth-int':
            response = hexmd5(":".join((ha1, o['nonce'], o['nc'],
                                        o['cnonce'], qop, ha2)))
        else:
            raise ValueError("qop value are wrong")
        return o['response'] == response

    def hex(self, x):
        if self.algorithm == 'MD5':
            return hexmd5(x)
        elif self.algorithm == 'SHA1':
            return hexsha1(x)
        else:
            raise ValueError('Unknown algorithm %s' % self.algorithm)

    def ha1(self, realm, password):
        return self.hex('%s:%s:%s' % (self.username, realm, password))

    def ha2(self, qop, method, uri, body=None):
        if qop == "auth" or qop is None:
            return self.hex("%s:%s" % (method, uri))
        elif qop == "auth-int":
            return self.hex("%s:%s:%s" % (method, uri, self.hex(body)))
        raise ValueError()


digest_parameters = frozenset(('username', 'realm', 'nonce', 'uri', 'nc',
                               'cnonce', 'response'))


def parse_authorization_header(value, charset='utf-8'):
    '''Parse an HTTP basic/digest authorisation header.

    :param value: the authorisation header to parse.
    :return: either `None` if the header was invalid or
        not given, otherwise an :class:`Auth` object.
    '''
    if not value:
        return
    try:
        auth_type, auth_info = value.split(None, 1)
        auth_type = auth_type.lower()
    except ValueError:
        return
    if auth_type == 'basic':
        try:
            up = b64decode(auth_info.encode(DEFAULT_CHARSET)).decode(charset)
            username, password = up.split(':', 1)
        except Exception:
            return
        return BasicAuth(username, password)
    elif auth_type == 'digest':
        auth_map = parse_dict_header(auth_info)
        if not digest_parameters.difference(auth_map):
            return DigestAuth(auth_map.pop('username'), options=auth_map)

########NEW FILE########
__FILENAME__ = content
'''The :mod:`pulsar.apps.wsgi.content` introduces several utility classes for
handling asynchronous content within a :ref:`WSGI handler <wsgi-async> or
:ref:`middleware <wsgi-middleware>`.

These classes can operate instead or in conjunction with a template engine,
their main purpose is to do what a web framework does: to provide a set of
tools working together to concatenate ``strings`` to return as a
response to an :ref:`HTTP client request <app-wsgi-request>`.

A string can be ``html``, ``json``, ``plain text`` or any other valid HTTP
content type.

The main class of this module is the :class:`AsyncString`, which can be
considered as the atomic component of an asynchronous web framework::

    >>> from pulsar.apps.wsgi import AsyncString
    >>> string = AsyncString('Hello')
    >>> string.render()
    'Hello'
    >>> string.render()
    ...
    RuntimeError: AsyncString already streamed

An :class:`AsyncString` can only be rendered once, and it accepts
:ref:`asynchronous components  <tutorials-coroutine>`::

    >>> a = Future()
    >>> string = AsyncString('Hello, ', a)
    >>> value = string.render()
    >>> value
    MultiFuture (pending)
    >>> value.done()
    False

Once the future is done, we have the concatenated string::

    >>> a.set_result('World!')
    'World!'
    >>> value.done()
    True
    >>> value.result()
    'Hello, World!'

Design
===============

The :meth:`~AsyncString.do_stream` method is responsible for the streaming
of ``strings`` or :ref:`asynchronous components  <tutorials-coroutine>`.
It can be overwritten by subclasses to customise the way an
:class:`AsyncString` streams its :attr:`~AsyncString.children`.

On the other hand, the :meth:`~AsyncString.to_string` method is responsible
for the concatenation of ``strings`` and, like :meth:`~AsyncString.do_stream`,
it can be customised by subclasses.


Asynchronous String
=====================

.. autoclass:: AsyncString
   :members:
   :member-order: bysource

Asynchronous Json
=====================

.. autoclass:: Json
   :members:
   :member-order: bysource

.. _wsgi-html:

Asynchronous Html
=====================

.. autoclass:: Html
   :members:
   :member-order: bysource

.. _wsgi-html-document:

Html Document
==================

Document
~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: HtmlDocument
   :members:
   :member-order: bysource

.. _wsgi-html-head:

Head
~~~~~~~~~~

.. autoclass:: Head
   :members:
   :member-order: bysource

Media
~~~~~~~~~~

.. autoclass:: Media
   :members:
   :member-order: bysource

Scripts
~~~~~~~~~~

.. autoclass:: Scripts
   :members:
   :member-order: bysource

Css
~~~~~~~~~~

.. autoclass:: Css
   :members:
   :member-order: bysource

Html Factory
=================

.. autofunction:: html_factory


'''
import json as pyjson

from collections import Mapping, OrderedDict
from functools import partial
from inspect import isgenerator

from pulsar import multi_async, Future, async, coroutine_return, chain_future
from pulsar.utils.pep import iteritems, is_string, to_string, ispy3k
from pulsar.utils.html import (slugify, INLINE_TAGS, tag_attributes, attr_iter,
                               dump_data_value, child_tag)
from pulsar.utils.httpurl import remove_double_slash
from pulsar.utils.system import json

from .html import html_visitor

__all__ = ['AsyncString', 'Html',
           'Json', 'HtmlDocument',
           'html_factory', 'Media', 'Scripts', 'Css']


if ispy3k:

    def stream_to_string(stream):
        for value in stream:
            if value is None:
                continue
            elif isinstance(value, bytes):
                yield value.decode('utf-8')
            elif isinstance(value, str):
                yield value
            else:
                yield str(value)

else:  # pragma nocover

    def stream_to_string(stream):
        for value in stream:
            if value is None:
                continue
            elif isinstance(value, unicode):
                yield value
            else:
                yield str(value)


def stream_mapping(value, request=None):
    result = {}
    async = False
    for key, value in iteritems(value):
        if isinstance(value, AsyncString):
            value = value.render(request)
        result[key] = value
    return multi_async(result)


class AsyncString(object):
    '''An asynchronous string which can be used with pulsar WSGI servers.
    '''
    _default_content_type = 'text/plain'
    _content_type = None
    '''Content type for this :class:`AsyncString`'''
    _streamed = False
    _children = None
    _parent = None
    charset = None

    def __init__(self, *children, **params):
        for child in children:
            self.append(child)
        self._setup(**params)

    def _setup(self, content_type=None, charset=None, **kw):
        self._content_type = content_type or self._default_content_type
        self.charset = charset or 'utf-8'

    @property
    def content_type(self):
        return '%s; charset=%s' % (self._content_type, self.charset)

    @property
    def parent(self):
        '''The :class:`AsyncString` element which contains this
        :class:`AsyncString`.'''
        return self._parent

    @property
    def children(self):
        '''A copy of all children of this :class:`AsyncString`.

        Children can be other :class:`AsyncString` or string or bytes,
        depending on implementation.
        :attr:`children` are added and removed via the :meth:`append` and
        :meth:`remove` methods.
        '''
        if self._children is None:
            self._children = []
        return self._children

    @property
    def has_default_content_type(self):
        '''``True`` if this is as the default content type.
        '''
        return self._content_type == self._default_content_type

    def __repr__(self):
        return self.__class__.__name__

    def __str__(self):
        return self.__repr__()

    def append(self, child):
        '''Append ``child`` to the list of :attr:`children`.

:param child: String, bytes or another :class:`AsyncString`. If it is an
    :class:`AsyncString`, this instance will be set as its :attr:`parent`.
    If ``child`` is ``None``, this method does nothing.

'''
        self.insert(None, child)

    def prepend(self, child):
        '''Prepend ``child`` to the list of :attr:`children`.

This is a shortcut for the :meth:`insert` method at index 0.

:param child: String, bytes or another :class:`AsyncString`. If it is an
    :class:`AsyncString`, this instance will be set as its :attr:`parent`.
    If ``child`` is ``None``, this method does nothing.
    '''
        self.insert(0, child)

    def insert(self, index, child):
        '''Insert ``child`` into the list of :attr:`children` at ``index``.

        :param index: The index (positive integer) where to insert ``child``.
        :param child: String, bytes or another :class:`AsyncString`.
            If it is an :class:`.AsyncString`, this instance will be set as
            its :attr:`parent`.
            If ``child`` is ``None``, this method does nothing.
        '''
        # make sure that child is not in child
        if child not in (None, self):
            if isinstance(child, AsyncString):
                child_parent = child._parent
                if self._parent is child:
                    # the parent is the child we are appending.
                    # remove from the child
                    child.remove(self)
                    if child_parent:
                        index = child_parent.children.index(child)
                        child_parent.remove(child)
                        child_parent.insert(index, self)
                elif child_parent:
                    child_parent.remove(child)
                child._parent = self
            if index is None:
                self.children.append(child)
            else:
                self.children.insert(index, child)

    def remove(self, child):
        '''Remove a ``child`` from the list of :attr:`children`.'''
        try:
            self.children.remove(child)
            if isinstance(child, AsyncString):
                child._parent = None
        except ValueError:
            pass

    def remove_all(self):
        '''Remove all :attr:`children`.'''
        if self._children:
            for child in self._children:
                if isinstance(child, AsyncString):
                    child._parent = None
            self._children = []

    def append_to(self, parent):
        '''Append itself to ``parent``. Return ``self``.'''
        parent.append(self)
        return self

    def stream(self, request):
        '''An iterable over strings or asynchronous elements.

        This is the most important method of an :class:`AsyncString`.
        It is called by :meth:`http_response` or by the :attr:`parent`
        of this :class:`AsyncString`.
        It returns an iterable (list, tuple or a generator) over
        strings (``unicode/str`` for python 2, ``str`` only for python 3) or
        :ref:`asynchronous elements <tutorials-coroutine>` which result in
        strings. This method can be called **once only**, otherwise a
        :class:`RuntimeError` occurs.

        This method should not be overwritten, instead one should use the
        :meth:`do_stream` to customise behaviour.
        '''
        if self._streamed:
            raise RuntimeError('%s already streamed' % self)
        self._streamed = True
        return self.do_stream(request)

    def do_stream(self, request):
        '''Returns an iterable over strings or asynchronous components.

        If :ref:`asynchronous elements <tutorials-coroutine>` are included
        in the iterable, when called, they must result in strings.

        This method can be re-implemented by subclasses and should not be
        invoked directly.

        Use the :meth:`stream` method instead.
        '''
        if self._children:
            for child in self._children:
                if isinstance(child, AsyncString):
                    for bit in child.stream(request):
                        yield bit
                else:
                    yield child

    def http_response(self, request):
        '''Return a coroutine which results in a :class:`.WsgiResponse`.

        This method asynchronously wait for :meth:`stream` and subsequently
        returns a :class:`.WsgiResponse`.
        '''
        response = request.response
        response.content_type = self.content_type
        body = yield multi_async(self.stream(request))
        response.content = self.to_string(body)
        coroutine_return(response)

    def to_string(self, stream):
        '''Once the :class:`.Future`, returned by :meth:`content`
        method, is ready, this method get called to transform the stream into
        the content string. This method can be overwritten by derived classes.

        :param stream: a collections containing ``strings/bytes`` used to
            build the final ``string/bytes``.
        :return: a string or bytes
        '''
        return to_string(''.join(stream_to_string(stream)))

    def render(self, request=None):
        '''Render this string.

        This method returns a string or a :class:`.Future` which results
        in a string.
        '''
        stream = multi_async(self.stream(request))
        if stream.done():
            return self.to_string(stream.result())
        else:
            return chain_future(stream, callback=self.to_string)

    def __call__(self, request):
        stream = multi_async(self.stream(request))
        return chain_future(stream, callback=self.to_string)


class Json(AsyncString):
    '''An :class:`AsyncString` which renders into a json string.

    The :attr:`AsyncString.content_type` attribute is set to
    ``application/json``.

    .. attribute:: as_list

        If ``True``, the content is always a list of objects.
        Default ``False``.

    .. attribute:: parameters

        Additional dictionary of parameters passed during initialisation.
    '''
    _default_content_type = 'application/json'

    def _setup(self, as_list=False, **params):
        self.as_list = as_list
        super(Json, self)._setup(**params)

    def do_stream(self, request):
        if self._children:
            for child in self._children:
                if isinstance(child, AsyncString):
                    for bit in child.stream(request):
                        yield bit
                elif isinstance(child, Mapping):
                    yield stream_mapping(child, request)
                else:
                    yield child

    def to_string(self, stream):
        if len(stream) == 1 and not self.as_list:
            return json.dumps(stream[0])
        else:
            return json.dumps(stream)


def html_factory(tag, **defaults):
    '''Returns an :class:`Html` factory function for ``tag`` and a given
    dictionary of ``defaults`` parameters. For example::

    >>> input_factory = html_factory('input', type='text')
    >>> html = input_factory(value='bla')

    '''
    def html_input(*children, **params):
        p = defaults.copy()
        p.update(params)
        return Html(tag, *children, **p)
    return html_input


class Html(AsyncString):
    '''An :class:`AsyncString` for ``html`` content.

    The :attr:`~AsyncString.content_type` attribute is set to ``text/html``.

    :param tag: Set the :attr:`tag` attribute. Must be given and can be
        ``None``.
    :param children: Optional children which will be added via the
        :meth:`~AsyncString.append` method.
    :param params: Optional keyed-value parameters
        including:

        * ``cn`` class name or list of class names.
        * ``attr`` dictionary of attributes to add.
        * ``data`` dictionary of data to add (rendered as HTML data attribute).
        * ``type`` type of element, only supported for tags which accept the
          ``type`` attribute (for example the ``input`` tag).

    Any other keyed-value parameter will be added as attribute,
    if in the set of:attr:`available_attributes` or as :meth:`data`.
    '''
    _default_content_type = 'text/html'

    def __init__(self, tag, *children, **params):
        self._tag = tag
        self._extra = {}
        self._setup(**params)
        for child in children:
            self.append(child)

    @property
    def tag(self):
        '''The tag for this HTML element.

        One of ``div``, ``a``, ``table`` and so forth.
        It can be ``None``.
        '''
        return self._tag

    @property
    def _classes(self):
        if 'classes' in self._extra:
            return self._extra['classes']

    @property
    def _data(self):
        if 'data' in self._extra:
            return self._extra['data']

    @property
    def _attr(self):
        if 'attr' in self._extra:
            return self._extra['attr']

    @property
    def _css(self):
        if 'css' in self._extra:
            return self._extra['css']

    @property
    def type(self):
        if 'attr' in self._extra:
            return self._extra['attr'].get('type')

    @property
    def available_attributes(self):
        '''The list of valid HTML attributes for this :attr:`tag`.'''
        return tag_attributes(self._tag, self.type)

    def get_form_value(self):
        '''Return the value of this :class:`Html` element when it is contained
        in a Html form element.

        For most element it gets the ``value`` attribute.
        '''
        return self._visitor.get_form_value(self)

    def set_form_value(self, value):
        '''Set the value of this :class:`Html` element when it is contained
in a Html form element. For most element it sets the ``value`` attribute.'''
        self._visitor.set_form_value(self, value)

    def __repr__(self):
        if self._tag and self._tag in INLINE_TAGS:
            return '<%s%s/>' % (self._tag, self.flatatt())
        elif self._tag:
            return '<%s%s>' % (self._tag, self.flatatt())
        else:
            return self.__class__.__name__

    def append(self, child):
        if child:
            tag = child_tag(self._tag)
            if tag:
                if isinstance(child, Html):
                    if child.tag != tag:
                        child = Html(tag, child)
                elif not child.startswith('<%s' % tag):
                    child = Html(tag, child)
        super(Html, self).append(child)

    def _setup(self, cn=None, attr=None, css=None, data=None, type=None,
               content_type=None, **params):
        self.charset = params.get('charset') or 'utf-8'
        self._content_type = content_type or self._default_content_type
        self._visitor = html_visitor(self._tag)
        self.addClass(cn)
        self.data(data)
        self.attr(attr)
        self.css(css)
        attributes = self.available_attributes
        if type and 'type' in attributes:
            self.attr('type', type)
            attributes = self.available_attributes
        for name, value in iteritems(params):
            if name in attributes:
                self.attr(name, value)
            elif name != 'charset':
                self.data(name, value)

    def attr(self, *args):
        '''Add the specific attribute to the attribute dictionary
        with key ``name`` and value ``value`` and return ``self``.'''
        attr = self._attr
        if not args:
            return attr or {}
        result, adding = self._attrdata('attr', *args)
        if adding:
            if attr is None:
                self._extra['attr'] = attr = {}
            available_attributes = self.available_attributes
            for name, value in iteritems(result):
                if value is not None:
                    if name in available_attributes:
                        attr[name] = value
                    elif name is 'value':
                        self.append(value)
            result = self
        return result

    def data(self, *args):
        '''Add or retrieve data values for this :class:`Html`.'''
        data = self._data
        if not args:
            return data or {}
        result, adding = self._attrdata('data', *args)
        if adding:
            if data is None:
                self._extra['data'] = {}
            add = self._visitor.add_data
            for key, value in iteritems(result):
                add(self, key, value)
            return self
        else:
            return result

    def addClass(self, cn):
        '''Add the specific class names to the class set and return ``self``.
        '''
        if cn:
            if isinstance(cn, (tuple, list, set, frozenset)):
                add = self.addClass
                for c in cn:
                    add(c)
            else:
                classes = self._classes
                if classes is None:
                    self._extra['classes'] = classes = set()
                add = classes.add
                for cn in cn.split():
                    add(slugify(cn, rtx='-'))
        return self

    def hasClass(self, cn):
        '''``True`` if ``cn`` is a class of self.'''
        classes = self._classes
        return classes and cn in classes

    def removeClass(self, cn):
        '''Remove classes'''
        if cn:
            ks = self._classes
            if ks:
                for cn in cn.split():
                    if cn in ks:
                        ks.remove(cn)
        return self

    def flatatt(self, **attr):
        '''Return a string with atributes to add to the tag'''
        cs = ''
        attr = self._attr
        classes = self._classes
        data = self._data
        css = self._css
        attr = attr.copy() if attr else {}
        if classes:
            cs = ' '.join(classes)
            attr['class'] = cs
        if css:
            attr['style'] = ' '.join(('%s:%s;' % (k, v) for
                                      k, v in css.items()))
        if data:
            for k, v in data.items():
                attr['data-%s' % k] = dump_data_value(v)
        if attr:
            return ''.join(attr_iter(attr))
        else:
            return ''

    def css(self, mapping=None):
        '''Update the css dictionary if ``mapping`` is a dictionary, otherwise
 return the css value at ``mapping``. If ``mapping`` is not given, return the
 whole ``css`` dictionary if available.'''
        css = self._css
        if mapping is None:
            return css
        elif isinstance(mapping, Mapping):
            if css is None:
                self._extra['css'] = css = {}
            css.update(mapping)
            return self
        else:
            return css.get(mapping) if css else None

    def hide(self):
        '''Same as jQuery hide method.'''
        self.css({'display': 'none'})
        return self

    def show(self):
        '''Same as jQuery show method.'''
        css = self._css
        if css:
            css.pop('display', None)
        return self

    def add_media(self, request):
        '''Invoked just before streaming this content.

        It can be used to add media entries to the document.

        TODO: more docs
        '''
        pass

    def do_stream(self, request):
        self.add_media(request)
        if self._tag and self._tag in INLINE_TAGS:
            yield '<%s%s>' % (self._tag, self.flatatt())
        else:
            if self._tag:
                yield '<%s%s>' % (self._tag, self.flatatt())
            if self._children:
                for child in self._children:
                    if isinstance(child, AsyncString):
                        for bit in child.stream(request):
                            yield bit
                    elif isgenerator(child):
                        yield async(child, getattr(request, '_loop', None))
                    else:
                        yield child
            if self._tag:
                yield '</%s>' % self._tag

    def _attrdata(self, cont, name, *val):
        if not name:
            return None, False
        if isinstance(name, Mapping):
            if val:
                raise TypeError('Cannot set a value to %s' % name)
            return name, True
        else:
            if val:
                if len(val) == 1:
                    return {name: val[0]}, True
                else:
                    raise TypeError('Too may arguments')
            else:
                cont = self._extra.get(cont)
                return cont.get(name) if cont else None, False


class Media(AsyncString):
    '''A useful container of media links or scripts.

    .. attribute:: media_path

        The base url path to the local media files, for example
        ``/media/``. Must include both slashes.

    .. attribute:: minified

        Optional flag indicating if relative media files should be modified to
        end with ``.min.js`` or ``.min.css`` rather than ``.js`` or ``.css``
        rispectively.

        Default: ``False``

    .. attribute:: known_libraries

        Optional dictionary of known media libraries, mapping a name to a
        valid absolute or local url. For example::

            known_libraries = {'jquery':
                               '//code.jquery.com/jquery-1.9.1.min.js'}

        Default: ``None``
    '''
    mediatype = None

    def __init__(self, media_path, minified=False, known_libraries=None):
        super(Media, self).__init__()
        self.media_path = media_path
        self.minified = minified
        self.known_libraries = known_libraries or {}

    @property
    def children(self):
        if self._children is None:
            self._children = OrderedDict()
        return self._children

    def append(self, value):
        '''Append new media to the container.'''
        raise NotImplementedError

    def is_relative(self, path):
        '''Check if ``path`` is a local relative path.

        A path is local relative when it does not start with a slash
        ``/`` nor ``http://`` nor ``https://``.
        '''
        return not (path.startswith('http://') or path.startswith('https://')
                    or path.startswith('/'))

    def absolute_path(self, path, with_media_ending=True):
        '''Return a suitable absolute url for ``path``.

        The url is calculated in the following way:

        * Check if ``path`` is an entry in the :attr:`known_libraries`
          dictionary. In this case replace ``path`` with
          ``known_libraries[path]``.
        * If ``path`` :meth:`is_relative` build a sutable url by prepending
          the :attr:`media_path` attribute.

        :return: A url path to insert in a HTML ``link`` or ``script``.
        '''
        urlparams = ''
        ending = '.%s' % self.mediatype
        if path in self.known_libraries:
            lib = self.known_libraries[path]
            if isinstance(lib, dict):
                urlparams = lib.get('urlparams', '')
                lib = lib['url']
            path = '%s%s' % (lib, ending)
        if self.minified:
            if path.endswith(ending):
                path = self._minify(path, ending)
        if not with_media_ending:
            path = path[:-len(ending)]
        if urlparams:
            path = '%s?%s' % (path, urlparams)
        if self.is_relative(path):
            return remove_double_slash('%s/%s' % (self.media_path, path))
        else:
            return path

    def _minify(self, path, postfix):
        new_postfix = 'min%s' % postfix
        if not path.endswith(new_postfix):
            path = '%s.%s' % (path[:-len(postfix)], new_postfix)
        return path


class Css(Media):
    '''A :class:`Media` container for style sheet links.
    '''
    mediatype = 'css'

    def append(self, value):
        '''Append a style sheet to this media container.

        ``value`` can be a string or a dictionary with keys given by
        of the media and values, lists of style sheet paths.
        For example::

            {'all': [path1, ...],
             'print': [path2, ...]}
        '''
        if value is not None:
            if isinstance(value, Html):
                value = {'all': [value]}
            elif isinstance(value, str):
                value = {'all': [value]}
            for media, values in value.items():
                if isinstance(values, str):
                    values = (values,)
                m = self.children.get(media, [])
                for value in values:
                    if not isinstance(value, Html):
                        if not isinstance(value, (tuple, list)):
                            value = (value, None)
                        path, condition = value
                        path = self.absolute_path(path)
                        value = Html('link', href=path, type='text/css',
                                     rel='stylesheet')
                        if condition:
                            value = Html(None, '<!--[if %s]>', value,
                                         '<![endif]-->')
                    m.append(value)
                self.children[media] = m

    def do_stream(self, request):
        children = self.children
        for medium in sorted(children):
            paths = children[medium]
            medium = '' if medium == 'all' else medium
            for path in paths:
                if medium:
                    path.attr('media', medium)
                yield path


class Scripts(Media):
    '''A :class:`Media` container for javascript links.

    Supports javascript Asynchronous Module Definition
    '''
    mediatype = 'js'

    def __init__(self, *args, **kwargs):
        self.dependencies = kwargs.pop('dependencies', {})
        self.require_callback = kwargs.pop('require_callback', None)
        self.wait = kwargs.pop('wait', 200)
        self.required = []
        super(Scripts, self).__init__(*args, **kwargs)

    def require(self, *scripts):
        '''Add a ``script`` to the list of :attr:`required` scripts.

        The ``script`` can be a name in the :attr:`~Media.known_libraries`,
        an absolute uri or a relative url.

        The script will be loaded using the ``require`` javascript package.
        '''
        for script in scripts:
            if script not in self.known_libraries:
                script = self.absolute_path(script)
            required = self.required
            if script not in required:
                required.append(script)

    def append(self, child):
        '''add a new link to the javascript links.

        :param child: a ``string`` representing an absolute path to the script
            or relative path (does not start with ``http`` or ``/``), in which
            case the :attr:`Media.media_path` attribute is prepended.
        '''
        if child:
            if is_string(child):
                path = self.absolute_path(child)
                script = Html('script', src=path,
                              type='application/javascript')
                self.children[script] = script
                return script
            elif isinstance(child, Html) and child.tag == 'script':
                self.children[child] = child

    def require_script(self):
        '''Can be used for requirejs'''
        libs = dict(((key, self.absolute_path(key, False))
                     for key in self.known_libraries))
        return OrderedDict((('deps', self.required),
                            ('paths', libs),
                            ('shim', self.dependencies),
                            ('waitSeconds', self.wait)))

    def do_stream(self, request):
        if self.required:
            require = self.require_script()
            callback = self.require_callback or ''
            if callback:
                callback = ('\nrequire.callback = function () {%s();}'
                            % callback)
            yield '''\
<script type="text/javascript">
var require = %s,
    media_path = "%s";%s
</script>\n''' % (pyjson.dumps(require), self.media_path, callback)
        for child in self.children.values():
            for bit in child.stream(request):
                yield bit
            yield '\n'


class EmbeddedCss(Html):

    def append(self, child, media=None, type=None):
        type = type or 'text/css'
        child = Html('style', child, media=media, type=type or 'text/css')
        super(EmbeddedCss, self).append(child)


class Head(Html):
    ''':class:`HtmlDocument` ``head`` tag element.

    Contains :class:`Html` attributes for the various part of an HTML
    Head element. The head element is accessed via the
    :attr:`HtmlDocument.head` attribute.

    .. attribute:: title

        Text in the ``title`` tag.

    .. attribute:: meta

        A container of :class:`Html` ``meta`` tags.
        To add new meta tags use the
        :meth:`add_meta` method rather than accessing the :attr:`meta`
        attribute directly.

    .. attribute:: links

        A container of ``css`` links. Rendered just after the :attr:`meta`
        container.

    .. attribute:: embedded_css

        Css embedded in the html page

    .. attribute:: scripts

        A container of Javascript files to render at the end of the body tag.
        To add new javascript files simply use the append method on
        this attribute. You can add relative paths::

            html.head.scripts.append('/media/js/scripts.js')

        as well as absolute paths::

            html.head.scripts.append(
                'https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.js')

    '''
    def __init__(self, media_path=None, title=None, meta=None, minified=False,
                 known_libraries=None, scripts_dependencies=None,
                 require_callback=None, **params):
        super(Head, self).__init__('head', **params)
        self.title = title
        self.append(Html(None, meta))
        self.append(Css(media_path, minified=minified,
                        known_libraries=known_libraries))
        self.append(EmbeddedCss(None))
        self.append(Scripts(media_path, minified=minified,
                            known_libraries=known_libraries,
                            dependencies=scripts_dependencies,
                            require_callback=require_callback))
        self.add_meta(charset=self.charset)

    @property
    def meta(self):
        return self._children[0]

    def __get_links(self):
        return self._children[1]

    def __get_media_path(self):
        return self.links.media_path

    def __set_media_path(self, media_path):
        self.links.media_path = media_path
        self.scripts.media_path = media_path
    media_path = property(__get_media_path, __set_media_path)

    def __set_links(self, links):
        self._children[1] = links
    links = property(__get_links, __set_links)

    def __get_css(self):
        return self._children[2]

    def __set_css(self, css):
        self._children[2] = css
    embedded_css = property(__get_css, __set_css, doc='Embedded css rules.')

    def __get_scripts(self):
        return self._children[3]

    def __set_scripts(self, scripts):
        self._children[3] = scripts
    scripts = property(__get_scripts, __set_scripts)

    def do_stream(self, request):
        if self.title:
            self._children.insert(0, '<title>%s</title>' % self.title)
        return super(Head, self).do_stream(request)

    def add_meta(self, **kwargs):
        '''Add a new :class:`Html` meta tag to the :attr:`meta` collection.'''
        meta = Html('meta', **kwargs)
        self.meta.append(meta)

    def __add__(self, other):
        if isinstance(other, Media):
            return Media(media=self).add(other)
        else:
            return self


class HtmlDocument(Html):
    '''An :class:`.Html` component rendered as an HTML5_ document.

    An instance of this class can be obtained via the
    :attr:`.WsgiRequest.html_document` attribute.

    .. attribute:: head

        The :class:`Head` part of this :class:`HtmlDocument`

    .. attribute:: body

        The :class:`Body` part of this :class:`HtmlDocument`

    .. _HTML5: http://www.w3schools.com/html/html5_intro.asp
    '''
    _template = ('<!DOCTYPE html>\n'
                 '<html%s>\n'
                 '%s\n%s'
                 '\n</html>')

    def __init__(self, title=None, media_path='/media/', charset=None,
                 minified=False, known_libraries=None, require_callback=None,
                 scripts_dependencies=None, **params):
        super(HtmlDocument, self).__init__(None, **params)
        self.head = Head(title=title, media_path=media_path, minified=minified,
                         known_libraries=known_libraries,
                         require_callback=require_callback,
                         scripts_dependencies=scripts_dependencies,
                         charset=charset)
        self.body = Html('body')
        self.end = Html(None)

    def do_stream(self, request):
        # stream the body
        self.body.append(self.end)
        body = multi_async(self.body.stream(request))
        # the body has asynchronous components
        # delay the header untl later
        if not body.done():
            yield self._html(request, body)
        else:
            head = multi_async(self.head.stream(request))
            #
            # header not ready (this should never occur really)
            if not head.done():
                yield self._html(request, body, head)
            else:
                yield self._template % (self.flatatt(),
                                        self.head.to_string(head.result()),
                                        self.body.to_string(body.result()))

    def _html(self, request, body, head=None):
        if head is None:
            body = yield body
            head = multi_async(self.head.stream(request))
        head = yield head
        result = self._template % (self.flatatt(),
                                   self.head.to_string(head),
                                   self.body.to_string(body))
        coroutine_return(result)

########NEW FILE########
__FILENAME__ = handlers
'''
This section describes the asynchronous WSGI specification used by pulsar.
It is a superset of the `WSGI 1.0.1`_ specification for synchronous
server/middleware.
If an application handler is synchronous, this specification is exactly
equivalent to `WSGI 1.0.1`_. Changes with respect `WSGI 1.0.1`_
concern asynchronous responses and nothing else.

Introduction
========================

The WSGI interface has two sides: the ``server`` or ``gateway`` side, and the
``application`` or ``framework`` side. The server side invokes a callable
object, here referred as **application handler**, that is provided by the
application side.


.. note::

    A standard WSGI application handler is always a callable, either a function
    or a callable object, which accepts two positional arguments:
    ``environ`` and ``start_response``. When called by the server,
    the application object must return an iterable yielding zero or more bytes.


.. _wsgi-handlers:

Application handlers
=============================

An asynchronous :ref:`application handler <wsgi-handlers>` must conform
with the standard `WSGI 1.0.1`_ specification with the following two
exceptions:

* It can return a :class:`~asyncio.Future`.
* If it returns a :class:`~asyncio.Future`, it must results in an
  :ref:`asynchronous iterable <wsgi-async-iter>`.

Pulsar is shipped with two WSGI application handlers documented below.

.. _wsgi-async-iter:

Asynchronous Iterable
========================

An asynchronous iterable is an iterable over a combination of ``bytes`` or
:class:`~asyncio.Future` which result in ``bytes``.
For example this could be an asynchronous iterable::

    def simple_async():
        yield b'hello'
        c = Future()
        c.set_result(b' ')
        yield c
        yield b'World!'


.. _wsgi-lazy-handler:

WsgiHandler
======================

The first application handler is the :class:`WsgiHandler`
which is a step above the :ref:`hello callable <tutorials-hello-world>`
in the tutorial. It accepts two iterables, a list of
:ref:`wsgi middleware <wsgi-middleware>` and an optional list of
:ref:`response middleware <wsgi-response-middleware>`.

.. autoclass:: WsgiHandler
   :members:
   :member-order: bysource


.. _wsgi-handler:

Lazy Wsgi Handler
======================

.. autoclass:: LazyWsgi
   :members:
   :member-order: bysource


.. _wsgi-pulsar-variables:

Pulsar Variables
======================
Pulsar inject two server-defined variables into the WSGI environ:

* ``pulsar.connection``, the :class:`.Connection` serving the request
* ``pulsar.cfg``, the :class:`.Config` dictionary of the server

The event loop serving the application can be retrieved from the connection
via the ``_loop`` attribute::

    loop = environ['pulsar.connection']._loop

.. _WSGI: http://www.wsgi.org
.. _`WSGI 1.0.1`: http://www.python.org/dev/peps/pep-3333/
'''
import sys
import types

from pulsar import async, Http404, coroutine_return
from pulsar.utils.structures import OrderedDict
from pulsar.utils.log import LocalMixin, local_method

from .utils import handle_wsgi_error
from .wrappers import WsgiResponse


__all__ = ['WsgiHandler', 'LazyWsgi']


class WsgiHandler(object):
    '''An handler for application conforming to python WSGI_.

    .. attribute:: middleware

        List of :ref:`asynchronous WSGI middleware <wsgi-middleware>` callables
        which accept ``environ`` and ``start_response`` as arguments.
        The order matter, since the response returned by the callable
        is the non ``None`` value returned by a middleware.

    .. attribute:: response_middleware

        List of functions of the form::

            def ..(environ, response):
                ...

        where ``response`` is a :ref:`WsgiResponse <wsgi-response>`.
        Pulsar contains some
        :ref:`response middlewares <wsgi-response-middleware>`.

    '''
    def __init__(self, middleware=None, response_middleware=None, **kwargs):
        if middleware:
            middleware = list(middleware)
        self.middleware = middleware or []
        self.response_middleware = response_middleware or []

    def __call__(self, environ, start_response):
        '''The WSGI callable'''
        c = environ.get('pulsar.connection')
        loop = c._loop if c else None
        return async(self._call(environ, start_response), loop)

    def _call(self, environ, start_response):
        resp = None
        for middleware in self.middleware:
            try:
                resp = yield middleware(environ, start_response)
            except Exception as exc:
                resp = yield handle_wsgi_error(environ, exc)
            if resp is not None:
                break
        if resp is None:
            raise Http404
        if isinstance(resp, WsgiResponse):
            # The response is a WSGIResponse
            for middleware in self.response_middleware:
                resp = yield middleware(environ, resp)
            start_response(resp.status, resp.get_headers())
        coroutine_return(resp)


class LazyWsgi(LocalMixin):
    '''A :ref:`wsgi handler <wsgi-handlers>` which loads the actual
    handler the first time it is called.

    Subclasses must implement the :meth:`setup` method.
    Useful when working in multiprocessing mode when the application
    handler must be a ``picklable`` instance. This handler can rebuild
    its wsgi :attr:`handler` every time is pickled and un-pickled without
    causing serialisation issues.
    '''
    def __call__(self, environ, start_response):
        return self.handler(environ)(environ, start_response)

    @local_method
    def handler(self, environ=None):
        '''The :ref:`wsgi application handler <wsgi-handlers>` which
        is loaded via the :meth:`setup` method, once only,
        when first accessed.
        '''
        return self.setup(environ)

    def setup(self, environ=None):
        '''The setup function for this :class:`LazyWsgi`.

        Called once only the first time this application handler is invoked.
        This **must** be implemented by subclasses and **must** return a
        :ref:`wsgi application handler <wsgi-handlers>`.
        '''
        raise NotImplementedError

########NEW FILE########
__FILENAME__ = html
from collections import Mapping

from pulsar.utils.structures import recursive_update

HTML_VISITORS = {}


__all__ = ['HtmlVisitor']


def html_visitor(tag):
    return HTML_VISITORS.get(tag, base)


class HtmlType(type):

    def __new__(cls, name, bases, attrs):
        abstract = attrs.pop('abstract', False)
        new_class = super(HtmlType, cls).__new__(cls, name, bases, attrs)
        if not abstract:
            HTML_VISITORS[name.lower()] = new_class()
        return new_class


class HtmlVisitor(HtmlType('HtmlVisitorBase', (object,), {'abstract': True})):
    '''A visitor class for :class:`Html`.'''
    abstract = True

    def get_form_value(self, html):
        return html.attr('value')

    def set_form_value(self, html, value):
        html.attr('value', value)

    def add_data(self, html, key, value):
        if value is not None:
            data = html._data
            if key in data and isinstance(value, Mapping):
                target = data[key]
                if isinstance(target, Mapping):
                    return recursive_update(target, value)
            data[key] = value


base = HtmlVisitor()


class Textarea(HtmlVisitor):

    def get_form_value(self, html):
        return html.children[0] if html.children else ''

    def set_form_value(self, html, value):
        html.remove_all()
        html.append(value)


class Select(HtmlVisitor):

    def get_form_value(self, html):
        values = []
        for child in html.children:
            if child.attr('selected') == 'selected':
                values.append(child.attr('value'))
        if html.attr('multiple') == 'multiple':
            return values
        elif values:
            return values[0]

        return html.children[0] if html.children else ''

    def set_form_value(self, html, value):
        if html.attr('multiple') == 'multiple':
            for child in html.children:
                if child.attr('value') == value:
                    child.attr('selected', 'selected')
                    break
        else:
            for child in html.children:
                if child.attr('value') == value:
                    child.attr('selected', 'selected')
                else:
                    child._attr.pop('selected', None)

########NEW FILE########
__FILENAME__ = middleware
'''
A WSGI Middleware is a function or callable object similar to a
:ref:`WSGI application handlers <wsgi-handlers>`
with the only difference that it can return nothing (``None``).

Middleware can be used in conjunction with a
:ref:`WsgiHandler <wsgi-handler>` or any
other handler which iterate through a list of middleware in a similar
way (for example django wsgi handler).

.. important::

    An asynchronous WSGI middleware is a callble accepting a WSGI
    ``environ`` and ``start_response`` as the only input paramaters and
    it must returns an :ref:`asynchronous iterator <wsgi-async-iter>`
    or nothing.

The two most important wsgi middleware in pulsar are:

* the :ref:`Router <wsgi-router>` for serving dynamic web applications
* the :ref:`MediaRouter <wsgi-media-router>` for serving static files

In addition, pulsar provides with the following four middlewares which don't
serve requests, instead they perform initialisation and sanity checks.


.. _wsgi-additional-middleware:

Clean path
~~~~~~~~~~~~~~~~~~
.. autofunction:: clean_path_middleware


Authorization
~~~~~~~~~~~~~~~~~~
.. autofunction:: authorization_middleware


.. _wait-for-body-middleware:

Wait for request body
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
.. autofunction:: wait_for_body_middleware

'''
import re

import pulsar
from pulsar import Future, async, coroutine_return
from pulsar.utils.httpurl import BytesIO

from .auth import parse_authorization_header


__all__ = ['clean_path_middleware',
           'authorization_middleware',
           'wait_for_body_middleware']


def clean_path_middleware(environ, start_response=None):
    '''Clean url from double slashes and redirect if needed.'''
    path = environ['PATH_INFO']
    if path and '//' in path:
        url = re.sub("/+", '/', path)
        if not url.startswith('/'):
            url = '/%s' % url
        qs = environ['QUERY_STRING']
        if qs:
            url = '%s?%s' % (url, qs)
        raise pulsar.HttpRedirect(url)


def authorization_middleware(environ, start_response=None):
    '''Parse the ``HTTP_AUTHORIZATION`` key in the ``environ``.

    If available, set the ``http.authorization`` key in ``environ`` with
    the result obtained from
    :func:`pulsar.apps.wsgi.auth.parse_authorization_header` function.
    '''
    key = 'http.authorization'
    c = environ.get(key)
    if c is None:
        code = 'HTTP_AUTHORIZATION'
        if code in environ:
            environ[key] = parse_authorization_header(environ[code])


def wait_for_body_middleware(environ, start_response=None):
    '''Use this middleware to wait for the full body.

    This middleware wait for the full body to be received before letting
    other middleware to be processed.

    Useful when using synchronous web-frameworks.
    '''
    if environ['wsgi.input']:
        return async(_wait_for_body_middleware(environ, start_response))


def _wait_for_body_middleware(environ, start_response):
    stream = environ['wsgi.input']
    chunk = stream.read()
    if isinstance(chunk, Future):
        chunk = yield chunk
    environ['wsgi.input'] = BytesIO(chunk)
    coroutine_return(None)

########NEW FILE########
__FILENAME__ = response
'''
.. _wsgi-response-middleware:

Response middleware are callable objects which can be used in conjunction
with pulsar :ref:`WsgiHandler <wsgi-handler>`.
They must return a :ref:`WsgiResponse <wsgi-response>` which can be the
same as the one passed to the callable or a brand new one.

Interface
=================

.. autoclass:: ResponseMiddleware
   :members:
   :member-order: bysource

GZip Middleware
=================
.. autoclass:: GZipMiddleware
   :members:
   :member-order: bysource


AccessControl
=================
.. autoclass:: AccessControl
   :members:
   :member-order: bysource

'''
import re
from gzip import GzipFile

from pulsar.utils.httpurl import BytesIO


re_accepts_gzip = re.compile(r'\bgzip\b')


__all__ = ['AccessControl', 'GZipMiddleware']


class ResponseMiddleware(object):
    '''Base class for response middlewares.

    A response middleware is used by a :ref:`WsgiHandler <wsgi-handler>`,
    it is a callable used to manipulate a :ref:`WsgiResponse <wsgi-response>`.

    The focus of this class is the :meth:`execute` method where
    the middleware logic is implemented.
    '''
    def version(self, environ):
        return environ.get('wsgi.version')

    def available(self, environ, response):
        '''Check if this :class:`ResponseMiddleware` can be applied to
        the ``response`` object.

        :param environ: a WSGI environ dictionary.
        :param response: a :class:`pulsar.apps.wsgi.wrappers.WsgiResponse`
        :return: ``True`` or ``False``.
        '''
        return True

    def __call__(self, environ, response):
        if not self.available(environ, response):
            return response
        resp = self.execute(environ, response)
        return resp if resp is not None else response

    def execute(self, environ, response):
        '''Manipulate *response*, called only if the :meth:`available`
method returns ``True``.'''
        pass


class AccessControl(ResponseMiddleware):
    '''A response middleware which add the ``Access-Control-Allow-Origin``
    response header.
    '''
    def __init__(self, origin='*', methods=None):
        self.origin = origin
        self.methods = methods

    def available(self, environ, response):
        return response.status_code == 200

    def execute(self, environ, response):
        response.headers['Access-Control-Allow-Origin'] = self.origin
        if self.methods:
            response.headers['Access-Control-Allow-Methods'] = self.methods


class GZipMiddleware(ResponseMiddleware):
    """A :class:`ResponseMiddleware` for compressing content if the request
allows gzip compression. It sets the Vary header accordingly.

The compression implementation is from
http://jython.xhaus.com/http-compression-in-python-and-jython
    """
    def __init__(self, min_length=200):
        self.min_length = min_length

    def available(self, environ, response):
        # It's not worth compressing non-OK or really short responses
        try:
            if response.status_code == 200 and not response.is_streamed:
                if response.length() < self.min_length:
                    return False
                headers = response.headers
                # Avoid gzipping if we've already got a content-encoding.
                if 'Content-Encoding' in headers:
                    return False
                # MSIE have issues with gzipped response of various
                # content types.
                if "msie" in environ.get('HTTP_USER_AGENT', '').lower():
                    ctype = headers.get('Content-Type', '').lower()
                    if not ctype.startswith("text/") or "javascript" in ctype:
                        return False
                ae = environ.get('HTTP_ACCEPT_ENCODING', '')
                if not re_accepts_gzip.search(ae):
                    return False
                return True
        except Exception:
            raise

    def execute(self, environ, response):
        headers = response.headers
        headers.add_header('Vary', 'Accept-Encoding')
        content = b''.join(response.content)
        response.content = (self.compress_string(content),)
        response.headers['Content-Encoding'] = 'gzip'

    def compress_string(self, s):
        zbuf = BytesIO()
        zfile = GzipFile(mode='wb', compresslevel=6, fileobj=zbuf)
        zfile.write(s)
        zfile.close()
        return zbuf.getvalue()

########NEW FILE########
__FILENAME__ = route
'''Routing classes for matching and parsing urls.

.. note::

    The :mod:`pulsar.apps.wsgi.route` module was originally from the routing
    module in werkzeug_. Original License:

    copyright (c) 2011 by the Werkzeug Team. License BSD

.. _werkzeug: https://github.com/mitsuhiko/werkzeug

A :class:`Route` is a class for relative url paths::

    r1 = Route('bla')
    r2 = Route('bla/foo')

Integers::

    # accept any integer
    Route('<int:size>')
    # accept an integer between 1 and 200 only
    Route('<int(min=1,max=200):size>')


Paths::

    # accept any path (including slashes)
    Route('<path:pages>')
    # accept an integer between 1 and 200 only
    Route('<path:pages>/edit')



.. _wsgi-route-decorator:

Route decorator
==================

.. autoclass:: route
   :members:
   :member-order: bysource

.. _apps-wsgi-route:

Route
================

.. autoclass:: Route
   :members:
   :member-order: bysource

'''
import re
from collections import namedtuple

from pulsar import Http404
from pulsar.utils.httpurl import (iteritems, iri_to_uri, remove_double_slash,
                                  ENCODE_URL_METHODS, ENCODE_BODY_METHODS)
from pulsar.utils.pep import to_string


__all__ = ['route', 'Route']


class rule_info(namedtuple('rinfo', 'rule method parameters position order')):

    def override(self, parent):
        if self.position is None:
            return rule_info(self.rule, self.method, self.parameters,
                             parent.position, parent.order)
        else:
            return self


_rule_re = re.compile(r'''
    (?:
        (?P<converter>[a-zA-Z_][a-zA-Z0-9_]*)   # converter name
        (?:\((?P<args>.*?)\))?                  # converter parameters
        \:                                      # variable delimiter
    )?
    (?P<variable>[a-zA-Z_][a-zA-Z0-9_]*)        # variable name
''', re.VERBOSE)

_converter_args_re = re.compile(r'''
    ((?P<name>\w+)\s*=\s*)?
    (?P<value>
        True|False|
        \d+.\d+|
        \d+.|
        \d+|
        \w+|
        [urUR]?(?P<stringval>"[^"]*?"|'[^']*')
    )\s*,
''', re.VERBOSE | re.UNICODE)


_PYTHON_CONSTANTS = {
    'None':     None,
    'True':     True,
    'False':    False
}


def _pythonize(value):
    if value in _PYTHON_CONSTANTS:
        return _PYTHON_CONSTANTS[value]
    for convert in int, float:
        try:
            return convert(value)
        except ValueError:
            pass
    if value[:1] == value[-1:] and value[0] in '"\'':
        value = value[1:-1]
    return unicode(value)


def parse_rule(rule):
    """Parse a rule and return it as generator. Each iteration yields tuples
    in the form ``(converter, parameters, variable)``. If the converter is
    `None` it's a static url part, otherwise it's a dynamic one.

    :internal:
    """
    m = _rule_re.match(rule)
    if m is None or m.end() < len(rule):
        raise ValueError('Error while parsing rule {0}'.format(rule))
    data = m.groupdict()
    converter = data['converter'] or 'default'
    return converter, data['args'] or None, data['variable']


class route(object):
    '''Decorator to create a child route from a :class:`.Router` method.

    Typical usage::

        from pulsar.apps import wsgi

        class View(wsgi.Router):

            wsgi.route('/foo')
            def handle1(self, request):
                ...

            wsgi.route('/bla', method='post')
            def handle2(self, request):
                ...


    In this example, ``View`` is the **parent router**.

    The decorator injects the :attr:`rule_method` attribute to the
    method it decorates. The attribute is a four elements tuple
    contains the :class:`Route`, the HTTP ``method``, a
    dictionary of additional ``parameters`` and the ``position`` for ordering.

    Check the :ref:`HttpBin example <tutorials-httpbin>`
    for a sample usage.

    :param rule: Optional string for the relative url served by the method
        which is decorated. If not supplied, the method name is used.
    :param method: Optional HTTP method name. Default is `get`.
    :param defaults: Optional dictionary of default variable values used when
        initialising the :class:`Route` instance.
    :param position: Optional positioning of the router within the
        list of child routers of the parent router
    :param parameters: Additional parameters used when initialising
        the :class:`pulsar.apps.wsgi.handlers.Router` created by this
        decorator

    '''
    creation_count = 0

    def __init__(self, rule=None, method=None, defaults=None,
                 position=None, **parameters):
        self.__class__.creation_count += 1
        self.position = position
        self.creation_count = self.__class__.creation_count
        self.rule = rule
        self.defaults = defaults
        self.method = method
        self.parameters = parameters

    @property
    def order(self):
        return self.creation_count if self.position is None else self.position

    def __call__(self, callable):
        bits = callable.__name__.split('_')
        method = None
        if len(bits) > 1:
            m = bits[0].upper()
            if m in ENCODE_URL_METHODS or method in ENCODE_BODY_METHODS:
                method = m
                bits = bits[1:]
        method = (self.method or method or 'get').lower()
        rule = Route(self.rule or '_'.join(bits), defaults=self.defaults)
        callable.rule_method = rule_info(rule, method, self.parameters,
                                         self.position, self.order)
        return callable


class Route(object):
    '''A Route is a class with a relative :attr:`path`.

    :parameter rule: a normal URL path with ``placeholders`` in the
        format ``<converter(parameters):name>``
        where both the ``converter`` and the ``parameters`` are optional.
        If no ``converter`` is defined the `default` converter is used which
        means ``string``, ``name`` is the variable name.
    :parameter defaults: optional dictionary of default values for the rule
        variables.

    .. attribute:: is_leaf

        If ``True``, the route is equivalent to a file.
        For example ``/bla/foo``

    .. attribute:: rule

        The rule string, does not include the initial ``'/'``

    .. attribute:: path

        The full rule for this route including initial ``'/'``.

    .. attribute:: variables

        a set of  variable names for this route. If the route has no
        variables, the set is empty.

    .. _werkzeug: https://github.com/mitsuhiko/werkzeug
    '''
    def __init__(self, rule, defaults=None):
        rule = remove_double_slash('/%s' % rule)
        self.defaults = defaults if defaults is not None else {}
        self.is_leaf = not rule.endswith('/')
        self.rule = rule[1:]
        self.variables = set(map(str, self.defaults))
        breadcrumbs = []
        self._converters = {}
        regex_parts = []
        if self.rule:
            for bit in self.rule.split('/'):
                if not bit:
                    continue
                s = bit[0]
                e = bit[-1]
                if s == '<' or e == '>':
                    if s + e != '<>':
                        raise ValueError(
                            'malformed rule {0}'.format(self.rule))
                    converter, parameters, variable = parse_rule(bit[1:-1])
                    if variable in self._converters:
                        raise ValueError('variable name {0} used twice in '
                                         'rule {1}.'.format(variable,
                                                            self.rule))
                    convobj = get_converter(converter, parameters)
                    regex_parts.append('(?P<%s>%s)' % (variable,
                                                       convobj.regex))
                    breadcrumbs.append((True, variable))
                    self._converters[variable] = convobj
                    self.variables.add(str(variable))
                else:
                    variable = bit
                    regex_parts.append(re.escape(variable))
                    breadcrumbs.append((False, variable))

        self.breadcrumbs = tuple(breadcrumbs)
        self._regex_string = '/'.join(regex_parts)
        if self._regex_string and not self.is_leaf:
            self._regex_string += '/'
        self._regex = re.compile(self.regex, re.UNICODE)

    @property
    def level(self):
        return len(self.breadcrumbs)

    @property
    def path(self):
        return '/' + self.rule

    @property
    def regex(self):
        if self.is_leaf:
            return '^' + self._regex_string + '$'
        else:
            return '^' + self._regex_string

    @property
    def bits(self):
        return tuple((b[1] for b in self.breadcrumbs))

    def ordered_variables(self):
        return tuple((b for dyn, b in self.breadcrumbs if dyn))

    def __hash__(self):
        return hash(self.rule)

    def __repr__(self):
        return self.path

    def __eq__(self, other):
        if isinstance(other, self.__class__):
            return str(self) == str(other)
        else:
            return False

    def __lt__(self, other):
        if isinstance(other, self.__class__):
            return to_string(self) < to_string(other)
        else:
            raise TypeError('Cannot compare {0} with {1}'.format(self, other))

    def _url_generator(self, values):
        for is_dynamic, val in self.breadcrumbs:
            if is_dynamic:
                val = self._converters[val].to_url(values[val])
            yield val

    def url(self, **urlargs):
        '''Build a ``url`` from ``urlargs`` key-value parameters
        '''
        if self.defaults:
            d = self.defaults.copy()
            d.update(urlargs)
            urlargs = d
        url = '/'.join(self._url_generator(urlargs))
        if not url:
            return '/'
        else:
            url = '/' + url
            return url if self.is_leaf else url + '/'

    def safe_url(self, params=None):
        try:
            if params:
                return self.url(**params)
            else:
                return self.url()
        except KeyError:
            return None

    def match(self, path):
        '''Match a path and return ``None`` if no matching, otherwise
        a dictionary of matched variables with values. If there is more
        to be match in the path, the remaining string is placed in the
        ``__remaining__`` key of the dictionary.'''
        match = self._regex.search(path)
        if match is not None:
            remaining = path[match.end():]
            groups = match.groupdict()
            result = {}
            for name, value in iteritems(groups):
                try:
                    value = self._converters[name].to_python(value)
                except Http404:
                    return
                result[str(name)] = value
            if remaining:
                result['__remaining__'] = remaining
            return result

    def split(self):
        '''Return a two element tuple containing the parent route and
the last url bit as route. If this route is the root route, it returns
the root route and ``None``. '''
        rule = self.rule
        if not self.is_leaf:
            rule = rule[:-1]
        if not rule:
            return Route('/'), None
        bits = ('/'+rule).split('/')
        last = Route(bits[-1] if self.is_leaf else bits[-1] + '/')
        if len(bits) > 1:
            return Route('/'.join(bits[:-1]) + '/'), last
        else:
            return last, None

    def __add__(self, other):
        cls = self.__class__
        defaults = self.defaults.copy()
        if isinstance(other, cls):
            rule = other.rule
            defaults.update(other.defaults)
        else:
            rule = str(other)
        return cls('%s/%s' % (self.rule, rule), defaults)


class BaseConverter(object):
    """Base class for all converters."""
    regex = '[^/]+'
    weight = 100

    def to_python(self, value):
        return value

    def to_url(self, value):
        return iri_to_uri(value)


class StringConverter(BaseConverter):
    """This converter is the default converter and accepts any string but
    only one path segment.  Thus the string can not include a slash.

    This is the default validator.

    Example::

        Rule('/pages/<page>'),
        Rule('/<string(length=2):lang_code>')

    :param minlength: the minimum length of the string.  Must be greater
                      or equal 1.
    :param maxlength: the maximum length of the string.
    :param length: the exact length of the string.
    """

    def __init__(self, minlength=1, maxlength=None, length=None):
        if length is not None:
            length = '{%d}' % int(length)
        else:
            if maxlength is None:
                maxlength = ''
            else:
                maxlength = int(maxlength)
            length = '{%s,%s}' % (
                int(minlength),
                maxlength
            )
        self.regex = '[^/]' + length


class AnyConverter(BaseConverter):
    """Matches one of the items provided.  Items can either be Python
    identifiers or strings::

        Rule('/<any(about, help, imprint, class, "foo,bar"):page_name>')

    :param items: this function accepts the possible items as positional
                  parameters.
    """

    def __init__(self, *items):
        self.regex = '(?:%s)' % '|'.join([re.escape(x) for x in items])


class PathConverter(BaseConverter):
    """Like the default :class:`StringConverter`, but it also matches
    slashes.  This is useful for wikis and similar applications::

        Rule('/<path:wikipage>')
        Rule('/<path:wikipage>/edit')
    """
    regex = '[^/].*?'
    regex = '.*'
    weight = 200


class NumberConverter(BaseConverter):
    """Baseclass for `IntegerConverter` and `FloatConverter`.

    :internal:
    """
    weight = 1

    def __init__(self, fixed_digits=0, min=None, max=None):
        self.fixed_digits = fixed_digits
        self.min = min
        self.max = max

    def to_python(self, value):
        if (self.fixed_digits and len(value) != self.fixed_digits):
            raise Http404()
        value = self.num_convert(value)
        if (self.min is not None and value < self.min) or \
           (self.max is not None and value > self.max):
            raise Http404()
        return value

    def to_url(self, value):
        if (self.fixed_digits and len(str(value)) > self.fixed_digits):
            raise ValueError()
        value = self.num_convert(value)
        if (self.min is not None and value < self.min) or \
           (self.max is not None and value > self.max):
            raise ValueError()
        if self.fixed_digits:
            value = ('%%0%sd' % self.fixed_digits) % value
        return str(value)


class IntegerConverter(NumberConverter):
    """This converter only accepts integer values::

        Rule('/page/<int:page>')

    This converter does not support negative values.

    :param fixed_digits: the number of fixed digits in the URL.  If you set
                         this to ``4`` for example, the application will
                         only match if the url looks like ``/0001/``.  The
                         default is variable length.
    :param min: the minimal value.
    :param max: the maximal value.
    """
    regex = r'\d+'
    num_convert = int


class FloatConverter(NumberConverter):
    """This converter only accepts floating point values::

        Rule('/probability/<float:probability>')

    This converter does not support negative values.

    :param min: the minimal value.
    :param max: the maximal value.
    """
    regex = r'\d+\.\d+'
    num_convert = float

    def __init__(self, min=None, max=None):
        super(FloatConverter, self).__init__(0, min, max)


def parse_converter_args(argstr):
    argstr += ','
    args = []
    kwargs = {}

    for item in _converter_args_re.finditer(argstr):
        value = item.group('stringval')
        if value is None:
            value = item.group('value')
        value = _pythonize(value)
        if not item.group('name'):
            args.append(value)
        else:
            name = item.group('name')
            kwargs[name] = value

    return tuple(args), kwargs


def get_converter(name, parameters):
    c = _CONVERTERS.get(name)
    if not c:
        raise LookupError('Route converter {0} not available'.format(name))
    if parameters:
        args, kwargs = parse_converter_args(parameters)
        return c(*args, **kwargs)
    else:
        return c()


#: the default converter mapping for the map.
_CONVERTERS = {
    'default':          StringConverter,
    'string':           StringConverter,
    'any':              AnyConverter,
    'path':             PathConverter,
    'int':              IntegerConverter,
    'float':            FloatConverter
}

########NEW FILE########
__FILENAME__ = routers
'''
Routing is the process of matching and parsing a URL to something we can use.
Pulsar provides a flexible integrated
routing system you can use for that. It works by creating a
:class:`Router` instance with its own ``rule`` and, optionally, additional
sub-routers for handling additional urls::

    class Page(Router):
        response_content_types = RouterParam(('text/html',
                                              'text/plain',
                                              'application/json'))

        def get(self, request):
            "This method handle request with get-method"
            ...

        def post(self, request):
            "This method handle request with post-method"
            ...

    middleware = Page('/bla')


.. _wsgi-router:

Router
=====================

The :ref:`middleware <wsgi-middleware>` constructed in the snippet above
handles ``get`` and ``post`` methods at the ``/bla`` url.
The :class:`Router` introduces a new element into pulsar WSGI handlers, the
:ref:`wsgi request <app-wsgi-request>`, a light-weight wrapper of the
WSGI environ.

For an exaustive example on how to use the :class:`Router` middleware make sure
you check out the :ref:`HttpBin example <tutorials-httpbin>`.

.. autoclass:: Router
   :members:
   :member-order: bysource


.. _wsgi-media-router:

Media Router
=====================

The :class:`MediaRouter` is a specialised :class:`Router` for serving static
files such ass ``css``, ``javascript``, images and so forth.

.. autoclass:: MediaRouter
   :members:
   :member-order: bysource


RouterParam
=================

.. autoclass:: RouterParam
   :members:
   :member-order: bysource

.. _WSGI: http://www.wsgi.org
'''
import os
import re
import stat
import mimetypes
from email.utils import parsedate_tz, mktime_tz

from pulsar.utils.httpurl import http_date, CacheControl
from pulsar.utils.structures import AttributeDictionary, OrderedDict
from pulsar import (Http404, PermissionDenied, HttpException, HttpRedirect,
                    multi_async)

from .route import Route
from .utils import wsgi_request
from .content import Html
from .structures import ContentAccept

__all__ = ['Router', 'MediaRouter', 'FileRouter', 'MediaMixin',
           'RouterParam']


def get_roule_methods(attrs):
    rule_methods = []
    for code, callable in attrs:
        if code.startswith('__') or not hasattr(callable, '__call__'):
            continue
        rule_method = getattr(callable, 'rule_method', None)
        if isinstance(rule_method, tuple):
            rule_methods.append((code, rule_method))
    return sorted(rule_methods, key=lambda x: x[1].order)


def update_args(urlargs, args):
    if urlargs:
        urlargs.update(args)
        return urlargs
    return args


class RouterParam(object):
    '''A :class:`RouterParam` is a way to flag a :class:`Router` parameter
so that children can retrieve the value if they don't define their own.

A :class:`RouterParam` is always defined as a class attribute and it
is processed by the :class:`Router` metaclass and stored in a dictionary
available as ``parameter`` class attribute.

.. attribute:: value

    The value associated with this :class:`RouterParam`. THis is the value
    stored in the :class:`Router.parameters` dictionary at key given by
    the class attribute specified in the class definition.
'''
    def __init__(self, value):
        self.value = value


class RouterType(type):
    ''':class:`Router` metaclass.'''
    def __new__(cls, name, bases, attrs):
        rule_methods = get_roule_methods(attrs.items())
        parameters = {}
        for key, value in list(attrs.items()):
            if isinstance(value, RouterParam):
                parameters[key] = attrs.pop(key).value
        no_rule = set(attrs) - set((x[0] for x in rule_methods))
        base_rules = []
        for base in reversed(bases):
            if hasattr(base, 'parameters'):
                params = base.parameters.copy()
                params.update(parameters)
                parameters = params
            if hasattr(base, 'rule_methods'):
                items = base.rule_methods.items()
            else:
                g = ((key, getattr(base, key)) for key in dir(base))
                items = get_roule_methods(g)
            rules = [pair for pair in items if pair[0] not in no_rule]
            base_rules = base_rules + rules

        if base_rules:
            all = base_rules + rule_methods
            rule_methods = {}
            for name, rule in all:
                if name in rule_methods:
                    rule = rule.override(rule_methods[name])
                rule_methods[name] = rule
            rule_methods = sorted(rule_methods.items(),
                                  key=lambda x: x[1].order)
        attrs['rule_methods'] = OrderedDict(rule_methods)
        attrs['parameters'] = parameters
        return super(RouterType, cls).__new__(cls, name, bases, attrs)


class Router(RouterType('RouterBase', (object,), {})):
    '''A :ref:`WSGI middleware <wsgi-middleware>` to handle client requests
    on multiple :ref:`routes <apps-wsgi-route>`.

    The user must implement the HTTP methods
    required by the application. For example if the route needs to
    serve a ``GET`` request, the ``get(self, request)`` method must
    be implemented.

    :param rule: String used for creating the :attr:`route` of this
        :class:`Router`.
    :param routes: Optional :class:`Router` instances which are added to the
        children :attr:`routes` of this router.
    :param parameters: Optional parameters for this router.
        They are stored in the :attr:`parameters` attribute.
        If a ``response_content_types`` value is
        passed, it overrides the :attr:`response_content_types` attribute.

    .. attribute:: routes

        List of children :class:`Router` of this :class:`Router`.

    .. attribute:: parent

        The parent :class:`Router` of this :class:`Router`.

    .. attribute:: response_content_types

        a list/tuple of possible content types of a response to a
        client request.

        The client request must accept at least one of the response content
        types, otherwise an HTTP ``415`` exception occurs.

    .. attribute:: allows_redirects

        boolean indicating if this router can redirect requests to valid urls
        within this router and its children. For example, if a router serves
        the '/echo' url but not the ``/echo/`` one, a request on ``/echo/``
        will be redirected to ``/echo``.

        Default: ``False``

    .. attribute:: parameters

        A :class:`.AttributeDictionary` of parameters for
        this :class:`Router`. Parameters are created at initialisation from
        the ``parameters`` class attribute and the key-valued parameters
        passed to the ``__init__`` method for which the value is not callable.
    '''
    _creation_count = 0
    _parent = None
    _name = None

    response_content_types = RouterParam(None)
    allows_redirects = RouterParam(False)

    def __init__(self, rule, *routes, **parameters):
        Router._creation_count += 1
        self._creation_count = Router._creation_count
        if not isinstance(rule, Route):
            rule = Route(rule)
        self._route = rule
        self._name = parameters.pop('name', rule.rule)
        self.routes = []
        # add routes specified via the initialiser
        for router in routes:
            self.add_child(router)
        # copy parameters
        self.parameters = AttributeDictionary(self.parameters)
        for name, rule_method in self.rule_methods.items():
            rule, method, params, _, _ = rule_method
            rparameters = params.copy()
            handler = getattr(self, name)
            router = self.add_child(Router(rule, **rparameters))
            setattr(router, method, handler)
        for name, value in parameters.items():
            if name in self.parameters:
                self.parameters[name] = value
            else:
                setattr(self, name, value)

    @property
    def route(self):
        '''The relative :class:`.Route` served by this
        :class:`Router`.
        '''
        parent = self._parent
        if parent and parent._route.is_leaf:
            return parent.route + self._route
        else:
            return self._route

    @property
    def full_route(self):
        '''The full :attr:`route` for this :class:`.Router`.

        It includes the :attr:`parent` portion of the route if a parent
        router is available.
        '''
        if self._parent:
            return self._parent.full_route + self._route
        else:
            return self._route

    @property
    def name(self):
        '''The name of this :class:`Router`.

        This attribute can be specified during initialisation.
        If available, it can be used to retrieve a child router
        by name via the :meth:`get_route` method.
        '''
        return self._name

    @property
    def root(self):
        '''The root :class:`Router` for this :class:`Router`.'''
        if self.parent:
            return self.parent.root
        else:
            return self

    @property
    def parent(self):
        return self._parent

    @property
    def default_content_type(self):
        '''The default content type for responses.

        This is the first element in the :attr:`response_content_types` list.
        '''
        ct = self.response_content_types
        return ct[0] if ct else None

    @property
    def creation_count(self):
        '''Integer for sorting :class:`Router` by creation.

        Auto-generated during initialisation.'''
        return self._creation_count

    @property
    def rule(self):
        '''The full ``rule`` string for this :class:`Router`.

        It includes the :attr:`parent` portion of the rule if a :attr:`parent`
        router is available.
        '''
        return self.full_route.rule

    def path(self, **urlargs):
        '''The full path of this :class:`Router`.

        It includes the :attr:`parent` portion of url if a parent router
        is available.
        '''
        return self.full_route.url(**urlargs)

    def __getattr__(self, name):
        '''Check the value of a :attr:`parameters` ``name``.

        If the parameter is not available, retrieve the parameter from the
        :attr:`parent` :class:`Router` if it exists.
        '''
        if not name.startswith('_'):
            return self.get_parameter(name, False)
        self.no_param(name)

    def get_parameter(self, name, safe=True):
        value = self.parameters.get(name)
        if value is None:
            if self._parent:
                return self._parent.get_parameter(name, safe)
            elif name in self.parameters:
                return value
            elif not safe:
                self.no_param(name)
        else:
            return value

    def no_param(self, name):
        raise AttributeError("'%s' object has no attribute '%s'" %
                             (self.__class__.__name__, name))

    def content_type(self, request):
        '''Evaluate the content type for the response to a client ``request``.

        The method uses the :attr:`response_content_types` parameter of
        accepted content types and the content types accepted by the client
        and figure out the best match.
        '''
        return request.content_types.best_match(self.response_content_types)

    def accept_content_type(self, content_type):
        '''Check if ``content_type`` is accepted by this :class:`Router`.

        Return the best mach or ``None`` if not accepted.'''
        response_content_types = self.response_content_types
        if response_content_types:
            return ContentAccept(
                [(content_type, 1)]).best_match(response_content_types)

    def __repr__(self):
        return self.route.__repr__()

    def __call__(self, environ, start_response=None):
        path = environ.get('PATH_INFO') or '/'
        path = path[1:]
        router_args = self.resolve(path)
        if router_args:
            router, args = router_args
            return router.response(environ, args)
        elif self.allows_redirects:
            if self.route.is_leaf:
                if path.endswith('/'):
                    router_args = self.resolve(path[:-1])
                    if router_args is not None:
                        return self.redirect(environ, '/%s' % path[:-1])
            else:
                if not path.endswith('/'):
                    router_args = self.resolve('%s/' % path)
                    if router_args is not None:
                        return self.redirect(environ, '/%s/' % path)

    def resolve(self, path, urlargs=None):
        '''Resolve a path and return a ``(handler, urlargs)`` tuple or
        ``None`` if the path could not be resolved.
        '''
        match = self.route.match(path)
        if match is None:
            if not self.route.is_leaf:  # no match
                return
        elif '__remaining__' in match:
            path = match.pop('__remaining__')
            urlargs = update_args(urlargs, match)
        else:
            return self, update_args(urlargs, match)
        #
        for handler in self.routes:
            view_args = handler.resolve(path, urlargs)
            if view_args is None:
                continue
            return view_args

    def response(self, environ, args):
        '''Once the :meth:`resolve` method has matched the correct
        :class:`Router` for serving the request, this matched router invokes
        this method to produce the WSGI response.
        '''
        request = wsgi_request(environ, self, args)
        # Set the response content type
        request.response.content_type = self.content_type(request)
        method = request.method.lower()
        callable = getattr(self, method, None)
        if callable is None:
            raise HttpException(status=405,
                                msg='Method "%s" not allowed' % method)
        return callable(request)

    def redirect(self, environ, path):
        raise HttpRedirect(path)

    def add_child(self, router):
        '''Add a new :class:`Router` to the :attr:`routes` list.
        '''
        assert isinstance(router, Router), 'Not a valid Router'
        assert router is not self, 'cannot add self to children'
        # Loop over available routers to check it the router
        # is already available
        for r in self.routes:
            if r.route == router.route:
                r.parameters.update(router.parameters)
                return r
        if router.parent:
            router.parent.remove_child(router)
        router._parent = self
        self.routes.append(router)
        return router

    def remove_child(self, router):
        '''remove a :class:`Router` from the :attr:`routes` list.'''
        if router in self.routes:
            self.routes.remove(router)
            router._parent = None

    def get_route(self, name):
        '''Get a child :class:`Router` by its :attr:`name`.'''
        for route in self.routes:
            if route.name == name:
                return route

    def link(self, *args, **urlargs):
        '''Return an anchor :class:`Html` element with the `href` attribute
        set to the url of this :class:`Router`.'''
        if len(args) > 1:
            raise ValueError
        url = self.route.url(**urlargs)
        if len(args) == 1:
            text = args[0]
        else:
            text = url
        return Html('a', text, href=url)

    def sitemap(self, root=None):
        '''This utility method returns a sitemap starting at root.

        If *root* is ``None`` it starts from this :class:`Router`.

        :param request: a :ref:`wsgi request wrapper <app-wsgi-request>`
        :param root: Optional url path where to start the sitemap.
            By default it starts from this :class:`Router`. Pass `"/"` to
            start from the root :class:`Router`.
        :param levels: Number of nested levels to include.
        :return: A list of children
        '''
        if not root:
            root = self
        else:
            handler_urlargs = self.root.resolve(root[1:])
            if handler_urlargs:
                root, urlargs = handler_urlargs
            else:
                return []
        return list(self.routes)

    def encoding(self, request):
        '''The encoding to use for the response.

        By default it returns ``utf-8``.'''
        return 'utf-8'


class MediaMixin(Router):
    response_content_types = RouterParam(('application/octet-stream',
                                          'text/css',
                                          'application/javascript',
                                          'text/html'))
    cache_control = CacheControl(maxage=86400)
    _file_path = ''

    def serve_file(self, request, fullpath, status_code=None):
        # Respect the If-Modified-Since header.
        statobj = os.stat(fullpath)
        content_type, encoding = mimetypes.guess_type(fullpath)
        response = request.response
        if content_type:
            response.content_type = content_type
        response.encoding = encoding
        if not (status_code or self.was_modified_since(
                request.environ.get('HTTP_IF_MODIFIED_SINCE'),
                statobj[stat.ST_MTIME],
                statobj[stat.ST_SIZE])):
            response.status_code = 304
        else:
            response.content = open(fullpath, 'rb').read()
            if status_code:
                response.status_code = status_code
            else:
                response.headers["Last-Modified"] = http_date(
                    statobj[stat.ST_MTIME])
        return response

    def was_modified_since(self, header=None, mtime=0, size=0):
        '''Check if an item was modified since the user last downloaded it

        :param header: the value of the ``If-Modified-Since`` header.
            If this is ``None``, simply return ``True``
        :param mtime: the modification time of the item in question.
        :param size: the size of the item.
        '''
        try:
            if header is None:
                raise ValueError
            matches = re.match(r"^([^;]+)(; length=([0-9]+))?$", header,
                               re.IGNORECASE)
            header_mtime = mktime_tz(parsedate_tz(matches.group(1)))
            header_len = matches.group(3)
            if header_len and int(header_len) != size:
                raise ValueError()
            if mtime > header_mtime:
                raise ValueError()
        except (AttributeError, ValueError, OverflowError):
            return True
        return False

    def directory_index(self, request, fullpath):
        names = [Html('a', '../', href='../', cn='folder')]
        files = []
        for f in sorted(os.listdir(fullpath)):
            if not f.startswith('.'):
                if os.path.isdir(os.path.join(fullpath, f)):
                    names.append(Html('a', f, href=f+'/', cn='folder'))
                else:
                    files.append(Html('a', f, href=f))
        names.extend(files)
        return self.static_index(request, names)

    def html_title(self, request):
        return 'Index of %s' % request.path

    def static_index(self, request, links):
        doc = request.html_document
        doc.title = 'Index of %s' % request.path
        title = Html('h2', doc.title)
        list = Html('ul', *[Html('li', a) for a in links])
        doc.body.append(Html('div', title, list))
        return doc.http_response(request)


class MediaRouter(MediaMixin):
    '''A :class:`Router` for serving static media files from a given
    directory.

    :param rute: The top-level url for this router. For example ``/media``
        will serve the ``/media/<path:path>`` :class:`Route`.
    :param path: Check the :attr:`path` attribute.
    :param show_indexes: Check the :attr:`show_indexes` attribute.

    .. attribute::    path

        The file-system path of the media files to serve.

    .. attribute::    show_indexes

        If ``True``, the router will serve media file directories as
        well as media files.

    .. attribute:: default_file

        The default file to serve when a directory is requested.
    '''
    def __init__(self, rute, path, show_indexes=False, mapping=None,
                 default_suffix=None, default_file='index.html',
                 raise_404=True):
        rute = '%s/<path:path>' % rute
        if rute.startswith('/'):
            rute = rute[1:]
        super(MediaRouter, self).__init__(rute)
        self._mapping = mapping or {}
        self._default_suffix = default_suffix
        self._default_file = default_file
        self._show_indexes = show_indexes
        self._file_path = path
        self._raise_404 = raise_404

    def filesystem_path(self, request):
        path = request.urlargs['path']
        bits = [bit for bit in path.split('/') if bit]
        return os.path.join(self._file_path, *bits)

    def get(self, request):
        fullpath = self.filesystem_path(request)
        if os.path.isdir(fullpath) and self._default_file:
            file = os.path.join(fullpath, self._default_file)
            if os.path.isfile(file):
                fullpath = file
        #
        if os.path.isdir(fullpath):
            if self._show_indexes:
                return self.directory_index(request, fullpath)
            else:
                raise PermissionDenied
        #
        filename = os.path.basename(fullpath)
        if '.' not in filename and self._default_suffix:
            fullpath = '%s.%s' % (fullpath, self._default_suffix)
        #
        if os.path.isfile(fullpath):
            return self.serve_file(request, fullpath)
        elif self._raise_404:
            raise Http404


class FileRouter(MediaMixin):
    '''A Router for a single file.'''
    def __init__(self, route, file_path, status_code=None, raise_404=True):
        super(FileRouter, self).__init__(route)
        self._status_code = status_code
        self._file_path = file_path
        self._raise_404 = raise_404

    def filesystem_path(self, request):
        return self._file_path

    def get(self, request):
        fullpath = self.filesystem_path(request)
        if os.path.isfile(fullpath):
            return self.serve_file(request, fullpath,
                                   status_code=self._status_code)
        elif self._raise_404:
            raise Http404

########NEW FILE########
__FILENAME__ = server
'''
HTTP Protocol Consumer
==============================

.. autoclass:: HttpServerResponse
   :members:
   :member-order: bysource


Testing WSGI Environ
=========================

.. autofunction:: test_wsgi_environ
'''
import sys
import time
import os
import socket
from wsgiref.handlers import format_date_time

import pulsar
from pulsar import HttpException, ProtocolError, Future, in_loop, chain_future
from pulsar.utils.pep import is_string, native_str, reraise
from pulsar.utils.httpurl import (Headers, unquote, has_empty_content,
                                  host_and_port_default, http_parser,
                                  urlparse, iri_to_uri, DEFAULT_CHARSET)

from pulsar.utils.internet import format_address, is_tls
from pulsar.async.protocols import ProtocolConsumer

from .utils import handle_wsgi_error, wsgi_request, HOP_HEADERS


__all__ = ['HttpServerResponse', 'MAX_CHUNK_SIZE', 'test_wsgi_environ']


MAX_CHUNK_SIZE = 65536


class FakeConnection(object):

    def __init__(self, loop=None):
        self._loop = loop


def test_wsgi_environ(path='/', method=None, headers=None, extra=None,
                      secure=False, loop=None):
    '''An function to create a WSGI environment dictionary for testing.

    :param url: the resource in the ``PATH_INFO``.
    :param method: the ``REQUEST_METHOD``.
    :param headers: optional request headers
    :params secure: a secure connection?
    :param extra: additional dictionary of parameters to add.
    :return: a valid WSGI environ dictionary.
    '''
    parser = http_parser(kind=0)
    method = (method or 'GET').upper()
    path = iri_to_uri(path)
    data = '%s %s HTTP/1.1\r\n\r\n' % (method, path)
    data = data.encode('latin1')
    parser.execute(data, len(data))
    request_headers = Headers(headers, kind='client')
    headers = Headers()
    stream = StreamReader(request_headers, parser)
    extra = extra or {}
    extra['pulsar.connection'] = FakeConnection(loop=loop)
    return wsgi_environ(stream, ('127.0.0.1', 8060), '777.777.777.777:8080',
                        headers, https=secure, extra=extra)


class StreamReader:
    _expect_sent = None
    _waiting = None

    def __init__(self, headers, parser, transport=None):
        self.headers = headers
        self.parser = parser
        self.transport = transport
        self.buffer = b''
        self.on_message_complete = Future()

    def __repr__(self):
        return repr(self.transport)
    __str__ = __repr__

    def done(self):
        '''``True`` when the full HTTP message has been read.
        '''
        return self.on_message_complete.done()

    def protocol(self):
        version = self.parser.get_version()
        return "HTTP/%s" % ".".join(('%s' % v for v in version))

    def waiting_expect(self):
        '''``True`` when the client is waiting for 100 Continue.
        '''
        if self._expect_sent is None:
            if (not self.parser.is_message_complete() and
                    self.headers.has('expect', '100-continue')):
                return True
            self._expect_sent = ''
        return False

    def recv(self):
        '''Read bytes in the buffer.
        '''
        if self.waiting_expect():
            if self.parser.get_version() < (1, 1):
                raise HttpException(status=417)
            else:
                msg = '%s 100 Continue\r\n\r\n' % self.protocol()
                self._expect_sent = msg
                self.transport.write(msg.encode(DEFAULT_CHARSET))
        return self.parser.recv_body()

    def read(self, maxbuf=None):
        '''Return bytes in the buffer.

        If the stream is not yet ready, return a :class:`asyncio.Future`
        which results in the bytes read.
        '''
        if not self._waiting:
            body = self.recv()
            if self.done():
                return self._getvalue(body, maxbuf)
            else:
                self._waiting = chain_future(
                    self.on_message_complete,
                    lambda r: self._getvalue(body, maxbuf))
                return self._waiting
        else:
            return self._waiting

    def fail(self):
        if self.waiting_expect():
            raise HttpException(status=417)

    #    INTERNALS
    def _getvalue(self, body, maxbuf):
        if self.buffer:
            body = self.buffer + body
        body = body + self.recv()
        if maxbuf and len(body) > maxbuf:
            body, self.buffer = body[:maxbuf], body[maxbuf:]
        return body


def wsgi_environ(stream, address, client_address, headers,
                 server_software=None, https=False, extra=None):
    protocol = stream.protocol()
    parser = stream.parser
    request_headers = stream.headers
    raw_uri = parser.get_url()
    request_uri = urlparse(raw_uri)
    #
    # http://www.w3.org/Protocols/rfc2616/rfc2616-sec5.html#sec5.2
    # If Request-URI is an absoluteURI, the host is part of the Request-URI.
    # Any Host header field value in the request MUST be ignored
    if request_uri.scheme:
        url_scheme = request_uri.scheme
        host = request_uri.netloc
    else:
        url_scheme = 'https' if https else 'http'
        host = None
    #
    environ = {"wsgi.input": stream,
               "wsgi.errors": sys.stderr,
               "wsgi.version": (1, 0),
               "wsgi.run_once": False,
               "wsgi.multithread": False,
               "wsgi.multiprocess": False,
               "SERVER_SOFTWARE": server_software or pulsar.SERVER_SOFTWARE,
               "REQUEST_METHOD": native_str(parser.get_method()),
               "QUERY_STRING": parser.get_query_string(),
               "RAW_URI": raw_uri,
               "SERVER_PROTOCOL": protocol,
               "CONTENT_TYPE": ''}
    forward = client_address
    script_name = os.environ.get("SCRIPT_NAME", "")
    for header, value in request_headers:
        header = header.lower()
        if header in HOP_HEADERS:
            headers[header] = value
        if header == 'x-forwarded-for':
            forward = value
        elif header == "x-forwarded-protocol" and value == "ssl":
            url_scheme = "https"
        elif header == "x-forwarded-ssl" and value == "on":
            url_scheme = "https"
        elif header == "host" and not host:
            host = value
        elif header == "script_name":
            script_name = value
        elif header == "content-type":
            environ['CONTENT_TYPE'] = value
            continue
        elif header == "content-length":
            environ['CONTENT_LENGTH'] = value
            continue
        key = 'HTTP_' + header.upper().replace('-', '_')
        environ[key] = value
    environ['wsgi.url_scheme'] = url_scheme
    if url_scheme == 'https':
        environ['HTTPS'] = 'on'
    if is_string(forward):
        # we only took the last one
        # http://en.wikipedia.org/wiki/X-Forwarded-For
        if forward.find(",") >= 0:
            forward = forward.rsplit(",", 1)[1].strip()
        remote = forward.split(":")
        if len(remote) < 2:
            remote.append('80')
    else:
        remote = forward
    environ['REMOTE_ADDR'] = remote[0]
    environ['REMOTE_PORT'] = str(remote[1])
    if not host and protocol == 'HTTP/1.0':
        host = format_address(address)
    if host:
        host = host_and_port_default(url_scheme, host)
        environ['SERVER_NAME'] = socket.getfqdn(host[0])
        environ['SERVER_PORT'] = host[1]
    path_info = parser.get_path()
    if path_info is not None:
        if script_name:
            path_info = path_info.split(script_name, 1)[1]
        environ['PATH_INFO'] = unquote(path_info)
    environ['SCRIPT_NAME'] = script_name
    if extra:
        environ.update(extra)
    return environ


def chunk_encoding(chunk):
    '''Write a chunk::

    chunk-size(hex) CRLF
    chunk-data CRLF

If the size is 0, this is the last chunk, and an extra CRLF is appended.
'''
    head = ("%X\r\n" % len(chunk)).encode('utf-8')
    return head + chunk + b'\r\n'


def keep_alive(headers, version):
        """ return True if the connection should be kept alive"""
        conn = set((v.lower() for v in headers.get_all('connection', ())))
        if "close" in conn:
            return False
        elif 'upgrade' in conn:
            headers['connection'] = 'upgrade'
            return True
        elif "keep-alive" in conn:
            return True
        elif version == (1, 1):
            headers['connection'] = 'keep-alive'
            return True
        else:
            return False


def keep_alive_with_status(status, headers):
    code = int(status.split()[0])
    if code >= 400:
        return False
    return True


class HttpServerResponse(ProtocolConsumer):
    '''Server side WSGI :class:`.ProtocolConsumer`.

    .. attribute:: wsgi_callable

        The wsgi callable handling requests.
    '''
    _status = None
    _headers_sent = None
    _stream = None
    _buffer = None
    SERVER_SOFTWARE = pulsar.SERVER_SOFTWARE
    ONE_TIME_EVENTS = ProtocolConsumer.ONE_TIME_EVENTS + ('on_headers',)

    def __init__(self, wsgi_callable, cfg, server_software=None):
        super(HttpServerResponse, self).__init__()
        self.wsgi_callable = wsgi_callable
        self.cfg = cfg
        self.parser = http_parser(kind=0)
        self.headers = Headers()
        self.keep_alive = False
        self.SERVER_SOFTWARE = server_software or self.SERVER_SOFTWARE

    def data_received(self, data):
        '''Implements :meth:`~.ProtocolConsumer.data_received` method.

        Once we have a full HTTP message, build the wsgi ``environ`` and
        delegate the response to the :func:`wsgi_callable` function.
        '''
        parser = self.parser
        processed = parser.execute(data, len(data))
        if not self._stream and parser.is_headers_complete():
            headers = Headers(parser.get_headers(), kind='client')
            self._stream = StreamReader(headers, parser, self.transport)
            self._response(self.wsgi_environ())
        #
        done = parser.is_message_complete()
        if done and not self._stream.on_message_complete.done():
            self._stream.on_message_complete.set_result(None)
        #
        if processed < len(data):
            if not done:
                # This is a parsing error, the client must have sent
                # bogus data
                raise ProtocolError
            else:
                if not self._buffer:
                    self._buffer = data[processed:]
                    self.bind_event('post_request', self._new_request)
                else:
                    self._buffer += data[processed:]

    @property
    def status(self):
        return self._status

    @property
    def upgrade(self):
        return self.headers.get('upgrade')

    @property
    def chunked(self):
        return self.headers.get('Transfer-Encoding') == 'chunked'

    @property
    def content_length(self):
        c = self.headers.get('Content-Length')
        if c:
            return int(c)

    @property
    def version(self):
        return self.parser.get_version()

    def start_response(self, status, response_headers, exc_info=None):
        '''WSGI compliant ``start_response`` callable, see pep3333_.

        The application may call start_response more than once, if and only
        if the ``exc_info`` argument is provided.
        More precisely, it is a fatal error to call ``start_response`` without
        the ``exc_info`` argument if start_response has already been called
        within the current invocation of the application.

        :parameter status: an HTTP ``status`` string like ``200 OK`` or
            ``404 Not Found``.
        :parameter response_headers: a list of ``(header_name, header_value)``
            tuples. It must be a Python list. Each header_name must be a valid
            HTTP header field-name (as defined by RFC 2616_, Section 4.2),
            without a trailing colon or other punctuation.
        :parameter exc_info: optional python ``sys.exc_info()`` tuple.
            This argument should be supplied by the application only if
            ``start_response`` is being called by an error handler.
        :return: The :meth:`write` method.

        ``HOP_HEADERS`` are not considered but no error is raised.

        .. _pep3333: http://www.python.org/dev/peps/pep-3333/
        .. _2616: http://www.faqs.org/rfcs/rfc2616.html
        '''
        if exc_info:
            try:
                if self._headers_sent:
                    # if exc_info is provided, and the HTTP headers have
                    # already been sent, start_response must raise an error,
                    # and should re-raise using the exc_info tuple
                    reraise(*exc_info)
            finally:
                # Avoid circular reference
                exc_info = None
        elif self._status:
            # Headers already set. Raise error
            raise HttpException("Response headers already set!")
        self._status = status
        if type(response_headers) is not list:
            raise TypeError("Headers must be a list of name/value tuples")
        for header, value in response_headers:
            if header.lower() in HOP_HEADERS:
                # These features are the exclusive province of this class,
                # this should be considered a fatal error for an application
                # to attempt sending them, but we don't raise an error,
                # just log a warning
                self.logger.warning('Application passing hop header "%s"',
                                    header)
                continue
            self.headers.add_header(header, value)
        return self.write

    def write(self, data, force=False):
        '''The write function returned by the :meth:`start_response` method.

        Required by the WSGI specification.

        :param data: bytes to write
        :param force: Optional flag used internally.
        '''
        if not self._headers_sent:
            tosend = self.get_headers()
            self._headers_sent = tosend.flat(self.version, self.status)
            self.fire_event('on_headers')
            self.transport.write(self._headers_sent)
        if data:
            if self.chunked:
                chunks = []
                while len(data) >= MAX_CHUNK_SIZE:
                    chunk, data = data[:MAX_CHUNK_SIZE], data[MAX_CHUNK_SIZE:]
                    chunks.append(chunk_encoding(chunk))
                if data:
                    chunks.append(chunk_encoding(data))
                self.transport.write(b''.join(chunks))
            else:
                self.transport.write(data)
        elif force and self.chunked:
            self.transport.write(chunk_encoding(data))

    ########################################################################
    #    INTERNALS
    @in_loop
    def _response(self, environ):
        exc_info = None
        response = None
        done = False
        while not done:
            done = True
            try:
                if exc_info is None:
                    if 'SERVER_NAME' not in environ:
                        raise HttpException(status=400)
                    response = self.wsgi_callable(environ, self.start_response)
                else:
                    response = handle_wsgi_error(environ, exc_info)
                #
                if isinstance(response, Future):
                    response = yield response
                #
                if exc_info:
                    self.start_response(response.status,
                                        response.get_headers(), exc_info)
                #
                for chunk in response:
                    if isinstance(chunk, Future):
                        chunk = yield chunk
                    self.write(chunk)
                #
                # make sure we write headers
                self.write(b'', True)

            except IOError:     # client disconnected, end this connection
                self.finished()
            except Exception as exc:
                if wsgi_request(environ).cache.handle_wsgi_error:
                    self.keep_alive = False
                    self.connection.close()
                    self.finished()
                else:
                    done = False
                    exc_info = sys.exc_info()
            else:
                if not self.keep_alive:
                    self.connection.close()
                self.finished()
            finally:
                if hasattr(response, 'close'):
                    try:
                        response.close()
                    except Exception:
                        self.logger.exception(
                            'Error while closing wsgi iterator')

    def is_chunked(self):
        '''Check if the response uses chunked transfer encoding.

        Only use chunked responses when the client is speaking HTTP/1.1
        or newer and there was no Content-Length header set.
        '''
        if (self.version <= (1, 0) or
                self._status == '200 Connection established' or
                has_empty_content(int(self.status[:3]))):
            return False
        elif self.headers.get('Transfer-Encoding') == 'chunked':
            return True
        else:
            return self.content_length is None

    def get_headers(self):
        '''Get the headers to send to the client.
        '''
        if not self._status:
            # we are sending headers but the start_response was not called
            raise HttpException('Headers not set.')
        headers = self.headers
        # Set chunked header if needed
        if self.is_chunked():
            headers['Transfer-Encoding'] = 'chunked'
            headers.pop('content-length', None)
        else:
            headers.pop('Transfer-Encoding', None)
        if self.keep_alive:
            self.keep_alive = keep_alive_with_status(self._status, headers)
        if not self.keep_alive:
            headers['connection'] = 'close'
        return headers

    def wsgi_environ(self):
        # return a the WSGI environ dictionary
        transport = self.transport
        https = True if is_tls(transport.get_extra_info('socket')) else False
        multiprocess = (self.cfg.concurrency == 'process')
        environ = wsgi_environ(self._stream,
                               transport.get_extra_info('sockname'),
                               self.address, self.headers,
                               self.SERVER_SOFTWARE,
                               https=https,
                               extra={'pulsar.connection': self.connection,
                                      'pulsar.cfg': self.cfg,
                                      'wsgi.multiprocess': multiprocess})
        self.keep_alive = keep_alive(self.headers, self.parser.get_version())
        self.headers.update([('Server', self.SERVER_SOFTWARE),
                             ('Date', format_date_time(time.time()))])
        return environ

    def _new_request(self, response):
        connection = response._connection
        if not connection.closed:
            connection.data_received(response._buffer)
            return connection._current_consumer
        return response

########NEW FILE########
__FILENAME__ = structures
import re
import codecs

from pulsar.utils.pep import ispy3k
from pulsar.utils.structures import FrozenDict

string_type = str if ispy3k else basestring
_locale_delim_re = re.compile(r'[_-]')


def order(values):
    same = {}
    for v, q in values:
        if q not in same:
            same[q] = []
        same[q].append(v)
    for q in reversed(sorted(same)):
        for v in same[q]:
            yield v, q


class Accept(tuple):
    """An :class:`Accept` object is a tuple subclass for tuples of
    ``(value, quality)`` tuples.  It is automatically sorted by quality.

    All :class:`Accept` objects work similar to a list but provide extra
    functionality for working with the data.  Containment checks are
    normalised to the rules of that header:

    >>> a = CharsetAccept([('ISO-8859-1', 1), ('utf-8', 0.7)])
    >>> a.best
    'ISO-8859-1'
    >>> 'iso-8859-1' in a
    True
    >>> 'UTF8' in a
    True
    >>> 'utf7' in a
    False

    To get the quality for an item you can use normal item lookup:

    >>> print(a['utf-8'])
    0.7
    >>> a(['utf7'])
    0
    """
    def __new__(cls, values=None):
        values = order(values) if values else ()
        return super(Accept, cls).__new__(cls, values)

    def _value_matches(self, value, item):
        """Check if a value matches a given accept item."""
        return item == '*' or item.lower() == value.lower()

    def quality(self, key):
        """Returns the quality of the key.

        .. versionadded:: 0.6
           In previous versions you had to use the item-lookup syntax
           (eg: ``obj[key]`` instead of ``obj.quality(key)``)
        """
        for item, quality in self:
            if self._value_matches(key, item):
                return quality
        return 0

    def __contains__(self, value):
        for item, quality in self:
            if self._value_matches(value, item):
                return True
        return False

    def __repr__(self):
        return '%s([%s])' % (
            self.__class__.__name__,
            ', '.join('(%r, %s)' % (x, y) for x, y in self)
        )

    def index(self, key):
        """Get the position of an entry or raise :exc:`ValueError`.

        :param key: The key to be looked up.

        .. versionchanged:: 0.5
           This used to raise :exc:`IndexError`, which was inconsistent
           with the list API.
        """
        if isinstance(key, string_type):
            for idx, (item, quality) in enumerate(self):
                if self._value_matches(key, item):
                    return idx
            raise ValueError(key)
        return list.index(self, key)

    def find(self, key):
        """Get the position of an entry or return -1.

        :param key: The key to be looked up.
        """
        try:
            return self.index(key)
        except ValueError:
            return -1

    def values(self):
        """Return a list of the values, not the qualities."""
        return list(self.itervalues())

    def itervalues(self):
        """Iterate over all values."""
        for item in self:
            yield item[0]

    def to_header(self):
        """Convert the header set into an HTTP header string."""
        result = []
        for value, quality in self:
            if quality != 1:
                value = '%s;q=%s' % (value, quality)
            result.append(value)
        return ','.join(result)

    def __str__(self):
        return self.to_header()

    def best_match(self, matches, default=None):
        """Returns the best match from a list of possible matches based
        on the quality of the client.  If two items have the same quality,
        the one is returned that comes first.

        :param matches: a list of matches to check for
        :param default: the value that is returned if none match
        """
        if matches:
            best_quality = -1
            result = default
            for server_item in matches:
                for client_item, quality in self:
                    if quality <= best_quality:
                        break
                    if self._value_matches(server_item, client_item):
                        best_quality = quality
                        result = server_item
            return result
        else:
            return self.best

    @property
    def best(self):
        """The best match as value."""
        if self:
            return self[0][0]


class ContentAccept(Accept):
    """Like :class:`Accept` but with special methods and behaviour for
    content types.
    """

    def _value_matches(self, value, item):
        def _normalize(x):
            x = x.lower()
            return x == '*' and ('*', '*') or x.split('/', 1)

        # this is from the application which is trusted.  to avoid developer
        # frustration we actually check these for valid values
        if '/' not in value:
            raise ValueError('invalid mimetype %r' % value)
        value_type, value_subtype = _normalize(value)
        if value_type == '*' and value_subtype != '*':
            raise ValueError('invalid mimetype %r' % value)

        if '/' not in item:
            return False
        item_type, item_subtype = _normalize(item)
        if item_type == '*' and item_subtype != '*':
            return False
        return (
            (item_type == item_subtype == '*' or
             value_type == value_subtype == '*') or
            (item_type == value_type and (item_subtype == '*' or
                                          value_subtype == '*' or
                                          item_subtype == value_subtype))
        )

    @property
    def accept_html(self):
        """True if this object accepts HTML."""
        return (
            'text/html' in self or
            'application/xhtml+xml' in self or
            self.accept_xhtml
        )

    @property
    def accept_xhtml(self):
        """True if this object accepts XHTML."""
        return (
            'application/xhtml+xml' in self or
            'application/xml' in self
        )

    @property
    def accept_json(self):
        """True if this object accepts JSON."""
        return 'application/json' in self


class LanguageAccept(Accept):
    """Like :class:`Accept` but with normalisation for languages."""

    def _value_matches(self, value, item):
        def _normalize(language):
            return _locale_delim_re.split(language.lower())
        return item == '*' or _normalize(value) == _normalize(item)


class CharsetAccept(Accept):
    """Like :class:`Accept` but with normalisation for charsets."""

    def _value_matches(self, value, item):
        def _normalize(name):
            try:
                return codecs.lookup(name).name
            except LookupError:
                return name.lower()
        return item == '*' or _normalize(value) == _normalize(item)


class RequestCacheControl(FrozenDict):
    pass

########NEW FILE########
__FILENAME__ = utils
'''
The :mod:`pulsar.apps.wsgi.utils` module include several utilities used
by various components in the :ref:`wsgi application <apps-wsgi>`
'''
import time
import re
import textwrap
import logging
from datetime import datetime, timedelta
from email.utils import formatdate


from pulsar import format_traceback
from pulsar.utils.system import json
from pulsar.utils.structures import MultiValueDict
from pulsar.utils.html import escape
from pulsar.utils.pep import to_string
from pulsar.utils.httpurl import (has_empty_content, REDIRECT_CODES, iteritems,
                                  parse_qsl, HTTPError, parse_dict_header,
                                  JSON_CONTENT_TYPES)

from .structures import Accept, RequestCacheControl
from .content import Html

__all__ = ['handle_wsgi_error',
           'render_error_debug',
           'wsgi_request',
           'set_wsgi_request_class',
           'HOP_HEADERS']

DEFAULT_RESPONSE_CONTENT_TYPES = ('text/html', 'text/plain'
                                  ) + JSON_CONTENT_TYPES
HOP_HEADERS = frozenset(('connection',
                         'keep-alive',
                         'proxy-authenticate',
                         'proxy-authorization',
                         'te',
                         'trailers',
                         'transfer-encoding',
                         'upgrade')
                        )

logger = logging.getLogger('pulsar.wsgi')
error_css = '''
.pulsar-error {
    width: 500px;
    margin: 50px auto;
}
'''

_RequestClass = None


def wsgi_request(environ, app_handler=None, urlargs=None):
    global _RequestClass
    return _RequestClass(environ, app_handler=app_handler, urlargs=urlargs)


def set_wsgi_request_class(RequestClass):
    global _RequestClass
    _RequestClass = RequestClass


def cookie_date(epoch_seconds=None):
    """Formats the time to ensure compatibility with Netscape's cookie
    standard.

    Accepts a floating point number expressed in seconds since the epoch in, a
    datetime object or a timetuple.  All times in UTC.  The :func:`parse_date`
    function can be used to parse such a date.

    Outputs a string in the format ``Wdy, DD-Mon-YYYY HH:MM:SS GMT``.

    :param expires: If provided that date is used, otherwise the current.
    """
    rfcdate = formatdate(epoch_seconds)
    return '%s-%s-%s GMT' % (rfcdate[:7], rfcdate[8:11], rfcdate[12:25])


def set_cookie(cookies, key, value='', max_age=None, expires=None, path='/',
               domain=None, secure=False, httponly=False):
    '''Set a cookie key into the cookies dictionary *cookies*.'''
    cookies[key] = value
    if expires is not None:
        if isinstance(expires, datetime):
            delta = expires - expires.utcnow()
            # Add one second so the date matches exactly (a fraction of
            # time gets lost between converting to a timedelta and
            # then the date string).
            delta = delta + timedelta(seconds=1)
            # Just set max_age - the max_age logic will set expires.
            expires = None
            max_age = max(0, delta.days * 86400 + delta.seconds)
        else:
            cookies[key]['expires'] = expires
    if max_age is not None:
        cookies[key]['max-age'] = max_age
        # IE requires expires, so set it if hasn't been already.
        if not expires:
            cookies[key]['expires'] = cookie_date(time.time() + max_age)
    if path is not None:
        cookies[key]['path'] = path
    if domain is not None:
        cookies[key]['domain'] = domain
    if secure:
        cookies[key]['secure'] = True
    if httponly:
        cookies[key]['httponly'] = True


_accept_re = re.compile(r'([^\s;,]+)(?:[^,]*?;\s*q=(\d*(?:\.\d+)?))?')


def parse_accept_header(value, cls=None):
    """Parses an HTTP Accept-* header.  This does not implement a complete
    valid algorithm but one that supports at least value and quality
    extraction.

    Returns a new :class:`Accept` object (basically a list of
    ``(value, quality)`` tuples sorted by the quality with some additional
    accessor methods).

    The second parameter can be a subclass of :class:`Accept` that is created
    with the parsed values and returned.

    :param value: the accept header string to be parsed.
    :param cls: the wrapper class for the return value (can be
                         :class:`Accept` or a subclass thereof)
    :return: an instance of `cls`.
    """
    if cls is None:
        cls = Accept
    if not value:
        return cls(None)
    result = []
    for match in _accept_re.finditer(value):
        quality = match.group(2)
        if not quality:
            quality = 1
        else:
            quality = max(min(float(quality), 1), 0)
        result.append((match.group(1), quality))
    return cls(result)


def parse_cache_control_header(value, on_update=None, cls=None):
    """Parse a cache control header.  The RFC differs between response and
    request cache control, this method does not.  It's your responsibility
    to not use the wrong control statements.

    :param value: a cache control header to be parsed.
    :param on_update: an optional callable that is called every time a value
                      on the :class:`~werkzeug.datastructures.CacheControl`
                      object is changed.
    :param cls: the class for the returned object.  By default
                :class:`pulsar.apps.wsgi.structures.RequestCacheControl` is
                used.
    :return: a `cls` object.
    """
    if cls is None:
        cls = RequestCacheControl
    if not value:
        return cls(None, on_update)
    return cls(parse_dict_header(value), on_update)


def _gen_query(query_string, encoding):
    # keep_blank_values=True
    for key, value in parse_qsl((query_string or ''), True):
        yield (to_string(key, encoding, errors='replace'),
               to_string(value, encoding, errors='replace'))


def query_dict(query_string, encoding='utf-8'):
    if query_string:
        return dict(MultiValueDict(_gen_query(query_string, encoding)).items())
    else:
        return {}


error_messages = {
    500: 'An exception has occurred while evaluating your request.',
    404: 'Cannot find what you are looking for.'
}


class dump_environ(object):
    __slots__ = ('environ',)

    def __init__(self, environ):
        self.environ = environ

    def __str__(self):
        def _():
            for k, v in iteritems(self.environ):
                try:
                    v = str(v)
                except Exception as e:
                    v = str(e)
                yield '%s=%s' % (k, v)
        return '\n%s\n' % '\n'.join(_())


def handle_wsgi_error(environ, exc):
    '''The default error handler while serving a WSGI request.

    :param environ: The WSGI environment.
    :param exc: the exception
    :return: a :class:`.WsgiResponse`
    '''
    if isinstance(exc, tuple):
        exc_info = exc
        exc = exc[1]
    else:
        exc_info = True
    request = wsgi_request(environ)
    request.cache.handle_wsgi_error = True
    response = request.response
    if isinstance(exc, HTTPError):
        response.status_code = exc.code or 500
    else:
        response.status_code = getattr(exc, 'status', 500)
        response.headers.update(getattr(exc, 'headers', None) or ())
    path = '@ %s "%s"' % (request.method, request.path)
    status = response.status_code
    if status == 500:
        logger.critical('Unhandled exception during HTTP response %s.%s',
                        path, dump_environ(environ), exc_info=exc_info)
    else:
        logger.warning('HTTP %s %s', response.status, path)
    if has_empty_content(status, request.method) or status in REDIRECT_CODES:
        response.content_type = None
        response.content = None
    else:
        request.cache.pop('html_document', None)
        renderer = environ.get('error.handler') or render_error
        try:
            content = renderer(request, exc)
        except Exception:
            logger.critical('Error while rendering error', exc_info=True)
            response.content_type = 'text/plain'
            content = 'Critical server error'
        response.content = content
    return response


def render_error(request, exc):
    '''Default renderer for errors.'''
    cfg = request.get('pulsar.cfg')
    debug = cfg.debug if cfg else False
    response = request.response
    if not response.content_type:
        response.content_type = request.content_types.best_match(
            DEFAULT_RESPONSE_CONTENT_TYPES)
    content_type = None
    if response.content_type:
        content_type = response.content_type.split(';')[0]

    if content_type == 'text/html':
        request.html_document.head.title = response.status

    if debug:
        msg = render_error_debug(request, exc, content_type)
    else:
        msg = error_messages.get(response.status_code) or ''
        if content_type == 'text/html':
            msg = textwrap.dedent("""
                <h1>{0[reason]}</h1>
                {0[msg]}
                <h3>{0[version]}</h3>
            """).format({"reason": response.status, "msg": msg,
                         "version": request.environ['SERVER_SOFTWARE']})
    #
    if content_type == 'text/html':
        doc = request.html_document
        doc.head.embedded_css.append(error_css)
        doc.body.append(Html('div', msg, cn='pulsar-error'))
        return doc.render(request)
    elif content_type in JSON_CONTENT_TYPES:
        return json.dumps({'status': response.status_code,
                           'message': msg})
    else:
        return '\n'.join(msg) if isinstance(msg, (list, tuple)) else msg


def render_error_debug(request, exc, content_type):
    '''Render the traceback into the content type in *response*.'''
    response = request.response
    is_html = content_type == 'text/html'
    error = Html('div', cn='section traceback error') if is_html else []
    trace = format_traceback(exc)
    for trace in format_traceback(exc):
        counter = 0
        for line in trace.split('\n'):
            if line.startswith('  '):
                counter += 1
                line = line[2:]
            if line:
                if is_html:
                    line = Html('p', escape(line))
                    if counter:
                        line.css({'margin-left': '%spx' % (20*counter)})
                error.append(line)
    return error

########NEW FILE########
__FILENAME__ = wrappers
'''This section introduces two classes used by pulsar
:ref:`wsgi application <apps-wsgi>` to pass a request/response state
during an HTTP request.
The :class:`WsgiRequest` is a thin wrapper around a WSGI ``environ``
dictionary.
It contains only the ``environ`` as its private data.
The :class:`WsgiResponse`, which is available in the
:class:`WsgiRequest.response` attribute, is an iterable over bytestring with
several utility methods for manipulating headers and asynchronous content.


Environ Mixin
=====================

.. autoclass:: EnvironMixin
   :members:
   :member-order: bysource


.. _app-wsgi-request:

Wsgi Request
=====================

.. autoclass:: WsgiRequest
   :members:
   :member-order: bysource


.. _wsgi-response:

Wsgi Response
=====================

.. autoclass:: WsgiResponse
   :members:
   :member-order: bysource

.. _WSGI: http://www.wsgi.org
.. _AJAX: http://en.wikipedia.org/wiki/Ajax_(programming)
.. _TLS: http://en.wikipedia.org/wiki/Transport_Layer_Security
'''
import re
from functools import reduce
from io import BytesIO

from pulsar import Future, coroutine_return
from pulsar.utils.system import json
from pulsar.utils.multipart import parse_form_data, parse_options_header
from pulsar.utils.structures import AttributeDictionary
from pulsar.utils.httpurl import (Headers, SimpleCookie, responses,
                                  has_empty_content, ispy3k,
                                  ENCODE_URL_METHODS, JSON_CONTENT_TYPES,
                                  remove_double_slash, iri_to_uri)

from .content import HtmlDocument
from .utils import (set_wsgi_request_class, set_cookie, query_dict,
                    parse_accept_header)
from .structures import ContentAccept, CharsetAccept, LanguageAccept


__all__ = ['EnvironMixin', 'WsgiResponse',
           'WsgiRequest', 'cached_property']

MAX_BUFFER_SIZE = 2**16
absolute_http_url_re = re.compile(r"^https?://", re.I)


def cached_property(f):
    name = f.__name__

    def _(self):
        if name not in self.cache:
            self.cache[name] = f(self)
        return self.cache[name]
    return property(_, doc=f.__doc__)


def wsgi_encoder(gen, encoding):
    for data in gen:
        if not isinstance(data, bytes):
            yield data.encode(encoding)
        else:
            yield data


class WsgiResponse(object):
    '''A WSGI response.

    Instances are callable using the standard WSGI call and, importantly,
    iterable::

        response = WsgiResponse(200)

    A :class:`WsgiResponse` is an iterable over bytes to send back to the
    requesting client.

    .. attribute:: status_code

        Integer indicating the HTTP status, (i.e. 200)

    .. attribute:: response

        String indicating the HTTP status (i.e. 'OK')

    .. attribute:: status

        String indicating the HTTP status code and response (i.e. '200 OK')

    .. attribute:: content_type

        The content type of this response. Can be ``None``.

    .. attribute:: headers

        The :class:`.Headers` container for this response.

    .. attribute:: environ

        The dictionary of WSGI environment if passed to the constructor.

    .. attribute:: cookies

        A python :class:`SimpleCookie` container of cookies included in the
        request as well as cookies set during the response.
    '''
    _started = False
    DEFAULT_STATUS_CODE = 200

    def __init__(self, status=None, content=None, response_headers=None,
                 content_type=None, encoding=None, environ=None,
                 can_store_cookies=True):
        self.environ = environ
        self.status_code = status or self.DEFAULT_STATUS_CODE
        self.encoding = encoding
        self.cookies = SimpleCookie()
        self.headers = Headers(response_headers, kind='server')
        self.content = content
        self._can_store_cookies = can_store_cookies
        if content_type is not None:
            self.content_type = content_type
        if environ:
            cookie = environ.get('HTTP_COOKIE')
            if cookie:
                self.cookies.load(cookie)

    @property
    def started(self):
        return self._started

    @property
    def path(self):
        if self.environ:
            return self.environ.get('PATH_INFO', '')

    @property
    def method(self):
        if self.environ:
            return self.environ.get('REQUEST_METHOD')

    @property
    def connection(self):
        if self.environ:
            return self.environ.get('pulsar.connection')

    @property
    def environ_cache(self):
        if self.environ:
            return self.environ.get('pulsar.cache')

    def _get_content(self):
        return self._content

    def _set_content(self, content):
        if not self._started:
            if content is None:
                content = ()
            elif ispy3k:
                if isinstance(content, str):
                    if not self.encoding:   # use utf-8 if not set
                        self.encoding = 'utf-8'
                    content = content.encode(self.encoding)
            else:   # pragma    nocover
                if isinstance(content, unicode):
                    if not self.encoding:  # use utf-8 if not set
                        self.encoding = 'utf-8'
                    content = content.encode(self.encoding)
            if isinstance(content, bytes):
                content = (content,)
            self._content = content
        else:
            raise RuntimeError('Cannot set content. Already iterated')
    content = property(_get_content, _set_content)

    def _get_content_type(self):
        return self.headers.get('content-type')

    def _set_content_type(self, typ):
        if typ:
            self.headers['content-type'] = typ
        else:
            self.headers.pop('content-type', None)
    content_type = property(_get_content_type, _set_content_type)

    @property
    def response(self):
        return responses.get(self.status_code)

    @property
    def status(self):
        return '%s %s' % (self.status_code, self.response)

    def __str__(self):
        return self.status

    def __repr__(self):
        return '%s(%s)' % (self.__class__.__name__, self)

    @property
    def is_streamed(self):
        '''Check if the response is streamed.

        A streamed response is an iterable with no length information.
        In this case streamed means that there is no information about
        the number of iterations.

        This is usually `True` if a generator is passed to the response object.
        '''
        try:
            len(self.content)
        except TypeError:
            return True
        return False

    def can_set_cookies(self):
        if self.status_code < 400:
            return self._can_store_cookies

    def length(self):
        if not self.is_streamed:
            return reduce(lambda x, y: x+len(y), self.content, 0)

    def __iter__(self):
        if self._started:
            raise RuntimeError('WsgiResponse can be iterated once only')
        self._started = True
        if self.is_streamed:
            return wsgi_encoder(self.content, self.encoding or 'utf-8')
        else:
            return iter(self.content)

    def __len__(self):
        return len(self.content)

    def close(self):
        if self.is_streamed:
            self.content.close()

    def set_cookie(self, key, **kwargs):
        """
        Sets a cookie.

        ``expires`` can be a string in the correct format or a
        ``datetime.datetime`` object in UTC. If ``expires`` is a datetime
        object then ``max_age`` will be calculated.
        """
        set_cookie(self.cookies, key, **kwargs)

    def delete_cookie(self, key, path='/', domain=None):
        set_cookie(self.cookies, key, max_age=0, path=path, domain=domain,
                   expires='Thu, 01-Jan-1970 00:00:00 GMT')

    def get_headers(self):
        '''The list of headers for this response
        '''
        headers = self.headers
        if has_empty_content(self.status_code, self.method):
            headers.pop('content-type', None)
            headers.pop('content-length', None)
            self._content = ()
        else:
            if not self.is_streamed:
                cl = 0
                for c in self.content:
                    cl += len(c)
                if cl == 0 and self.content_type in JSON_CONTENT_TYPES:
                    self._content = (b'{}',)
                    cl = len(self._content[0])
                headers['Content-Length'] = str(cl)
            ct = self.content_type
            # content type encoding available
            if self.encoding:
                ct = ct or 'text/plain'
                if 'charset=' not in ct:
                    ct = '%s; charset=%s' % (ct, self.encoding)
            if ct:
                headers['Content-Type'] = ct
        if self.can_set_cookies():
            for c in self.cookies.values():
                headers.add_header('Set-Cookie', c.OutputString())
        return list(headers)

    def has_header(self, header):
        return header in self.headers
    __contains__ = has_header

    def __setitem__(self, header, value):
        self.headers[header] = value

    def __getitem__(self, header):
        return self.headers[header]


class EnvironMixin(object):
    '''A wrapper around a WSGI_ environ.

    Instances of this class have the :attr:`environ` attribute as their
    only private data. Every other attribute is stored in the :attr:`environ`
    itself at the ``pulsar.cache`` wsgi-extension key.

    .. attribute:: environ

        WSGI_ environ dictionary
    '''
    __slots__ = ('environ',)

    def __init__(self, environ, name=None):
        self.environ = environ
        if 'pulsar.cache' not in environ:
            environ['pulsar.cache'] = AttributeDictionary()
            self.cache.mixins = {}
        if name:
            self.cache.mixins[name] = self

    @property
    def cache(self):
        '''An :ref:`attribute dictionary <attribute-dictionary>` of
pulsar-specific data stored in the :attr:`environ` at the wsgi-extension
key ``pulsar.cache``.'''
        return self.environ['pulsar.cache']

    @property
    def connection(self):
        '''The :class:`.Connection` handling the request
        '''
        return self.environ.get('pulsar.connection')

    @property
    def _loop(self):
        '''Event loop if :attr:`connection` is available.
        '''
        c = self.connection
        if c:
            return c._loop

    def __getattr__(self, name):
        mixin = self.cache.mixins.get(name)
        if mixin is None:
            raise AttributeError("'%s' object has no attribute '%s'" %
                                 (self.__class__.__name__, name))
        return mixin

    def get(self, key, default=None):
        '''Shortcut to the :attr:`environ` get method.'''
        return self.environ.get(key, default)


class WsgiRequest(EnvironMixin):
    '''An :class:`EnvironMixin` for wsgi requests.'''
    def __init__(self, environ, app_handler=None, urlargs=None):
        super(WsgiRequest, self).__init__(environ)
        self.cache.cfg = environ.get('pulsar.cfg', {})
        if app_handler:
            self.cache.app_handler = app_handler
            self.cache.urlargs = urlargs

    def __repr__(self):
        return self.path

    def __str__(self):
        return self.__repr__()

    @cached_property
    def content_types(self):
        '''List of content types this client supports as a
        :class:`.ContentAccept` object.

        Obtained form the ``Accept`` request header.
        '''
        return parse_accept_header(self.environ.get('HTTP_ACCEPT'),
                                   ContentAccept)

    @cached_property
    def charsets(self):
        '''List of charsets this client supports as a
        :class:`.CharsetAccept` object.

        Obtained form the ``Accept-Charset`` request header.
        '''
        return parse_accept_header(self.environ.get('HTTP_ACCEPT_CHARSET'),
                                   CharsetAccept)

    @cached_property
    def encodings(self):
        """List of encodings this client supports as
        :class:`.Accept` object.

        Obtained form the ``Accept-Charset`` request header.
        Encodings in a HTTP term are compression encodings such as gzip.
        For charsets have a look at :attr:`charsets` attribute.
        """
        return parse_accept_header(self.environ.get('HTTP_ACCEPT_ENCODING'))

    @cached_property
    def languages(self):
        """List of languages this client accepts as
        :class:`.LanguageAccept` object.

        Obtained form the ``Accept-Language`` request header.
        """
        return parse_accept_header(self.environ.get('HTTP_ACCEPT_LANGUAGE'),
                                   LanguageAccept)

    @property
    def app_handler(self):
        '''The WSGI application handling this request.'''
        return self.cache.app_handler

    @property
    def urlargs(self):
        '''Dictionary of url parameters obtained when matching a
:ref:`router <wsgi-router>` with this request :attr:`path`.'''
        return self.cache.urlargs

    @property
    def cfg(self):
        '''The :ref:`config container <settings>` of the server
        '''
        return self.cache.cfg

    @property
    def ipaddress(self):
        '''internet protocol address of the client
        '''
        return self.environ.get('REMOTE_ADDR')

    @cached_property
    def response(self):
        '''The :class:`WsgiResponse` for this client request.
        '''
        return WsgiResponse(environ=self.environ)

    #######################################################################
    #    environ shortcuts
    @property
    def is_xhr(self):
        '''``True`` if this is an AJAX_ request
        '''
        return self.environ.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'

    @property
    def is_secure(self):
        '''``True`` if this request is via a TLS_ connection
        '''
        return self.environ.get('HTTPS') == 'on'

    @property
    def path(self):
        '''Shortcut to the :attr:`~EnvironMixin.environ` ``PATH_INFO`` value.
        '''
        return self.environ.get('PATH_INFO', '/')

    @property
    def method(self):
        '''The request method (uppercase).'''
        return self.environ['REQUEST_METHOD']

    @cached_property
    def encoding(self):
        return self.content_type_options[1].get('charset', 'utf-8')

    @cached_property
    def content_type_options(self):
        content_type = self.environ.get('CONTENT_TYPE')
        if content_type:
            return parse_options_header(content_type)
        else:
            return None, {}

    def data_and_files(self, data=True, files=True):
        '''Retrieve body data.

        Returns a two-elements tuple of a
        :class:`~.MultiValueDict` containing data from
        the request body, and data from uploaded files.

        If the body data is not ready, return a :class:`.Future`
        which results in the tuple.

        The result is cached.
        '''
        value = self.cache.data_and_files
        if not value:
            return self._data_and_files(data, files)
        elif data and files:
            return value
        elif data:
            return value[0]
        elif files:
            return value[1]
        else:
            return None

    def body_data(self):
        '''A :class:`~.MultiValueDict` containing data from the request body.
        '''
        return self.data_and_files(files=False)

    def _data_and_files(self, data=True, files=True):
        result = {}, None
        stream = self.environ.get('wsgi.input')
        chunk = None
        try:
            if self.method not in ENCODE_URL_METHODS and stream:
                chunk = stream.read()
                if isinstance(chunk, Future):
                    chunk = yield chunk
                content_type, options = self.content_type_options
                charset = options.get('charset', 'utf-8')
                if content_type in JSON_CONTENT_TYPES:
                    result = json.loads(chunk.decode(charset)), None
                else:
                    self.environ['wsgi.input'] = BytesIO(chunk)
                    result = parse_form_data(self.environ, charset)
        finally:
            self.cache.data_and_files = result
            if chunk is not None:
                self.environ['wsgi.input'] = BytesIO(chunk)
        coroutine_return(self.data_and_files(data, files))

    @cached_property
    def url_data(self):
        '''A (cached) dictionary containing data from the ``QUERY_STRING``
        in :attr:`~.EnvironMixin.environ`.
        '''
        return query_dict(self.environ.get('QUERY_STRING', ''),
                          encoding=self.encoding)

    @cached_property
    def html_document(self):
        '''Return a cached instance of :class:`.HtmlDocument`.'''
        return HtmlDocument()

    def get_host(self, use_x_forwarded=True):
        """Returns the HTTP host using the environment or request headers."""
        # We try three options, in order of decreasing preference.
        if use_x_forwarded and ('HTTP_X_FORWARDED_HOST' in self.environ):
            host = self.environ['HTTP_X_FORWARDED_HOST']
        elif 'HTTP_HOST' in self.environ:
            host = self.environ['HTTP_HOST']
        else:
            # Reconstruct the host using the algorithm from PEP 333.
            host = self.environ['SERVER_NAME']
            server_port = str(self.environ['SERVER_PORT'])
            if server_port != ('443' if self.is_secure else '80'):
                host = '%s:%s' % (host, server_port)
        return host

    def full_path(self, *args, **query):
        '''Return a full path'''
        path = None
        if args:
            if len(args) > 1:
                raise TypeError("full_url() takes exactly 1 argument "
                                "(%s given)" % len(args))
            path = args[0]
        if path is None:
            path = self.path
            if not query:
                query = self.url_data
        elif not path.startswith('/'):
            path = remove_double_slash('%s/%s' % (self.path, path))
        return iri_to_uri(path, query)

    def absolute_uri(self, location=None, scheme=None):
        '''Builds an absolute URI from ``location`` and variables
        available in this request.

        If no ``location`` is specified, the relative URI is built from
        :meth:`full_path`.
        '''
        if not location or not absolute_http_url_re.match(location):
            location = self.full_path(location)
            if not scheme:
                scheme = self.is_secure and 'https' or 'http'
            base = '%s://%s' % (scheme, self.get_host())
            return '%s%s' % (base, location)
        elif not scheme:
            return iri_to_uri(location)
        else:
            raise ValueError('Absolute location with scheme not valid')


set_wsgi_request_class(WsgiRequest)

########NEW FILE########
__FILENAME__ = access
import os
import threading
import logging
from collections import OrderedDict
from threading import current_thread
from multiprocessing import current_process

import asyncio
from asyncio.futures import _PENDING, _CANCELLED, _FINISHED
from asyncio.base_events import BaseEventLoop, _StopError

from pulsar.utils.config import Global

__all__ = ['get_request_loop',
           'get_event_loop',
           'new_event_loop',
           'asyncio',
           'get_actor',
           'is_mainthread',
           'process_data',
           'thread_data',
           'logger',
           'get_logger',
           'NOTHING',
           'SELECTORS']


LOGGER = logging.getLogger('pulsar')
NOTHING = object()
SELECTORS = OrderedDict()

for selector in ('Epoll', 'Kqueue', 'Poll', 'Select'):
    name = '%sSelector' % selector
    selector_class = getattr(asyncio.selectors, name, None)
    if selector_class:
        SELECTORS[selector.lower()] = selector_class


if os.environ.get('BUILDING-PULSAR-DOCS') == 'yes':     # pragma nocover
    default_selector = 'epoll on linux, kqueue on mac, select on windows'
else:
    default_selector = tuple(SELECTORS)[0]


class PollerSetting(Global):
    name = "selector"
    flags = ["--io"]
    choices = tuple(SELECTORS)
    default = default_selector
    desc = """\
        Specify the default selector used for I/O event polling.

        The default value is the best possible for the system running the
        application.
        """

get_event_loop = asyncio.get_event_loop


def new_event_loop(**kwargs):
    '''Obtain a new event loop.'''
    loop = asyncio.new_event_loop()
    if hasattr(loop, 'setup_loop'):
        loop.setup_loop(**kwargs)
    return loop


def is_mainthread(thread=None):
    '''Check if thread is the main thread. If ``thread`` is not supplied check
the current thread.'''
    thread = thread if thread is not None else current_thread()
    return isinstance(thread, threading._MainThread)


def get_request_loop():
    return asyncio.get_event_loop_policy().get_request_loop()


def logger(loop=None):
    return getattr(loop or get_request_loop(), 'logger', LOGGER)


def get_logger(default=None):
    return getattr(get_request_loop(), 'logger', default or LOGGER)


def process_data(name=None):
    '''Fetch the current process local data dictionary. If *name* is not
``None`` it returns the value at *name*, otherwise it return the process data
dictionary.'''
    ct = current_process()
    if not hasattr(ct, '_pulsar_local'):
        ct._pulsar_local = {}
    loc = ct._pulsar_local
    return loc.get(name) if name else loc


def thread_data(name, value=NOTHING, ct=None):
    '''Set or retrieve an attribute ``name`` from thread ``ct``.

    If ``ct`` is not given used the current thread. If ``value``
    is None, it will get the value otherwise it will set the value.
    '''
    ct = ct or current_thread()
    if is_mainthread(ct):
        loc = process_data()
    elif not hasattr(ct, '_pulsar_local'):
        ct._pulsar_local = loc = {}
    else:
        loc = ct._pulsar_local
    if value is not NOTHING:
        if name in loc:
            if loc[name] is not value:
                raise RuntimeError(
                    '%s is already available on this thread' % name)
        else:
            loc[name] = value
    return loc.get(name)


get_actor = lambda: thread_data('actor')
set_actor = lambda actor: thread_data('actor', actor)

########NEW FILE########
__FILENAME__ = actor
import sys
import os
from time import time
import pickle
from inspect import isgenerator
from threading import current_thread

from pulsar import HaltServer, CommandError, MonitorStarted, system
from pulsar.utils.log import WritelnDecorator

from .futures import in_loop, async, add_errback
from .events import EventHandler
from .threads import get_executor
from .proxy import ActorProxy, ActorProxyMonitor, ActorIdentity
from .mailbox import command_in_context
from .access import get_actor
from .cov import Coverage
from .consts import *


__all__ = ['is_actor', 'send', 'Actor', 'ACTOR_STATES', 'get_stream']


def is_actor(obj):
    return isinstance(obj, Actor)


def get_stream(cfg):
    '''Obtain the python stream handler given a config dictionary.
    '''
    stream = sys.stderr
    return WritelnDecorator(stream)


def send(target, action, *args, **params):
    '''Send a :ref:`message <api-remote_commands>` to ``target``

    The message is to perform a given ``action``. The actor sending the
    message is obtained via the :func:`get_actor` function.

    :parameter target: the :class:`Actor` id or an :class:`.ActorProxy` or
        name of the target actor which will receive the message.
    :parameter action: the :ref:`remote command <api-remote_commands>`
        to perform in the ``target`` :class:`Actor`.
    :parameter args: positional arguments to pass to the
        :ref:`remote command <api-remote_commands>` ``action``.
    :parameter params: dictionary of parameters to pass to
        :ref:`remote command <api-remote_commands>` ``action``.
    :return: an :class:`~asyncio.Future` if the action acknowledge the
        caller or `None`.

    Typical example::

        >>> r = send(p,'ping')
        >>> r.result()
        'pong'
    '''
    return get_actor().send(target, action, *args, **params)


class Actor(EventHandler, ActorIdentity, Coverage):
    '''The base class for parallel execution in pulsar.

    In computer science, the **Actor model** is a mathematical model
    of concurrent computation that treats *actors* as the universal primitives
    of computation.
    In response to a message that it receives, an actor can make local
    decisions, create more actors, send more messages, and determine how
    to respond to the next message received.

    The current implementation allows for actors to perform specific tasks
    such as listening to a socket, acting as http server, consuming
    a task queue and so forth.

    To spawn a new actor::

        >>> from pulsar import spawn
        >>> a = spawn()
        >>> a.is_alive()
        True

    Here ``a`` is actually a reference to the remote actor, it is
    an :class:`.ActorProxy`.

    **ATTRIBUTES**

    .. attribute:: name

        The name of this :class:`Actor`.

    .. attribute:: aid

        Unique ID for this :class:`Actor`.

    .. attribute:: impl

        The :class:`.Concurrency` implementation for this :class:`Actor`.

    .. attribute:: _loop

        An :ref:`event loop <asyncio-event-loop>` which listen
        for input/output events on sockets or socket-like objects.
        It is the driver of the :class:`Actor`.
        If the :attr:`_loop` stops, the :class:`Actor` stops
        running and goes out of scope.

    .. attribute:: mailbox

        Used to send and receive :ref:`actor messages <tutorials-messages>`.

    .. attribute:: address

        The socket address for this :attr:`Actor.mailbox`.

    .. attribute:: proxy

        Instance of a :class:`.ActorProxy` holding a reference
        to this :class:`Actor`. The proxy is a lightweight representation
        of the actor which can be shared across different processes
        (i.e. it is picklable).

    .. attribute:: state

        The actor :ref:`numeric state <actor-states>`.

    .. attribute:: extra

        A dictionary which can be populated with extra parameters useful
        for other actors. This dictionary is included in the dictionary
        returned by the :meth:`info` method.
        Check the :ref:`info command <actor_info_command>` for how to obtain
        information about an actor.

    .. attribute:: info_state

        Current state description string. One of ``initial``, ``running``,
        ``stopping``, ``closed`` and ``terminated``.

    .. attribute:: next_periodic_task

        The :class:`asyncio.Handle` for the next
        :ref:`actor periodic task <actor-periodic-task>`.

    .. attribute:: stream

        A ``stream`` handler to write information messages without using
        the :attr:`~.AsyncObject.logger`.
    '''
    ONE_TIME_EVENTS = ('start', 'stopping', 'stop')
    MANY_TIMES_EVENTS = ('on_info', 'on_params')
    exit_code = None
    mailbox = None
    monitor = None
    next_periodic_task = None

    def __init__(self, impl):
        EventHandler.__init__(self)
        self.state = ACTOR_STATES.INITIAL
        self.__impl = impl
        for name in self.events:
            hook = impl.params.pop(name, None)
            if hook:
                self.bind_event(name, hook)
        for name, value in impl.params.items():
            setattr(self, name, value)
        self.servers = {}
        self.extra = {}
        self.stream = get_stream(self.cfg)
        del impl.params
        self.tid = current_thread().ident
        self.pid = os.getpid()
        try:
            self.cfg.post_fork(self)
        except Exception:
            pass
        impl.setup_event_loop(self)

    def __repr__(self):
        return self.impl.unique_name

    def __str__(self):
        return self.__repr__()

    # ############################################################# PROPERTIES
    @property
    def name(self):
        return self.__impl.name

    @property
    def aid(self):
        return self.__impl.aid

    @property
    def impl(self):
        return self.__impl

    @property
    def cfg(self):
        return self.__impl.cfg

    @property
    def proxy(self):
        return ActorProxy(self)

    @property
    def address(self):
        return self.mailbox.address

    @property
    def _loop(self):
        return self.mailbox._loop

    @property
    def info_state(self):
        return ACTOR_STATES.DESCRIPTION[self.state]

    def executor(self):
        '''An executor for this actor

        Obtained from the :attr:`_loop` attribute
        '''
        return get_executor(self._loop)

    #######################################################################
    #    HIGH LEVEL API METHODS
    #######################################################################
    def start(self):
        '''Called after forking to start the actor's life.

        This is where logging is configured, the :attr:`mailbox` is
        registered and the :attr:`_loop` is initialised and
        started. Calling this method more than once does nothing.
        '''
        if self.state == ACTOR_STATES.INITIAL:
            self.__impl.before_start(self)
            self._started = self._loop.time()
            self.state = ACTOR_STATES.STARTING
            self._run()

    @in_loop
    def send(self, target, action, *args, **kwargs):
        '''Send a message to ``target`` to perform ``action`` with given
        positional ``args`` and key-valued ``kwargs``.
        Always return a :class:`asyncio.Future`.'''
        target = self.monitor if target == 'monitor' else target
        mailbox = self.mailbox
        if isinstance(target, ActorProxyMonitor):
            mailbox = target.mailbox
        else:
            actor = self.get_actor(target)
            if isinstance(actor, Actor):
                # this occur when sending a message from arbiter to monitors or
                # viceversa.
                return command_in_context(action, self, actor, args, kwargs)
            elif isinstance(actor, ActorProxyMonitor):
                mailbox = actor.mailbox
        if hasattr(mailbox, 'request'):
            # if not mailbox.closed:
            return mailbox.request(action, self, target, args, kwargs)
        else:
            raise CommandError('Cannot execute "%s" in %s. Unknown actor %s.'
                               % (action, self, target))

    def spawn(self, **params):
        raise RuntimeError('Cannot spawn an actor from an actor.')

    def stop(self, exc=None):
        '''Gracefully stop the :class:`Actor`.

        Implemented by the :meth:`.Concurrency.stop` method of the :attr:`impl`
        attribute.'''
        return self.__impl.stop(self, exc)

    def close_executor(self):
        '''Close the :meth:`executor`'''
        executor = self._loop._default_executor
        if executor:
            self.logger.debug('Waiting for executor shutdown')
            executor.shutdown()
            self._loop._default_executor = None

    # ##############################################################  STATES
    def is_running(self):
        '''``True`` if actor is running, that is when the :attr:`state`
        is equal to :ref:`ACTOR_STATES.RUN <actor-states>` and the loop is
        running.'''
        return self.state == ACTOR_STATES.RUN and self._loop.is_running()

    def started(self):
        '''``True`` if actor has started.

        It does not necessarily mean it is running.
        Its state is greater or equal :ref:`ACTOR_STATES.RUN <actor-states>`.
        '''
        return self.state >= ACTOR_STATES.RUN

    def closed(self):
        '''``True`` if actor has exited in an clean fashion.

        Its :attr:`state` is :ref:`ACTOR_STATES.CLOSE <actor-states>`.
        '''
        return self.state == ACTOR_STATES.CLOSE

    def stopped(self):
        '''``True`` if actor has exited.

        Its :attr:`state` is greater or equal to
        :ref:`ACTOR_STATES.CLOSE <actor-states>`.
        '''
        return self.state >= ACTOR_STATES.CLOSE

    def is_arbiter(self):
        '''Return ``True`` if ``self`` is the :class:`.Arbiter`.'''
        return self.__impl.is_arbiter()

    def is_monitor(self):
        '''Return ``True`` if ``self`` is a :class:`.Monitor`.'''
        return False

    def is_process(self):
        '''boolean indicating if this is an actor on a child process.'''
        return self.__impl.is_process()

    def __reduce__(self):
        raise pickle.PicklingError('{0} - Cannot pickle Actor instances'
                                   .format(self))

    #######################################################################
    #    INTERNALS
    #######################################################################
    def get_actor(self, aid):
        '''Given an actor unique id return the actor proxy.'''
        if aid == self.aid:
            return self
        elif aid == 'monitor':
            return self.monitor or self

    def info(self):
        '''Return a nested dictionary of information related to the actor
        status and performance. The dictionary contains the following entries:

        * ``actor`` a dictionary containing information regarding the type of
          actor and its status.
        * ``events`` a dictionary of information about the
          :ref:`event loop <asyncio-event-loop>` running the actor.
        * ``extra`` the :attr:`extra` attribute (you can use it to add stuff).
        * ``system`` system info.

        This method is invoked when you run the
        :ref:`info command <actor_info_command>` from another actor.
        '''
        if not self.started():
            return
        isp = self.is_process()
        actor = {'name': self.name,
                 'state': self.info_state,
                 'actor_id': self.aid,
                 'uptime': time() - self._started,
                 'thread_id': self.tid,
                 'process_id': self.pid,
                 'is_process': isp,
                 'age': self.impl.age}
        events = {'callbacks': len(self._loop._ready),
                  'scheduled': len(self._loop._scheduled)}
        data = {'actor': actor,
                'events': events,
                'extra': self.extra}
        if isp:
            data['system'] = system.process_info(self.pid)
        self.fire_event('on_info', info=data)
        return data

    def _run(self, initial=True):
        exc = None
        if initial:
            try:
                self.cfg.when_ready(self)
            except Exception:   # pragma    nocover
                self.logger.exception('Unhandled exception in when_ready hook')
        try:
            exc = self.__impl.run_actor(self)
        except MonitorStarted:
            return
        except (Exception, HaltServer) as exc:
            return self.stop(exc)
        except BaseException:
            pass
        self.stop()

########NEW FILE########
__FILENAME__ = arbiter
import os
import sys
from multiprocessing import current_process

import pulsar
from pulsar.utils.tools import Pidfile
from pulsar.utils.security import gen_unique_id
from pulsar.utils.pep import itervalues
from pulsar import HaltServer

from .actor import Actor, ACTOR_STATES
from .monitor import PoolMixin, Monitor, _spawn_actor
from .futures import multi_async
from .access import get_actor, set_actor
from .proxy import actor_proxy_future


__all__ = ['arbiter', 'spawn', 'Arbiter']


def arbiter(**params):
    '''Obtain the :class:`.Arbiter`.

    It returns the arbiter instance only if we are on the arbiter
    context domain, otherwise it returns nothing.
    '''
    arbiter = get_actor()
    if arbiter is None:
        # Create the arbiter
        return set_actor(_spawn_actor(Arbiter, None, **params))
    elif isinstance(arbiter, Actor) and arbiter.is_arbiter():
        return arbiter


def spawn(**kwargs):
    '''Spawn a new :class:`.Actor` and return an :class:`.ActorProxyFuture`.

    This method can be used from any :class:`.Actor`.
    If not in the :class:`.Arbiter` domain, the method sends a request
    to the :class:`.Arbiter` to spawn a new actor.
    Once the arbiter creates the actor it returns the ``proxy`` to the
    original caller.

    **Parameter kwargs**

    These optional parameters are:

    * ``aid`` the actor id
    * ``name`` the actor name
    * :ref:`actor hooks <actor-hooks>` such as ``start``, ``stopping``
      and ``stop``
    * ``actor_class`` a custom :class:`.Actor` subclass (never used)

    :return: an :class:`.ActorProxyFuture`.

    A typical usage::

        >>> def do_something(actor):
                ...
        >>> a = spawn(start=do_something, ...)
        >>> a.aid
        'ba42b02b'
        >>> a.called
        True
        >>> p = a.result()
        >>> p.address
        ('127.0.0.1', 46691)
    '''
    aid = gen_unique_id()[:8]
    kwargs['aid'] = aid
    actor = get_actor()
    # The actor is not the Arbiter domain.
    # We send a message to the Arbiter to spawn a new Actor
    if not isinstance(actor, Arbiter):
        # send the request to the arbiter
        future = actor.send('arbiter', 'spawn', **kwargs)
        return actor_proxy_future(aid, future)
    else:
        return actor.spawn(**kwargs)


def stop_arbiter(self, exc=None):     # pragma    nocover
    p = self.pidfile
    if p is not None:
        self.logger.debug('Removing %s' % p.fname)
        p.unlink()
        self.pidfile = None
    if self.managed_actors:
        self.state = ACTOR_STATES.TERMINATE
    self.collect_coverage()
    exit_code = self.exit_code or 0
    self.stream.writeln("Bye (exit code = %s)" % exit_code)
    try:
        self.cfg.when_exit(self)
    except Exception:
        pass
    if exit_code:
        sys.exit(exit_code)
    return self


def start_arbiter(self, exc=None):
    if current_process().daemon:
        raise HaltServer('Cannot create the arbiter in a daemon process')
    os.environ["SERVER_SOFTWARE"] = pulsar.SERVER_SOFTWARE
    pidfile = self.cfg.pidfile
    if pidfile is not None:
        try:
            p = Pidfile(pidfile)
            p.create(self.pid)
        except RuntimeError as e:
            raise HaltServer('ERROR. %s' % str(e), exit_code=3)
        self.pidfile = p


def info_arbiter(self, info=None):
    data = info
    monitors = {}
    for m in itervalues(self.monitors):
        info = m.info()
        if info:
            actor = info['actor']
            monitors[actor['name']] = info
    server = data.pop('actor')
    server.update({'version': pulsar.__version__,
                   'name': pulsar.SERVER_NAME,
                   'number_of_monitors': len(self.monitors),
                   'number_of_actors': len(self.managed_actors)})
    server.pop('is_process', None)
    server.pop('ppid', None)
    server.pop('actor_id', None)
    server.pop('age', None)
    data['server'] = server
    data['workers'] = [a.info for a in itervalues(self.managed_actors)]
    data['monitors'] = monitors
    return data


class Arbiter(PoolMixin):
    '''The Arbiter drives pulsar servers.

    It is the most important a :class:`.Actor` and :class:`.PoolMixin` in
    pulsar concurrent framework. It is used as singleton
    in the main process and it manages one or more :class:`.Monitor`.
    It runs the main :ref:`event loop <asyncio-event-loop>` of your
    concurrent application.

    Users access the arbiter (in the arbiter process domain) by the
    high level api::

        import pulsar

        arbiter = pulsar.arbiter()
    '''
    pidfile = None

    def __init__(self, impl):
        super(Arbiter, self).__init__(impl)
        self.monitors = {}
        self.registered = {'arbiter': self}
        self.bind_event('start', start_arbiter)
        self.bind_event('stop', stop_arbiter)
        self.bind_event('on_info', info_arbiter)

    ########################################################################
    # ARBITER HIGH LEVEL API
    ########################################################################
    def add_monitor(self, monitor_name, monitor_class=None, **params):
        '''Add a new :class:`.Monitor` to the :class:`Arbiter`.

        :param monitor_class: a :class:`.Monitor` class.
        :param monitor_name: a unique name for the monitor.
        :param kwargs: dictionary of key-valued parameters for the monitor.
        :return: the :class:`.Monitor` added.
        '''
        if monitor_name in self.registered:
            raise KeyError('Monitor "%s" already available' % monitor_name)
        monitor_class = monitor_class or Monitor
        params.update(self.actorparams())
        params['name'] = monitor_name
        m = self.spawn(monitor_class, **params)
        self.registered[m.name] = m
        self.monitors[m.aid] = m
        return m

    def close_monitors(self):
        '''Close all :class:`.Monitor` at once.
        '''
        return multi_async((m.stop() for m in list(itervalues(self.monitors))))

    def get_actor(self, aid):
        '''Given an actor unique id return the actor proxy.'''
        a = super(Arbiter, self).get_actor(aid)
        if a is None:
            if aid in self.monitors:  # Check in monitors aid
                return self.monitors[aid]
            elif aid in self.managed_actors:
                return self.managed_actors[aid]
            elif aid in self.registered:
                return self.registered[aid]
            else:  # Finally check in workers in monitors
                for m in itervalues(self.monitors):
                    if aid in m.managed_actors:
                        return m.managed_actors[aid]
        else:
            return a

    def identity(self):
        return self.name

    ########################################################################
    # INTERNALS
    ########################################################################
    def _remove_actor(self, actor, log=True):
        a = super(Arbiter, self)._remove_actor(actor, False)
        b = self.registered.pop(actor.name, None)
        c = self.monitors.pop(actor.aid, None)
        removed = a or b or c
        if removed and log:
            self.logger.warning('Removing %s', actor)
        return removed

########NEW FILE########
__FILENAME__ = clients
from functools import reduce
from asyncio import Queue, QueueFull

from pulsar.utils.internet import is_socket_closed

from .futures import coroutine_return, AsyncObject, future_timeout
from .protocols import Producer


__all__ = ['Pool', 'PoolConnection', 'AbstractClient', 'AbstractUdpClient']


class Pool(AsyncObject):
    '''An asynchronous pool of open connections.

    Open connections are either :attr:`in_use` or :attr:`available`
    to be used. Available connection are placed in an :class:`asyncio.Queue`.

    This class is not thread safe.
    '''
    def __init__(self, creator, pool_size=10, loop=None, timeout=None, **kw):
        self._creator = creator
        self._closed = False
        self._timeout = timeout
        self._queue = Queue(maxsize=pool_size, loop=loop)
        self._connecting = 0
        self._loop = self._queue._loop
        self._in_use_connections = set()

    @property
    def pool_size(self):
        '''The maximum number of open connections allowed.

        If more connections are requested, the request
        is queued and a connection returned as soon as one becomes
        available.
        '''
        return self._queue._maxsize

    @property
    def in_use(self):
        '''The number of connections in use.

        These connections are not available until they are released back
        to the pool.
        '''
        return len(self._in_use_connections)

    @property
    def available(self):
        '''Number of available connections in the pool.
        '''
        return reduce(self._count_connections, self._queue._queue, 0)

    def __contains__(self, connection):
        if connection not in self._in_use_connections:
            return connection in self._queue._queue
        return True

    def connect(self):
        '''Get a connection from the pool.

        The connection is either a new one or retrieved from the
        :attr:`available` connections in the pool.

        :return: a :class:`.Future` resulting in the connection.
        '''
        assert not self._closed
        return PoolConnection.checkout(self)

    def close(self):
        '''Close all :attr:`available` and :attr:`in_use` connections.
        '''
        self._closed = True
        queue = self._queue
        while queue.qsize():
            connection = queue.get_nowait()
            connection.close()
        in_use = self._in_use_connections
        self._in_use_connections = set()
        for connection in in_use:
            connection.close()

    def _get(self):
        queue = self._queue
        # grab the connection without waiting, important!
        if queue.qsize():
            connection = queue.get_nowait()
        # wait for one to be available
        elif self.in_use + self._connecting >= queue._maxsize:
            if self._timeout:
                connection = yield future_timeout(queue.get(), self._timeout)
            else:
                connection = yield queue.get()
        else:   # must create a new connection
            self._connecting += 1
            try:
                connection = yield self._creator()
            finally:
                self._connecting -= 1
        # None signal that a connection was removed form the queue
        # Go again
        if connection is None:
            connection = yield self._get()
        else:
            if is_socket_closed(connection.sock):
                connection.close()
                connection = yield self._get()
            else:
                self._in_use_connections.add(connection)
        coroutine_return(connection)

    def _put(self, conn, discard=False):
        if not self._closed:
            try:
                self._queue.put_nowait(None if discard else conn)
            except QueueFull:
                conn.close()
        self._in_use_connections.discard(conn)

    def info(self, message=None, level=None):   # pragma    nocover
        if self._queue._maxsize != 2:
            return
        message = '%s: ' % message if message else ''
        self.logger.log(level or 10,
                        '%smax size %s, in_use %s, available %s',
                        message, self._queue._maxsize, self.in_use,
                        self.available)

    def _count_connections(self, x, y):
        return x + int(y is not None)


class PoolConnection(object):
    '''A wrapper for a :class:`Connection` in a connection :class:`Pool`.

    Objects are never initialised directly, instead they are `checked-out`
    via the :meth:`checkout` class method from the :meth:`Pool.connect`
    method.

    .. attribute:: pool

        The :class:`Pool` which created this :class:`PoolConnection`

    .. attribute:: connection

        The underlying socket connection.
    '''
    __slots__ = ('pool', 'connection')

    def __init__(self, pool, connection):
        self.pool = pool
        self.connection = connection

    def close(self, discard=False):
        '''Close this pool connection by releasing the underlying
        :attr:`connection` back to the ;attr:`pool`.
        '''
        if self.pool is not None:
            self.pool._put(self.connection, discard)
            self.pool = None
            self.connection = None

    def detach(self):
        '''Remove the underlying :attr:`connection` from the connection
        :attr:`pool`.
        '''
        self.close(True)

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        self.close()

    def __getattr__(self, name):
        return getattr(self.connection, name)

    def __del__(self):
        self.close()

    @classmethod
    def checkout(cls, pool):
        '''Checkout a new connection from ``pool``.
        '''
        connection = yield pool._get()
        coroutine_return(cls(pool, connection))


class AbstractClient(Producer):
    '''A :class:`.Producer` for a client connections.
    '''
    ONE_TIME_EVENTS = ('finish',)

    def __repr__(self):
        return self.__class__.__name__
    __str__ = __repr__

    def connect(self):
        '''Abstract method for creating a connection.
        '''
        raise NotImplementedError

    def close(self):
        '''Close all idle connections.
        '''
        return self.fire_event('finish')
    abort = close

    def create_connection(self, address, protocol_factory=None, **kw):
        '''Helper method for creating a connection to an ``address``.
        '''
        protocol_factory = protocol_factory or self.create_protocol
        if isinstance(address, tuple):
            host, port = address
            _, protocol = yield self._loop.create_connection(
                protocol_factory, host, port, **kw)
        else:
            raise NotImplementedError('Could not connect to %s' %
                                      str(address))
        coroutine_return(protocol)


class AbstractUdpClient(Producer):
    '''A :class:`.Producer` for a client udp connections.
    '''
    ONE_TIME_EVENTS = ('finish',)

    def __repr__(self):
        return self.__class__.__name__
    __str__ = __repr__

    def create_endpoint(self):
        '''Abstract method for creating the endpoint
        '''
        raise NotImplementedError

    def close(self):
        '''Close all idle connections.
        '''
        return self.fire_event('finish')
    abort = close

    def create_datagram_endpoint(self, protocol_factory=None, **kw):
        '''Helper method for creating a connection to an ``address``.
        '''
        protocol_factory = protocol_factory or self.create_protocol
        _, protocol = yield self._loop.create_datagram_endpoint(
            protocol_factory, **kw)
        yield protocol.event('connection_made')
        coroutine_return(protocol)

########NEW FILE########
__FILENAME__ = commands
from time import time

from pulsar import CommandError

from .futures import async_while, coroutine_return
from .proxy import command, ActorProxyMonitor


@command()
def ping(request):
    return 'pong'


@command()
def echo(request, message):
    '''Returns *message*'''
    return message


@command()
def config(request, setget, name, *values):
    setget = setget.lower()
    if setget == 'get':
        if len(values) > 0:
            raise CommandError('"config get" accept only one parameter')
        return request.actor.cfg.get(name)
    elif setget == 'set':
        if len(values) > 1:
            raise CommandError('"config get" accept only two parameters')
        request.actor.cfg.set(name, values[0])
    else:
        raise CommandError('config must be followed by set or get')


@command()
def run(request, callable, *args, **kwargs):
    '''Execute a python *callable*.'''
    return callable(request.actor, *args, **kwargs)


@command(ack=False)
def stop(request):
    '''Stop the actor from running.'''
    return request.actor.stop()


@command()
def notify(request, info):
    '''The actor notify itself with a dictionary of information.

    The command perform the following actions:

    * Update the mailbox to the current consumer of the actor connection
    * Update the info dictionary
    * Returns the time of the update
    '''
    t = time()
    actor = request.actor
    remote_actor = request.caller
    if isinstance(remote_actor, ActorProxyMonitor):
        remote_actor.mailbox = request.connection
        info['last_notified'] = t
        remote_actor.info = info
        callback = remote_actor.callback
        # if a callback is still available, this is the first
        # time we got notified
        if callback:
            remote_actor.callback = None
            callback.set_result(remote_actor)
            if actor.cfg.debug:
                actor.logger.debug('Got first notification from %s',
                                   remote_actor)
        elif actor.cfg.debug:
            actor.logger.debug('Got notification from %s', remote_actor)
    else:
        actor._logger.warning('notify got a bad actor')
    return t


@command()
def spawn(request, **kwargs):
    '''Spawn a new actor.'''
    return request.actor.spawn(**kwargs)


@command()
def info(request):
    ''' Returns information and statistics about the server as a json string'''
    return request.actor.info()


@command()
def kill_actor(request, aid, timeout=5):
    '''Kill an actor with id ``aid``. This command can only be executed by the
arbiter, therefore a valid sintax is only::

    send('arbiter', 'kill_actor', 'abc')

Return 'killed abc` if successful, otherwise it returns ``None``.
'''
    arb = request.actor
    if arb.is_arbiter():
        arb.send(aid, 'stop')
        proxy = yield async_while(timeout, arb.get_actor, aid)
        if proxy:
            arb.logger.warning('Could not kill actor %s', aid)
        else:
            coroutine_return('killed %s' % aid)

########NEW FILE########
__FILENAME__ = concurrency
import sys
from functools import partial
from multiprocessing import Process, current_process

from pulsar import system, HaltServer, MonitorStarted
from pulsar.utils.security import gen_unique_id
from pulsar.utils.pep import itervalues

from .proxy import ActorProxyMonitor, get_proxy
from .access import get_actor, set_actor, logger, _StopError, SELECTORS
from .threads import Thread
from .mailbox import MailboxClient, MailboxProtocol, ProxyMailbox
from .futures import multi_async, Future, add_errback
from .eventloop import EventLoop
from .protocols import TcpServer
from .consts import *


if sys.platform == 'win32':     # pragma    nocover
    signal = None
else:
    import signal


__all__ = ['Concurrency', 'concurrency']


def concurrency(kind, actor_class, monitor, cfg, **params):
    '''Function invoked by the :class:`.Arbiter` or a :class:`.Monitor` when
spawning a new :class:`.Actor`. It created a :class:`.Concurrency` instance
which handle the initialisation and the life of an :class:`.Actor`.

:parameter kind: Type of concurrency.
:parameter monitor: The monitor (or arbiter) managing the :class:`.Actor`.
:return: a :class:`.Councurrency` instance.
'''
    maker = concurrency_models.get(kind)
    if maker:
        c = maker()
        return c.make(kind, actor_class, monitor, cfg, **params)
    else:
        raise ValueError('Concurrency %s not supported in pulsar' % kind)


class Concurrency(object):
    '''Actor :class:`.Concurrency`.

    Responsible for the actual spawning of actors according to a
    concurrency implementation. Instances are picklable
    and are shared between the :class:`.Actor` and its
    :class:`.ActorProxyMonitor`.
    This is an abstract class, derived classes must implement the
    ``start`` method.

    :param concurrency: string indicating the concurrency implementation.
        Valid choices are ``monitor``, ``process``, ``thread``.
    :param actor_class: :class:`.Actor` or one of its subclasses.
    :param timeout: timeout in seconds for the actor.
    :param kwargs: additional key-valued arguments to be passed to the actor
        constructor.
    '''
    _creation_counter = 0

    def make(self, kind, actor_class, monitor, cfg, name=None, aid=None, **kw):
        self.__class__._creation_counter += 1
        self.aid = aid or gen_unique_id()[:8]
        self.age = self.__class__._creation_counter
        self.name = name or actor_class.__name__.lower()
        self.kind = kind
        self.cfg = cfg
        self.actor_class = actor_class
        self.params = kw
        self.params['monitor'] = monitor
        return self.get_actor()

    @property
    def unique_name(self):
        return '%s(%s)' % (self.name, self.aid)

    def __repr__(self):
        return self.unique_name
    __str__ = __repr__

    def before_start(self, actor):
        pass

    def is_process(self):
        return False

    def is_arbiter(self):
        return False

    def selector(self):
        '''Return a selector instance.

        By default it return nothing so that the best handler for the
        system is chosen.
        '''
        return SELECTORS[self.cfg.selector]()

    def run_actor(self, actor):
        '''Start running the ``actor``.
        '''
        set_actor(actor)
        actor.mailbox.start_serving()
        actor._loop.run_forever()

    def setup_event_loop(self, actor):
        '''Set up the event loop for ``actor``.
        '''
        actor._logger = self.cfg.configured_logger(actor.name)
        loop = EventLoop(self.selector(), logger=actor._logger,
                         iothreadloop=True)
        actor.mailbox = self.create_mailbox(actor, loop)

    def hand_shake(self, actor):
        '''Perform the hand shake for ``actor``

        The hand shake occurs when the ``actor`` is in starting state.
        It performs the following actions:

        * set the ``actor`` as the actor of the current thread
        * bind two additional callbacks to the ``start`` event
        * fire the ``start`` event

        If the hand shake is successful, the actor will eventually
        results in a running state.
        '''
        try:
            assert actor.state == ACTOR_STATES.STARTING
            if actor.cfg.debug:
                actor.logger.debug('starting handshake')
            a = get_actor()
            if a is not actor and a is not actor.monitor:
                set_actor(actor)
            actor.bind_event('start', self._switch_to_run)
            actor.bind_event('start', self.periodic_task)
            actor.bind_event('start', self._acknowledge_start)
            actor.fire_event('start')
        except Exception as exc:
            actor.stop(exc)

    def get_actor(self):
        self.daemon = False
        self.params['monitor'] = get_proxy(self.params['monitor'])
        # make sure these parameters are picklable
        # pickle.dumps(self.params)
        return ActorProxyMonitor(self)

    def create_mailbox(self, actor, loop):
        '''Create the mailbox for ``actor``.'''
        client = MailboxClient(actor.monitor.address, actor, loop)
        loop.call_soon_threadsafe(self.hand_shake, actor)
        client.bind_event('finish', lambda _, **kw: loop.stop())
        return client

    def _install_signals(self, actor):
        proc_name = "%s-%s" % (actor.cfg.proc_name, actor)
        if system.set_proctitle(proc_name):
            actor.logger.debug('Set process title to %s', proc_name)
        system.set_owner_process(actor.cfg.uid, actor.cfg.gid)
        if signal:
            actor.logger.debug('Installing signals')
            for sig in system.EXIT_SIGNALS:
                try:
                    actor._loop.add_signal_handler(
                        sig, self.handle_exit_signal, actor, sig)
                except ValueError:
                    pass

    def periodic_task(self, actor, **kw):
        '''Implement the :ref:`actor period task <actor-periodic-task>`.

        This is an internal method called periodically by the
        :attr:`.Actor._loop` to ping the actor monitor.
        If successful return a :class:`asyncio.Future` called
        back with the acknowledgement from the monitor.
        '''
        actor.next_periodic_task = None
        ack = None
        if actor.is_running():
            if actor.cfg.debug:
                actor.logger.debug('notify monitor')
            # if an error occurs, shut down the actor
            ack = actor.send('monitor', 'notify', actor.info())
            add_errback(ack, actor.stop)
            next = max(ACTOR_TIMEOUT_TOLE*actor.cfg.timeout, MIN_NOTIFY)
        else:
            next = 0
        actor.next_periodic_task = actor._loop.call_later(
            min(next, MAX_NOTIFY), self.periodic_task, actor)
        return ack

    def stop(self, actor, exc):
        '''Gracefully stop the ``actor``.
        '''
        if actor.state <= ACTOR_STATES.RUN:
            # The actor has not started the stopping process. Starts it now.
            actor.state = ACTOR_STATES.STOPPING
            actor.event('start').clear()
            if exc:
                actor.exit_code = getattr(exc, 'exit_code', 1)
                if actor.exit_code == 1:
                    actor.logger.critical('Stopping', exc_info=True)
                elif actor.exit_code:
                    actor.stream.writeln(str(exc))
                else:
                    actor.logger.info('Stopping')
            else:
                if actor.logger:
                    actor.logger.debug('stopping')
                actor.exit_code = 0
            stopping = actor.fire_event('stopping')
            actor.close_executor()
            if not stopping.done() and actor._loop.is_running():
                actor.logger.debug('async stopping')
                stopping.add_done_callback(lambda _: self._stop_actor(actor))
            else:
                self._stop_actor(actor)
        elif actor.stopped():
            # The actor has finished the stopping process.
            actor.fire_event('stop')
        return actor.event('stop')

    def _stop_actor(self, actor):
        '''Exit from the :class:`.Actor` domain.'''
        actor.state = ACTOR_STATES.CLOSE
        if actor._loop.is_running():
            actor.logger.debug('Closing mailbox')
            actor.mailbox.close()
        else:
            actor.exit_code = 1
            actor.mailbox.abort()
            self.stop(actor, 0)

    def _switch_to_run(self, actor, exc=None):
        if exc is None and actor.state < ACTOR_STATES.RUN:
            actor.state = ACTOR_STATES.RUN
        elif exc:
            actor.stop(exc)

    def _acknowledge_start(self, actor, exc=None):
        if exc is None:
            actor.logger.info('started')
        else:
            actor.stop(exc)


class ProcessMixin(object):

    def is_process(self):
        return True

    def before_start(self, actor):  # pragma    nocover
        actor.start_coverage()
        self._install_signals(actor)

    def handle_exit_signal(self, actor, sig):
        actor.logger.warning("Got %s. Stopping.", system.SIG_NAMES.get(sig))
        actor._loop.exit_signal = sig
        raise _StopError


class MonitorMixin(object):

    def get_actor(self):
        return self.actor_class(self)

    def start(self):
        '''does nothing'''
        pass

    def is_active(self):
        return self.actor.is_alive()

    @property
    def pid(self):
        return current_process().pid


############################################################################
#    CONCURRENCY IMPLEMENTATIONS
class MonitorConcurrency(MonitorMixin, Concurrency):
    ''':class:`.Concurrency` class for a :class:`.Monitor`.

    Monitors live in the **main thread** of the master process and
    therefore do not require to be spawned.
    '''
    def setup_event_loop(self, actor):
        actor._logger = self.cfg.configured_logger(actor.name)
        actor.mailbox = ProxyMailbox(actor)
        actor.mailbox._loop.call_soon(actor.start)

    def run_actor(self, actor):
        actor._loop.call_soon(self.hand_shake, actor)
        raise MonitorStarted

    def create_mailbox(self, actor, loop):
        raise NotImplementedError

    def periodic_task(self, actor, **kw):
        '''Override the :meth:`.Concurrency.periodic_task` to implement
        the :class:`.Monitor` :ref:`periodic task <actor-periodic-task>`.'''
        interval = 0
        actor.next_periodic_task = None
        if actor.is_running():
            interval = MONITOR_TASK_PERIOD
            actor.manage_actors()
            actor.spawn_actors()
            actor.stop_actors()
            actor.monitor_task()
        actor.next_periodic_task = actor._loop.call_later(
            interval, self.periodic_task, actor)

    def _stop_actor(self, actor):

        def _cleanup(_):
            if not actor.terminated_actors:
                actor.monitor._remove_actor(actor)
            actor.fire_event('stop')

        return actor.close_actors().add_done_callback(_cleanup)


class ArbiterConcurrency(MonitorMixin, ProcessMixin, Concurrency):
    '''Concurrency implementation for the :class:`.Arbiter`
    '''
    def is_arbiter(self):
        return True

    def before_start(self, actor):  # pragma    nocover
        '''Daemonise the system if required.
        '''
        if actor.cfg.daemon:
            system.daemonize()
        actor.start_coverage()
        self._install_signals(actor)

    def create_mailbox(self, actor, loop):
        '''Override :meth:`.Concurrency.create_mailbox` to create the
        mailbox server.
        '''
        mailbox = TcpServer(MailboxProtocol, loop, ('127.0.0.1', 0),
                            name='mailbox')
        # when the mailbox stop, close the event loop too
        mailbox.bind_event('stop', lambda _, **kw: loop.stop())
        mailbox.bind_event(
            'start',
            lambda _, **kw: loop.call_soon(self.hand_shake, actor))
        return mailbox

    def periodic_task(self, actor, **kw):
        '''Override the :meth:`.Concurrency.periodic_task` to implement
        the :class:`.Arbiter` :ref:`periodic task <actor-periodic-task>`.'''
        interval = 0
        actor.next_periodic_task = None
        if actor.is_running():
            # managed actors job
            interval = MONITOR_TASK_PERIOD
            actor.manage_actors()
            for m in list(itervalues(actor.monitors)):
                if m.started() and not m.is_running():
                    actor._remove_actor(m)
        actor.next_periodic_task = actor._loop.call_later(
            interval, self.periodic_task, actor)

    def _stop_actor(self, actor):
        '''Stop the pools the message queue and remaining actors.'''
        if actor._loop.is_running():
            self._exit_arbiter(actor)
        else:
            actor.logger.debug('Restarts event loop to stop actors')
            loop = actor._loop
            actor._loop.call_soon(self._exit_arbiter, actor)
            actor._run(False)

    def _exit_arbiter(self, actor, fut=None):
        if fut:
            actor.logger.debug('Closing mailbox server')
            actor.state = ACTOR_STATES.CLOSE
            actor.mailbox.close()
        else:
            actor.logger.debug('Close monitors and actors')
            active = multi_async((actor.close_monitors(),
                                  actor.close_actors()))
            active.add_done_callback(partial(self._exit_arbiter, actor))


def run_actor(self):
    self._actor = actor = self.actor_class(self)
    try:
        actor.start()
    finally:
        try:
            actor.cfg.when_exit(actor)
        except Exception:   # pragma    nocover
            pass
        log = actor.logger or logger()
        self.stop_coverage(actor)
        log.info('Bye from "%s"', actor)


class ActorProcess(ProcessMixin, Concurrency, Process):
    '''Actor on a Operative system process.

    Created using the python multiprocessing module.
    '''
    def run(self):  # pragma    nocover
        # The coverage for this process has not yet started
        run_actor(self)

    def stop_coverage(self, actor):
        actor.stop_coverage()


class TerminateActorThread(Exception):
    pass


class ActorThread(Concurrency, Thread):
    '''Actor on a thread in the master process.'''
    _actor = None

    def run(self):
        run_actor(self)

    def stop_coverage(self, actor):
        pass

    def loop(self):
        if self._actor:
            return self._actor._loop


concurrency_models = {'arbiter': ArbiterConcurrency,
                      'monitor': MonitorConcurrency,
                      'thread': ActorThread,
                      'process': ActorProcess}

########NEW FILE########
__FILENAME__ = consts
'''
Constants used throughout pulsar.
'''
from pulsar import platform
from pulsar.utils.structures import AttributeDictionary, FrozenDict

# LOW LEVEL CONSTANTS - NO NEED TO CHANGE THOSE ###########################
ACTOR_STATES = AttributeDictionary(INITIAL=0X0,
                                   INACTIVE=0X1,
                                   STARTING=0x2,
                                   RUN=0x3,
                                   STOPPING=0x4,
                                   CLOSE=0x5,
                                   TERMINATE=0x6)
'''
.. _actor-states:

Actor state constants are access via::

    from pulsar import ACTOR_STATES

They are:

* ``ACTOR_STATES.INITIAL = 0`` when an actor is just created, before the
  :class:`pulsar.Actor.start` method is called.
* ``ACTOR_STATES.STARTING = 2`` when :class:`pulsar.Actor.start` method
  is called.
* ``ACTOR_STATES.RUN = 3`` when :class:`pulsar.Actor._loop` is up
  and running.
* ``ACTOR_STATES.STOPPING = 4`` when :class:`pulsar.Actor.stop` has been
  called for the first time and the actor is running.
'''
ACTOR_STATES.DESCRIPTION = {ACTOR_STATES.INACTIVE: 'inactive',
                            ACTOR_STATES.INITIAL: 'initial',
                            ACTOR_STATES.STARTING: 'starting',
                            ACTOR_STATES.RUN: 'running',
                            ACTOR_STATES.STOPPING: 'stopping',
                            ACTOR_STATES.CLOSE: 'closed',
                            ACTOR_STATES.TERMINATE: 'terminated'}
SPECIAL_ACTORS = ('monitor', 'arbiter')
#
ACTOR_ACTION_TIMEOUT = 5
'''Important constant used by :class:`pulsar.Monitor` to kill actors which
don't respond to the ``stop`` command.'''

MAX_ASYNC_WHILE = 1     # Max interval for async_while
MIN_NOTIFY = 3     # DON'T NOTIFY BELOW THIS INTERVAL
MAX_NOTIFY = 30    # NOTIFY AT LEAST AFTER THESE SECONDS
ACTOR_TIMEOUT_TOLE = 0.3  # NOTIFY AFTER THIS TIMES THE TIMEOUT
ACTOR_JOIN_THREAD_POOL_TIMEOUT = 5  # TIMEOUT WHEN JOINING THE THREAD POOL
MONITOR_TASK_PERIOD = 2
'''Interval for :class:`pulsar.Monitor` and :class:`pulsar.Arbiter`
periodic task.'''
#
DEFAULT_CONNECT_TIMEOUT = 10
DEFAULT_ACCEPT_TIMEOUT = 10
NUMBER_ACCEPTS = 30 if platform.type == "posix" else 1
LOG_THRESHOLD_FOR_CONNLOST_WRITES = 5
MAX_CONSECUTIVE_WRITES = 500
#
# Globals
EMPTY_TUPLE = ()
EMPTY_DICT = FrozenDict()

########NEW FILE########
__FILENAME__ = cov
from multiprocessing import current_process

try:
    import coverage
except ImportError:
    coverage = None


class Coverage(object):
    '''Coverage mixin for actors.
    '''
    @property
    def coverage(self):
        return getattr(current_process(), '_coverage', None)

    def start_coverage(self):
        if coverage and self.cfg.coverage:
            cov = self.coverage
            if not cov:
                self.logger.info('Start coverage')
                p = current_process()
                p._coverage = coverage.coverage(data_suffix=True)
                p._coverage.start()

    def stop_coverage(self):
        cov = self.coverage
        if cov and not self.is_arbiter():
            self.logger.info('Saving coverage file')
            cov.stop()
            cov.save()

    def collect_coverage(self):
        cov = self.coverage
        if cov:
            self.logger.info('Combining coverage files')
            cov.stop()
            cov.save()
            c = coverage.coverage(data_suffix=True)
            c.combine()
            c.save()
            self.stream.write('Coverage file available. Type "coverage html" '
                              'for a report\n')

########NEW FILE########
__FILENAME__ = eventloop
import os
import asyncio
from threading import current_thread

from .access import thread_data, LOGGER
from .futures import Future, maybe_async, async, Task
from .threads import run_in_executor, QueueEventLoop, set_as_loop


__all__ = ['EventLoop', 'call_repeatedly', 'loop_thread_id']


class EventLoopPolicy(asyncio.AbstractEventLoopPolicy):
    '''Pulsar event loop policy'''
    def get_event_loop(self):
        return thread_data('_event_loop')

    def get_request_loop(self):
        return thread_data('_request_loop') or self.get_event_loop()

    def new_event_loop(self):
        return EventLoop()

    def set_event_loop(self, event_loop):
        """Set the event loop."""
        assert event_loop is None or isinstance(event_loop,
                                                asyncio.AbstractEventLoop)
        if isinstance(event_loop, QueueEventLoop):
            thread_data('_request_loop', event_loop)
        else:
            thread_data('_event_loop', event_loop)


asyncio.set_event_loop_policy(EventLoopPolicy())


Handle = asyncio.Handle
TimerHandle = asyncio.TimerHandle


class LoopingCall(object):

    def __init__(self, loop, callback, args, interval=None):
        self._loop = loop
        self.callback = callback
        self.args = args
        self._cancelled = False
        interval = interval or 0
        if interval > 0:
            self.interval = interval
            self.handler = self._loop.call_later(interval, self)
        else:
            self.interval = None
            self.handler = self._loop.call_soon(self)

    @property
    def cancelled(self):
        return self._cancelled

    def cancel(self):
        '''Attempt to cancel the callback.'''
        self._cancelled = True

    def __call__(self):
        try:
            result = maybe_async(self.callback(*self.args), self._loop)
        except Exception:
            self._loop.logger.exception('Exception in looping callback')
            self.cancel()
            return
        if isinstance(result, Future):
            result.add_done_callback(self._might_continue)
        else:
            self._continue()

    def _continue(self):
        if not self._cancelled:
            handler = self.handler
            loop = self._loop
            if self.interval:
                handler._cancelled = False
                handler._when = loop.time() + self.interval
                loop._add_callback(handler)
            else:
                loop._ready.append(self.handler)

    def _might_continue(self, fut):
        try:
            fut.result()
        except Exception:
            self._loop.logger.exception('Exception in looping callback')
            self.cancel()
        else:
            self._continue()


class EventLoop(asyncio.SelectorEventLoop):
    task_factory = Task

    def __init__(self, selector=None, iothreadloop=False, logger=None):
        super(EventLoop, self).__init__(selector)
        self._iothreadloop = iothreadloop
        self.logger = logger or LOGGER
        self.call_soon(set_as_loop, self)

    def run_in_executor(self, executor, callback, *args):
        return run_in_executor(self, executor, callback, *args)


def call_repeatedly(loop, interval, callback, *args):
    """Call a ``callback`` every ``interval`` seconds.

    It handles asynchronous results. If an error occur in the ``callback``,
    the chain is broken and the ``callback`` won't be called anymore.
    """
    return LoopingCall(loop, callback, args, interval)


def loop_thread_id(loop):
    '''Thread ID of the running ``loop``.
    '''
    waiter = asyncio.Future(loop=loop)
    loop.call_soon_threadsafe(
        lambda: waiter.set_result(current_thread().ident))
    return waiter

########NEW FILE########
__FILENAME__ = events
from collections import deque
from functools import partial

from pulsar.utils.pep import iteritems

from .futures import (Future, maybe_async, InvalidStateError,
                      future_result_exc, AsyncObject)


__all__ = ['EventHandler', 'Event', 'OneTime']


class AbstractEvent(AsyncObject):
    '''Abstract event handler.'''
    _silenced = False
    _handlers = None
    _fired = 0

    @property
    def silenced(self):
        '''Boolean indicating if this event is silenced.

        To silence an event one uses the :meth:`silence` method.
        '''
        return self._silenced

    @property
    def handlers(self):
        if self._handlers is None:
            self._handlers = []
        return self._handlers

    def bind(self, callback):
        '''Bind a ``callback`` to this event.
        '''
        self.handlers.append(callback)

    def fired(self):
        '''The number of times this event has fired'''
        return self._fired

    def fire(self, arg, **kwargs):
        '''Fire this event.'''
        raise NotImplementedError

    def clear(self):
        if self._handlers:
            self._handlers[:] = []

    def silence(self):
        '''Silence this event.

        A silenced event won't fire when the :meth:`fire` method is called.
        '''
        self._silenced = True


class Event(AbstractEvent):
    '''The default implementation of :class:`AbstractEvent`.
    '''
    def __init__(self, loop=None):
        self._loop = loop

    def __repr__(self):
        return repr(self._handlers)
    __str__ = __repr__

    def fire(self, arg, **kwargs):
        if not self._silenced:
            self._fired += self._fired + 1
            if self._handlers:
                for hnd in self._handlers:
                    try:
                        maybe_async(hnd(arg, **kwargs), self._loop)
                    except Exception:
                        self.logger.exception('Exception while firing event')
        return self


class OneTime(Future, AbstractEvent):
    '''An :class:`AbstractEvent` which can be fired once only.

    This event handler is a subclass of :class:`.Future`.
    Implemented mainly for the one time events of the :class:`EventHandler`.
    '''
    @property
    def handlers(self):
        if self._handlers is None:
            self._handlers = deque()
        return self._handlers

    def bind(self, callback):
        '''Bind a ``callback`` to this event.
        '''
        if not self.done():
            self.handlers.append(callback)
        else:
            result, exc = future_result_exc(self)
            self._loop.call_soon(
                lambda: maybe_async(callback(result, exc=exc), self._loop))

    def fire(self, arg, exc=None, **kwargs):
        '''The callback handlers registered via the :meth:~AbstractEvent.bind`
        method are executed first.

        :param arg: the argument
        :param exc: optional exception
        '''
        if not self._silenced:
            if self._fired:
                raise InvalidStateError('already fired')
            self._fired = 1
            self._process(arg, exc, kwargs)
        return self

    def clear(self):
        if self._handlers:
            self._handlers.clear()

    def _process(self, arg, exc, kwargs, future=None):
        while self._handlers:
            hnd = self._handlers.popleft()
            try:
                result = maybe_async(hnd(arg, exc=exc, **kwargs), self._loop)
            except Exception:
                self.logger.exception('Exception while firing event')
            else:
                if isinstance(result, Future):
                    result.add_done_callback(
                        partial(self._process, arg, exc, kwargs))
                    return
        if exc:
            self.set_exception(exc)
        else:
            self.set_result(arg)


class EventHandler(AsyncObject):
    '''A Mixin for handling events.

    It handles :class:`OneTime` events and :class:`Event` that occur
    several times.
    '''
    ONE_TIME_EVENTS = ()
    '''Event names which occur once only.'''
    MANY_TIMES_EVENTS = ()
    '''Event names which occur several times.'''
    def __init__(self, loop=None, one_time_events=None,
                 many_times_events=None):
        one = self.ONE_TIME_EVENTS
        if one_time_events:
            one = set(one)
            one.update(one_time_events)
        events = dict(((name, OneTime(loop=loop)) for name in one))
        many = self.MANY_TIMES_EVENTS
        if many_times_events:
            many = set(many)
            many.update(many_times_events)
        events.update(((name, Event(loop=loop)) for name in many))
        self._events = events

    @property
    def events(self):
        '''The dictionary of all events.
        '''
        return self._events

    def event(self, name):
        '''Returns the :class:`Event` at ``name``.

        If no event is registered for ``name`` returns nothing.
        '''
        event = self._events.get(name)
        if event:
            assert self._loop, "No event loop for %s" % self
            event._loop = self._loop
        return event

    def bind_event(self, name, callback):
        '''Register a ``callback`` with ``event``.

        The callback must be a callable accepting one positional parameter
        and at least the ``exc`` optional parameter::

            def callback(arg, ext=None):
                ...

            o.bind_event('start', callback)

        the instance firing the event or the first positional argument
        passed to the :meth:`fire_event` method.

        :param name: the event name. If the event is not available a warning
            message is logged.
        :param callback: a callable receiving one positional parameter. It
            can also be a list/tuple of callables.
        :return: nothing.
        '''
        if name not in self._events:
            self._events[name] = Event()
        event = self._events[name]
        event.bind(callback)

    def bind_events(self, **events):
        '''Register all known events found in ``events`` key-valued parameters.

        The events callbacks can be specified as a single callable or as
        list/tuple of callabacks or (callback, erroback) tuples.
        '''
        for name in self._events:
            if name in events:
                callbacks = events[name]
                self.bind_event(name, events[name])

    def fire_event(self, name, *args, **kwargs):
        """Dispatches ``arg`` or ``self`` to event ``name`` listeners.

        * If event at ``name`` is a one-time event, it makes sure that it was
          not fired before.

        :param args: optional argument passed as positional parameter to the
            event handler.
        :param kwargs: optional key-valued parameters to pass to the event
            handler. Can only be used for
            :ref:`many times events <many-times-event>`.
        :return: the :class:`Event` fired
        """
        if not args:
            arg = self
        elif len(args) == 1:
            arg = args[0]
        else:
            raise TypeError('fire_event expected at most 1 argument got %s' %
                            len(args))
        event = self.event(name)
        if event:
            try:
                event.fire(arg, **kwargs)
            except InvalidStateError:
                self.logger.error('Event %s already fired' % name)
            return event
        else:
            self.logger.warning('Unknown event "%s" for %s', name, self)

    def silence_event(self, name):
        '''Silence event ``name``.

        This causes the event not to fire at the :meth:`fire_event` method
        is invoked with the event ``name``.
        '''
        event = self._events.get(name)
        if event:
            event.silence()

    def copy_many_times_events(self, other):
        '''Copy :ref:`many times events <many-times-event>` from  ``other``.

        All many times events of ``other`` are copied to this handler
        provided the events handlers already exist.
        '''
        if isinstance(other, EventHandler):
            events = self._events
            for name, event in iteritems(other._events):
                if isinstance(event, Event) and event._handlers:
                    ev = events.get(name)
                    # If the event is available add it
                    if ev:
                        for callback in event._handlers:
                            ev.bind(callback)

########NEW FILE########
__FILENAME__ = futures
import sys
import traceback
import types
import asyncio
from collections import deque, namedtuple, Mapping
from inspect import isgeneratorfunction
from functools import wraps, partial

from pulsar.utils.pep import iteritems, default_timer, range

from .consts import MAX_ASYNC_WHILE
from .access import (get_request_loop, get_event_loop, logger, LOGGER,
                     _PENDING, _CANCELLED, _FINISHED)


CancelledError = asyncio.CancelledError
TimeoutError = asyncio.TimeoutError
InvalidStateError = asyncio.InvalidStateError
Future = asyncio.Future
GeneratorType = types.GeneratorType
ASYNC_OBJECTS = (Future, GeneratorType)

__all__ = ['Future',
           'CancelledError',
           'TimeoutError',
           'InvalidStateError',
           'FutureTypeError',
           'Return',
           'coroutine_return',
           'add_async_binding',
           'maybe_async',
           'run_in_loop',
           'async',
           'add_errback',
           'add_callback',
           'future_timeout',
           'task_callback',
           'multi_async',
           'async_while',
           'in_loop',
           'task',
           'wait_complete',
           'chain_future',
           'ASYNC_OBJECTS',
           'future_result_exc',
           'AsyncObject']


class FutureTypeError(TypeError):
    '''raised when invoking ``async`` on a wrong type.'''


if hasattr(asyncio, 'Return'):
    Return = asyncio.Return

else:

    class Return(StopIteration):

        def __init__(self, *value):
            StopIteration.__init__(self)
            if not value:
                self.value = None
            elif len(value) == 1:
                self.value = value[0]
            else:
                self.value = value
            self.raised = False

        def __del__(self):
            if not self.raised:
                asyncio.log.logger.error(
                    'Return(%r) used without raise', self.value)


def coroutine_return(*value):
    error = Return(*value)
    error.raised = True
    raise error


def add_errback(future, callback, loop=None):
    '''Add a ``callback`` to a ``future`` executed only if an exception
    or cancellation has occurred.'''
    def _error_back(fut):
        if fut._exception:
            callback(fut.exception())
        elif fut.cancelled():
            callback(CancelledError())

    future = async(future, loop=None)
    future.add_done_callback(_error_back)
    return future


def add_callback(future, callback, loop=None):
    '''Add a ``callback`` to ``future`` executed only if an exception
    has not occurred.'''
    def _call_back(fut):
        if not (fut._exception or fut.cancelled()):
            callback(fut.result())

    future = async(future, loop=None)
    future.add_done_callback(_call_back)
    return future


def future_timeout(future, timeout, exc_class=None):
    '''Add a ``timeout`` to ``future``.

    :return: the future
    '''
    exc_class = exc_class or TimeoutError

    def _check_timeout():
        if not future.done():
            future.set_exception(exc_class())

    future._loop.call_later(timeout, _check_timeout)

    return future


def chain_future(future, callback=None, errback=None, next=None, timeout=None):
    '''Chain a :class:`asyncio.Future` to an existing ``future``.

    This function `chain` the ``next`` future to an existing ``future``.
    When the input ``future`` receive a result the optional
    ``callback`` is executed and its result set as the results of ``next``.
    If an exception occurs the optional ``errback`` is executed.

    :param future: the original :class:`asyncio.Future` (can be a coroutine)
    :param callback: optional callback to execute on the result of ``future``
    :param errback: optional callback to execute on the exception of ``future``
    :param next: optional :class:`asyncio.Future` to chain.
        If not provided a new future is created
    :param timeout: optional timeout to set on ``next``
    :return: the future ``next``
    '''
    future = async(future)
    if next is None:
        next = Future(loop=future._loop)
        if timeout and timeout > 0:
            future_timeout(next, timeout)
    else:
        assert timeout is None, 'cannot set timeout'

    def _callback(fut):
        try:
            try:
                exc = future.exception()
            except CancelledError as e:
                exc = e
            if exc:
                if errback:
                    exc = None
                    result = errback(result)
            else:
                result = future.result()
                if callback:
                    result = callback(result)
        except Exception as exc:
            next.set_exception(exc)
        else:
            if exc:
                next.set_exception(exc)
            elif isinstance(result, Future):
                chain(result, next=next)
            else:
                next.set_result(result)

    future.add_done_callback(_callback)
    return next


def as_exception(fut):
    if fut._state == _CANCELLED:
        return CancelledError()
    elif fut._exception:
        return fut.exception()


def future_result_exc(future):
    '''Return a two elements tuple containing the future result and exception.

    The :class:`.Future` must be ``done``
    '''
    if future._state == _CANCELLED:
        return None, CancelledError()
    elif future._exception:
        return None, fut.exception()
    else:
        return future.result(), None


def task_callback(callback):

    @wraps(callback)
    def _task_callback(fut):
        return async(callback(fut.result()), fut._loop)

    return _task_callback


def async(coro_or_future, loop=None):
    '''Handle an asynchronous ``coro_or_future``.

    Equivalent to the ``asyncio.async`` function but returns a
    :class:`.Future`. Raises :class:`.FutureTypeError` if ``value``
    is not a generator nor a :class:`.Future`.

    :parameter coro_or_future: the value to convert to a :class:`.Future`.
    :parameter loop: optional :class:`.EventLoop`.
    :return: a :class:`.Future`.
    '''
    if _bindings:
        for binding in _bindings:
            d = binding(coro_or_future, loop)
            if d is not None:
                return d
    if isinstance(coro_or_future, Future):
        return coro_or_future
    elif isinstance(coro_or_future, GeneratorType):
        loop = loop or get_request_loop()
        task_factory = getattr(loop, 'task_factory', Task)
        return task_factory(coro_or_future, loop=loop)
    else:
        raise FutureTypeError


def maybe_async(value, loop=None):
    '''Handle a possible asynchronous ``value``.

    Return an :ref:`asynchronous instance <tutorials-coroutine>`
    only if ``value`` is a generator, a :class:`.Future`.

    :parameter value: the value to convert to an asynchronous instance
        if it needs to.
    :parameter loop: optional :class:`.EventLoop`.
    :return: a :class:`.Future` or a synchronous ``value``.
    '''
    try:
        return async(value, loop)
    except FutureTypeError:
        return value


def task(method):
    '''Decorator to run a ``method`` returning a coroutine in the event loop
    of the instance of the bound ``method``.

    The instance must be an :ref:`async object <async-object>`.
    '''
    assert isgeneratorfunction(method)

    @wraps(method)
    def _(self, *args, **kwargs):
        loop = self._loop
        task_factory = getattr(loop, 'task_factory', Task)
        coro = method(self, *args, **kwargs)
        future = task_factory(coro, loop=loop)
        if not getattr(loop, '_iothreadloop', True) and not loop.is_running():
            return loop.run_until_complete(future)
        else:
            return future

    return _


def wait_complete(method):
    '''Decorator to wait for a ``method`` to complete.

    It only affects asynchronous object with a local event loop.
    '''
    @wraps(method)
    def _(self, *args, **kwargs):
        loop = self._loop
        result = method(self, *args, **kwargs)
        if not getattr(loop, '_iothreadloop', True) and not loop.is_running():
            return loop.run_until_complete(async(result, loop=loop))
        else:
            return result

    return _


def run_in_loop(loop, callback, *args, **kwargs):
    '''Run ``callable`` in the event ``loop`` thread.

    Return a :class:`.Future`
    '''
    def _():
        result = callback(*args, **kwargs)
        try:
            future = async(result, loop=loop)
        except FutureTypeError:
            coroutine_return(result)
        else:
            result = yield future
            coroutine_return(result)

    return getattr(loop, 'task_factory', Task)(_(), loop=loop)


def in_loop(method):
    '''Decorator to run a method in the event loop of the instance of
    the bound ``method``.

    The instance must be an :ref:`async object <async-object>`.
    '''
    @wraps(method)
    def _(self, *args, **kwargs):
        return run_in_loop(self._loop, method, self, *args, **kwargs)

    return _


def multi_async(iterable=None, loop=None, **kwargs):
    '''Utility to convert an ``iterable`` over possible asynchronous
    components into a :class:`~asyncio.Future` which results in an iterable
    of results.

    The ``iterable`` can be:

    * a ``list``, ``tuple`` or a ``generator``: in this case
      the returned future will result in a ``list``
    * a :class:`~collections.abc.Mapping` instance: in this case
      the returned future will result in a ``dict``
    '''
    return MultiFuture(loop, iterable, **kwargs)


def async_while(timeout, while_clause, *args):
    '''The asynchronous equivalent of ``while while_clause(*args):``

    Use this function within a :ref:`coroutine <coroutine>` when you need
    to wait ``while_clause`` to be satisfied.

    :parameter timeout: a timeout in seconds after which this function stop.
    :parameter while_clause: while clause callable.
    :parameter args: optional arguments to pass to the ``while_clause``
        callable.
    :return: A :class:`.Future`.
    '''
    loop = get_event_loop()

    def _():
        start = loop.time()
        di = 0.1
        interval = 0
        result = while_clause(*args)
        while result:
            interval = min(interval+di, MAX_ASYNC_WHILE)
            try:
                yield asyncio.sleep(interval, loop)
            except TimeoutError:
                pass
            if timeout and loop.time() - start >= timeout:
                break
            result = while_clause(*args)
        coroutine_return(result)

    return async(_(), loop)


class Bench:
    '''Execute a given number of asynchronous requests and wait for results.
    '''
    start = None
    '''The :meth:`~asyncio.BaseEventLoop.time` when the execution starts'''
    finish = None
    '''The :meth:`~asyncio.BaseEventLoop.time` when the execution finishes'''
    result = ()
    '''Tuple of results'''

    def __init__(self, times, loop=None):
        self._loop = loop or get_event_loop()
        self.times = times

    @property
    def taken(self):
        '''The total time taken for execution
        '''
        if self.finish:
            return self.finish - self.start

    def __call__(self, func, *args, **kwargs):
        self.start = self._loop.time()
        self.result = MultiFuture(
            self._loop, (func(*args, **kwargs) for t in range(self.times)))
        return chain_future(self.result, callback=self._done)

    def _done(self, result):
        self.finish = self._loop.time()
        self.result = tuple(result)
        return self


class AsyncObject(object):
    '''Interface for :ref:`async objects <async-object>`

    .. attribute:: _loop

        The event loop associated with this object
    '''
    _logger = None
    _loop = None

    @property
    def logger(self):
        '''The logger for this object
        '''
        return self._logger or getattr(self._loop, 'logger', LOGGER)

    def timeit(self, method, times, *args, **kwargs):
        '''Useful utility for benchmarking an asynchronous ``method``.

        :param method: the name of the ``method`` to execute
        :param times: number of times to execute the ``method``
        :param args: positional arguments to pass to the ``method``
        :param kwargs: key-valued arguments to pass to the ``method``
        :return: a :class:`~asyncio.Future` which results in a :class:`Bench`
            object if successful

        The usage is simple::

            >>> b = self.timeit('asyncmethod', 100)
        '''
        bench = Bench(times, loop=self._loop)
        return bench(getattr(self, method), *args, **kwargs)


class Task(asyncio.Task):
    '''A modified ``asyncio`` :class:`.Task`.

    It has the following features:

    * handles both ``yield`` and ``yield from``
    * tolerant of synchronous values
    '''
    _current_tasks = {}

    def _step(self, value=None, exc=None):
        assert not self.done(), \
            '_step(): already done: {!r}, {!r}, {!r}'.format(self, value, exc)
        if self._must_cancel:
            if not isinstance(exc, CancelledError):
                exc = CancelledError()
            self._must_cancel = False
        coro = self._coro
        self._fut_waiter = None
        sync = True
        self.__class__._current_tasks[self._loop] = self
        #
        try:
            while sync:
                sync = False
                try:
                    if exc:
                        result = coro.throw(exc)
                    elif value is not None:
                        result = coro.send(value)
                    else:
                        result = next(coro)
                    # handle possibly asynchronous results
                    try:
                        result = async(result, self._loop)
                    except FutureTypeError:
                        pass
                except Return as exc:
                    exc.raised = True
                    self.set_result(exc.value)
                except StopIteration as e:
                    self.set_result(getattr(e, 'value', None))
                except Exception as exc:
                    self.set_exception(exc)
                except BaseException as exc:
                    self.set_exception(exc)
                    raise
                else:
                    if isinstance(result, Future):
                        result._blocking = False
                        result.add_done_callback(self._wakeup)
                        self._fut_waiter = result
                        if self._must_cancel:
                            if self._fut_waiter.cancel():
                                self._must_cancel = False
                    elif result is None:
                        # transfer control to the event loop
                        self._loop.call_soon(self._step)
                    else:
                        # Go again
                        value, exc, sync = result, None, True
        finally:
            self.__class__._current_tasks.pop(self._loop)
        self = None

    def _wakeup(self, future, inthread=False):
        if inthread or future._loop is self._loop:
            try:
                exc = future.exception()
            except CancelledError as e:
                exc = e
            if exc:
                self._step(exc=exc)
            else:
                self._step(future.result())
        else:
            self._loop.call_soon_threadsafe(self._wakeup, future, True)
        self = None


# ############################################################## MultiFuture
class MultiFuture(Future):

    def __init__(self, loop, data, type=None, raise_on_error=True):
        super(MultiFuture, self).__init__(loop=loop)
        self._futures = {}
        self._failures = []
        self._raise_on_error = raise_on_error
        if not type:
            type = data.__class__ if data is not None else list
        if issubclass(type, Mapping):
            data = iteritems(data)
        else:
            type = list
            data = enumerate(data)
        self._stream = type()
        for key, value in data:
            value = self._get_set_item(key, maybe_async(value, self._loop))
            if isinstance(value, Future):
                self._futures[key] = value
                value.add_done_callback(partial(self._future_done, key))
            elif self._state != _PENDING:
                break
        self._check()

    @property
    def failures(self):
        return self._failures

    #    INTERNALS
    def _check(self):
        if not self._futures and self._state == _PENDING:
            self.set_result(self._stream)

    def _future_done(self, key, future, inthread=False):
        if inthread or future._loop is self._loop:
            self._futures.pop(key, None)
            if self._state == _PENDING:
                self._get_set_item(key, future)
                self._check()
        else:
            self._loop.call_soon(self._future_done, key, future, True)

    def _get_set_item(self, key, value):
        if isinstance(value, Future):
            if value._state != _PENDING:
                exc = as_exception(value)
                if exc:
                    if self._raise_on_error:
                        self._futures.clear()
                        self.set_exception(exc)
                        return
                    else:
                        self._failures.append(exc)
                        value = exc
                else:
                    value = value._result
        stream = self._stream
        if isinstance(stream, list) and key == len(stream):
            stream.append(value)
        else:
            stream[key] = value
        return value


def add_async_binding(callable):
    global _bindings
    _bindings.append(callable)


_bindings = []

########NEW FILE########
__FILENAME__ = mailbox
'''Actors communicate with each other by sending and receiving messages.
The :mod:`pulsar.async.mailbox` module implements the message passing layer
via a bidirectional socket connections between the :class:`.Arbiter`
and any :class:`.Actor`.

Message sending is asynchronous and safe, the message is guaranteed to
eventually reach the recipient, provided that the recipient exists.

The implementation details are outlined below:

* Messages are sent via the :func:`.send` function, which is a proxy for
  the actor :meth:`~.Actor.send` method.
  Here is how you ping actor ``abc`` in a coroutine::

      from pulsar import send

      def example():
          result = yield send('abc', 'ping')

* The :class:`.Arbiter` :attr:`~pulsar.Actor.mailbox` is a :class:`.TcpServer`
  accepting connections from remote actors.
* The :attr:`.Actor.mailbox` is a :class:`.MailboxClient` of the arbiter
  mailbox server.
* When an actor sends a message to another actor, the arbiter mailbox behaves
  as a proxy server by routing the message to the targeted actor.
* Communication is bidirectional and there is **only one connection** between
  the arbiter and any given actor.
* Messages are encoded and decoded using the unmasked websocket protocol
  implemented in :func:`.frame_parser`.
* If, for some reasons, the connection between an actor and the arbiter
  get broken, the actor will eventually stop running and garbaged collected.


Implementation
=========================
  For the curious this is how the internal protocol is implemented

Protocol
~~~~~~~~~~~~

.. autoclass:: MailboxProtocol
  :members:
  :member-order: bysource

Client
~~~~~~~~~~~~

.. autoclass:: MailboxClient
  :members:
  :member-order: bysource

'''
import sys
import logging
import socket
import pickle
from collections import namedtuple

from pulsar import ProtocolError, CommandError
from pulsar.utils.internet import nice_address
from pulsar.utils.websocket import frame_parser
from pulsar.utils.security import gen_unique_id

from .access import get_actor
from .futures import Future, coroutine_return, task
from .proxy import actorid, get_proxy, get_command, ActorProxy
from .protocols import Protocol
from .clients import AbstractClient


LOGGER = logging.getLogger('pulsar.mailbox')
CommandRequest = namedtuple('CommandRequest', 'actor caller connection')


def command_in_context(command, caller, actor, args, kwargs):
    cmnd = get_command(command)
    if not cmnd:
        raise CommandError('unknown %s' % command)
    request = CommandRequest(actor, caller, None)
    return cmnd(request, args, kwargs)


class ProxyMailbox(object):
    '''A proxy for the arbiter :class:`Mailbox`.
    '''
    active_connections = 0

    def __init__(self, actor):
        mailbox = actor.monitor.mailbox
        if isinstance(mailbox, ProxyMailbox):
            mailbox = mailbox.mailbox
        self.mailbox = mailbox

    def __repr__(self):
        return self.mailbox.__repr__()

    def __str__(self):
        return self.mailbox.__str__()

    def __getattr__(self, name):
        return getattr(self.mailbox, name)

    def _run(self):
        pass

    def close(self):
        pass


class Message(object):
    '''A message which travels from actor to actor.
    '''
    def __init__(self, data, future=None):
        self.data = data
        self.future = future

    def __repr__(self):
        return self.data.get('command', 'unknown')
    __str__ = __repr__

    @classmethod
    def command(cls, command, sender, target, args, kwargs):
        command = get_command(command)
        data = {'command': command.__name__,
                'sender': actorid(sender),
                'target': actorid(target),
                'args': args if args is not None else (),
                'kwargs': kwargs if kwargs is not None else {}}
        if command.ack:
            future = Future()
            data['ack'] = gen_unique_id()[:8]
        else:
            future = None
        return cls(data, future)

    @classmethod
    def callback(cls, result, ack):
        data = {'command': 'callback', 'result': result, 'ack': ack}
        return cls(data)


class MailboxProtocol(Protocol):
    '''The :class:`.Protocol` for internal message passing between actors.

    Encoding and decoding uses the unmasked websocket protocol.
    '''
    def __init__(self, **kw):
        super(MailboxProtocol, self).__init__(**kw)
        self._pending_responses = {}
        self._parser = frame_parser(kind=2, pyparser=True)
        actor = get_actor()
        if actor.is_arbiter():
            self.bind_event('connection_lost', self._connection_lost)

    def request(self, command, sender, target, args, kwargs):
        '''Used by the server to send messages to the client.'''
        req = Message.command(command, sender, target, args, kwargs)
        self._start(req)
        return req.future

    def data_received(self, data):
        # Feed data into the parser
        msg = self._parser.decode(data)
        while msg:
            try:
                message = pickle.loads(msg.body)
            except Exception as e:
                raise ProtocolError('Could not decode message body: %s' % e)
            self._on_message(message)
            msg = self._parser.decode()

    ########################################################################
    #    INTERNALS
    def _start(self, req):
        if req.future and 'ack' in req.data:
            self._pending_responses[req.data['ack']] = req.future
            try:
                self._write(req)
            except Exception as exc:
                req.future.set_exception(exc)
        else:
            self._write(req)

    def _connection_lost(self, _, exc=None):
        if exc:
            actor = get_actor()
            if actor.is_running():
                actor.logger.warning('Connection lost with actor.')

    @task
    def _on_message(self, message):
        actor = get_actor()
        command = message.get('command')
        ack = message.get('ack')
        if command == 'callback':
            if not ack:
                raise ProtocolError('A callback without id')
            try:
                pending = self._pending_responses.pop(ack)
            except KeyError:
                raise KeyError('Callback %s not in pending callbacks' % ack)
            pending.set_result(message.get('result'))
        else:
            try:
                target = actor.get_actor(message['target'])
                if target is None:
                    raise CommandError('cannot execute "%s", unknown actor '
                                       '"%s"' % (command, message['target']))
                # Get the caller proxy without throwing
                caller = get_proxy(actor.get_actor(message['sender']),
                                   safe=True)
                if isinstance(target, ActorProxy):
                    # route the message to the actor proxy
                    if caller is None:
                        raise CommandError(
                            "'%s' got message from unknown '%s'"
                            % (actor, message['sender']))
                    result = yield actor.send(target, command,
                                              *message['args'],
                                              **message['kwargs'])
                else:
                    actor = target
                    command = get_command(command)
                    req = CommandRequest(target, caller, self)
                    result = yield command(req, message['args'],
                                           message['kwargs'])
            except CommandError as exc:
                self.logger.warning('Command error: %s' % exc)
                result = None
            except Exception as exc:
                self.logger.exception('Unhandled exception')
                result = None
            if ack:
                self._start(Message.callback(result, ack))

    def _write(self, req):
        obj = pickle.dumps(req.data, protocol=2)
        data = self._parser.encode(obj, opcode=2)
        try:
            self._transport.write(data)
        except socket.error:
            actor = get_actor()
            if actor.is_running():
                if actor.is_arbiter():
                    raise
                else:
                    actor.logger.warning('Lost connection with arbiter')
                    actor._loop.stop()


class MailboxClient(AbstractClient):
    '''Used by actors to send messages to other actors via the arbiter.
    '''
    protocol_factory = MailboxProtocol

    def __init__(self, address, actor, loop):
        super(MailboxClient, self).__init__(loop)
        self.address = address
        self.name = 'Mailbox for %s' % actor
        self._connection = None

    def response(self, request):
        resp = super(MailboxClient, self).response
        self._consumer = resp(request, self._consumer, False)
        return self._consumer

    def connect(self):
        return self.create_connection(self.address)

    def __repr__(self):
        return '%s %s' % (self.name, nice_address(self.address))

    @task
    def request(self, command, sender, target, args, kwargs):
        # the request method
        if self._connection is None:
            self._connection = yield self.connect()
            self._connection.bind_event('connection_lost', self._lost)
        req = Message.command(command, sender, target, args, kwargs)
        self._connection._start(req)
        response = yield req.future
        coroutine_return(response)

    def start_serving(self):
        pass

    def close(self):
        if self._connection:
            self._connection.close()

    def _lost(self, _, exc=None):
        self._loop.stop()

########NEW FILE########
__FILENAME__ = monitor
import sys
from time import time

from pulsar import Config
from pulsar.utils.pep import iteritems, itervalues, range
from pulsar.utils.security import gen_unique_id

from .proxy import actor_proxy_future
from .actor import Actor
from .futures import async_while
from .concurrency import concurrency
from .consts import *


__all__ = ['Monitor', 'PoolMixin']


def _spawn_actor(cls, monitor, cfg=None, name=None, aid=None, **kw):
    # Internal function which spawns a new Actor and return its
    # ActorProxyMonitor.
    # *cls* is the Actor class
    # *monitor* can be either the arbiter or a monitor
    kind = None
    if issubclass(cls, PoolMixin):
        kind = 'monitor'
    if monitor:
        params = monitor.actorparams()
        name = params.pop('name', name)
        aid = params.pop('aid', aid)
        cfg = params.pop('cfg', cfg)

    # get config if not available
    if cfg is None:
        if monitor:
            cfg = monitor.cfg.copy()
        else:
            cfg = Config()

    if not monitor:  # monitor not available, this is the arbiter
        if kind != 'monitor':
            raise TypeError('class %s not a valid monitor' % cls)
        kind = 'arbiter'
        params = {}
        if not cfg.exc_id:
            if not aid:
                aid = gen_unique_id()[:8]
            cfg.set('exc_id', aid)
    #
    for key, value in iteritems(kw):
        if key in cfg.settings:
            cfg.set(key, value)
        else:
            params[key] = value
    #
    if monitor:
        if not kind:
            if not issubclass(cls, Actor):
                raise TypeError('Class %s not a valid actor.' % cls)
            kind = cfg.concurrency
    if not kind:
        raise TypeError('Cannot spawn class %s. not a valid concurrency.'
                        % cls)
    actor_proxy = concurrency(kind, cls, monitor, cfg, name=name,
                              aid=aid, **params)
    # Add to the list of managed actors if this is a remote actor
    if isinstance(actor_proxy, Actor):
        return actor_proxy
    else:
        actor_proxy.monitor = monitor
        monitor.managed_actors[actor_proxy.aid] = actor_proxy
        future = actor_proxy_future(actor_proxy)
        actor_proxy.start()
        return future


class PoolMixin(Actor):
    '''A mixin for :class:`.Actor` which manages a pool (group) of actors.

    It is used by both the :class:`Arbiter` and the :class:`Monitor` classes.

    .. attribute:: managed_actors

        dictionary with keys given by actor's ids and values by
        :class:`.ActorProxyMonitor` instances. These are the actors
        managed by the pool.

    .. attribute:: terminated_actors

        list of :class:`.ActorProxyMonitor` which have been terminated
        (the remote actor did not have a cleaned shutdown).
    '''
    CLOSE_TIMEOUT = 30000000000000
    actor_class = Actor
    '''The class derived form :class:`Actor` which the monitor manages
    during its life time.

    Default: :class:`Actor`'''

    def __init__(self, impl):
        super(PoolMixin, self).__init__(impl)
        self.managed_actors = {}
        self.terminated_actors = []

    def get_actor(self, aid):
        aid = getattr(aid, 'aid', aid)
        if aid == self.aid:
            return self
        elif aid in self.managed_actors:
            return self.managed_actors[aid]
        elif self.monitor and aid == self.monitor.aid:
            return self.monitor

    def spawn(self, actor_class=None, **params):
        '''Spawn a new :class:`Actor` and return its
        :class:`.ActorProxyMonitor`.
        '''
        actor_class = actor_class or self.actor_class
        return _spawn_actor(actor_class, self, **params)

    def actorparams(self):
        '''Returns a dictionary of parameters for spawning actors.

        The disctionary is passed to the spawn method when creating new
        actors. Fire the :ref:`on_params actor hook <actor-hooks>`.
        '''
        data = {}
        self.fire_event('on_params', params=data)
        return data

    def _remove_actor(self, actor, log=True):
        removed = self.managed_actors.pop(actor.aid, None)
        if log and removed:
            log = False
            self.logger.warning('Removing %s', actor)
        if self.monitor:
            self.monitor._remove_actor(actor, log)
        return removed

    def manage_actors(self, stop=False):
        '''Remove :class:`Actor` which are not alive from the
        :class:`PoolMixin.managed_actors` and return the number of actors
        still alive.

        :parameter stop: if ``True`` stops all alive actor.
        '''
        alive = 0
        if self.managed_actors:
            for aid, actor in list(iteritems(self.managed_actors)):
                alive += self.manage_actor(actor, stop)
        return alive

    def manage_actor(self, actor, stop=False):
        '''If an actor failed to notify itself to the arbiter for more than
        the timeout, stop the actor.

        :param actor: the :class:`Actor` to manage.
        :param stop: if ``True``, stop the actor.
        :return: if the actor is alive 0 if it is not.
        '''
        if not self.is_running():
            stop = True
        if not actor.is_alive():
            if not actor.should_be_alive() and not stop:
                return 1
            actor.join()
            self._remove_actor(actor)
            return 0
        timeout = None
        started_stopping = bool(actor.stopping_start)
        # if started_stopping is True, set stop to True
        stop = stop or started_stopping
        if not stop and actor.notified:
            gap = time() - actor.notified
            stop = timeout = gap > actor.cfg.timeout
        if stop:   # we are stopping the actor
            dt = actor.should_terminate()
            if not actor.mailbox or dt:
                if not actor.mailbox:
                    self.logger.warning('Terminating %s. No mailbox.', actor)
                else:
                    self.logger.warning('Terminating %s. Could not stop after'
                                        ' %.2f seconds.', actor, dt)
                actor.terminate()
                self.terminated_actors.append(actor)
                self._remove_actor(actor)
                return 0
            elif not started_stopping:
                if timeout:
                    self.logger.warning('Stopping %s. Timeout %.2f',
                                        actor, timeout)
                else:
                    self.logger.info('Stopping %s.', actor)
                self.send(actor, 'stop')
        return 1

    def spawn_actors(self):
        '''Spawn new actors if needed. If the :class:`PoolMixin` is spawning
do nothing.'''
        to_spawn = self.cfg.workers - len(self.managed_actors)
        if self.cfg.workers and to_spawn > 0:
            for _ in range(to_spawn):
                self.spawn()

    def stop_actors(self):
        """Maintain the number of workers by spawning or killing as required
        """
        if self.cfg.workers:
            num_to_kill = len(self.managed_actors) - self.cfg.workers
            for i in range(num_to_kill, 0, -1):
                w, kage = 0, sys.maxsize
                for worker in itervalues(self.managed_actors):
                    age = worker.impl.age
                    if age < kage:
                        w, kage = w, age
                self.manage_actor(w, True)

    def close_actors(self):
        '''Close all managed :class:`Actor`.'''
        return async_while(2*ACTOR_ACTION_TIMEOUT, self.manage_actors, True)


class Monitor(PoolMixin):
    '''A monitor is a **very** special :class:`.Actor`.

    it is a :class:`.PoolMixin` which shares the same event loop
    with the :class:`.Arbiter` and therefore lives in the main thread
    of the master process domain.

    The Arbiter manages monitors which in turn manage a set of :class:`.Actor`
    performing similar tasks.

    In other words, you may have a monitor managing actors for serving HTTP
    requests on a given port, another monitor managing actors consuming tasks
    from a task queue and so forth. You can think of :class:`.Monitor` as
    managers of pools of :class:`.Actor`.

    Monitors are created by invoking the :meth:`.Arbiter.add_monitor`
    functions and not by directly invoking the constructor. Therefore
    adding a new monitor to the arbiter follows the pattern::

        import pulsar

        m = pulsar.arbiter().add_monitor('mymonitor')
    '''
    @property
    def arbiter(self):
        return self.monitor

    def is_monitor(self):
        return True

    def monitor_task(self):
        '''Monitor specific task.

        Called by the :meth:`.MonitorConcurrency.periodic_task` method.
        By default it does nothing. Override if you need to.
        '''
        pass

    def info(self):
        info = super(Monitor, self).info()
        if self.started():
            info['actor'].update({'concurrency': self.cfg.concurrency,
                                  'workers': len(self.managed_actors)})
            info['workers'] = [a.info for a in itervalues(self.managed_actors)
                               if a.info]
        return info

    def get_actor(self, aid):
        # Delegate get_actor to the arbiter
        a = super(Monitor, self).get_actor(aid)
        if a is None:
            a = self.monitor.get_actor(aid)
        return a

########NEW FILE########
__FILENAME__ = protocols
import sys
from functools import partial

import pulsar
from pulsar.utils.internet import nice_address, format_address

from .futures import multi_async, in_loop, task, coroutine_return
from .events import EventHandler
from .access import asyncio, get_event_loop, new_event_loop


__all__ = ['ProtocolConsumer',
           'Protocol',
           'DatagramProtocol',
           'Connection',
           'Producer',
           'TcpServer',
           'DatagramServer']


BIG = 2**31


class ProtocolConsumer(EventHandler):
    '''The consumer of data for a server or client :class:`Connection`.

    It is responsible for receiving incoming data from an end point via the
    :meth:`Connection.data_received` method, decoding (parsing) and,
    possibly, writing back to the client or server via
    the :attr:`transport` attribute.

    .. note::

        For server consumers, :meth:`data_received` is the only method
        to implement.
        For client consumers, :meth:`start_request` should also be implemented.

    A :class:`ProtocolConsumer` is a subclass of :class:`.EventHandler` and it
    has two default :ref:`one time events <one-time-event>`:

    * ``pre_request`` fired when the request is received (for servers) or
      just before is sent (for clients).
      This occurs just before the :meth:`start_request` method.
    * ``post_request`` fired when the request is done. The
      :attr:`on_finished` attribute is a shortcut for the ``post_request``
      :class:`.OneTime` event and therefore can be used to wait for
      the request to have received a full response (clients).

    In addition, it has two :ref:`many times events <many-times-event>`:

    * ``data_received`` fired when new data is received from the transport but
      not yet processed (before the :meth:`data_received` method is invoked)
    * ``data_processed`` fired just after data has been consumed (after the
      :meth:`data_received` method)

    .. note::

        A useful example on how to use the ``data_received`` event is
        the :ref:`wsgi proxy server <tutorials-proxy-server>`.
    '''
    _connection = None
    _data_received_count = 0
    ONE_TIME_EVENTS = ('pre_request', 'post_request')
    MANY_TIMES_EVENTS = ('data_received', 'data_processed')

    @property
    def connection(self):
        '''The :class:`Connection` of this consumer.'''
        return self._connection

    @property
    def _loop(self):
        '''The event loop of this consumer.

        The same as the :attr:`connection` event loop.
        '''
        if self._connection:
            return self._connection._loop

    @property
    def request(self):
        '''The request.

        Used for clients only and available only after the
        :meth:`start` method is invoked.
        '''
        return getattr(self, '_request', None)

    @property
    def transport(self):
        '''The :class:`Transport` of this consumer'''
        if self._connection:
            return self._connection.transport

    @property
    def address(self):
        if self._connection:
            return self._connection.address

    @property
    def producer(self):
        '''The :class:`Producer` of this consumer.'''
        if self._connection:
            return self._connection.producer

    @property
    def on_finished(self):
        '''The ``post_request`` one time event.
        '''
        return self.event('post_request')

    def connection_made(self, connection):
        '''Called by a :class:`Connection` when it starts using this consumer.

        By default it does nothing.
        '''

    def data_received(self, data):
        '''Called when some data is received.

        **This method must be implemented by subclasses** for both server and
        client consumers.

        The argument is a bytes object.
        '''

    def start_request(self):
        '''Starts a new request.

        Invoked by the :meth:`start` method to kick start the
        request with remote server. For server :class:`ProtocolConsumer` this
        method is not invoked at all.

        **For clients this method should be implemented** and it is critical
        method where errors caused by stale socket connections can arise.
        **This method should not be called directly.** Use :meth:`start`
        instead. Typically one writes some data from the :attr:`request`
        into the transport. Something like this::

            self.transport.write(self.request.encode())
        '''
        raise NotImplementedError

    def start(self, request=None):
        '''Starts processing the request for this protocol consumer.

        There is no need to override this method,
        implement :meth:`start_request` instead.
        If either :attr:`connection` or :attr:`transport` are missing, a
        :class:`RuntimeError` occurs.

        For server side consumer, this method simply fires the ``pre_request``
        event.'''
        if hasattr(self, '_request'):
            raise RuntimeError('Consumer already started')
        conn = self._connection
        if not conn:
            raise RuntimeError('Cannot start new request. No connection.')
        if not conn._transport:
            raise RuntimeError('%s has no transport.' % conn)
        conn._processed += 1
        if conn._producer:
            p = getattr(conn._producer, '_requests_processed', 0)
            conn._producer._requests_processed = p + 1
        self.bind_event('post_request', self._finished)
        self._request = request
        self.fire_event('pre_request')
        if self._request is not None:
            try:
                self.start_request()
            except Exception as exc:
                self.finished(exc=exc)

    def connection_lost(self, exc):
        '''Called by the :attr:`connection` when the transport is closed.

        By default it calls the :meth:`finished` method. It can be overwritten
        to handle the potential exception ``exc``.'''
        return self.finished(exc)

    def finished(self, *arg, **kw):
        '''Fire the ``post_request`` event if it wasn't already fired.
        '''
        if not self.event('post_request').fired():
            return self.fire_event('post_request', *arg, **kw)

    def _data_received(self, data):
        # Called by Connection, it updates the counters and invoke
        # the high level data_received method which must be implemented
        # by subclasses
        if not hasattr(self, '_request'):
            self.start()
        self._data_received_count = self._data_received_count + 1
        self.fire_event('data_received', data=data)
        result = self.data_received(data)
        self.fire_event('data_processed', data=data)
        return result

    def _finished(self, _, exc=None):
        c = self._connection
        if c and c._current_consumer is self:
            c._current_consumer = None


class PulsarProtocol(EventHandler):
    '''A mixin class for both :class:`.Protocol` and
    :class:`.DatagramProtocol`.

    A :class:`PulsarProtocol` is an :class:`.EventHandler` which has
    two :ref:`one time events <one-time-event>`:

    * ``connection_made``
    * ``connection_lost``
    '''
    ONE_TIME_EVENTS = ('connection_made', 'connection_lost')

    _transport = None
    _idle_timeout = None
    _address = None
    _type = 'server'

    def __init__(self, session=1, producer=None, timeout=0):
        super(PulsarProtocol, self).__init__()
        self._session = session
        self._timeout = timeout
        self._producer = producer
        self.bind_event('connection_lost', self._cancel_timeout)

    def __repr__(self):
        address = self._address
        if address:
            return '%s %s session %s' % (self._type, nice_address(address),
                                         self._session)
        else:
            return '<pending> session %s' % self._session
    __str__ = __repr__

    @property
    def session(self):
        '''Connection session number.

        Passed during initialisation by the :attr:`producer`.
        Usually an integer representing the number of separate connections
        the producer has processed at the time it created this
        :class:`Protocol`.
        '''
        return self._session

    @property
    def transport(self):
        '''The :ref:`transport <asyncio-transport>` for this protocol.

        Available once the :meth:`connection_made` is called.'''
        return self._transport

    @property
    def sock(self):
        '''The socket of :attr:`transport`.
        '''
        if self._transport:
            return self._transport.get_extra_info('socket')

    @property
    def address(self):
        '''The address of the :attr:`transport`.
        '''
        return self._address

    @property
    def timeout(self):
        '''Number of seconds to keep alive this connection when idle.

        A value of ``0`` means no timeout.'''
        return self._timeout

    @property
    def _loop(self):
        '''The :attr:`transport` event loop.
        '''
        if self._transport:
            return self._transport._loop

    @property
    def producer(self):
        '''The producer of this :class:`Protocol`.
        '''
        return self._producer

    @property
    def closed(self):
        '''``True`` if the :attr:`transport` is closed.'''
        return self._transport._closing if self._transport else True

    def close(self):
        '''Close by closing the :attr:`transport`.'''
        if self._transport:
            self._transport.close()

    def abort(self):
        '''Abort by aborting the :attr:`transport`.'''
        if self._transport:
            self._transport.abort()

    def connection_made(self, transport):
        '''Sets the :attr:`transport`, fire the ``connection_made`` event
        and adds a :attr:`timeout` for idle connections.
        '''
        if self._transport is not None:
            self._cancel_timeout()
        self._transport = transport
        addr = self._transport.get_extra_info('peername')
        if not addr:
            self._type = 'client'
            addr = self._transport.get_extra_info('sockname')
        self._address = addr
        # let everyone know we have a connection with endpoint
        self.fire_event('connection_made')
        self._add_idle_timeout()

    def connection_lost(self, exc=None):
        '''Fires the ``connection_lost`` event.
        '''
        self.fire_event('connection_lost', exc=exc)

    def eof_received(self):
        '''The socket was closed from the remote end'''

    def set_timeout(self, timeout):
        '''Set a new :attr:`timeout` for this connection.'''
        self._cancel_timeout()
        self._timeout = timeout
        self._add_idle_timeout()

    def info(self):
        connection = {'session': self._session,
                      'timeout': self._timeout}
        info = {'connection': connection}
        if self._producer:
            info.update(self._producer.info())
        return info

    ########################################################################
    #    INTERNALS
    def _timed_out(self):
        self.close()
        self.logger.debug('Closed idle %s.', self)

    def _add_idle_timeout(self):
        if not self.closed and not self._idle_timeout and self._timeout:
            self._idle_timeout = self._loop.call_later(self._timeout,
                                                       self._timed_out)

    def _cancel_timeout(self, *args, **kw):
        if self._idle_timeout:
            self._idle_timeout.cancel()
            self._idle_timeout = None


class Protocol(PulsarProtocol, asyncio.Protocol):
    '''An :class:`asyncio.Protocol` with :ref:`events <event-handling>`
    '''


class DatagramProtocol(PulsarProtocol, asyncio.DatagramProtocol):
    '''An ``asyncio.DatagramProtocol`` with events`'''


class Connection(Protocol):
    '''A :class:`Protocol` to handle multiple request/response.

    It is a class which acts as bridge between a
    :ref:`transport <asyncio-transport>` and a :class:`.ProtocolConsumer`.
    It routes data arriving from the transport to the
    :meth:`current_consumer`.

    .. attribute:: _consumer_factory

        A factory of :class:`.ProtocolConsumer`.

    .. attribute:: _processed

        number of separate requests processed.
    '''
    _current_consumer = None

    def __init__(self, consumer_factory=None, **kw):
        super(Connection, self).__init__(**kw)
        self._processed = 0
        self._consumer_factory = consumer_factory
        self.bind_event('connection_lost', self._connection_lost)

    def current_consumer(self):
        '''The :class:`ProtocolConsumer` currently handling incoming data.

        This instance will receive data when this connection get data
        from the :attr:`~Protocol.transport` via the :meth:`data_received`
        method.
        '''
        if self._current_consumer is None:
            self._build_consumer(None)
        return self._current_consumer

    def set_consumer(self, consumer):
        assert self._current_consumer is None, 'Consumer is not None'
        self._current_consumer = consumer
        consumer._connection = self
        consumer.connection_made(self)

    def data_received(self, data):
        '''Delegates handling of data to the :meth:`current_consumer`.

        Once done set a timeout for idle connections when a
        :attr:`~Protocol.timeout` is a positive number (of seconds).
        '''
        self._cancel_timeout()
        while data:
            consumer = self.current_consumer()
            data = consumer._data_received(data)
        self._add_idle_timeout()

    def upgrade(self, consumer_factory):
        '''Upgrade the :func:`_consumer_factory` callable.

        This method can be used when the protocol specification changes
        during a response (an example is a WebSocket request/response,
        or HTTP tunneling).

        This method adds a ``post_request`` callback to the
        :meth:`current_consumer` to build a new consumer with the new
        :func:`_consumer_factory`.

        :param consumer_factory: the new consumer factory (a callable
            accepting no parameters)
        :return: ``None``.
        '''
        self._consumer_factory = consumer_factory
        consumer = self._current_consumer
        if consumer:
            consumer.bind_event('post_request', self._build_consumer)
        else:
            self._build_consumer(None)

    def info(self):
        info = super(Connection, self).info()
        connection = info['connection']
        connection.update({'request_processed': self._processed})
        return info

    def _build_consumer(self, _, exc=None):
        if not exc:
            consumer = self._producer.build_consumer(self._consumer_factory)
            self.set_consumer(consumer)

    def _connection_lost(self, conn, exc=None):
        '''It performs these actions in the following order:

        * Fires the ``connection_lost`` :ref:`one time event <one-time-event>`
          if not fired before, with ``exc`` as event data.
        * Cancel the idle timeout if set.
        * Invokes the :meth:`ProtocolConsumer.connection_lost` method in the
          :meth:`current_consumer`.
          '''
        if conn._current_consumer:
            conn._current_consumer.connection_lost(exc)


class Producer(EventHandler):
    '''An Abstract :class:`.EventHandler` class for all producers of
    connections.
    '''
    _requests_processed = 0
    _sessions = 0

    protocol_factory = None
    '''A callable producing protocols.

    The signature of the protocol factory callable must be::

        protocol_factory(session, producer, **params)
    '''

    def __init__(self, loop):
        self._loop = loop or get_event_loop() or new_event_loop()
        super(Producer, self).__init__(self._loop)

    @property
    def sessions(self):
        '''Total number of protocols created by the :class:`Producer`.
        '''
        return self._sessions

    @property
    def requests_processed(self):
        '''Total number of requests processed.
        '''
        return self._requests_processed

    def create_protocol(self):
        '''Create a new protocol via the :meth:`protocol_factory`

        This method increase the count of :attr:`sessions` and build
        the protocol passing ``self`` as the producer.
        '''
        self._sessions = session = self._sessions + 1
        return self.protocol_factory(session=session, producer=self)

    def build_consumer(self, consumer_factory):
        '''Build a consumer for a protocol.

        This method can be used by protocols which handle several requests,
        for example the :class:`Connection` class.

        :param consumer_factory: consumer factory to use.
        '''
        consumer = consumer_factory()
        consumer.copy_many_times_events(self)
        return consumer


class TcpServer(Producer):
    '''A :class:`Producer` of server :class:`Connection` for TCP servers.

    .. attribute:: _server

        A :class:`.Server` managed by this Tcp wrapper.

        Available once the :meth:`start_serving` method has returned.
    '''
    ONE_TIME_EVENTS = ('start', 'stop')
    MANY_TIMES_EVENTS = ('connection_made', 'pre_request', 'post_request',
                         'connection_lost')
    _server = None
    _started = None

    def __init__(self, protocol_factory, loop, address=None,
                 name=None, sockets=None, max_connections=None,
                 keep_alive=None):
        super(TcpServer, self).__init__(loop)
        self.protocol_factory = protocol_factory
        self._name = name or self.__class__.__name__
        self._params = {'address': address, 'sockets': sockets}
        self._max_connections = max_connections
        self._keep_alive = keep_alive
        self._concurrent_connections = set()

    def __repr__(self):
        address = self.address
        if address:
            return '%s %s' % (self.__class__.__name__, address)
        else:
            return self.__class__.__name__
    __str_ = __repr__

    @property
    def address(self):
        '''Socket address of this server.

        It is obtained from the first socket ``getsockname`` method.
        '''
        if self._server is not None:
            return self._server.sockets[0].getsockname()

    @task
    def start_serving(self, backlog=100, sslcontext=None):
        '''Start serving.

        :param backlog: Number of maximum connections
        :param sslcontext: optional SSLContext object.
        :return: a :class:`.Future` called back when the server is
            serving the socket.'''
        if hasattr(self, '_params'):
            address = self._params['address']
            sockets = self._params['sockets']
            del self._params
            create_server = self._loop.create_server
            try:
                if sockets:
                    server = None
                    for sock in sockets:
                        srv = yield create_server(self.create_protocol,
                                                  sock=sock,
                                                  backlog=backlog,
                                                  ssl=sslcontext)
                        if server:
                            server.sockets.extend(srv.sockets)
                        else:
                            server = srv
                else:
                    if isinstance(address, tuple):
                        server = yield create_server(self.create_protocol,
                                                     host=address[0],
                                                     port=address[1],
                                                     backlog=backlog,
                                                     ssl=sslcontext)
                    else:
                        raise NotImplementedError
                self._server = server
                self._started = self._loop.time()
                for sock in server.sockets:
                    address = sock.getsockname()
                    self.logger.info('%s serving on %s', self._name,
                                     format_address(address))
                self.fire_event('start')
            except Exception as exc:
                self.fire_event('start', exc=exc)

    def stop_serving(self):
        '''Stop serving the :attr:`.Server.sockets`.
        '''
        if self._server:
            server, self._server = self._server, None
            server.close()

    @task
    def close(self):
        '''Stop serving the :attr:`.Server.sockets` and close all
        concurrent connections.
        '''
        if self._server:
            server, self._server = self._server, None
            server.close()
            yield None
            yield self._close_connections()
            self.fire_event('stop')
        coroutine_return(self)

    def info(self):
        sockets = []
        up = int(self._loop.time() - self._started) if self._started else 0
        server = {'pulsar_version': pulsar.__version__,
                  'python_version': sys.version,
                  'uptime_in_seconds': up,
                  'sockets': sockets,
                  'max_connections': self._max_connections,
                  'keep_alive': self._keep_alive}
        clients = {'processed_clients': self._sessions,
                   'connected_clients': len(self._concurrent_connections),
                   'requests_processed': self._requests_processed}
        if self._server:
            for sock in self._server.sockets:
                sockets.append({
                    'address': format_address(sock.getsockname())})
        return {'server': server,
                'clients': clients}

    def create_protocol(self):
        '''Override :meth:`Producer.create_protocol`.
        '''
        self._sessions = session = self._sessions + 1
        protocol = self.protocol_factory(session=session,
                                         producer=self,
                                         timeout=self._keep_alive)
        protocol.bind_event('connection_made', self._connection_made)
        protocol.bind_event('connection_lost', self._connection_lost)
        if (self._server and self._max_connections and
                session >= self._max_connections):
            self.logger.info('Reached maximum number of connections %s. '
                             'Stop serving.' % self._max_connections)
            self.close()
        return protocol

    #    INTERNALS
    def _connection_made(self, connection, exc=None):
        if not exc:
            self._concurrent_connections.add(connection)

    def _connection_lost(self, connection, exc=None):
        self._concurrent_connections.discard(connection)

    def _close_connections(self, connection=None):
        '''Close ``connection`` if specified, otherwise close all connections.

        Return a list of :class:`.Future` called back once the connection/s
        are closed.
        '''
        all = []
        if connection:
            all.append(connection.event('connection_lost'))
            connection.transport.close()
        else:
            connections = list(self._concurrent_connections)
            self._concurrent_connections = set()
            for connection in connections:
                all.append(connection.event('connection_lost'))
                connection.transport.close()
        if all:
            self.logger.info('%s closing %d connections', self, len(all))
            return multi_async(all)


class DatagramServer(EventHandler):
    '''An :class:`.EventHandler` for serving UDP sockets.

    .. attribute:: _transports

        A list of :class:`.DatagramTransport`.

        Available once the :meth:`create_endpoint` method has returned.
    '''
    _transports = None
    _started = None

    ONE_TIME_EVENTS = ('start', 'stop')
    MANY_TIMES_EVENTS = ('pre_request', 'post_request')

    def __init__(self, protocol_factory, loop=None, address=None,
                 name=None, sockets=None, max_requests=None):
        self._loop = loop or get_event_loop()
        super(DatagramServer, self).__init__(self._loop)
        self.protocol_factory = protocol_factory
        self._max_requests = max_requests
        self._requests_processed = 0
        self._name = name or self.__class__.__name__
        self._params = {'address': address, 'sockets': sockets}

    @task
    def create_endpoint(self, **kw):
        '''create the server endpoint.

        :return: a :class:`~asyncio.Future` called back when the server is
            serving the socket.
        '''
        if hasattr(self, '_params'):
            address = self._params['address']
            sockets = self._params['sockets']
            del self._params
            try:
                transports = []
                if sockets:
                    for transport in sockets:
                        proto = self.create_protocol()
                        transports.append(transport(self._loop, proto))
                else:
                    transport, _ = yield self._loop.create_datagram_endpoint(
                        self.protocol_factory, local_addr=adress)
                    transports.append(transport)
                self._transports = transports
                self._started = self._loop.time()
                for transport in self._transports:
                    address = transport.get_extra_info('sockname')
                    self.logger.info('%s serving on %s', self._name,
                                     format_address(address))
                self.fire_event('start')
            except Exception as exc:
                self.logger.exception('Error while starting UDP server')
                self.fire_event('start', exc=exc)
                self.fire_event('stop')

    @in_loop
    def close(self):
        '''Stop serving the :attr:`.Server.sockets` and close all
        concurrent connections.
        '''
        if self._transports:
            transports, self._transports = self._transports, None
            for transport in transports:
                transport.close()
            self.fire_event('stop')
        coroutine_return(self)

    def info(self):
        sockets = []
        up = int(self._loop.time() - self._started) if self._started else 0
        server = {'pulsar_version': pulsar.__version__,
                  'python_version': sys.version,
                  'uptime_in_seconds': up,
                  'sockets': sockets,
                  'max_requests': self._max_requests}
        clients = {'requests_processed': self._requests_processed}
        if self._transports:
            for transport in self._transports:
                sockets.append({
                    'address': format_address(transport._sock.getsockname())})
        return {'server': server,
                'clients': clients}

    def create_protocol(self):
        '''Override :meth:`Producer.create_protocol`.
        '''
        return self.protocol_factory(producer=self)

########NEW FILE########
__FILENAME__ = proxy
from pulsar import CommandNotFound
from pulsar.utils.pep import default_timer

from .futures import Future, chain_future
from .consts import *

__all__ = ['ActorProxy',
           'ActorProxyMonitor',
           'get_proxy',
           'command',
           'get_command']

global_commands_table = {}


def get_proxy(obj, safe=False):
    if isinstance(obj, ActorProxy):
        return obj
    elif hasattr(obj, 'proxy'):
        return get_proxy(obj.proxy)
    else:
        if safe:
            return None
        else:
            raise ValueError('"%s" is not an actor or actor proxy.' % obj)


def actorid(actor):
    return actor.identity() if hasattr(actor, 'identity') else actor


def get_command(name):
    '''Get the command function *name*'''
    command = global_commands_table.get(name.lower())
    if not command:
        raise CommandNotFound(name)
    return command


class command:
    '''Decorator for pulsar command functions.

    :parameter ack: ``True`` if the command acknowledge the sender with a
        response. Usually is set to ``True`` (which is also the default value).
    '''
    def __init__(self, ack=True):
        self.ack = ack

    def __call__(self, f):
        self.name = f.__name__.lower()

        def command_function(request, args, kwargs):
            return f(request, *args, **kwargs)

        command_function.ack = self.ack
        command_function.__name__ = self.name
        command_function.__doc__ = f.__doc__
        global_commands_table[self.name] = command_function
        return command_function


class ActorIdentity(object):

    def identity(self):
        return self.aid


def actor_proxy_future(aid, future=None):
    self = ActorProxyFuture()
    if isinstance(aid, ActorProxyMonitor):
        assert future is None
        aid.callback = self
        self.aid = aid.aid
    else:
        self.aid = aid
        chain_future(future, next=self)
    return self


class ActorProxyFuture(Future, ActorIdentity):
    '''A :class:`.Future` for an :class:`.ActorProxy`.

    The callback will be an :class:`.ActorProxy` which will be received once
    the remote :class:`.Actor` is fully functional.

    .. attribute:: aid

        The the remote :attr:`.Actor` id

    '''
    def __repr__(self):
        if self.done():
            return '%s(%s)' % (self.__class__.__name__, self.aid)
        else:
            return '%s(%s) PENDING' % (self.__class__.__name__, self.aid)
    __str__ = __repr__


class ActorProxy(ActorIdentity):
    '''A proxy for a remote :class:`.Actor`.

    This is a lightweight class which delegates function calls to the
    underlying remote object.

    It is picklable and therefore can be send from actor to actor using
    :ref:`actor message passing <tutorials-messages>`.

    For example, lets say we have a proxy ``a``, to send a message to it::

        from pulsar import send

        send(a, 'echo', 'hello there!')

    will send the :ref:`command <actor_commands>` ``echo`` to actor ``a`` with
    parameter ``"hello there!"``.

    .. attribute:: aid

        Unique ID for the remote :class:`.Actor`

    .. attribute:: address

        the socket address of the underlying :attr:`.Actor.mailbox`.

    '''
    def __init__(self, impl):
        self.aid = impl.aid
        self.name = impl.name
        self.cfg = impl.cfg
        self.address = getattr(impl, 'address', None)

    def __repr__(self):
        return '%s(%s)' % (self.name, self.aid)
    __str__ = __repr__

    @property
    def proxy(self):
        return self

    def __eq__(self, o):
        o = get_proxy(o, True)
        return o and self.aid == o.aid

    def __ne__(self, o):
        return not self.__eq__(o)


class ActorProxyMonitor(ActorProxy):
    '''A specialised :class:`.ActorProxy` class.

    It contains additional information about the remote underlying
    :class:`.Actor`. Instances of this class serialise into
    :class:`.ActorProxy`.

    The :class:`.ActorProxyMonitor` is special since it lives in the
    :class:`.Arbiter` domain and it is used by the :class:`.Arbiter`
    (or a :class:`.Monitor`) to monitor the state of the spawned actor.

    .. attribute:: impl

        The :class:`.Concurrency` instance for the remote :class:`.Actor`. This
        dictionary is constantly updated by the remote actor by sending the
        :ref:`info message <actor_info_command>`.

    .. attribute:: info

        Dictionary of information regarding the remote :class:`.Actor`

    .. attribute:: mailbox

        This is the connection with the remote actor. It is available once the
        :ref:`actor handshake <handshake>` between the actor and the monitor
        has completed. The :attr:`mailbox` is a server-side
        :class:`.MailboxProtocol` instance and it is used
        by the :func:`.send` function to send messages to the remote actor.
    '''
    monitor = None

    def __init__(self, impl):
        self.impl = impl
        self.info = {}
        self.mailbox = None
        self.callback = None
        self.spawning_start = None
        self.stopping_start = None
        super(ActorProxyMonitor, self).__init__(impl)

    @property
    def notified(self):
        '''Last time this :class:`.ActorProxyMonitor` was notified by the
        remote actor.'''
        return self.info.get('last_notified')

    @property
    def pid(self):
        return self.impl.pid

    @property
    def proxy(self):
        '''The :class:`.ActorProxy` for this monitor.'''
        return ActorProxy(self)

    def __reduce__(self):
        return self.proxy.__reduce__()

    def is_alive(self):
        '''``True`` if underlying actor is alive.
        '''
        return self.impl.is_alive()

    def terminate(self):
        '''Terminate life of underlying actor.
        '''
        self.impl.terminate()

    def join(self, timeout=None):
        '''Wait until the underlying actor terminates.

        If ``timeout`` is provided, it raises an exception if the timeout
        is reached.
        '''
        self.impl.join(timeout=timeout)

    def start(self):
        '''Start the remote actor.
        '''
        self.spawning_start = default_timer()
        self.impl.start()

    def should_be_alive(self):
        if not self.mailbox:
            return default_timer() - self.spawning_start > ACTOR_ACTION_TIMEOUT
        else:
            return True

    def should_terminate(self):
        if self.stopping_start is None:
            self.stopping_start = default_timer()
            return False
        else:
            dt = default_timer() - self.stopping_start
            return dt if dt >= ACTOR_ACTION_TIMEOUT else False

########NEW FILE########
__FILENAME__ = threads
import logging
import threading
import weakref
from multiprocessing import dummy, current_process
from functools import partial
from asyncio import selectors, events, get_event_loop, set_event_loop

try:
    import queue
except ImportError:  # pragma nocover
    import Queue as queue
ThreadQueue = queue.Queue
Empty = queue.Empty
Full = queue.Full

from .access import (asyncio, new_event_loop, get_actor, set_actor,
                     thread_data, _StopError, BaseEventLoop)
from .futures import Future, Task, async, AsyncObject
from .consts import ACTOR_STATES


__all__ = ['Thread', 'IOqueue', 'ThreadPool', 'ThreadQueue', 'Empty', 'Full']

_MAX_WORKERS = 5
_threads_queues = weakref.WeakKeyDictionary()
passthrough = lambda: None


def set_as_loop(loop):
    if loop._iothreadloop:
        set_event_loop(loop)


def get_executor(loop):
    executor = loop._default_executor
    if executor is None:
        executor = ThreadPool(loop=loop)
        loop._default_executor = executor
    return executor


def run_in_executor(loop, executor, callback, *args):
    if isinstance(callback, events.Handle):
        assert not args
        assert not isinstance(callback, events.TimerHandle)
        if callback._cancelled:
            f = Future(loop=loop)
            f.set_result(None)
            return f
        callback, args = callback._callback, callback._args
    if executor is None:
        executor = get_executor(loop)
    return executor.submit(callback, *args)


class Thread(dummy.DummyProcess):
    @property
    def pid(self):
        return current_process().pid

    def loop(self):
        raise NotImplemented

    def terminate(self):
        '''Invoke the stop on the event loop method.'''
        if self.is_alive():
            loop = self.loop()
            if loop:
                loop.stop()


class PoolThread(Thread):
    '''A thread for the :class;`.ThreadPool`.
    '''
    def __init__(self, pool):
        self.pool = pool
        super(PoolThread, self).__init__(name=pool.worker_name)

    def __repr__(self):
        if self.ident:
            return '%s-%s' % (self.name, self.ident)
        else:
            return self.name
    __str__ = __repr__

    def run(self):
        '''Modified run method which set the actor and the event_loop.
        '''
        if self.pool._actor:
            set_actor(self.pool._actor)
        asyncio.set_event_loop(self.pool._loop)
        # The run method for the threads in this thread pool
        logger = logging.getLogger('pulsar.%s' % self.name)
        loop = QueueEventLoop(self.pool, logger=logger, iothreadloop=True)
        loop.run_forever()

    def loop(self):
        return thread_data('_request_loop', ct=self)


class IOqueue(selectors.BaseSelector):
    '''A selector based on a distributed queue

    Since there is no way to my knowledge to wake up the queue while
    getting an itiem from the task queue, the timeout cannot be larger than
    a small number which by default is ``0.5`` seconds.
    '''
    max_timeout = 0.5

    def __init__(self, executor):
        super(IOqueue, self).__init__()
        self._actor = executor._actor
        self._work_queue = executor._work_queue
        self._maxtasks = executor._maxtasks
        self._received = 0
        self._completed = 0

    def select(self, timeout=None):
        if self._actor and self._actor.state > ACTOR_STATES.RUN:
            raise _StopError
        if self._maxtasks and self._received >= self._maxtasks:
            if self._completed < self._received:
                return ()
            else:
                raise _StopError
        block = True
        if timeout is None:
            timeout = self.max_timeout
        elif timeout <= 0:
            timeout = 0
            block = False
        else:
            timeout = min(self.max_timeout, timeout)
        try:
            task = self._work_queue.get(block=block, timeout=timeout)
        except (Empty, TypeError):
            return ()
        except (EOFError, IOError):
            raise _StopError
        if task is None:    # got the sentinel, exit!
            self._work_queue.put(None)
            raise _StopError
        return task

    def process_task(self, task):
        self._received += 1
        future, func, args, kwargs = task
        try:
            result = yield func(*args, **kwargs)
        except Exception as exc:
            self._completed += 1
            future.set_exception(exc)
        else:
            self._completed += 1
            try:
                future.set_result(result)
            finally:
                # IMPORTANT: make sure to wake up the loop of the
                # waiting future
                future._loop.call_soon_threadsafe(passthrough)

    def get_map(self):
        return {}

    def register(self, fileobj, events, data=None):
        pass

    def unregister(self, fileobj):
        pass


class QueueEventLoop(BaseEventLoop):
    task_factory = Task

    def __init__(self, executor, iothreadloop=False, logger=None):
        super(QueueEventLoop, self).__init__()
        self._default_executor = executor
        self._iothreadloop = iothreadloop
        self._selector = IOqueue(executor)
        self.logger = logger or LOGGER
        self.call_soon(set_as_loop, self)

    def _write_to_self(self):
        pass

    def _process_events(self, task):
        if task:
            async(self._selector.process_task(task), self)

    def run_in_executor(self, executor, callback, *args):
        return run_in_executor(self, executor, callback, *args)


class ThreadPool(AsyncObject):
    '''A thread pool for an actor.

    This pool maintains a group of threads to perform asynchronous tasks via
    the :meth:`submit` method.
    '''
    worker_name = 'exec'

    def __init__(self, max_workers=None, actor=None, loop=None,
                 maxtasks=None):
        self._actor = actor or get_actor()
        if self._actor:
            loop = loop or self._actor._loop
            if not max_workers:
                max_workers = self._actor.cfg.thread_workers
            self.worker_name = '%s.%s' % (self._actor.name, self.worker_name)
        self._loop = loop or get_event_loop()
        self._max_workers = min(max_workers or _MAX_WORKERS, _MAX_WORKERS)
        self._threads = set()
        self._maxtasks = maxtasks
        self._work_queue = ThreadQueue()
        self._shutdown = False
        self._shutdown_lock = threading.Lock()

    def submit(self, func, *args, **kwargs):
        '''Equivalent to ``func(*args, **kwargs)``.

        This method create a new task for function ``func`` and adds it to
        the queue.
        Return a :class:`~asyncio.Future` called back once the task
        has finished.
        '''
        with self._shutdown_lock:
            if self._shutdown:
                raise RuntimeError(
                    'cannot schedule new futures after shutdown')
            future = Future(loop=self._loop)
            self._work_queue.put((future, func, args, kwargs))
            self._adjust_thread_count()
            return future

    def shutdown(self, wait=True):
        with self._shutdown_lock:
            self._shutdown = True
            self._work_queue.put(None)
        if wait:
            for t in self._threads:
                t.join()

    def _adjust_thread_count(self):
        if len(self._threads) < self._max_workers:
            t = PoolThread(self)
            t.daemon = True
            t.start()
            self._threads.add(t)
            _threads_queues[t] = self._work_queue

########NEW FILE########
__FILENAME__ = tracelogger
import sys
import logging
import traceback
from collections import namedtuple


logger = logging.getLogger('pulsar')
async_exec_info = namedtuple('async_exec_info', 'error_class error trace')
log_exc_info = ('error', 'critical')


def is_relevant_tb(tb):
    return '__skip_traceback__' not in tb.tb_frame.f_locals


def tb_length(tb):
    length = 0
    while tb and is_relevant_tb(tb):
        length += 1
        tb = tb.tb_next
    return length


def format_exception(exctype, value, tb):
    trace = getattr(value, '__traceback__', None)
    while tb and not is_relevant_tb(tb):
        tb = tb.tb_next
    length = tb_length(tb)
    if length or not trace:
        tb = traceback.format_exception(exctype, value, tb, length)
    if trace:
        if tb:
            tb = tb[:-1]
            tb.extend(trace[1:])
        else:
            tb = trace
    value.__traceback__ = tb
    return tb


def _tarceback_list(exctype, value, tb, trace=None):
    while tb and not is_relevant_tb(tb):
        tb = tb.tb_next
    length = tb_length(tb)
    if length or not trace:
        tb = traceback.format_exception(exctype, value, tb, length)
    if trace:
        if tb:
            tb = tb[:-1]
            tb.extend(trace[1:])
        else:
            tb = trace
    return tb


if sys.version_info >= (3, 0):

    def format_traceback(exc):
        return _tarceback_list(exc.__class__, exc, exc.__traceback__)

    class _TracebackLogger:
        __slots__ = ['exc', 'tb']

        def __init__(self, exc):
            self.exc = exc
            self.tb = None

        def activate(self):
            exc = self.exc
            if exc is not None:
                self.exc = None
                self.tb = traceback.format_exception(exc.__class__, exc,
                                                     exc.__traceback__)

        def clear(self):
            self.exc = None
            self.tb = None

        def __del__(self):
            if self.tb:
                logger.error('Future/Task exception was never retrieved:\n%s',
                             ''.join(self.tb))

else:  # pragma    nocover

    def format_traceback(exc):
        return getattr(exc, '__traceback__', [])

    class _TracebackLogger:
        __slots__ = ['exc', 'tb']

        def __init__(self, exc):
            self.exc = exc
            self.tb = format_exception(*sys.exc_info())

        def activate(self):
            self.exc = None

        def clear(self):
            self.exc = None
            self.tb = None

        def __del__(self):
            if self.tb and self.exc is None:
                logger.error('Future/Task exception was never retrieved:\n%s',
                             ''.join(self.tb))

########NEW FILE########
__FILENAME__ = config
'''Configuration utilities which provides pulsar with configuration parameters
which can be parsed from the command line. Parsing is implemented using
the python argparser_ standard library module.

Config
~~~~~~~~~~

.. autoclass:: Config
   :members:
   :member-order: bysource

Setting
~~~~~~~~~~

.. autoclass:: Setting
   :members:
   :member-order: bysource


.. _argparser: http://docs.python.org/dev/library/argparse.html
'''
import inspect
import argparse
import os
import textwrap
import logging

from pulsar import __version__, SERVER_NAME
from . import system
from .internet import parse_address
from .importer import import_system_file
from .httpurl import HttpParser as PyHttpParser
from .log import configured_logger
from .pep import to_bytes, iteritems, native_str, pickle


__all__ = ['Config',
           'Setting',
           'ordered_settings',
           'validate_string',
           'validate_callable',
           'validate_bool',
           'validate_list',
           'validate_dict',
           'validate_pos_int',
           'validate_pos_float',
           'make_optparse_options']

LOGGER = logging.getLogger('pulsar.config')

section_docs = {}
KNOWN_SETTINGS = {}
KNOWN_SETTINGS_ORDER = []


def pass_through(arg):
    '''A dummy function accepting one parameter only.

It does nothing and it is used as default by
:ref:`Application Hooks <setting-section-application-hooks>`.'''
    pass


def set_if_avail(container, key, value, *skip_values):
    if value is not None and value not in skip_values:
        container[key] = value


def wrap_method(func):
    def _wrapped(instance, *args, **kwargs):
        return func(*args, **kwargs)
    return _wrapped


def ordered_settings():
    for name in KNOWN_SETTINGS_ORDER:
        yield KNOWN_SETTINGS[name]


class Config(object):
    '''A dictionary-like container of :class:`Setting` parameters for
    fine tuning pulsar servers.

    It provides easy access to :attr:`Setting.value`
    attribute by exposing the :attr:`Setting.name` as attribute.

    :param description: description used when parsing the command line,
        same usage as in the :class:`argparse.ArgumentParser` class.
    :param epilog: epilog used when parsing the command line, same usage
        as in the :class:`argparse.ArgumentParser` class.
    :param version: version used when parsing the command line, same usage
        as in the :class:`argparse.ArgumentParser` class.
    :param apps: list of application namespaces to include in the
        :attr:`settings` dictionary. For example if ``apps`` is set to
        ``['socket', 'tasks']``, the
        :ref:`socket server <setting-section-socket-servers>` and
        :ref:`task queue <setting-section-task-consumer>` settings are
        loaded in addition to the standard
        :ref:`global settings <setting-section-global-server-settings>`,
        :ref:`worker settings <setting-section-worker-processes>` and
        :ref:`hook settings <setting-section-application-hooks>`.

    .. attribute:: settings

        Dictionary of all :class:`Setting` instances available in this
        :class:`Config` container.

        Keys are given by the :attr:`Setting.name` attribute.

    .. attribute:: params

        Dictionary of additional parameters which cannot be parsed in the
        command line.
    '''
    script = None
    application = None
    exclude_from_config = set(('config',))

    def __init__(self, description=None, epilog=None,
                 version=None, apps=None, include=None,
                 exclude=None, settings=None, prefix=None,
                 name=None, log_name=None, **params):
        self.settings = {} if settings is None else settings
        self.name = name
        self.log_name = log_name
        self.prefix = prefix
        self.include = set(include or ())
        self.exclude = set(exclude or ())
        self.apps = set(apps or ())
        if settings is None:
            self.update_settings()
        self.params = {}
        self.description = description or 'Pulsar server'
        self.epilog = epilog or 'Have fun!'
        self.version = version or __version__
        self.update(params, True)

    def __iter__(self):
        return iter(self.settings)

    def __len__(self):
        return len(self.settings)

    def __contains__(self, name):
        return name in self.settings

    def items(self):
        for k, setting in iteritems(self.settings):
            yield k, setting.value

    def __getstate__(self):
        return self.__dict__.copy()

    def __setstate__(self, state):
        for k, v in state.items():
            self.__dict__[k] = v
        config = getattr(self, 'config', None)
        if config:
            self.import_from_module(config)

    def __getattr__(self, name):
        try:
            return self._get(name)
        except KeyError:
            raise AttributeError("'%s' object has no attribute '%s'." %
                                 (self.__class__.__name__, name))

    def __setattr__(self, name, value):
        if name != "settings" and name in self.settings:
            raise AttributeError("Invalid access!")
        super(Config, self).__setattr__(name, value)

    def update(self, data, default=False):
        '''Update this :attr:`Config` with ``data``.

        :param data: must be a ``Mapping`` like object exposing the ``item``
            method for iterating through key-value pairs.
        :param default: if ``True`` the updated :attr:`settings` will also
            set their :attr:`~Setting.default` attribute with the
            updating value (provided it is a valid one).
        '''
        for name, value in data.items():
            if value is not None:
                self.set(name, value, default)

    def copy_globals(self, cfg):
        '''Copy global settings from ``cfg`` to this config.

        The settings are copied only if they were not already modified.
        '''
        for name, setting in cfg.settings.items():
            csetting = self.settings.get(name)
            if (setting.is_global and csetting is not None and
                    not csetting.modified):
                csetting.set(setting.get())

    def get(self, name, default=None):
        '''Get the value at ``name`` for this :class:`Config` container

        The returned value is obtained from:

        * the value at ``name`` in the :attr:`settings` dictionary
          if available.
        * the value at ``name`` in the :attr:`params` dictionary if available.
        * the ``default`` value.
        '''
        try:
            return self._get(name, default)
        except KeyError:
            return default

    def set(self, name, value, default=False):
        '''Set the :class:`Setting` at ``name`` with a new ``value``.

        If ``default`` is ``True``, the :attr:`Setting.default` is also set.
        '''
        if name in self.__dict__:
            self.__dict__[name] = value
        elif name not in self.settings:
            # not in settings, check if this is a prefixed name
            if self.prefix:
                prefix_name = '%s_%s' % (self.prefix, name)
                if prefix_name in self.settings:
                    return  # don't set this value
            self.params[name] = value
        else:
            self.settings[name].set(value, default=default)

    def parser(self):
        '''Create the argparser_ for this configuration by adding all
        settings via the :meth:`Setting.add_argument` method.

        :rtype: an instance of :class:`ArgumentParser`.
        '''
        kwargs = {
            "description": self.description,
            "epilog": self.epilog
        }
        parser = argparse.ArgumentParser(**kwargs)
        parser.add_argument('--version',
                            action='version',
                            version=self.version)
        return self.add_to_parser(parser)

    def add_to_parser(self, parser):
        '''Add this container :attr:`settings` to an existing ``parser``.
        '''
        setts = self.settings
        sorter = lambda x: (setts[x].section, setts[x].order)
        for k in sorted(setts, key=sorter):
            setts[k].add_argument(parser)
        return parser

    def import_from_module(self, mod=None):
        if mod:
            self.set('config', mod)
        try:
            mod = import_system_file(self.config)
        except Exception as e:
            raise RuntimeError('Failed to read config file "%s". %s' %
                               (self.config, e))
        unknowns = []
        if mod:
            for k in dir(mod):
                # Skip private functions and attributes
                kl = k.lower()
                if k.startswith('_') or kl in self.exclude_from_config:
                    continue
                val = getattr(mod, k)
                # add unknown names to list
                if kl not in self.settings:
                    unknowns.append((k, val))
                else:
                    self.set(kl, val)
        return unknowns

    def on_start(self):
        '''Invoked by a :class:`.Application` just before starting.
        '''
        for sett in self.settings.values():
            sett.on_start()

    def app(self):
        if self.application:
            return self.application.from_config(self)

    @property
    def workers(self):
        return self.settings['workers'].get()

    @property
    def address(self):
        '''An address to bind to, only available if a
        :ref:`bind <setting-bind>` setting has been added to this
        :class:`Config` container.
        '''
        bind = self.settings.get('bind')
        if bind:
            return parse_address(to_bytes(bind.get()))

    @property
    def uid(self):
        user = self.settings.get('user')
        if user:
            return system.get_uid(user.get())

    @property
    def gid(self):
        group = self.settings.get('group')
        if group:
            return system.get_gid(group.get())

    @property
    def proc_name(self):
        pn = self.settings.get('process_name')
        if pn:
            pn = pn.get()
        if pn is not None:
            return pn
        else:
            pn = self.settings.get('default_process_name')
            if pn:
                return pn.get()

    def copy(self, name=None, prefix=None):
        '''A copy of this :class:`Config` container.

        If ``prefix`` is given, it prefixes all non
        :ref:`global settings <setting-section-global-server-settings>`
        with it. Used when multiple applications are loaded.
        '''
        cls = self.__class__
        me = cls.__new__(cls)
        me.__dict__.update(self.__dict__)
        if prefix:
            me.prefix = prefix
        settings = me.settings
        me.settings = {}
        for setting in settings.values():
            setting = setting.copy(name, prefix)
            me.settings[setting.name] = setting
        me.params = me.params.copy()
        return me

    def clone(self):
        return pickle.loads(pickle.dumps(self))

    def configured_logger(self, name=None):
        '''Configured logger.
        '''
        loggers = {}
        loghandlers = self.loghandlers
        if not name and self.log_name:
            name = self.log_name
        else:
            name = 'pulsar.%s' % (name or self.name)
        default_loglevel = None
        for loglevel in self.loglevel or ():
            bits = loglevel.split('.')
            loglevel = bits[-1]
            if len(bits) > 1:
                namespace = '.'.join(bits[:-1])
            else:
                namespace = name
            if namespace in loggers:
                continue
            logger = configured_logger(namespace,
                                       config=self.logconfig,
                                       level=loglevel,
                                       handlers=loghandlers)
            loggers[namespace] = logger
            if namespace == 'pulsar' or default_loglevel is None:
                default_loglevel = logger.level

        default_loglevel = asyncio_loglevel = default_loglevel or 0
        if asyncio_loglevel:
            asyncio_loglevel = max(asyncio_loglevel,
                                   logging._checkLevel('WARNING'))
        for namespace, loglevel in (('pulsar', default_loglevel),
                                    (name, default_loglevel),
                                    ('asyncio', asyncio_loglevel)):
            if namespace not in loggers:
                loggers[namespace] = configured_logger(namespace,
                                                       config=self.logconfig,
                                                       level=loglevel,
                                                       handlers=loghandlers)
        return loggers[name]

    def __copy__(self):
        return self.copy()

    def __deepcopy__(self, memo):
        return self.copy()

    ########################################################################
    #    INTERNALS
    def update_settings(self):
        for s in ordered_settings():
            setting = s().copy(name=self.name, prefix=self.prefix)
            if setting.name in self.settings:
                continue
            if setting.name not in self.include:
                if setting.name in self.exclude:
                    continue    # setting name in exclude set
                if setting.app and setting.app not in self.apps:
                    continue    # the setting is for an app not in the apps set
            self.settings[setting.name] = setting

    def _get(self, name, default=None):
        if name not in self.settings:
            if name in self.params:
                return self.params[name]
            if name in KNOWN_SETTINGS:
                return default
            raise KeyError("'%s'" % name)
        return self.settings[name].get()


class SettingMeta(type):
    '''A metaclass which collects all setting classes and put them
    in the global ``KNOWN_SETTINGS`` list.'''
    def __new__(cls, name, bases, attrs):
        super_new = super(SettingMeta, cls).__new__
        # parents = [b for b in bases if isinstance(b, SettingMeta)]
        val = attrs.get("validator")
        attrs["validator"] = wrap_method(val) if val else None
        if attrs.pop('virtual', False):
            return super_new(cls, name, bases, attrs)
        attrs["order"] = len(KNOWN_SETTINGS) + 1
        new_class = super_new(cls, name, bases, attrs)
        # build one instance to increase count
        new_class()
        new_class.fmt_desc(attrs['desc'] or '')
        if not new_class.name:
            new_class.name = new_class.__name__.lower()
        if new_class.name in KNOWN_SETTINGS_ORDER:
            old_class = KNOWN_SETTINGS.pop(new_class.name)
            new_class.order = old_class.order
        else:
            KNOWN_SETTINGS_ORDER.append(new_class.name)
        KNOWN_SETTINGS[new_class.name] = new_class
        return new_class

    def fmt_desc(cls, desc):
        desc = textwrap.dedent(desc).strip()
        setattr(cls, "desc", desc)
        lines = desc.split('\n\n')
        setattr(cls, "short", '' if not lines else lines[0])


# This works for Python 2 and Python 3
class Setting(SettingMeta('BaseSettings', (object,), {'virtual': True})):
    '''Class for creating :ref:`pulsar settings <settings>`.

    Most parameters can be specified on the command line,
    all of them on a ``config`` file.
    '''
    creation_count = 0
    virtual = True
    '''If set to ``True`` the settings won't be loaded.

    It can be only used as base class for other settings.'''
    name = None
    '''The key to access this setting in a :class:`Config` container.'''
    validator = None
    '''A validating function for this setting.

    It provided it must be a function accepting one positional argument,
    the value to validate.'''
    value = None
    '''The actual value for this setting.'''
    default = None
    '''The default value for this setting.'''
    nargs = None
    '''The number of command-line arguments that should be consumed'''
    const = None
    '''A constant value required by some action and nargs selections'''
    app = None
    '''Setting for a specific :class:`Application`.'''
    section = None
    '''Setting section, used for creating the
    :ref:`settings documentation <settings>`.'''
    flags = None
    '''List of options strings, e.g. ``[-f, --foo]``.'''
    choices = None
    '''Restrict the argument to the choices provided.'''
    type = None
    '''The type to which the command-line argument should be converted'''
    meta = None
    '''Same usage as ``metavar`` in the python :mod:`argparse` module. It is
    the name for the argument in usage message.'''
    action = None
    '''The basic type of action to be taken when this argument is encountered
    at the command line'''
    short = None
    '''Optional shot description string'''
    desc = None
    '''Description string'''
    is_global = False
    '''``True`` only for
    :ref:`global settings <setting-section-global-server-settings>`.'''
    orig_name = None

    def __init__(self, name=None, flags=None, action=None, type=None,
                 default=None, nargs=None, desc=None, validator=None,
                 app=None, meta=None, choices=None, const=None):
        self.extra = e = {}
        self.app = app or self.app
        set_if_avail(e, 'choices', choices or self.choices)
        set_if_avail(e, 'const', const or self.const)
        set_if_avail(e, 'type', type or self.type, 'string')
        self.default = default if default is not None else self.default
        self.desc = desc or self.desc
        self.flags = flags or self.flags
        self.action = action or self.action
        self.meta = meta or self.meta
        self.name = name or self.name
        self.nargs = nargs or self.nargs
        self.short = self.short or self.desc
        self.desc = self.desc or self.short
        if self.default is not None:
            self.set(self.default)
        if self.app and not self.section:
            self.section = self.app
        if not self.section:
            self.section = 'unknown'
        self.__class__.creation_count += 1
        if not hasattr(self, 'order'):
            self.order = 1000 + self.__class__.creation_count
        self.modified = False

    def __getstate__(self):
        return self.__dict__.copy()

    def __str__(self):
        return '{0} ({1})'.format(self.name, self.value)
    __repr__ = __str__

    def on_start(self):
        '''Called when pulsar server starts.

        It can be used to perform custom initialization for this
        :class:`Setting`.
        '''
        pass

    def get(self):
        '''Returns :attr:`value`'''
        return self.value

    def set(self, val, default=False):
        '''Set ``val`` as the :attr:`value` for this :class:`Setting`.

        If ``default`` is ``True`` set also the :attr:`default` value.
        '''
        if hasattr(self.validator, '__call__'):
            val = self.validator(val)
        self.value = val
        if default:
            self.default = val
        self.modified = True

    def add_argument(self, parser, set_default=False):
        '''Add this :class:`Setting` to the ``parser``.

        The operation is carried out only if :attr:`flags` or
        :attr:`nargs` and :attr:`name` are defined.
        '''
        default = self.default if set_default else None
        kwargs = {'nargs': self.nargs}
        kwargs.update(self.extra)
        if self.flags:
            args = tuple(self.flags)
            kwargs.update({'dest': self.name,
                           'action': self.action or "store",
                           'default': default,
                           'help': "%s [%s]" % (self.short, self.default)})
            if kwargs["action"] != "store":
                kwargs.pop("type", None)
                kwargs.pop("nargs", None)
        elif self.nargs and self.name:
            args = (self.name,)
            kwargs.update({'metavar': self.meta or None,
                           'help': self.short})
        else:
            # Not added to argparser
            return
        if self.meta:
            kwargs['metavar'] = self.meta
        parser.add_argument(*args, **kwargs)

    def copy(self, name=None, prefix=None):
        '''Copy this :class:`SettingBase`'''
        setting = self.__class__.__new__(self.__class__)
        setting.__dict__.update(self.__dict__)
        # Keep the modified flag?
        # setting.modified = False
        if prefix and not setting.is_global:
            flags = setting.flags
            if flags and flags[-1].startswith('--'):
                # Prefix a setting
                setting.orig_name = setting.name
                setting.name = '%s_%s' % (prefix, setting.name)
                setting.flags = ['--%s-%s' % (prefix, flags[-1][2:])]
        if name and not setting.is_global:
            setting.short = '%s application. %s' % (name, setting.short)
        return setting

    def __copy__(self):
        return self.copy()

    def __deepcopy__(self, memo):
        return self.copy()


class TestOption(Setting):
    virtual = True
    app = 'test'
    section = "Test"


def validate_bool(val):
    if isinstance(val, bool):
        return val
    val = native_str(val)
    if not isinstance(val, str):
        raise TypeError("Invalid type for casting: %s" % val)
    if val.lower().strip() == "true":
        return True
    elif val.lower().strip() == "false":
        return False
    else:
        raise ValueError("Invalid boolean: %s" % val)


def validate_pos_int(val):
    if not isinstance(val, int):
        val = int(val, 0)
    else:
        # Booleans are ints!
        val = int(val)
    if val < 0:
        raise ValueError("Value must be positive: %s" % val)
    return val


def validate_pos_float(val):
    val = float(val)
    if val < 0:
        raise ValueError("Value must be positive: %s" % val)
    return val


def validate_string(val):
    va = native_str(val)
    if va is None:
        return None
    if not isinstance(va, str):
        raise TypeError("Not a string: %s" % val)
    return va.strip()


def validate_list(val):
    if val and not isinstance(val, (list, tuple)):
        raise TypeError("Not a list: %s" % val)
    return list(val)


def validate_dict(val):
    if val and not isinstance(val, dict):
        raise TypeError("Not a dictionary: %s" % val)
    return val


def validate_callable(arity):
    def _validate_callable(val):
        if not hasattr(val, '__call__'):
            raise TypeError("Value is not callable: %s" % val)
        if not inspect.isfunction(val):
            cval = val.__call__
            discount = 1
        else:
            discount = 0
            cval = val
        result = inspect.getargspec(cval)
        nargs = len(result.args) - discount
        if result.defaults:
            group = tuple(range(nargs-len(result.defaults), nargs+1))
        else:
            group = (nargs,)
        if arity not in group:
            raise TypeError("Value must have an arity of: %s" % arity)
        return val
    return _validate_callable


def make_optparse_options(apps=None, exclude=None, include=None):
    '''Create a tuple of optparse options.'''
    from optparse import make_option

    class AddOptParser(list):
        def add_argument(self, *args, **kwargs):
            self.append(make_option(*args, **kwargs))

    config = Config(apps=apps, exclude=exclude, include=include)
    parser = AddOptParser()
    config.add_to_parser(parser)
    return tuple(parser)


############################################################################
#    Global Server Settings
section_docs['Global Server Settings'] = '''
These settings are global in the sense that they are used by the arbiter
as well as all pulsar workers. They are server configuration parameters.
'''


class Global(Setting):
    virtual = True
    section = "Global Server Settings"
    is_global = True


class ConfigFile(Global):
    name = "config"
    flags = ["-c", "--config"]
    meta = "FILE"
    validator = validate_string
    default = 'config.py'
    desc = """\
        The path to a Pulsar config file, where default Settings
        paramaters can be specified.
        """


class HttpProxyServer(Global):
    name = "http_proxy"
    flags = ["--http-proxy"]
    default = ''
    desc = """\
        The HTTP proxy server to use with HttpClient.
        """

    def on_start(self):
        if self.value:  # pragma    nocover
            os.environ['http_proxy'] = self.value
            os.environ['https_proxy'] = self.value
            os.environ['ws_proxy'] = self.value
            os.environ['wss_proxy'] = self.value


class HttpParser(Global):
    name = "http_py_parser"
    flags = ["--http-py-parser"]
    action = "store_true"
    default = False
    desc = '''\
        Set the python parser as default HTTP parser
    '''

    def on_start(self):
        if self.value:  # pragma    nocover
            from pulsar.utils.httpurl import setDefaultHttpParser
            setDefaultHttpParser(PyHttpParser)


class Debug(Global):
    name = "debug"
    flags = ["--debug"]
    nargs = '?'
    type = int
    default = 0
    const = 1
    desc = """\
        Turn on debugging in the server.

        Set the log level to debug, limits the number of worker processes
        to 1 and changes some error handling that's sent to clients.
        """


class Daemon(Global):
    name = "daemon"
    flags = ["-D", "--daemon"]
    validator = validate_bool
    action = "store_true"
    default = False
    desc = """\
        Daemonize the pulsar process (posix only).

        Detaches the server from the controlling terminal and enters the
        background.
        """


class Noisy(Global):
    name = "noisy"
    flags = ["--noisy"]
    validator = validate_bool
    action = "store_true"
    default = False
    desc = """\
        Log Failures as soon as they occur.

        This option is really needed during development when hunting
        for hidden bugs
        """


class Pidfile(Global):
    name = "pidfile"
    flags = ["-p", "--pid"]
    meta = "FILE"
    validator = validate_string
    default = None
    desc = """\
        A filename to use for the PID file.

        If not set, no PID file will be written.
        """


class Password(Global):
    name = "password"
    flags = ["--password"]
    validator = validate_string
    default = None
    desc = """Set a password for the server"""


class User(Global):
    name = "user"
    flags = ["-u", "--user"]
    meta = "USER"
    validator = validate_string
    default = None
    desc = """\
        Switch worker processes to run as this user.

        A valid user id (as an integer) or the name of a user that can be
        retrieved with a call to pwd.getpwnam(value) or None to not change
        the worker process user.
        """


class Group(Global):
    name = "group"
    flags = ["-g", "--group"]
    meta = "GROUP"
    validator = validate_string
    default = None
    desc = """\
        Switch worker process to run as this group.

        A valid group id (as an integer) or the name of a user that can be
        retrieved with a call to pwd.getgrnam(value) or None to not change
        the worker processes group.
        """


class Loglevel(Global):
    name = "loglevel"
    flags = ["--log-level"]
    nargs = '+'
    default = ['info']
    validator = validate_list
    desc = '''
        The granularity of log outputs.

        This setting controls loggers with ``pulsar`` namespace
        and the the root logger (if not already set).
        Valid level names are:

        * debug
        * info
        * warning
        * error
        * critical
        * none
        '''


class LogHandlers(Global):
    name = "loghandlers"
    flags = ["--log-handlers"]
    nargs = '+'
    default = ['console']
    validator = validate_list
    desc = '''Log handlers for pulsar server'''


class LogConfig(Global):
    name = "logconfig"
    default = {}
    validator = validate_dict
    desc = '''
    The logging configuration dictionary.

    This settings can only be specified on a config file and therefore
    no command-line parameter is available.
    '''


class Procname(Global):
    name = "process_name"
    flags = ["-n", "--name"]
    meta = "STRING"
    validator = validate_string
    default = None
    desc = """\
        A base to use with setproctitle for process naming.

        This affects things like ``ps`` and ``top``. If you're going to be
        running more than one instance of Pulsar you'll probably want to set a
        name to tell them apart. This requires that you install the
        setproctitle module.

        It defaults to 'pulsar'.
        """


class DefaultProcName(Global):
    name = "default_process_name"
    validator = validate_string
    default = SERVER_NAME
    desc = """\
        Internal setting that is adjusted for each type of application.
        """


class Coverage(Global):
    name = "coverage"
    flags = ["--coverage"]
    validator = validate_bool
    action = "store_true"
    default = False
    desc = """Collect code coverage from all spawn actors."""


class DataStore(Global):
    name = 'data_store'
    flags = ['--data-store']
    meta = "CONNECTION STRING"
    default = ''
    desc = '''\
    Default data store.

    Use this setting to specify a datastore used by pulsar applications.
    By default no datastore is used.
    '''


class ExecutionId(Global):
    name = 'exc_id'
    flags = ['--exc-id']
    default = ''
    desc = '''\
    Execution ID.

    Use this setting to specify an execution ID.
    If not provided, a value will be assigned by pulsar.
    '''


############################################################################
#    Worker Processes
section_docs['Worker Processes'] = '''
This group of configuration parameters control the number of actors
for a given :class:`.Monitor`, the type of concurreny of the server and
other actor-specific parameters.

They are available to all applications and, unlike global settings,
each application can specify different values.
'''


class Workers(Setting):
    name = "workers"
    section = "Worker Processes"
    flags = ["-w", "--workers"]
    validator = validate_pos_int
    type = int
    default = 1
    desc = """\
        The number of workers for handling requests.

        If using a multi-process concurrency, a number in the
        the ``2-4 x NUM_CORES`` range should be good. If you are using
        threads this number can be higher.
        """


class Concurrency(Setting):
    name = "concurrency"
    section = "Worker Processes"
    choices = ('process', 'thread')
    flags = ["--concurrency"]
    default = "process"
    desc = """The type of concurrency to use."""


class MaxRequests(Setting):
    name = "max_requests"
    section = "Worker Processes"
    flags = ["--max-requests"]
    validator = validate_pos_int
    type = int
    default = 0
    desc = """\
        The maximum number of requests a worker will process before restarting.

        Any value greater than zero will limit the number of requests a worker
        will process before automatically restarting. This is a simple method
        to help limit the damage of memory leaks.

        If this is set to zero (the default) then the automatic worker
        restarts are disabled.
        """


class Timeout(Setting):
    name = "timeout"
    section = "Worker Processes"
    flags = ["-t", "--timeout"]
    validator = validate_pos_int
    type = int
    default = 30
    desc = """\
        Workers silent for more than this many seconds are
        killed and restarted."""


class ThreadWorkers(Setting):
    name = "thread_workers"
    section = "Worker Processes"
    flags = ["--thread-workers"]
    validator = validate_pos_int
    type = int
    default = 1
    desc = """\
        The number of threads in an actor thread pool.

        The thread pool is used by actors to perform CPU intensive
        calculations. In this way the actor main thread is free to listen
        to events on file descriptors and process them as quick as possible.
        """


############################################################################
#    APPLICATION HOOKS
section_docs['Application Hooks'] = '''
Application hooks are functions which can be specified in a
:ref:`config <setting-config>` file to perform custom tasks in a pulsar server.
These tasks can be scheduled when events occurs or at every event loop of
the various components of a pulsar application.

All application hooks are functions which accept one parameter only, the actor
invoking the function.

Like worker process settings, each application can specify their own.
'''


class Postfork(Setting):
    name = "post_fork"
    section = "Application Hooks"
    validator = validate_callable(1)
    type = "callable"
    default = staticmethod(pass_through)
    desc = """\
        Called just after a worker has been forked.

        The event loop is not yet available.
        """


class WhenReady(Setting):
    name = "when_ready"
    section = "Application Hooks"
    validator = validate_callable(1)
    type = "callable"
    default = staticmethod(pass_through)
    desc = """\
        Called just before a worker starts its event loop.

        This is a chance to setup :class:`pulsar.EventLoop` callbacks which
        can run periodically, at every loop or when some defined events occur.
        """


class WhenExit(Setting):
    name = "when_exit"
    section = "Application Hooks"
    validator = validate_callable(1)
    type = "callable"
    default = staticmethod(pass_through)
    desc = """\
        Called just before an actor is garbadge collected.

        This is a chance to check the actor status if needed.
        """


class ConnectionMade(Setting):
    name = "connection_made"
    section = "Application Hooks"
    validator = validate_callable(1)
    type = "callable"
    default = staticmethod(pass_through)
    desc = """\
        Called after a new connection is made.

        The callable needs to accept one parameter for the
        connection instance.
        """


class ConnectionLost(Setting):
    name = "connection_lost"
    section = "Application Hooks"
    validator = validate_callable(1)
    type = "callable"
    default = staticmethod(pass_through)
    desc = """
        Called after a connection is lost.

        The callable needs to accept one parameter for the
        connection instance.
        """


class PreRequest(Setting):
    name = "pre_request"
    section = "Application Hooks"
    validator = validate_callable(1)
    type = "callable"
    default = staticmethod(pass_through)
    desc = """\
        Called just before an application server processes a request.

        The callable needs to accept one parameters for the
        consumer.
        """


class PostRequest(Setting):
    name = "post_request"
    section = "Application Hooks"
    validator = validate_callable(1)
    type = "callable"
    default = staticmethod(pass_through)
    desc = """\
        Called after an application server processes a request.

        The callable needs to accept one parameter for the
        consumer.
        """

########NEW FILE########
__FILENAME__ = exceptions
'''
A list of all Exception specific to pulsar library.
'''


class PulsarException(Exception):
    '''Base class of all Pulsar exceptions.'''


class MonitorStarted(PulsarException):
    pass


class ImproperlyConfigured(PulsarException):
    '''A :class:`PulsarException` raised when an inconsistent configuration
has occured.'''
    pass


class CommandError(PulsarException):
    pass


class CommandNotFound(CommandError):

    def __init__(self, name):
        super(CommandNotFound, self).__init__('Command "%s" not available' %
                                              name)


class ProtocolError(PulsarException):
    '''Raised when the protocol encounter unexpected data. It will close
the socket connection.'''
    status_code = None

    def ProtocolError(self, msg=None, status_code=None):
        super(ProtocolError, self).__init__(msg)
        self.status_code = status_code


class TooManyConsecutiveWrite(PulsarException):
    '''Raise when too many consecutive writes are attempted.'''


class TooManyConnections(PulsarException):
    '''Raised when there are too many concurrent connections.'''


class EventAlreadyRegistered(PulsarException):
    pass


class InvalidOperation(PulsarException):
    '''An invalid operation in pulsar'''
    pass


class HaltServer(BaseException):
    ''':class:`BaseException` raised to stop a running server.

    When ``exit_code`` is greater than 1, it is considered an expected
    failure and therefore the full stack trace is not logged.'''
    def __init__(self, reason='Exiting server.', exit_code=2):
        super(HaltServer, self).__init__(reason)
        self.exit_code = exit_code


# #################################################################### HTTP
class HTTPError(PulsarException):
    "Base for all HTTP related errors."
    pass


class SSLError(HTTPError):
    "Raised when SSL certificate fails in an HTTPS connection."
    pass


class HttpException(HTTPError):
    '''The base class of all ``HTTP`` server exceptions

Introduces the following attributes:

.. attribute:: status

    The numeric status code for the exception (ex 500 for server error).

    Default: ``500``.

.. attribute:: headers

    Additional headers to add to the client response.
'''
    status = 500

    def __init__(self, msg='', status=None, handler=None, strict=False,
                 headers=None, content_type=None):
        self.status = status or self.status
        self.code = self.status  # for compatibility with HTTPError
        self.handler = handler
        self.strict = strict
        self.headers = headers
        self.content_type = content_type
        super(HttpException, self).__init__(msg)

    @property
    def hdrs(self):
        return self.headers


class HttpRedirect(HttpException):
    '''An :class:`HttpException` for redirects.

    The :attr:`~HttpException.status` is set to ``302`` by default.
    '''
    status = 302

    def __init__(self, location, status=None, headers=None, **kw):
        headers = [] if headers is None else headers
        headers.append(('location', location))
        super(HttpRedirect, self).__init__(status=status or self.status,
                                           headers=headers, **kw)

    @property
    def location(self):
        '''The value in the ``Location`` header entry.

        Equivalent to ``self.headers['location']``.
        '''
        return self.headers['location']


class BadRequest(HttpException):
    status = 400


class PermissionDenied(HttpException):
    '''An :class:`HttpException` with default ``403`` status code.'''
    status = 403


class Http404(HttpException):
    '''An :class:`HttpException` with default ``404`` status code.'''
    status = 404


class MethodNotAllowed(HttpException):
    '''An :class:`HttpException` with default ``405`` status code.'''
    status = 405


class ContentNotAccepted(HttpException):
    '''An :class:`HttpException` with default ``406`` status code.'''
    status = 406

########NEW FILE########
__FILENAME__ = html
'''Utilities for HTML and text manipulation.
'''
import re
from unicodedata import normalize

from .system import json
from .pep import (ispy3k, native_str, to_string, iteritems, is_string,
                  string_type)

NOTHING = ('', b'', None)
'''Tuple of elements considered as null.'''
INLINE_TAGS = set(('input', 'link', 'meta', 'hr'))
# The global attributes below can be used on any HTML element
# class and style are misssing here since they are treated separately
GLOBAL_HTML_ATTRIBUTES = ('accesskey', 'contenteditable', 'contextmenu', 'dir',
                          'draggable', 'dropzone', 'hidden', 'id', 'lang',
                          'spellcheck', 'tabindex', 'title', 'traslate')
HTML_ATTRIBUTES = {}
HTML_CHILDREN_TAG = {}

# Extend GLOBAL ATTRIBUTES (which can be used in any HTML element).
e = lambda *t: GLOBAL_HTML_ATTRIBUTES + t

# Input atg attributes
# http://www.w3schools.com/tags/tag_input.asp
input_attr = lambda *t: e('type', 'autocomplete', 'autofocus', 'disabled',
                          'form', 'formnovalidate', 'list', 'max', 'maxlength',
                          'min', 'multiple', 'name', 'pattern', 'placeholder',
                          'readonly', 'required', 'size', 'step', 'value', *t)

# HTML TAG ATTRIBUTES
############################################################################
HTML_ATTRIBUTES['a'] = e('href', 'name', 'target')
HTML_ATTRIBUTES['form'] = e('accept-charset', 'action', 'autocomplete',
                            'enctype', 'method', 'name', 'novalidate',
                            'target')
HTML_ATTRIBUTES['img'] = e('align', 'alt', 'broder', 'crossorigin',
                           'height', 'hspace', 'ismap', 'longdesc',
                           'src', 'usemap', 'vspace', 'width')
HTML_ATTRIBUTES['input'] = input_attr()
HTML_ATTRIBUTES['input[type="checkbox"]'] = input_attr('checked')
HTML_ATTRIBUTES['input[type="file"]'] = input_attr('accept')
HTML_ATTRIBUTES['input[type="image"]'] = input_attr(
    'alt', 'formaction', 'formenctype', 'formmethod', 'formtarget',
    'height', 'src', 'width')
HTML_ATTRIBUTES['input[type="radio"]'] = input_attr('checked')
HTML_ATTRIBUTES['input[type="submit"]'] = input_attr(
    'formaction', 'formenctype', 'formmethod', 'formtarget')
HTML_ATTRIBUTES['link'] = e('href', 'hreflang', 'media', 'rel',
                            'sizes', 'type')
HTML_ATTRIBUTES['meta'] = e('name', 'charset', 'content')
HTML_ATTRIBUTES['option'] = e('disabled', 'label', 'selected', 'value')
HTML_ATTRIBUTES['script'] = e('async', 'charset', 'defer', 'src', 'type')
HTML_ATTRIBUTES['style'] = e('media', 'scoped', 'type')
HTML_ATTRIBUTES['select'] = e('autofocus', 'disabled', 'form', 'multiple',
                              'name', 'required', 'size')
HTML_ATTRIBUTES['textarea'] = e('autofocus', 'cols', 'disabled', 'maxlength',
                                'name', 'placeholder', 'readonly', 'required',
                                'rows', 'wrap')
HTML_ATTRIBUTES['th'] = e('colspan', 'headers', 'rowspan', 'scope')

# DEFAULT HTML TAG CHILDREN
############################################################################
HTML_CHILDREN_TAG['ul'] = 'li'
HTML_CHILDREN_TAG['ol'] = 'li'
HTML_CHILDREN_TAG['select'] = 'option'

# COMMON HTML ENTITIES
# Check http://www.w3schools.com/tags/ref_symbols.asp for more
############################################################################
HTML_NON_BREACKING_SPACE = '&nbsp;'
'''HTML non breaking space symbol.'''
HTML_LESS_THEN = '&lt;'
'''HTML < symbol.'''
HTML_GREATER_THEN = '&gt;'
'''HTML > symbol.'''
HTML_AMPERSAND = '&amp;'
'''HTML & symbol.'''
HTML_ENDASH = '&ndash;'
'''HTML - symbol.'''
HTML_EMDASH = '&mdash;'
'''HTML -- symbol.'''


def tag_attributes(tag, type=None):
    '''Return a tuple of valid attributes for the HTML ``tag`` and optional
``type``. If the ``tag`` is not found in the global ``HTML_ATTRIBUTES``
dictionary, the ``GLOBAL_HTML_ATTRIBUTES`` set is returned.'''
    if type:
        ntag = '%s[type="%s"]' % (tag, type)
        if ntag in HTML_ATTRIBUTES:
            return HTML_ATTRIBUTES[ntag]
    return HTML_ATTRIBUTES.get(tag, GLOBAL_HTML_ATTRIBUTES)


def child_tag(tag):
    '''The default children ``tag`` for a given ``tag``.'''
    return HTML_CHILDREN_TAG.get(tag)


def slugify(value, rtx='_'):
    '''Normalizes string, removes non-alpha characters,
and converts spaces to ``rtx`` character (hyphens or underscore).'''
    value = normalize('NFKD', to_string(value)).encode('ascii', 'ignore')
    value = to_string(re.sub('[^\w\s-]', rtx, value.decode()).strip())
    return re.sub('[-\s]+', rtx, value)


def mark_safe(v):
    '''Mar a string ``v`` as safe. A safe string won't be escaped by the
:func:`escape` function.'''
    return SafeString(v)


def is_safe(v):
    return getattr(v, '__html__', False)


def escape(html, force=False):
    """Returns the given HTML with ampersands,
quotes and angle brackets encoded."""
    if hasattr(html, '__html__') and not force:
        return html
    if html in NOTHING:
        return ''
    else:
        return to_string(html).replace('&', '&amp;').replace(
            '<', '&lt;').replace('>', '&gt;').replace("'", '&#39;').replace(
            '"', '&quot;')


def attr_iter(attrs):
    for k, v in iteritems(attrs):
        if v is not None:
            yield " %s='%s'" % (k, escape(v, force=True))


def dump_data_value(v):
    if not is_string(v):
        if isinstance(v, bytes):
            v = v.decode('utf-8')
        else:
            v = json.dumps(v)
    return mark_safe(v)


def lazy_string(f):
    def _(*args, **kwargs):
        return _lazy(f, args, kwargs)
    return _


def capfirst(x):
    '''Capitalise the first letter of ``x``.
    '''
    x = to_string(x).strip()
    if x:
        return x[0].upper() + x[1:].lower()
    else:
        return x


def nicename(name):
    '''Make ``name`` a more user friendly string.

    Capitalise the first letter and replace dash and underscores with a space
    '''
    name = to_string(name)
    return capfirst(' '.join(name.replace('-', ' ').replace('_', ' ').split()))


def plural(n, text, plural=None):
    if n != 1:
        text = plural or '%ss' % text
    return '%d %s' % (n, text)


class SafeString(string_type):
    __html__ = True


class _lazy:

    def __init__(self, f, args, kwargs):
        self._value = None
        self._f = f
        self.args = args
        self.kwargs = kwargs

    def __str__(self):
        if self._value is None:
            self._value = native_str(self._f(*self.args, **self.kwargs) or '')
        return self._value
    __repr__ = __str__


if ispy3k:

    class UnicodeMixin(object):

        def __unicode__(self):
            return '%s object' % self.__class__.__name__

        def __str__(self):
            return self.__unicode__()

        def __repr__(self):
            return '%s: %s' % (self.__class__.__name__, self)

else:  # pragma nocover

    class UnicodeMixin(object):

        def __unicode__(self):
            return unicode('%s object' % self.__class__.__name__)

        def __str__(self):
            return self.__unicode__().encode()

        def __repr__(self):
            return '%s: %s' % (self.__class__.__name__, self)

########NEW FILE########
__FILENAME__ = httpurl
'''This is a substantial module which imporfts several classes and functions
from the standard library in a python 2.6 to python 3.3 compatible fashion.
On top of that, it implements the :class:`HttpClient` for handling synchronous
and asynchronous HTTP requests in a pythonic way.

It is a thin layer on top of urllib2 in python2 / urllib in Python 3.
Several opensource efforts have been used as source of snippets:

* http-parser_
* request_
* urllib3_
* werkzeug_


.. _tools-http-headers:

HTTP Headers
~~~~~~~~~~~~~~~~~

.. autoclass:: Headers
   :members:
   :member-order: bysource


.. _tools-http-parser:

HTTP Parser
~~~~~~~~~~~~~~~~~

.. autoclass:: HttpParser
   :members:
   :member-order: bysource


.. _http-parser: https://github.com/benoitc/http-parser
.. _urllib3: https://github.com/shazow/urllib3
.. _request: https://github.com/kennethreitz/requests
.. _werkzeug: https://github.com/mitsuhiko/werkzeug
.. _`HTTP cookie`: http://en.wikipedia.org/wiki/HTTP_cookie
'''
import os
import sys
import re
import string
import time
import mimetypes
import platform
import socket
from hashlib import sha1, md5
from uuid import uuid4
from email.utils import formatdate
from io import BytesIO
import zlib
from collections import deque

from .structures import mapping_iterator, OrderedDict
from .pep import ispy3k, iteritems, itervalues, to_bytes, native_str
from .html import capfirst

# try:
#     from http_parser.parser import HttpParser as CHttpParser
#     hasextensions = True
#     _Http_Parser = CHttpParser
# except ImportError:  # pragma    nocover
#     hasextensions = False
#     _Http_Parser = None
#
# The http_parser has several bugs, therefore it is switched off
hasextensions = False
_Http_Parser = None

try:
    from select import poll, POLLIN
except ImportError:   # pragma    nocover
    poll = False
    try:
        from select import select
    except ImportError:  # pragma    nocover
        select = False


def setDefaultHttpParser(parser):   # pragma    nocover
    global _Http_Parser
    _Http_Parser = parser


def http_parser(**kwargs):
    global _Http_Parser
    return _Http_Parser(**kwargs)


create_connection = socket.create_connection

try:    # Compiled with SSL?
    BaseSSLError = None
    ssl = None
    import ssl
    BaseSSLError = ssl.SSLError
except (ImportError, AttributeError):   # pragma : no cover
    pass

if ispy3k:  # Python 3
    from urllib import request as urllibr
    from http import client as httpclient
    from urllib.parse import (quote, unquote, urlencode, urlparse, urlsplit,
                              parse_qs, parse_qsl, splitport, urlunparse,
                              urljoin)
    from http.client import responses
    from http.cookiejar import CookieJar, Cookie
    from http.cookies import SimpleCookie

    string_type = str
    getproxies_environment = urllibr.getproxies_environment
    ascii_letters = string.ascii_letters
    chr = chr
    is_string = lambda s: isinstance(s, str)

    def force_native_str(s, encoding=None):
        if isinstance(s, bytes):
            return s.decode(encoding or 'utf-8')
        elif not isinstance(s, str):
            return str(s)
        else:
            return s

else:   # pragma : no cover
    import urllib2 as urllibr
    import httplib as httpclient
    from urllib import (quote, unquote, urlencode, getproxies_environment,
                        splitport)
    from urlparse import (urlparse, urlsplit, parse_qs, urlunparse, urljoin,
                          parse_qsl)
    from httplib import responses
    from cookielib import CookieJar, Cookie
    from Cookie import SimpleCookie

    string_type = unicode
    ascii_letters = string.letters
    chr = unichr
    is_string = lambda s: isinstance(s, unicode)

    if sys.version_info < (2, 7):
        #
        def create_connection(address, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
                              source_address=None):
            """Form Python 2.7"""
            host, port = address
            err = None
            for res in socket.getaddrinfo(host, port, 0, socket.SOCK_STREAM):
                af, socktype, proto, canonname, sa = res
                sock = None
                try:
                    sock = socket.socket(af, socktype, proto)
                    if timeout is not socket._GLOBAL_DEFAULT_TIMEOUT:
                        sock.settimeout(timeout)
                    if source_address:
                        sock.bind(source_address)
                    sock.connect(sa)
                    return sock
                except Exception as _:
                    err = _
                    if sock is not None:
                        sock.close()
            if err is not None:
                raise err
            else:
                raise Exception("getaddrinfo returns an empty list")

    def force_native_str(s, encoding=None):
        if isinstance(s, unicode):
            return s.encode(encoding or 'utf-8')
        elif not isinstance(s, str):
            return str(s)
        else:
            return s

HTTPError = urllibr.HTTPError
URLError = urllibr.URLError
request_host = urllibr.request_host
parse_http_list = urllibr.parse_http_list


class SSLError(HTTPError):
    "Raised when SSL certificate fails in an HTTPS connection."
    pass

# ###################################################    URI & IRI SUFF
#
# The reserved URI characters (RFC 3986 - section 2.2)
# Default is charset is "iso-8859-1" (latin-1) from section 3.7.1
# http://www.ietf.org/rfc/rfc2616.txt
DEFAULT_CHARSET = 'ISO-8859-1'
URI_GEN_DELIMS = frozenset(':/?#[]@')
URI_SUB_DELIMS = frozenset("!$&'()*+,;=")
URI_RESERVED_SET = URI_GEN_DELIMS.union(URI_SUB_DELIMS)
URI_RESERVED_CHARS = ''.join(URI_RESERVED_SET)
# The unreserved URI characters (RFC 3986 - section 2.3)
URI_UNRESERVED_SET = frozenset(ascii_letters + string.digits + '-._~')
URI_SAFE_CHARS = URI_RESERVED_CHARS + '%~'
HEADER_TOKEN_CHARS = frozenset("!#$%&'*+-.0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ"
                               '^_`abcdefghijklmnopqrstuvwxyz|~')

escape = lambda s: quote(s, safe='~')
urlquote = lambda iri: quote(iri, safe=URI_RESERVED_CHARS)


def _gen_unquote(uri):
    unreserved_set = URI_UNRESERVED_SET
    for n, part in enumerate(force_native_str(uri, 'latin1').split('%')):
        if not n:
            yield part
        else:
            h = part[0:2]
            if len(h) == 2:
                c = chr(int(h, 16))
                if c in unreserved_set:
                    yield c + part[2:]
                else:
                    yield '%' + part
            else:
                yield '%' + part


def unquote_unreserved(uri):
    """Un-escape any percent-escape sequences in a URI that are unreserved
characters. This leaves all reserved, illegal and non-ASCII bytes encoded."""
    return ''.join(_gen_unquote(uri))


def requote_uri(uri):
    """Re-quote the given URI.

    This function passes the given URI through an unquote/quote cycle to
    ensure that it is fully and consistently quoted.
    """
    # Unquote only the unreserved characters
    # Then quote only illegal characters (do not quote reserved, unreserved,
    # or '%')
    return quote(unquote_unreserved(uri), safe=URI_SAFE_CHARS)


def iri_to_uri(iri, kwargs=None):
    '''Convert an Internationalised Resource Identifier (IRI) portion
    to a URI portion that is suitable for inclusion in a URL.
    This is the algorithm from section 3.1 of RFC 3987.
    Returns an ASCII native string containing the encoded result.
    '''
    if iri is None:
        return iri
    if kwargs:
        iri = '%s?%s' % (force_native_str(iri, 'latin1'),
                         '&'.join(('%s=%s' % kv for kv in iteritems(kwargs))))
    return urlquote(unquote_unreserved(iri))


def host_and_port(host):
    host, port = splitport(host)
    return host, int(port) if port else None


def default_port(scheme):
    if scheme in ("http", "ws"):
        return '80'
    elif scheme in ("https", "wss"):
        return '443'


def host_and_port_default(scheme, host):
    host, port = splitport(host)
    if not port:
        port = default_port(scheme)
    return host, port


def host_no_default_port(scheme, netloc):
    host, port = splitport(netloc)
    if port and port == default_port(scheme):
        return host
    else:
        return netloc


def get_hostport(scheme, full_host):
    host, port = host_and_port(full_host)
    if port is None:
        i = host.rfind(':')
        j = host.rfind(']')         # ipv6 addresses have [...]
        if i > j:
            try:
                port = int(host[i+1:])
            except ValueError:
                if host[i+1:] == "":  # http://foo.com:/ == http://foo.com/
                    port = default_port(scheme)
                else:
                    raise httpclient.InvalidURL("nonnumeric port: '%s'"
                                                % host[i+1:])
            host = host[:i]
        else:
            port = default_port(scheme)
        if host and host[0] == '[' and host[-1] == ']':
            host = host[1:-1]
    return host, int(port)


def remove_double_slash(route):
    if '//' in route:
        route = re.sub('/+', '/', route)
    return route


# ###################################################    CONTENT TYPES
JSON_CONTENT_TYPES = ('application/json',
                      'application/javascript',
                      'text/json',
                      'text/x-json')
# ###################################################    REQUEST METHODS
ENCODE_URL_METHODS = frozenset(['DELETE', 'GET', 'HEAD', 'OPTIONS'])
ENCODE_BODY_METHODS = frozenset(['PATCH', 'POST', 'PUT', 'TRACE'])
REDIRECT_CODES = (301, 302, 303, 307)


def has_empty_content(status, method=None):
    '''204, 304 and 1xx codes have no content'''
    if status == httpclient.NO_CONTENT or\
            status == httpclient.NOT_MODIFIED or\
            100 <= status < 200 or\
            method == "HEAD":
        return True
    else:
        return False


def is_succesful(status):
    '''2xx status is succesful'''
    return status >= 200 and status < 300


# ###################################################    HTTP HEADERS
WEBSOCKET_VERSION = (8, 13)
HEADER_FIELDS = {'general': frozenset(('Cache-Control', 'Connection', 'Date',
                                       'Pragma', 'Trailer',
                                       'Transfer-Encoding',
                                       'Upgrade', 'Sec-WebSocket-Extensions',
                                       'Sec-WebSocket-Protocol',
                                       'Via', 'Warning')),
                 # The request-header fields allow the client to pass
                 # additional information about the request, and about the
                 # client to the server.
                 'request': frozenset(('Accept', 'Accept-Charset',
                                       'Accept-Encoding', 'Accept-Language',
                                       'Authorization',
                                       'Cookie', 'Expect', 'From',
                                       'Host', 'If-Match', 'If-Modified-Since',
                                       'If-None-Match', 'If-Range',
                                       'If-Unmodified-Since', 'Max-Forwards',
                                       'Proxy-Authorization', 'Range',
                                       'Referer',
                                       'Sec-WebSocket-Key',
                                       'Sec-WebSocket-Version',
                                       'TE',
                                       'User-Agent',
                                       'X-Requested-With')),
                 # The response-header fields allow the server to pass
                 # additional information about the response which cannot be
                 # placed in the Status- Line.
                 'response': frozenset(('Accept-Ranges',
                                        'Age',
                                        'ETag',
                                        'Location',
                                        'Proxy-Authenticate',
                                        'Retry-After',
                                        'Sec-WebSocket-Accept',
                                        'Server',
                                        'Set-Cookie',
                                        'Set-Cookie2',
                                        'Vary',
                                        'WWW-Authenticate',
                                        'X-Frame-Options')),
                 'entity': frozenset(('Allow', 'Content-Encoding',
                                      'Content-Language', 'Content-Length',
                                      'Content-Location', 'Content-MD5',
                                      'Content-Range', 'Content-Type',
                                      'Expires', 'Last-Modified'))}

CLIENT_HEADER_FIELDS = HEADER_FIELDS['general'].union(
    HEADER_FIELDS['entity'], HEADER_FIELDS['request'])
SERVER_HEADER_FIELDS = HEADER_FIELDS['general'].union(
    HEADER_FIELDS['entity'], HEADER_FIELDS['response'])
ALL_HEADER_FIELDS = CLIENT_HEADER_FIELDS.union(SERVER_HEADER_FIELDS)
ALL_HEADER_FIELDS_DICT = dict(((k.lower(), k) for k in ALL_HEADER_FIELDS))
CRLF = '\r\n'
LWS = '\r\n '
TYPE_HEADER_FIELDS = {'client': CLIENT_HEADER_FIELDS,
                      'server': SERVER_HEADER_FIELDS,
                      'both': ALL_HEADER_FIELDS}

header_type = {0: 'client', 1: 'server', 2: 'both'}
header_type_to_int = dict(((v, k) for k, v in header_type.items()))


def capheader(name):
    return '-'.join((b for b in (capfirst(n) for n in name.split('-')) if b))


def header_field(name, HEADERS_SET=None, strict=False):
    '''Return a header `name` in Camel case.

    For example::

        header_field('connection') == 'Connection'
        header_field('accept-charset') == 'Accept-Charset'

    If ``header_set`` is given, only return headers included in the set.
    '''
    name = name.lower()
    if name.startswith('x-'):
        return capheader(name)
    else:
        header = ALL_HEADER_FIELDS_DICT.get(name)
        if header and HEADERS_SET:
            return header if header in HEADERS_SET else None
        elif header:
            return header
        elif not strict:
            return capheader(name)


#    HEADERS UTILITIES
HEADER_FIELDS_JOINER = {'Cookie': '; ',
                        'Set-Cookie': None,
                        'Set-Cookie2': None}


def split_comma(value):
    return [v for v in (v.strip() for v in value.split(',')) if v]


def parse_cookies(value):
    return [c.OutputString() for c in SimpleCookie(value).values()]


header_parsers = {'Connection': split_comma,
                  'Cookie': parse_cookies}


def header_values(header, value):
    assert isinstance(value, str)
    if header in header_parsers:
        return header_parsers[header](value)
    else:
        return [value]


def quote_header_value(value, extra_chars='', allow_token=True):
    """Quote a header value if necessary.

    :param value: the value to quote.
    :param extra_chars: a list of extra characters to skip quoting.
    :param allow_token: if this is enabled token values are returned
        unchanged.
    """
    value = force_native_str(value)
    if allow_token:
        token_chars = HEADER_TOKEN_CHARS | set(extra_chars)
        if set(value).issubset(token_chars):
            return value
    return '"%s"' % value.replace('\\', '\\\\').replace('"', '\\"')


def unquote_header_value(value, is_filename=False):
    """Unquotes a header value.

    Reversal of :func:`quote_header_value`. This does not use the real
    un-quoting but what browsers are actually using for quoting.

    :param value: the header value to unquote.
    """
    if value and value[0] == value[-1] == '"':
        # this is not the real unquoting, but fixing this so that the
        # RFC is met will result in bugs with internet explorer and
        # probably some other browsers as well.  IE for example is
        # uploading files with "C:\foo\bar.txt" as filename
        value = value[1:-1]
        # if this is a filename and the starting characters look like
        # a UNC path, then just return the value without quotes.  Using the
        # replace sequence below on a UNC path has the effect of turning
        # the leading double slash into a single slash and then
        # _fix_ie_filename() doesn't work correctly.  See #458.
        if not is_filename or value[:2] != '\\\\':
            return value.replace('\\\\', '\\').replace('\\"', '"')
    return value


def parse_dict_header(value):
    """Parse lists of key, value pairs as described by RFC 2068 Section 2 and
    convert them into a python dict:

    >>> d = parse_dict_header('foo="is a fish", bar="as well"')
    >>> type(d) is dict
    True
    >>> sorted(d.items())
    [('bar', 'as well'), ('foo', 'is a fish')]

    If there is no value for a key it will be `None`:

    >>> parse_dict_header('key_without_value')
    {'key_without_value': None}

    To create a header from the :class:`dict` again, use the
    :func:`dump_header` function.

    :param value: a string with a dict header.
    :return: :class:`dict`
    """
    result = {}
    for item in parse_http_list(value):
        if '=' not in item:
            result[item] = None
            continue
        name, value = item.split('=', 1)
        if value[:1] == value[-1:] == '"':
            value = unquote_header_value(value[1:-1])
        result[name] = value
    return result


class Headers(object):
    '''Utility for managing HTTP headers for both clients and servers.

    It has a dictionary like interface with few extra functions to facilitate
    the insertion of multiple header values. Header fields are
    **case insensitive**, therefore doing::

        >>> h = Headers()
        >>> h['Content-Length'] = '1050'

    is equivalent to

        >>> h['content-length'] = '1050'

    :param headers: optional iterable over header field/value pairs.
    :param kind: optional headers type, one of ``server``, ``client`` or
        ``both``.
    :param strict: if ``True`` only valid headers field will be included.

    This :class:`Headers` container maintains an ordering as suggested by
    http://www.w3.org/Protocols/rfc2616/rfc2616.html:

    .. epigraph::

        The order in which header fields with differing field names are
        received is not significant. However, it is "good practice" to send
        general-header fields first, followed by request-header or
        response-header fields, and ending with the entity-header fields.

        -- rfc2616 section 4.2

    The strict parameter is rarely used and it forces the omission on
    non-standard header fields.
    '''
    def __init__(self, headers=None, kind='server', strict=False):
        if isinstance(kind, int):
            kind = header_type.get(kind, 'both')
        else:
            kind = str(kind).lower()
        self.kind = kind
        self.strict = strict
        self.all_headers = TYPE_HEADER_FIELDS.get(self.kind)
        if not self.all_headers:
            self.kind = 'both'
            self.all_headers = TYPE_HEADER_FIELDS[self.kind]
        self._headers = {}
        if headers is not None:
            self.update(headers)

    def __repr__(self):
        return '%s %s' % (self.kind, self._headers.__repr__())

    def __str__(self):
        return '\r\n'.join(self._ordered())

    def __bytes__(self):
        return str(self).encode(DEFAULT_CHARSET)

    def __len__(self):
        return len(self._headers)

    @property
    def kind_number(self):
        return header_type_to_int.get(self.kind)

    def update(self, iterable):
        """Extend the headers with an ``iterable``.

        :param iterable: a dictionary or an iterable over keys, vaues tuples.
        """
        for key, value in mapping_iterator(iterable):
            self.add_header(key, value)

    def override(self, iterable):
        '''Extend headers by overriding fields form iterable.

        :param iterable: a dictionary or an iterable over keys, vaues tuples.
        '''
        seen = set()
        for key, value in mapping_iterator(iterable):
            key = key.lower()
            if key in seen:
                self.add_header(key, value)
            else:
                seen.add(key)
                self[key] = value

    def copy(self):
        return self.__class__(self, kind=self.kind, strict=self.strict)

    def __contains__(self, key):
        return header_field(key) in self._headers

    def __getitem__(self, key):
        key = header_field(key)
        values = self._headers[key]
        joiner = HEADER_FIELDS_JOINER.get(key, ', ')
        if joiner is None:
            joiner = '; '
        return joiner.join(values)

    def __delitem__(self, key):
        self._headers.__delitem__(header_field(key))

    def __setitem__(self, key, value):
        key = header_field(key, self.all_headers, self.strict)
        if key and value:
            if not isinstance(value, list):
                value = header_values(key, value)
            self._headers[key] = value

    def get(self, key, default=None):
        '''Get the field value at ``key`` as comma separated values.

        For example::

            >>> from pulsar.utils.httpurl import Headers
            >>> h = Headers(kind='client')
            >>> h.add_header('accept-encoding', 'gzip')
            >>> h.add_header('accept-encoding', 'deflate')
            >>> h.get('accept-encoding')

        results in::

            'gzip, deflate'
        '''
        if key in self:
            return self.__getitem__(key)
        else:
            return default

    def get_all(self, key, default=None):
        '''Get the values at header ``key`` as a list rather than a
        string separated by comma (which is returned by the
        :meth:`get` method).

        For example::

            >>> from pulsar.utils.httpurl import Headers
            >>> h = Headers(kind='client')
            >>> h.add_header('accept-encoding', 'gzip')
            >>> h.add_header('accept-encoding', 'deflate')
            >>> h.get_all('accept-encoding')

        results in::

            ['gzip', 'deflate']
        '''
        return self._headers.get(header_field(key), default)

    def has(self, field, value):
        '''Check if ``value`` is avialble in header ``field``.'''
        value = value.lower()
        for c in self.get_all(field, ()):
            if c.lower() == value:
                return True
        return False

    def pop(self, key, *args):
        return self._headers.pop(header_field(key), *args)

    def clear(self):
        '''Same as :meth:`dict.clear`, it removes all headers.
        '''
        self._headers.clear()

    def getheaders(self, key):  # pragma    nocover
        '''Required by cookielib in python 2.

        If the key is not available, it returns an empty list.
        '''
        return self._headers.get(header_field(key), [])

    def add_header(self, key, values):
        '''Add ``values`` to ``key`` header.

        If the header is already available, append the value to the list.

        :param key: header name
        :param values: a string value or a list/tuple of strings values
            for header ``key``
        '''
        key = header_field(key, self.all_headers, self.strict)
        if key and values:
            if not isinstance(values, (tuple, list)):
                values = header_values(key, values)
            current = self._headers.get(key, [])
            for value in values:
                if value and value not in current:
                    current.append(value)
            self._headers[key] = current

    def remove_header(self, key, value=None):
        '''Remove the header at ``key``.

        If ``value`` is provided, it removes only that value if found.
        '''
        key = header_field(key, self.all_headers, self.strict)
        if key:
            if value:
                value = value.lower()
                values = self._headers.get(key, [])
                removed = None
                for v in values:
                    if v.lower() == value:
                        removed = v
                        values.remove(v)
                self._headers[key] = values
                return removed
            else:
                return self._headers.pop(key, None)

    def flat(self, version, status):
        '''Full headers bytes representation'''
        vs = version + (status, self)
        return ('HTTP/%s.%s %s\r\n%s' % vs).encode(DEFAULT_CHARSET)

    def __iter__(self):
        dj = ', '
        for k, values in iteritems(self._headers):
            joiner = HEADER_FIELDS_JOINER.get(k, dj)
            if joiner:
                yield k, joiner.join(values)
            else:
                for value in values:
                    yield k, value

    def _ordered(self):
        hf = HEADER_FIELDS
        hj = HEADER_FIELDS_JOINER
        dj = ', '
        order = (('general', []), ('request', []),
                 ('response', []), ('entity', []))
        headers = self._headers
        for key in headers:
            for name, group in order:
                if key in hf[name]:
                    group.append(key)
                    break
            if key not in group:    # non-standard header
                group.append(key)
        for _, group in order:
            for k in group:
                joiner = hj.get(k, dj)
                if not joiner:
                    for header in headers[k]:
                        yield "%s: %s" % (k, header)
                else:
                    yield "%s: %s" % (k, joiner.join(headers[k]))
        yield ''
        yield ''


###############################################################################
#    HTTP PARSER
###############################################################################
METHOD_RE = re.compile("[A-Z0-9$-_.]{3,20}")
VERSION_RE = re.compile("HTTP/(\d+).(\d+)")
STATUS_RE = re.compile("(\d{3})\s*(\w*)")
HEADER_RE = re.compile("[\x00-\x1F\x7F()<>@,;:\[\]={} \t\\\\\"]")

# errors
BAD_FIRST_LINE = 0
INVALID_HEADER = 1
INVALID_CHUNK = 2


class InvalidRequestLine(Exception):
    """ error raised when first line is invalid """


class InvalidHeader(Exception):
    """ error raised on invalid header """


class InvalidChunkSize(Exception):
    """ error raised when we parse an invalid chunk size """


class HttpParser(object):
    '''A python HTTP parser.

    Original code from https://github.com/benoitc/http-parser

    2011 (c) Benoit Chesneau <benoitc@e-engura.org>
    '''
    def __init__(self, kind=2, decompress=False, method=None):
        self.decompress = decompress
        # errors vars
        self.errno = None
        self.errstr = ""
        # protected variables
        self._buf = []
        self._version = None
        self._method = method
        self._status_code = None
        self._status = None
        self._reason = None
        self._url = None
        self._path = None
        self._query_string = None
        self._kind = kind
        self._fragment = None
        self._headers = OrderedDict()
        self._chunked = False
        self._body = []
        self._trailers = None
        self._partial_body = False
        self._clen = None
        self._clen_rest = None
        # private events
        self.__on_firstline = False
        self.__on_headers_complete = False
        self.__on_message_begin = False
        self.__on_message_complete = False
        self.__decompress_obj = None

    @property
    def kind(self):
        return self._kind

    def get_version(self):
        return self._version

    def get_method(self):
        return self._method

    def get_status_code(self):
        return self._status_code

    def get_url(self):
        return self._url

    def get_path(self):
        return self._path

    def get_query_string(self):
        return self._query_string

    def get_fragment(self):
        return self._fragment

    def get_headers(self):
        return self._headers

    def recv_body(self):
        """ return last chunk of the parsed body"""
        body = b''.join(self._body)
        self._body = []
        self._partial_body = False
        return body

    def is_headers_complete(self):
        """ return True if all headers have been parsed. """
        return self.__on_headers_complete

    def is_partial_body(self):
        """ return True if a chunk of body have been parsed """
        return self._partial_body

    def is_message_begin(self):
        """ return True if the parsing start """
        return self.__on_message_begin

    def is_message_complete(self):
        """ return True if the parsing is done (we get EOF) """
        return self.__on_message_complete

    def is_chunked(self):
        """ return True if Transfer-Encoding header value is chunked"""
        return self._chunked

    def execute(self, data, length):
        # end of body can be passed manually by putting a length of 0
        if length == 0:
            self.__on_message_complete = True
            return length
        #
        data = bytes(data)
        # start to parse
        nb_parsed = 0
        while True:
            if not self.__on_firstline:
                idx = data.find(b'\r\n')
                if idx < 0:
                    self._buf.append(data)
                    return len(data)
                else:
                    self.__on_firstline = True
                    self._buf.append(data[:idx])
                    first_line = native_str(b''.join(self._buf),
                                            DEFAULT_CHARSET)
                    rest = data[idx+2:]
                    data = b''
                    if self._parse_firstline(first_line):
                        nb_parsed = nb_parsed + idx + 2
                        self._buf = [rest]
                    else:
                        return nb_parsed
            elif not self.__on_headers_complete:
                if data:
                    self._buf.append(data)
                    data = b''
                try:
                    to_parse = b''.join(self._buf)
                    ret = self._parse_headers(to_parse)
                    if ret is False:
                        return length
                    nb_parsed = nb_parsed + (len(to_parse) - ret)
                except InvalidHeader as e:
                    self.errno = INVALID_HEADER
                    self.errstr = str(e)
                    return nb_parsed
            elif not self.__on_message_complete:
                self.__on_message_begin = True
                if data:
                    self._buf.append(data)
                    data = b''
                ret = self._parse_body()
                if ret is None:
                    return length
                elif ret < 0:
                    return ret
                elif ret == 0:
                    self.__on_message_complete = True
                    return length
                else:
                    nb_parsed = max(length, ret)
            else:
                return 0

    def _parse_firstline(self, line):
        try:
            if self.kind == 2:  # auto detect
                try:
                    self._parse_request_line(line)
                except InvalidRequestLine:
                    self._parse_response_line(line)
            elif self.kind == 1:
                self._parse_response_line(line)
            elif self.kind == 0:
                self._parse_request_line(line)
        except InvalidRequestLine as e:
            self.errno = BAD_FIRST_LINE
            self.errstr = str(e)
            return False
        return True

    def _parse_response_line(self, line):
        bits = line.split(None, 1)
        if len(bits) != 2:
            raise InvalidRequestLine(line)

        # version
        matchv = VERSION_RE.match(bits[0])
        if matchv is None:
            raise InvalidRequestLine("Invalid HTTP version: %s" % bits[0])
        self._version = (int(matchv.group(1)), int(matchv.group(2)))

        # status
        matchs = STATUS_RE.match(bits[1])
        if matchs is None:
            raise InvalidRequestLine("Invalid status %" % bits[1])

        self._status = bits[1]
        self._status_code = int(matchs.group(1))
        self._reason = matchs.group(2)

    def _parse_request_line(self, line):
        bits = line.split(None, 2)
        if len(bits) != 3:
            raise InvalidRequestLine(line)
        # Method
        if not METHOD_RE.match(bits[0]):
            raise InvalidRequestLine("invalid Method: %s" % bits[0])
        self._method = bits[0].upper()
        # URI
        self._url = bits[1]
        parts = urlsplit('http://dummy.com%s' % bits[1])
        self._path = parts.path or ""
        self._query_string = parts.query or ""
        self._fragment = parts.fragment or ""
        # Version
        match = VERSION_RE.match(bits[2])
        if match is None:
            raise InvalidRequestLine("Invalid HTTP version: %s" % bits[2])
        self._version = (int(match.group(1)), int(match.group(2)))

    def _parse_headers(self, data):
        if data == b'\r\n':
            self.__on_headers_complete = True
            self._buf = []
            return 0
        idx = data.find(b'\r\n\r\n')
        if idx < 0:  # we don't have all headers
            return False
        chunk = native_str(data[:idx], DEFAULT_CHARSET)
        # Split lines on \r\n keeping the \r\n on each line
        lines = deque(('%s\r\n' % line for line in chunk.split('\r\n')))
        # Parse headers into key/value pairs paying attention
        # to continuation lines.
        while len(lines):
            # Parse initial header name : value pair.
            curr = lines.popleft()
            if curr.find(":") < 0:
                continue
            name, value = curr.split(":", 1)
            name = name.rstrip(" \t").upper()
            if HEADER_RE.search(name):
                raise InvalidHeader("invalid header name %s" % name)
            name, value = header_field(name.strip()), [value.lstrip()]
            # Consume value continuation lines
            while len(lines) and lines[0].startswith((" ", "\t")):
                value.append(lines.popleft())
            value = ''.join(value).rstrip()
            if name in self._headers:
                self._headers[name].append(value)
            else:
                self._headers[name] = [value]
        # detect now if body is sent by chunks.
        clen = self._headers.get('Content-Length')
        if 'Transfer-Encoding' in self._headers:
            te = self._headers['Transfer-Encoding'][0].lower()
            self._chunked = (te == 'chunked')
        else:
            self._chunked = False
        #
        status = self._status_code
        if status and (status == httpclient.NO_CONTENT or
                       status == httpclient.NOT_MODIFIED or
                       100 <= status < 200 or      # 1xx codes
                       self._method == "HEAD"):
            clen = 0
        elif clen is not None:
            try:
                clen = int(clen[0])
            except ValueError:
                clen = None
            else:
                if clen < 0:  # ignore nonsensical negative lengths
                    clen = None
        #
        if clen is None:
            self._clen_rest = sys.maxsize
        else:
            self._clen_rest = self._clen = clen
        #
        # detect encoding and set decompress object
        if self.decompress and 'Content-Encoding' in self._headers:
            encoding = self._headers['Content-Encoding'][0]
            if encoding == "gzip":
                self.__decompress_obj = zlib.decompressobj(16+zlib.MAX_WBITS)
            elif encoding == "deflate":
                self.__decompress_obj = zlib.decompressobj()
        rest = data[idx+4:]
        self._buf = [rest]
        self.__on_headers_complete = True
        self.__on_message_begin = True
        return len(rest)

    def _parse_body(self):
        data = b''.join(self._buf)
        #
        if not self._chunked:
            #
            if not data and self._clen is None:
                if not self._status:    # message complete only for servers
                    self.__on_message_complete = True
            else:
                if self._clen_rest is not None:
                    self._clen_rest -= len(data)
                # maybe decompress
                if self.__decompress_obj is not None:
                    data = self.__decompress_obj.decompress(data)
                self._partial_body = True
                if data:
                    self._body.append(data)
                self._buf = []
                if self._clen_rest <= 0:
                    self.__on_message_complete = True
            return
        else:
            try:
                size, rest = self._parse_chunk_size(data)
            except InvalidChunkSize as e:
                self.errno = INVALID_CHUNK
                self.errstr = "invalid chunk size [%s]" % str(e)
                return -1
            if size == 0:
                return size
            if size is None or len(rest) < size:
                return None
            body_part, rest = rest[:size], rest[size:]
            if len(rest) < 2:
                self.errno = INVALID_CHUNK
                self.errstr = "chunk missing terminator [%s]" % data
                return -1
            # maybe decompress
            if self.__decompress_obj is not None:
                body_part = self.__decompress_obj.decompress(body_part)
            self._partial_body = True
            self._body.append(body_part)
            rest = rest[2:]
            self._buf = [rest] if rest else []
            return len(rest) + 2

    def _parse_chunk_size(self, data):
        idx = data.find(b'\r\n')
        if idx < 0:
            return None, None
        line, rest_chunk = data[:idx], data[idx+2:]
        chunk_size = line.split(b';', 1)[0].strip()
        try:
            chunk_size = int(chunk_size, 16)
        except ValueError:
            raise InvalidChunkSize(chunk_size)
        if chunk_size == 0:
            self._parse_trailers(rest_chunk)
            return 0, None
        return chunk_size, rest_chunk

    def _parse_trailers(self, data):
        idx = data.find(b'\r\n\r\n')
        if data[:2] == b'\r\n':
            self._trailers = self._parse_headers(data[:idx])

if not hasextensions:   # pragma    nocover
    setDefaultHttpParser(HttpParser)


# ############################################    UTILITIES, ENCODERS, PARSERS
def get_environ_proxies():
    """Return a dict of environment proxies. From requests_."""

    proxy_keys = [
        'all',
        'http',
        'https',
        'ftp',
        'socks',
        'ws',
        'wss',
        'no'
    ]

    get_proxy = lambda k: os.environ.get(k) or os.environ.get(k.upper())
    proxies = [(key, get_proxy(key + '_proxy')) for key in proxy_keys]
    return dict([(key, val) for (key, val) in proxies if val])


def appendslash(url):
    '''Append a slash to *url* if it does not have one.'''
    if not url.endswith('/'):
        url = '%s/' % url
    return url


def choose_boundary():
    """Our embarassingly-simple replacement for mimetools.choose_boundary."""
    return uuid4().hex


def get_content_type(filename):
    return mimetypes.guess_type(filename)[0] or 'application/octet-stream'


def encode_multipart_formdata(fields, boundary=None, charset=None):
    """Encode a dictionary of ``fields`` using the multipart/form-data format.

    :param fields:
        Dictionary of fields or list of (key, value) field tuples.  The key is
        treated as the field name, and the value as the body of the form-data
        bytes. If the value is a tuple of two elements, then the first element
        is treated as the filename of the form-data section.

        Field names and filenames must be unicode.

    :param boundary:
        If not specified, then a random boundary will be generated using
        :func:`mimetools.choose_boundary`.
    """
    charset = charset or 'utf-8'
    body = BytesIO()
    if boundary is None:
        boundary = choose_boundary()
    for fieldname, value in mapping_iterator(fields):
        body.write(('--%s\r\n' % boundary).encode(charset))
        if isinstance(value, tuple):
            filename, data = value
            body.write(('Content-Disposition: form-data; name="%s"; '
                        'filename="%s"\r\n' % (fieldname, filename))
                       .encode(charset))
            body.write(('Content-Type: %s\r\n\r\n' %
                       (get_content_type(filename))).encode(charset))
        else:
            data = value
            body.write(('Content-Disposition: form-data; name="%s"\r\n'
                        % (fieldname)).encode(charset))
            body.write(b'Content-Type: text/plain\r\n\r\n')
        data = body.write(to_bytes(data))
        body.write(b'\r\n')
    body.write(('--%s--\r\n' % (boundary)).encode(charset))
    content_type = 'multipart/form-data; boundary=%s' % boundary
    return body.getvalue(), content_type


def hexmd5(x):
    return md5(to_bytes(x)).hexdigest()


def hexsha1(x):
    return sha1(to_bytes(x)).hexdigest()


def http_date(epoch_seconds=None):
    """
    Formats the time to match the RFC1123 date format as specified by HTTP
    RFC2616 section 3.3.1.

    Accepts a floating point number expressed in seconds since the epoch, in
    UTC - such as that outputted by time.time(). If set to None, defaults to
    the current time.

    Outputs a string in the format 'Wdy, DD Mon YYYY HH:MM:SS GMT'.
    """
    return formatdate(epoch_seconds, usegmt=True)


# ################################################################# COOKIE
def create_cookie(name, value, **kwargs):
    """Make a cookie from underspecified parameters.

    By default, the pair of `name` and `value` will be set for the domain ''
    and sent on every request (this is sometimes called a "supercookie").
    """
    result = dict(
        version=0,
        name=name,
        value=value,
        port=None,
        domain='',
        path='/',
        secure=False,
        expires=None,
        discard=True,
        comment=None,
        comment_url=None,
        rest={'HttpOnly': None},
        rfc2109=False,)
    badargs = set(kwargs) - set(result)
    if badargs:
        err = 'create_cookie() got unexpected keyword arguments: %s'
        raise TypeError(err % list(badargs))
    result.update(kwargs)
    result['port_specified'] = bool(result['port'])
    result['domain_specified'] = bool(result['domain'])
    result['domain_initial_dot'] = result['domain'].startswith('.')
    result['path_specified'] = bool(result['path'])
    return Cookie(**result)


def cookiejar_from_dict(cookie_dict, cookiejar=None):
    """Returns a CookieJar from a key/value dictionary.

    :param cookie_dict: Dict of key/values to insert into CookieJar.
    """
    if not isinstance(cookie_dict, CookieJar):
        if cookiejar is None:
            cookiejar = CookieJar()
        if cookie_dict is not None:
            for name in cookie_dict:
                cookiejar.set_cookie(create_cookie(name, cookie_dict[name]))
        return cookiejar
    else:
        return cookie_dict


cc_delim_re = re.compile(r'\s*,\s*')


class accept_content_type(object):

    def __init__(self, values=None):
        self._all = {}
        self.update(values)

    def update(self, values):
        if values:
            all = self._all
            accept_headers = cc_delim_re.split(values)
            for h in accept_headers:
                v = h.split('/')
                if len(v) == 2:
                    a, b = v
                    if a in all:
                        all[a].append(b)
                    else:
                        all[a] = [b]

    def __contains__(self, content_type):
        all = self._all
        if not all:
            # If no Accept header field is present, then it is assumed that the
            # client accepts all media types.
            return True
        a, b = content_type.split('/')
        if a in all:
            all = all[a]
            if '*' in all:
                return True
            else:
                return b in all
        elif '*' in all:
            return True
        else:
            return False


def patch_vary_headers(response, newheaders):
    """\
Adds (or updates) the "Vary" header in the given HttpResponse object.
newheaders is a list of header names that should be in "Vary". Existing
headers in "Vary" aren't removed.

For information on the Vary header, see:

    http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.44
    """
    # Note that we need to keep the original order intact, because cache
    # implementations may rely on the order of the Vary contents in, say,
    # computing an MD5 hash.
    if 'Vary' in response:
        vary_headers = cc_delim_re.split(response['Vary'])
    else:
        vary_headers = []
    # Use .lower() here so we treat headers as case-insensitive.
    existing_headers = set([header.lower() for header in vary_headers])
    additional_headers = [newheader for newheader in newheaders
                          if newheader.lower() not in existing_headers]
    response['Vary'] = ', '.join(vary_headers + additional_headers)


def has_vary_header(response, header_query):
    """
    Checks to see if the response has a given header name in its Vary header.
    """
    if not response.has_header('Vary'):
        return False
    vary_headers = cc_delim_re.split(response['Vary'])
    existing_headers = set([header.lower() for header in vary_headers])
    return header_query.lower() in existing_headers


class CacheControl(object):
    '''
    http://www.mnot.net/cache_docs/

.. attribute:: maxage

    Specifies the maximum amount of time that a representation will be
    considered fresh.
    '''
    def __init__(self, maxage=None, private=False,
                 must_revalidate=False, proxy_revalidate=False,
                 nostore=False):
        self.maxage = maxage
        self.private = private
        self.must_revalidate = must_revalidate
        self.proxy_revalidate = proxy_revalidate
        self.nostore = nostore

    def __call__(self, headers):
        if self.nostore:
            headers['cache-control'] = ('no-store, no-cache, must-revalidate,'
                                        ' max-age=0')
        elif self.maxage:
            headers['cache-control'] = 'max-age=%s' % self.maxage
            if self.private:
                headers.add_header('cache-control', 'private')
            else:
                headers.add_header('cache-control', 'public')
            if self.must_revalidate:
                headers.add_header('cache-control', 'must-revalidate')
            elif self.proxy_revalidate:
                headers.add_header('cache-control', 'proxy-revalidate')
        else:
            headers['cache-control'] = 'no-cache'

########NEW FILE########
__FILENAME__ = importer
import os
import sys
import glob
from importlib import *


def expand_star(mod_name):
    """Expand something like 'unuk.tasks.*' into a list of all the modules
    there.
    """
    expanded = []
    mod_dir = os.path.dirname(
        __import__(mod_name[:-2], {}, {}, ['']).__file__)
    for f in glob.glob1(mod_dir, "[!_]*.py"):
        expanded.append('%s.%s' % (mod_name[:-2], f[:-3]))
    return expanded


def import_modules(modules):
    '''Safely import a list of *modules*
    '''
    all = []
    for mname in modules:
        if mname.endswith('.*'):
            to_load = expand_star(mname)
        else:
            to_load = [mname]
        for module in to_load:
            try:
                all.append(import_module(module))
            except ImportError as e:
                pass
    return all


def module_attribute(dotpath, default=None, safe=False):
    '''Load an attribute from a module.

    If the module or the attribute is not available, return the default
    argument if *safe* is `True`.
    '''
    if dotpath:
        bits = str(dotpath).split('.')
        try:
            module = import_module('.'.join(bits[:-1]))
            return getattr(module, bits[-1], default)
        except Exception as e:
            if not safe:
                raise
            return default
    else:
        if not safe:
            raise ImportError()
        return default


def py_file(name):
    if name.endswith('.py'):
        return name[:-3]
    elif name.endswith('.pyc'):
        return name[:-4]
    else:
        return name


def import_system_file(mod, add_to_path=True):
    if os.path.isfile(mod):
        # it is a file in the system path
        dir, name = os.path.split(mod)
        names = [py_file(name)]
        while dir and dir not in sys.path:
            ndir, name = os.path.split(dir)
            if dir == ndir:
                dir = ''
                break
            dir = ndir
            names.insert(0, name)
        # the file was not in the system path
        if not dir and add_to_path:
            dir, name = os.path.split(mod)
            if dir and dir != mod:
                sys.path.append(dir)
            mod_name = py_file(name)
        else:
            mod_name = '.'.join(names)
        return import_module(mod_name)

########NEW FILE########
__FILENAME__ = internet
import sys
import os
import socket
from functools import partial

try:
    from select import poll, POLLIN
except ImportError:  # pragma    nocover
    poll = None
    try:
        from select import select
    except ImportError:  # pragma    nocover
        select = False

try:
    _SSLContext = None
    HAS_SNI = False
    ssl = None
    CERT_NONE = 0
    import ssl
    from ssl import wrap_socket, PROTOCOL_SSLv23, CERT_NONE
    from ssl import SSLContext as _SSLContext
    from ssl import HAS_SNI  # Has SNI?
except ImportError:  # pragma: no cover
    pass


from .system import platform, socketpair
from .httpurl import urlsplit, parse_qsl, urlencode
from .pep import native_str, ispy3k
from .exceptions import SSLError

BUFFER_MAX_SIZE = 256 * 1024  # 256 kb

if platform.is_windows:    # pragma    nocover
    EPERM = object()
    from errno import WSAEINVAL as EINVAL
    from errno import WSAEWOULDBLOCK as EWOULDBLOCK
    from errno import WSAEINPROGRESS as EINPROGRESS
    from errno import WSAEALREADY as EALREADY
    from errno import WSAECONNRESET as ECONNRESET
    from errno import WSAEISCONN as EISCONN
    from errno import WSAENOTCONN as ENOTCONN
    from errno import WSAEINTR as EINTR
    from errno import WSAENOBUFS as ENOBUFS
    from errno import WSAEMFILE as EMFILE
    from errno import WSAECONNRESET as ECONNABORTED
    from errno import WSAEADDRINUSE as EADDRINUSE
    from errno import WSAEMSGSIZE as EMSGSIZE
    from errno import WSAENETRESET as ENETRESET
    from errno import WSAETIMEDOUT as ETIMEDOUT
    from errno import WSAECONNREFUSED as ECONNREFUSED
    from errno import WSAESHUTDOWN as ESHUTDOWN
    # No such thing as WSAENFILE, either.
    ENFILE = object()
    # Nor ENOMEM
    ENOMEM = object()
    EAGAIN = EWOULDBLOCK
    SOCKET_WRITE_ERRORS = (EINTR, ECONNRESET)
else:
    from errno import (EPERM, EINVAL, EWOULDBLOCK, EINPROGRESS, EALREADY,
                       ECONNRESET, EISCONN, ENOTCONN, EINTR, ENOBUFS, EMFILE,
                       ENFILE, ENOMEM, EAGAIN, ECONNABORTED, EADDRINUSE,
                       EMSGSIZE, ENETRESET, ETIMEDOUT, ECONNREFUSED, ESHUTDOWN,
                       EPIPE)
    SOCKET_WRITE_ERRORS = (EPIPE, EINTR, ECONNRESET)

ACCEPT_ERRORS = (EMFILE, ENOBUFS, ENFILE, ENOMEM, ECONNABORTED)
TRY_WRITE_AGAIN = (EWOULDBLOCK, ENOBUFS, EINPROGRESS)
TRY_READ_AGAIN = (EWOULDBLOCK, EAGAIN)

SOCKET_INTERRUPT_ERRORS = (EINTR, ECONNRESET)


def parse_address(netloc, default_port=8000):
    '''Parse an internet address ``netloc`` and return a tuple with
``host`` and ``port``.'''
    if isinstance(netloc, tuple):
        if len(netloc) != 2:
            raise ValueError('Invalid address %s' % str(netloc))
        return netloc
    #
    netloc = native_str(netloc)
    auth = None
    # Check if auth is available
    if '@' in netloc:
        auth, netloc = netloc.split('@')
    if netloc.startswith("unix:"):
        host = netloc.split("unix:")[1]
        return '%s@%s' % (auth, host) if auth else host
    # get host
    if '[' in netloc and ']' in netloc:
        host = netloc.split(']')[0][1:].lower()
    elif ':' in netloc:
        host = netloc.split(':')[0].lower()
    elif netloc == "":
        host = "0.0.0.0"
    else:
        host = netloc.lower()
    # get port
    netloc = netloc.split(']')[-1]
    if ":" in netloc:
        port = netloc.split(':', 1)[1]
        if not port.isdigit():
            raise ValueError("%r is not a valid port number." % port)
        port = int(port)
    else:
        port = default_port
    return ('%s@%s' % (auth, host) if auth else host, port)


def parse_connection_string(connection_string, default_port=8000):
    """Converts the ``connection_string`` into a three elements tuple
``(scheme, host, params)`` where ``scheme`` is a string, ``host`` could
be a string or a two elements tuple (for a tcp address) and ``params`` a
dictionary of parameters. The ``default_port`` parameter can be used to
set the port if a port is not available in the ``connection_string``.

For example::

    >>> parse_connection_string('http://127.0.0.1:9080')
    ('http', ('127.0.0.1', 9080), {})

and this example::

    >>> parse_connection_string('redis://127.0.0.1:6379?db=3&password=bla')
    ('redis', ('127.0.0.1', 6379), {'db': '3', 'password': 'bla'})
"""
    if '://' not in connection_string:
        connection_string = 'dummy://%s' % connection_string
    scheme, host, path, query, fragment = urlsplit(connection_string)
    if not scheme and not host:
        host, path = path, ''
    elif path and not query:
        query, path = path, ''
        if query:
            if query.find('?'):
                path = query
            else:
                query = query[1:]
    if path:
        raise ValueError("Address must not have a path. Found '%s'" % path)
    if query:
        params = dict(parse_qsl(query))
    else:
        params = {}
    if scheme == 'dummy':
        scheme = ''
    return scheme, parse_address(host, default_port), params


def get_connection_string(scheme, address, params):
    address = ':'.join((str(b) for b in address))
    if params:
        address += '?' + urlencode(params)
    return scheme + '://' + address


def is_socket_closed(sock):
    """Check if socket ``sock`` is closed."""
    if not sock:
        return True
    try:
        if not poll:    # pragma nocover
            if not select:
                return False
            try:
                return bool(select([sock], [], [], 0.0)[0])
            except socket.error:
                return True
        # This version is better on platforms that support it.
        p = poll()
        p.register(sock, POLLIN)
        for (fno, ev) in p.poll(0.0):
            if fno == sock.fileno():
                # Either data is buffered (bad), or the connection is dropped.
                return True
    except Exception:
        return True


def close_socket(sock):
    '''Shutdown and close the socket.'''
    if sock:
        try:
            sock.shutdown(socket.SHUT_RDWR)
        except Exception:
            pass
        try:
            sock.close()
        except Exception:
            pass


def nice_address(address, family=None):
    if isinstance(address, tuple):
        address = ':'.join((str(s) for s in address[:2]))
    return '%s %s' % (family, address) if family else address


def format_address(address):
    if isinstance(address, tuple):
        if len(address) == 2:
            return '%s:%s' % address
        elif len(address) == 4:
            return '[%s]:%s' % address[:2]
        else:
            raise ValueError('Could not format address %s' % str(address))
    else:
        return str(address)


class WrapSocket:   # pragma    nocover

    def __init__(self, sock):
        self.sock = sock

    def __getstate__(self):
        s = self.sock
        return {'sock': (s.fileno(), s.family, s.type, s.proto)}

    def __setstate__(self, state):
        values = state.pop('sock')
        self.sock = socket.fromfd(*values)


class SSLContext:
    '''A picklable SSLContext class
    '''
    def __init__(self, keyfile=None, certfile=None, cert_reqs=CERT_NONE,
                 ca_certs=None, server_hostname=None,
                 protocol=PROTOCOL_SSLv23):
        self.keyfile = keyfile
        self.certfile = certfile
        self.cert_reqs = cert_reqs
        self.ca_certs = ca_certs
        self.server_hostname = server_hostname
        self.protocol = protocol

    @property
    def verify_mode(self):
        return self.cert_reqs

    def wrap_socket(self, sock, server_side=False,
                    do_handshake_on_connect=True,
                    suppress_ragged_eofs=True, server_hostname=None):
        if not ssl:
            raise NotImplementedError
        server_hostname = self.server_hostname or server_hostname
        if not HAS_SNI:     # pragma    nocover
            server_hostname = None

        if _SSLContext:
            wrap = self._wrap3k(sock, server_hostname)
        else:   # pragma    nocover
            wrap = partial(wrap_socket, sock, keyfile=self.keyfile,
                           certfile=self.certfile, ca_certs=self.ca_certs,
                           cert_reqs=self.cert_reqs, ssl_version=self.protocol)
        return wrap(server_side=server_side,
                    do_handshake_on_connect=do_handshake_on_connect,
                    suppress_ragged_eofs=suppress_ragged_eofs)

    def _wrap3k(self, sock, server_hostname):
        context = _SSLContext(self.protocol)
        if self.cert_reqs:
            context.verify_mode = self.cert_reqs
        if self.ca_certs:
            try:
                context.load_verify_locations(self.ca_certs)
            # Py32 raises IOError
            # Py33 raises FileNotFoundError
            except Exception as e:  # Re-raise as SSLError
                raise SSLError(e)
        if self.certfile:
            # FIXME: This block needs a test.
            context.load_cert_chain(self.certfile, self.keyfile)
        if HAS_SNI:  # Platform-specific: OpenSSL with enabled SNI
            return partial(context.wrap_socket, sock,
                           server_hostname=server_hostname)
        else:   # pragma    nocover
            return partial(context.wrap_socket, sock)


def is_tls(sock):
    '''Check if ``sock`` is a socket over transport layer security
    '''
    return ssl and isinstance(sock, ssl.SSLSocket)


def ssl_context(context, server_side=False):
    if not ssl:
        raise NotImplementedError
    if server_side:
        assert isinstance(
            context, SSLContext), 'Must pass an SSLContext'
    else:
        # Client-side may pass ssl=True to use a default context.
        context = context or SSLContext()
    return context

########NEW FILE########
__FILENAME__ = log
'''
Module containing utilities and mixins for logging and serialisation.
'''
import sys
from copy import deepcopy, copy
from time import time
import logging
from threading import Lock
from functools import wraps
from multiprocessing import current_process

from .pep import force_native_str

win32 = sys.platform == "win32"

if sys.version_info < (2, 7):    # pragma    nocover
    from .fallbacks._dictconfig import dictConfig

    class NullHandler(logging.Handler):
        def emit(self, record):
            pass
else:
    from logging.config import dictConfig
    from logging import NullHandler

from .structures import AttributeDictionary


LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'verbose': {
            'format': ('%(asctime)s [p=%(process)s, t=%(thread)s,'
                       ' %(levelname)s, %(name)s] %(message)s'),
            'datefmt': '%H:%M:%S'
        },
        'very_verbose': {
            'format': '%(asctime)s [p=%(process)s,t=%(thread)s]'
                      ' [%(levelname)s] [%(name)s] %(message)s',
            'datefmt': '%Y-%m-%d %H:%M:%S'
        },
        'simple': {
            'format': '%(asctime)s %(levelname)s %(message)s',
            'datefmt': '%Y-%m-%d %H:%M:%S'
        },
        'level_message': {'format': '%(levelname)s - %(message)s'},
        'message': {'format': '%(message)s'}
    },
    'handlers': {
        'silent': {
            'class': 'pulsar.utils.log.Silence',
        },
        'console': {
            'level': 'DEBUG',
            'class': 'pulsar.utils.log.ColoredStream',
            'formatter': 'verbose'
        },
        'console_message': {
            'class': 'pulsar.utils.log.ColoredStream',
            'formatter': 'message'
        },
        'console_level_message': {
            'class': 'pulsar.utils.log.ColoredStream',
            'formatter': 'level_message'
        }
    },
    'filters ': {},
    'loggers': {},
    'root': {}
}


def update_config(config, c):
    for name in ('handlers', 'formatters', 'filters', 'loggers', 'root'):
        if name in c:
            config[name].update(c[name])


def local_method(f):
    '''Decorator to be used in conjunction with :class:`LocalMixin` methods.
    '''
    name = f.__name__

    def _(self, *args):
        local = self.local
        if name not in local:
            setattr(local, name, f(self, *args))
        return getattr(local, name)
    return _


def local_property(f):
    '''Decorator to be used in conjunction with :class:`LocalMixin` methods.
    '''
    name = f.__name__

    def _(self):
        local = self.local
        if name not in local:
            setattr(local, name, f(self))
        return getattr(local, name)

    return property(_, doc=f.__doc__)


def lazy_string(f):
    def _(*args, **kwargs):
        return LazyString(f, *args, **kwargs)
    return _


class LazyString:
    __slots__ = ('value', 'f', 'args', 'kwargs')

    def __init__(self, f, *args, **kwargs):
        self.value = None
        self.f = f
        self.args = args
        self.kwargs = kwargs

    def __str__(self):
        if self.value is None:
            self.value = force_native_str(self.f(*self.args, **self.kwargs))
        return self.value
    __repr__ = __str__


class WritelnDecorator(object):
    """Used to decorate file-like objects with a handy 'writeln' method.
    taken from python.
    """
    def __init__(self, stream):
        self.stream = stream

    def __getattr__(self, attr):
        if attr in ('stream', '__getstate__'):
            raise AttributeError(attr)
        return getattr(self.stream, attr)

    def writeln(self, arg=None):
        if arg:
            self.write(arg)
        self.write('\n')  # text-mode streams translate to \r\n if needed


class LocalMixin(object):
    '''Defines the :attr:`local` attribute.

    Classes derived from a :class:`LocalMixin` can use the
    :func:`local_method` and :func:`local_property` decorators for managing
    attributes which are not picklable.
    '''
    @property
    def local(self):
        '''A lazy :class:`pulsar.utils.structures.AttributeDictionary`.

        This attribute is removed when pickling an instance.
        '''
        if not hasattr(self, '_local'):
            self._local = AttributeDictionary()
        return self._local

    @local_property
    def lock(self):
        '''A local threading.Lock.'''
        return Lock()

    @local_property
    def process_lock(self):
        return process_global('lock')

    def clear_local(self):
        self.__dict__.pop('_local', None)

    def __getstate__(self):
        '''Remove the local dictionary.'''
        d = self.__dict__.copy()
        d.pop('_local', None)
        return d


def lazymethod(f):
    name = '_lazy_%s' % f.__name__

    @wraps(f)
    def _(self):
        if not hasattr(self, name):
            setattr(self, name, f(self))
        return getattr(self, name)

    return _


def lazyproperty(f):
    return property(lazymethod(f), doc=f.__doc__)


def process_global(name, val=None, setval=False):
    '''Access and set global variables for the current process.'''
    p = current_process()
    if not hasattr(p, '_pulsar_globals'):
        p._pulsar_globals = {'lock': Lock()}
    if setval:
        p._pulsar_globals[name] = val
    else:
        return p._pulsar_globals.get(name)


class Silence(logging.Handler):
    def emit(self, record):
        pass


def configured_logger(name, config=None, level=None, handlers=None):
    '''Configured logger.
    '''
    with process_global('lock'):
        logconfig = original = process_global('_config_logging')
        # if the logger was not configured, do so.
        if not logconfig:
            logconfig = deepcopy(LOGGING_CONFIG)
            if config:
                update_config(logconfig, config)
            original = logconfig
            process_global('_config_logging', logconfig, True)
        else:
            loggers = logconfig.get('loggers')
            if loggers and name in loggers:
                return logging.getLogger(name)
            logconfig = deepcopy(logconfig)
            logconfig['disable_existing_loggers'] = False
            logconfig.pop('loggers', None)
            logconfig.pop('root', None)

        if level is None:
            level = logging.NOTSET
        else:
            try:
                level = int(level)
            except ValueError:
                lv = str(level).upper()
                try:
                    level = logging._checkLevel(lv)
                except ValueError:
                    level = logging.NOTSET
        # No loggers configured. This means no logconfig setting
        # parameter was used. Set up the root logger with default
        # loggers
        if level == logging.NOTSET:
            handlers = ['silent']
        else:
            handlers = handlers or ['console']
        level = logging.getLevelName(level)
        if 'loggers' not in logconfig:
            logconfig['loggers'] = {}
        l = {'level': level, 'handlers': handlers, 'propagate': False}
        original['loggers'][name] = l
        logconfig['loggers'][name] = l
        #
        if not original.get('root'):
            logconfig['root'] = {'handlers': handlers,
                                 'level': level}
        if logconfig:
            dictConfig(logconfig)
        return logging.getLogger(name)


WHITE = 37
COLOURS = {'red': 31,
           'green': 32,
           'yellow': 33,
           'blue': 34,
           'magenta': 35,
           'cyan': 36,
           'white': WHITE}


class ColoredStream(logging.StreamHandler):   # pragma    nocover
    bold = True
    terminator = '\n'
    COLORS = {"DEBUG": "cyan",
              "WARNING": "magenta",
              "ERROR": "red",
              "CRITICAL": "red",
              "INFO": "green"}

    def __init__(self, stream=None):
        if not stream:
            stream = sys.stdout
        logging.StreamHandler.__init__(self, stream)

    def emit(self, record):
        try:
            self.color(record)
            self.flush()
        except (KeyboardInterrupt, SystemExit):  # pragma: no cover
            raise
        except:
            self.handleError(record)

    def color(self, record):
        text = self.format(record)
        file = self.stream
        if file.isatty() or True:
            colour = self.COLORS.get(record.levelname)
            code = COLOURS.get(colour, WHITE)
            if win32:
                handle = GetStdHandle(-11)
                oldcolors = GetConsoleInfo(handle).wAttributes
                code |= (oldcolors & 0x00F0)
                if self.bold:
                    code |= FOREGROUND_INTENSITY
                SetConsoleTextAttribute(handle, code)
                while len(text) > 32768:
                    file.write(text[:32768])
                    text = text[32768:]
                if text:
                    file.write(text)
                file.write(self.terminator)
                self.flush()
                SetConsoleTextAttribute(handle, oldcolors)
            else:
                text = '\x1b[%sm%s\x1b[0m' % (code, text)
                file.write(text)
                file.write(self.terminator)
                self.flush()
        else:
            file.write(text)
            file.write(self.terminator)
            self.flush()


if win32:   # pragma    nocover
    import ctypes
    from ctypes import wintypes

    SHORT = ctypes.c_short

    class COORD(ctypes.Structure):
        _fields_ = [('X', SHORT),
                    ('Y', SHORT)]

    class SMALL_RECT(ctypes.Structure):
        _fields_ = [('Left', SHORT),
                    ('Top', SHORT),
                    ('Right', SHORT),
                    ('Bottom', SHORT)]

    class CONSOLE_SCREEN_BUFFER_INFO(ctypes.Structure):
        _fields_ = [('dwSize', COORD),
                    ('dwCursorPosition', COORD),
                    ('wAttributes', wintypes.WORD),
                    ('srWindow', SMALL_RECT),
                    ('dwMaximumWindowSize', COORD)]

    WHITE = 0x0007
    FOREGROUND_INTENSITY = 0x0008
    COLOURS = {'red': 0x0004,
               'green': 0x0002,
               'yellow': 0x0006,
               'blue': 0x0001,
               'magenta': 0x0005,
               'cyan': 0x0003,
               'white': WHITE}

    _GetStdHandle = ctypes.windll.kernel32.GetStdHandle
    _GetStdHandle.argtypes = [wintypes.DWORD]
    _GetStdHandle.restype = wintypes.HANDLE

    def GetStdHandle(kind):
        return _GetStdHandle(kind)

    SetConsoleTextAttribute = ctypes.windll.kernel32.SetConsoleTextAttribute
    SetConsoleTextAttribute.argtypes = [wintypes.HANDLE, wintypes.WORD]
    SetConsoleTextAttribute.restype = wintypes.BOOL

    _GetConsoleScreenBufferInfo = \
        ctypes.windll.kernel32.GetConsoleScreenBufferInfo
    _GetConsoleScreenBufferInfo.argtypes = [
        wintypes.HANDLE, ctypes.POINTER(CONSOLE_SCREEN_BUFFER_INFO)]
    _GetConsoleScreenBufferInfo.restype = wintypes.BOOL

    def GetConsoleInfo(handle):
        info = CONSOLE_SCREEN_BUFFER_INFO()
        _GetConsoleScreenBufferInfo(handle, info)
        return info

########NEW FILE########
__FILENAME__ = multipart
'''
Parser for multipart/form-data
==============================

This module provides a parser for the multipart/form-data format. It can read
from a file, a socket or a WSGI environment.
'''
import re
import sys
from tempfile import TemporaryFile
from wsgiref.headers import Headers
from base64 import b64encode
from io import BytesIO

from .httpurl import parse_qs, ENCODE_BODY_METHODS, mapping_iterator
from .structures import MultiValueDict


def copy_file(stream, target, maxread=-1, buffer_size=2*16):
    ''' Read from :stream and write to :target until :maxread or EOF. '''
    size, read = 0, stream.read
    while 1:
        to_read = buffer_size if maxread < 0 else min(buffer_size,
                                                      maxread-size)
        part = read(to_read)
        if not part:
            return size
        target.write(part)
        size += len(part)

# ############################################################################
# ############################## Header Parser ###############################
# ############################################################################

_special = re.escape('()<>@,;:\\"/[]?={} \t')
_re_special = re.compile('[%s]' % _special)
_qstr = '"(?:\\\\.|[^"])*"'  # Quoted string
_value = '(?:[^%s]+|%s)' % (_special, _qstr)  # Save or quoted string
_option = '(?:;|^)\s*([^%s]+)\s*=\s*(%s)' % (_special, _value)
_re_option = re.compile(_option)  # key=value part of an Content-Type header


def header_quote(val):
    if not _re_special.search(val):
        return val
    return '"' + val.replace('\\', '\\\\').replace('"', '\\"') + '"'


def header_unquote(val, filename=False):
    if val[0] == val[-1] == '"':
        val = val[1:-1]
        if val[1:3] == ':\\' or val[:2] == '\\\\':
            val = val.split('\\')[-1]  # fix ie6 bug: full path --> filename
        return val.replace('\\\\', '\\').replace('\\"', '"')
    return val


def parse_options_header(header, options=None):
    if ';' not in header:
        return header.lower().strip(), {}
    ctype, tail = header.split(';', 1)
    options = options or {}
    for match in _re_option.finditer(tail):
        key = match.group(1).lower()
        value = header_unquote(match.group(2), key == 'filename')
        options[key] = value
    return ctype, options

# ############################################################################
# ################################ Multipart #################################
# ############################################################################


class MultipartError(ValueError):
    pass


class MultipartParser(object):

    def __init__(self, stream, boundary, content_length=-1,
                 disk_limit=2**30, mem_limit=2**20, memfile_limit=2**18,
                 buffer_size=2**16, charset='latin1'):
        ''' Parse a multipart/form-data byte stream. This object is an
        iterator over the parts of the message.

        :param stream: A file-like stream. Must implement ``.read(size)``.
        :param boundary: The multipart boundary as a byte string.
        :param content_length: The maximum number of bytes to read.
        '''
        self.stream, self.boundary = stream, boundary
        self.content_length = content_length
        self.disk_limit = disk_limit
        self.memfile_limit = memfile_limit
        self.mem_limit = min(mem_limit, self.disk_limit)
        self.buffer_size = min(buffer_size, self.mem_limit)
        self.charset = charset
        if self.buffer_size - 6 < len(boundary):  # "--boundary--\r\n"
            raise MultipartError('Boundary does not fit into buffer_size.')
        self._done = []
        self._part_iter = None
        self.separator = '--{0}'.format(self.boundary).encode()
        self.terminator = '--{0}--'.format(self.boundary).encode()

    def __iter__(self):
        ''' Iterate over the parts of the multipart message. '''
        if not self._part_iter:
            self._part_iter = self._iterparse()
        for part in self._done:
            yield part
        for part in self._part_iter:
            self._done.append(part)
            yield part

    def parts(self):
        ''' Returns a list with all parts of the multipart message. '''
        return list(iter(self))

    def get(self, name, default=None):
        ''' Return the first part with that name or a default value (None). '''
        for part in self:
            if name == part.name:
                return part
        return default

    def get_all(self, name):
        ''' Return a list of parts with that name. '''
        return [p for p in self if p.name == name]

    def _lineiter(self):
        ''' Iterate over a binary file-like object line by line. Each line is
            returned as a (line, line_ending) tuple. If the line does not fit
            into self.buffer_size, line_ending is empty and the rest of the
            lineis returned with the next iteration.
        '''
        read = self.stream.read
        maxread, maxbuf = self.content_length, self.buffer_size
        _bcrnl = b'\r\n'
        _bcr = _bcrnl[:1]
        _bnl = _bcrnl[1:]
        _bempty = _bcrnl[:0]  # b'rn'[:0] -> b''
        buffer = _bempty  # buffer for the last (partial) line
        while 1:
            data = read(maxbuf if maxread < 0 else min(maxbuf, maxread))
            maxread -= len(data)
            lines = (buffer+data).splitlines(True)
            len_first_line = len(lines[0])
            # be sure that the first line does not become too big
            if len_first_line > self.buffer_size:
                # at the same time don't split a '\r\n' accidentally
                if (len_first_line == self.buffer_size+1 and
                        lines[0].endswith(_bcrnl)):
                    splitpos = self.buffer_size - 1
                else:
                    splitpos = self.buffer_size
                lines[:1] = [lines[0][:splitpos],
                             lines[0][splitpos:]]
            if data:
                buffer = lines[-1]
                lines = lines[:-1]
            for line in lines:
                if line.endswith(_bcrnl):
                    yield line[:-2], _bcrnl
                elif line.endswith(_bnl):
                    yield line[:-1], _bnl
                elif line.endswith(_bcr):
                    yield line[:-1], _bcr
                else:
                    yield line, _bempty
            if not data:
                break

    def _iterparse(self):
        lines, line = self._lineiter(), ''
        separator = self.separator
        terminator = self.terminator
        # Consume first boundary. Ignore leading blank lines
        for line, nl in lines:
            if line:
                break
        if line != separator:
            raise MultipartError("Stream does not start with boundary")
        # For each part in stream...
        mem_used, disk_used = 0, 0  # Track used resources to prevent DoS
        is_tail = False  # True if the last line was incomplete (cutted)
        opts = {'buffer_size': self.buffer_size,
                'memfile_limit': self.memfile_limit,
                'charset': self.charset}
        part = MultipartPart(**opts)
        for line, nl in lines:
            if line == terminator and not is_tail:
                part.file.seek(0)
                yield part
                break
            elif line == separator and not is_tail:
                if part.is_buffered():
                    mem_used += part.size
                else:
                    disk_used += part.size
                part.file.seek(0)
                yield part
                part = MultipartPart(**opts)
            else:
                is_tail = not nl  # The next line continues this one
                part.feed(line, nl)
                if part.is_buffered():
                    if part.size + mem_used > self.mem_limit:
                        raise MultipartError("Memory limit reached.")
                elif part.size + disk_used > self.disk_limit:
                    raise MultipartError("Disk limit reached.")
        if line != terminator:
            raise MultipartError("Unexpected end of multipart stream.")


class MultipartPart(object):
    default_charset = 'latin1'

    def __init__(self, buffer_size=2**16, memfile_limit=2**18, charset=None):
        self.headerlist = []
        self.headers = None
        self.file = False
        self.size = 0
        self._buf = b''
        self.disposition, self.name, self.filename = None, None, None
        self.content_type = None
        self.charset = charset or self.default_charset
        self.memfile_limit = memfile_limit
        self.buffer_size = buffer_size

    def feed(self, line, nl=''):
        if self.file:
            return self.write_body(line, nl)
        return self.write_header(line, nl)

    def write_header(self, line, nl):
        line = line.decode(self.charset)
        if not nl:
            raise MultipartError('Unexpected end of line in header.')
        if not line.strip():  # blank line -> end of header segment
            self.finish_header()
        elif line[0] in ' \t' and self.headerlist:
            name, value = self.headerlist.pop()
            self.headerlist.append((name, value+line.strip()))
        else:
            if ':' not in line:
                raise MultipartError("Syntax error in header: No colon.")
            name, value = line.split(':', 1)
            self.headerlist.append((name.strip(), value.strip()))

    def write_body(self, line, nl):
        if not line and not nl:  # This does not even flush the buffer
            return
        self.size += len(line) + len(self._buf)
        self.file.write(self._buf + line)
        self._buf = nl
        if self.content_length > 0 and self.size > self.content_length:
            raise MultipartError('Size of body exceeds Content-Length header.')
        if self.size > self.memfile_limit and isinstance(self.file, BytesIO):
            # TODO: What about non-file uploads that exceed the memfile_limit?
            self.file, old = TemporaryFile(mode='w+b'), self.file
            old.seek(0)
            copy_file(old, self.file, self.size, self.buffer_size)

    def finish_header(self):
        self.file = BytesIO()
        self.headers = Headers(self.headerlist)
        cdis = self.headers.get('Content-Disposition', '')
        ctype = self.headers.get('Content-Type', '')
        clen = self.headers.get('Content-Length', '-1')
        if not cdis:
            raise MultipartError('Content-Disposition header is missing.')
        self.disposition, self.options = parse_options_header(cdis)
        self.name = self.options.get('name')
        self.filename = self.options.get('filename')
        self.content_type, options = parse_options_header(ctype)
        self.charset = options.get('charset') or self.charset
        self.content_length = int(self.headers.get('Content-Length', '-1'))

    def is_buffered(self):
        ''' Return true if the data is fully buffered in memory.'''
        return isinstance(self.file, BytesIO)

    def bytes(self):
        pos = self.file.tell()
        self.file.seek(0)
        val = self.file.read()
        self.file.seek(pos)
        return val

    def base64(self, charset=None):
        '''Data encoded as base 64'''
        return b64encode(self.bytes()).decode(charset or self.charset)

    def string(self, charset=None):
        '''Data decoded with the specified charset'''
        return self.bytes().decode(charset or self.charset)

    def save_as(self, path):
        fp = open(path, 'wb')
        pos = self.file.tell()
        try:
            self.file.seek(0)
            size = copy_file(self.file, fp)
        finally:
            self.file.seek(pos)
        return size


def parse_form_data(environ, charset='utf-8', strict=False, **kw):
    '''Parse form data from an environ dict and return a (forms, files) tuple.
Both tuple values are dictionaries with the form-field name as a key
(unicode) and lists as values (multiple values per key are possible).
The forms-dictionary contains form-field values as unicode strings.
The files-dictionary contains :class:`MultipartPart` instances, either
because the form-field was a file-upload or the value is to big to fit
into memory limits.

:parameter environ: A WSGI environment dict.
:parameter charset: The charset to use if unsure. (default: utf8)
:parameter strict: If True, raise :exc:`MultipartError` on any parsing
    errors. These are silently ignored by default.'''
    forms, files = MultiValueDict(), MultiValueDict()
    try:
        if (environ.get('REQUEST_METHOD', 'GET').upper()
                not in ENCODE_BODY_METHODS):
            raise MultipartError("Request method not valid.")
        content_length = int(environ.get('CONTENT_LENGTH', '-1'))
        content_type = environ.get('CONTENT_TYPE', '')
        if not content_type:
            raise MultipartError("Missing Content-Type header.")
        content_type, options = parse_options_header(content_type)
        stream = environ.get('wsgi.input') or BytesIO()
        kw['charset'] = charset = options.get('charset', charset)
        if content_type == 'multipart/form-data':
            boundary = options.get('boundary', '')
            if not boundary:
                raise MultipartError("No boundary for multipart/form-data.")
            for part in MultipartParser(stream, boundary,
                                        content_length, **kw):
                if part.filename or not part.is_buffered():
                    files[part.name] = part
                else:
                    forms[part.name] = part.string()
        elif content_type in ('application/x-www-form-urlencoded',
                              'application/x-url-encoded'):
            mem_limit = kw.get('mem_limit', 2**20)
            if content_length > mem_limit:
                raise MultipartError("Request to big. Increase MAXMEM.")
            data = stream.read(mem_limit).decode(charset)
            if stream.read(1):  # These is more that does not fit mem_limit
                raise MultipartError("Request to big. Increase MAXMEM.")
            data = parse_qs(data, keep_blank_values=True)
            for key, values in mapping_iterator(data):
                for value in values:
                    forms[key] = value
        else:
            raise MultipartError("Unsupported content type.")
    except MultipartError:
        if strict:
            raise
    return forms, files

########NEW FILE########
__FILENAME__ = numbers
from time import mktime
from datetime import datetime, timedelta


def date2timestamp(dte):
    '''Convert a *dte* into a valid unix timestamp.'''
    seconds = mktime(dte.timetuple())
    if isinstance(dte, datetime):
        return seconds + dte.microsecond / 1000000.0
    else:
        return int(seconds)

########NEW FILE########
__FILENAME__ = path
'''Stand alone compact module for managing python paths.'''
import os
import sys

from .importer import import_module
from .pep import range, string_type


__all__ = ['Path']


class Path(string_type):
    '''A lightweight utility for the filesystem and python modules.'''
    def __new__(cls, path=None):
        path = path or ''
        abspath = os.path.abspath(path)
        return super(Path, cls).__new__(cls, abspath)

    @classmethod
    def cwd(cls):
        '''Return the current working directory as a path object.'''
        return cls(os.getcwd())

    isfile = lambda self: os.path.isfile(self)
    isdir = lambda self: os.path.isdir(self)
    exists = lambda self: os.path.exists(self)
    realpath = lambda self: self.__class__(os.path.realpath(string_type(self)))

    def join(self, *path):
        return self.__class__(os.path.join(self, *path))

    def split(self):
        d, f = os.path.split(self)
        return self.__class__(d), f

    def dir(self):
        if self.isfile():
            return self.parent
        elif self.isdir():
            return self
        else:
            raise ValueError('%s not a valid directory' % self)

    @property
    def basename(self):
        return os.path.basename(self)

    @property
    def parent(self):
        return self.__class__(os.path.dirname(self))

    def module_name(self):
        name = os.path.basename(self)
        if name.endswith('.py'):
            return name[:-3]
        if name.endswith('.pyc'):
            return name[:-4]
        else:
            raise ValueError('%s not a valid python module' % self)

    def ancestor(self, n):
        p = self
        for i in range(n):
            p = p.parent
        return p

    def ispymodule(self):
        '''Check if this :class:`Path` is a python module.'''
        if self.isdir():
            return os.path.isfile(os.path.join(self, '__init__.py'))
        elif self.isfile():
            return self.endswith('.py')

    def add2python(self, module=None, up=0, down=None, front=False,
                   must_exist=True):
        '''Add a directory to the python path.

:parameter module: Optional module name to try to import once we have found
    the directory
:parameter up: number of level to go up the directory three from
    :attr:`local_path`.
:parameter down: Optional tuple of directory names to travel down once we have
    gone *up* levels.
:parameter front: Boolean indicating if we want to insert the new path at the
    front of ``sys.path`` using ``sys.path.insert(0,path)``.
:parameter must_exist: Boolean indicating if the module must exists.'''
        if module:
            try:
                return import_module(module)
            except ImportError:
                pass
        dir = self.dir().ancestor(up)
        if down:
            dir = dir.join(*down)
        if dir.isdir():
            if dir not in sys.path:
                if front:
                    sys.path.insert(0, dir)
                else:
                    sys.path.append(dir)
        elif must_exist:
            raise ImportError('Directory {0} not available'.format(dir))
        else:
            return None
        if module:
            try:
                return import_module(module)
            except ImportError:
                if must_exist:
                    raise

########NEW FILE########
__FILENAME__ = pep
import sys
import time
import string
import threading
from inspect import istraceback

try:    # pragma    nocover
    from asyncio.py33_exceptions import reraise
except ImportError:

    def reraise(tp, value, tb=None):
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
        raise value


ispy3k = sys.version_info >= (3, 0)

if ispy3k:
    default_timer = time.monotonic
else:   # pragma    nocover
    default_timer = time.time

try:
    pypy = True
    import __pypy__
except ImportError:
    pypy = False

if ispy3k:  # Python 3
    import pickle
    string_type = str
    ascii_letters = string.ascii_letters
    zip = zip
    map = map
    range = range
    chr = chr
    iteritems = lambda d: d.items()
    itervalues = lambda d: d.values()
    is_string = lambda s: isinstance(s, str)

    def to_bytes(s, encoding=None, errors=None):
        '''Convert *s* into bytes'''
        if not isinstance(s, bytes):
            return ('%s' % s).encode(encoding or 'utf-8', errors or 'strict')
        elif not encoding or encoding == 'utf-8':
            return s
        else:
            d = s.decode('utf-8')
            return d.encode(encoding, errors or 'strict')

    def to_string(s, encoding=None, errors='strict'):
        """Inverse of to_bytes"""
        if isinstance(s, bytes):
            return s.decode(encoding or 'utf-8', errors)
        else:
            return str(s)

    def native_str(s, encoding=None):
        if isinstance(s, bytes):
            return s.decode(encoding or 'utf-8')
        else:
            return s

    def force_native_str(s, encoding=None):
        if isinstance(s, bytes):
            return s.decode(encoding or 'utf-8')
        elif not isinstance(s, str):
            return str(s)
        else:
            return s

else:   # pragma : no cover
    from itertools import izip as zip, imap as map
    import cPickle as pickle
    string_type = unicode
    ascii_letters = string.letters
    range = xrange
    chr = unichr
    iteritems = lambda d: d.iteritems()
    itervalues = lambda d: d.itervalues()
    is_string = lambda s: isinstance(s, basestring)

    def to_bytes(s, encoding=None, errors='strict'):
        encoding = encoding or 'utf-8'
        if isinstance(s, bytes):
            if encoding != 'utf-8':
                return s.decode('utf-8', errors).encode(encoding, errors)
            else:
                return s
        else:
            return unicode(s).encode(encoding, errors)

    def to_string(s, encoding=None, errors='strict'):
        """Inverse of to_bytes"""
        if isinstance(s, bytes):
            return s.decode(encoding or 'utf-8', errors)
        else:
            return unicode(s)

    def native_str(s, encoding=None):
        if isinstance(s, unicode):
            return s.encode(encoding or 'utf-8')
        else:
            return s

    def force_native_str(s, encoding=None):
        if isinstance(s, unicode):
            return s.encode(encoding or 'utf-8')
        elif not isinstance(s, str):
            return str(s)
        else:
            return s

########NEW FILE########
__FILENAME__ = security
"""\
Security related helpers such as secure password hashing tools.
"""
from hashlib import sha1
from uuid import uuid4
import string
from random import SystemRandom, choice

from .pep import range
from .httpurl import ascii_letters

SALT_CHARS = ascii_letters + string.digits


_sys_rng = SystemRandom()


def gen_unique_id():
    return 'i%s' % uuid4().hex


def gen_salt(length):
    """Generate a random string of SALT_CHARS with specified ``length``."""
    if length <= 0:
        raise ValueError('requested salt of length <= 0')
    return ''.join(_sys_rng.choice(SALT_CHARS) for _ in range(length))


def _hash_internal(salt, password):
    return sha1(('%s%s' % (salt, password)).encode('utf-8')).hexdigest()


def generate_password_hash(password, salt_length=8):
    salt = gen_salt(salt_length)
    h = _hash_internal(salt, password)
    return '%s$%s' % (salt, h)


def check_password_hash(pwhash, password):
    if pwhash.count('$') != 1:
        return False
    salt, hashval = pwhash.split('$')
    return _hash_internal(salt, password) == hashval


def random_string(characters=None, length=None):
    length = length or 20
    characters = characters or SALT_CHARS
    return ''.join((choice(characters) for s in range(length)))

########NEW FILE########
__FILENAME__ = backend
'''
Importing this module to add this extra settings to pulsar
'''
import pulsar


class BackendServer(pulsar.Setting):
    name = 'backend_server'
    flags = ['-s', '--backend-server']
    meta = "CONNECTION STRING"
    default = ''
    validator = pulsar.validate_string
    desc = 'Connection string to a backend server'

########NEW FILE########
__FILENAME__ = misc
from copy import copy
from itertools import islice
import collections

from ..pep import ispy3k, iteritems

Mapping = collections.Mapping


def mapping_iterator(iterable):
    if isinstance(iterable, Mapping):
        iterable = iteritems(iterable)
    return iterable


def inverse_mapping(iterable):
    if isinstance(iterable, Mapping):
        iterable = iteritems(iterable)
    return ((value, key) for key, value in iterable)


def isgenerator(value):
    return hasattr(value, '__iter__') and not hasattr(value, '__len__')


def aslist(value):
    if isinstance(value, list):
        return value
    if isgenerator(value) or isinstance(value, (tuple, set, frozenset)):
        return list(value)
    else:
        return [value]


class MultiValueDict(dict):
    """A subclass of dictionary customized to handle multiple
values for the same key.
    """
    def __init__(self, data=None):
        super(MultiValueDict, self).__init__()
        if data:
            self.update(data)

    def __getitem__(self, key):
        """Returns the data value for this key. If the value is a list with
only one element, it returns that element, otherwise it returns the list.
Raises KeyError if key is not found."""
        l = super(MultiValueDict, self).__getitem__(key)
        return l[0] if len(l) == 1 else l

    def __setitem__(self, key, value):
        if key in self:
            l = super(MultiValueDict, self).__getitem__(key)
            # if value already there don't add it.
            # I'm not sure this is the correct way of doing thing but
            # it makes sense not to have repeating items
            if value not in l:
                l.append(value)
        else:
            super(MultiValueDict, self).__setitem__(key, [value])

    def update(self, items):
        if isinstance(items, dict):
            items = iteritems(items)
        for k, v in items:
            self[k] = v

    def __copy__(self):
        return self.__class__(((k, v[:]) for k, v in self.lists()))

    def get(self, key, default=None):
        try:
            return self[key]
        except KeyError:
            return default

    def pop(self, key, *arg):
        if key in self:
            l = super(MultiValueDict, self).pop(key)
            return l[0] if len(l) == 1 else l
        else:
            return super(MultiValueDict, self).pop(key, *arg)

    def getlist(self, key):
        """Returns the list of values for the passed key."""
        return super(MultiValueDict, self).__getitem__(key)

    def setlist(self, key, _list):
        if key in self:
            self.getlist(key).extend(_list)
        else:
            _list = aslist(_list)
            super(MultiValueDict, self).__setitem__(key, _list)

    def setdefault(self, key, default=None):
        if key not in self:
            self[key] = default
        return self[key]

    def extend(self, key, values):
        """Appends an item to the internal list associated with key."""
        for value in values:
            self[key] = value

    def items(self):
        """Returns a generator of (key, value) pairs.
        """
        return ((key, self[key]) for key in self)

    def lists(self):
        """Returns a list of (key, list) pairs."""
        return super(MultiValueDict, self).items()

    def values(self):
        """Returns a list of the last value on every key list."""
        return [self[key] for key in self.keys()]

    def copy(self):
        return copy(self)

    def update(self, elem):
        if isinstance(elem, Mapping):
            elem = elem.items()
        for key, val in elem:
            self.extend(key, aslist(val))


class AttributeDictionary(collections.Mapping):
    '''A :class:`Mapping` structures which exposes keys as attributes.'''
    def __init__(self, *iterable, **kwargs):
        if iterable:
            if len(iterable) > 1:
                raise TypeError('%s exceped at most 1 arguments, got %s.' %
                                (self.__class__.__name__, len(iterable)))
            self.update(iterable[0])
        if kwargs:
            self.update(kwargs)

    def __repr__(self):
        return repr(self.__dict__)

    def __str__(self):
        return str(self.__dict__)

    def __contains__(self, name):
        return name in self.__dict__

    def __len__(self):
        return len(self.__dict__)

    def __iter__(self):
        return iter(self.__dict__)

    def __getattr__(self, name):
        return self.__dict__.get(name)

    def __setattr__(self, name, value):
        self.__dict__[name] = value

    def __setitem__(self, name, value):
        self.__dict__[name] = value

    def __getitem__(self, name):
        return self.__dict__[name]

    def update(self, iterable):
        for name, value in mapping_iterator(iterable):
            setattr(self, name, value)

    def all(self):
        return self.__dict__

    def pop(self, name, default=None):
        return self.__dict__.pop(name, default)

    def values(self):
        return self.__dict__.values()

    def items(self):
        return self.__dict__.items()

    if not ispy3k:   # pragma    nocover
        def itervalues(self):
            return self.__dict__.itervalues()

        def iteritems(self):
            return self.__dict__.iteritems()


class FrozenDict(dict):
    '''A dictionary which cannot be changed once initialised.'''

    def __init__(self, *iterable, **kwargs):
        update = super(FrozenDict, self).update
        if iterable:
            if len(iterable) > 1:
                raise TypeError('%s exceped at most 1 arguments, got %s.' %
                                (self.__class__.__name__, len(iterable)))
            update(iterable[0])
        if kwargs:
            update(kwargs)

    def __setitem__(self, key, value):
        raise TypeError("'%s' object does not support item assignment"
                        % self.__class__.__name__)

    def update(self, iterable):
        raise TypeError("'%s' object does not support update"
                        % self.__class__.__name__)

    def pop(self, key):
        raise TypeError("'%s' object does not support pop"
                        % self.__class__.__name__)

    def __gt__(self, other):
        if hasattr(other, '__len__'):
            return len(self) > len(other)
        else:
            return False

    def __lt__(self, other):
        if hasattr(other, '__len__'):
            return len(self) < len(other)
        else:
            return False


class Dict(dict):

    def mget(self, fields):
        return [self.get(f) for f in fields]

    def flat(self):
        result = []
        [result.extend(pair) for pair in iteritems(self)]
        return result


class Deque(collections.deque):

    def insert_before(self, pivot, value):
        l = list(self)
        try:
            index = l.index(pivot)
        except ValueError:
            pass
        else:
            l.insert(index, value)
            self.clear()
            self.extend(l)

    def insert_after(self, pivot, value):
        l = list(self)
        try:
            index = l.index(pivot)
        except ValueError:
            pass
        else:
            l.insert(index+1, value)
            self.clear()
            self.extend(l)

    def remove(self, elem, count=1):
        rev = False
        if count:
            if count < 0:
                rev = True
                count = -count
                l = list(reversed(self))
            else:
                l = list(self)
            while count:
                try:
                    l.remove(elem)
                    count -= 1
                except ValueError:
                    break
        else:
            l = [v for v in self if v != elem]
        removed = len(self) - len(l)
        if removed:
            self.clear()
            self.extend(reversed(l) if rev else l)
        return removed

    def trim(self, start, end):
        slice = list(islice(self, start, end))
        self.clear()
        self.extend(slice)


def merge_prefix(deque, size):
    """Replace the first entries in a deque of bytes with a single
string of up to *size* bytes."""
    if len(deque) == 1 and len(deque[0]) <= size:
        return
    prefix = []
    remaining = size
    while deque and remaining > 0:
        chunk = deque.popleft()
        if len(chunk) > remaining:
            deque.appendleft(chunk[remaining:])
            chunk = chunk[:remaining]
        prefix.append(chunk)
        remaining -= len(chunk)
    if prefix:
        deque.appendleft(b''.join(prefix))
    elif not deque:
        deque.appendleft(b'')


def recursive_update(target, mapping):
    for key, value in iteritems(mapping):
        if value is not None:
            if key in target:
                cont = target[key]
                if isinstance(value, Mapping) and isinstance(cont, Mapping):
                    recursive_update(cont, value)
                else:
                    target[key] = value
            else:
                target[key] = value

########NEW FILE########
__FILENAME__ = skiplist
# Modified version of skiplist
# http://code.activestate.com/recipes/
#    576930-efficient-running-median-using-an-indexable-skipli/
import sys
from random import random
from math import log
from collections import Sequence

ispy3k = int(sys.version[0]) >= 3

if not ispy3k:
    range = xrange


class Node(object):
    __slots__ = ('score', 'value', 'next', 'width')

    def __init__(self, score, value, next, width):
        self.score, self.value, self.next, self.width = (score, value,
                                                         next, width)


SKIPLIST_MAXLEVEL = 32     # Should be enough for 2^32 elements

neg_inf = float('-inf')
inf = float('inf')


class Skiplist(Sequence):
    '''Sorted collection supporting O(log n) insertion,
    removal, and lookup by rank.'''
    __slots__ = ('_unique', '_size', '_head', '_level')

    def __init__(self, data=None, unique=False):
        self._unique = unique
        self.clear()
        if data is not None:
            self.extend(data)

    def __repr__(self):
        return list(self).__repr__()

    def __str__(self):
        return self.__repr__()

    def __len__(self):
        return self._size

    def __getitem__(self, index):
        node = self._head
        traversed = 0
        index += 1
        for i in range(self._level-1, -1, -1):
            while node.next[i] and (traversed + node.width[i]) <= index:
                traversed += node.width[i]
                node = node.next[i]
            if traversed == index:
                return node.value
        raise IndexError('skiplist index out of range')

    def clear(self):
        '''Clear the container from all data.'''
        self._size = 0
        self._level = 1
        self._head = Node('HEAD', None,
                          [None]*SKIPLIST_MAXLEVEL,
                          [1]*SKIPLIST_MAXLEVEL)

    def extend(self, iterable):
        '''Extend this skiplist with an iterable over
        ``score``, ``value`` pairs.
        '''
        i = self.insert
        for score_values in iterable:
            i(*score_values)
    update = extend

    def rank(self, score):
        '''Return the 0-based index (rank) of ``score``.

        If the score is not available it returns a negative integer which
        absolute score is the right most closest index with score less than
        ``score``.
        '''
        node = self._head
        rank = 0
        for i in range(self._level-1, -1, -1):
            while node.next[i] and node.next[i].score < score:
                rank += node.width[i]
                node = node.next[i]
        node = node.next[0]
        if node and node.score == score:
            return rank
        else:
            return -2 - rank

    def range(self, start=0, end=None, scores=False):
        N = len(self)
        if start < 0:
            start = max(N + start, 0)
        if start >= N:
            raise StopIteration
        if end is None:
            end = N
        elif end < 0:
            end = max(N + end, 0)
        else:
            end = min(end, N)
        if start >= end:
            raise StopIteration
        node = self._head.next[0]
        index = 0
        while node:
            if index >= start:
                if index < end:
                    yield (node.score, node.value) if scores else node.value
                else:
                    break
            index += 1
            node = node.next[0]

    def range_by_score(self, minval, maxval, include_min=True,
                       include_max=True, start=0, num=None, scores=False):
        node = self._head
        if include_min:
            for i in range(self._level-1, -1, -1):
                while node.next[i] and node.next[i].score < minval:
                    node = node.next[i]
        else:
            for i in range(self._level-1, -1, -1):
                while node.next[i] and node.next[i].score <= minval:
                    node = node.next[i]
        node = node.next[0]
        if node and node.score >= minval:
            index = 0
            while node:
                index += 1
                if num is not None and index - start > num:
                    break
                if ((include_max and node.score > maxval) or
                        (not include_max and node.score >= maxval)):
                    break
                if index > start:
                    yield (node.score, node.value) if scores else node.value
                node = node.next[0]

    def insert(self, score, value):
        # find first node on each level where node.next[levels].score > score
        if score != score:
            raise ValueError('Cannot insert score {0}'.format(score))
        chain = [None] * SKIPLIST_MAXLEVEL
        rank = [0] * SKIPLIST_MAXLEVEL
        node = self._head
        for i in range(self._level-1, -1, -1):
            # store rank that is crossed to reach the insert position
            rank[i] = 0 if i == self._level-1 else rank[i+1]
            while node.next[i] and node.next[i].score <= score:
                rank[i] += node.width[i]
                node = node.next[i]
            chain[i] = node
        # the score already exist
        if chain[0].score == score and self._unique:
            return
        # insert a link to the newnode at each level
        level = min(SKIPLIST_MAXLEVEL, 1 - int(log(random(), 2.0)))
        if level > self._level:
            for i in range(self._level, level):
                rank[i] = 0
                chain[i] = self._head
                chain[i].width[i] = self._size
            self._level = level

        # create the new node
        node = Node(score, value, [None]*level, [None]*level)
        for i in range(level):
            prevnode = chain[i]
            steps = rank[0] - rank[i]
            node.next[i] = prevnode.next[i]
            node.width[i] = prevnode.width[i] - steps
            prevnode.next[i] = node
            prevnode.width[i] = steps + 1

        # increment width for untouched levels
        for i in range(level, self._level):
            chain[i].width[i] += 1

        self._size += 1
        return node

    def remove_range(self, start, end, callback=None):
        '''Remove a range by rank.

        This is equivalent to perform::

            del l[start:end]

        on a python list.
        It returns the number of element removed.
        '''
        N = len(self)
        if start < 0:
            start = max(N + start, 0)
        if start >= N:
            return 0
        if end is None:
            end = N
        elif end < 0:
            end = max(N + end, 0)
        else:
            end = min(end, N)
        if start >= end:
            return 0
        node = self._head
        index = 0
        chain = [None] * self._level
        for i in range(self._level-1, -1, -1):
            while node.next[i] and (index + node.width[i]) <= start:
                index += node.width[i]
                node = node.next[i]
            chain[i] = node
        node = node.next[0]
        initial = self._size
        while node and index < end:
            next = node.next[0]
            self._remove_node(node, chain)
            index += 1
            if callback:
                callback(node.score, node.value)
            node = next
        return initial - self._size

    def remove_range_by_score(self, minval, maxval, include_min=True,
                              include_max=True, callback=None):
        '''Remove a range with scores between ``minval`` and ``maxval``.

        :param minval: the start value of the range to remove
        :param maxval: the end value of the range to remove
        :param include_min: whether or not to include ``minval`` in the
            values to remove
        :param include_max: whether or not to include ``maxval`` in the
            scores to to remove
        :param callback: optional callback function invoked for each
            score, value pair removed.
        :return: the number of elements removed.
        '''
        node = self._head
        chain = [None] * self._level
        if include_min:
            for i in range(self._level-1, -1, -1):
                while node.next[i] and node.next[i].score < minval:
                    node = node.next[i]
                chain[i] = node
        else:
            for i in range(self._level-1, -1, -1):
                while node.next[i] and node.next[i].score <= minval:
                    node = node.next[i]
                chain[i] = node
        node = node.next[0]
        initial = self._size
        while node and node.score >= minval:
            if ((include_max and node.score > maxval) or
                    (not include_max and node.score >= maxval)):
                break
            next = node.next[0]
            self._remove_node(node, chain)
            if callback:
                callback(node.score, node.value)
            node = next
        return initial - self._size

    def count(self, minval, maxval, include_min=True, include_max=True):
        '''Returns the number of elements in the skiplist with a score
        between min and max.
        '''
        rank1 = self.rank(minval)
        if rank1 < 0:
            rank1 = -rank1 - 1
        elif not include_min:
            rank1 += 1
        rank2 = self.rank(maxval)
        if rank2 < 0:
            rank2 = -rank2 - 1
        elif include_max:
            rank2 += 1
        return max(rank2 - rank1, 0)

    def __iter__(self):
        'Iterate over values in sorted order'
        node = self._head.next[0]
        while node:
            yield node.score, node.value
            node = node.next[0]

    def flat(self):
        return tuple(self._flat())

    def _flat(self):
        node = self._head.next[0]
        while node:
            yield node.score
            yield node.value
            node = node.next[0]

    def _remove_node(self, node, chain):
        for i in range(self._level):
            if chain[i].next[i] == node:
                chain[i].width[i] += node.width[i] - 1
                chain[i].next[i] = node.next[i]
            else:
                chain[i].width[i] -= 1
        self._size -= 1


class SkipListSlice(object):
    __slots__ = ('sl', 'slice')

    def __init__(self, sl, slice):
        self.sl = sl
        self.slice = slice

########NEW FILE########
__FILENAME__ = zset
from .skiplist import Skiplist
from ..pep import iteritems, zip


class Zset(object):
    '''Ordered-set equivalent of redis zset.
    '''
    def __init__(self, data=None):
        self._sl = Skiplist()
        self._dict = {}
        if data:
            self.update(data)

    def __repr__(self):
        return repr(self._sl)
    __str__ = __repr__

    def __len__(self):
        return len(self._dict)

    def __iter__(self):
        for _, value in self._sl:
            yield value

    def __getstate__(self):
        return self._dict

    def __setstate__(self, state):
        self._dict = state
        self._sl = Skiplist(((score, member) for member, score
                             in iteritems(state)))

    def __eq__(self, other):
        if isinstance(other, Zset):
            return other._dict == self._dict
        return False

    def items(self):
        '''Iterable over ordered score, value pairs of this :class:`zset`
        '''
        return iter(self._sl)

    def range(self, start, end, scores=False):
        return self._sl.range(start, end, scores)

    def range_by_score(self, minval, maxval, include_min=True,
                       include_max=True, start=0, num=None, scores=False):
        return self._sl.range_by_score(minval, maxval, start=start,
                                       num=num, include_min=include_min,
                                       include_max=include_max,
                                       scores=scores)

    def score(self, member, default=None):
        '''The score of a given member'''
        return self._dict.get(member, default)

    def count(self, minval, maxval, include_min=True, include_max=True):
        return self._sl.count(minval, maxval, include_min, include_max)

    def add(self, score, val):
        r = 1
        if val in self._dict:
            sc = self._dict[val]
            if sc == score:
                return 0
            self.remove(val)
            r = 0
        self._dict[val] = score
        self._sl.insert(score, val)
        return r

    def update(self, score_vals):
        '''Update the :class:`zset` with an iterable over pairs of
scores and values.'''
        add = self.add
        for score, value in score_vals:
            add(score, value)

    def remove_items(self, items):
        removed = 0
        for item in items:
            score = self.remove(item)
            if score is not None:
                removed += 1
        return removed

    def remove(self, item):
        '''Remove ``item`` for the :class:`zset` it it exists.
        If found it returns the score of the item removed.
        '''
        score = self._dict.pop(item, None)
        if score is not None:
            index = self._sl.rank(score)
            assert index >= 0, 'could not find start range'
            for i, v in enumerate(self._sl.range(index)):
                if v == item:
                    assert self._sl.remove_range(index + i, index+i + 1) == 1
                    return score
            assert False, 'could not find element'

    def remove_range(self, start, end):
        '''Remove a range by score.
        '''
        return self._sl.remove_range(
            start, end, callback=lambda sc, value: self._dict.pop(value))

    def remove_range_by_score(self, minval, maxval,
                              include_min=True, include_max=True):
        '''Remove a range by score.
        '''
        return self._sl.remove_range_by_score(
            minval, maxval, include_min=include_min, include_max=include_max,
            callback=lambda sc, value: self._dict.pop(value))

    def clear(self):
        '''Clear this :class:`zset`.'''
        self._sl = skiplist()
        self._dict.clear()

    def rank(self, item):
        '''Return the rank (index) of ``item`` in this :class:`zset`.'''
        score = self._dict.get(item)
        if score is not None:
            return self._sl.rank(score)

    def flat(self):
        return self._sl.flat()

    @classmethod
    def union(cls, zsets, weights, oper):
        result = None
        for zset, weight in zip(zsets, weights):
            if result is None:
                result = cls()
                sl = result._sl
                for score, value in zset._sl:
                    result.add(score*weight, value)
            else:
                for score, value in zset._sl:
                    score *= weight
                    existing = sl.score(value)
                    if existing is not None:
                        score = oper(score, existing)
                    result.add(score, value)
        return result

    @classmethod
    def inter(cls, zsets, weights, oper):
        result = None
        values = None
        for zset, _ in zip(zsets, weights):
            if values is None:
                values = set(zset)
            else:
                values.intersection_update(zset)
        #
        for zset, weight in zip(zsets, weights):
            if result is None:
                result = cls()
                sl = result._sl
                for score, value in zset._sl:
                    if value in values:
                        result.add(score*weight, value)
            else:
                for score, value in zset._sl:
                    if value in values:
                        existing = result.score(value)
                        score = oper((score*weight, existing))
                        result.add(score, value)
        return result

########NEW FILE########
__FILENAME__ = base
try:
    import signal
except ImportError:
    signal = None


__all__ = ['ALL_SIGNALS',
           'SIG_NAMES',
           'SKIP_SIGNALS',
           'MAXFD',
           'set_proctitle']


SIG_NAMES = {}
MAXFD = 1024
SKIP_SIGNALS = frozenset(('KILL', 'STOP', 'WINCH'))


def all_signals():
    if signal:
        for sig in dir(signal):
            if sig.startswith('SIG') and sig[3] != "_":
                val = getattr(signal, sig)
                if isinstance(val, int):
                    name = sig[3:]
                    if name not in SKIP_SIGNALS:
                        SIG_NAMES[val] = name
                        yield name


ALL_SIGNALS = tuple(all_signals())


try:
    from setproctitle import setproctitle

    def set_proctitle(title):
        setproctitle(title)
        return True
except ImportError:  # pragma    nocover

    def set_proctitle(title):
        return

########NEW FILE########
__FILENAME__ = posixsystem
import os
import fcntl
import resource
import grp
import pwd
import signal
import socket
import ctypes
from multiprocessing import Pipe

from .base import *

__all__ = ['close_on_exec',
           'Waker',
           'daemonize',
           'socketpair',
           'EXIT_SIGNALS',
           'get_uid',
           'get_gid',
           'get_maxfd',
           'set_owner_process']

# standard signal quit
EXIT_SIGNALS = (signal.SIGINT, signal.SIGTERM, signal.SIGABRT, signal.SIGQUIT)
# Default maximum for the number of available file descriptors.
REDIRECT_TO = getattr(os, "devnull", "/dev/null")

socketpair = socket.socketpair


def get_parent_id():
    return os.getppid()


def chown(path, uid, gid):
    try:
        os.chown(path, uid, gid)
    except OverflowError:
        os.chown(path, uid, -ctypes.c_int(-gid).value)


def close_on_exec(fd):
    if fd:
        flags = fcntl.fcntl(fd, fcntl.F_GETFD)
        fcntl.fcntl(fd, fcntl.F_SETFD, flags | fcntl.FD_CLOEXEC)


def _set_non_blocking(fd):
    flags = fcntl.fcntl(fd, fcntl.F_GETFL) | os.O_NONBLOCK
    fcntl.fcntl(fd, fcntl.F_SETFL, flags)


def get_uid(user=None):
    if not user:
        return os.geteuid()
    elif user.isdigit() or isinstance(user, int):
        return int(user)
    else:
        return pwd.getpwnam(user).pw_uid


def get_gid(group=None):
    if not group:
        return os.getegid()
    elif group.isdigit() or isinstance(group, int):
        return int(group)
    else:
        return grp.getgrnam(group).gr_gid


def set_owner_process(uid, gid):
    """ set user and group of workers processes """
    if gid:
        try:
            os.setgid(gid)
        except OverflowError:
            # versions of python < 2.6.2 don't manage unsigned int for
            # groups like on osx or fedora
            os.setgid(-ctypes.c_int(-gid).value)
    if uid:
        os.setuid(uid)


def setpgrp():
    os.setpgrp()


def get_maxfd():
    maxfd = resource.getrlimit(resource.RLIMIT_NOFILE)[1]
    if (maxfd == resource.RLIM_INFINITY):
        maxfd = MAXFD
    return maxfd


def daemonize():    # pragma    nocover
    """Standard daemonization of a process. Code is based on the
ActiveState recipe at http://code.activestate.com/recipes/278731/"""
    if os.fork() == 0:
        os.setsid()
        if os.fork() != 0:
            os.umask(0)
        else:
            os._exit(0)
    else:
        os._exit(0)
    maxfd = get_maxfd()
    # Iterate through and close all file descriptors.
    for fd in range(0, maxfd):
        try:
            os.close(fd)
        except OSError:    # ERROR, fd wasn't open to begin with (ignored)
            pass
    os.open(REDIRECT_TO, os.O_RDWR)
    os.dup2(0, 1)
    os.dup2(0, 2)


class Waker(object):

    def __init__(self):
        r, w = Pipe(duplex=False)
        _set_non_blocking(r.fileno())
        _set_non_blocking(w.fileno())
        close_on_exec(r.fileno())
        close_on_exec(w.fileno())
        self._writer = w
        self._reader = r

    def __str__(self):
        return 'Pipe waker %s' % self.fileno()

    def fileno(self):
        return self._reader.fileno()

    def wake(self):
        try:
            self._writer.send(b'x')
        except IOError:
            pass

    def consume(self):
        r = self._reader
        try:
            while r.poll():
                r.recv()
        except (IOError, EOFError):
            pass

########NEW FILE########
__FILENAME__ = runtime
#    ORIGINAL FILE FROM TWISTED twisted.python.runtime
#    Modified and adapted for pulsar
#
# -*- test-case-name: twisted.python.test.test_runtime -*-
# Copyright (c) 2001-2008 Twisted Matrix Laboratories.
# See LICENSE for details.


# System imports
import os
import sys
import time
import imp
import socket


knownPlatforms = {
    'nt': 'win',
    'ce': 'win',
    'posix': 'posix',
    'java': 'java',
    'org.python.modules.os': 'java',
    }

_timeFunctions = {
    # 'win': time.clock,
    'win': time.time,
    }


class Platform(object):
    """Gives us information about the platform we're running on"""

    name = os.name
    type = knownPlatforms.get(os.name)
    seconds = staticmethod(_timeFunctions.get(type, time.time))

    def __str__(self):
        return '{0} - {1}'.format(self.type, self.name)

    def __repr__(self):
        return '{0}: {1}'.format(self.__class__.__name__, self)

    def isKnown(self):
        """Do we know about this platform?
        """
        return self.type is not None

    def getType(self):
        """Return ``posix``, ``win`` or ``java``"""
        return self.type

    @property
    def is_posix(self):
        return self.type == 'posix'

    @property
    def isMacOSX(self):
        """Return if we are runnng on Mac OS X."""
        return sys.platform == "darwin"

    @property
    def is_winNT(self):
        """Are we running in Windows NT?"""
        if self.getType() == 'win':
            import _winreg
            try:
                k = _winreg.OpenKeyEx(
                    _winreg.HKEY_LOCAL_MACHINE,
                    r'Software\Microsoft\Windows NT\CurrentVersion')
                _winreg.QueryValueEx(k, 'SystemRoot')
                return True
            except WindowsError:
                return False
        # not windows NT
        return False

    @property
    def is_windows(self):
        return self.getType() == 'win'

    def supportsThreads(self):
        """Can threads be created?
        """
        try:
            return imp.find_module('thread')[0] is None
        except ImportError:
            return False

    @property
    def has_multiProcessSocket(self):
        '''Indicates if support for multiprocess sockets is available.
        '''
        return hasattr(socket, 'fromfd')

########NEW FILE########
__FILENAME__ = windowssystem
import os
import signal
import ctypes
import ctypes.wintypes
import socket
import getpass

from .base import *

__all__ = ['close_on_exec',
           'Waker',
           'daemonize',
           'socketpair',
           'EXIT_SIGNALS',
           'get_uid',
           'get_gid',
           'get_maxfd',
           'set_owner_process']

# See: http://msdn.microsoft.com/en-us/library/ms724935(VS.85).aspx
SetHandleInformation = ctypes.windll.kernel32.SetHandleInformation
SetHandleInformation.argtypes = (ctypes.wintypes.HANDLE, ctypes.wintypes.DWORD,
                                 ctypes.wintypes.DWORD)
SetHandleInformation.restype = ctypes.wintypes.BOOL

HANDLE_FLAG_INHERIT = 0x00000001
EXIT_SIGNALS = (signal.SIGINT, signal.SIGTERM, signal.SIGABRT, signal.SIGBREAK)


set_owner_process = lambda gid, uid: None


def get_parent_id():
    if ispy32:
        return os.getppid()
    else:
        return None


def chown(path, uid, gid):
    pass


def close_on_exec(fd):
    if fd:
        success = SetHandleInformation(fd, HANDLE_FLAG_INHERIT, 0)
        if not success:
            raise ctypes.GetLastError()


def _set_non_blocking(fd):
    pass


def get_uid(user=None):
    if not user:
        return getpass.getuser()
    elif user == getpass.getuser():
        return user


def get_gid(group=None):
    return None


def setpgrp():
    pass


def get_maxfd():
    return MAXFD


def daemonize():
    pass


def socketpair(family=socket.AF_INET, type=socket.SOCK_STREAM, proto=0):
    """A socket pair usable as a self-pipe, for Windows.

    Origin: https://gist.github.com/4325783, by Geert Jansen.  Public domain.
    """
    # We create a connected TCP socket. Note the trick with setblocking(0)
    # that prevents us from having to create a thread.
    lsock = socket.socket(family, type, proto)
    lsock.bind(('localhost', 0))
    lsock.listen(1)
    addr, port = lsock.getsockname()
    csock = socket.socket(family, type, proto)
    csock.setblocking(True)
    try:
        csock.connect((addr, port))
    except Exception:
        lsock.close()
        csock.close()
        raise
    ssock, _ = lsock.accept()
    csock.setblocking(True)
    lsock.close()
    return (ssock, csock)


class Waker(object):
    '''In windows'''
    def __init__(self):
        self._reader, self._writer = socketpair()
        self._writer.setblocking(False)
        self._reader.setblocking(False)

    def __str__(self):
        return 'Socket waker {0}'.format(self.fileno())

    def fileno(self):
        return self._reader.fileno()

    def wake(self):
        try:
            self._writer.send(b'x')
        except IOError:
            pass

    def consume(self):
        try:
            result = True
            while result:
                result = self._reader.recv(1024)
        except IOError:
            pass

    def close(self):
        self.reader.close()
        self.writer.close()

########NEW FILE########
__FILENAME__ = winprocess
import sys
import os
from multiprocessing import forking, process, freeze_support
from multiprocessing.util import _logger, _log_to_stderr

WINEXE = forking.WINEXE


def get_preparation_data(name):
    '''
    Return info about parent needed by child to unpickle process object.
    Monkey-patch from
    '''
    d = dict(
        name=name,
        sys_path=sys.path,
        sys_argv=sys.argv,
        log_to_stderr=_log_to_stderr,
        orig_dir=process.ORIGINAL_DIR,
        authkey=process.current_process().authkey,
    )

    if _logger is not None:
        d['log_level'] = _logger.getEffectiveLevel()

    if not WINEXE:
        main_path = getattr(sys.modules['__main__'], '__file__', None)
        if not main_path and sys.argv[0] not in ('', '-c'):
            main_path = sys.argv[0]
        if main_path is not None:
            if (not os.path.isabs(main_path) and process.ORIGINAL_DIR
                    is not None):
                main_path = os.path.join(process.ORIGINAL_DIR, main_path)
            if not main_path.endswith('.exe'):
                d['main_path'] = os.path.normpath(main_path)

    return d


forking.get_preparation_data = get_preparation_data
freeze_support()

########NEW FILE########
__FILENAME__ = winservice
import os
import sys
import logging
import time

import pythoncom
import win32serviceutil
import win32service
import win32event
import win32api
import servicemanager

import pulsar
from pulsar.utils.importer import import_module

import multiprocessing


class ServiceManagerLogHandler(logging.Handler):

    def emit(self, record):
        try:
            msg = self.format(record)
            if record.levelno >= logging.ERROR:
                servicemanager.LogErrorMsg(msg)
            elif record.levelno >= logging.INFO:
                servicemanager.LogiNFOMsg(msg)
        except Exception:
            pass


def ctrlHandler(ctrlType):
    return True


class PulsarService(win32serviceutil.ServiceFramework):
    _svc_name_ = 'PULSAR_%s' % pulsar.__version__
    _svc_display_name_ = "PULSAR %s server" % pulsar.__version__
    _svc_description_ = "Pulsar asynchronous server"
    _command_lines = 'pulsar_command_line'

    def __init__(self, args):
        win32serviceutil.ServiceFramework.__init__(self, args)
        self.hWaitStop = win32event.CreateEvent(None, 0, 0, None)
        self.running = False

    def SvcStop(self):
        # self.log.info('%s - Received stop signal' % self._svc_name_)
        pulsar.arbiter().stop()
        self.running = False
        self.ReportServiceStatus(win32service.SERVICE_STOP_PENDING)
        win32event.SetEvent(self.hWaitStop)

    def SvcDoRun(self):
        mod = import_module(self._command_lines)
        os.remove(os.path.abspath(mod.__file__))
        self.setup(mod.argv)

    def setup(self, argv):
        raise NotImplementedError

    def main(self):
        arbiter = pulsar.arbiter()
        arbiter.log.info('%s - starting up the service' % self._svc_name_)
        self.running = True
        while self.running:
            time.sleep(1)
        arbiter.log.info('%s - exiting up the service' % self._svc_name_)

    @classmethod
    def run(cls, **params):
        argv = sys.argv
        args = sys.argv[:1]
        if len(sys.argv) > 2:
            args += sys.argv[2:]
        f = open(cls._command_lines+'.py', 'w')
        f.write('argv = {0}'.format(args))
        f.close()
        argv = argv[:2]
        if not argv or not argv[0]:
            main_path = getattr(sys.modules['__main__'], '__file__', None)
            path, script = os.path.split(main_path)
            argv = [script, 'start']
        sys.argv = argv
        cls.params = params
        win32api.SetConsoleCtrlHandler(ctrlHandler, True)
        win32serviceutil.HandleCommandLine(cls)


if __name__ == '__main__':
    '''To debug type::

    python winservice.py debug
    '''
    PulsarService.run()

########NEW FILE########
__FILENAME__ = arity
import inspect

__all__ = ['checkarity']


def checkarity(func, args, kwargs, discount=0):
    '''Check if arguments respect a given function arity and return
a error message if the check did not pass, otherwise it returns ``None``.

:parameter func: the function.
:parameter args: function arguments.
:parameter kwargs: function key-valued parameters.
:parameter discount: optional integer which discount the number of
                     positional argument to check. Default ``0``.'''
    spec = inspect.getargspec(func)
    args = list(args)
    defaults = list(spec.defaults or ())
    len_defaults = len(defaults)
    len_args = len(spec.args) - discount
    len_args_input = len(args)
    minlen = len_args - len_defaults
    totlen = len_args_input + len(kwargs)
    maxlen = len_args
    if spec.varargs or spec.keywords:
        maxlen = None
        if not minlen:
            return

    if not spec.defaults and maxlen:
        start = '"{0}" takes'.format(func.__name__)
    else:
        if maxlen and totlen > maxlen:
            start = '"{0}" takes at most'.format(func.__name__)
        else:
            start = '"{0}" takes at least'.format(func.__name__)

    if totlen < minlen:
        return '{0} {1} parameters. {2} given.'.format(start, minlen, totlen)
    elif maxlen and totlen > maxlen:
        return '{0} {1} parameters. {2} given.'.format(start, maxlen, totlen)

    # Length of parameter OK, check names
    if len_args_input < len_args:
        l = minlen - len_args_input
        for arg in spec.args[discount:]:
            if args:
                args.pop(0)
            else:
                if l > 0:
                    if defaults:
                        defaults.pop(0)
                    elif arg not in kwargs:
                        return ('"{0}" has missing "{1}" parameter.'
                                .format(func.__name__, arg))
                kwargs.pop(arg, None)
            l -= 1
        if kwargs and maxlen:
            s = ''
            if len(kwargs) > 1:
                s = 's'
            p = ', '.join('"{0}"'.format(p) for p in kwargs)
            return ('"{0}" does not accept {1} parameter{2}.'
                    .format(func.__name__, p, s))
    elif len_args_input > len_args + len_defaults:
        n = len_args + len_defaults
        start = '"{0}" takes'.format(func.__name__)
        return ('{0} {1} positional parameters. {2} given.'
                .format(start, n, len_args_input))

########NEW FILE########
__FILENAME__ = pidfile
import errno
import os
import tempfile

__all__ = ['Pidfile']


class Pidfile(object):
    """\
    Manage a PID file. If a specific name is provided
    it and '"%s.oldpid" % name' will be used. Otherwise
    we create a temp file using os.mkstemp.
    """
    def __init__(self, fname=None):
        self.fname = fname
        self.pid = None

    def create(self, pid=None):
        pid = pid or os.getpid()
        oldpid = self.read()
        if oldpid:
            if oldpid == pid:
                return
            raise RuntimeError("Already running on PID %s "
                               "(or pid file '%s' is stale)" %
                               (oldpid, self.fname))
        self.pid = pid
        # Write pidfile
        if self.fname:
            fdir = os.path.dirname(self.fname)
            if fdir and not os.path.isdir(fdir):
                raise RuntimeError("%s doesn't exist. Can't create pidfile."
                                   % fdir)
        else:
            self.fname = tempfile.mktemp()
        with open(self.fname, 'w') as f:
            f.write("%s\n" % self.pid)
        # set permissions to -rw-r--r--
        os.chmod(self.fname, 420)

    def rename(self, path):
        self.unlink()
        self.fname = path
        self.create(self.pid)

    def unlink(self):
        """ delete pidfile"""
        try:
            with open(self.fname, "r") as f:
                pid1 = int(f.read() or 0)
            if pid1 == self.pid:
                os.unlink(self.fname)
        except Exception:
            pass

    def read(self):
        """ Validate pidfile and make it stale if needed"""
        if not self.fname:
            return
        try:
            with open(self.fname, "r") as f:
                wpid = int(f.read() or 0)
                if wpid <= 0:
                    return
                return wpid
        except IOError:
            return

########NEW FILE########
__FILENAME__ = text
import math
import sys

if sys.version_info >= (3, 0):
    from itertools import zip_longest
else:   # pragma    nocover
    from itertools import izip_longest as zip_longest, izip as zip

__all__ = ['grouper', 'num2eng', 'nice_number']


# Tokens from 1000 and up
_PRONOUNCE = ['', 'thousand', 'million', 'billion', 'trillion']

# Tokens up to 90
_SMALL = {
    '1': 'one',
    '2': 'two',
    '3': 'three',
    '4': 'four',
    '5': 'five',
    '6': 'six',
    '7': 'seven',
    '8': 'eight',
    '9': 'nine',
    '10': 'ten',
    '11': 'eleven',
    '12': 'twelve',
    '13': 'thirteen',
    '14': 'fourteen',
    '15': 'fifteen',
    '16': 'sixteen',
    '17': 'seventeen',
    '18': 'eighteen',
    '19': 'nineteen',
    '20': 'twenty',
    '30': 'thirty',
    '40': 'forty',
    '50': 'fifty',
    '60': 'sixty',
    '70': 'seventy',
    '80': 'eighty',
    '90': 'ninety'
}


def grouper(n, iterable, padvalue=None):
    '''grouper(3, 'abcdefg', 'x') -->
    ('a','b','c'), ('d','e','f'), ('g','x','x')
    '''
    return zip_longest(*[iter(iterable)]*n, fillvalue=padvalue)


def num2eng(num):
    '''English representation of a number up to a trillion.
    '''
    num = str(int(num))  # Convert to string, throw if bad number
    if (len(num) / 3 >= len(_PRONOUNCE)):  # Sanity check
        return num
    elif num == '0':  # Zero is a special case
        return 'zero'
    pron = []  # Result accumulator
    first = True
    for pr, bits in zip(_PRONOUNCE, grouper(3, reversed(num), '')):
        num = ''.join(reversed(bits))
        n = int(num)
        bits = []
        if n > 99:  # Got hundred
            bits.append('%s hundred' % _SMALL[num[0]])
            num = num[1:]
            n = int(num)
            num = str(n)
        if (n > 20) and (n != (n // 10 * 10)):
            bits.append('%s %s' % (_SMALL[num[0] + '0'], _SMALL[num[1]]))
        elif n:
            bits.append(_SMALL[num])
        if len(bits) == 2 and first:
            first = False
            p = ' and '.join(bits)
        else:
            p = ' '.join(bits)
        if p and pr:
            p = '%s %s' % (p, pr)
        pron.append(p)
    return ', '.join(reversed(pron))


def nice_number(number, name=None, plural=None):
    if not name:
        return num2eng(number)
    elif number == 1:
        return 'one %s' % name
    else:
        if not plural:
            plural = '%ss' % name
        return '%s %s' % (num2eng(number), plural)

########NEW FILE########
__FILENAME__ = version
import datetime
import os
import subprocess


def get_version(version):
    assert len(version) == 5
    assert version[3] in ('alpha', 'beta', 'rc', 'final')
    main = '.'.join(map(str, version[:3]))
    sub = ''
    if version[3] == 'alpha' and version[4] == 0:
        git_changeset = get_git_changeset()
        if git_changeset:
            sub = '-dev.%s' % git_changeset
    elif version[3] != 'final':
        sub = '-%s.%s' % tuple(version[3:])
    return main + sub


def sh(command, cwd=None):
    return subprocess.Popen(command,
                            stdout=subprocess.PIPE,
                            stderr=subprocess.PIPE,
                            shell=True,
                            cwd=cwd,
                            universal_newlines=True).communicate()[0]


def get_git_changeset():
    """Returns a numeric identifier of the latest git changeset.

    The result is the UTC timestamp of the changeset in YYYYMMDDHHMMSS format.
    This value isn't guaranteed to be unique, but collisions are very unlikely,
    so it's sufficient for generating the development version numbers.
    """
    repo_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    git_show = sh('git show --pretty=format:%ct --quiet HEAD',
                  cwd=repo_dir)
    timestamp = git_show.partition('\n')[0]
    try:
        timestamp = datetime.datetime.utcfromtimestamp(int(timestamp))
    except ValueError:
        return None
    return timestamp.strftime('%Y%m%d%H%M%S')


FORMAT = '%n'.join(['%H', '%aN', '%ae', '%cN', '%ce', '%s'])


def gitrepo(root=None):
    if not root:
        cwd = root = os.getcwd()
    else:
        cwd = os.getcwd()
        if cwd != root:
            os.chdir(root)
    gitlog = sh('git --no-pager log -1 --pretty="format:%s"' % FORMAT,
                cwd=root).split('\n', 5)
    branch = sh('git rev-parse --abbrev-ref HEAD', cwd=root).strip()
    remotes = [x.split() for x in
               filter(lambda x: x.endswith('(fetch)'),
                      sh('git remote -v', cwd=root).strip().splitlines())]
    if cwd != root:
        os.chdir(cwd)
    return {
        "head": {
            "id": gitlog[0],
            "author_name": gitlog[1],
            "author_email": gitlog[2],
            "committer_name": gitlog[3],
            "committer_email": gitlog[4],
            "message": gitlog[5].strip(),
        },
        "branch": branch,
        "remotes": [{'name': remote[0], 'url': remote[1]}
                    for remote in remotes]
    }

########NEW FILE########
__FILENAME__ = websocket
# -*- coding: utf-8 -*-
'''WebSocket_ Protocol is implemented via the :class:`Frame` and
:class:`FrameParser` classes.

To obtain a frame parser one should use the :func:`frame_parser` function.

frame parser
~~~~~~~~~~~~~~~~~~~

.. autofunction:: frame_parser


Frame
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: Frame
   :members:
   :member-order: bysource


Frame Parser
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autoclass:: FrameParser
   :members:
   :member-order: bysource


parse_close
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. autofunction:: parse_close


.. _WebSocket: http://tools.ietf.org/html/rfc6455'''
import os
from struct import pack, unpack
from array import array

from .pep import ispy3k, range, to_bytes
from .exceptions import ProtocolError

try:
    from .lib import FrameParser as CFrameParser, CLOSE_CODES
except:     # pragma    nocover
    CFrameParser = None

    CLOSE_CODES = {
        1000: "OK",
        1001: "going away",
        1002: "protocol error",
        1003: "unsupported type",
        # 1004: - (reserved)
        # 1005: no status code (internal)
        # 1006: connection closed abnormally (internal)
        1007: "invalid data",
        1008: "policy violation",
        1009: "message too big",
        1010: "extension required",
        1011: "unexpected error",
        # 1015: TLS failure (internal)
    }


DEFAULT_VERSION = 13
SUPPORTED_VERSIONS = (DEFAULT_VERSION,)
WS_EXTENSIONS = {}
WS_PROTOCOLS = {}

if ispy3k:
    string_type = str

else:  # pragma    nocover
    string_type = basestring


def get_version(version):
    try:
        version = int(version or DEFAULT_VERSION)
    except Exception:
        pass
    if version not in SUPPORTED_VERSIONS:
        raise ProtocolError('Version %s not supported.' % version)
    return version


class Extension(object):

    def receive(self, data):
        return data

    def send(self, data):
        return data


def frame_parser(version=None, kind=0, extensions=None, protocols=None,
                 pyparser=False):
    '''Create a new :class:`FrameParser` instance.

    :param version: protocol version, the default is 13
    :param kind: the kind of parser, and integer between 0 and 3 (check the
        :class:`FrameParser` documentation for details)
    :param extensions: not used at the moment
    :param protocols: not used at the moment
    :param pyparser: if ``True`` (default ``False``) uses the python frame
        parser implementation rather than the much faster cython
        implementation.
    '''
    version = get_version(version)
    Parser = FrameParser if pyparser else CFrameParser
    # extensions, protocols
    return Parser(version, kind, ProtocolError, None, None)


def websocket_mask(data, masking_key):
    mask_size = len(masking_key)
    key = array('B', masking_key)
    data = array('B', data)
    for i in range(len(data)):
        data[i] ^= key[i % mask_size]
    return data.tobytes() if ispy3k else data.tostring()


class Frame:
    _body = None
    _masking_key = None

    def __init__(self, opcode, final, payload_length):
        self._opcode = opcode
        self._final = final
        self._payload_length = payload_length

    @property
    def final(self):
        return self._final

    @property
    def opcode(self):
        return self._opcode

    @property
    def body(self):
        return self._body

    @property
    def masking_key(self):
        return self._masking_key

    @property
    def is_message(self):
        return self._opcode == 1

    @property
    def is_bytes(self):
        return self._opcode == 2

    @property
    def is_close(self):
        return self._opcode == 8

    @property
    def is_ping(self):
        return self._opcode == 9

    @property
    def is_pong(self):
        return self._opcode == 10


class FrameParser(object):
    '''Decoder and encoder for the websocket protocol.

    .. attribute:: version

        Optional protocol version (Default 13).

    .. attribute:: kind

        * 0 for parsing client's frames and sending server frames (to be used
          in the server)
        * 1 for parsing server frames and sending client frames (to be used
          by the client)
        * 2 Assumes always unmasked data
    '''
    def __init__(self, version, kind, ProtocolError, extensions, protocols):
        self.version = version
        self.kind = kind
        self.frame = None
        self.buffer = bytearray()
        self._opcodes = (0, 1, 2, 8, 9, 10)
        self._encode_mask_length = 0
        self._decode_mask_length = 0
        if kind == 0:
            self._decode_mask_length = 4
        elif kind == 1:
            self._encode_mask_length = 4
        elif kind == 3:
            self._decode_mask_length = 4
            self._encode_mask_length = 4
        self._max_payload = 1 << 63
        self._extensions = extensions
        self._protocols = protocols

    @property
    def max_payload(self):
        return self._max_payload

    @property
    def decode_mask_length(self):
        return self._decode_mask_length

    @property
    def encode_mask_length(self):
        return self._encode_mask_length

    @property
    def extensions(self):
        return self._extensions

    @property
    def protocols(self):
        return self._protocols

    def ping(self, body=None):
        '''return a `ping` :class:`Frame`.'''
        return self.encode(body, opcode=0x9)

    def pong(self, body=None):
        '''return a `pong` :class:`Frame`.'''
        return self.encode(body, opcode=0xA)

    def close(self, code=None):
        '''return a `close` :class:`Frame`.
        '''
        code = code or 1000
        body = pack('!H', code) + CLOSE_CODES.get(code, '').encode('utf-8')
        return self.encode(body, opcode=0x8)

    def continuation(self, body=None, final=True):
        '''return a `continuation` :class:`Frame`.'''
        return self.encode(body, opcode=0, final=final)

    def encode(self, message, final=True, masking_key=None,
               opcode=None, rsv1=0, rsv2=0, rsv3=0):
        '''Encode a ``message`` for writing into the wire.

        To produce several frames for a given large message use
        :meth:`multi_encode` method.
        '''
        fin = 1 if final else 0
        opcode, masking_key, data = self._info(message, opcode, masking_key)
        return self._encode(data, opcode, masking_key, fin,
                            rsv1, rsv2, rsv3)

    def multi_encode(self, message, masking_key=None, opcode=-1,
                     rsv1=0, rsv2=0, rsv3=0, max_payload=0):
        '''Encode a ``message`` into several frames depending on size.

        Returns a generator of bytes to be sent over the wire.
        '''
        max_payload = max(2, max_payload or self._max_payload)
        opcode, masking_key, data = self._info(message, opcode, masking_key)
        #
        while data:
            if len(data) >= max_payload:
                chunk, data, fin = (data[:max_payload],
                                    data[max_payload:], 0)
            else:
                chunk, data, fin = data, b'', 1
            yield self._encode(chunk, opcode, masking_key, fin,
                               rsv1, rsv2, rsv3)

    def decode(self, data=None):
        frame = self.frame
        mask_length = self._decode_mask_length

        if data:
            self.buffer.extend(data)
        if frame is None:
            if len(self.buffer) < 2:
                return
            chunk = self._chunk(2)
            first_byte, second_byte = unpack("BB", chunk)
            fin = (first_byte >> 7) & 1
            rsv1 = (first_byte >> 6) & 1
            rsv2 = (first_byte >> 5) & 1
            rsv3 = (first_byte >> 4) & 1
            opcode = first_byte & 0xf
            if fin not in (0, 1):
                raise ProtocolError('FIN must be 0 or 1')
            if bool(mask_length) != bool(second_byte & 0x80):
                if mask_length:
                    raise ProtocolError('unmasked client frame.')
                else:
                    raise ProtocolError('masked server frame.')
            payload_length = second_byte & 0x7f
            # All control frames MUST have a payload length of 125 bytes
            # or less
            if opcode > 7:
                if payload_length > 125:
                    raise ProtocolError(
                        'WEBSOCKET control frame too large')
                elif not fin:
                    raise ProtocolError(
                        'WEBSOCKET control frame fragmented')
            self.frame = frame = Frame(opcode, bool(fin), payload_length)

        if frame._masking_key is None:
            if frame._payload_length == 0x7e:  # 126
                if len(self.buffer) < 2 + mask_length:  # 2 + 4 for mask
                    return
                chunk = self._chunk(2)
                frame._payload_length = unpack("!H", chunk)[0]
            elif frame._payload_length == 0x7f:  # 127
                if len(self.buffer) < 8 + mask_length:  # 8 + 4 for mask
                    return
                chunk = self._chunk(8)
                frame._payload_length = unpack("!Q", chunk)[0]
            elif len(self.buffer) < mask_length:
                return
            if mask_length:
                frame._masking_key = self._chunk(mask_length)
            else:
                frame._masking_key = b''

        if len(self.buffer) >= frame._payload_length:
            self.frame = None
            chunk = self._chunk(frame._payload_length)
            if self._extensions:
                for extension in self._extensions:
                    chunk = extension.receive(frame, self.buffer)
            if frame._masking_key:
                chunk = websocket_mask(chunk, frame._masking_key)
            if frame.opcode == 1:
                frame._body = chunk.decode("utf-8", "replace")
            else:
                frame._body = chunk
            return frame

    def _encode(self, data, opcode, masking_key, fin, rsv1, rsv2, rsv3):
        buffer = bytearray()
        length = len(data)
        mask_bit = 128 if masking_key else 0

        buffer.append(((fin << 7) | (rsv1 << 6) | (rsv2 << 5) |
                       (rsv3 << 4) | opcode))

        if length < 126:
            buffer.append(mask_bit | length)
        elif length < 65536:
            buffer.append(mask_bit | 126)
            buffer.extend(pack('!H', length))
        elif length < self._max_payload:
            buffer.append(mask_bit | 127)
            buffer.extend(pack('!Q', length))
        else:
            raise ProtocolError('WEBSOCKET frame too large')
        if masking_key:
            buffer.extend(masking_key)
            buffer.extend(websocket_mask(data, masking_key))
        else:
            buffer.extend(data)
        return bytes(buffer)

    def _info(self, message, opcode, masking_key):
        mask_length = self._encode_mask_length

        if mask_length:
            masking_key = to_bytes(masking_key or os.urandom(4))
            assert len(masking_key) == mask_length, "bad masking key"
        else:
            masking_key = b''
        if opcode is None:
            opcode = 1 if isinstance(message, string_type) else 2
        data = to_bytes(message or b'', 'utf-8')
        if opcode not in self._opcodes:
            raise ProtocolError('WEBSOCKET opcode a reserved value')
        elif opcode > 7:
            if len(data) > 125:
                raise ProtocolError('WEBSOCKET control frame too large')
            if opcode == 8:
                # TODO CHECK CLOSE FRAME STATUS CODE
                pass
        return opcode, masking_key, data

    def _chunk(self, length):
        chunk = bytes(self.buffer[:length])
        self.buffer = self.buffer[length:]
        return chunk


def parse_close(data):
    '''Parse the body of a close :class:`Frame`.

    Returns a tuple (``code``, ``reason``) if successful otherwise
    raise :class:`.ProtocolError`.
    '''
    length = len(data)
    if length == 0:
        return 1005, ''
    elif length == 1:
        raise ProtocolError("Close frame too short")
    else:
        code, = unpack('!H', data[:2])
        if not (code in CLOSE_CODES or 3000 <= code < 5000):
            raise ProtocolError("Invalid status code for websocket")
        reason = data[2:].decode('utf-8')
        return code, reason


if CFrameParser is None:     # pragma    nocover
    CFrameParser = FrameParser

########NEW FILE########
__FILENAME__ = runtests
#!/usr/bin/env python
import sys
import os
from multiprocessing import current_process


def run(**params):
    args = params.get('argv', sys.argv)
    # pep8
    if '--pep8' in args:
        from pulsar.apps.test import pep8_run
        msg, code = pep8_run(args, ['pulsar', 'examples', 'tests'],
                             'setup.cfg')
        if msg:
            sys.stderr.write(msg)
        sys.exit(code)
    # Submit to coveralls
    elif '--coveralls' in args:
        import pulsar
        from pulsar.utils.path import Path
        from pulsar.apps.test.cov import coveralls

        path = Path(__file__)
        repo_token = None
        strip_dirs = [Path(pulsar.__file__).parent.parent, os.getcwd()]
        if os.path.isfile('.coveralls-repo-token'):
            with open('.coveralls-repo-token') as f:
                repo_token = f.read().strip()
        code = coveralls(strip_dirs=strip_dirs,
                         repo_token=repo_token)
        sys.exit(0)
    # Run the test suite
    if '--coverage' in args or params.get('coverage'):
        import coverage
        print('Start coverage')
        p = current_process()
        p._coverage = coverage.coverage(data_suffix=True)
        p._coverage.start()
    runtests(**params)


def runtests(**params):
    import pulsar
    from pulsar.utils.path import Path
    from pulsar.apps.test import TestSuite
    from pulsar.apps.test.plugins import bench, profile
    import pulsar.utils.settings.backend
    #
    path = Path(__file__)
    path.add2python('stdnet', 1, down=['python-stdnet'], must_exist=False)
    #
    TestSuite(description='Pulsar Asynchronous test suite',
              modules=('tests',
                       ('examples', 'tests'),
                       ('examples', 'test_*')),
              plugins=(bench.BenchMark(),
                       profile.Profile()),
              pidfile='test.pid',
              **params).start()


if __name__ == '__main__':
    run()

########NEW FILE########
__FILENAME__ = greenio
import unittest

try:
    from pulsar.apps import greenio
except ImportError:
    greenio = None

from pulsar import send, multi_async

from examples.echo.manage import server, Echo


@unittest.skipUnless(greenio, 'Requires the greenlet package')
class TestGreenIO(unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        s = server(name=cls.__name__.lower(), bind='127.0.0.1:0')
        cls.server_cfg = yield send('arbiter', 'run', s)
        cls.client = Echo(cls.server_cfg.addresses[0],
                          loop=greenio.GreenEventLoop())

    @classmethod
    def tearDownClass(cls):
        if cls.server_cfg:
            return send('arbiter', 'kill_actor', cls.server_cfg.name)

    def test_loop(self):
        c = self.client
        self.assertIsInstance(c._loop, greenio.GreenEventLoop)
        self.assertTrue(c._loop._loop)

    def test_ping(self):
        result = yield self.client(b'ciao luca')
        self.assertEqual(result, b'ciao luca')

    def test_large(self):
        '''Echo a 3MB message'''
        msg = b''.join((b'a' for x in range(2**13)))
        result = yield self.client(msg)
        self.assertEqual(result, msg)

    def test_multi(self):
        result = yield multi_async((self.client(b'ciao'),
                                    self.client(b'pippo'),
                                    self.client(b'foo')))
        self.assertEqual(len(result), 3)
        self.assertTrue(b'ciao' in result)
        self.assertTrue(b'pippo' in result)
        self.assertTrue(b'foo' in result)

########NEW FILE########
__FILENAME__ = multi
'''Tests the rpc middleware and utilities. It uses the calculator example.'''
import unittest

import pulsar
from pulsar import Config, get_actor
from pulsar.apps import MultiApp
from pulsar.apps.wsgi import WSGIServer
from pulsar.apps.tasks import TaskQueue
from pulsar.apps.test import run_on_arbiter


def dummy(environ, start_response):
    start_response('200 OK', [])
    yield [b'dummy']


class MultiWsgi(MultiApp):
    cfg = Config(bind=':0', rpc_bind=':0', bla='foo')

    def build(self):
        yield self.new_app(WSGIServer, callable=dummy)
        yield self.new_app(WSGIServer, 'rpc', callable=dummy)


class TestMultiApp(unittest.TestCase):

    def create(self, **params):
        # create the application
        return MultiWsgi(**params)

    def testApp(self):
        app = self.create(version='2.0')
        self.assertEqual(app.version, '2.0')
        self.assertTrue(app)
        apps = app.apps()
        self.assertEqual(len(apps), 2)
        self.assertEqual(apps[0].version, '2.0')
        self.assertEqual(apps[1].version, pulsar.__version__)

    def testConfig(self):
        app = self.create(bind=':9999', unz='whatz')
        self.assertTrue(app)
        self.assertEqual(len(app.cfg.params), 4)
        apps = app.apps()
        self.assertEqual(len(app.cfg.params), 2)
        self.assertEqual(app.cfg.bla, 'foo')
        self.assertEqual(app.cfg.unz, 'whatz')
        self.assertEqual(app.cfg.bind, ':9999')

    def testTimeout(self):
        app = self.create(timeout=22, name='pippo')
        self.assertEqual(app.name, 'pippo')
        self.assertEqual(app.cfg.timeout, 22)
        apps = app.apps()
        self.assertEqual(app.cfg.timeout, 22)
        self.assertNotEqual(app.cfg.rpc_timeout, 22)
        app1 = apps[0]
        self.assertEqual(app1.name, 'pippo')
        self.assertEqual(app1.cfg.timeout, 22)
        app2 = apps[1]
        self.assertEqual(app2.name, 'rpc_pippo')
        self.assertNotEqual(app2.cfg.timeout, 22)
        self.assertEqual(app2.cfg.timeout,
                         app2.cfg.settings['timeout'].default)

    def testName(self):
        app = self.create()
        self.assertEqual(app.name, 'multiwsgi')
        app = self.create(name='bla')
        self.assertEqual(app.name, 'bla')
        apps = app.apps()
        self.assertEqual(apps[0].name, 'bla')
        self.assertEqual(apps[1].name, 'rpc_bla')

    @run_on_arbiter
    def testInstall(self):
        arbiter = get_actor()
        app = self.create(name='pluto')
        self.assertTrue(app)
        self.assertFalse(arbiter.get_actor('pluto'))
        self.assertFalse(arbiter.get_actor('rpc_pluto'))
        # create the application
        yield app.start()
        monitor1 = arbiter.get_actor('pluto')
        self.assertTrue(monitor1)
        self.assertTrue(monitor1.is_monitor())
        monitor2 = arbiter.get_actor('rpc_pluto')
        self.assertTrue(monitor2)
        self.assertTrue(monitor2.is_monitor())
        yield monitor1.stop()
        yield monitor2.stop()
        yield None

    def test_config_copy(self):
        app = self.create()
        self.assertTrue(app)
        apps = app.apps()
        rpc = apps[1]
        cfg = rpc.cfg.copy()
        self.assertEqual(cfg.prefix, rpc.cfg.prefix)
        for name in cfg:
            self.assertTrue(name in rpc.cfg)

########NEW FILE########
__FILENAME__ = rpc
'''Tests the rpc middleware and utilities. It uses the calculator example.'''
import unittest

from pulsar.apps import rpc
from pulsar.apps.test import HttpTestClient


class rpcTest(unittest.TestCase):

    def proxy(self):
        from examples.calculator.manage import Site
        http = HttpTestClient(self, Site())
        return rpc.JsonProxy('http://127.0.0.1:8060/', http=http, timeout=20)

    def test_proxy(self):
        p = self.proxy()
        http = p._http
        self.assertTrue(len(http.headers))
        self.assertEqual(http.headers['user-agent'], 'Pulsar-Http-Test-Client')
        self.assertEqual(http.test, self)
        self.assertTrue(http.server_consumer)
        self.assertTrue(http.wsgi_handler)
        self.assertEqual(p._version, '2.0')

########NEW FILE########
__FILENAME__ = actor
'''Tests actor and actor proxies.'''
import unittest

from multiprocessing.queues import Queue
from functools import partial

import pulsar
from pulsar import (send, get_actor, CommandNotFound, async_while, TcpServer,
                    coroutine_return, Connection)
from pulsar.utils.pep import pickle, default_timer
from pulsar.apps.test import (ActorTestMixin, run_on_arbiter,
                              dont_run_with_thread)

from examples.echo.manage import Echo, EchoServerProtocol


def add(actor, a, b):
    return (actor.name, a+b)


class create_echo_server(object):
    '''partial is not picklable in python 2.6'''
    def __init__(self, address):
        self.address = address

    def __call__(self, actor):
        '''Starts an echo server on a newly spawn actor'''
        address = self.address
        server = TcpServer(partial(Connection, EchoServerProtocol),
                           actor._loop, self.address)
        yield server.start_serving()
        actor.servers['echo'] = server
        actor.extra['echo-address'] = server.address
        actor.bind_event('stopping', self._stop_server)
        coroutine_return(actor)

    def _stop_server(self, actor):
        yield actor.servers['echo'].close()
        coroutine_return(actor)


class TestProxy(unittest.TestCase):

    def test_get_proxy(self):
        self.assertRaises(ValueError, pulsar.get_proxy, 'shcbjsbcjcdcd')
        self.assertEqual(pulsar.get_proxy('shcbjsbcjcdcd', safe=True), None)

    def test_bad_concurrency(self):
        actor = pulsar.get_actor()
        # bla concurrency does not exists
        self.assertRaises(ValueError, pulsar.concurrency, 'bla', pulsar.Actor,
                          actor, pulsar.Config())

    def test_dummy_proxy(self):
        p = pulsar.concurrency('thread', pulsar.Actor, pulsar.get_actor(),
                               pulsar.Config())
        self.assertEqual(p.mailbox, None)
        self.assertEqual(p.spawning_start, None)
        self.assertEqual(p.stopping_start, None)
        self.assertEqual(p.callback, None)
        self.assertEqual(str(p), 'actor(%s)' % p.aid)

    def test_actor_coverage(self):
        '''test case for coverage'''
        actor = pulsar.get_actor()
        try:
            yield send(send, 'sjdcbhjscbhjdbjsj', 'bla')
        except CommandNotFound:
            pass
        # self.assertRaises(pickle.PicklingError, pickle.dumps, actor)


class TestActorThread(ActorTestMixin, unittest.TestCase):
    concurrency = 'thread'

    def test_spawn_and_interact(self):
        proxy = yield self.spawn_actor(name='pluto')
        self.assertEqual(proxy.name, 'pluto')
        yield self.async.assertEqual(send(proxy, 'ping'), 'pong')
        yield self.async.assertEqual(send(proxy, 'echo', 'Hello!'), 'Hello!')
        name, result = yield send(proxy, 'run', add, 1, 3)
        self.assertEqual(name, 'pluto')
        self.assertEqual(result, 4)

    def test_info(self):
        proxy = yield self.spawn_actor(name='pippo')
        self.assertEqual(proxy.name, 'pippo')
        info = yield send(proxy, 'info')
        self.assertTrue('actor' in info)
        ainfo = info['actor']
        self.assertEqual(ainfo['is_process'], self.concurrency == 'process')

    @run_on_arbiter
    def testSimpleSpawn(self):
        '''Test start and stop for a standard actor on the arbiter domain.'''
        proxy = yield self.spawn_actor(
            name='simple-actor-on-%s' % self.concurrency)
        arbiter = pulsar.get_actor()
        proxy_monitor = arbiter.get_actor(proxy.aid)
        self.assertEqual(proxy_monitor, proxy)
        yield self.async.assertEqual(send(proxy, 'ping'), 'pong')
        yield self.async.assertEqual(send(proxy.proxy, 'echo', 'Hello!'),
                                     'Hello!')
        # We call the ActorTestMixin.stop_actors method here, since the
        # ActorTestMixin.tearDown method is invoked on the test-worker domain
        # (here we are in the arbiter domain)
        yield self.stop_actors(proxy)
        is_alive = yield async_while(3, proxy_monitor.is_alive)
        self.assertFalse(is_alive)


class d:
    def test_start_hook(self):
        proxy = yield self.spawn_actor(
            start=create_echo_server(('127.0.0.1', 0)))
        address = None
        start = default_timer()
        while not address:
            info = yield send(proxy, 'info')
            address = info['extra'].get('echo-address')
            if default_timer() - start > 3:
                break
        self.assertTrue(address)
        echo = Echo(address)
        result = yield echo(b'Hello')
        self.assertEqual(result, b'Hello')
        yield self.stop_actors(proxy)


@dont_run_with_thread
class TestActorProcess(TestActorThread):
    concurrency = 'process'

########NEW FILE########
__FILENAME__ = api
'''API design'''
import sys
import unittest

from pulsar import maybe_async


class Context(object):

    def __enter__(self):
        return self

    def __exit__(self, type, value, traceback):
        self._result = value
        return True


class TestApi(unittest.TestCase):

    def test_with_statement(self):
        with Context() as c:
            yield None
            yield None
            raise ValueError
        self.assertIsInstance(c._result, ValueError)

########NEW FILE########
__FILENAME__ = arbiter
'''Tests for arbiter and monitors.'''
import os
import unittest

import pulsar
from pulsar import (send, spawn, system, platform, ACTOR_ACTION_TIMEOUT,
                    MONITOR_TASK_PERIOD, multi_async)
from pulsar.utils.pep import default_timer
from pulsar.apps.test import (run_on_arbiter, ActorTestMixin,
                              dont_run_with_thread)


def timeout(start):
    return default_timer() - start > 1.5*ACTOR_ACTION_TIMEOUT


def cause_timeout(actor):
    if actor.next_periodic_task:
        actor.next_periodic_task.cancel()
    else:
        actor.event_loop.call_soon(cause_timeout, actor)


def cause_terminate(actor):
    if actor.next_periodic_task:
        actor.next_periodic_task.cancel()
        # hayjack the stop method
        actor.stop = lambda exc=None: False
    else:
        actor.event_loop.call_soon(cause_timeout, actor)


class TestArbiterThread(ActorTestMixin, unittest.TestCase):
    concurrency = 'thread'

    @run_on_arbiter
    def testArbiterObject(self):
        '''Test the arbiter in its process domain'''
        arbiter = pulsar.get_actor()
        self.assertEqual(arbiter, pulsar.arbiter())
        self.assertTrue(arbiter.is_arbiter())
        self.assertEqual(arbiter.impl.kind, 'arbiter')
        self.assertTrue(arbiter.monitors)
        self.assertEqual(arbiter.exit_code, None)
        info = arbiter.info()
        self.assertTrue('server' in info)
        server = info['server']
        self.assertEqual(server['state'], 'running')

    @run_on_arbiter
    def test_arbiter_mailbox(self):
        arbiter = pulsar.get_actor()
        mailbox = arbiter.mailbox
        self.assertFalse(hasattr(mailbox, 'request'))
        # Same for all monitors mailboxes
        for monitor in arbiter.monitors.values():
            mailbox = monitor.mailbox
            self.assertFalse(hasattr(mailbox, 'request'))

    @run_on_arbiter
    def test_registered(self):
        '''Test the arbiter in its process domain'''
        arbiter = pulsar.get_actor()
        self.assertTrue(arbiter.is_arbiter())
        self.assertTrue(arbiter.registered)
        self.assertTrue('arbiter' in arbiter.registered)
        self.assertTrue('test' in arbiter.registered)

    @run_on_arbiter
    def test_ping_test_worker(self):
        arbiter = pulsar.get_actor()
        info = arbiter.info()
        test = info['monitors']['test']
        workers = [w['actor']['actor_id'] for w in test['workers']]
        self.assertTrue(workers)
        result = yield multi_async((arbiter.send(w, 'ping') for w in workers))
        self.assertEqual(len(result), len(workers))
        self.assertEqual(result, len(result)*['pong'])

    @run_on_arbiter
    def test_spawning_in_arbiter(self):
        arbiter = pulsar.get_actor()
        self.assertEqual(arbiter.name, 'arbiter')
        self.assertTrue(len(arbiter.monitors) >= 1)
        name = 'testSpawning-%s' % self.concurrency
        future = spawn(name=name, concurrency=self.concurrency)
        self.assertTrue(future.aid in arbiter.managed_actors)
        proxy = yield future
        self.assertEqual(future.aid, proxy.aid)
        self.assertEqual(proxy.name, name)
        self.assertTrue(proxy.aid in arbiter.managed_actors)
        yield send(proxy, 'stop')

    @run_on_arbiter
    def testBadMonitor(self):
        arbiter = pulsar.get_actor()
        self.assertTrue(arbiter.monitors)
        name = list(arbiter.monitors.values())[0].name
        self.assertRaises(KeyError, arbiter.add_monitor, name)

    @run_on_arbiter
    def testTimeout(self):
        '''Test a bogus actor for timeout.'''
        arbiter = pulsar.get_actor()
        self.assertTrue(arbiter.is_arbiter())
        name = 'bogus-timeout-%s' % self.concurrency
        proxy = yield self.spawn_actor(name=name, timeout=1)
        self.assertEqual(proxy.name, name)
        self.assertTrue(proxy.aid in arbiter.managed_actors)
        proxy = arbiter.managed_actors[proxy.aid]
        yield send(proxy, 'run', cause_timeout)
        # The arbiter should soon start to stop the actor
        interval = 2*MONITOR_TASK_PERIOD
        yield pulsar.async_while(interval,
                                 lambda: not proxy.stopping_start)
        self.assertTrue(proxy.stopping_start)
        #
        yield pulsar.async_while(interval,
                                 lambda: proxy.aid in arbiter.managed_actors)
        self.assertFalse(proxy.aid in arbiter.managed_actors)

    @run_on_arbiter
    def test_terminate(self):
        arbiter = pulsar.get_actor()
        self.assertTrue(arbiter.is_arbiter())
        name = 'bogus-term-%s' % self.concurrency
        proxy = yield self.spawn_actor(name=name, timeout=1)
        self.assertEqual(proxy.name, name)
        self.assertTrue(proxy.aid in arbiter.managed_actors)
        proxy = arbiter.managed_actors[proxy.aid]
        #
        result = yield send(proxy, 'run', cause_terminate)
        #
        # The arbiter should soon start stop the actor
        interval = 3*MONITOR_TASK_PERIOD
        yield pulsar.async_while(2*MONITOR_TASK_PERIOD,
                                 lambda: not proxy.stopping_start)
        self.assertTrue(proxy.stopping_start)
        #
        yield pulsar.async_while(1.5*ACTOR_ACTION_TIMEOUT,
                                 lambda: proxy.aid in arbiter.managed_actors)
        self.assertTrue(proxy in arbiter.terminated_actors)
        self.assertFalse(proxy.aid in arbiter.managed_actors)

    @run_on_arbiter
    def __test_actor_termination(self):
        '''Terminate the remote actor via the concurreny terminate method.'''
        arbiter = pulsar.get_actor()
        self.assertTrue(arbiter.is_arbiter())
        name = 'actor-term-%s' % self.concurrency
        proxy = yield self.spawn_actor(name=name)
        self.assertEqual(proxy.name, name)
        self.assertTrue(proxy.aid in arbiter.managed_actors)
        proxy = arbiter.managed_actors[proxy.aid]
        #
        # terminate the actor and see what appens
        proxy.terminate()
        #
        # The arbiter should soon start stop the actor
        interval = 3*MONITOR_TASK_PERIOD
        #
        yield pulsar.async_while(interval,
                                 lambda: proxy.aid in arbiter.managed_actors)
        self.assertFalse(proxy in arbiter.terminated_actors)
        self.assertFalse(proxy.aid in arbiter.managed_actors)

    def test_no_arbiter_in_worker_domain(self):
        worker = pulsar.get_actor()
        self.assertFalse(worker.is_arbiter())
        self.assertEqual(pulsar.arbiter(), None)
        self.assertTrue(worker.monitor)
        self.assertNotEqual(worker.monitor.name, 'arbiter')


@dont_run_with_thread
class TestArbiterProcess(TestArbiterThread):
    concurrency = 'process'

########NEW FILE########
__FILENAME__ = coro
import unittest

from pulsar import (Future, maybe_async, coroutine_return, chain_future,
                    get_event_loop)


def c_summation(value):
    result = yield value
    coroutine_return(result + 2)


class TestCoroFuture(unittest.TestCase):

    def test_coroutine1(self):
        loop = get_event_loop()
        d1 = Future()
        loop.call_later(0.2, d1.set_result, 1)
        a = yield c_summation(d1)
        self.assertEqual(a, 3)
        self.assertEqual(d1.result(), 1)

    def test_chain(self):
        loop = get_event_loop()
        future = Future()
        next = chain_future(future, callback=lambda r: r+2)
        loop.call_later(0.2, future.set_result, 1)
        result = yield next
        self.assertEqual(result, 3)

########NEW FILE########
__FILENAME__ = eventloop
import asyncio
import unittest
from threading import current_thread

import pulsar
from pulsar.async.eventloop import LoopingCall
from pulsar import (run_in_loop, Future, call_repeatedly,
                    get_event_loop, new_event_loop, loop_thread_id)


def has_callback(loop, handler):
    if isinstance(handler, asyncio.TimerHandle):
        return handler in loop._scheduled
    else:
        return handler in loop._ready


class TestEventLoop(unittest.TestCase):

    def test_request_loop(self):
        request_loop = pulsar.get_request_loop()
        event_loop = get_event_loop()
        self.assertNotEqual(event_loop, request_loop)

    def test_io_loop(self):
        ioloop = get_event_loop()
        self.assertTrue(ioloop)
        tid = yield loop_thread_id(ioloop)
        self.assertNotEqual(tid, current_thread().ident)

    def test_call_soon(self):
        ioloop = get_event_loop()
        tid = yield loop_thread_id(ioloop)
        d = Future()
        callback = lambda: d.set_result(current_thread().ident)
        cbk = ioloop.call_soon(callback)
        self.assertEqual(cbk._callback, callback)
        self.assertEqual(cbk._args, ())
        # we should be able to wait less than a second
        result = yield d
        self.assertEqual(result, tid)

    def test_call_later(self):
        ioloop = get_event_loop()
        tid = yield loop_thread_id(ioloop)
        d = Future()
        timeout1 = ioloop.call_later(
            20, lambda: d.set_result(current_thread().ident))
        timeout2 = ioloop.call_later(
            10, lambda: d.set_result(current_thread().ident))
        # lets wake the ioloop
        self.assertTrue(has_callback(ioloop, timeout1))
        self.assertTrue(has_callback(ioloop, timeout2))
        timeout1.cancel()
        timeout2.cancel()
        self.assertTrue(timeout1._cancelled)
        self.assertTrue(timeout2._cancelled)
        timeout1 = ioloop.call_later(
            0.1, lambda: d.set_result(current_thread().ident))
        yield d
        self.assertTrue(d.done())
        self.assertEqual(d.result(), tid)
        self.assertFalse(has_callback(ioloop, timeout1))

    def test_call_at(self):
        loop = get_event_loop()
        d1 = Future()
        d2 = Future()
        c1 = loop.call_at(loop.time()+1, lambda: d1.set_result(loop.time()))
        c2 = loop.call_later(1, lambda: d2.set_result(loop.time()))
        t1, t2 = yield pulsar.multi_async((d1, d2))
        self.assertTrue(t1 <= t2)

    def test_periodic(self):
        test = self
        loop = get_event_loop()
        waiter = Future()

        class p:
            def __init__(self, loops):
                self.loops = loops
                self.c = 0

            def __call__(self):
                self.c += 1
                if self.c == self.loops:
                    try:
                        raise ValueError('test periodic')
                    except Exception:
                        waiter.set_result(self.c)
                        raise

        every = 2
        loops = 2
        track = p(loops)
        start = loop.time()
        periodic = call_repeatedly(loop, every, track)
        self.assertIsInstance(periodic, LoopingCall)
        done = yield waiter
        taken = loop.time() - start
        self.assertEqual(done, loops)
        self.assertTrue(taken > every*loops)
        self.assertTrue(taken < every*loops + 2)
        self.assertTrue(periodic.cancelled)
        self.assertFalse(has_callback(loop, periodic.handler))

    def test_run_in_thread_loop(self):
        event_loop = get_event_loop()

        def simple(a, b):
            return a + b

        d = run_in_loop(event_loop, simple, 1, 2)
        self.assertIsInstance(d, Future)
        result = yield d
        self.assertEqual(result, 3)
        d = run_in_loop(event_loop, simple, 1, 'a')
        self.assertIsInstance(d, Future)
        try:
            result = yield d
        except TypeError:
            pass
        else:
            assert False, "TypeError not raised"

########NEW FILE########
__FILENAME__ = events
import unittest

from pulsar import EventHandler, get_request_loop


class Handler(EventHandler):

    def __init__(self, **kw):
        self._loop = get_request_loop()
        super(Handler, self).__init__(self._loop, **kw)


class TestFailure(unittest.TestCase):

    def test_one_time(self):
        h = Handler(one_time_events=('start', 'finish'))
        h.bind_event('finish', lambda f, exc=None: 'OK')
        result = yield h.fire_event('finish', 'foo')
        self.assertTrue(h.event('finish').done())
        self.assertEqual(result, 'foo')

    def test_one_time_error(self):
        h = Handler(one_time_events=('start', 'finish'))
        h.bind_event('finish', lambda f, exc=None: 'OK'+4)
        result = yield h.fire_event('finish', 3)
        self.assertTrue(h.event('finish').done())
        self.assertEqual(result, 3)

    def test_bind_events(self):
        h = Handler(one_time_events=('start', 'finish'))
        h.bind_events(foo=3, bla=6)
        self.assertFalse(h.events['start'].handlers)
        self.assertFalse(h.events['finish'].handlers)
        h.bind_events(start=lambda r, exc=None: r+1,
                      finish=lambda r, exc=None: r+1)
        self.assertTrue(h.events['start'].handlers)
        self.assertTrue(h.events['finish'].handlers)
        result = yield h.fire_event('start', 2)
        self.assertEqual(result, 2)

########NEW FILE########
__FILENAME__ = multi
'''MultiFuture coverage'''
import sys
import unittest

from pulsar import (get_event_loop, multi_async, InvalidStateError, Future,
                    maybe_async)


class TestApi(unittest.TestCase):

    def test_empy_list(self):
        r = multi_async(())
        self.assertTrue(r.done())
        self.assertEqual(r.result(), [])

    def test_empy_dict(self):
        r = multi_async({})
        self.assertTrue(r.done())
        self.assertEqual(r.result(), {})

    def test_multi(self):
        d1 = Future()
        d2 = Future()
        d = multi_async([d1, d2, 'bla'])
        self.assertFalse(d.done())
        d2.set_result('first')
        self.assertFalse(d.done())
        d1.set_result('second')
        result = yield d
        self.assertEqual(result, ['second', 'first', 'bla'])

########NEW FILE########
__FILENAME__ = coroutine
import unittest

from pulsar import async, new_event_loop, coroutine_return, Future


DELAY = 0


def async_func(loop, value):
    p = Future(loop=loop)
    loop.call_later(DELAY, p.set_result, value)
    return p


def sub_sub(loop, num):
    a = yield async_func(loop, num)
    b = yield async_func(loop, num)
    coroutine_return(a+b)


def sub(loop, num):
    a = yield async_func(loop, num)
    b = yield async_func(loop, num)
    c = yield sub_sub(loop, num)
    coroutine_return(a+b+c)


def main(loop, num):
    a = yield async_func(loop, num)
    b = yield sub(loop, num)
    c = yield sub(loop, num)
    coroutine_return(a+b+c)


class TestCoroutine(unittest.TestCase):
    __benchmark__ = True
    __number__ = 100

    def setUp(self):
        self.loop = new_event_loop()

    def test_coroutine(self):
        future = async(main(self.loop, 1), loop=self.loop)
        self.loop.run_until_complete(future)
        self.assertEqual(future.result(), 9)

    def getTime(self, dt):
        return dt - 9*DELAY

########NEW FILE########
__FILENAME__ = coroutine3
import sys
import unittest

from pulsar import async, Future, new_event_loop

DELAY = 0


def async_func(loop, value):
    p = Future(loop=loop)
    loop.call_later(DELAY, p.set_result, value)
    return p


def sub_sub(loop, num):
    a = yield from async_func(loop, num)
    b = yield from async_func(loop, num)
    return a + b


def sub(loop, num):
    a = yield from async_func(loop, num)
    b = yield from async_func(loop, num)
    c = yield from sub_sub(loop, num)
    return a + b + c


def main(loop, num):
    a = yield from async_func(loop, num)
    b = yield from sub(loop, num)
    c = yield from sub(loop, num)
    return a + b + c


class TestCoroutine33(unittest.TestCase):
    __benchmark__ = True
    __number__ = 100

    def setUp(self):
        self.loop = new_event_loop()

    def test_coroutine(self):
        future = async(main(self.loop, 1), loop=self.loop)
        self.loop.run_until_complete(future)
        self.assertEqual(future.result(), 9)

    def getTime(self, dt):
        return dt - 9*DELAY

########NEW FILE########
__FILENAME__ = redis
from random import randint, choice
import string
import unittest

from pulsar import HAS_C_EXTENSIONS
from pulsar.apps.data import redis_parser
from pulsar.utils.pep import ispy3k

if ispy3k:
    characters = string.ascii_letters + string.digits
else:   # pragma nocover
    characters = string.letters + string.digits
    range = xrange


class RedisPyParser(unittest.TestCase):
    __benchmark__ = True
    __number__ = 100
    _sizes = {'tiny': 2,
              'small': 10,
              'normal': 100,
              'big': 1000,
              'huge': 10000}
    redis_py_parser = True

    @classmethod
    def setUpClass(cls):
        size = cls.cfg.size
        nsize = cls._sizes[size]
        cls.data = [''.join((choice(characters) for l in range(20)))
                    for s in range(nsize)]
        cls.data_bytes = [(''.join((choice(characters) for l in range(20)))
                           ).encode('utf-8') for s in range(nsize)]
        cls.parser = redis_parser(cls.redis_py_parser)()
        cls.chunk = cls.parser.multi_bulk(cls.data)

    def test_pack_command(self):
        self.parser.pack_command(self.data)

    def test_encode_multi_bulk(self):
        self.parser.multi_bulk(self.data)

    def test_encode_multi_bulk_bytes(self):
        self.parser.multi_bulk(self.data_bytes)

    def test_decode_multi_bulk(self):
        self.parser.feed(self.chunk)
        result = self.parser.get()


@unittest.skipUnless(HAS_C_EXTENSIONS, 'Requires C extensions')
class RedisCParser(RedisPyParser):
    redis_py_parser = False

########NEW FILE########
__FILENAME__ = websocket
from random import randint
import unittest

from pulsar.utils.websocket import frame_parser

i2b = lambda args: bytes(bytearray(args))


class TestCParser(unittest.TestCase):
    __benchmark__ = True
    __number__ = 10000
    _sizes = {'tiny': 10,
              'small': 200,
              'normal': 2000,
              'large': 10000,
              'huge': 100000}

    @classmethod
    def setUpClass(cls):
        size = cls.cfg.size
        nsize = cls._sizes[size]
        cls.data = i2b((randint(0, 255) for v in range(nsize)))

    def setUp(self):
        self.server = self.parser()
        self.client = self.parser(kind=1)

    def parser(self, kind=0):
        return frame_parser(kind=kind)

    def test_masked_encode(self):
        self.client.encode(self.data, opcode=2)


class TestPyParser(TestCParser):

    def parser(self, kind=0):
        return frame_parser(pyparser=True, kind=kind)

########NEW FILE########
__FILENAME__ = base
__test__ = False
import os
import sys
from base64 import b64decode
import unittest

import examples
from pulsar import send, SERVER_SOFTWARE, new_event_loop
from pulsar.utils.path import Path
from pulsar.utils.httpurl import iri_to_uri, SimpleCookie
from pulsar.utils.pep import pypy
from pulsar.apps.http import (HttpClient, TooManyRedirects, HttpResponse,
                              HTTPError)


def dodgyhook(response, exc=None):
    raise ValueError('Dodgy header hook')


class TestHttpClientBase:
    app = None
    with_httpbin = True
    with_proxy = False
    with_tls = False
    proxy_app = None
    # concurrency is set by the config object unless you set it here
    concurrency = None
    timeout = 10

    @classmethod
    def setUpClass(cls):
        # Create the HttpBin server by sending this request to the arbiter
        from examples.proxyserver.manage import server as pserver
        from examples.httpbin import manage
        concurrency = cls.concurrency or cls.cfg.concurrency
        if cls.with_httpbin:
            server = manage.server
            if cls.with_tls:
                base_path = os.path.abspath(os.path.dirname(manage.__file__))
                key_file = os.path.join(base_path, 'server.key')
                cert_file = os.path.join(base_path, 'server.crt')
            else:
                key_file, cert_file = None, None
            s = server(bind='127.0.0.1:0', concurrency=concurrency,
                       name='httpbin-%s' % cls.__name__.lower(),
                       keep_alive=30, key_file=key_file, cert_file=cert_file,
                       workers=1)
            cfg = yield send('arbiter', 'run', s)
            cls.app = cfg.app()
            bits = ('https' if cls.with_tls else 'http',) + cfg.addresses[0]
            cls.uri = '%s://%s:%s/' % bits
        if cls.with_proxy:
            s = pserver(bind='127.0.0.1:0', concurrency=concurrency,
                        name='proxyserver-%s' % cls.__name__.lower())
            cfg = yield send('arbiter', 'run', s)
            cls.proxy_app = cfg.app()
            cls.proxy_uri = 'http://{0}:{1}'.format(*cfg.addresses[0])
        cls._client = cls.client()

    @classmethod
    def tearDownClass(cls):
        if cls.app is not None:
            yield send('arbiter', 'kill_actor', cls.app.name)
        if cls.proxy_app is not None:
            yield send('arbiter', 'kill_actor', cls.proxy_app.name)

    @classmethod
    def client(cls, loop=None, parser=None, pool_size=2, **kwargs):
        parser = cls.parser()
        if cls.with_proxy:
            kwargs['proxy_info'] = {'http': cls.proxy_uri,
                                    'https': cls.proxy_uri,
                                    'ws': cls.proxy_uri,
                                    'wss': cls.proxy_uri}
        return HttpClient(loop=loop, parser=parser, pool_size=pool_size,
                          **kwargs)

    @classmethod
    def parser(cls):
        return None

    @property
    def tunneling(self):
        '''When tunneling, the client needs to perform an extra request.'''
        return int(self.with_proxy and self.with_tls)

    def _check_pool(self, http, response, available=1, processed=1,
                    sessions=1, pools=1):
        # Test the connection pool
        self.assertEqual(len(http.connection_pools), pools)
        if pools:
            pool = http.connection_pools[response.request.key]
            self.assertEqual(http.sessions, sessions)
            self.assertEqual(pool.available, available)
            self.assertEqual(http.requests_processed, processed)

    def _after(self, method, response):
        '''Check for a after_%s % method to test the response.'''
        method = getattr(self, 'after_%s' % method, None)
        if method:
            method(response)

    def httpbin(self, *suffix):
        if suffix:
            return self.uri + '/'.join(suffix)
        else:
            return self.uri

    def after_test_home_page(self, response, processed=1):
        request = response.request
        self.assertEqual(request.scheme, 'https' if self.with_tls else 'http')
        # Only one connection pool,
        # even though the proxy and the connection are for different addresses
        http = response.producer
        self.assertEqual(len(http.connection_pools), 1)
        pool = http.connection_pools[response.request.key]
        self.assertEqual(pool.available, 1)
        self.assertEqual(pool.in_use, 0)
        self.assertEqual(http.sessions, 1)
        self.assertEqual(http.requests_processed, processed)
        self.assertEqual(response._connection._processed, processed)

    def _check_server(self, response):
        self.assertEqual(response.headers['server'], SERVER_SOFTWARE)


class TestHttpClient(TestHttpClientBase, unittest.TestCase):

    def test_HttpResponse(self):
        r = HttpResponse()
        self.assertEqual(r.request, None)
        self.assertEqual(str(r), '<None>')
        self.assertEqual(r.headers, None)

    def test_client(self):
        http = self.client(max_redirects=5, timeout=33)
        self.assertTrue('accept-encoding' in http.headers)
        self.assertEqual(http.timeout, 33)
        self.assertEqual(http.version, 'HTTP/1.1')
        self.assertEqual(http.max_redirects, 5)
        if self.with_proxy:
            self.assertEqual(http.proxy_info, {'http': self.proxy_uri,
                                               'https': self.proxy_uri,
                                               'ws': self.proxy_uri,
                                               'wss': self.proxy_uri})

    def test_home_page(self):
        http = self.client()
        response = yield http.get(self.httpbin())
        self.assertEqual(str(response), '200')
        self.assertTrue('content-length' in response.headers)
        content = response.get_content()
        size = response.headers['content-length']
        self.assertEqual(len(content), int(size))
        self.assertEqual(response.headers['connection'], 'Keep-Alive')
        self._check_server(response)
        self.after_test_home_page(response)
        # Try again
        response = yield http.get(self.httpbin())
        self.assertEqual(str(response), '200')
        self._check_server(response)
        self.after_test_home_page(response, 2)

    def test_200_get(self):
        http = self.client()
        response = yield http.get(self.httpbin())
        self.assertEqual(str(response), '200')
        self.assertEqual(repr(response), 'HttpResponse(200)')
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.get_status(), '200 OK')
        self.assertTrue(response.get_content())
        self.assertEqual(response.url, self.httpbin())
        self._check_pool(http, response)
        response = yield http.get(self.httpbin('get'))
        self.assertEqual(response.status_code, 200)
        self._check_pool(http, response, processed=2)

    def test_request_object(self):
        http = self._client
        response = yield http.get(self.httpbin())
        request = response.request
        self.assertTrue(request.headers)
        self.assertTrue(request.has_header('Connection'))
        self.assertTrue(request.has_header('Accept-Encoding'))
        self.assertTrue(request.has_header('User-Agent'))
        self.assertFalse(request.has_header('foo'))
        self.assertEqual(request.headers.kind, 'client')
        self.assertEqual(request.unredirected_headers.kind, 'client')

    def test_http10(self):
        '''By default HTTP/1.0 close the connection if no keep-alive header
        was passed by the client.
        '''
        http = self.client(version='HTTP/1.0')
        http.headers.clear()
        self.assertEqual(http.version, 'HTTP/1.0')
        response = yield http.get(self.httpbin())
        self.assertEqual(response.headers['connection'], 'close')
        self.assertEqual(str(response), '200')
        self._check_pool(http, response, available=0)

    def test_http11(self):
        '''By default HTTP/1.1 keep alive the connection if no keep-alive
        header was passed by the client.
        '''
        http = self.client()
        http.headers.clear()
        self.assertEqual(http.version, 'HTTP/1.1')
        response = yield http.get(self.httpbin())
        self.assertEqual(response.headers['connection'], 'keep-alive')
        self._check_pool(http, response)

    def test_http11_close(self):
        http = self.client()
        self.assertEqual(http.version, 'HTTP/1.1')
        response = yield http.get(
            self.httpbin(), headers=[('connection', 'close')])
        self.assertEqual(response.headers['connection'], 'close')
        self._check_pool(http, response, available=0)

    def test_200_get_data(self):
        http = self.client()
        response = yield http.get(self.httpbin('get'),
                                  data={'bla': 'foo'})
        result = response.json()
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.headers['content-type'],
                         'application/json; charset=utf-8')
        self.assertEqual(result['args'], {'bla': 'foo'})
        self.assertEqual(response.url,
                         self.httpbin(iri_to_uri('get', {'bla': 'foo'})))
        self._check_pool(http, response)

    def test_200_gzip(self):
        http = self._client
        response = yield http.get(self.httpbin('gzip'))
        self.assertEqual(response.status_code, 200)
        content = response.json()
        self.assertTrue(content['gzipped'])
        if 'content-encoding' in response.headers:
            self.assertTrue(response.headers['content-encoding'], 'gzip')

    def test_post(self):
        data = (('bla', 'foo'), ('unz', 'whatz'),
                ('numero', '1'), ('numero', '2'))
        http = self._client
        response = yield http.post(self.httpbin('post'),
                                   encode_multipart=False,
                                   data=data)
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertTrue(result['args'])
        self.assertEqual(result['args']['numero'], ['1', '2'])

    def test_large_response(self):
        http = self._client
        response = yield http.get(self.httpbin('getsize/600000'))
        self.assertEqual(response.status_code, 200)
        data = response.json()
        self.assertEqual(data['size'], 600000)
        self.assertEqual(len(data['data']), 600000)
        self.assertFalse(response.parser.is_chunked())

    def test_400_and_get(self):
        '''Bad request 400'''
        http = self.client()
        response = yield http.get(self.httpbin('status', '400'))
        self._check_pool(http, response, available=0)
        self.assertEqual(response.status_code, 400)
        self.assertEqual(response.get_status(), '400 Bad Request')
        self.assertTrue(response.get_content())
        self.assertRaises(HTTPError, response.raise_for_status)
        # Make sure we only have one connection after a valid request
        response = yield http.get(self.httpbin('get'))
        self.assertEqual(response.status_code, 200)
        # for tunneling this fails sometimes
        self._check_pool(http, response, sessions=2, processed=2)

    def test_404_get(self):
        '''Not Found 404'''
        http = self._client
        response = yield http.get(self.httpbin('status', '404'))
        self.assertEqual(response.status_code, 404)
        self.assertTrue(response.headers.has('connection', 'close'))
        self.assertTrue('content-type' in response.headers)
        self.assertTrue(response.get_content())
        self.assertRaises(HTTPError, response.raise_for_status)

    def test_dodgy_on_header_event(self):
        client = self._client
        response = yield client.get(self.httpbin(), on_headers=dodgyhook)
        self.assertTrue(response.headers)
        self.assertEqual(response.status_code, 200)

    def test_redirect_1(self):
        http = self.client()
        response = yield http.get(self.httpbin('redirect', '1'))
        self.assertEqual(response.status_code, 200)
        history = response.history
        self.assertEqual(len(history), 1)
        self.assertTrue(history[0].url.endswith('/redirect/1'))
        self._after('test_redirect_1', response)

    def after_test_redirect_1(self, response):
        redirect = response.history[0]
        self.assertEqual(redirect.connection, response.connection)
        self.assertEqual(response.connection._processed, 2)

    def test_redirect_6(self):
        http = self.client()
        response = yield http.get(self.httpbin('redirect', '6'))
        self.assertEqual(response.status_code, 200)
        history = response.history
        self.assertEqual(len(history), 6)
        self.assertTrue(history[0].url.endswith('/redirect/6'))
        self._after('test_redirect_6', response)

    def after_test_redirect_6(self, response):
        redirect = response.history[-1]
        self.assertEqual(redirect.connection, response.connection)
        self.assertEqual(response.connection._processed, 7)

    def test_large_response(self):
        if pypy:
            # TODO: this fails in pypy randomnly
            return
        http = self._client
        response = yield http.get(self.httpbin('getsize/600000'))
        self.assertEqual(response.status_code, 200)
        data = response.json()
        self.assertEqual(data['size'], 600000)
        self.assertEqual(len(data['data']), 600000)
        self.assertFalse(response.parser.is_chunked())

    def test_too_many_redirects(self):
        http = self._client
        try:
            response = yield http.get(self.httpbin('redirect', '5'),
                                      max_redirects=2)
        except TooManyRedirects as e:
            response = e.response
        else:
            assert False, 'TooManyRedirects not raised'
        history = response.history
        self.assertEqual(len(history), 2)
        self.assertTrue(history[0].url.endswith('/redirect/5'))
        self.assertTrue(history[1].url.endswith('/redirect/4'))

    def test_post_multipart(self):
        data = (('bla', 'foo'), ('unz', 'whatz'),
                ('numero', '1'), ('numero', '2'))
        http = self._client
        response = yield http.post(self.httpbin('post'), data=data)
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertTrue(result['args'])
        self.assertEqual(result['args']['numero'], ['1', '2'])

    def test_put(self):
        data = (('bla', 'foo'), ('unz', 'whatz'),
                ('numero', '1'), ('numero', '2'))
        http = self._client
        response = yield http.put(self.httpbin('put'), data=data)
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertTrue(result['args'])
        self.assertEqual(result['args']['numero'], ['1', '2'])

    def test_patch(self):
        data = (('bla', 'foo'), ('unz', 'whatz'),
                ('numero', '1'), ('numero', '2'))
        http = self._client
        response = yield http.patch(self.httpbin('patch'),
                                    data=data)
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertTrue(result['args'])
        self.assertEqual(result['args']['numero'], ['1', '2'])

    def test_delete(self):
        data = (('bla', 'foo'), ('unz', 'whatz'),
                ('numero', '1'), ('numero', '2'))
        http = self._client
        response = yield http.delete(self.httpbin('delete'),
                                     data=data)
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertTrue(result['args'])
        self.assertEqual(result['args']['numero'], ['1', '2'])

    def test_response_headers(self):
        http = self._client
        response = yield http.get(self.httpbin('response-headers'))
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertEqual(result['Transfer-Encoding'], 'chunked')
        parser = response.parser
        self.assertTrue(parser.is_chunked())

    def test_stream_response(self):
        http = self._client
        response = yield http.get(self.httpbin('stream/3000/20'))
        self.assertEqual(response.status_code, 200)
        self.assertTrue(response.parser.is_chunked())

    def test_stream_response_large_chunk(self):
        # TODO fix this test. Issue #97
        if not self.with_tls:
            http = self._client
            response = yield http.get(self.httpbin('stream/100000/3'))
            self.assertEqual(response.status_code, 200)
            self.assertTrue(response.parser.is_chunked())

    def test_expect(self):
        http = self._client
        data = (('bla', 'foo'), ('unz', 'whatz'),
                ('numero', '1'), ('numero', '2'))
        response = yield http.post(self.httpbin('post'), data=data,
                                   wait_continue=True)
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertTrue(result['args'])
        self.assertEqual(result['args']['numero'], ['1', '2'])

    def test_send_cookie(self):
        http = self._client
        cookies = {'sessionid': 't1', 'cookies_are': 'working'}
        response = yield http.get(self.httpbin(), cookies=cookies)
        self.assertEqual(response.status_code, 200)
        self.assertTrue(response.headers['set-cookie'])
        self.assertEqual(response.cookies, SimpleCookie(cookies))

    def test_cookie(self):
        http = self._client
        # First set the cookies
        r = yield http.get(self.httpbin(
            'cookies', 'set', 'bla', 'foo'))
        self.assertEqual(r.status_code, 200)
        self.assertTrue(r.history)
        self.assertTrue(r.history[0].headers['set-cookie'])
        self.assertTrue(http.cookies)
        # Now check if I get them
        r = yield http.get(self.httpbin('cookies'))
        self.assertEqual(r.status_code, 200)
        self.assertTrue(r.request.unredirected_headers)
        result = r.json()
        self.assertTrue(result['cookies'])
        self.assertEqual(result['cookies']['bla'], 'foo')
        # Try without saving cookies
        http = self.client(store_cookies=False)
        r = yield http.get(self.httpbin(
            'cookies', 'set', 'bla', 'foo'))
        self.assertEqual(r.status_code, 200)
        self.assertTrue(r.history)
        self.assertTrue(r.history[0].headers['set-cookie'])
        r = yield http.get(self.httpbin('cookies'))
        self.assertEqual(r.status_code, 200)
        result = r.json()
        self.assertFalse(result['cookies'])

    def test_basic_authentication(self):
        http = self._client
        r = yield http.get(self.httpbin('basic-auth/bla/foo'))
        # The response MUST include a WWW-Authenticate header field
        self.assertEqual(r.status_code, 401)
        http.add_basic_authentication('bla', 'foo')
        r = yield http.get(self.httpbin('basic-auth/bla/foo'))
        self.assertEqual(r.status_code, 200)

    def test_digest_authentication(self):
        # TODO fix this test. Issue #94
        if not self.tunneling:
            http = self.client()
            r = yield http.get(self.httpbin(
                'digest-auth/luca/bla/auth'))
            self.assertEqual(r.status_code, 401)
            http.add_digest_authentication('luca', 'bla')
            r = yield http.get(self.httpbin(
                'digest-auth/luca/bla/auth'))
            self.assertEqual(r.status_code, 200)

    def test_missing_host_400(self):
        http = self._client

        def remove_host(response, exc=None):
            r = response.request
            self.assertTrue(r.has_header('host'))
            response.request.remove_header('host')
            self.assertFalse(r.has_header('host'))

        response = yield http.get(self.httpbin(),
                                  pre_request=remove_host)
        if self.with_proxy and not self.tunneling:
            # When using a proxy, The proxy server obtains the host from
            # the absolute URI which part of the request.
            self.assertEqual(response.status_code, 200)
        else:
            # In any other request, this should cause a 400 error
            self.assertEqual(response.status_code, 400)

    def test_missing_host_10(self):
        http = self.client(version='HTTP/1.0')

        def remove_host(response, exc=None):
            r = response.request
            self.assertTrue(r.has_header('host'))
            r.remove_header('host')
            self.assertFalse(r.has_header('host'))
            return response

        response = yield http.get(self.httpbin(),
                                  pre_request=remove_host)
        self.assertEqual(response.status_code, 200)

    def test_expect_fail(self):
        '''This is an important test for the proxy server example.
        The expect-continue must be handled by the upstream server which in
        this case refuses the continue.'''
        http = self._client
        data = (('bla', 'foo'), ('unz', 'whatz'),
                ('numero', '1'), ('numero', '2'))
        response = yield http.post(self.httpbin('expect'), data=data,
                                   wait_continue=True)
        self.assertEqual(response.status_code, 417)

    def test_expect_fail_no_waiting(self):
        http = self._client
        data = (('bla', 'foo'), ('unz', 'whatz'),
                ('numero', '1'), ('numero', '2'))
        response = yield http.post(self.httpbin('expect'), data=data
                                   )
        self.assertEqual(response.status_code, 200)
        result = response.json()
        self.assertTrue(result['args'])
        self.assertEqual(result['args']['numero'], ['1', '2'])

    def test_media_root(self):
        http = self._client
        response = yield http.get(self.httpbin('media/'))
        self.assertEqual(response.status_code, 200)
        self.assertEqual(response.headers['content-type'],
                         'text/html; charset=utf-8')

    def test_media_file(self):
        http = self._client
        response = yield http.get(self.httpbin('media/httpbin.js'))
        self.assertEqual(response.status_code, 200)
        self.assertTrue(response.headers['content-type'] in
                        ('application/javascript',
                         'application/x-javascript'))
        self.assertTrue(int(response.headers['content-length']) > 0)
        modified = response.headers.get('Last-modified')
        self.assertTrue(modified)
        #
        # Test if modified since
        response = yield http.get(self.httpbin('media/httpbin.js'),
                                  headers=[('If-modified-since', modified)]
                                  )
        self.assertEqual(response.status_code, 304)
        self.assertFalse('Content-length' in response.headers)

    def test_http_get_timeit(self):
        N = 10
        client = self._client
        bench = yield client.timeit('get', N, self.httpbin('get'),
                                    data={'bla': 'foo'})
        self.assertTrue(bench.taken)
        self.assertEqual(len(bench.result), N)
        for r in bench.result:
            self.assertEqual(r.status_code, 200)

    def test_send_files(self):
        client = self._client
        files = {'test': 'simple file'}
        data = (('bla', 'foo'), ('unz', 'whatz'),
                ('numero', '1'), ('numero', '2'))
        response = yield client.post(self.httpbin('post'), data=data,
                                     files=files)
        self.assertEqual(response.status_code, 200)
        ct = response.request.headers['content-type']
        self.assertTrue(ct.startswith('multipart/form-data; boundary='))
        data = response.json()
        self.assertEqual(data['files'], {'test': ['simple file']})
        self.assertEqual(data['args']['numero'], ['1', '2'])

    def test_send_images(self):
        path = Path(examples.__file__).parent.parent
        path = path.join('docs', 'source', '_static')
        files = []
        sent = []
        for name in ('pulsar.png', 'favicon.ico'):
            with open(path.join(name), 'rb') as file:
                image = file.read()
            sent.append(image)
            files.append(('images', (name, image)))
        client = self._client
        response = yield client.post(self.httpbin('post'), files=files)
        self.assertEqual(response.status_code, 200)
        ct = response.request.headers['content-type']
        self.assertTrue(ct.startswith('multipart/form-data; boundary='))
        data = response.json()
        images = data['files']['images']
        self.assertEqual(len(images), 2)
        for image, s in zip(images, sent):
            image = b64decode(image.encode('utf-8'))
            self.assertEqual(image, s)

    def test_bench_json(self):
        http = self._client
        response = yield http.get(self.httpbin('json'))
        self.assertEqual(response.headers['content-type'],
                         'application/json; charset=utf-8')
        result = response.decode_content()
        self.assertEqual(result, {'message': 'Hello, World!'})

    def test_bench_text(self):
        http = self._client
        response = yield http.get(self.httpbin('plaintext'))
        self.assertEqual(response.headers['content-type'],
                         'text/plain; charset=utf-8')
        result = response.decode_content()
        self.assertEqual(result, 'Hello, World!')

    def test_pool_200(self):
        N = 6
        http = self.client(pool_size=2)
        bench = yield http.timeit('get', N, self.httpbin())
        self.assertEqual(len(bench.result), N)
        for response in bench.result:
            self.assertEqual(str(response), '200')
            self.assertTrue('content-length' in response.headers)
        self.assertEqual(len(http.connection_pools), 1)
        pool = tuple(http.connection_pools.values())[0]
        self.assertEqual(pool.pool_size, 2)
        self.assertEqual(pool.in_use, 0)
        self.assertEqual(pool.available, 2)

    def test_pool_400(self):
        N = 6
        http = self.client(pool_size=2)
        bench = yield http.timeit('get', N, self.httpbin('status', '400'))
        self.assertEqual(len(bench.result), N)
        for response in bench.result:
            self.assertEqual(str(response), '400')
            self.assertTrue('content-length' in response.headers)
        self.assertEqual(len(http.connection_pools), 1)
        pool = tuple(http.connection_pools.values())[0]
        self.assertEqual(pool.pool_size, 2)
        self.assertEqual(pool.in_use, 0)
        self.assertEqual(pool.available, 0)

########NEW FILE########
__FILENAME__ = client
import unittest

from pulsar.utils.httpurl import urlparse

from . import base


class TestHttpClient(base.TestHttpClient):

    def __test_connect(self):
        http = self.client()
        p = urlparse(self.uri)
        response = yield http.connect(p.netloc)
        self.assertEqual(response.status_code, 405)
        self.assertEqual(response._request.method, 'CONNECT')

########NEW FILE########
__FILENAME__ = defaults
import unittest

from pulsar.apps.http import HttpClient


class TestClientDefaults(unittest.TestCase):

    def test_headers(self):
        headers = HttpClient.DEFAULT_HTTP_HEADERS
        self.assertEqual(len(headers), 3)
        accept = headers['accept-encoding']
        self.assertTrue('gzip' in accept)
        self.assertTrue('deflate' in accept)

    def test_override_headers(self):
        headers = {'Accept': 'application/json, text/plain; q=0.8',
                   'content-type': 'application/json'}
        client = HttpClient(headers=headers)
        self.assertEqual(client.headers['accept'],
                         'application/json, text/plain; q=0.8')
        self.assertEqual(client.headers['content-type'], 'application/json')

########NEW FILE########
__FILENAME__ = external
import socket
import unittest

from pulsar import get_actor
from pulsar.apps import http
from pulsar.apps.http import URLError

from .base import TestHttpClientBase


class ExternalBase(TestHttpClientBase):
    with_httpbin = False

    def after_response(self, response):
        pass

    def ___test_http_get_timeit(self):
        client = self.client()
        N = 20
        responses = yield client.timeit(N, 'get', 'http://www.bbc.co.uk/')
        self.assertEqual(len(responses), N)
        for n in range(N):
            all = []

            def save_data(r, data=None):
                all.append(data)
            try:
                response = yield client.get('http://www.theguardian.com/',
                                            data_received=save_data)
            except Exception:
                for n, d in enumerate(all):
                    with open('data%s.dat' % n, 'wb') as f:
                        f.write(d)
                raise
            self.assertEqual(response.status_code, 200)

    def __test_http_get(self):
        client = self.client()
        response = yield client.get('http://www.bbc.co.uk/')
        self.assertEqual(response.status_code, 200)
        self.after_response(response)

    def test_get_https(self):
        client = self.client()
        response = yield client.get('https://github.com/trending')
        self.assertEqual(response.status_code, 200)

    def __test_bad_host(self):
        client = self.client()
        try:
            response = yield client.get('http://xxxyyyxxxxyyy/blafoo')
        except socket.error:
            pass
        else:
            self.assertTrue(response.request.proxy)
            self.assertTrue(response.status_code >= 400)


class ProxyExternal(ExternalBase):

    def after_response(self, response):
        self.assertTrue(response.request.proxy)

    def test_get_https(self):
        client = self.client()
        response = yield client.get('https://github.com/trending')
        self.assertEqual(response.status_code, 200)


@unittest.skipUnless(get_actor().cfg.http_proxy == '',
                     'Requires no external proxy')
class Test_HttpClient_NoProxy_External(ExternalBase, unittest.TestCase):
    '''Test external URI when no global proxy server is present.
    '''


@unittest.skipUnless(get_actor().cfg.http_proxy == '',
                     'Requires no external proxy')
class Test_HttpClient_Proxy_External(ProxyExternal, unittest.TestCase):
    with_proxy = True


@unittest.skipUnless(get_actor().cfg.http_proxy, 'Requires external proxy')
class Test_HttpClient_ExternalProxy_External(ProxyExternal,
                                             unittest.TestCase):
    pass

########NEW FILE########
__FILENAME__ = parser
import os
import unittest

from pulsar.utils.httpurl import hasextensions
from pulsar.utils import httpurl


class TestPythonHttpParser(unittest.TestCase):

    @classmethod
    def parser(cls, **kwargs):
        return httpurl.HttpParser(**kwargs)

    def __test_amazon_protocol_error(self):
        all = []
        for n in range(18):
            with open(os.path.join(os.path.dirname(__file__), 'data',
                                   'data%d.dat' % n), 'rb') as f:
                all.append(f.read())
        #
        p = self.parser()
        for chunk in all:
            self.assertEqual(p.execute(chunk, len(chunk)), len(chunk))
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_begin())

    def test_client_connect(self):
        p = self.parser()
        data = b'HTTP/1.1 200 Connection established\r\n\r\n'
        self.assertEqual(p.execute(data, len(data)), len(data))
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_begin())
        self.assertFalse(p.is_partial_body())
        self.assertFalse(p.is_message_complete())

    def test_client_200_OK_no_headers(self):
        p = self.parser()
        data = b'HTTP/1.1 200 OK\r\n\r\n'
        self.assertEqual(p.execute(data, len(data)), len(data))
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_begin())
        self.assertFalse(p.is_partial_body())
        self.assertFalse(p.is_message_complete())

    def test_simple_server_message(self):
        p = self.parser()
        self.assertFalse(p.is_headers_complete())
        data = b'GET /forum/bla?page=1#post1 HTTP/1.1\r\n\r\n'
        self.assertEqual(p.execute(data, len(data)), len(data))
        self.assertEqual(p.get_fragment(), 'post1')
        self.assertTrue(p.is_message_begin())
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_complete())
        self.assertFalse(p.get_headers())

    def test_bad_combinations(self):
        p = self.parser()
        # body with no headers not valid
        data = b'GET /get HTTP/1.1\r\nciao'
        self.assertEqual(p.execute(data, len(data)), len(data))
        self.assertFalse(p.is_headers_complete())
        # self.assertTrue(p.is_message_begin())
        self.assertFalse(p.is_message_complete())
        self.assertEqual(p.execute(b'x', 1), 1)

    def test_client_connect(self):
        p = self.parser()
        data = b'HTTP/1.1 200 Connection established\r\n\r\n'
        self.assertEqual(p.execute(data, len(data)), len(data))
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_begin())
        self.assertFalse(p.is_partial_body())
        self.assertFalse(p.is_message_complete())

    def test_client_no_body(self):
        p = self.parser()
        data = (b'HTTP/1.1 200 OK\r\n'
                b'Connection: keep-alive\r\n\r\n')
        self.assertEqual(p.execute(data, len(data)), len(data))
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_begin())
        self.assertFalse(p.is_partial_body())
        self.assertFalse(p.is_message_complete())

    def testBadFirstLine(self):
        p = self.parser()
        self.assertFalse(p.is_headers_complete())
        data = b'GET HTTP/1.1\r\n\r\n'
        self.assertNotEqual(p.execute(data, len(data)), len(data))
        p = self.parser()
        data = b'get /foo HTTP/1.1\r\n\r\n'
        self.assertNotEqual(p.execute(data, len(data)), len(data))
        p = self.parser()
        data = b'GET /foo FTP/1.1\r\n\r\n'
        self.assertNotEqual(p.execute(data, len(data)), len(data))
        p = self.parser()
        data = b'GET get/ HTTP/1-x\r\n'
        self.assertNotEqual(p.execute(data, len(data)), len(data))

    def testPartialFirstLine(self):
        p = self.parser()
        data = b'GET /get H'
        self.assertEqual(p.execute(data, len(data)), len(data))
        self.assertFalse(p.is_headers_complete())
        data = b'TTP/1.1\r\n\r\n'
        p.execute(data, len(data))
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_complete())
        self.assertFalse(p.get_headers())

    def testBadHeader(self):
        p = self.parser()
        data = b'GET /get HTTP/1.1\r\nbla\0: bar\r\n\r\n'
        self.assertNotEqual(p.execute(data, len(data)), len(data))
        #
        p = self.parser()
        data = b'GET /test HTTP/1.1\r\nfoo\r\n\r\n'
        self.assertEqual(p.execute(data, len(data)), len(data))
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_begin())
        self.assertTrue(p.is_message_complete())
        headers = p.get_headers()
        self.assertEqual(len(headers), 0)

    def testHeaderOnly(self):
        p = self.parser()
        data = b'GET /test HTTP/1.1\r\nHost: 0.0.0.0=5000\r\n\r\n'
        p.execute(data, len(data))
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_begin())
        self.assertTrue(p.is_message_complete())

    def testContentLength(self):
        p = self.parser()
        data = b'GET /test HTTP/1.1\r\n'
        p.execute(data, len(data))
        self.assertFalse(p.is_headers_complete())
        data = b'Content-Length: 4\r\n\r\n'
        p.execute(data, len(data))
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_begin())
        self.assertFalse(p.is_message_complete())
        data = b'cia'
        p.execute(data, len(data))
        self.assertFalse(p.is_message_complete())
        data = b'o'
        p.execute(data, len(data))
        self.assertTrue(p.is_message_complete())

    def test_ouble_header(self):
        p = self.parser()
        data = b'GET /test HTTP/1.1\r\n'
        p.execute(data, len(data))
        data = b'Accept: */*\r\n'
        p.execute(data, len(data))
        data = b'Accept: jpeg\r\n\r\n'
        p.execute(data, len(data))
        self.assertTrue(p.is_headers_complete())
        self.assertTrue(p.is_message_begin())
        self.assertTrue(p.is_message_complete())
        headers = p.get_headers()
        self.assertEqual(len(headers), 1)
        self.assertEqual(headers.get('Accept'), ['*/*', 'jpeg'])

    def test_connect(self):
        p = self.parser()
        data = b'HTTP/1.1 200 Connection established\r\n\r\n'
        self.assertEqual(p.execute(data, len(data)), len(data))


@unittest.skipUnless(hasextensions, 'Requires C extensions')
class TestCHttpParser(TestPythonHttpParser):

    @classmethod
    def parser(cls, **kwargs):
        return httpurl.CHttpParser(**kwargs)

########NEW FILE########
__FILENAME__ = proxy
from . import base


class TestHttpClientWithProxy(base.TestHttpClient):
    with_proxy = True

    def _check_server(self, response):
        pass

########NEW FILE########
__FILENAME__ = pyclient
import unittest

from pulsar.utils.httpurl import hasextensions, HttpParser

from . import client


@unittest.skipUnless(hasextensions, 'Requires C extensions')
class TestHttpClientWithPythonParser(client.TestHttpClient):

    @classmethod
    def parser(cls):
        return HttpParser

########NEW FILE########
__FILENAME__ = tls
from . import base


class TestTlsHttpClient(base.TestHttpClient):
    with_tls = True

    def test_large_response(self):
        # TODO: THis fails on python 2.7 (sometimes)
        pass

########NEW FILE########
__FILENAME__ = tools
'''tests the httpurl stand-alone script.'''
import time
import unittest

from pulsar.utils.httpurl import (Headers, CacheControl,
                                  urlquote, unquote_unreserved, requote_uri,
                                  remove_double_slash, appendslash, capfirst,
                                  encode_multipart_formdata, http_date,
                                  cookiejar_from_dict, SimpleCookie)
from pulsar.utils.pep import to_bytes, native_str, force_native_str
from pulsar.apps.http import Auth, HTTPBasicAuth, HTTPDigestAuth


class TestAuth(unittest.TestCase):

    def test_auth(self):
        auth = Auth()
        self.assertRaises(NotImplementedError, auth, None)
        self.assertEqual(str(auth), repr(auth))

    def test_basic_auth(self):
        auth = HTTPBasicAuth('bla', 'foo')
        self.assertEqual(str(auth), 'Basic: bla')

    def test_digest_auth(self):
        auth = HTTPDigestAuth('bla', options={'realm': 'fake realm'})
        self.assertEqual(auth.type, 'digest')
        self.assertEqual(auth.username, 'bla')
        self.assertEqual(auth.password, None)
        self.assertEqual(auth.options['realm'], 'fake realm')

    def test_CacheControl(self):
        headers = Headers()
        c = CacheControl()
        self.assertFalse(c.private)
        self.assertFalse(c.maxage)
        c(headers)
        self.assertEqual(headers['cache-control'], 'no-cache')
        c = CacheControl(maxage=3600)
        c(headers)
        self.assertEqual(headers['cache-control'], 'max-age=3600, public')
        c = CacheControl(maxage=3600, private=True)
        c(headers)
        self.assertEqual(headers['cache-control'], 'max-age=3600, private')
        c = CacheControl(maxage=3600, must_revalidate=True)
        c(headers)
        self.assertEqual(headers['cache-control'],
                         'max-age=3600, public, must-revalidate')
        c = CacheControl(maxage=3600, proxy_revalidate=True)
        c(headers)
        self.assertEqual(headers['cache-control'],
                         'max-age=3600, public, proxy-revalidate')
        c = CacheControl(maxage=3600, proxy_revalidate=True,
                         nostore=True)
        c(headers)
        self.assertEqual(headers['cache-control'],
                         'no-store, no-cache, must-revalidate, max-age=0')


class TestTools(unittest.TestCase):

    def test_to_bytes(self):
        s = to_bytes('ciao')
        self.assertTrue(isinstance(s, bytes))
        s2 = to_bytes(s)
        self.assertEqual(id(s), id(s2))
        s3 = to_bytes(s, 'latin-1')
        self.assertEqual(s, s3)
        self.assertNotEqual(id(s), id(s3))

    def test_native_str(self):
        s = 'ciao'
        s2 = native_str(s)
        self.assertEqual(id(s), id(s2))

    def test_force_native_str(self):
        self.assertEqual(force_native_str('ciao'), 'ciao')
        self.assertEqual(force_native_str(b'ciao'), 'ciao')
        self.assertEqual(force_native_str(1), '1')
        self.assertEqual(force_native_str((1, 'b')), str((1, 'b')))

    def test_quote_unreserved(self):
        '''Test a string of unreserved characters'''
        s = 'a~b_(c-d).'
        qs = urlquote(s)
        self.assertTrue('%' in qs)
        uqs = unquote_unreserved(qs)
        self.assertEqual(uqs, s)
        self.assertEqual(requote_uri(s), s)
        self.assertEqual(requote_uri(qs), s)

    def test_quote_unreserved_percent(self):
        s = 'a=3.5%;b=2%'
        qs = urlquote(s)
        self.assertTrue('%' in qs)
        uqs = unquote_unreserved(qs)
        self.assertNotEqual(uqs, s)
        s = 'a~b_(c-d).'
        qs = urlquote(s) + '%f'
        uqs = unquote_unreserved(qs)
        self.assertEqual(uqs, s+'%f')

    def test_remove_double_slash(self):
        r = remove_double_slash
        self.assertEqual(r('/bla//foo/'), '/bla/foo/')
        self.assertEqual(r('/bla/////////foo//////////'), '/bla/foo/')
        self.assertEqual(r('/bla/foo/'), '/bla/foo/')

    def test_appendslash(self):
        self.assertEqual(appendslash('bla'), 'bla/')
        self.assertEqual(appendslash('bla/'), 'bla/')

    def test_capfirst(self):
        c = capfirst
        self.assertEqual(c('blA'), 'Bla')
        self.assertEqual(c(''), '')
        self.assertEqual(c('bOlA'), 'Bola')

    def test_encode_multipart_formdata(self):
        data, ct = encode_multipart_formdata([('bla', 'foo'),
                                              ('foo', ('pippo', 'pluto'))])
        idx = data.find(b'\r\n')
        boundary = data[2:idx].decode('utf-8')
        self.assertEqual(ct, 'multipart/form-data; boundary=%s' % boundary)

    def test_http_date(self):
        now = time.time()
        fmt = http_date(now)
        self.assertTrue(fmt.endswith(' GMT'))
        self.assertEqual(fmt[3:5], ', ')

    def test_cookiejar_from_dict(self):
        j = cookiejar_from_dict({'bla': 'foo'})
        j2 = cookiejar_from_dict({'pippo': 'pluto'}, j)
        self.assertEqual(j, j2)

########NEW FILE########
__FILENAME__ = tunnel
from pulsar.utils.httpurl import urlparse

from . import base


# class TestHttpClient(client.TestHttpClientBase, client.unittest.TestCase):

class TestTlsHttpClientWithProxy(base.TestHttpClient):
    with_proxy = True
    with_tls = True

########NEW FILE########
__FILENAME__ = couchdbtest
from pulsar.utils.security import gen_unique_id
from pulsar.apps.data import odm
from pulsar.apps.tasks import Task

models = odm.Mapper('couchdb://127.0.0.1:5984/test')
store = models.default_store
try:
    ok = store.delete_database()
except Exception:
    pass
ok = store.create_database()

models.register(Task)
ok = models.create_tables()

tasks = models.task
task1 = tasks.create(name='bla', id=gen_unique_id())
assert task1.name == 'bla'
task2 = tasks.create(name='foo', id=gen_unique_id())
assert task2.name == 'foo'
task3 = tasks.create(name='foo', id=gen_unique_id())
assert task3.name == 'foo'

objs = store.table_info(Task)

store.

ok = models.drop_tables()

########NEW FILE########
__FILENAME__ = tunnel
from functools import partial
try:
    from pulsar.apps import http
except ImportError:
    import sys
    sys.path.append('../../')
    from pulsar.apps import http

from pulsar.utils.log import configure_logging

HOME_URL = 'https://127.0.0.1:8060/'

configure_logging(level='debug')
proxy_info = {'http': 'http://127.0.0.1:9080',
              'https': 'http://127.0.0.1:9080'}


def data_received(response, data=None):
    print('DATA RECEIVED')
    print(response.request)
    print('%s' % data)
    print('---------------------------------------------------')
    print('')


def pre_request(response):
    connection = response.connection
    print('PRE REQUEST ON CONNECTION %s' % connection)
    print(response.request)
    print('---------------------------------------------------')
    print('')


def post_request(response):
    print('REQUEST DONE')
    print(response)
    print('Headers')
    print(response.headers)
    return response


hooks = {'data_received': data_received,
         'pre_request': pre_request,
         'post_request': post_request}

client = http.HttpClient(proxy_info=proxy_info, force_sync=True)


def get(bit=''):
    url = HOME_URL + bit
    return client.get(url, **hooks)


print('======================================================================')
print('======================================================================')
print(get())
print('\n\n')
print('======================================================================')
print('======================================================================')
print(get('redirect/1'))
print('\n\n')
print('======================================================================')
print('======================================================================')
print(get('status/400'))

########NEW FILE########
__FILENAME__ = couchdb
import unittest

from pulsar import coroutine_return, multi_async, new_event_loop
from pulsar.utils.security import random_string
from pulsar.apps.data import create_store
from pulsar.apps.test import check_server
from pulsar.apps.data.stores import CouchDbError, CouchDbNoDbError


OK = check_server('couchdb')


@unittest.skipUnless(OK, 'Requires a running CouchDB server')
class CouchDbTest(object):

    @classmethod
    def create_store(cls, pool_size=2, **kw):
        addr = '%s/%s' % (cls.cfg.couchdb_server, cls.name(cls.__name__))
        return create_store(addr, pool_size=pool_size, **kw)


class TestStoreWithDb(object):
    store = None
    databases = []

    @classmethod
    def name(cls, name):
        '''A modified database name
        '''
        return ('test_%s_%s' % (cls.cfg.exc_id, name)).lower()

    @classmethod
    def createdb(cls, name, store=None):
        '''Create a new database.

        Add the newly created database name to the list of database to remove
        once this :class:`TestCase` invokes the :meth:`tearDownClass`
        method.
        '''
        if not cls.databases:
            cls.databases = []
        name = cls.name(name)
        store = store or cls.store
        result = yield store.create_database(name)
        cls.databases.append(name)
        coroutine_return(result)

    @classmethod
    def dropdbs(cls):
        if cls.databases:
            return multi_async((cls.store.delete_database(name)
                                for name in cls.databases))

    @classmethod
    def create_store(cls, address, pool_size=2, **kw):
        return create_store(address, pool_size=pool_size, **kw)


@unittest.skipUnless(OK, 'Requires a running CouchDB server')
class TestCouchDbStore(TestStoreWithDb, unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        cls.store = cls.create_store(cls.cfg.couchdb_server)

    @classmethod
    def tearDownClass(cls):
        return cls.dropdbs()

    def test_store(self):
        store = self.store
        self.assertEqual(store.name, 'couchdb')
        self.assertEqual(store.scheme[:4], 'http')
        client = self.store.client()
        self.assertEqual(client.store, store)

    def test_admin(self):
        result = yield self.store.info()
        self.assertTrue('version' in result)
        self.assertEqual(result['couchdb'], 'Welcome')

    def test_createdb(self):
        result = yield self.createdb('a')
        self.assertTrue(result['ok'])

    def test_createdb_illegal(self):
        store = self.store
        yield self.async.assertRaises(CouchDbError,
                                      store.create_database, 'bla.foo')

    def test_delete_non_existent_db(self):
        store = self.store
        name = ('r%s' % random_string()).lower()
        yield self.async.assertRaises(CouchDbError,
                                      store.delete_database, name)

    def test_databases(self):
        client = self.store.client()
        dbs = yield client.databases()
        self.assertTrue(dbs)
        self.assertTrue('_users' in dbs)

    def test_users(self):
        client = self.store.client()
        users = yield client.users()
        self.assertTrue(users)
        # self.assertTrue('_users' in dbs)

    # DOCUMENTS
    def test_get_invalid_document(self):
        client = self.store.client()
        yield self.async.assertRaises(CouchDbNoDbError,
                                      client.get, 'bla', '234234')

    def test_create_document(self):
        client = self.store.client()
        result = yield self.createdb('test1')
        self.assertTrue(result['ok'])
        result = yield client.post(self.name('test1'),
                                   {'title': 'Hello World',
                                    'author': 'lsbardel'})
        self.assertTrue(result['ok'])
        id = result['id']
        doc = yield client.get(self.name('test1'), result['id'])
        data = doc['data']
        self.assertEqual(data['author'], 'lsbardel')
        self.assertEqual(data['title'], 'Hello World')

    def test_sync_store(self):
        loop = new_event_loop()
        store = self.create_store(self.cfg.couchdb_server, loop=loop)
        self.assertEqual(store._loop, loop)
        self.assertEqual(store._http._loop, loop)
        result = store.ping()
        self.assertTrue('version' in result)
        self.assertEqual(result['couchdb'], 'Welcome')

########NEW FILE########
__FILENAME__ = basicwords
basic_english_words = 'a,able,about,account,acid,across,act,addition,\
adjustment,advertisement,after,again,against,agreement,air,all,almost,\
among,amount,amusement,and,angle,angry,animal,answer,ant,any,apparatus,\
apple,approval,arch,argument,arm,army,art,as,at,attack,attempt,attention,\
attraction,authority,automatic,awake,baby,back,bad,bag,balance,ball,band,\
base,basin,basket,bath,be,beautiful,because,bed,bee,before,behaviour,\
belief,bell,bent,berry,between,bird,birth,bit,bite,bitter,black,blade,\
blood,blow,blue,board,boat,body,boiling,bone,book,boot,bottle,box,boy,brain,\
brake,branch,brass,bread,breath,brick,bridge,bright,broken,brother,brown,\
brush,bucket,building,bulb,burn,burst,business,but,butter,button,by,cake,\
camera,canvas,card,care,carriage,cart,cat,cause,certain,chain,chalk,chance,\
change,cheap,cheese,chemical,chest,chief,chin,church,circle,clean,clear,\
clock,cloth,cloud,coal,coat,cold,collar,colour,comb,come,comfort,committee,\
common,company,comparison,competition,complete,complex,condition,connection,\
conscious,control,cook,copper,copy,cord,cork,cotton,cough,country,cover,cow,\
crack,credit,crime,cruel,crush,cry,cup,cup,current,curtain,curve,cushion,\
damage,\
danger,dark,daughter,day,dead,dear,death,debt,decision,deep,degree,delicate,\
dependent,design,desire,destruction,detail,development,different,digestion,\
direction,dirty,discovery,discussion,disease,disgust,distance,distribution,\
division,do,dog,door,doubt,down,drain,drawer,dress,drink,driving,drop,dry,\
dust,ear,early,earth,east,edge,education,effect,egg,elastic,electric,end,\
engine,enough,equal,error,even,event,ever,every,example,exchange,existence,\
expansion,experience,expert,eye,face,fact,fall,false,family,far,farm,fat,\
father,fear,feather,feeble,feeling,female,fertile,fiction,field,fight,finger,\
fire,first,fish,fixed,flag,flame,flat,flight,floor,flower,fly,fold,food,\
foolish,\
foot,for,force,fork,form,forward,fowl,frame,free,frequent,friend,from,front,\
fruit,\
full,future,garden,general,get,girl,give,glass,glove,go,goat,gold,good,\
government,grain,grass,great,green,grey,grip,group,growth,guide,gun,hair,\
hammer,hand,hanging,happy,harbour,hard,harmony,hat,hate,have,he,head,healthy,\
hear,hearing,heart,heat,help,high,history,hole,hollow,hook,hope,horn,horse,\
hospital,hour,house,how,humour,I,ice,idea,if,ill,important,impulse,in,\
increase,\
industry,ink,insect,instrument,insurance,interest,invention,iron,island,jelly,\
jewel,join,journey,judge,jump,keep,kettle,key,kick,kind,kiss,knee,knife,knot,\
knowledge,land,language,last,late,laugh,law,lead,leaf,learning,leather,left,\
leg,let,letter,level,library,lift,light,like,limit,line,linen,lip,liquid,list,\
little,living,lock,long,look,loose,loss,loud,love,low,machine,make,male,man,\
manager,map,mark,market,married,mass,match,material,may,meal,measure,meat,\
medical,meeting,memory,metal,middle,military,milk,mind,mine,minute,mist,\
mixed,money,monkey,month,moon,morning,mother,motion,mountain,mouth,move,much,\
muscle,music,nail,name,narrow,nation,natural,near,necessary,neck,need,needle,\
nerve,net,new,news,night,no,noise,normal,north,nose,not,note,now,number,nut,\
observation,of,off,offer,office,oil,old,on,only,open,operation,opinion,\
opposite,or,orange,order,organization,ornament,other,out,oven,over,owner,\
page,pain,paint,paper,parallel,parcel,part,past,paste,payment,peace,pen,\
pencil,person,physical,picture,pig,pin,pipe,place,plane,plant,plate,play,\
please,pleasure,plough,pocket,point,poison,polish,political,poor,porter,\
position,possible,pot,potato,powder,power,present,price,print,prison,private,\
probable,process,produce,profit,property,prose,protest,public,pull,pump,\
punishment,purpose,push,put,quality,question,quick,quiet,quite,rail,rain,\
range,rat,rate,ray,reaction,reading,ready,reason,receipt,record,red,regret,\
regular,relation,religion,representative,request,respect,responsible,rest,\
reward,rhythm,rice,right,ring,river,road,rod,roll,roof,room,root,rough,\
round,rub,rule,run,sad,safe,sail,salt,same,sand,say,scale,school,science,\
scissors,screw,sea,seat,second,secret,secretary,see,seed,seem,selection,self,\
send,sense,separate,serious,servant,sex,shade,shake,shame,sharp,sheep,shelf,\
ship,shirt,shock,shoe,short,shut,side,sign,silk,silver,simple,sister,size,\
skin,,skirt,sky,sleep,slip,slope,slow,small,smash,smell,smile,smoke,smooth,\
snake,sneeze,snow,so,soap,society,sock,soft,solid,some,,son,song,sort,sound,\
soup,south,space,spade,special,sponge,spoon,spring,square,stage,stamp,star,\
start,statement,station,steam,steel,stem,step,stick,sticky,stiff,still,\
stitch,stocking,stomach,stone,stop,store,story,straight,strange,street,\
stretch,strong,structure,substance,such,sudden,sugar,suggestion,summer,sun,\
support,surprise,sweet,swim,system,table,tail,take,talk,tall,taste,tax,\
teaching,tendency,test,than,that,the,then,theory,there,thick,thin,thing,\
this,thought,thread,throat,through,through,thumb,thunder,ticket,tight,till,\
time,tin,tired,to,toe,together,tomorrow,tongue,tooth,top,touch,town,trade,\
train,transport,tray,tree,trick,trouble,trousers,true,turn,twist,umbrella,\
under,unit,up,use,value,verse,very,vessel,view,violent,voice,waiting,walk,\
wall,war,warm,wash,waste,watch,water,wave,wax,way,weather,week,weight,well,\
west,wet,wheel,when,where,while,whip,whistle,white,who,why,wide,will,wind,\
window,wine,wing,winter,wire,wise,with,woman,wood,wool,word,work,worm,wound,\
writing,wrong,year,yellow,yes,yesterday,you,young'.split(',')

########NEW FILE########
__FILENAME__ = couchdb
import unittest

from . import Odm
from ..couchdb import CouchDbTest


class TestCouchdbODM(CouchDbTest, Odm, unittest.TestCase):
    pass

########NEW FILE########
__FILENAME__ = mongodb
import unittest

from pulsar import new_event_loop, data_stores

from . import Odm


@unittest.skipUnless('mongodb' in data_stores,
                     'Requires pymong and a running mongodb')
class TestMongodbODM(Odm, unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        addr = 'redis://%s' % cls.cfg.mongodb_server
        cls.store = cls.create_store(addr)
        cls.sync_store = cls.create_store(addr, loop=new_event_loop())

########NEW FILE########
__FILENAME__ = pulsards
import unittest

from . import Odm
from ..testmodels import User
from ..pulsards import StoreMixin


class TestPulsardsODM(StoreMixin, Odm, unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        return cls.create_pulsar_store()

########NEW FILE########
__FILENAME__ = redis
from pulsar import new_event_loop

from .pulsards import unittest, StoreMixin, Odm


class TestRedisODM(StoreMixin, Odm, unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        addr = 'redis://%s' % cls.cfg.redis_server
        cls.store = cls.create_store(addr)
        cls.sync_store = cls.create_store(addr, loop=new_event_loop())

########NEW FILE########
__FILENAME__ = parser
from random import randint
import unittest

import pulsar
from pulsar.apps.ds import (redis_parser, ResponseError, NoScriptError,
                            InvalidResponse)


def lua_nested_table(nesting, s=100):
    s = b''.join((b'1234567890' for n in range(s)))
    pres = [100, s]
    result = pres
    for i in range(nesting):
        res = [-8, s, None]
        # dres = {1: 'valid', 'bla': 6}
        dres = 1
        pres.extend((res, res, dres))
        pres = res
    return result


class TestParser(unittest.TestCase):

    def parser(self):
        return redis_parser()()

    #    DECODER
    def test_null(self):
        test = b'$-1\r\n'
        p = self.parser()
        p.feed(test)
        self.assertEqual(p.get(), None)

    def test_empty_string(self):
        test = b'$0\r\n\r\n'
        p = self.parser()
        p.feed(test)
        self.assertEqual(p.get(), b'')
        self.assertEqual(p.buffer(), b'')

    def test_empty_vector(self):
        test = b'*0\r\n'
        p = self.parser()
        p.feed(test)
        self.assertEqual(p.get(), [])
        self.assertEqual(p.buffer(), b'')

    def test_parseError(self):
        test = b'pxxxx\r\n'
        p = self.parser()
        p.feed(test)
        self.assertRaises(InvalidResponse, p.get)

    def test_responseError(self):
        test = b'-ERR random error\r\n'
        p = self.parser()
        p.feed(test)
        value = p.get()
        self.assertIsInstance(value, ResponseError)
        self.assertEqual(str(value), 'random error')

    def test_noscriptError(self):
        test = b'-NOSCRIPT random error\r\n'
        p = self.parser()
        p.feed(test)
        value = p.get()
        self.assertIsInstance(value, NoScriptError)
        self.assertEqual(str(value), 'random error')

    def test_binary(self):
        test = (b'$31\r\n\x80\x02]q\x00(X\x04\x00\x00\x00ciaoq\x01X\x05\x00'
                b'\x00\x00pippoq\x02e.\r\n')
        p = self.parser()
        p.feed(test)
        self.assertEqual(p.buffer(), test)
        value = p.get()
        self.assertTrue(value)
        self.assertEqual(p.buffer(), b'')

    def test_multi(self):
        test = (b'+OK\r\n+QUEUED\r\n+QUEUED\r\n+QUEUED\r\n*3\r\n$-1\r\n:1'
                b'\r\n:39\r\n')
        p = self.parser()
        p.feed(test)
        self.assertEqual(p.get(), b'OK')
        self.assertEqual(p.get(), b'QUEUED')
        self.assertEqual(p.get(), b'QUEUED')
        self.assertEqual(p.get(), b'QUEUED')
        self.assertEqual(p.get(), [None, 1, 39])

    def test_nested(self):
        p = self.parser()
        result = lua_nested_table(2)
        chunk = p.multi_bulk(result)
        p.feed(chunk)
        res2 = p.get()
        self.assertEqual(len(res2), len(result))
        self.assertEqual(res2[0], b'100')
        self.assertEqual(res2[1], result[1])

    def test_nested_bug_fixer(self):
        p = self.parser()
        result = [b'100',
                  b'1234567890',
                  [b'-8', b'1234567890', None],
                  [b'-8', b'1234567890', None],
                  b'1']
        data = p.multi_bulk(result)
        chunks = [b'*5\r\n$3\r\n100',
                  b'\r\n$10\r\n12345',
                  b'67890\r\n*3',
                  b'\r\n$2\r',
                  b'\n-8\r\n$10\r',
                  b'\n1234567890\r\n$-1\r\n',
                  b'*3\r\n$2\r\n-8\r\n$10\r\n1234567890\r\n$-1\r\n$1\r\n1\r\n']
        self.assertEqual(data, b''.join(chunks))
        for chunk in chunks[:-1]:
            p.feed(chunk)
            self.assertEqual(p.get(), False)
        p.feed(chunks[-1])
        self.assertEqual(p.get(), result)

    def test_nested_a_drop_at_a_time(self):
        p = self.parser()
        result = lua_nested_table(3)
        data = p.multi_bulk(result)
        while data:
            self.assertEqual(p.get(), False)
            i = randint(1, 30)
            chunk, data = data[:i], data[i:]
            p.feed(chunk)
        res2 = p.get()
        self.assertEqual(len(res2), len(result))
        self.assertEqual(res2[0], b'100')
        self.assertEqual(res2[1], result[1])

    # CLIENT ENCODERS
    def test_encode_commands(self):
        p = self.parser()
        chunk = p.pack_command(['whatever', None])
        self.assertEqual(chunk, b'*2\r\n$8\r\nwhatever\r\n$4\r\nNone\r\n')

    # SERVER ENCODERS

    def test_encode_empty_string(self):
        p = self.parser()
        chunk = p.bulk(None)
        self.assertEqual(chunk, b'$-1\r\n')

    def test_encode_multi_bulk(self):
        p = self.parser()
        self.assertEqual(p.multi_bulk([]), b'*0\r\n')
        self.assertEqual(p.multi_bulk(()), b'*0\r\n')


@unittest.skipUnless(pulsar.HAS_C_EXTENSIONS, 'Requires C extensions')
class TestPythonParser(TestParser):

    def parser(self):
        return redis_parser(True)()

########NEW FILE########
__FILENAME__ = pulsards
import binascii
import time
import unittest
from asyncio import Queue

import pulsar
from pulsar import new_event_loop
from pulsar.utils.security import random_string
from pulsar.utils.structures import Zset
from pulsar.apps.ds import PulsarDS, redis_parser, ResponseError
from pulsar.apps.data import create_store


class Listener:

    def __init__(self):
        self._messages = Queue()

    def __call__(self, channel, message):
        self._messages.put_nowait((channel, message))

    def get(self):
        return self._messages.get()


class StringProtocol:

    def encode(self, message):
        return message

    def decode(self, message):
        return message.decode('utf-8')


class StoreMixin(object):
    client = None
    pulsar_app_cfg = None
    redis_py_parser = False

    @classmethod
    def create_store(cls, address, namespace=None, pool_size=2, **kw):
        if cls.redis_py_parser:
            kw['parser_class'] = redis_parser(True)
        if not namespace:
            namespace = cls.randomkey(6).lower()
        return create_store(address, namespace=namespace,
                            pool_size=pool_size, **kw)

    @classmethod
    def randomkey(cls, length=None):
        return random_string(length=length)

    @classmethod
    def create_pulsar_store(cls):
        server = PulsarDS(name=cls.__name__.lower(),
                          bind='127.0.0.1:0',
                          concurrency=cls.cfg.concurrency,
                          redis_py_parser=cls.redis_py_parser)
        cls.pulsar_app_cfg = yield pulsar.send('arbiter', 'run', server)
        cls.pulsards_uri = 'pulsar://%s:%s' % cls.pulsar_app_cfg.addresses[0]
        cls.store = cls.create_store('%s/9' % cls.pulsards_uri)

    @classmethod
    def tearDownClass(cls):
        if cls.pulsar_app_cfg is not None:
            yield pulsar.send('arbiter', 'kill_actor', cls.pulsar_app_cfg.name)

    def _remove_and_push(self, key, rem=1):
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.delete(key), rem)
        yield eq(c.rpush(key, 'bla'), 1)

    def _remove_and_sadd(self, key, rem=1):
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.delete(key), rem)
        yield eq(c.sadd(key, 'bla'), 1)


class RedisCommands(StoreMixin):

    def test_store(self):
        store = self.store
        self.assertEqual(len(store.namespace), 7)

    ###########################################################################
    #    KEYS
    def test_dump_restore(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.dump(key), None)
        yield eq(c.set(key, 'hello'), True)
        value = yield c.dump(key)
        self.assertTrue(value)
        yield self.async.assertRaises(ResponseError, c.restore, key, 0, 'bla')
        yield eq(c.restore(key+'2', 0, value), True)
        yield eq(c.get(key+'2'), b'hello')

    def test_exists(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.exists(key), False)
        yield eq(c.set(key, 'hello'), True)
        yield eq(c.exists(key), True)
        yield eq(c.delete(key), 1)

    def test_expire_persist_ttl(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield self.async.assertRaises(ResponseError, c.expire, key, 'bla')
        yield eq(c.expire(key, 1), False)
        yield eq(c.set(key, 1), True)
        yield eq(c.expire(key, 10), True)
        ttl = yield c.ttl(key)
        self.assertTrue(ttl > 0 and ttl <= 10)
        yield eq(c.persist(key), True)
        yield eq(c.ttl(key), -1)
        yield eq(c.persist(key), False)

    def test_expireat(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield self.async.assertRaises(ResponseError, c.expireat, key, 'bla')
        t = int(time.time() + 3)
        yield eq(c.expireat(key, t), False)
        yield eq(c.set(key, 1), True)
        t = int(time.time() + 10)
        yield eq(c.expireat(key, t), True)
        ttl = yield c.ttl(key)
        self.assertTrue(ttl > 0 and ttl <= 10)
        yield eq(c.persist(key), True)
        yield eq(c.ttl(key), -1)
        yield eq(c.persist(key), False)

    def test_keys(self):
        key = self.randomkey()
        keya = '%s_a' % key
        keyb = '%s_a' % key
        keyc = '%sc' % key
        c = self.client
        eq = self.async.assertEqual
        keys_with_underscores = set([keya.encode('utf-8'),
                                     keyb.encode('utf-8')])
        keys = keys_with_underscores.union(set([keyc.encode('utf-8')]))
        yield eq(c.mset(keya, 1, keyb, 2, keyc, 3), True)
        k1 = yield c.keys('%s_*' % key)
        k2 = yield c.keys('%s*' % key)
        self.assertEqual(set(k1), keys_with_underscores)
        self.assertEqual(set(k2), keys)

    def test_move(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        db = 3 if c.store.database == 4 else 4
        yield eq(c.move(key, 'bla'), False)
        yield eq(c.move(key, db), False)
        yield eq(c.set(key, 'ciao'), True)
        yield eq(c.move(key, db), True)
        s2 = self.create_store(self.store.dns, database=db)
        c2 = s2.client()
        yield eq(c2.get(key), b'ciao')
        yield eq(c.exists(key), False)
        yield eq(c.set(key, 'foo'), True)
        yield eq(c.move(key, db), False)
        yield eq(c.exists(key), True)

    def test_randomkey(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.mset(key, 1, key+'a', 2, key+'b', 3), True)
        key = yield c.randomkey()
        yield eq(c.exists(key), True)

    def test_rename_renamenx(self):
        key = self.randomkey()
        des = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield self.async.assertRaises(ResponseError, c.rename, key, des)
        yield eq(c.set(key, 'hello'), True)
        yield self.async.assertRaises(ResponseError, c.rename, key, key)
        yield eq(c.rename(key, des), True)
        yield eq(c.exists(key), False)
        yield eq(c.get(des), b'hello')
        yield eq(c.set(key, 'ciao'), True)
        yield eq(c.renamenx(key, des), False)
        yield eq(c.renamenx(key, des+'a'), True)
        yield eq(c.exists(key), False)

    def test_watch(self):
        key1 = self.randomkey()
        key2 = key1 + '2'
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.watch(key1, key2), True)
        yield eq(c.unwatch(), True)

    ###########################################################################
    #    BAD REQUESTS
    # def test_no_command(self):
    #     yield self.async.assertRaises(ResponseError, self.store.execute)

    # def test_bad_command(self):
    #     yield self.async.assertRaises(ResponseError, self.store.execute,
    #                                   'foo')
    ###########################################################################
    #    STRINGS
    def test_append(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.append(key, 'a1'), 2)
        yield eq(c.get(key), b'a1')
        yield eq(c.append(key, 'a2'), 4)
        yield eq(c.get(key), b'a1a2')
        yield self._remove_and_push(key)
        yield self.async.assertRaises(ResponseError, c.append, key, 'g')

    def test_bitcount(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.bitcount(key), 0)
        yield eq(c.setbit(key, 5, 1), 0)
        yield eq(c.bitcount(key), 1)
        yield eq(c.setbit(key, 6, 1), 0)
        yield eq(c.bitcount(key), 2)
        yield eq(c.setbit(key, 5, 0), 1)
        yield eq(c.bitcount(key), 1)
        yield eq(c.setbit(key, 9, 1), 0)
        yield eq(c.setbit(key, 17, 1), 0)
        yield eq(c.setbit(key, 25, 1), 0)
        yield eq(c.setbit(key, 33, 1), 0)
        yield eq(c.bitcount(key), 5)
        yield eq(c.bitcount(key, 0, -1), 5)
        yield eq(c.bitcount(key, 2, 3), 2)
        yield eq(c.bitcount(key, 2, -1), 3)
        yield eq(c.bitcount(key, -2, -1), 2)
        yield eq(c.bitcount(key, 1, 1), 1)
        yield self._remove_and_push(key)
        yield self.async.assertRaises(ResponseError, c.bitcount, key)

    def test_bitop_not_empty_string(self):
        key = self.randomkey()
        des = key + 'd'
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.set(key, ''), True)
        yield eq(c.bitop('not', des, key), 0)
        yield eq(c.get(des), None)

    def test_bitop_not(self):
        key = self.randomkey()
        des = key + 'd'
        c = self.client
        eq = self.async.assertEqual
        test_str = b'\xAA\x00\xFF\x55'
        correct = ~0xAA00FF55 & 0xFFFFFFFF
        yield eq(c.set(key, test_str), True)
        yield eq(c.bitop('not', des, key), 4)
        result = yield c.get(des)
        self.assertEqual(int(binascii.hexlify(result), 16), correct)

    def test_bitop_not_in_place(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        test_str = b'\xAA\x00\xFF\x55'
        correct = ~0xAA00FF55 & 0xFFFFFFFF
        yield eq(c.set(key, test_str), True)
        yield eq(c.bitop('not', key, key), 4)
        result = yield c.get(key)
        assert int(binascii.hexlify(result), 16) == correct

    def test_bitop_single_string(self):
        key = self.randomkey()
        des = key + 'd'
        c = self.client
        eq = self.async.assertEqual
        test_str = b'\x01\x02\xFF'
        yield eq(c.set(key, test_str), True)
        yield eq(c.bitop('and', key+'1', key), 3)
        yield eq(c.bitop('or', key+'2', key), 3)
        yield eq(c.bitop('xor', key+'3', key), 3)
        yield eq(c.get(key + '1'), test_str)
        yield eq(c.get(key + '2'), test_str)
        yield eq(c.get(key + '3'), test_str)

    def test_bitop_string_operands(self):
        c = self.client
        eq = self.async.assertEqual
        key1 = self.randomkey()
        key2 = key1 + '2'
        des1 = key1 + 'd1'
        des2 = key1 + 'd2'
        des3 = key1 + 'd3'
        yield eq(c.set(key1, b'\x01\x02\xFF\xFF'), True)
        yield eq(c.set(key2, b'\x01\x02\xFF'), True)
        yield eq(c.bitop('and', des1, key1, key2), 4)
        yield eq(c.bitop('or', des2, key1, key2), 4)
        yield eq(c.bitop('xor', des3, key1, key2), 4)
        res1 = yield c.get(des1)
        res2 = yield c.get(des2)
        res3 = yield c.get(des3)
        self.assertEqual(int(binascii.hexlify(res1), 16), 0x0102FF00)
        self.assertEqual(int(binascii.hexlify(res2), 16), 0x0102FFFF)
        self.assertEqual(int(binascii.hexlify(res3), 16), 0x000000FF)

    def test_getbit(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.getbit(key, 5), 0)
        yield eq(c.setbit(key, 5, 1), 0)
        yield eq(c.getbit(key, 5), 1)
        yield self.async.assertRaises(ResponseError, c.getbit, key, -1)
        yield eq(c.getbit(key, 4), 0)
        yield eq(c.setbit(key, 4, 1), 0)
        # set bit 4
        yield eq(c.getbit(key, 4), 1)
        yield eq(c.getbit(key, 5), 1)
        # set bit 5 again
        yield eq(c.setbit(key, 5, 1), 1)
        yield eq(c.getbit(key, 5), 1)
        #
        yield eq(c.getbit(key, 30), 0)
        #
        yield self._remove_and_push(key)
        yield self.async.assertRaises(ResponseError, c.getbit, key, 1)

    def test_getrange(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.getrange(key, 0, 0), b'')
        yield eq(c.set(key, 'Hello there'), True)
        yield eq(c.getrange(key, 0, 0), b'H')
        yield eq(c.getrange(key, 0, 4), b'Hello')
        yield eq(c.getrange(key, 5, 5), b' ')
        yield eq(c.getrange(key, 20, 25), b'')
        yield eq(c.getrange(key, -5, -1), b'there')
        yield self.async.assertRaises(ResponseError, c.getrange, key, 1, 'b')
        yield self._remove_and_push(key)
        yield self.async.assertRaises(ResponseError, c.getrange, key, 1, 2)

    def test_decr(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.decr(key), -1)
        yield eq(c.get(key), b'-1')
        yield eq(c.decr(key), -2)
        yield eq(c.get(key), b'-2')
        yield eq(c.decr(key, 5), -7)
        yield eq(c.get(key), b'-7')

    def test_incr(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.incr(key), 1)
        yield eq(c.get(key), b'1')
        yield eq(c.incr(key), 2)
        yield eq(c.get(key), b'2')
        yield eq(c.incr(key, 5), 7)
        yield eq(c.get(key), b'7')

    def test_get(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield c.set(key, 'foo')
        yield eq(c.get(key), b'foo')
        yield eq(c.get('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'), None)

    def test_mget(self):
        key1 = self.randomkey()
        key2 = key1 + 'x'
        key3 = key2 + 'y'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.set(key1, 'foox'), True)
        yield eq(c.set(key2, 'fooxx'), True)
        yield eq(c.mget(key1, key2, key3), [b'foox', b'fooxx', None])

    ###########################################################################
    #    HASHES
    def test_hdel(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.hdel(key, 'f1', 'f2', 'gh'), 0)
        yield eq(c.hmset(key, {'f1': 1, 'f2': 'hello', 'f3': 'foo'}), True)
        yield eq(c.hdel(key, 'f1', 'f2', 'gh'), 2)
        yield eq(c.hdel(key, 'fgf'), 0)
        yield eq(c.type(key), 'hash')
        yield eq(c.hdel(key, 'f3'), 1)
        yield eq(c.type(key), 'none')
        yield self._remove_and_push(key, 0)
        yield self.async.assertRaises(ResponseError, c.hdel, key, 'foo')

    def test_hexists(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.hexists(key, 'foo'), False)
        yield eq(c.hmset(key, {'f1': 1, 'f2': 'hello', 'f3': 'foo'}), True)
        yield eq(c.hexists(key, 'f3'), True)
        yield eq(c.hexists(key, 'f5'), False)
        yield self._remove_and_push(key)
        yield self.async.assertRaises(ResponseError, c.hexists, key, 'foo')

    def test_hset_hget(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.hget(key, 'foo'), None)
        yield eq(c.hset(key, 'foo', 4), 1)
        yield eq(c.hget(key, 'foo'), b'4')
        yield eq(c.hset(key, 'foo', 6), 0)
        yield eq(c.hget(key, 'foo'), b'6')
        yield self._remove_and_push(key)
        yield self.async.assertRaises(ResponseError, c.hset, key, 'foo', 7)
        yield self.async.assertRaises(ResponseError, c.hget, key, 'foo')
        yield self.async.assertRaises(ResponseError, c.hmset, key, 'foo')

    def test_hgetall(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        h = {b'f1': b'1', b'f2': b'hello', b'f3': b'foo'}
        yield eq(c.hgetall(key), {})
        yield eq(c.hmset(key, h), True)
        yield eq(c.hgetall(key), h)
        yield self._remove_and_push(key)
        yield self.async.assertRaises(ResponseError, c.hgetall, key)

    def test_hincrby(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.hincrby(key, 'foo', 1), 1)
        yield eq(c.hincrby(key, 'foo', 2), 3)
        yield eq(c.hincrby(key, 'foo', -1), 2)
        yield self._remove_and_push(key)
        yield self.async.assertRaises(ResponseError, c.hincrby, key, 'foo', 3)

    def test_hincrbyfloat(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.hincrbyfloat(key, 'foo', 1), 1.0)
        yield eq(c.hincrbyfloat(key, 'foo', 2.5), 3.5)
        yield eq(c.hincrbyfloat(key, 'foo', -1.1), 2.4)
        yield self._remove_and_push(key)

    def test_hkeys_hvals_hlen_hmget(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        h = {b'f1': b'1', b'f2': b'hello', b'f3': b'foo'}
        yield eq(c.hkeys(key), [])
        yield eq(c.hvals(key), [])
        yield eq(c.hlen(key), 0)
        yield eq(c.hmset(key, h), True)
        keys = yield c.hkeys(key)
        vals = yield c.hvals(key)
        self.assertEqual(sorted(keys), sorted(h))
        self.assertEqual(sorted(vals), sorted(h.values()))
        yield eq(c.hlen(key), 3)
        yield eq(c.hmget(key, 'f1', 'f3', 'hj'),
                 {'f1': b'1', 'f3': b'foo', 'hj': None})
        yield self._remove_and_push(key)
        yield self.async.assertRaises(ResponseError, c.hkeys, key)
        yield self.async.assertRaises(ResponseError, c.hvals, key)
        yield self.async.assertRaises(ResponseError, c.hlen, key)
        yield self.async.assertRaises(ResponseError, c.hmget, key, 'f1', 'f2')

    def test_hsetnx(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.hsetnx(key, 'a', 'foo'), 1)
        yield eq(c.hget(key, 'a'), b'foo')
        yield eq(c.hsetnx(key, 'a', 'bla'), 0)
        yield eq(c.hget(key, 'a'), b'foo')
        yield self._remove_and_push(key)
        yield self.async.assertRaises(ResponseError, c.hsetnx, key, 'a', 'jk')

    ###########################################################################
    #    LISTS
    def test_blpop(self):
        key1 = self.randomkey()
        key2 = key1 + 'x'
        bk1 = key1.encode('utf-8')
        bk2 = key2.encode('utf-8')
        eq = self.async.assertEqual
        c = self.client
        yield self.async.assertRaises(ResponseError, c.blpop, key1, 'bla')
        yield eq(c.rpush(key1, 1, 2), 2)
        yield eq(c.rpush(key2, 3, 4), 2)
        yield eq(c.blpop((key2, key1), 1), (bk2, b'3'))
        yield eq(c.blpop((key2, key1), 1), (bk2, b'4'))
        yield eq(c.blpop((key2, key1), 1), (bk1, b'1'))
        yield eq(c.blpop((key2, key1), 1), (bk1, b'2'))
        yield eq(c.blpop((key2, key1), 1), None)
        yield eq(c.rpush(key1, '1'), 1)
        yield eq(c.blpop(key1, 1), (bk1, b'1'))

    def test_brpop(self):
        key1 = self.randomkey()
        key2 = key1 + 'x'
        bk1 = key1.encode('utf-8')
        bk2 = key2.encode('utf-8')
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.rpush(key1, 1, 2), 2)
        yield eq(c.rpush(key2, 3, 4), 2)
        yield eq(c.brpop((key2, key1), 1), (bk2, b'4'))
        yield eq(c.brpop((key2, key1), 1), (bk2, b'3'))
        yield eq(c.brpop((key2, key1), 1), (bk1, b'2'))
        yield eq(c.brpop((key2, key1), 1), (bk1, b'1'))
        yield eq(c.brpop((key2, key1), 1), None)
        yield eq(c.rpush(key1, '1'), 1)
        yield eq(c.brpop(key1, 1), (bk1, b'1'))

    def test_lindex_llen(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.lindex(key, '0'), None)
        yield eq(c.llen(key), 0)
        yield eq(c.rpush(key, '1', '2', '3'), 3)
        yield eq(c.lindex(key, '0'), b'1')
        yield eq(c.lindex(key, '1'), b'2')
        yield eq(c.lindex(key, '2'), b'3')
        yield eq(c.lindex(key, '3'), None)
        yield eq(c.llen(key), 3)
        yield self._remove_and_sadd(key)
        yield self.async.assertRaises(ResponseError, c.lindex, key, '1')
        yield self.async.assertRaises(ResponseError, c.llen, key)

    def test_linsert(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield eq(c.linsert(key, 'after', '2', '2.5'), 0)
        yield eq(c.rpush(key, '1', '2', '3'), 3)
        yield eq(c.linsert(key, 'after', '2', '2.5'), 4)
        yield eq(c.lrange(key, 0, -1), [b'1', b'2', b'2.5', b'3'])
        yield eq(c.linsert(key, 'before', '2', '1.5'), 5)
        yield eq(c.lrange(key, 0, -1), [b'1', b'1.5', b'2', b'2.5', b'3'])
        yield eq(c.linsert(key, 'before', '100', '1.5'), -1)
        yield self.async.assertRaises(ResponseError, c.linsert, key,
                                      'banana', '2', '2.5')
        yield self._remove_and_sadd(key)
        yield self.async.assertRaises(ResponseError, c.linsert, key,
                                      'after', '2', '2.5')

    def test_lpop(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.lpop(key), None)
        yield eq(c.rpush(key, 1, 2), 2)
        yield eq(c.lpop(key), b'1')
        yield eq(c.lpop(key), b'2')
        yield eq(c.lpop(key), None)
        yield eq(c.type(key), 'none')
        yield self._remove_and_sadd(key, 0)
        yield self.async.assertRaises(ResponseError, c.lpop, key)
        yield self.async.assertRaises(ResponseError, c.lpush, key, 4)

    def test_rpop(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.rpop(key), None)
        yield eq(c.rpush(key, 1, 2), 2)
        yield eq(c.rpop(key), b'2')
        yield eq(c.rpop(key), b'1')
        yield eq(c.rpop(key), None)
        yield eq(c.type(key), 'none')

    def test_lpushx_rpushx(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.lpushx(key, 'b'), 0)
        yield eq(c.rpushx(key, 'b'), 0)
        yield eq(c.lrange(key, 0, -1), [])
        yield eq(c.lpush(key, 'a'), 1)
        yield eq(c.lpushx(key, 'b'), 2)
        yield eq(c.rpushx(key, 'c'), 3)
        yield eq(c.lrange(key, 0, -1), [b'b', b'a', b'c'])
        yield self._remove_and_sadd(key)
        yield self.async.assertRaises(ResponseError, c.lpushx, key, 'g')

    def test_lrem(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.lrem(key, 1, 'a'), 0)
        yield eq(c.rpush(key, 'a', 'a', 'a', 'b', 'a', 'a'), 6)
        yield eq(c.lrem(key, 1, 'a'), 1)
        yield eq(c.lrange(key, 0, -1), [b'a', b'a', b'b', b'a', b'a'])
        yield eq(c.lrem(key, -1, 'a'), 1)
        yield eq(c.lrange(key, 0, -1), [b'a', b'a', b'b', b'a'])
        yield eq(c.lrem(key, 0, 'a'), 3)
        yield self.async.assertRaises(ResponseError, c.lrem, key, 'g', 'foo')
        yield eq(c.lrange(key, 0, -1), [b'b'])
        yield eq(c.lrem(key, 0, 'b'), 1)
        yield self._remove_and_sadd(key, 0)
        yield self.async.assertRaises(ResponseError, c.lrem, key, 1)

    ###########################################################################
    #    SORT
    def test_sort_basic(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield c.rpush(key, '3', '2', '1', '4')
        yield self.async.assertEqual(c.sort(key), [b'1', b'2', b'3', b'4'])

    def test_sort_limited(self):
        key = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        yield c.rpush(key, '3', '2', '1', '4')
        yield self.async.assertEqual(c.sort(key, start=1, num=2), [b'2', b'3'])

    def test_sort_by(self):
        key = self.randomkey()
        key2 = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        pipe = c.pipeline()
        pipe.mset('%s:1' % key, 8,
                  '%s:2' % key, 3,
                  '%s:3' % key, 5)
        pipe.rpush(key2, '3', '2', '1')
        res = yield pipe.commit()
        self.assertEqual(len(res), 2)
        yield eq(c.sort(key2, by='%s:*' % key), [b'2', b'3', b'1'])

    def test_sort_get(self):
        key = self.randomkey()
        key2 = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        pipe = c.pipeline()
        pipe.mset('%s:1' % key, 'u1',
                  '%s:2' % key, 'u2',
                  '%s:3' % key, 'u3')
        pipe.rpush(key2, '3', '2', '1')
        res = yield pipe.commit()
        self.assertEqual(len(res), 2)
        yield eq(c.sort(key2, get='%s:*' % key), [b'u1', b'u2', b'u3'])

    def test_sort_get_multi(self):
        key = self.randomkey()
        key2 = self.randomkey()
        c = self.client
        eq = self.async.assertEqual
        pipe = c.pipeline()
        pipe.mset('%s:1' % key, 'u1',
                  '%s:2' % key, 'u2',
                  '%s:3' % key, 'u3')
        pipe.rpush(key2, '3', '2', '1')
        res = yield pipe.commit()
        self.assertEqual(len(res), 2)
        yield eq(c.sort(key2, get=('%s:*' % key, '#')),
                 [b'u1', b'1', b'u2', b'2', b'u3', b'3'])
        yield eq(c.sort(key2, get=('%s:*' % key, '#'), groups=True),
                 [(b'u1', b'1'), (b'u2', b'2'), (b'u3', b'3')])

    ###########################################################################
    #    SETS
    def test_sadd_scard(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        members = (b'1', b'2', b'3', b'2')
        yield eq(c.sadd(key, *members), 3)
        yield eq(c.smembers(key), set(members))
        yield eq(c.scard(key), 3)

    def test_sdiff(self):
        key = self.randomkey()
        key2 = key + '2'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, 1, 2, 3), 3)
        yield eq(c.sdiff(key, key2), set((b'1', b'2', b'3')))
        yield eq(c.sadd(key2, 2, 3), 2)
        yield eq(c.sdiff(key, key2), set([b'1']))

    def test_sdiffstore(self):
        key = self.randomkey()
        key2 = key + '2'
        des = key + 'd'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, 1, 2, 3), 3)
        yield eq(c.sdiffstore(des, key, key2), 3)
        yield eq(c.smembers(des), set([b'1', b'2', b'3']))
        yield eq(c.sadd(key2, 2, 3), 2)
        yield eq(c.sdiffstore(des, key, key2), 1)
        yield eq(c.smembers(des), set([b'1']))

    def test_sinter(self):
        key = self.randomkey()
        key2 = key + '2'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, 1, 2, 3), 3)
        yield eq(c.sinter(key, key2), set())
        yield eq(c.sadd(key2, 2, 3), 2)
        yield eq(c.sinter(key, key2), set([b'2', b'3']))

    def test_sinterstore(self):
        key = self.randomkey()
        key2 = key + '2'
        des = key + 'd'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, 1, 2, 3), 3)
        yield eq(c.sinterstore(des, key, key2), 0)
        yield eq(c.smembers(des), set())
        yield eq(c.sadd(key2, 2, 3), 2)
        yield eq(c.sinterstore(des, key, key2), 2)
        yield eq(c.smembers(des), set([b'2', b'3']))

    def test_sismember(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, 1, 2, 3), 3)
        yield eq(c.sismember(key, 1), True)
        yield eq(c.sismember(key, 2), True)
        yield eq(c.sismember(key, 3), True)
        yield eq(c.sismember(key, 4), False)

    def test_smove(self):
        key = self.randomkey()
        key2 = key + '2'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.smove(key, key2, 1), False)
        yield eq(c.sadd(key, 1, 2), 2)
        yield eq(c.sadd(key2, 3, 4), 2)
        yield eq(c.smove(key, key2, 1), True)
        yield eq(c.smembers(key), set([b'2']))
        yield eq(c.smembers(key2), set([b'1', b'3', b'4']))

    def test_spop(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, 1, 2, 3), 3)
        value = yield c.spop(key)
        self.assertTrue(value in set([b'1', b'2', b'3']))
        yield eq(c.smembers(key), set([b'1', b'2', b'3']) - set([value]))

    def test_srandmember(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, 1, 2, 3), 3)
        value = yield c.srandmember(key)
        self.assertTrue(value in set((b'1', b'2', b'3')))
        yield eq(c.smembers(key), set((b'1', b'2', b'3')))

    def test_srandmember_multi_value(self):
        s = [b'1', b'2', b'3']
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, *s), 3)
        randoms = yield c.srandmember(key, 2)
        self.assertEqual(len(randoms), 2)
        self.assertEqual(set(randoms).intersection(s), set(randoms))

    def test_srem(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, 1, 2, 3, 4), 4)
        yield eq(c.srem(key, 5), 0)
        yield eq(c.srem(key, 5), 0)
        yield eq(c.srem(key, 2, 4), 2)
        yield eq(c.smembers(key), set([b'1', b'3']))

    def test_sunion(self):
        key = self.randomkey()
        key2 = key + '2'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, 1, 2, 3), 3)
        yield eq(c.sunion(key, key2), set((b'1', b'2', b'3')))
        yield eq(c.sadd(key2, 2, 3, 4), 3)
        yield eq(c.sunion(key, key2), set((b'1', b'2', b'3', b'4')))

    def test_sunionstore(self):
        key = self.randomkey()
        key2 = key + '2'
        des = key + 'd'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.sadd(key, 1, 2, 3), 3)
        yield eq(c.sunionstore(des, key, key2), 3)
        yield eq(c.smembers(des), set([b'1', b'2', b'3']))
        yield eq(c.sadd(key2, 2, 3, 4), 3)
        yield eq(c.sunionstore(des, key, key2), 4)
        yield eq(c.smembers(des), set([b'1', b'2', b'3', b'4']))

    ###########################################################################
    #    SORTED SETS
    def test_zadd_zcard(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        members = (b'1', b'2', b'3', b'2')
        yield eq(c.zadd(key, a1=1, a2=2, a3=3), 3)
        yield eq(c.zrange(key, 0, -1), [b'a1', b'a2', b'a3'])
        yield eq(c.zcard(key), 3)

    def test_zcount(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key, a1=1, a2=2, a3=3), 3)
        yield eq(c.zcount(key, '-inf', '+inf'), 3)
        yield eq(c.zcount(key, '(1', 2), 1)
        yield eq(c.zcount(key, '(1', '(3'), 1)
        yield eq(c.zcount(key, 1, 3), 3)

    def test_zincrby(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key, a1=1, a2=2, a3=3), 3)
        yield eq(c.zincrby(key, 1, 'a2'), 3.0)
        yield eq(c.zincrby(key, 5, 'a3'), 8.0)
        yield eq(c.zscore(key, 'a2'), 3.0)
        yield eq(c.zscore(key, 'a3'), 8.0)
        yield eq(c.zscore(key, 'blaaa'), None)

    def test_zinterstore_sum(self):
        des = self.randomkey()
        key1 = des + '1'
        key2 = des + '2'
        key3 = des + '3'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key1, a1=1, a2=2, a3=1), 3)
        yield eq(c.zadd(key2, a1=2, a2=2, a3=2), 3)
        yield eq(c.zadd(key3, a1=6, a3=5, a4=4), 3)
        yield eq(c.zinterstore(des, (key1, key2, key3)), 2)
        yield eq(c.zrange(des, 0, -1, withscores=True),
                 Zset(((8.0, b'a3'), (9.0, b'a1'))))

    def test_zinterstore_max(self):
        des = self.randomkey()
        key1 = des + '1'
        key2 = des + '2'
        key3 = des + '3'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key1, a1=1, a2=2, a3=1), 3)
        yield eq(c.zadd(key2, a1=2, a2=2, a3=2), 3)
        yield eq(c.zadd(key3, a1=6, a3=5, a4=4), 3)
        yield eq(c.zinterstore(des, (key1, key2, key3), aggregate='max'), 2)
        yield eq(c.zrange(des, 0, -1, withscores=True),
                 Zset(((5.0, b'a3'), (6.0, b'a1'))))

    def test_zinterstore_min(self):
        des = self.randomkey()
        key1 = des + '1'
        key2 = des + '2'
        key3 = des + '3'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key1, a1=1, a2=2, a3=1), 3)
        yield eq(c.zadd(key2, a1=2, a2=2, a3=2), 3)
        yield eq(c.zadd(key3, a1=6, a3=5, a4=4), 3)
        yield eq(c.zinterstore(des, (key1, key2, key3), aggregate='min'), 2)
        yield eq(c.zrange(des, 0, -1, withscores=True),
                 Zset(((1.0, b'a3'), (1.0, b'a1'))))

    def test_zinterstore_with_weights(self):
        des = self.randomkey()
        key1 = des + '1'
        key2 = des + '2'
        key3 = des + '3'
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key1, a1=1, a2=2, a3=1), 3)
        yield eq(c.zadd(key2, a1=2, a2=2, a3=2), 3)
        yield eq(c.zadd(key3, a1=6, a3=5, a4=4), 3)
        yield eq(c.zinterstore(des, (key1, key2, key3), weights=(1, 2, 3)), 2)
        yield eq(c.zrange(des, 0, -1, withscores=True),
                 Zset(((20.0, b'a3'), (23.0, b'a1'))))

    def test_zrange(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key, a1=1, a2=2, a3=3), 3)
        yield eq(c.zrange(key, 0, 1), [b'a1', b'a2'])
        yield eq(c.zrange(key, 1, 2), [b'a2', b'a3'])
        yield eq(c.zrange(key, 0, 1, withscores=True),
                 Zset([(1, b'a1'), (2, b'a2')]))
        yield eq(c.zrange(key, 1, 2, withscores=True),
                 Zset([(2, b'a2'), (3, b'a3')]))

    def test_zrangebyscore(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key, a1=1, a2=2, a3=3, a4=4, a5=5), 5)
        yield eq(c.zrangebyscore(key, 2, 4), [b'a2', b'a3', b'a4'])
        # slicing with start/num
        yield eq(c.zrangebyscore(key, 2, 4, offset=1, count=2),
                 [b'a3', b'a4'])
        # withscores
        yield eq(c.zrangebyscore(key, 2, 4, withscores=True),
                 Zset([(2.0, b'a2'), (3.0, b'a3'), (4.0, b'a4')]))

    def test_zrank(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key, a1=1, a2=2, a3=3, a4=4, a5=5), 5)
        yield eq(c.zrank(key, 'a1'), 0)
        yield eq(c.zrank(key, 'a2'), 1)
        yield eq(c.zrank(key, 'a6'), None)

    def test_zrem(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key, a1=1, a2=2, a3=3, a4=4, a5=5), 5)
        yield eq(c.zrem(key, 'a2'), 1)
        yield eq(c.zrange(key, 0, -1), [b'a1', b'a3', b'a4', b'a5'])
        yield eq(c.zrem(key, 'b'), 0)
        yield eq(c.zrange(key, 0, -1), [b'a1', b'a3', b'a4', b'a5'])
        yield eq(c.zrem(key, 'a3', 'a5', 'h'), 2)
        yield eq(c.zrange(key, 0, -1), [b'a1', b'a4'])
        yield eq(c.zrem(key, 'a1', 'a4'), 2)
        yield eq(c.type(key), 'none')

    def test_zremrangebyrank(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key, a1=1, a2=2, a3=3, a4=4, a5=5), 5)
        yield eq(c.zremrangebyrank(key, 1, 3), 3)
        yield eq(c.zrange(key, 0, 5), [b'a1', b'a5'])

    def test_zremrangebyscore(self):
        key = self.randomkey()
        eq = self.async.assertEqual
        c = self.client
        yield eq(c.zadd(key, a1=1, a2=2, a3=3, a4=4, a5=5), 5)
        yield eq(c.zremrangebyscore(key, 2, 4), 3)
        yield eq(c.zrange(key, 0, -1), [b'a1', b'a5'])
        yield eq(c.zremrangebyscore(key, 2, 4), 0)
        yield eq(c.zrange(key, 0, -1), [b'a1', b'a5'])

    ###########################################################################
    #    CONNECTION
    def test_ping(self):
        result = yield self.client.ping()
        self.assertTrue(result)

    def test_echo(self):
        result = yield self.client.echo('Hello')
        self.assertEqual(result, b'Hello')

    ###########################################################################
    #    SERVER
    def test_dbsize(self):
        yield self.client.set('one_at_least', 'foo')
        result = yield self.client.dbsize()
        self.assertTrue(result >= 1)

    def test_info(self):
        info = yield self.client.info()
        self.assertIsInstance(info, dict)

    def test_time(self):
        t = yield self.client.time()
        self.assertIsInstance(t, tuple)
        total = t[0] + 0.000001*t[1]

    ###########################################################################
    #    PUBSUB
    def test_handler(self):
        client = self.client
        pubsub = client.pubsub()
        self.assertEqual(client.store, pubsub.store)
        self.assertEqual(client.store._loop, pubsub._loop)
        self.assertEqual(pubsub._connection, None)

    def test_subscribe_one(self):
        key = self.randomkey()
        pubsub1 = self.client.pubsub()
        self.assertFalse(pubsub1._connection)
        # Subscribe to one channel
        yield pubsub1.subscribe(key)
        count = yield pubsub1.count(key)
        self.assertEqual(len(count), 1)
        self.assertEqual(count[key.encode('utf-8')], 1)
        #
        pubsub2 = self.client.pubsub()
        yield pubsub2.subscribe(key)
        count = yield pubsub1.count(key)
        self.assertEqual(len(count), 1)
        self.assertEqual(count[key.encode('utf-8')], 2)

    def test_subscribe_many(self):
        base = self.randomkey()
        key1 = base + '_a'
        key2 = base + '_b'
        key3 = base + '_c'
        key4 = base + 'x'
        pubsub = self.client.pubsub()
        yield pubsub.subscribe(key1, key2, key3, key4)
        channels = yield pubsub.channels(base + '_*')
        self.assertEqual(len(channels), 3)
        count = yield pubsub.count(key1, key2, key3)
        self.assertEqual(len(count), 3)
        self.assertEqual(count[key1.encode('utf-8')], 1)
        self.assertEqual(count[key2.encode('utf-8')], 1)
        self.assertEqual(count[key3.encode('utf-8')], 1)

    def test_publish(self):
        pubsub = self.client.pubsub()
        listener = Listener()
        pubsub.add_client(listener)
        yield pubsub.subscribe('chat')
        result = yield pubsub.publish('chat', 'Hello')
        self.assertTrue(result >= 0)
        channel, message = yield listener.get()
        self.assertEqual(channel, 'chat')
        self.assertEqual(message, b'Hello')

    def test_pattern_subscribe(self):
        # switched off for redis. Issue #95
        if self.store.name == 'pulsar':
            eq = self.async.assertEqual
            pubsub = self.client.pubsub(protocol=StringProtocol())
            listener = Listener()
            pubsub.add_client(listener)
            yield eq(pubsub.psubscribe('f*'), None)
            yield eq(pubsub.publish('foo', 'hello foo'), 1)
            channel, message = yield listener.get()
            self.assertEqual(channel, 'foo')
            self.assertEqual(message, 'hello foo')
            yield eq(pubsub.punsubscribe(), None)
            # yield listener.get()

    ###########################################################################
    #    TRANSACTION
    def test_watch(self):
        key1 = self.randomkey()
        key2 = key1 + '2'
        result = yield self.client.watch(key1)
        self.assertEqual(result, 1)

    ###########################################################################
    #    SYNCHRONOUS CLIENT
    def test_sync(self):
        client = self.sync_store.client()
        self.assertFalse(client.store._loop.is_running())
        self.assertEqual(client.echo('Hello'), b'Hello')


class Scripting(object):

    def test_eval(self):
        result = yield self.client.eval('return "Hello"')
        self.assertEqual(result, b'Hello')
        result = yield self.client.eval("return {ok='OK'}")
        self.assertEqual(result, b'OK')

    def test_eval_with_keys(self):
        result = yield self.client.eval("return {KEYS, ARGV}",
                                        ('a', 'b'),
                                        ('first', 'second', 'third'))
        self.assertEqual(len(result), 2)
        self.assertEqual(result[0], [b'a', b'b'])
        self.assertEqual(result[1], [b'first', b'second', b'third'])


class TestPulsarStore(RedisCommands, unittest.TestCase):
    app_cfg = None

    @classmethod
    def setUpClass(cls):
        yield cls.create_pulsar_store()
        cls.sync_store = cls.create_store('%s/10' % cls.pulsards_uri,
                                          loop=new_event_loop())
        cls.client = cls.store.client()


@unittest.skipUnless(pulsar.HAS_C_EXTENSIONS, 'Requires cython extensions')
class TestPulsarStorePyParser(TestPulsarStore):
    redis_py_parser = True

########NEW FILE########
__FILENAME__ = couchdb
import unittest

from . import QueryTest
from ..couchdb import CouchDbTest


class TestCouchdbQuery(CouchDbTest, QueryTest, unittest.TestCase):
    pass

########NEW FILE########
__FILENAME__ = redis
import unittest

from . import QueryTest
from ..redis import RedisDbTest


class TestCouchdbQuery(RedisDbTest, QueryTest, unittest.TestCase):
    pass

########NEW FILE########
__FILENAME__ = redis
from pulsar import new_event_loop, HAS_C_EXTENSIONS
from pulsar.apps.test import check_server

from .pulsards import unittest, RedisCommands, Scripting, create_store


OK = check_server('redis')


@unittest.skipUnless(OK, 'Requires a running Redis server')
class RedisDbTest(object):

    @classmethod
    def create_store(cls, pool_size=2, namespace=None, **kw):
        addr = cls.cfg.redis_server
        if not addr.startswith('redis://'):
            addr = 'redis://%s' % cls.cfg.redis_server
        namespace = namespace or cls.name(cls.__name__)
        return create_store(addr, pool_size=pool_size, namespace=namespace,
                            **kw)


@unittest.skipUnless(OK, 'Requires a running redis server')
class TestRedisStore(RedisCommands, Scripting, unittest.TestCase):
    store = None

    @classmethod
    def setUpClass(cls):
        addr = 'redis://%s' % cls.cfg.redis_server
        cls.store = cls.create_store(addr)
        cls.sync_store = create_store(addr, loop=new_event_loop())
        cls.client = cls.store.client()


@unittest.skipUnless(OK and HAS_C_EXTENSIONS, 'Requires cython extensions')
class TestRedisStorePyParser(TestRedisStore):
    pass

########NEW FILE########
__FILENAME__ = testmodels
__test__ = False
from datetime import datetime, timedelta

from pulsar.apps.data import odm


default_expiry = lambda: datetime.now() + timedelta(days=7)


class User(odm.Model):
    username = odm.CharField(unique=True)
    password = odm.CharField(required=False, hidden=True)
    first_name = odm.CharField(required=False, index=True)
    last_name = odm.CharField(required=False, index=True)
    email = odm.CharField(required=False, unique=True)
    is_active = odm.BooleanField(default=True)
    can_login = odm.BooleanField(default=True)
    is_superuser = odm.BooleanField(default=False)
    data = odm.JSONField()


class Session(odm.Model):
    '''A session model with a hash table as data store.'''
    data = odm.JSONField()
    expiry = odm.DateTimeField(default=default_expiry)
    user = odm.ForeignKey(User)


class Blog(odm.Model):
    published = odm.DateField()
    title = odm.CharField()
    body = odm.CharField()


class StoreTest(object):

    @classmethod
    def name(cls, name):
        '''A modified name with the execution id
        '''
        return ('test_%s_%s' % (cls.cfg.exc_id, name)).lower()

    @classmethod
    def mapper(cls, *models, **kw):
        '''Create a mapper for models'''
        mapper = odm.Mapper(cls.store)
        for model in models:
            mapper.register(model)
        return mapper

    @classmethod
    def create_store(cls, **kwargs):
        raise NotImplementedError

########NEW FILE########
__FILENAME__ = utils
import re
import unittest

from pulsar.apps.ds import redis_to_py_pattern


class TestUtils(unittest.TestCase):

    def match(self, c, text):
        self.assertEqual(c.match(text).group(), text)

    def not_match(self, c, text):
        self.assertEqual(c.match(text), None)

    def test_redis_to_py_pattern(self):
        p = redis_to_py_pattern('h?llo')
        c = re.compile(p)
        self.match(c, 'hello')
        self.match(c, 'hallo')
        self.not_match(c, 'haallo')
        self.not_match(c, 'hallox')
        #
        p = redis_to_py_pattern('h*llo')
        c = re.compile(p)
        self.match(c, 'hello')
        self.match(c, 'hallo')
        self.match(c, 'hasjdbvhckjcvkfcdfllo')
        self.not_match(c, 'haallox')
        self.not_match(c, 'halloouih')
        #
        p = redis_to_py_pattern('h[ae]llo')
        c = re.compile(p)
        self.match(c, 'hello')
        self.match(c, 'hallo')
        self.not_match(c, 'hollo')

########NEW FILE########
__FILENAME__ = coverage
'''Test cases for code not covered in standard test cases'''
import os
import tempfile
import uuid
import shutil
import unittest

import pulsar


class PulsarCoverage(unittest.TestCase):

    def test_profile_plugin(self):
        from pulsar.apps.test.plugins import profile
        p = profile.Profile()
        p.config.set('profile', True)
        p.configure(p.config)
        p.profile_temp_path = tempfile.mkdtemp()
        self.assertFalse(p.on_end())
        shutil.rmtree(p.profile_temp_path)
        #
        lines = list(profile.data_stream(['', 'a b c d e f']))
        self.assertEqual(lines, [])

########NEW FILE########
__FILENAME__ = failures
'''Tests the test suite loader.'''
import os
import time
import unittest
from threading import current_thread

import pulsar
from pulsar.apps.test import TestLoader


class TestFailures(unittest.TestCase):

    @unittest.expectedFailure
    def test_fail(self):
        self.assertEqual(1, 0, "broken")


class TestSetupFailure(unittest.TestCase):

    @unittest.expectedFailure
    def setUp(self):
        self.assertEqual(1, 0, "broken")

    def test_ok(self):
        # Never goes in here
        pass


class TestTearDownFailure(unittest.TestCase):
    processed = 0

    @unittest.expectedFailure
    def test_fail(self):
        self.__class__.processed += 1
        self.assertEqual(1, 0, "broken")

    def test_ok(self):
        self.__class__.processed += 1

    @classmethod
    def tearDownClass(cls):
        assert cls.processed == 2, "Should have processed 2"

########NEW FILE########
__FILENAME__ = loader
'''Tests the test suite loader.'''
import os
import sys
import time
import unittest
from threading import current_thread

from pulsar import get_actor, get_application
from pulsar.apps.test import TestLoader, run_on_arbiter


class TestTestLoader(unittest.TestCase):

    @run_on_arbiter
    def test_testsuite(self):
        app = yield get_application('test')
        self.assertTrue(app.cfg.script)
        # self.assertEqual(app.script, sys.argv[0])
        self.assertEqual(os.path.dirname(app.cfg.script), app.root_dir)
        self.assertEqual(app.cfg.modules, ('tests',
                                           ('examples', 'tests'),
                                           ('examples', 'test_*')))

    def test_load_pulsar_tests(self):
        app = get_actor().app
        loader = TestLoader(app.root_dir, app.cfg.modules, app.runner)
        self.assertEqual(loader.modules, [('tests', None, None),
                                          ('examples', 'tests', None),
                                          ('examples', 'test_*', None)])
        modules = dict(loader.testmodules())
        self.assertTrue(modules)
        self.assertFalse('httpbin' in modules)
        self.assertTrue('echo' in modules)
        self.assertTrue('djangoapp' in modules)
        self.assertTrue('djangoapp.app' in modules)
        self.assertTrue('djangoapp.pulse' in modules)
        self.assertTrue('async' in modules)
        self.assertTrue('suite.single' in modules)

    def test_sorted_tags(self):
        app = get_actor().app
        loader = TestLoader(app.root_dir, app.cfg.modules, app.runner)
        modules = list(loader.testmodules())
        self.assertTrue(modules)
        tags = [m[0] for m in modules]
        self.assertEqual(tags, sorted(tags))

    def test_load_tags1(self):
        app = get_actor().app
        loader = TestLoader(app.root_dir, app.cfg.modules, app.runner)
        modules = dict(loader.testmodules(('suite',)))
        self.assertEqual(len(modules), 6)

    def test_load_exclude(self):
        app = get_actor().app
        loader = TestLoader(app.root_dir, app.cfg.modules, app.runner)
        modules = dict(loader.testmodules(
            exclude_tags=('taskqueue', 'apps.pubsub')))
        self.assertTrue(modules)
        for module in modules:
            self.assertTrue('taskqueue' not in module)
            self.assertTrue('apps.pubsub' not in module)

    def __test_djangoapp_tags(self):
        # TODO Fix this
        app = get_actor().app
        loader = TestLoader(app.root_dir, app.cfg.modules, app.runner)
        modules = dict(loader.testmodules(('djangoapp',)))
        self.assertEqual(len(modules), 3)

########NEW FILE########
__FILENAME__ = me
'''Tests the test suite and pulsar distribution.'''
import os
import unittest
from threading import current_thread
from asyncio import sleep, Future

import pulsar
from pulsar import send, multi_async, get_event_loop, coroutine_return
from pulsar.async.eventloop import QueueEventLoop
from pulsar.apps.test import run_on_arbiter, TestSuite, sequential
from pulsar.apps.test.plugins import bench, profile
from pulsar.utils.version import get_version


def simple_function(actor):
    return actor.name


def wait(actor, period=0.5):
    start = actor._loop.time()
    yield sleep(period)
    coroutine_return(actor._loop.time() - start)


class TestTestWorker(unittest.TestCase):

    def testWorker(self):
        '''Test the test worker'''
        worker = pulsar.get_actor()
        self.assertTrue(pulsar.is_actor(worker))
        self.assertTrue(worker.is_running())
        self.assertFalse(worker.closed())
        self.assertFalse(worker.stopped())
        self.assertEqual(worker.info_state, 'running')
        self.assertNotEqual(worker.tid, current_thread().ident)
        self.assertEqual(worker.pid, os.getpid())
        self.assertFalse(worker.impl.daemon)
        self.assertFalse(worker.is_monitor())
        self.assertEqual(str(worker.impl), worker.impl.unique_name)

    def testCPUbound(self):
        worker = pulsar.get_actor()
        loop = pulsar.get_request_loop()
        self.assertIsInstance(loop, QueueEventLoop)
        self.assertNotIsInstance(worker._loop, QueueEventLoop)

    def testWorkerMonitor(self):
        worker = pulsar.get_actor()
        mailbox = worker.mailbox
        monitor = worker.monitor
        self.assertEqual(mailbox.address, monitor.address)

    @run_on_arbiter
    def test_TestSuiteMonitor(self):
        arbiter = pulsar.get_actor()
        self.assertTrue(len(arbiter.monitors) >= 1)
        monitor = arbiter.registered['test']
        app = monitor.app
        self.assertTrue(isinstance(app, TestSuite))

    def test_mailbox(self):
        worker = pulsar.get_actor()
        mailbox = worker.mailbox
        self.assertTrue(mailbox)
        self.assertTrue(hasattr(mailbox, 'request'))
        self.assertTrue(mailbox._loop)
        self.assertTrue(mailbox._loop.is_running())
        self.assertEqual(worker._loop, mailbox._loop)
        self.assertTrue(mailbox.address)
        self.assertTrue(mailbox.name)

    def test_event_loop(self):
        '''Test event loop in test worker'''
        worker = pulsar.get_actor()
        loop = pulsar.get_request_loop()
        event_loop = get_event_loop()
        self.assertTrue(loop.is_running())
        self.assertTrue(event_loop.is_running())
        self.assertNotEqual(loop, event_loop)
        self.assertEqual(worker._loop, event_loop)

    def test_yield(self):
        '''Yielding a future calling back on separate thread'''
        worker = pulsar.get_actor()
        loop = pulsar.get_request_loop()
        loop_tid = yield pulsar.loop_thread_id(loop)
        self.assertNotEqual(worker.tid, current_thread().ident)
        self.assertEqual(loop_tid, current_thread().ident)
        yield None
        self.assertEqual(loop_tid, current_thread().ident)
        d = Future()
        # We are calling back the future in the event_loop which is on
        # a separate thread

        def _callback():
            d.set_result(current_thread().ident)
        worker._loop.call_later(0.2, _callback)
        result = yield d
        self.assertEqual(worker.tid, result)
        self.assertNotEqual(worker.tid, current_thread().ident)
        self.assertEqual(loop_tid, current_thread().ident)

    def testInline(self):
        val = yield 3
        self.assertEqual(val, 3)
        future = yield send('monitor', 'ping')
        self.assertEqual(future, 'pong')

    def test_run_on_arbiter(self):
        actor = pulsar.get_actor()
        response = yield actor.send('arbiter', 'run', simple_function)
        self.assertEqual(response, 'arbiter')

    def test_unknown_send_target(self):
        # The target does not exists
        result = yield pulsar.send('vcghdvchdgcvshcd', 'ping')
        self.assertEqual(result, None)

    def test_multiple_execute(self):
        m = yield multi_async((send('arbiter', 'run', wait, 1.2),
                               send('arbiter', 'ping'),
                               send('arbiter', 'echo', 'ciao!'),
                               send('arbiter', 'run', wait, 2.1),
                               send('arbiter', 'echo', 'ciao again!')))
        self.assertTrue(m[0] >= 1.1)
        self.assertEqual(m[1], 'pong')
        self.assertEqual(m[2], 'ciao!')
        self.assertTrue(m[3] >= 2.0)
        self.assertEqual(m[4], 'ciao again!')

    def test_tasks(self):
        worker = pulsar.get_actor()
        backend = worker.app.backend
        self.assertTrue(worker.app.backend)
        self.assertEqual(backend.name, worker.app.name)
        self.assertEqual(len(backend.registry), 1)
        self.assertTrue('test' in backend.registry)


class TestTestSuite(unittest.TestCase):

    def test_no_plugins(self):
        suite = TestSuite()
        self.assertFalse(suite.cfg.plugins)
        self.assertFalse('profile' in suite.cfg.settings)

    def test_profile_plugins(self):
        suite = TestSuite(plugins=[profile.Profile()])
        self.assertTrue(suite.cfg.plugins)
        self.assertTrue('profile' in suite.cfg.settings)
        self.assertTrue('profile_stats_path' in suite.cfg.settings)


class TestPulsar(unittest.TestCase):

    def test_version(self):
        self.assertTrue(pulsar.VERSION)
        self.assertTrue(pulsar.__version__)
        self.assertEqual(pulsar.__version__, get_version(pulsar.VERSION))
        self.assertTrue(len(pulsar.VERSION) >= 2)

    def test_meta(self):
        for m in ("__author__", "__contact__", "__homepage__", "__doc__"):
            self.assertTrue(getattr(pulsar, m, None))

########NEW FILE########
__FILENAME__ = config
'''Config and Setting classes'''
import os
import pickle
import tempfile
import unittest

import pulsar
from pulsar import get_actor, Config, validate_callable


def connection_made(conn):
    return conn


def post_fork(actor):
    return actor


class TestConfig(unittest.TestCase):

    def testFunction(self):
        cfg = Config()
        worker = get_actor()
        self.assertTrue(cfg.post_fork)
        self.assertEqual(cfg.post_fork(worker), None)
        cfg.set('post_fork', post_fork)
        self.assertEqual(cfg.post_fork(worker), worker)
        cfg1 = pickle.loads(pickle.dumps(cfg))
        self.assertEqual(cfg1.post_fork(worker), worker)

    def testFunctionFromConfigFile(self):
        worker = get_actor()
        cfg = Config()
        self.assertEqual(cfg.connection_made(worker), None)
        self.assertTrue(cfg.import_from_module(__file__))
        self.assertEqual(cfg.connection_made(worker), worker)
        cfg1 = pickle.loads(pickle.dumps(cfg))
        self.assertEqual(cfg1.connection_made(worker), worker)

    def testBadConfig(self):
        cfg = Config()
        self.assertEqual(cfg.import_from_module('foo/bla/cnkjnckjcn.py'), [])
        cfg.set('config', None)
        self.assertEqual(cfg.config, None)
        cfg = Config(exclude=['config'])
        self.assertEqual(cfg.config, None)

    def testDefaults(self):
        from pulsar.utils import config
        self.assertFalse(config.pass_through(None))
        cfg = Config()
        self.assertEqual(list(sorted(cfg)), list(sorted(cfg.settings)))

        def _():
            cfg.debug = 3
        self.assertRaises(AttributeError, _)
        #
        name = tempfile.mktemp()
        with open(name, 'w') as f:
            f.write('a')
        self.assertRaises(RuntimeError, cfg.import_from_module, name)
        os.remove(name)
        #
        name = '%s.py' % name
        with open(name, 'w') as f:
            f.write('a')
        self.assertRaises(RuntimeError, cfg.import_from_module, name)
        os.remove(name)

    def testSystem(self):
        from pulsar import system
        cfg = Config()
        self.assertEqual(cfg.uid, system.get_uid())
        self.assertEqual(cfg.gid, system.get_gid())
        self.assertEqual(cfg.proc_name, 'pulsar')
        cfg.set('process_name', 'bla')
        self.assertEqual(cfg.proc_name, 'bla')

    def testValidation(self):
        self.assertEqual(pulsar.validate_list((1, 2)), [1, 2])
        self.assertRaises(TypeError, pulsar.validate_list, 'bla')
        self.assertEqual(pulsar.validate_string(b' bla  '), 'bla')
        self.assertEqual(pulsar.validate_string(None), None)
        self.assertRaises(TypeError, pulsar.validate_string, [])
        self.assertEqual(pulsar.validate_bool(True), True)
        self.assertEqual(pulsar.validate_bool('true '), True)
        self.assertEqual(pulsar.validate_bool(' false'), False)
        self.assertRaises(TypeError, pulsar.validate_bool, [])
        self.assertRaises(ValueError, pulsar.validate_bool, 'foo')
        self.assertRaises(ValueError, pulsar.validate_pos_int, 'foo')
        self.assertRaises(ValueError, pulsar.validate_pos_int, -1)
        self.assertRaises(ValueError, pulsar.validate_pos_float, 'foo')
        self.assertRaises(ValueError, pulsar.validate_pos_float, -0.001)
        self.assertEqual(pulsar.validate_pos_float('0.101'), 0.101)
        self.assertRaises(TypeError, pulsar.validate_dict, 4)

    def test_validate_callable(self):
        self.assertRaises(TypeError, validate_callable(1), None)
        self.assertRaises(TypeError, validate_callable(1), 4)
        self.assertRaises(TypeError, validate_callable(1), object())

        class test1:
            def __call__(self, arg):
                pass

        class test2:
            def __call__(self, arg1, arg2=None):
                pass

        test = test1()
        self.assertEqual(validate_callable(1)(test), test)
        self.assertRaises(TypeError, validate_callable(2), test)
        test = test2()
        self.assertEqual(validate_callable(1)(test), test)
        self.assertEqual(validate_callable(2)(test), test)
        self.assertRaises(TypeError, validate_callable(3), test)

    def test_methods(self):
        cfg = Config()
        self.assertEqual(cfg.get('sdjcbsjkbcd', 'ciao'), 'ciao')
        d = dict(cfg.items())
        self.assertEqual(len(d), len(cfg))
        sett = cfg.get('debug')
        self.assertTrue(str(sett))
        self.assertEqual(cfg.settings['debug'].default, False)
        cfg.set('debug', True, default=True)
        self.assertEqual(cfg.debug, True)
        self.assertEqual(cfg.settings['debug'].default, True)

########NEW FILE########
__FILENAME__ = frame
from random import randint
import struct
import unittest

from pulsar import ProtocolError, HAS_C_EXTENSIONS
from pulsar.utils.websocket import frame_parser, parse_close
import pulsar.apps.ws

i2b = lambda args: bytes(bytearray(args))


class FrameTest(unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        cls.bdata = i2b((randint(0, 255) for v in range(256)))
        cls.large_bdata = i2b((randint(0, 255) for v in range(64*1024)))

    def parser(self, pyparser=False, **kw):
        return frame_parser(**kw)

    def test_version(self):
        self.assertRaises(ProtocolError, self.parser, version='bla')

    def test_server(self):
        server = self.parser()
        self.assertEqual(server.decode_mask_length, 4)
        self.assertEqual(server.encode_mask_length, 0)
        self.assertEqual(server.max_payload, 1 << 63)

    def test_both_masked(self):
        server = self.parser(kind=2)
        self.assertEqual(server.decode_mask_length, 0)
        self.assertEqual(server.encode_mask_length, 0)
        server = self.parser(kind=3)
        self.assertEqual(server.decode_mask_length, 4)
        self.assertEqual(server.encode_mask_length, 4)

    def testCloseFrame(self):
        parser = self.parser(kind=2)
        close_message = struct.pack('!H', 1000) + b'OK'
        f = parser.encode(close_message, opcode=0x8)
        self.assertEqual(close_message, f[2:])

    def testControlFrames(self):
        s = self.parser()
        c = self.parser(kind=1)
        #
        chunk = s.close(1001)
        frame = c.decode(chunk)
        self.assertTrue(frame.final)
        self.assertEqual(frame.opcode, 8)
        code, reason = parse_close(frame.body)
        self.assertEqual(code, 1001)
        #
        chunk = s.ping('Hello')
        frame = c.decode(chunk)
        self.assertTrue(frame.final)
        self.assertEqual(frame.opcode, 9)
        self.assertEqual(i2b((0x89, 0x05, 0x48, 0x65, 0x6c, 0x6c, 0x6f)),
                         chunk)
        self.assertEqual(frame.body, b'Hello')
        self.assertRaises(ProtocolError, s.ping, self.bdata)
        #
        chunk = s.pong('Hello')
        frame = c.decode(chunk)
        self.assertTrue(frame.final)
        self.assertEqual(frame.opcode, 10)
        self.assertEqual(frame.body, b'Hello')
        self.assertRaises(ProtocolError, s.pong, self.bdata)

    def test_conntrol_frames_fragmented(self):
        c = self.parser(kind=1)
        for opcode in (8, 9, 10):
            chunk = c.encode('test', opcode=opcode, final=False)
            s = self.parser()
            try:
                s.decode(chunk)
            except ProtocolError as e:
                pass
            else:
                raise Exception('Protocol error not raised')

    def testUnmaskedDataFrame(self):
        parser = self.parser(kind=2)
        data = parser.encode('Hello')
        f = parser.decode(data)
        self.assertEqual(f.opcode, 1)
        self.assertEqual(len(f.body), 5)
        self.assertFalse(f.masking_key)
        #
        self.assertEqual(i2b((0x81, 0x05, 0x48, 0x65, 0x6c, 0x6c, 0x6f)), data)
        f1 = parser.encode('Hel', final=False)
        f2 = parser.continuation('lo', final=True)
        self.assertEqual(i2b((0x01, 0x03, 0x48, 0x65, 0x6c)), f1)
        self.assertEqual(i2b((0x80, 0x02, 0x6c, 0x6f)), f2)

    def testBinaryDataFrame(self):
        s = self.parser()
        c = self.parser(kind=1)
        #
        chunk = s.encode(self.bdata, opcode=2)
        frame = c.decode(chunk)
        self.assertEqual(frame.opcode, 2)
        self.assertFalse(frame.masking_key)
        self.assertEqual(frame.body, self.bdata)
        self.assertEqual(struct.pack('!BBH', 0x82, 0x7E, 0x0100),
                         chunk[:4])
        #
        chunk = s.encode(self.large_bdata, opcode=2)
        frame = c.decode(chunk)
        self.assertEqual(frame.opcode, 2)
        self.assertFalse(frame.masking_key)
        self.assertEqual(frame.body, self.large_bdata)
        self.assertEqual(struct.pack('!BBQ', 0x82, 0x7F, 0x0000000000010000),
                         chunk[:10])

    def testMaskData(self):
        client = self.parser(kind=1)
        masking_key = i2b((0x37, 0xfa, 0x21, 0x3d))
        chunk = client.encode('Hello', masking_key=masking_key)
        msg = i2b((0x81, 0x85, 0x37, 0xfa, 0x21, 0x3d, 0x7f, 0x9f,
                   0x4d, 0x51, 0x58))
        self.assertEqual(chunk, msg)

    def testParserBinary(self):
        s = self.parser()
        c = self.parser(kind=1)
        chunk = c.encode(self.bdata, opcode=2)
        frame = s.decode(chunk)
        self.assertTrue(frame)
        self.assertEqual(frame.body, self.bdata)
        #
        # Now try different masking key
        chunk = c.encode(self.large_bdata, opcode=2, masking_key=b'ciao')
        frame = s.decode(chunk)
        self.assertTrue(frame)
        self.assertEqual(frame.body, self.large_bdata)

    def testPartialParsing(self):
        s = self.parser()
        c = self.parser(kind=1)
        chunk = s.encode(self.large_bdata, opcode=2)
        #
        self.assertEqual(c.decode(chunk[:1]), None)
        self.assertEqual(c.decode(chunk[1:5]), None)
        self.assertEqual(c.decode(chunk[5:50]), None)
        frame = c.decode(chunk[50:])
        self.assertTrue(frame)
        self.assertEqual(frame.body, self.large_bdata)
        self.assertEqual(frame.opcode, 2)

    def test_multi_encode(self):
        s = self.parser()
        c = self.parser(kind=1)
        chunks = list(s.multi_encode(self.large_bdata, opcode=2,
                                     max_payload=6500))
        self.assertEqual(len(chunks), 11)
        #
        # Now decode them
        frames = []
        for chunk in chunks:
            frames.append(c.decode(chunk))
        for frame in frames[:-1]:
            self.assertFalse(frame.final)
        self.assertTrue(frames[-1].final)
        msg = b''.join((f.body for f in frames))
        self.assertEqual(msg, self.large_bdata)

    def test_bad_mask(self):
        s = self.parser()
        chunk = s.encode('hello')
        self.assertRaises(ProtocolError, s.decode, chunk)
        #
        # and the client
        c = self.parser(kind=1)
        chunk = c.encode('hello')
        self.assertRaises(ProtocolError, c.decode, chunk)

    def test_symmetric_mask(self):
        s = self.parser(kind=2)
        chunk = s.encode('Hello')
        self.assertEqual(s.decode(chunk).body, 'Hello')
        s = self.parser(kind=3)
        chunk = s.encode('Hello')
        self.assertEqual(s.decode(chunk).body, 'Hello')

    def test_parse_close(self):
        self.assertRaises(ProtocolError, parse_close, b'o')


@unittest.skipUnless(HAS_C_EXTENSIONS, "Requires C extensions")
class PyFrameTest(FrameTest):

    def parser(self, pyparser=True, **kw):
        return frame_parser(pyparser=True, **kw)

########NEW FILE########
__FILENAME__ = git
'''Tests git info.'''
import unittest

from pulsar.utils.version import gitrepo


class TestGit(unittest.TestCase):

    def test_pulsar(self):
        info = gitrepo()
        self.assertTrue(info)
        self.assertTrue(info['branch'])
        self.assertIsInstance(info['head'], dict)
        self.assertIsInstance(info['remotes'], list)
        remote = info['remotes'][0]
        self.assertIsInstance(remote, dict)
        self.assertEqual(remote['name'], 'origin')

########NEW FILE########
__FILENAME__ = headers
import unittest

from pulsar.utils.httpurl import (Headers, accept_content_type,
                                  DEFAULT_CHARSET, SimpleCookie)


class TestHeaders(unittest.TestCase):

    def testServerHeader(self):
        h = Headers()
        self.assertEqual(h.kind, 'server')
        self.assertEqual(len(h), 0)
        h['content-type'] = 'text/html'
        self.assertEqual(len(h), 1)

    def testHeaderBytes(self):
        h = Headers(kind=None)
        h['content-type'] = 'text/html'
        h['server'] = 'bla'
        self.assertTrue(repr(h).startswith('both '))
        self.assertEqual(bytes(h), b'Server: bla\r\n'
                                   b'Content-Type: text/html\r\n\r\n')

    def testClientHeader(self):
        h = Headers(kind='client')
        self.assertEqual(h.kind, 'client')
        self.assertEqual(len(h), 0)
        h['content-type'] = 'text/html'
        self.assertEqual(h.get_all('content-type'), ['text/html'])
        self.assertEqual(len(h), 1)
        h['server'] = 'bla'
        self.assertEqual(len(h), 1)
        del h['content-type']
        self.assertEqual(len(h), 0)
        self.assertEqual(h.get_all('content-type', []), [])

    def test_non_standard_request_headers(self):
        h = Headers(kind='client')
        h['accept'] = 'text/html'
        self.assertEqual(len(h), 1)
        h['server'] = 'bla'
        self.assertEqual(len(h), 1)
        h['proxy-connection'] = 'keep-alive'
        self.assertEqual(len(h), 2)
        headers = str(h)
        self.assertTrue('Proxy-Connection:' in headers)

    def test_multiple_entry(self):
        h = Headers([('Connection', 'Keep-Alive'),
                     ('Accept-Encoding', 'identity'),
                     ('Accept-Encoding', 'deflate'),
                     ('Accept-Encoding', 'compress'),
                     ('Accept-Encoding', 'gzip')],
                    kind='client')
        accept = h['accept-encoding']
        self.assertEqual(accept, 'identity, deflate, compress, gzip')

    def test_accept_content_type(self):
        accept = accept_content_type()
        self.assertTrue('text/html' in accept)
        accept = accept_content_type(
            'text/*, text/html, text/html;level=1, */*')
        self.assertTrue('text/html' in accept)
        self.assertTrue('text/plain' in accept)

    def test_init_int(self):
        h = Headers(kind=1)
        self.assertEqual(h.kind, 'server')
        self.assertEqual(h.kind_number, 1)
        h = Headers(kind=0)
        self.assertEqual(h.kind, 'client')
        self.assertEqual(h.kind_number, 0)
        h = Headers(kind=56)
        self.assertEqual(h.kind, 'both')
        self.assertEqual(h.kind_number, 2)

    def test_remove_header(self):
        h = Headers([('Content-type', 'text/html')])
        self.assertEqual(len(h), 1)
        self.assertEqual(h.remove_header('foo'), None)
        self.assertEqual(h.remove_header('content-length'), None)
        self.assertEqual(h.remove_header('content-type'), ['text/html'])
        self.assertEqual(len(h), 0)

    def test_remove_header_value(self):
        h = Headers([('Accept-encoding', 'gzip'),
                     ('Accept-encoding', 'deflate'),
                     ('Accept', '*/*')], kind=2)
        self.assertEqual(len(h), 2)
        self.assertEqual(h['accept-encoding'], 'gzip, deflate')
        self.assertEqual(h.remove_header('accept-encoding', 'x'), None)
        self.assertEqual(h['accept-encoding'], 'gzip, deflate')
        self.assertEqual(h.remove_header('accept-encoding', 'deflate'),
                         'deflate')
        self.assertEqual(len(h), 2)
        self.assertEqual(h['accept-encoding'], 'gzip')

    def test_override(self):
        h = Headers([('Accept-encoding', 'gzip'),
                     ('Accept-encoding', 'deflate'),
                     ('Accept', '*/*')], kind=2)
        h.override([('Accept-encoding', 'gzip2'),
                    ('Accept-encoding', 'deflate2'),
                    ('Accept', 'text/html'),
                    ('Accept', '*/*; q=0.8')])
        self.assertEqual(len(h), 2)
        self.assertEqual(h['accept-encoding'], 'gzip2, deflate2')
        self.assertEqual(h['accept'], 'text/html, */*; q=0.8')

    def test_cookies(self):
        h = Headers()
        cookies = SimpleCookie({'bla': 'foo', 'pippo': 'pluto'})
        self.assertEqual(len(cookies), 2)
        for c in cookies.values():
            v = c.OutputString()
            h.add_header('Set-Cookie', v)
        h = str(h)
        self.assertTrue(
            h in ('Set-Cookie: bla=foo\r\nSet-Cookie: pippo=pluto\r\n\r\n',
                  'Set-Cookie: pippo=pluto\r\nSet-Cookie: bla=foo\r\n\r\n'))

########NEW FILE########
__FILENAME__ = internet
import os
import io
import socket
import tempfile
import time
import unittest

import pulsar
from pulsar import platform
from pulsar.utils.internet import (parse_address, parse_connection_string,
                                   socketpair, close_socket, is_socket_closed,
                                   format_address)
from pulsar.utils.pep import pickle
from pulsar.apps.test import mock


class TestParseAddress(unittest.TestCase):

    def test_parse_ipv4(self):
        address = parse_address('127.0.0.1')
        self.assertEqual(address, ('127.0.0.1', 8000))
        address = parse_address('127.0.0.1', 8060)
        self.assertEqual(address, ('127.0.0.1', 8060))

    def test_parse_ipv6(self):
        address = parse_address('[::1]')
        self.assertEqual(address, ('::1', 8000))
        address = parse_address('[::1]:8070')
        self.assertEqual(address, ('::1', 8070))

    def test_parse_error(self):
        self.assertRaises(ValueError, parse_address, ())
        self.assertRaises(ValueError, parse_address, (1,))
        self.assertRaises(ValueError, parse_address, (1, 2, 3))
        self.assertRaises(ValueError, parse_address, '127.0.0.1:bla')


class TestParseConnectionString(unittest.TestCase):

    def test_parse_tcp(self):
        scheme, address, params = parse_connection_string('127.0.0.1:8050')
        self.assertEqual(scheme, '')
        self.assertEqual(address, ('127.0.0.1', 8050))
        self.assertEqual(params, {})

    def test_parse_tcp_default(self):
        scheme, address, params = parse_connection_string('127.0.0.1', 8095)
        self.assertEqual(scheme, '')
        self.assertEqual(address, ('127.0.0.1', 8095))
        self.assertEqual(params, {})

    def test_parse_unix(self):
        scheme, address, params = parse_connection_string('unix:bla.foo')
        self.assertEqual(scheme, '')
        self.assertEqual(address, 'bla.foo')
        self.assertEqual(params, {})

    def test_parse_unix_with_scheme(self):
        scheme, address, params = parse_connection_string(
            'redis://unix:bla.foo')
        self.assertEqual(scheme, 'redis')
        self.assertEqual(address, 'bla.foo')
        self.assertEqual(params, {})

    def test_parse_tcp_with_scheme_and_params(self):
        scheme, address, params = parse_connection_string('redis://:6439?db=3')
        self.assertEqual(scheme, 'redis')
        self.assertEqual(address, ('', 6439))
        self.assertEqual(params, {'db': '3'})

    def test_parse_tcp_with_http_and_params(self):
        scheme, address, params = parse_connection_string(
            'http://:6439?db=3&bla=foo')
        self.assertEqual(scheme, 'http')
        self.assertEqual(address, ('', 6439))
        self.assertEqual(params, {'db': '3', 'bla': 'foo'})

    def test_parse_tcp_with_https_and_params(self):
        scheme, address, params = parse_connection_string(
            'https://127.0.0.1:6439?db=3&bla=foo')
        self.assertEqual(scheme, 'https')
        self.assertEqual(address, ('127.0.0.1', 6439))
        self.assertEqual(params, {'db': '3', 'bla': 'foo'})


class TestMisc(unittest.TestCase):

    def test_socketpair(self):
        server, client = socketpair()
        self.assertEqual(client.send(b'ciao'), 4)
        self.assertEqual(server.recv(io.DEFAULT_BUFFER_SIZE), b'ciao')
        self.assertEqual(server.send(b'ciao a te'), 9)
        self.assertEqual(client.recv(io.DEFAULT_BUFFER_SIZE), b'ciao a te')
        close_socket(server)
        self.assertTrue(is_socket_closed(server))
        self.assertTrue(is_socket_closed(None))

    def test_close_socket(self):
        close_socket(None)
        sock = mock.Mock()
        sock.configure_mock(**{'shutdown.side_effect': TypeError,
                               'close.side_effect': TypeError})
        close_socket(sock)
        sock.shutdown.assert_called_with(socket.SHUT_RDWR)
        sock.close.assert_called_with()

    def test_format_address(self):
        self.assertRaises(ValueError, format_address, (1,))
        self.assertRaises(ValueError, format_address, (1, 2, 3))
        self.assertRaises(ValueError, format_address, (1, 2, 3, 4, 5))
        self.assertEqual(format_address(1), '1')

########NEW FILE########
__FILENAME__ = misc
import sys
import unittest
from datetime import timedelta

from pulsar.utils.pep import reraise


class TestMiscellaneous(unittest.TestCase):

    def test_reraise(self):
        self.assertRaises(RuntimeError, reraise, RuntimeError, RuntimeError())
        try:
            raise RuntimeError('bla')
        except Exception:
            exc_info = sys.exc_info()
        self.assertRaises(RuntimeError, reraise, *exc_info)

########NEW FILE########
__FILENAME__ = mixins
import unittest


class TestMixins(unittest.TestCase):

    def testLocal(self):
        from pulsar.utils.structures import AttributeDictionary
        from pulsar.utils.log import LocalMixin
        elem = LocalMixin()
        el = elem.local
        self.assertTrue(isinstance(el, AttributeDictionary))
        self.assertEqual(id(elem.local), id(el))
        self.assertEqual(elem.local.process, None)
        elem.local.process = True
        self.assertEqual(elem.local.process, True)

########NEW FILE########
__FILENAME__ = path
import unittest

from pulsar.utils.path import Path


class TestPath(unittest.TestCase):

    def testThis(self):
        p = Path(__file__)
        self.assertTrue(p.isfile())
        self.assertFalse(p.isdir())
        c = Path.cwd()
        self.assertNotEqual(p, c)
        self.assertTrue(c.isdir())

    def testDir(self):
        c = Path.cwd()
        self.assertEqual(c, c.dir())
        c = Path('/sdjc/scdskjcdnsd/dhjdhjdjksdjksdksd')
        self.assertFalse(c.exists())
        self.assertRaises(ValueError, c.dir)

    def testAdd2Python(self):
        p = Path('/sdjc/scdskjcdnsd/dhjdhjdjksdjksdksd')
        module = p.add2python('pulsar')
        self.assertEqual(module.__name__, 'pulsar')
        self.assertRaises(ValueError, p.add2python, 'kaputttt')

    def testAdd2Python_failure(self):
        p = Path()
        self.assertRaises(ImportError, p.add2python, 'kaputttt')
        self.assertFalse(p.add2python('vdfvdavfdv', must_exist=False))

########NEW FILE########
__FILENAME__ = security
import unittest

import pulsar
from pulsar.utils import security


class TestSecurity(unittest.TestCase):

    def testSalt(self):
        s1 = security.gen_salt(10)
        self.assertEqual(len(s1), 10)
        self.assertNotEqual(security.gen_salt(10), s1)
        s1 = security.gen_salt(30)
        self.assertEqual(len(s1), 30)
        self.assertRaises(ValueError, security.gen_salt, 0)

    def testPassword(self):
        password = 'my-test$$-password'
        hash = security.generate_password_hash(password)
        self.assertTrue('$' in hash)
        self.assertFalse(security.check_password_hash('bla', 'bla'))
        self.assertFalse(security.check_password_hash(hash, 'bla'))
        self.assertFalse(security.check_password_hash(hash, 'bla$foo'))
        self.assertTrue(security.check_password_hash(hash, password))

    def test_random_string(self):
        s1 = security.random_string(length=20)
        self.assertEqual(len(s1), 20)
        self.assertIsInstance(s1, str)
        self.assertNotEqual(s1, security.random_string(length=20))
        self.assertNotEqual(s1, security.random_string(length=20))
        self.assertNotEqual(s1, security.random_string(length=20))

########NEW FILE########
__FILENAME__ = skiplist
from random import randint
import unittest

from pulsar.utils.pep import zip
from pulsar.utils.structures import Skiplist
from pulsar.apps.test import populate


class TestSkiplist(unittest.TestCase):
    skiplist = Skiplist

    def random(self, size=100, score_min=-10, score_max=10):
        scores = populate('float', size, score_min, score_max)
        data = populate('string', size, min_len=5, max_len=10)
        return self.skiplist(zip(scores, data))

    def test_extend(self):
        sl = self.skiplist()
        sl.extend([(94, 'bla'), (-5, 'foo')])
        self.assertEqual(len(sl), 2)

    def test_count(self):
        sl = self.skiplist()
        self.assertEqual(sl.count(-2, 2), 0)
        sl.insert(1, 'bla')
        self.assertEqual(sl.count(-2, 2), 1)
        sl = self.random()
        self.assertEqual(sl.count(float('-inf'), float('+inf')), 100)
        n = 0
        for score, _ in sl:
            n += int(score >= -5 and score <= 5)
        self.assertEqual(sl.count(-5, 5), n)
        #
        # test exclusive
        sl = self.skiplist(((1, 'a1'), (2, 'a2'), (3, 'a3')))
        self.assertEqual(sl.count(1, 2), 2)
        self.assertEqual(sl.count(1, 2, include_min=False), 1)
        self.assertEqual(sl.count(1, 2, include_max=False), 1)
        self.assertEqual(sl.count(1, 2, include_min=False,
                                  include_max=False), 0)

    def test_range_by_score(self):
        sl = self.skiplist()
        self.assertEqual(tuple(sl.range_by_score(float('-inf'), 5)), ())
        sl.insert(1, 'bla')
        self.assertEqual(tuple(sl.range_by_score(-3, 5)), ('bla',))
        sl.insert(1.5, 'foo')
        sl.insert(0.3, 'pippo')
        self.assertEqual(tuple(sl.range_by_score(0.9, 1.1)), ('bla',))
        self.assertEqual(tuple(sl.range_by_score(1, 2)), ('bla', 'foo'))
        self.assertEqual(tuple(sl.range_by_score(1, 2, include_min=False)),
                         ('foo',))
        self.assertEqual(tuple(sl.range_by_score(1, 1.5)), ('bla', 'foo'))
        self.assertEqual(tuple(sl.range_by_score(1, 1.5, include_max=False)),
                         ('bla',))
        self.assertEqual(tuple(sl.range_by_score(-1, 2, start=1)),
                         ('bla', 'foo'))
        self.assertEqual(tuple(sl.range_by_score(-1, 2, start=1, num=1)),
                         ('bla',))

    def test_remove_range(self):
        sl = self.skiplist()
        self.assertEqual(sl.remove_range(0, 3), 0)
        sl.insert(1, 'bla')
        self.assertEqual(sl.remove_range(0, 3), 1)
        sl = self.random(10)
        li = list(sl)
        lir = li[:4] + li[7:]
        self.assertEqual(sl.remove_range(4, 7), 3)
        li2 = list(sl)
        self.assertEqual(li2, lir)
        #
        sl = self.random()
        li = list(sl)
        lir = li[:5] + li[-8:]
        self.assertEqual(sl.remove_range(5, -8), len(li[5:-8]))
        li2 = list(sl)
        self.assertEqual(li2, lir)
        #
        sl = self.random()
        c = 0
        while sl:
            c += 1
            index = randint(0, len(sl)-1)
            self.assertEqual(sl.remove_range(index, index+1), 1)
        self.assertEqual(c, 100)

    def test_remove_range_by_score(self):
        sl = self.skiplist()
        self.assertEqual(sl.remove_range_by_score(0, 3), 0)
        sl.insert(1, 'bla')
        self.assertEqual(sl.remove_range_by_score(0, 3), 1)

########NEW FILE########
__FILENAME__ = structures
'''Tests the tools and utilities in pulsar.utils.'''
import unittest

from pulsar.utils.structures import (MultiValueDict, merge_prefix, deque,
                                     AttributeDictionary)


class TestMultiValueDict(unittest.TestCase):

    def testConstructor(self):
        m = MultiValueDict()
        self.assertEqual(len(m), 0)
        #
        m = MultiValueDict({'bla': 3})
        self.assertEqual(len(m), 1)
        self.assertEqual(m['bla'], 3)
        #
        m = MultiValueDict({'bla': (3, 78), 'foo': 'ciao'})
        self.assertEqual(len(m), 2)
        self.assertEqual(m['bla'], [3, 78])
        self.assertEqual(m['foo'], 'ciao')
        #
        m = MultiValueDict({'bla': [3, 78], 'foo': (v for v in (1, 2))})
        self.assertEqual(m['bla'], [3, 78])
        self.assertEqual(m['foo'], [1, 2])

    def testset(self):
        m = MultiValueDict()
        m['bla'] = 5
        m['bla'] = 89
        self.assertEqual(m['bla'], [5, 89])
        m['foo'] = 'pippo'
        self.assertEqual(m['foo'], 'pippo')
        return m

    def testextra(self):
        m = MultiValueDict()
        m.setdefault('bla', 'foo')
        self.assertEqual(m['bla'], 'foo')
        m['bla'] = 'ciao'
        self.assertEqual(m['bla'], ['foo', 'ciao'])

    def testget(self):
        m = self.testset()
        self.assertEqual(m.get('sdjcbhjcbh'), None)
        self.assertEqual(m.get('sdjcbhjcbh', 'ciao'), 'ciao')

    def testupdate(self):
        m = self.testset()
        m.update({'bla': 'star', 5: 'bo'})
        self.assertEqual(m['bla'], [5, 89, 'star'])
        self.assertEqual(m[5], 'bo')

    def test_iterators(self):
        m = self.testset()
        d = dict(m.items())
        self.assertEqual(d['bla'], [5, 89])
        self.assertEqual(d['foo'], 'pippo')
        l = list(m.values())
        self.assertEqual(len(l), 2)
        self.assertTrue([5, 89] in l)
        self.assertTrue('pippo' in l)

    def testlists(self):
        m = self.testset()
        items = dict(m.lists())
        self.assertEqual(len(items), 2)
        for k, v in items.items():
            self.assertTrue(isinstance(v, list))
        self.assertEqual(items['bla'], [5, 89])
        self.assertEqual(items['foo'], ['pippo'])

    def testCopy(self):
        m = self.testset()
        m2 = m.copy()
        self.assertEqual(m2['bla'], [5, 89])
        self.assertEqual(m2['foo'], 'pippo')
        self.assertEqual(m2.getlist('foo'), ['pippo'])

    def testPop(self):
        m = self.testset()
        self.assertRaises(KeyError, m.pop, 'jhsdbcjcd')
        self.assertEqual(m.pop('skcbnskcbskcbd', 'ciao'), 'ciao')
        self.assertEqual(m.pop('foo'), 'pippo')
        self.assertRaises(KeyError, m.pop, 'foo')
        self.assertEqual(m.pop('bla'), [5, 89])
        self.assertFalse(m)

    def test_to_dict(self):
        m = MultiValueDict((('id', 1), ('id', 2)))
        self.assertEqual(len(m), 1)
        self.assertEqual(m['id'], [1, 2])
        d = dict(m)
        self.assertEqual(d, {'id': [1, 2]})


class TestAttributeDictionary(unittest.TestCase):

    def testInit(self):
        self.assertRaises(TypeError, AttributeDictionary, {}, {})
        a = AttributeDictionary({'bla': 1}, foo='pippo')
        self.assertEqual(dict(a), {'bla': 1, 'foo': 'pippo'})
        self.assertEqual(len(a), 2)

    def testAssign(self):
        a = AttributeDictionary()
        a['ciao'] = 5
        self.assertEqual(a.ciao, 5)
        self.assertEqual(a['ciao'], 5)
        self.assertEqual(list(a.values()), [5])
        self.assertEqual(list(a.items()), [('ciao', 5)])


class TestFunctions(unittest.TestCase):

    def test_merge_prefix(self):
        d = deque([b'abc', b'de', b'fghi', b'j'])
        merge_prefix(d, 5)
        self.assertEqual(d, deque([b'abcde', b'fghi', b'j']))
        d = deque([b'abc', b'de', b'fghi', b'j'])
        merge_prefix(d, 4)
        self.assertEqual(d, deque([b'abcd', b'e', b'fghi', b'j']))
        merge_prefix(d, 7)
        self.assertEqual(d, deque([b'abcdefg', b'hi', b'j']))
        merge_prefix(d, 3)
        self.assertEqual(d, deque([b'abc', b'defg', b'hi', b'j']))
        merge_prefix(d, 100)
        self.assertEqual(d, deque([b'abcdefghij']))

########NEW FILE########
__FILENAME__ = zset
import unittest
from random import randint

from pulsar.utils.structures import Zset
from pulsar.apps.test import populate


class TestZset(unittest.TestCase):
    zset = Zset

    def random(self):
        string = populate('string', size=100)
        values = populate('float', size=100, min=-10, max=10)
        s = self.zset()
        s.update(zip(values, string))
        return s

    def test_add(self):
        s = self.zset()
        s.add(3, 'ciao')
        s.add(4, 'bla')
        self.assertEqual(len(s), 2)
        s.add(-1, 'bla')
        self.assertEqual(len(s), 2)
        data = list(s)
        self.assertEqual(data, ['bla', 'ciao'])

    def test_rank(self):
        s = self.zset()
        s.add(3, 'ciao')
        s.add(4, 'bla')
        s.add(2, 'foo')
        s.add(20, 'pippo')
        s.add(-1, 'bla')
        self.assertEqual(len(s), 4)
        self.assertEqual(s.rank('bla'), 0)
        self.assertEqual(s.rank('foo'), 1)
        self.assertEqual(s.rank('ciao'), 2)
        self.assertEqual(s.rank('pippo'), 3)
        self.assertEqual(s.rank('xxxx'), None)

    def test_update(self):
        s = self.random()
        self.assertTrue(s)
        prev = None
        for score, _ in s.items():
            if prev is not None:
                self.assertTrue(score >= prev)
            prev = score
        return s

    def test_remove(self):
        s = self.test_update()
        values = list(s)
        while values:
            index = randint(0, len(values)-1)
            val = values.pop(index)
            self.assertTrue(val in s)
            self.assertNotEqual(s.remove(val), None)
            self.assertFalse(val in s)
        self.assertFalse(s)

    def test_remove_same_score(self):
        s = self.zset([(3, 'bla'), (3, 'foo'), (3, 'pippo')])
        self.assertEqual(s.remove('foo'), 3)
        self.assertEqual(len(s), 2)
        self.assertFalse('foo' in s)

    def test_range(self):
        s = self.random()
        values = list(s.range(3, 10))
        self.assertTrue(values)
        self.assertEqual(len(values), 7)
        all = list(s)[3:10]
        self.assertEqual(all, values)

    def test_range_scores(self):
        s = self.random()
        values = list(s.range(3, 10, True))
        self.assertTrue(values)
        self.assertEqual(len(values), 7)
        all = list(s)[3:10]
        all2 = [v for s, v in values]
        self.assertEqual(all, all2)

    def test_remove_range_by_score(self):
        s = self.zset([(1.2, 'bla'), (2.3, 'foo'), (3.6, 'pippo')])
        self.assertEqual(s.remove_range_by_score(1.6, 4), 2)
        self.assertEqual(s, self.zset([(1.2, 'bla')]))

    def test_remove_range_by_rank(self):
        s = self.zset([(1.2, 'bla'), (2.3, 'foo'), (3.6, 'pippo'),
                       (4, 'b'), (5, 'c')])
        self.assertEqual(s.remove_range(1, 4), 3)
        self.assertEqual(s, self.zset([(1.2, 'bla'), (5, 'c')]))

########NEW FILE########
__FILENAME__ = system
'''Tests the tools and utilities in pulsar.utils.'''
import unittest

from pulsar import system, platform


class TestSystem(unittest.TestCase):

    @unittest.skipUnless(platform.is_posix, 'Posix platform required')
    def testPlatform(self):
        self.assertFalse(platform.is_windows)
        self.assertFalse(platform.is_winNT)

    def test_maxfd(self):
        m = system.get_maxfd()
        self.assertTrue(m)

########NEW FILE########
__FILENAME__ = text
'''Tests the tools and utilities in pulsar.utils.'''
import unittest

from pulsar.utils.log import lazy_string


class TestTextUtils(unittest.TestCase):

    def testLazy(self):
        @lazy_string
        def blabla(n):
            return 'AAAAAAAAAAAAAAAAAAAA %s' % n
        r = blabla(3)
        self.assertEqual(r.value, None)
        v = str(r)
        self.assertEqual(v, 'AAAAAAAAAAAAAAAAAAAA 3')
        self.assertEqual(r.value, v)

########NEW FILE########
__FILENAME__ = tools
'''Tests the tools and utilities in pulsar.utils.'''
import os
import unittest

from pulsar import system, get_actor, spawn, send
from pulsar.utils.tools import checkarity, Pidfile, nice_number
from pulsar.apps.test import ActorTestMixin


def f0(a, b):
    pass


def f0_discount(request, a, b):
    pass


def f1(a, b=0):
    pass


def f2(a, **kwargs):
    # This fails curretly
    pass


def arity_check(func, *args, **kwargs):
    discount = kwargs.pop('discount', 0)
    return checkarity(func, args, kwargs, discount=discount)


class TestArityCheck(unittest.TestCase):

    def testArity0(self):
        self.assertEqual(arity_check(f0, 3, 4), None)
        self.assertEqual(arity_check(f0, 3),
                         '"f0" takes 2 parameters. 1 given.')
        self.assertEqual(arity_check(f0),
                         '"f0" takes 2 parameters. 0 given.')
        self.assertEqual(arity_check(f0, 4, 5, 6),
                         '"f0" takes 2 parameters. 3 given.')
        self.assertEqual(arity_check(f0, a=3, b=5), None)
        self.assertEqual(arity_check(f0, a=3, c=5),
                         '"f0" has missing "b" parameter.')
        self.assertEqual(arity_check(f0, a=3, c=5, d=6),
                         '"f0" takes 2 parameters. 3 given.')

    def testArity0WidthDiscount(self):
        f0 = f0_discount
        fname = f0.__name__
        self.assertEqual(arity_check(f0, 3, 4, discount=1), None)
        self.assertEqual(arity_check(f0, 3, discount=1),
                         '"%s" takes 2 parameters. 1 given.' % fname)
        self.assertEqual(arity_check(f0, discount=1),
                         '"%s" takes 2 parameters. 0 given.' % fname)
        self.assertEqual(arity_check(f0, 4, 5, 6, discount=1),
                         '"%s" takes 2 parameters. 3 given.' % fname)
        self.assertEqual(arity_check(f0, a=3, b=5, discount=1), None)
        self.assertEqual(arity_check(f0, a=3, c=5, discount=1),
                         '"%s" has missing "b" parameter.' % fname)
        self.assertEqual(arity_check(f0, a=3, c=5, d=6, discount=1),
                         '"%s" takes 2 parameters. 3 given.' % fname)

    def testArity1(self):
        self.assertEqual(checkarity(f1, (3,), {}), None)
        self.assertEqual(checkarity(f1, (3, 4), {}), None)
        self.assertEqual(checkarity(f1, (), {}),
                         '"f1" takes at least 1 parameters. 0 given.')
        self.assertEqual(checkarity(f1, (4, 5, 6), {}),
                         '"f1" takes at most 2 parameters. 3 given.')
        self.assertEqual(checkarity(f1, (), {'a': 3, 'b': 5}), None)
        self.assertEqual(checkarity(f1, (), {'a': 3, 'c': 5}),
                         '"f1" does not accept "c" parameter.')
        self.assertEqual(checkarity(f1, (), {'a': 3, 'c': 5, 'd': 6}),
                         '"f1" takes at most 2 parameters. 3 given.')

    def testArity2(self):
        self.assertEqual(checkarity(f2, (3,), {}), None)
        self.assertEqual(checkarity(f2, (3,), {'c': 4}), None)
        self.assertEqual(checkarity(f2, (3, 4), {}),
                         '"f2" takes 1 positional parameters. 2 given.')
        self.assertEqual(checkarity(f2, (), {}),
                         '"f2" takes at least 1 parameters. 0 given.')
        self.assertEqual(checkarity(f2, (4, 5, 6), {}),
                         '"f2" takes 1 positional parameters. 3 given.')
        self.assertEqual(checkarity(f2, (), {'a': 3, 'b': 5}), None)
        self.assertEqual(checkarity(f2, (), {'a': 3, 'c': 5}), None)
        self.assertEqual(checkarity(f2, (), {'b': 3, 'c': 5}),
                         '"f2" has missing "a" parameter.')
        self.assertEqual(checkarity(f2, (), {'a': 3, 'c': 5, 'd': 6}), None)


class TestPidfile(ActorTestMixin, unittest.TestCase):
    concurrency = 'process'

    def testCreate(self):
        proxy = yield self.spawn_actor(name='pippo')
        info = yield send(proxy, 'info')
        result = info['actor']
        self.assertTrue(result['is_process'])
        pid = result['process_id']
        #
        p = Pidfile()
        self.assertEqual(p.fname, None)
        self.assertEqual(p.pid, None)
        p.create(pid)
        self.assertTrue(p.fname)
        self.assertEqual(p.pid, pid)
        p1 = Pidfile(p.fname)
        self.assertRaises(RuntimeError, p1.create, p.pid+1)
        #
        p1 = Pidfile('bla/ksdcskcbnskcdbskcbksdjcb')
        self.assertRaises(RuntimeError, p1.create, p.pid+1)
        p1.unlink()
        p.unlink()
        self.assertFalse(os.path.exists(p.fname))


class TestSystemInfo(unittest.TestCase):

    def testMe(self):
        worker = get_actor()
        info = system.process_info(worker.pid)
        info2 = system.process_info()
        self.assertTrue(isinstance(info, dict))


class TestFunctions(unittest.TestCase):

    def test_convert_bytes(self):
        from pulsar.utils.system import convert_bytes
        self.assertEqual(convert_bytes(None), '#NA')
        self.assertEqual(convert_bytes(4), '4B')
        self.assertEqual(convert_bytes(1024),    '1.0KB')
        self.assertEqual(convert_bytes(1024**2), '1.0MB')
        self.assertEqual(convert_bytes(1024**3), '1.0GB')
        self.assertEqual(convert_bytes(1024**4), '1.0TB')
        self.assertEqual(convert_bytes(1024**5), '1.0PB')
        self.assertEqual(convert_bytes(1024**6), '1.0EB')
        self.assertEqual(convert_bytes(1024**7), '1.0ZB')
        self.assertEqual(convert_bytes(1024**8), '1.0YB')

    def test_nice_number(self):
        self.assertEqual(nice_number(0), 'zero')
        self.assertEqual(nice_number(1), 'one')
        self.assertEqual(nice_number(2), 'two')
        self.assertEqual(nice_number(1, 'bla'), 'one bla')
        self.assertEqual(nice_number(10, 'bla'), 'ten blas')
        self.assertEqual(nice_number(23, 'bla', 'blax'), 'twenty three blax')

    def test_nice_number_large(self):
        self.assertEqual(nice_number(100), 'one hundred')
        self.assertEqual(nice_number(203), 'two hundred and three')
        self.assertEqual(nice_number(4210),
                         'four thousand, two hundred and ten')
        self.assertEqual(nice_number(51345618),
                         'fifty one million, three hundred forty five '
                         'thousand, six hundred and eighteen')

########NEW FILE########
__FILENAME__ = accept
import unittest

from pulsar.apps.wsgi import WsgiRequest


class AcceptTests(unittest.TestCase):

    def test_empty_mime(self):
        environ = {}
        a = WsgiRequest(environ)
        content_types = a.content_types
        self.assertFalse(content_types)

    def test_content_types(self):
        environ = {'HTTP_ACCEPT': ('text/html, application/xhtml+xml, '
                                   'application/xml;q=0.9, */*;q=0.8')}
        a = WsgiRequest(environ)
        content_types = a.content_types
        self.assertTrue(content_types)
        self.assertEqual(len(content_types), 4)
        self.assertEqual(id(content_types), id(a.content_types))
        self.assertTrue('text/html' in content_types)
        self.assertTrue('text/plain' in content_types)
        self.assertEqual(content_types.quality('text/html'), 1)
        self.assertEqual(content_types.quality('text/plain'), 0.8)
        self.assertEqual(content_types.quality('application/json'), 0.8)
        self.assertEqual(content_types.best, 'text/html')

    def test_best(self):
        environ = {'HTTP_ACCEPT': ('text/html, application/xhtml+xml, '
                                   'application/xml;q=0.9, */*;q=0.8')}
        a = WsgiRequest(environ)
        content_types = a.content_types
        self.assertTrue(content_types)
        self.assertEqual(content_types.best_match(('text/html',
                                                   'application/json')),
                         'text/html')
        self.assertEqual(content_types.best_match(('application/json',
                                                   'text/html')),
                         'text/html')

########NEW FILE########
__FILENAME__ = content
import unittest
from asyncio import Future

from pulsar.apps import wsgi
from pulsar.utils.system import json


class TestAsyncContent(unittest.TestCase):

    def test_string(self):
        a = wsgi.AsyncString('Hello')
        self.assertEqual(a.render(), 'Hello')
        self.assertRaises(RuntimeError, a.render)

    def test_simple_json(self):
        response = wsgi.Json({'bla': 'foo'})
        self.assertEqual(len(response.children), 1)
        self.assertEqual(response.content_type,
                         'application/json; charset=utf-8')
        self.assertFalse(response.as_list)
        self.assertEqual(response.render(), json.dumps({'bla': 'foo'}))

    def test_simple_json_as_list(self):
        response = wsgi.Json({'bla': 'foo'}, as_list=True)
        self.assertEqual(len(response.children), 1)
        self.assertEqual(response.content_type,
                         'application/json; charset=utf-8')
        self.assertTrue(response.as_list)
        self.assertEqual(response.render(), json.dumps([{'bla': 'foo'}]))

    def test_json_with_async_string(self):
        astr = wsgi.AsyncString('ciao')
        response = wsgi.Json({'bla': astr})
        self.assertEqual(len(response.children), 1)
        self.assertEqual(response.content_type,
                         'application/json; charset=utf-8')
        self.assertEqual(response.render(), json.dumps({'bla': 'ciao'}))

    def test_json_with_async_string2(self):
        d = Future()
        astr = wsgi.AsyncString(d)
        response = wsgi.Json({'bla': astr})
        self.assertEqual(len(response.children), 1)
        result = response.render()
        self.assertIsInstance(result, Future)
        d.set_result('ciao')
        result = yield result
        self.assertEqual(result, json.dumps({'bla': 'ciao'}))

    def test_append_self(self):
        root = wsgi.AsyncString()
        self.assertEqual(root.parent, None)
        root.append(root)
        self.assertEqual(root.parent, None)
        self.assertEqual(len(root.children), 0)

    def test_append(self):
        root = wsgi.AsyncString()
        child1 = wsgi.AsyncString()
        child2 = wsgi.AsyncString()
        root.append(child1)
        self.assertEqual(child1.parent, root)
        self.assertEqual(len(root.children), 1)
        root.prepend(child2)
        self.assertEqual(child2.parent, root)
        self.assertEqual(len(root.children), 2)

    def test_append_parent(self):
        root = wsgi.AsyncString()
        child1 = wsgi.AsyncString()
        child2 = wsgi.AsyncString()
        root.append(child1)
        root.append(child2)
        self.assertEqual(len(root.children), 2)
        child1.append(root)
        self.assertEqual(child1.parent, None)
        self.assertEqual(root.parent, child1)
        self.assertEqual(len(root.children), 1)
        self.assertEqual(len(child1.children), 1)

    def test_append_parent_with_parent(self):
        root = wsgi.AsyncString()
        child1 = wsgi.AsyncString()
        child2 = wsgi.AsyncString()
        child3 = wsgi.AsyncString()
        root.append(child1)
        child1.append(child2)
        child1.append(child3)
        self.assertEqual(len(root.children), 1)
        self.assertEqual(len(child1.children), 2)
        child2.append(child1)
        self.assertEqual(len(root.children), 1)
        self.assertEqual(root.children[0], child2)
        self.assertEqual(len(child2.children), 1)
        self.assertEqual(child1.parent, child2)
        self.assertEqual(child2.parent, root)

    def test_change_parent(self):
        root = wsgi.AsyncString()
        child1 = wsgi.AsyncString()
        child2 = wsgi.AsyncString()
        child3 = wsgi.AsyncString()
        root.append(child1)
        child1.append(child2)
        child1.append(child3)
        self.assertEqual(len(root.children), 1)
        self.assertEqual(len(child1.children), 2)
        root.append(child3)
        self.assertEqual(len(root.children), 2)
        self.assertEqual(len(child1.children), 1)

    def test_remove_valueerror(self):
        root = wsgi.AsyncString()
        child1 = wsgi.AsyncString()
        self.assertEqual(len(root.children), 0)
        root.remove(child1)
        self.assertEqual(len(root.children), 0)
        child1.append_to(root)
        self.assertEqual(len(root.children), 1)
        self.assertEqual(child1.parent, root)

    def test_remove_all(self):
        root = wsgi.Html('div')
        child1 = wsgi.Html('div')
        root.append(child1)
        root.append('ciao')
        self.assertEqual(len(root.children), 2)
        root.remove_all()
        self.assertEqual(len(root.children), 0)

    def test_media_path(self):
        media = wsgi.Scripts('/media/',
                             known_libraries={'jquery':
                                              'http://bla.foo/jquery'})
        self.assertTrue(media.is_relative('bla/test.js'))
        path = media.absolute_path('bla/foo.js')
        self.assertEqual(path, '/media/bla/foo.js')
        self.assertEqual(media.absolute_path('/bla/foo.js'), '/bla/foo.js')
        self.assertEqual(media.absolute_path('jquery'),
                         'http://bla.foo/jquery.js')

    def test_media_minified(self):
        media = wsgi.Css('/media/', minified=True)
        self.assertEqual(media.absolute_path('bla/foo.css'),
                         '/media/bla/foo.min.css')
        self.assertEqual(media.absolute_path('bla/foo.min.css'),
                         '/media/bla/foo.min.css')

    def test_html_doc_media(self):
        doc = wsgi.HtmlDocument(media_path='/foo/')
        self.assertEqual(doc.head.scripts.media_path, '/foo/')
        self.assertEqual(doc.head.links.media_path, '/foo/')
        doc.head.title = 'ciao'
        doc.head.media_path = '/assets/'
        self.assertEqual(doc.head.title, 'ciao')
        self.assertEqual(doc.head.scripts.media_path, '/assets/')
        self.assertEqual(doc.head.links.media_path, '/assets/')

########NEW FILE########
__FILENAME__ = html
import unittest

from pulsar.apps import wsgi


class TestHtmlFactory(unittest.TestCase):

    def test_html_factory(self):
        input = wsgi.html_factory('input', type='text')
        h = input(value='bla')
        self.assertTrue(h)
        self.assertEqual(h.attr('value'), 'bla')
        self.assertEqual(h.attr('type'), 'text')
        text = h.render()
        self.assertTrue(" type='text'" in text)
        self.assertTrue(" value='bla'" in text)


class TestAttributes(unittest.TestCase):

    def testEmpty(self):
        c = wsgi.Html('div')
        self.assertEqual(c._attr, None)
        self.assertEqual(c._classes, None)
        self.assertEqual(c._data, None)
        self.assertEqual(c._css, None)

    def testHtmlRepr(self):
        c = wsgi.Html('div', cn='bla', charset='utf-16')
        self.assertEqual(c.content_type, 'text/html; charset=utf-16')
        self.assertEqual(str(c), "<div class='bla'>")
        c = wsgi.Html(None, cn='bla')
        self.assertEqual(c.tag, None)
        self.assertEqual(str(c), "Html")

    def testClass(self):
        c = wsgi.Html('div').addClass('ciao').addClass('pippo')
        self.assertTrue(c.hasClass('ciao'))
        self.assertTrue(c.hasClass('pippo'))
        f = c.flatatt()
        self.assertTrue(f in (" class='ciao pippo'",
                              " class='pippo ciao'"))
        c = wsgi.Html('div').addClass('ciao pippo bla')
        self.assertTrue(c.hasClass('bla'))

    def testClassList(self):
        c = wsgi.Html('div', cn=['ciao', 'pippo', 'ciao'])
        self.assertEqual(len(c._classes), 2)
        self.assertTrue('ciao' in c._classes)
        self.assertTrue('pippo' in c._classes)
        self.assertTrue(c.hasClass('pippo'))

    def testRemoveClass(self):
        c = wsgi.Html('div', cn=['ciao', 'pippo', 'ciao', 'foo'])
        self.assertEqual(len(c._classes), 3)
        c.removeClass('sdjkcbhjsd smdhcbjscbsdcsd')
        self.assertEqual(len(c._classes), 3)
        c.removeClass('ciao sdjkbsjc')
        self.assertEqual(len(c._classes), 2)
        c.removeClass('pippo foo')
        self.assertEqual(len(c._classes), 0)

    def testData(self):
        c = wsgi.Html('div')
        c.data('food', 'pasta').data('city', 'Rome')
        self.assertEqual(c.data('food'), 'pasta')
        self.assertEqual(c.data('city'), 'Rome')
        f = c.flatatt()
        self.assertTrue(f in (" data-food='pasta' data-city='Rome'",
                              " data-city='Rome' data-food='pasta'"))
        c.data('food', 'risotto')
        self.assertEqual(c.data('food'), 'risotto')

    def testNestedData(self):
        random = ['bla', 3, 'foo']
        table = {'name': 'path',
                 'resizable': True}
        c = wsgi.Html('div')
        r = c.data({'table': table, 'random': random})
        self.assertEqual(r, c)
        self.assertEqual(c.data('table')['name'], 'path')
        self.assertEqual(c.data('table')['resizable'], True)
        self.assertEqual(c.data('random')[0], 'bla')
        attr = c.flatatt()
        self.assertTrue('data-table' in attr)
        c.data('table', {'resizable': False, 'rows': 40})
        self.assertEqual(c.data('table')['name'], 'path')
        self.assertEqual(c.data('table')['resizable'], False)
        self.assertEqual(c.data('table')['rows'], 40)

    def testEmptyAttr(self):
        c = wsgi.Html('input', type='text')
        c.attr('value', None)
        self.assertEqual(c.attr('value'), None)
        self.assertEqual(c.flatatt(), " type='text'")
        c.attr('value', '')
        self.assertEqual(c.attr('value'), '')
        self.assertTrue(" value=''" in c.flatatt())
        c.attr('value', 0)
        self.assertTrue(" value='0'" in c.flatatt())
        self.assertEqual(c.attr('value'), 0)

    def test_option_empty_attribute(self):
        opt = wsgi.Html('option', '--------', value='')
        self.assertEqual(opt.attr('value'), '')
        text = opt.render()
        self.assertTrue(" value=''" in text)

    def test_textarea_value_attribute(self):
        opt = wsgi.Html('textarea', 'Hello World!')
        self.assertEqual(opt.attr('value'), None)
        self.assertEqual(opt.get_form_value(), 'Hello World!')
        text = opt.render()
        self.assertTrue("Hello World!" in text)

    def testHide(self):
        c = wsgi.Html('div', 'foo').hide()
        self.assertEqual(c.flatatt(), " style='display:none;'")
        c.show()
        self.assertEqual(c.flatatt(), "")


class TestWidgets(unittest.TestCase):

    def testAncor(self):
        a = wsgi.Html('a', 'kaput', cn='bla', href='/abc/')
        self.assertEqual(a.attr('href'), '/abc/')
        ht = a.render()
        self.assertTrue('>kaput</a>' in ht)
        a = wsgi.Html('a', xxxx='ciao')
        self.assertFalse('xxxx' in a.attr())
        self.assertEqual(a.data('xxxx'), 'ciao')

    def testList(self):
        ul = wsgi.Html('ul')
        self.assertEqual(ul.tag, 'ul')
        self.assertEqual(len(ul.children), 0)
        ul = wsgi.Html('ul', 'a list item', 'another one')
        self.assertEqual(len(ul.children), 2)
        ht = ul.render()
        self.assertTrue('<ul>' in ht)
        self.assertTrue('</ul>' in ht)
        self.assertTrue('<li>a list item</li>' in ht)
        self.assertTrue('<li>another one</li>' in ht)


class TestHtmlDocument(unittest.TestCase):

    def testSimple(self):
        html = wsgi.HtmlDocument()
        self.assertEqual(len(html.head.children), 4)
        self.assertEqual(len(html.body.children), 0)

    def testHead(self):
        html = wsgi.HtmlDocument()
        head = html.head
        self.assertTrue(head.meta)
        self.assertTrue(head.links)
        self.assertTrue(head.scripts)

    def testMeta(self):
        html = wsgi.HtmlDocument()
        meta = html.head.meta
        self.assertEqual(len(meta.children), 1)
        self.assertEqual(meta.tag, None)
        html.head.add_meta(name='bla')
        self.assertEqual(len(meta.children), 2)
        text = meta.render()
        self.assertEqual(text, "<meta charset='utf-8'><meta name='bla'>")


class TestMedia(unittest.TestCase):

    def testEmptyHtml(self):
        m = wsgi.HtmlDocument(title='test', bla='foo')
        self.assertTrue(m.head)
        self.assertTrue(m.body)
        self.assertEqual(m.head.title, 'test')
        txt = m.render()
        self.assertEqual(txt,
                         ''.join(['<!DOCTYPE html>\n',
                                  "<html data-bla='foo'>\n",
                                  '<head>',
                                  '<title>test</title>'
                                  "<meta charset='utf-8'>",
                                  '</head>\n'
                                  '<body>',
                                  '</body>\n',
                                  '</html>']))

    def testHtml(self):
        m = wsgi.HtmlDocument(title='test')
        m.body.append(wsgi.Html('div', 'this is a test'))
        txt = m.render()
        self.assertEqual(txt,
                         ''.join(['<!DOCTYPE html>\n',
                                  '<html>\n',
                                  '<head>',
                                  '<title>test</title>'
                                  "<meta charset='utf-8'>",
                                  '</head>\n'
                                  '<body>',
                                  '<div>this is a test</div>',
                                  '</body>\n',
                                  '</html>']))

########NEW FILE########
__FILENAME__ = route
import unittest

from pulsar.apps.wsgi import Route


class Routes(unittest.TestCase):

    def testRoot(self):
        r = Route('/')
        self.assertFalse(r.is_leaf)
        self.assertEqual(r.rule, '')
        r = Route('////')
        self.assertFalse(r.is_leaf)
        self.assertEqual(r.rule, '')
        self.assertEqual(r.match(''), {})
        self.assertEqual(r.match('bee/'), {'__remaining__': 'bee/'})

    def testSimple(self):
        r = Route('bla/')
        self.assertFalse(r.is_leaf)
        self.assertEqual(r.level, 1)
        self.assertEqual(len(r.variables), 0)
        self.assertEqual(r.rule, 'bla/')
        self.assertEqual(r.match('bla/'), {})
        self.assertEqual(r.match('bladdd/'), None)
        self.assertEqual(r.match('bla/another/'),
                         {'__remaining__': 'another/'})

    def testSimpleLevel2(self):
        r = Route('bla/foo/')
        self.assertFalse(r.is_leaf)
        self.assertEqual(r.level, 2)
        self.assertEqual(len(r.variables), 0)
        self.assertEqual(r.rule, 'bla/foo/')
        self.assertEqual(r.match('bla/'), None)
        self.assertEqual(r.match('bla/foo/'), {})
        self.assertEqual(r.match('bla/fooddd/'), None)
        self.assertEqual(r.match('bla/foo/another/'),
                         {'__remaining__': 'another/'})

    def testMalformedRule1(self):
        self.assertRaises(ValueError, Route, '<bla')
        self.assertRaises(ValueError, Route, '<bla/')
        self.assertRaises(ValueError, Route, 'bla>/')
        self.assertRaises(ValueError, Route, '/<bla')

    def testMalformedRule2(self):
        self.assertRaises(ValueError, Route, '<foo>/<bla')
        self.assertRaises(ValueError, Route, 'ciao/<bla/')
        self.assertRaises(ValueError, Route, 'ahhh>/bla>/')
        self.assertRaises(ValueError, Route, 'ahhh/bla>/')

    def testMalformedRule3(self):
        self.assertRaises(ValueError, Route, '<foo>/<foo>')
        self.assertRaises(ValueError, Route, '<foo>/bla/<foo>')
        self.assertRaises(ValueError, Route, '<foo>/<bla>/<foo>')

    def testStringVariable(self):
        r = Route('<name>/')
        self.assertFalse(r.is_leaf)
        self.assertEqual(r.variables, set(['name']))
        self.assertEqual(r.breadcrumbs, ((True, 'name'),))
        self.assertEqual(r.rule, '<name>/')
        self.assertEqual(r.match('bla-foo/'), {'name': 'bla-foo'})
        self.assertEqual(r.match('bla/another/'),
                         {'name': 'bla', '__remaining__': 'another/'})
        self.assertEqual(r.url(name='luca'), '/luca/')

    def test2StringVariables(self):
        r = Route('<name>/<child>/')
        self.assertFalse(r.is_leaf)
        self.assertEqual(r.level, 2)
        self.assertEqual(r.variables, set(['name', 'child']))
        self.assertEqual(r.breadcrumbs, ((True, 'name'), (True, 'child')))
        self.assertEqual(r.rule, '<name>/<child>/')
        self.assertEqual(r.match('bla/foo/'), {'name': 'bla', 'child': 'foo'})
        self.assertEqual(r.match('bla/foo/another/'),
                         {'name': 'bla',
                          'child': 'foo',
                          '__remaining__': 'another/'})
        self.assertRaises(KeyError, r.url, name='luca')
        self.assertEqual(r.url(name='luca', child='joshua'), '/luca/joshua/')

    def testAddDirLeaf(self):
        r = Route('bla/')
        self.assertFalse(r.is_leaf)
        r2 = Route('foo')
        self.assertTrue(r2.is_leaf)
        r3 = r + r2
        self.assertEqual(r3.rule, 'bla/foo')
        self.assertTrue(r3.is_leaf)

    def testIntVariable(self):
        r = Route('<int:id>/')
        self.assertEqual(str(r), '/<int:id>/')
        self.assertEqual(r.variables, set(['id']))
        self.assertEqual(r.breadcrumbs, ((True, 'id'),))
        self.assertEqual(r.match('35/'), {'id': 35})
        self.assertEqual(r.url(id=1), '/1/')
        self.assertRaises(ValueError, r.url, id='bla')

    def testIntVariableFixDigits(self):
        r = Route('<int(2):id>/')
        self.assertEqual(str(r), '/<int(2):id>/')
        self.assertEqual(r.variables, set(['id']))
        self.assertEqual(r.breadcrumbs, ((True, 'id'),))
        self.assertEqual(r.match('35/'), {'id': 35})
        self.assertEqual(r.match('355/'), None)
        self.assertEqual(r.match('6/'), None)
        self.assertEqual(r.match('ch/'), None)
        self.assertEqual(r.url(id=13), '/13/')
        self.assertEqual(r.url(id=1), '/01/')
        self.assertRaises(ValueError, r.url, id=134)
        self.assertRaises(ValueError, r.url, id='bl')
        self.assertRaises(ValueError, r.url, id='bla')

    def testIntVariableMinMax(self):
        r = Route('<int(min=1):cid>/')
        self.assertEqual(str(r), '/<int(min=1):cid>/')
        self.assertEqual(r.variables, set(['cid']))
        self.assertEqual(r.breadcrumbs, ((True, 'cid'),))
        self.assertEqual(r.match('1/'), {'cid': 1})
        self.assertEqual(r.match('476876/'), {'cid': 476876})
        self.assertEqual(r.match('0/'), None)
        self.assertEqual(r.match('-5/'), None)
        self.assertEqual(r.url(cid=13), '/13/')
        self.assertEqual(r.url(cid=1), '/1/')
        self.assertRaises(ValueError, r.url, cid=0)
        self.assertRaises(ValueError, r.url, cid=-10)
        self.assertRaises(ValueError, r.url, cid='bla')

    def testPathVaiable(self):
        r = Route('bla/<path:rest>', defaults={'rest': ''})
        self.assertEqual(r.variables, set(['rest']))
        self.assertEqual(r.level, 2)
        self.assertTrue(r.is_leaf)
        self.assertEqual(r.match('bla/a/b/c.html'), {'rest': 'a/b/c.html'})
        self.assertEqual(r.match('bla/'), {'rest': ''})
        self.assertEqual(r.url(rest='a/'), '/bla/a/')
        self.assertEqual(r.url(), '/bla/')

    def testSplitRoot(self):
        r = Route('')
        self.assertEqual(r.level, 0)
        p, l = r.split()
        self.assertFalse(p.is_leaf)
        self.assertEqual(p.path, '/')
        self.assertEqual(l, None)
        r = Route('bla')
        p, l = r.split()
        self.assertFalse(p.is_leaf)
        self.assertTrue(l.is_leaf)
        self.assertEqual(p.path, '/')
        self.assertEqual(l.path, '/bla')
        r = Route('bla/')
        p, l = r.split()
        self.assertFalse(p.is_leaf)
        self.assertFalse(l.is_leaf)
        self.assertEqual(p.path, '/')
        self.assertEqual(l.path, '/bla/')

    def testSplitDir(self):
        r = Route('bla/foo/<id>/pluto/')
        self.assertEqual(r.level, 4)
        p, l = r.split()
        self.assertFalse(p.is_leaf)
        self.assertFalse(l.is_leaf)
        self.assertEqual(p.path, '/bla/foo/<id>/')
        self.assertEqual(l.path, '/pluto/')

    def testSplitLeaf(self):
        r = Route('bla/foo/<id>/pluto/leaf')
        p, l = r.split()
        self.assertFalse(p.is_leaf)
        self.assertTrue(l.is_leaf)
        self.assertEqual(p.path, '/bla/foo/<id>/pluto/')
        self.assertEqual(l.path, '/leaf')

    def testDefaults(self):
        r = Route('bla/<id>/add/<path:path>', {'path': ''})
        self.assertEqual(r.url(id=10), '/bla/10/add/')
        self.assertEqual(r.url(id=10, path='ciao/luca'),
                         '/bla/10/add/ciao/luca')

    def testDefaultsAddition(self):
        r = Route('add/<path:path>', {'path': ''})
        r2 = Route('bla/<id>/') + r
        self.assertEqual(r2.defaults, r.defaults)

    def test_add_string(self):
        r = Route('add/<path:path>', {'path': 'foo'})
        r2 = r + 'bla'
        self.assertEqual(r2.rule, 'add/<path:path>/bla')
        self.assertEqual(str(r2), '/add/<path:path>/bla')
        self.assertNotEqual(r2, '/add/<path:path>/bla')

    def test_empty_url(self):
        r = Route('')
        self.assertEqual(r.rule, '')
        self.assertEqual(r.url(), '/')
        self.assertEqual(r.path, '/')

########NEW FILE########
__FILENAME__ = router
'''Tests the wsgi middleware in pulsar.apps.wsgi'''
import unittest

import pulsar
from pulsar.apps.wsgi import Router, RouterParam, route

from examples.httpbin.manage import HttpBin


class HttpBin2(HttpBin):

    def gzip(self):
        pass    # switch off gzip handler, it is not a route anymore

    @route('get2')
    def _get(self, request):    # override the _get handler
        raise pulsar.Http404

    @route('async', async=True)
    def test_async_route(self, request):
        yield 'Hello'

    @route('async', async=True, method='post')
    def test_async_route_post(self, request):
        yield 'Hello'


class HttpBin3(HttpBin):

    @route('new', position=0)
    def new(self, request):
        return self.info_data_response(request)

    @route('post', method='post', title='Returns POST data', position=-1)
    def _post(self, request):
        return self.info_data_response(request)


class TestRouter(unittest.TestCase):

    def router(self, path='/'):
        class testRouter(Router):
            response_content_types = RouterParam(('text/html',
                                                  'text/plain',
                                                  'application/json'))

            def get(self, request):
                return 'Hello World!'

            @route()
            def bla(self, request):
                return 'This is /bla route'

            @route('/foo')
            def xxx(self, request):
                return 'This is /foo route'

            @route()
            def post_pluto(self, request):
                return 'This is /pluto POST route'

        router = testRouter(path)
        self.assertEqual(len(router.routes), 3)
        return router

    def test_router(self):
        router = self.router()
        self.assertEqual(router.route.path, '/')
        handler, urlargs = router.resolve('')
        self.assertEqual(handler, router)
        self.assertEqual(urlargs, {})
        #
        handler, urlargs = router.resolve('bla')
        self.assertNotEqual(handler, router)
        self.assertEqual(urlargs, {})

    def test_derived(self):
        self.assertTrue('gzip' in HttpBin.rule_methods)
        self.assertFalse('gzip' in HttpBin2.rule_methods)

    def test_async_route(self):
        self.assertTrue('test_async_route' in HttpBin2.rule_methods)
        method = HttpBin2.rule_methods['test_async_route']
        self.assertEqual(method[2].get('async'), True)
        app = HttpBin2('/')
        router, args = app.resolve('async')
        self.assertFalse(args)
        get = router.get
        post = router.post

    def test_override(self):
        self.assertTrue('_get' in HttpBin.rule_methods)
        self.assertEqual(HttpBin.rule_methods['_get'][0].rule, 'get')
        self.assertTrue('_get' in HttpBin2.rule_methods)
        self.assertEqual(HttpBin2.rule_methods['_get'][0].rule, 'get2')
        # The position in the ordered dict should be the same too
        all = list(HttpBin.rule_methods)
        all2 = list(HttpBin2.rule_methods)
        self.assertEqual(all2.index('_get'), all.index('_get'))

    def test_override_change_position(self):
        self.assertTrue('_post' in HttpBin.rule_methods)
        self.assertEqual(HttpBin.rule_methods['_post'][0].rule, 'post')
        self.assertTrue('_get' in HttpBin3.rule_methods)
        self.assertEqual(HttpBin3.rule_methods['_post'][0].rule, 'post')
        # The position in the ordered dict should be the same too
        all = list(HttpBin.rule_methods)
        all3 = list(HttpBin3.rule_methods)
        self.assertEqual(all3.index('new'), 1)
        self.assertTrue(all3.index('_post') < all.index('_post'))

    def test_accept(self):
        router = self.router()
        self.assertEqual(router.accept_content_type('text/html'), 'text/html')
        self.assertEqual(router.accept_content_type('text/*'), 'text/html')
        self.assertEqual(router.accept_content_type('text/plain'),
                         'text/plain')
        self.assertEqual(router.accept_content_type('*/*'), 'text/html')
        self.assertEqual(router.accept_content_type('application/*'),
                         'application/json')
        self.assertEqual(router.accept_content_type('application/json'),
                         'application/json')
        self.assertEqual(router.accept_content_type('application/javascript'),
                         None)

    def test_path_method(self):
        router = Router('/root',
                        Router('a', get=lambda r: ['route a']))
        self.assertEqual(router.path(), '/root')
        self.assertEqual(router.route.is_leaf, True)
        child, args = router.resolve('root/a')
        self.assertFalse(args)
        self.assertEqual(child.parent, router)
        self.assertEqual(child.path(), '/root/a')

########NEW FILE########
__FILENAME__ = wsgi
'''Tests the wsgi middleware in pulsar.apps.wsgi'''
import time
import sys
import unittest
from datetime import datetime, timedelta

import pulsar
from pulsar import Http404
from pulsar.utils.pep import range, zip, pickle
from pulsar.apps import wsgi
from pulsar.apps import http
from pulsar.utils.multipart import parse_form_data, MultipartError
from pulsar.utils.httpurl import urlparse, unquote
from pulsar.apps.wsgi.utils import cookie_date


class WsgiRequestTests(unittest.TestCase):

    def request(self, **kwargs):
        environ = wsgi.test_wsgi_environ(**kwargs)
        return wsgi.WsgiRequest(environ)

    def test_is_secure(self):
        request = self.request(secure=True)
        self.assertTrue(request.is_secure)
        self.assertEqual(request.environ['HTTPS'], 'on')
        self.assertEqual(request.environ['wsgi.url_scheme'], 'https')

    def test_parse_form_data(self):
        environ = wsgi.test_wsgi_environ()
        self.assertRaises(MultipartError, parse_form_data, environ,
                          strict=True)
        environ = wsgi.test_wsgi_environ(method='POST')
        self.assertRaises(MultipartError, parse_form_data, environ,
                          strict=True)

    def test_get_host(self):
        request = self.request(headers=[('host', 'blaa.com')])
        self.assertEqual(request.get_host(), 'blaa.com')

    def test_full_path(self):
        request = self.request(headers=[('host', 'blaa.com')])
        self.assertEqual(request.full_path(), '/')
        self.assertEqual(request.full_path('/foo'), '/foo')

    def test_full_path_query(self):
        request = self.request(path='/bla?path=foo&id=5')
        self.assertEqual(request.path, '/bla')
        self.assertEqual(request.url_data, {'path': 'foo', 'id': '5'})
        self.assertTrue(request.full_path() in ('/bla?path=foo&id=5',
                                                '/bla?id=5&path=foo'))
        self.assertEqual(request.full_path(g=7), '/bla?g=7')

    def test_url_handling(self):
        target = '/\N{SNOWMAN}'
        request = self.request(path=target)
        path = urlparse(request.path).path
        self.assertEqual(path, target)

    def testResponse200(self):
        r = wsgi.WsgiResponse(200)
        self.assertEqual(r.status_code, 200)
        self.assertEqual(r.status, '200 OK')
        self.assertEqual(r.content, ())
        self.assertFalse(r.is_streamed)
        self.assertFalse(r.started)
        self.assertEqual(list(r), [])
        self.assertTrue(r.started)
        self.assertEqual(str(r), r.status)
        self.assertTrue(repr(r))

    def testResponse500(self):
        r = wsgi.WsgiResponse(500, content=b'A critical error occurred')
        self.assertEqual(r.status_code, 500)
        self.assertEqual(r.status, '500 Internal Server Error')
        self.assertEqual(r.content, (b'A critical error occurred',))
        self.assertFalse(r.is_streamed)
        self.assertFalse(r.started)
        self.assertEqual(list(r), [b'A critical error occurred'])
        self.assertTrue(r.started)

    def testStreamed(self):
        stream = ('line {0}\n'.format(l+1) for l in range(10))
        r = wsgi.WsgiResponse(content=stream)
        self.assertEqual(r.status_code, 200)
        self.assertEqual(r.status, '200 OK')
        self.assertEqual(r.content, stream)
        self.assertTrue(r.is_streamed)
        data = []
        for l, a in enumerate(r):
            data.append(a)
            self.assertTrue(r.started)
            self.assertEqual(a, ('line {0}\n'.format(l+1)).encode('utf-8'))
        self.assertEqual(len(data), 10)

    def testForCoverage(self):
        r = wsgi.WsgiResponse(environ={'PATH_INFO': 'bla/'})
        self.assertEqual(r.path, 'bla/')
        self.assertEqual(r.connection, None)
        self.assertEqual(r.content, ())
        self.assertEqual(list(r), [])
        self.assertRaises(RuntimeError, list, r)

    def test_parse_authorization_header(self):
        parse = wsgi.parse_authorization_header
        self.assertEqual(parse(''), None)
        self.assertEqual(parse('csdcds'), None)
        self.assertEqual(parse('csdcds cbsdjchbjsc'), None)
        self.assertEqual(parse('basic cbsdjcbsjchbsd'), None)
        auths = http.HTTPBasicAuth('pippo', 'pluto').header()
        self.assertTrue(parse(auths).authenticated({}, 'pippo', 'pluto'))

    def testCookies(self):
        response = wsgi.WsgiResponse()
        expires = datetime.now() + timedelta(seconds=3600)
        response.set_cookie('bla', expires=expires)
        self.assertTrue('bla' in response.cookies)

    def testDeleteCookie(self):
        response = wsgi.WsgiResponse()
        response.delete_cookie('bla')
        self.assertTrue('bla' in response.cookies)

    def test_far_expiration(self):
        "Cookie will expire when an distant expiration time is provided"
        response = wsgi.WsgiResponse()
        response.set_cookie('datetime', expires=datetime(2028, 1, 1, 4, 5, 6))
        datetime_cookie = response.cookies['datetime']
        self.assertEqual(datetime_cookie['expires'],
                         'Sat, 01-Jan-2028 04:05:06 GMT')

    def test_max_age_expiration(self):
        "Cookie will expire if max_age is provided"
        response = wsgi.WsgiResponse()
        response.set_cookie('max_age', max_age=10)
        max_age_cookie = response.cookies['max_age']
        self.assertEqual(max_age_cookie['max-age'], 10)
        self.assertEqual(max_age_cookie['expires'],
                         cookie_date(time.time()+10))

    def test_httponly_cookie(self):
        response = wsgi.WsgiResponse()
        response.set_cookie('example', httponly=True)
        example_cookie = response.cookies['example']
        # A compat cookie may be in use -- check that it has worked
        # both as an output string, and using the cookie attributes
        self.assertTrue('; httponly' in str(example_cookie))
        self.assertTrue(example_cookie['httponly'])

    def test_headers(self):
        response = wsgi.WsgiResponse(200)
        response['content-type'] = 'text/plain'
        self.assertTrue('content-type' in response)
        self.assertTrue(response.has_header('content-type'))
        self.assertEqual(response['content-type'], 'text/plain')

    def testBuildWsgiApp(self):
        appserver = wsgi.WSGIServer()
        self.assertEqual(appserver.name, 'wsgi')
        self.assertEqual(appserver.cfg.callable, None)

    def testWsgiHandler(self):
        hnd = wsgi.WsgiHandler(middleware=(wsgi.authorization_middleware,))
        self.assertEqual(len(hnd.middleware), 1)
        hnd2 = pickle.loads(pickle.dumps(hnd))
        self.assertEqual(len(hnd2.middleware), 1)

    def testHttpBinServer(self):
        from examples.httpbin.manage import server
        app = server(bind='127.0.0.1:0')
        app2 = pickle.loads(pickle.dumps(app))

    def test_clean_path_middleware(self):
        url = 'bla//foo'
        try:
            wsgi.clean_path_middleware({'PATH_INFO': url,
                                        'QUERY_STRING': 'page=1'}, None)
        except pulsar.HttpRedirect as e:
            url = e.headers[0][1]
            self.assertEqual(url, '/bla/foo?page=1')

    def test_handle_wsgi_error(self):
        environ = wsgi.test_wsgi_environ(
            extra={'error.handler': lambda request, failure: 'bla'})
        try:
            raise ValueError('just a test')
        except ValueError as exc:
            response = wsgi.handle_wsgi_error(environ, exc)
        self.assertEqual(response.status_code, 500)
        self.assertEqual(response.content, (b'bla',))

    def test_handle_wsgi_error_debug(self):
        cfg = self.cfg.copy()
        cfg.set('debug', True)
        environ = wsgi.test_wsgi_environ(extra={'pulsar.cfg': cfg})
        try:
            raise ValueError('just a test for debug wsgi error handler')
        except ValueError as exc:
            response = wsgi.handle_wsgi_error(environ, exc)
        self.assertEqual(response.status_code, 500)
        self.assertEqual(response.content_type, None)
        self.assertEqual(len(response.content), 1)

    def test_handle_wsgi_error_debug_html(self):
        cfg = self.cfg.copy()
        cfg.set('debug', True)
        headers = [('Accept', '*/*')]
        environ = wsgi.test_wsgi_environ(extra={'pulsar.cfg': cfg},
                                         headers=headers)
        try:
            raise ValueError('just a test for debug wsgi error handler')
        except ValueError as exc:
            response = wsgi.handle_wsgi_error(environ, exc)
        self.assertEqual(response.status_code, 500)
        html = response.content[0]
        self.assertEqual(response.content_type, 'text/html')
        self.assertTrue(html.startswith(b'<!DOCTYPE html>'))
        self.assertTrue(b'<title>500 Internal Server Error</title>' in html)

    def test_wsgi_handler(self):
        handler = wsgi.WsgiHandler()
        try:
            yield handler({}, None)
        except Http404:
            pass
        else:
            assert False

########NEW FILE########
