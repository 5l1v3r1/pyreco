__FILENAME__ = fill_array
#!/usr/bin/env python
"""
This benchmark compares the fill_array Hist method with Python's map() and
NumPy's histogram function.
"""
print __doc__
from rootpy.plotting import Hist
import numpy as np
import cProfile
import timeit


h = Hist(1000, -5, 5)
array = np.random.randn(1E6)

def time_repeat(cmd, repeat=5, number=1):
    best_time = min(
            timeit.repeat(cmd,
                repeat=repeat, number=number,
                setup="from __main__ import h, array, np")) / number
    print "%d loops, best of %d: %fs per loop" % (
            number, repeat, best_time)


print "Using Python's map()..."
cProfile.run('map(h.Fill, array)')

h.Reset()

print "time without profiler overhead:"
time_repeat('map(h.Fill, array)')

h.Reset()

print
print '=' * 40
print

print "Using NumPy's histogram..."
cProfile.run('np.histogram(array)')

h.Reset()

print "time without profiler overhead:"
time_repeat('np.histogram(array)')

h.Reset()

print
print '=' * 40
print

print "Using compiled C extension..."
cProfile.run('h.fill_array(array)')

h.Reset()

print "time without profiler overhead:"
time_repeat('h.fill_array(array)')

########NEW FILE########
__FILENAME__ = read_benchmark
#!/usr/bin/env python
"""
==========================
Comparing read performance
==========================

This example demonstrates differences in read performance with and without
reading branches on demand.
"""
print __doc__
from rootpy.tree import Tree
from rootpy.io import root_open
import random
import string
import time

def random_name(length):
    return ''.join(random.choice(string.ascii_letters) for x in xrange(length))

f = root_open("test.root", "recreate")


def create_tree(num_branches, num_entries):

    branches = dict([(random_name(10), 'F') for x in xrange(num_branches)])
    tree = Tree()
    tree.create_branches(branches)
    # fill the tree with zeros
    for i in xrange(num_entries):
        tree.fill()
    return tree

for on_demand in (False, True):
    for num_branched_read in xrange(1, 50, 10):
        tree = create_tree(1000, 10000)
        names = tree.branchnames
        tree.read_branches_on_demand = on_demand
        tree.SetCacheSize(10000000)
        tree.SetCacheLearnEntries(10)
        read_names = random.sample(names, num_branched_read)
        t0 = time.time()
        # loop on the tree
        for event in tree:
            # getattr the branches
            for name in read_names:
                getattr(tree, name)
            pass
        t1 = time.time()
        print on_demand, num_branched_read, t1 - t0
f.close()

########NEW FILE########
__FILENAME__ = tree_read
#!/usr/bin/env python

# this import is required to register the Tree class
import rootpy.tree
from rootpy.io import root_open
from time import time
from ROOT import TTreeCache
import sys

for cached in (False, True):

    try:
        f = root_open("test.root")
    except IOError:
        sys.exit("test.root does not exist. Please run tree_write.py first.")
    tree = f.test

    if cached:
        TTreeCache.SetLearnEntries(1)
        tree.SetCacheSize(10000000)
    tree.use_cache(cached)

    start_time = time()
    for event in tree:
        event.x
    end_time = time()
    print "%.2fsec to read one branch" % (end_time - start_time)

    start_time = time()
    for event in tree:
        event.x
        event.y
    end_time = time()
    print "%.2fsec to read two branches" % (end_time - start_time)

    start_time = time()
    for event in tree:
        event.x
        event.y
        event.z
    end_time = time()
    print "%.2fsec to read three branches" % (end_time - start_time)

    print "Reading %i bytes in %i transactions" % (f.GetBytesRead(), f.GetReadCalls())
    f.close()

########NEW FILE########
__FILENAME__ = tree_write
#!/usr/bin/env python

from rootpy.tree import Tree, TreeModel
from rootpy.io import root_open
from rootpy.types import FloatCol, ObjectCol
from rootpy.math.physics.vector import LorentzVector
from random import gauss, randint
import ROOT

f = root_open("test.root", "recreate")


# define the model
class Event(TreeModel):

    x = FloatCol()
    y = FloatCol()
    z = FloatCol()

    a = ROOT.vector("float")
    b = ROOT.vector("float")
    c = ROOT.vector("float")

    d = ROOT.vector("vector<float>")
    e = ROOT.vector("vector<float>")
    f = ROOT.vector("vector<float>")

    g = ObjectCol(LorentzVector)

tree = Tree("test", model=Event)

# fill the tree
for i in xrange(50000):
    tree.x = gauss(.5, 1.)
    tree.y = gauss(.3, 2.)
    tree.z = gauss(13., 42.)

    for i in xrange(randint(1, 10)):
        tree.a.push_back(gauss(.5, 1.))
    for i in xrange(randint(1, 10)):
        tree.b.push_back(gauss(.5, 1.))
    for i in xrange(randint(1, 10)):
        tree.c.push_back(gauss(.5, 1.))

    for i in xrange(randint(1, 10)):
        t = ROOT.vector("float")()
        for j in xrange(randint(1, 10)):
            t.push_back(gauss(.5, 1.))
        tree.d.push_back(t)
    for i in xrange(randint(1, 10)):
        t = ROOT.vector("float")()
        for j in xrange(randint(1, 10)):
            t.push_back(gauss(.5, 1.))
        tree.e.push_back(t)
    for i in xrange(randint(1, 10)):
        t = ROOT.vector("float")()
        for j in xrange(randint(1, 10)):
            t.push_back(gauss(.5, 1.))
        tree.f.push_back(t)

    tree.g.SetPtEtaPhiM(2, 2, 2, 2)
    tree.fill(reset=True)
tree.write()

f.close()

########NEW FILE########
__FILENAME__ = create_tree
#!/usr/bin/env python

from rootpy.tree import Tree, TreeModel
from rootpy.io import root_open
from rootpy.types import FloatCol, IntCol
from rootpy.math.physics.vector import LorentzVector
from random import gauss, randint
import ROOT


entries = 1000000
f = root_open("test.root", "recreate")


# define the model
class Event(TreeModel):

    # properties of particle "a"
    a_x = FloatCol()
    a_y = FloatCol()
    a_z = FloatCol()

    # properties of particle "b"
    b_x = FloatCol()
    b_y = FloatCol()
    b_z = FloatCol()

    # a collection of particles
    col_x = ROOT.vector("float")
    col_y = ROOT.vector("float")
    col_z = ROOT.vector("float")
    col_n = IntCol()

    # a TLorentzVector
    p = LorentzVector

    i = IntCol()

tree = Tree("test", model=Event)

# fill the tree
for i in xrange(entries):
    tree.a_x = gauss(.5, 1.)
    tree.a_y = gauss(.3, 2.)
    tree.a_z = gauss(13., 42.)

    tree.b_x = gauss(.5, 1.)
    tree.b_y = gauss(.3, 2.)
    tree.b_z = gauss(13., 42.)

    n = randint(1, 10)
    for j in xrange(n):
        tree.col_x.push_back(gauss(.5, 1.))
        tree.col_y.push_back(gauss(.3, 2.))
        tree.col_z.push_back(gauss(13., 42.))
    tree.col_n = n

    tree.p.SetPtEtaPhiM(gauss(.5, 1.),
                        gauss(.5, 1.),
                        gauss(.5, 1.),
                        gauss(.5, 1.))

    tree.i = i
    tree.fill(reset=True)

tree.write()
f.Close()

########NEW FILE########
__FILENAME__ = test
#!/usr/bin/env python

# this import is required
import rootpy.tree
from rootpy.io import root_open

from rootpy.root2array import tree_to_recarray_py, \
                              tree_to_recarray, \
                              tree_to_ndarray

import cProfile
import time

with root_open('test.root') as f:

    tree = f.test
    branches = ["a_x", "a_y", "a_z"]
    tree.SetWeight(.5)

    print "Using pure Python method..."
    cProfile.run('arr1 = tree_to_recarray_py(tree, branches=branches,'
                 'include_weight=True)')

    print "time without profiler overhead:"
    t1 = time.time()
    arr1 = tree_to_recarray_py(tree, branches=branches,
                               include_weight=True)
    t2 = time.time()
    print "%f seconds" % (t2 - t1)

    print '=' * 40

    print "Using compiled C extension..."
    cProfile.run('arr2 = tree_to_recarray(tree, branches=branches,'
                 'include_weight=True)')

    print "time without profiler overhead:"
    t1 = time.time()
    arr2 = tree_to_recarray(tree, branches=branches,
                            include_weight=True)
    t2 = time.time()
    print "%f seconds" % (t2 - t1)

    print '=' * 40
    print "Comparison of output:"

    print
    print "Python result:"
    print arr1
    print arr1['a_x']
    print arr1['weight']

    print
    print "C result:"
    print arr2
    print arr2['a_x']
    print arr2['weight']

    arr3 = tree_to_ndarray(tree, branches=branches,
                           include_weight=True)

    print
    print "C result as ndarray:"
    print arr3

########NEW FILE########
__FILENAME__ = unique
#!/usr/bin/env python

import cProfile
import time
import numpy as np
from rootpy.io import root_open
from rootpy.root2array import tree_to_ndarray
from rootpy.plotting import Hist
# this import is required
import rootpy.tree

h = Hist(10, 0, 1)


def pyroot(tree):

    tree.Draw('a_x', '', 'goff', hist=h)
    v1 = tree.GetV1()
    return set(v1[n] for n in xrange(tree.GetEntries()))


def rootpy(tree):

    return np.unique(tree_to_ndarray(tree, branches=["a_x"]))


with root_open('test.root') as f:

    tree = f.test
    print "Trees has %i entries" % tree.GetEntries()
    print
    print "Using the ROOT/PyROOT way..."
    cProfile.run('pyroot(tree)')
    print "time without profiler overhead:"
    t1 = time.time()
    a = pyroot(tree)
    t2 = time.time()
    print "%f seconds" % (t2 - t1)
    print
    print '=' * 40
    print
    print "Using compiled C extension and numpy..."
    cProfile.run('rootpy(tree)')
    print "time without profiler overhead:"
    t1 = time.time()
    a = rootpy(tree)
    t2 = time.time()
    print "%f seconds" % (t2 - t1)

########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# rootpy documentation build configuration file, created by
# sphinx-quickstart on Fri Oct 14 23:01:54 2011.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os
from os import path
import datetime
now = datetime.datetime.now()

HERE = path.dirname(path.abspath(__file__))
rootpy_root = path.abspath(path.join(HERE, path.pardir))

execfile(path.join(rootpy_root, 'rootpy', 'info.py'))

# put rootpy at the front of sys.path
sys.path.insert(0, rootpy_root)

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(1, path.join(HERE, 'sphinxext'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.autosummary',
    'sphinx.ext.doctest',
    #'sphinx.ext.intersphinx',
    #'sphinx.ext.todo',
    #'sphinx.ext.coverage',
    #'sphinx.ext.pngmath',
    #'sphinx.ext.ifconfig',
    'sphinx.ext.viewcode',
    'ipython_console_highlighting',
    'numpydoc',
    #'sphinxcontrib.ansi',
    'sphinxcontrib.programoutput',
    ]

#programoutput_use_ansi = True

# Suppress numpydoc warnings as suggested here:
# https://github.com/phn/pytpm/issues/3
numpydoc_show_class_members = False

ON_RTD = os.environ.get('READTHEDOCS', None) == 'True'
if not ON_RTD:
    extensions += ['gen_rst']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['templates']

autodoc_default_flags = ['members']

# generate autosummary even if no references
autosummary_generate = True

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'rootpy'
copyright = u'%d, rootpy developers' % now.year

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = __version__
# The full version, including alpha/beta/rc tags.
release = __version__

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['README*']
exclude_trees = ['_build', 'templates', 'themes']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output --------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'readthedocs'

# (Optional) Logo. Should be exactly 24x24 px to fit the nav. bar.
# Path should be relative to the static files directory.
#html_logo = "my_logo.png"

# Theme options are theme-specific and customize the look and feel of a
# theme further.
html_theme_options = {
    'custom_css': 'rootpy.css',
    'show_sphinx': False,
    'analytics_code': 'UA-39364267-1',
}

# Add any paths that contain custom themes here, relative to this directory.
html_theme_path = ['themes']

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
html_logo = '_static/rootpy-logo-80dpi.png'

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'rootpydoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index2', 'rootpy.tex', u'rootpy Documentation',
   u'rootpy developers', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
# latex_logo = 'logos/rootpy-logo.png'

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index2', 'rootpy', u'rootpy Documentation',
     [u'rootpy developers'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index2', 'rootpy', u'rootpy Documentation', u'rootpy developers',
   'rootpy', 'One line description of project.', 'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'


# -- Options for Epub output ---------------------------------------------------

# Bibliographic Dublin Core info.
epub_title = u'rootpy'
epub_author = u'rootpy developers'
epub_publisher = u'rootpy developers'
epub_copyright = u'%d, rootpy developers' % now.year

# The language of the text. It defaults to the language option
# or en if the language is not set.
#epub_language = ''

# The scheme of the identifier. Typical schemes are ISBN or URL.
#epub_scheme = ''

# The unique identifier of the text. This can be a ISBN number
# or the project homepage.
#epub_identifier = ''

# A unique identification for the text.
#epub_uid = ''

# A tuple containing the cover image and cover page html template filenames.
#epub_cover = ()

# HTML files that should be inserted before the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_pre_files = []

# HTML files shat should be inserted after the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_post_files = []

# A list of files that should not be packed into the epub file.
#epub_exclude_files = []

# The depth of the table of contents in toc.ncx.
#epub_tocdepth = 3

# Allow duplicate toc entries.
#epub_tocdup = True


# Configuration for intersphinx
intersphinx_mapping = {
    'python' : ('http://docs.python.org/2', None),
    'matplotlib' : ('http://matplotlib.sourceforge.net/', None),
    }

# Taken from http://read-the-docs.readthedocs.org/en/latest/faq.html#i-get-import-errors-on-libraries-that-depend-on-c-modules

from itertools import product
hists = ["TH{0}{1}".format(a, b) for a, b, in product((1, 2, 3), "CSIFD")]

ROOT_CLASSES = set(
    "TPad TCanvas TGraphAsymmErrors TGraph2D TEfficiency THStack TLegend "
    "TDirectoryFile TFile TEllipse TTree"
    .split()
    + hists)

class MockROOT(object):
    def __init__(self, *args, **kwargs):
        pass

    def __call__(self, *args, **kwargs):
        return MockROOT()

    def __iter__(self):
        return iter([])

    def __getitem__(self, i):
        return MockROOT()

    def GetDynamicPath(*args):
        return ""

    @classmethod
    def __getattr__(cls, name):
        if name in ('__file__', '__path__'):
            return '/dev/null'
        elif name in ROOT_CLASSES:
            mockType = type(name, (), {})
            mockType.__module__ = __name__
            return mockType
        else:
            return MockROOT()

class Mock(object):
    def __init__(self, *args, **kwargs):
        pass

    def __call__(self, *args, **kwargs):
        return Mock()

    @classmethod
    def __getattr__(cls, name):
        if name in ('__file__', '__path__'):
            return '/dev/null'
        elif name[0] == name[0].upper():
            mockType = type(name, (), {})
            mockType.__module__ = __name__
            return mockType
        else:
            return Mock()

if ON_RTD:
    MOCK_MODULES = 'ROOT'.split()
    for mod_name in MOCK_MODULES:
        sys.modules[mod_name] = MockROOT()

    MOCK_MODULES = 'numpy numpy.lib numpy.core.multiarray numpy.ma matplotlib.cbook tables'.split()
    for mod_name in MOCK_MODULES:
        sys.modules[mod_name] = Mock()
else:
    import ROOT

    def skip_ROOT_member(app, what, name, obj, skip, options):
        return skip or isinstance(obj, ROOT.MethodProxy)

    def setup(app):
        app.connect('autodoc-skip-member', skip_ROOT_member)

########NEW FILE########
__FILENAME__ = gen_rst
"""
Example generation for rootpy

Generate the rst files for the examples by iterating over the python
example files.

Files that generate images should start with 'plot'
"""
from time import time
import os
import shutil
import traceback
import glob
import sys
from StringIO import StringIO
import token
import tokenize

import matplotlib
matplotlib.use('Agg')

import ROOT
ROOT.gROOT.SetBatch(True)


###############################################################################
# A tee object to redict streams to multiple outputs

class Tee(object):

    def __init__(self, file1, file2):
        self.file1 = file1
        self.file2 = file2

    def write(self, data):
        self.file1.write(data)
        self.file2.write(data)

    def flush(self):
        self.file1.flush()
        self.file2.flush()

###############################################################################
rst_template = """

.. _example_%(short_fname)s:

%(docstring)s

**Python source code:** :download:`%(fname)s <%(fname)s>`

.. literalinclude:: %(fname)s
    :lines: %(end_row)s-
    """

plot_rst_template = """

.. _example_%(short_fname)s:

%(docstring)s

%(image_list)s

%(stdout)s

**Python source code:** :download:`%(fname)s <%(fname)s>`

.. literalinclude:: %(fname)s
    :lines: %(end_row)s-

**Total running time of the example:** %(time_elapsed) .2f seconds
    """

# The following strings are used when we have several pictures: we use
# an html div tag that our CSS uses to turn the lists into horizontal
# lists.
HLIST_HEADER = """
.. rst-class:: horizontal

"""

HLIST_IMAGE_TEMPLATE = """
.. image:: images/%s
   :scale: 50
"""

SINGLE_IMAGE = """
.. image:: images/%s
   :align: center
"""


def extract_docstring(filename):
    """ Extract a module-level docstring, if any
    """
    lines = file(filename).readlines()
    start_row = 0
    if lines[0].startswith('#!'):
        lines.pop(0)
        start_row = 1

    docstring = ''
    first_par = ''
    tokens = tokenize.generate_tokens(iter(lines).next)
    for tok_type, tok_content, _, (erow, _), _ in tokens:
        tok_type = token.tok_name[tok_type]
        if tok_type in ('NEWLINE', 'COMMENT', 'NL', 'INDENT', 'DEDENT'):
            continue
        elif tok_type == 'STRING':
            docstring = eval(tok_content)
            # If the docstring is formatted with several paragraphs, extract
            # the first one:
            paragraphs = '\n'.join(line.rstrip()
                              for line in docstring.split('\n')).split('\n\n')
            if len(paragraphs) > 0:
                first_par = paragraphs[0]
        break
    end_row = erow + 1 + start_row
    if lines and lines[end_row - 2] == 'print __doc__\n':
        end_row += 1
    return docstring, first_par, end_row


def generate_example_rst(app):
    """ Generate the list of examples, as well as the contents of
        examples.
    """
    root_dir = os.path.join(app.builder.srcdir, 'auto_examples')
    example_dir = os.path.abspath(app.builder.srcdir + '/../' + 'examples')
    try:
        plot_gallery = eval(app.builder.config.plot_gallery)
    except TypeError:
        plot_gallery = bool(app.builder.config.plot_gallery)
    if not os.path.exists(example_dir):
        os.makedirs(example_dir)
    if not os.path.exists(root_dir):
        os.makedirs(root_dir)

    # we create an index.rst with all examples
    fhindex = file(os.path.join(root_dir, 'index.rst'), 'w')
    #Note: The sidebar button has been removed from the examples page for now
    #      due to how it messes up the layout. Will be fixed at a later point
    fhindex.write("""\

.. raw:: html


    <style type="text/css">

    div#sidebarbutton {
        display: none;
    }

    .figure {
        float: left;
        margin: 10px;
        width: auto;
        height: 200px;
        width: 180px;
    }

    .figure img {
        display: inline;
        }

    .figure .caption {
        width: 170px;
        text-align: center !important;
    }
    </style>

.. _examples-index:
""")
    # Here we don't use an os.walk, but we recurse only twice: flat is
    # better than nested.
    generate_dir_rst('.', fhindex, example_dir, root_dir, plot_gallery)
    for dir in sorted(os.listdir(example_dir)):
        if os.path.isdir(os.path.join(example_dir, dir)):
            generate_dir_rst(dir, fhindex, example_dir, root_dir, plot_gallery)
    fhindex.flush()


def generate_dir_rst(dir, fhindex, example_dir, root_dir, plot_gallery):
    """ Generate the rst file for an example directory.
    """
    if not dir == '.':
        target_dir = os.path.join(root_dir, dir)
        src_dir = os.path.join(example_dir, dir)
    else:
        target_dir = root_dir
        src_dir = example_dir
    if not os.path.exists(os.path.join(src_dir, 'README.txt')):
        print 80 * '_'
        print ('Example directory %s does not have a README.txt file'
                        % src_dir)
        print 'Skipping this directory'
        print 80 * '_'
        return
    fhindex.write("""


%s


""" % file(os.path.join(src_dir, 'README.txt')).read())
    if not os.path.exists(target_dir):
        os.makedirs(target_dir)

    def sort_key(a):
        # put last elements without a plot
        if not a.startswith('plot') and a.endswith('.py'):
            return 'zz' + a
        return a
    for fname in sorted(os.listdir(src_dir), key=sort_key):
        if fname.endswith('py'):
            generate_file_rst(fname, target_dir, src_dir, plot_gallery)
            #thumb = os.path.join(dir, 'images', 'thumb', fname[:-3] + '.png')
            link_name = os.path.join(dir, fname).replace(os.path.sep, '_')
            #fhindex.write('.. figure:: %s\n' % thumb)
            #if link_name.startswith('._'):
            #    link_name = link_name[2:]
            #if dir != '.':
            #    fhindex.write('   :target: ./%s/%s.html\n\n' % (dir,
            #                                                   fname[:-3]))
            #else:
            #    fhindex.write('   :target: ./%s.html\n\n' % link_name[:-3])
            fhindex.write("""

.. toctree::

   %s/%s

""" % (dir, fname[:-3]))
    fhindex.write("""
.. raw:: html

    <div style="clear: both"></div>
    """)  # clear at the end of the section


def generate_file_rst(fname, target_dir, src_dir, plot_gallery):
    """ Generate the rst file for a given example.
    """
    base_image_name = os.path.splitext(fname)[0]
    image_fname = '%s_%%s.png' % base_image_name
    root_image_fname = 'root_%s_%%s.png' % base_image_name
    root_fig_num = 1

    this_template = rst_template
    last_dir = os.path.split(src_dir)[-1]
    # to avoid leading . in file names, and wrong names in links
    if last_dir == '.' or last_dir == 'examples':
        last_dir = ''
    else:
        last_dir += '_'
    short_fname = last_dir + fname
    src_file = os.path.join(src_dir, fname)
    example_file = os.path.join(target_dir, fname)
    shutil.copyfile(src_file, example_file)

    # The following is a list containing all the figure names
    figure_list = []

    image_dir = os.path.join(target_dir, 'images')
    thumb_dir = os.path.join(image_dir, 'thumb')
    if not os.path.exists(image_dir):
        os.makedirs(image_dir)
    if not os.path.exists(thumb_dir):
        os.makedirs(thumb_dir)
    image_path = os.path.join(image_dir, image_fname)
    root_image_path = os.path.join(image_dir, root_image_fname)

    stdout_path = os.path.join(image_dir,
                               'stdout_%s.txt' % base_image_name)
    time_path = os.path.join(image_dir,
                               'time_%s.txt' % base_image_name)
    thumb_file = os.path.join(thumb_dir, fname[:-3] + '.png')
    time_elapsed = 0
    if plot_gallery and fname.startswith('plot'):
        # generate the plot as png image if file name
        # starts with plot and if it is more recent than an
        # existing image.
        first_image_file = image_path % 1
        first_root_image_file = root_image_path % 1
        if os.path.exists(stdout_path):
            stdout = open(stdout_path).read()
        else:
            stdout = ''
        if os.path.exists(time_path):
            time_elapsed = float(open(time_path).read())

        if (not os.path.exists(first_image_file) or
            not os.path.exists(first_root_image_file) or
                os.stat(first_image_file).st_mtime <=
                                    os.stat(src_file).st_mtime):
            # We need to execute the code
            print 'plotting %s' % fname
            t0 = time()
            import matplotlib.pyplot as plt
            plt.close('all')
            cwd = os.getcwd()
            try:
                # First CD in the original example dir, so that any file
                # created by the example get created in this directory
                orig_stdout = sys.stdout
                os.chdir(os.path.dirname(src_file))
                my_buffer = StringIO()
                my_stdout = Tee(sys.stdout, my_buffer)
                sys.stdout = my_stdout
                my_globals = {'pl': plt}
                execfile(os.path.basename(src_file), my_globals)
                time_elapsed = time() - t0
                sys.stdout = orig_stdout
                my_stdout = my_buffer.getvalue()
                if '__doc__' in my_globals:
                    # The __doc__ is often printed in the example, we
                    # don't with to echo it
                    my_stdout = my_stdout.replace(
                                            my_globals['__doc__'],
                                            '')
                my_stdout = my_stdout.strip()
                if my_stdout:
                    stdout = '**Script output**::\n\n  %s\n\n' % (
                        '\n  '.join(my_stdout.split('\n')))
                open(stdout_path, 'w').write(stdout)
                open(time_path, 'w').write('%f' % time_elapsed)
                os.chdir(cwd)

                # In order to save every figure we have two solutions :
                # * iterate from 1 to infinity and call plt.fignum_exists(n)
                #   (this requires the figures to be numbered
                #    incrementally: 1, 2, 3 and not 1, 2, 5)
                # * iterate over [fig_mngr.num for fig_mngr in
                #   matplotlib._pylab_helpers.Gcf.get_all_fig_managers()]
                for fig_num in (fig_mngr.num for fig_mngr in
                        matplotlib._pylab_helpers.Gcf.get_all_fig_managers()):
                    # Set the fig_num figure as the current figure as we can't
                    # save a figure that's not the current figure.
                    plt.figure(fig_num)
                    plt.savefig(image_path % fig_num)
                    figure_list.append(image_fname % fig_num)
                for canvas in ROOT.gROOT.GetListOfCanvases():
                    canvas.SaveAs(root_image_path % root_fig_num)
                    canvas.Close()
                    figure_list.append(root_image_fname % root_fig_num)
                    root_fig_num += 1
            except:
                print 80 * '_'
                print '%s is not compiling:' % fname
                traceback.print_exc()
                print 80 * '_'
            finally:
                os.chdir(cwd)
                sys.stdout = orig_stdout

            print " - time elapsed : %.2g sec" % time_elapsed
        else:
            figure_list = [f[len(image_dir):]
                            for f in glob.glob(image_path % '[1-9]')]
                            #for f in glob.glob(image_path % '*')]

        # generate thumb file
        this_template = plot_rst_template
        from matplotlib import image
        if os.path.exists(first_image_file):
            image.thumbnail(first_image_file, thumb_file, 0.2)
        elif os.path.exists(first_root_image_file):
            image.thumbnail(first_root_image_file, thumb_file, 0.2)

    if not os.path.exists(thumb_file):
        # create something not to replace the thumbnail
        shutil.copy('images/blank_image.png', thumb_file)

    docstring, short_desc, end_row = extract_docstring(example_file)

    # Depending on whether we have one or more figures, we're using a
    # horizontal list or a single rst call to 'image'.
    if len(figure_list) == 1:
        figure_name = figure_list[0]
        image_list = SINGLE_IMAGE % figure_name.lstrip('/')
    else:
        image_list = HLIST_HEADER
        for figure_name in figure_list:
            image_list += HLIST_IMAGE_TEMPLATE % figure_name.lstrip('/')

    f = open(os.path.join(target_dir, fname[:-2] + 'rst'), 'w')
    f.write(this_template % locals())
    f.flush()


def setup(app):
    app.connect('builder-inited', generate_example_rst)
    app.add_config_value('plot_gallery', True, 'html')

    # Sphinx hack: sphinx copies generated images to the build directory
    #  each time the docs are made.  If the desired image name already
    #  exists, it appends a digit to prevent overwrites.  The problem is,
    #  the directory is never cleared.  This means that each time you build
    #  the docs, the number of images in the directory grows.
    #
    # This question has been asked on the sphinx development list, but there
    #  was no response: http://osdir.com/ml/sphinx-dev/2011-02/msg00123.html
    #
    # The following is a hack that prevents this behavior by clearing the
    #  image build directory each time the docs are built.  If sphinx
    #  changes their layout between versions, this will not work (though
    #  it should probably not cause a crash).  Tested successfully
    #  on Sphinx 1.0.7
    build_image_dir = '_build/html/_images'
    if os.path.exists(build_image_dir):
        filelist = os.listdir(build_image_dir)
        for filename in filelist:
            if filename.endswith('png'):
                os.remove(os.path.join(build_image_dir, filename))

########NEW FILE########
__FILENAME__ = ipython_console_highlighting
"""reST directive for syntax-highlighting ipython interactive sessions.

XXX - See what improvements can be made based on the new (as of Sept 2009)
'pycon' lexer for the python console.  At the very least it will give better
highlighted tracebacks.
"""

#-----------------------------------------------------------------------------
# Needed modules

# Standard library
import re

# Third party
from pygments.lexer import Lexer, do_insertions
from pygments.lexers.agile import (PythonConsoleLexer, PythonLexer,
                                   PythonTracebackLexer)
from pygments.token import Comment, Generic

from sphinx import highlighting

#-----------------------------------------------------------------------------
# Global constants
line_re = re.compile('.*?\n')

#-----------------------------------------------------------------------------
# Code begins - classes and functions

class IPythonConsoleLexer(Lexer):
    """
    For IPython console output or doctests, such as:

    .. sourcecode:: ipython

      In [1]: a = 'foo'

      In [2]: a
      Out[2]: 'foo'

      In [3]: print a
      foo

      In [4]: 1 / 0

    Notes:

      - Tracebacks are not currently supported.

      - It assumes the default IPython prompts, not customized ones.
    """

    name = 'IPython console session'
    aliases = ['ipython']
    mimetypes = ['text/x-ipython-console']
    input_prompt = re.compile("(In \[[0-9]+\]: )|(   \.\.\.+:)")
    output_prompt = re.compile("(Out\[[0-9]+\]: )|(   \.\.\.+:)")
    continue_prompt = re.compile("   \.\.\.+:")
    tb_start = re.compile("\-+")

    def get_tokens_unprocessed(self, text):
        pylexer = PythonLexer(**self.options)
        tblexer = PythonTracebackLexer(**self.options)

        curcode = ''
        insertions = []
        for match in line_re.finditer(text):
            line = match.group()
            input_prompt = self.input_prompt.match(line)
            continue_prompt = self.continue_prompt.match(line.rstrip())
            output_prompt = self.output_prompt.match(line)
            if line.startswith("#"):
                insertions.append((len(curcode),
                                   [(0, Comment, line)]))
            elif input_prompt is not None:
                insertions.append((len(curcode),
                                   [(0, Generic.Prompt, input_prompt.group())]))
                curcode += line[input_prompt.end():]
            elif continue_prompt is not None:
                insertions.append((len(curcode),
                                   [(0, Generic.Prompt, continue_prompt.group())]))
                curcode += line[continue_prompt.end():]
            elif output_prompt is not None:
                # Use the 'error' token for output.  We should probably make
                # our own token, but error is typicaly in a bright color like
                # red, so it works fine for our output prompts.
                insertions.append((len(curcode),
                                   [(0, Generic.Error, output_prompt.group())]))
                curcode += line[output_prompt.end():]
            else:
                if curcode:
                    for item in do_insertions(insertions,
                                              pylexer.get_tokens_unprocessed(curcode)):
                        yield item
                        curcode = ''
                        insertions = []
                yield match.start(), Generic.Output, line
        if curcode:
            for item in do_insertions(insertions,
                                      pylexer.get_tokens_unprocessed(curcode)):
                yield item


def setup(app):
    """Setup as a sphinx extension."""

    # This is only a lexer, so adding it below to pygments appears sufficient.
    # But if somebody knows that the right API usage should be to do that via
    # sphinx, by all means fix it here.  At least having this setup.py
    # suppresses the sphinx warning we'd get without it.
    pass

#-----------------------------------------------------------------------------
# Register the extension as a valid pygments lexer
highlighting.lexers['ipython'] = IPythonConsoleLexer()

########NEW FILE########
__FILENAME__ = ipython_directive
# -*- coding: utf-8 -*-
"""Sphinx directive to support embedded IPython code.

This directive allows pasting of entire interactive IPython sessions, prompts
and all, and their code will actually get re-executed at doc build time, with
all prompts renumbered sequentially. It also allows you to input code as a pure
python input by giving the argument python to the directive. The output looks
like an interactive ipython section.

To enable this directive, simply list it in your Sphinx ``conf.py`` file
(making sure the directory where you placed it is visible to sphinx, as is
needed for all Sphinx directives).

By default this directive assumes that your prompts are unchanged IPython ones,
but this can be customized. The configurable options that can be placed in
conf.py are

ipython_savefig_dir:
    The directory in which to save the figures. This is relative to the
    Sphinx source directory. The default is `html_static_path`.
ipython_rgxin:
    The compiled regular expression to denote the start of IPython input
    lines. The default is re.compile('In \[(\d+)\]:\s?(.*)\s*'). You
    shouldn't need to change this.
ipython_rgxout:
    The compiled regular expression to denote the start of IPython output
    lines. The default is re.compile('Out\[(\d+)\]:\s?(.*)\s*'). You
    shouldn't need to change this.
ipython_promptin:
    The string to represent the IPython input prompt in the generated ReST.
    The default is 'In [%d]:'. This expects that the line numbers are used
    in the prompt.
ipython_promptout:

    The string to represent the IPython prompt in the generated ReST. The
    default is 'Out [%d]:'. This expects that the line numbers are used
    in the prompt.

ToDo
----

- Turn the ad-hoc test() function into a real test suite.
- Break up ipython-specific functionality from matplotlib stuff into better
  separated code.

Authors
-------

- John D Hunter: orignal author.
- Fernando Perez: refactoring, documentation, cleanups, port to 0.11.
- VáclavŠmilauer <eudoxos-AT-arcig.cz>: Prompt generalizations.
- Skipper Seabold, refactoring, cleanups, pure python addition
"""

#-----------------------------------------------------------------------------
# Imports
#-----------------------------------------------------------------------------

# Stdlib
import cStringIO
import os
import re
import sys
import tempfile
import ast

# To keep compatibility with various python versions
try:
    from hashlib import md5
except ImportError:
    from md5 import md5

# Third-party
import matplotlib
import sphinx
from docutils.parsers.rst import directives
from docutils import nodes
from sphinx.util.compat import Directive

matplotlib.use('Agg')

# Our own
from IPython import Config, InteractiveShell
from IPython.core.profiledir import ProfileDir
from IPython.utils import io

#-----------------------------------------------------------------------------
# Globals
#-----------------------------------------------------------------------------
# for tokenizing blocks
COMMENT, INPUT, OUTPUT =  range(3)

#-----------------------------------------------------------------------------
# Functions and class declarations
#-----------------------------------------------------------------------------
def block_parser(part, rgxin, rgxout, fmtin, fmtout):
    """
    part is a string of ipython text, comprised of at most one
    input, one ouput, comments, and blank lines.  The block parser
    parses the text into a list of::

      blocks = [ (TOKEN0, data0), (TOKEN1, data1), ...]

    where TOKEN is one of [COMMENT | INPUT | OUTPUT ] and
    data is, depending on the type of token::

      COMMENT : the comment string

      INPUT: the (DECORATOR, INPUT_LINE, REST) where
         DECORATOR: the input decorator (or None)
         INPUT_LINE: the input as string (possibly multi-line)
         REST : any stdout generated by the input line (not OUTPUT)


      OUTPUT: the output string, possibly multi-line
    """

    block = []
    lines = part.split('\n')
    N = len(lines)
    i = 0
    decorator = None
    while 1:

        if i==N:
            # nothing left to parse -- the last line
            break

        line = lines[i]
        i += 1
        line_stripped = line.strip()
        if line_stripped.startswith('#'):
            block.append((COMMENT, line))
            continue

        if line_stripped.startswith('@'):
            # we're assuming at most one decorator -- may need to
            # rethink
            decorator = line_stripped
            continue

        # does this look like an input line?
        matchin = rgxin.match(line)
        if matchin:
            lineno, inputline = int(matchin.group(1)), matchin.group(2)

            # the ....: continuation string
            continuation = '   %s:'%''.join(['.']*(len(str(lineno))+2))
            Nc = len(continuation)
            # input lines can continue on for more than one line, if
            # we have a '\' line continuation char or a function call
            # echo line 'print'.  The input line can only be
            # terminated by the end of the block or an output line, so
            # we parse out the rest of the input line if it is
            # multiline as well as any echo text

            rest = []
            while i<N:

                # look ahead; if the next line is blank, or a comment, or
                # an output line, we're done

                nextline = lines[i]
                matchout = rgxout.match(nextline)
                #print "nextline=%s, continuation=%s, starts=%s"%(nextline, continuation, nextline.startswith(continuation))
                if matchout or nextline.startswith('#'):
                    break
                elif nextline.startswith(continuation):
                    inputline += '\n' + nextline[Nc:]
                else:
                    rest.append(nextline)
                i+= 1

            block.append((INPUT, (decorator, inputline, '\n'.join(rest))))
            continue

        # if it looks like an output line grab all the text to the end
        # of the block
        matchout = rgxout.match(line)
        if matchout:
            lineno, output = int(matchout.group(1)), matchout.group(2)
            if i<N-1:
                output = '\n'.join([output] + lines[i:])

            block.append((OUTPUT, output))
            break

    return block

class EmbeddedSphinxShell(object):
    """An embedded IPython instance to run inside Sphinx"""

    def __init__(self):

        self.cout = cStringIO.StringIO()


        # Create config object for IPython
        config = Config()
        config.Global.display_banner = False
        config.Global.exec_lines = ['import numpy as np',
                                    'from pylab import *'
                                    ]
        config.InteractiveShell.autocall = False
        config.InteractiveShell.autoindent = False
        config.InteractiveShell.colors = 'NoColor'

        # create a profile so instance history isn't saved
        tmp_profile_dir = tempfile.mkdtemp(prefix='profile_')
        profname = 'auto_profile_sphinx_build'
        pdir = os.path.join(tmp_profile_dir,profname)
        profile = ProfileDir.create_profile_dir(pdir)

        # Create and initialize ipython, but don't start its mainloop
        IP = InteractiveShell.instance(config=config, profile_dir=profile)
        # io.stdout redirect must be done *after* instantiating InteractiveShell
        io.stdout = self.cout
        io.stderr = self.cout

        # For debugging, so we can see normal output, use this:
        #from IPython.utils.io import Tee
        #io.stdout = Tee(self.cout, channel='stdout') # dbg
        #io.stderr = Tee(self.cout, channel='stderr') # dbg

        # Store a few parts of IPython we'll need.
        self.IP = IP
        self.user_ns = self.IP.user_ns
        self.user_global_ns = self.IP.user_global_ns

        self.input = ''
        self.output = ''

        self.is_verbatim = False
        self.is_doctest = False
        self.is_suppress = False

        # on the first call to the savefig decorator, we'll import
        # pyplot as plt so we can make a call to the plt.gcf().savefig
        self._pyplot_imported = False

    def clear_cout(self):
        self.cout.seek(0)
        self.cout.truncate(0)

    def process_input_line(self, line, store_history=True):
        """process the input, capturing stdout"""
        #print "input='%s'"%self.input
        stdout = sys.stdout
        splitter = self.IP.input_splitter
        try:
            sys.stdout = self.cout
            splitter.push(line)
            more = splitter.push_accepts_more()
            if not more:
                source_raw = splitter.source_raw_reset()[1]
                self.IP.run_cell(source_raw, store_history=store_history)
        finally:
            sys.stdout = stdout

    def process_image(self, decorator):
        """
        # build out an image directive like
        # .. image:: somefile.png
        #    :width 4in
        #
        # from an input like
        # savefig somefile.png width=4in
        """
        savefig_dir = self.savefig_dir
        source_dir = self.source_dir
        saveargs = decorator.split(' ')
        filename = saveargs[1]
        # insert relative path to image file in source
        outfile = os.path.relpath(os.path.join(savefig_dir,filename),
                    source_dir)

        imagerows = ['.. image:: %s'%outfile]

        for kwarg in saveargs[2:]:
            arg, val = kwarg.split('=')
            arg = arg.strip()
            val = val.strip()
            imagerows.append('   :%s: %s'%(arg, val))

        image_file = os.path.basename(outfile) # only return file name
        image_directive = '\n'.join(imagerows)
        return image_file, image_directive


    # Callbacks for each type of token
    def process_input(self, data, input_prompt, lineno):
        """Process data block for INPUT token."""
        decorator, input, rest = data
        image_file = None
        image_directive = None
        #print 'INPUT:', data  # dbg
        is_verbatim = decorator=='@verbatim' or self.is_verbatim
        is_doctest = decorator=='@doctest' or self.is_doctest
        is_suppress = decorator=='@suppress' or self.is_suppress
        is_savefig = decorator is not None and \
                     decorator.startswith('@savefig')

        input_lines = input.split('\n')
        if len(input_lines) > 1:
            if input_lines[-1] != "":
                input_lines.append('') # make sure there's a blank line
                                       # so splitter buffer gets reset

        continuation = '   %s:'%''.join(['.']*(len(str(lineno))+2))
        Nc = len(continuation)

        if is_savefig:
            image_file, image_directive = self.process_image(decorator)

        ret = []
        is_semicolon = False

        for i, line in enumerate(input_lines):
            if line.endswith(';'):
                is_semicolon = True

            if i==0:
                # process the first input line
                if is_verbatim:
                    self.process_input_line('')
                    self.IP.execution_count += 1 # increment it anyway
                else:
                    # only submit the line in non-verbatim mode
                    self.process_input_line(line, store_history=True)
                formatted_line = '%s %s'%(input_prompt, line)
            else:
                # process a continuation line
                if not is_verbatim:
                    self.process_input_line(line, store_history=True)

                formatted_line = '%s %s'%(continuation, line)

            if not is_suppress:
                ret.append(formatted_line)

        if not is_suppress and len(rest.strip()) and is_verbatim:
            # the "rest" is the standard output of the
            # input, which needs to be added in
            # verbatim mode
            ret.append(rest)

        self.cout.seek(0)
        output = self.cout.read()
        if not is_suppress and not is_semicolon:
            ret.append(output)
        elif is_semicolon: # get spacing right
            ret.append('')

        self.cout.truncate(0)
        return (ret, input_lines, output, is_doctest, image_file,
                    image_directive)
        #print 'OUTPUT', output  # dbg

    def process_output(self, data, output_prompt,
                       input_lines, output, is_doctest, image_file):
        """Process data block for OUTPUT token."""
        if is_doctest:
            submitted = data.strip()
            found = output
            if found is not None:
                found = found.strip()

                # XXX - fperez: in 0.11, 'output' never comes with the prompt
                # in it, just the actual output text.  So I think all this code
                # can be nuked...

                # the above comment does not appear to be accurate... (minrk)

                ind = found.find(output_prompt)
                if ind<0:
                    e='output prompt="%s" does not match out line=%s' % \
                       (output_prompt, found)
                    raise RuntimeError(e)
                found = found[len(output_prompt):].strip()

                if found!=submitted:
                    e = ('doctest failure for input_lines="%s" with '
                         'found_output="%s" and submitted output="%s"' %
                         (input_lines, found, submitted) )
                    raise RuntimeError(e)
                #print 'doctest PASSED for input_lines="%s" with found_output="%s" and submitted output="%s"'%(input_lines, found, submitted)

    def process_comment(self, data):
        """Process data fPblock for COMMENT token."""
        if not self.is_suppress:
            return [data]

    def save_image(self, image_file):
        """
        Saves the image file to disk.
        """
        self.ensure_pyplot()
        command = 'plt.gcf().savefig("%s")'%image_file
        #print 'SAVEFIG', command  # dbg
        self.process_input_line('bookmark ipy_thisdir', store_history=False)
        self.process_input_line('cd -b ipy_savedir', store_history=False)
        self.process_input_line(command, store_history=False)
        self.process_input_line('cd -b ipy_thisdir', store_history=False)
        self.process_input_line('bookmark -d ipy_thisdir', store_history=False)
        self.clear_cout()


    def process_block(self, block):
        """
        process block from the block_parser and return a list of processed lines
        """
        ret = []
        output = None
        input_lines = None
        lineno = self.IP.execution_count

        input_prompt = self.promptin%lineno
        output_prompt = self.promptout%lineno
        image_file = None
        image_directive = None

        for token, data in block:
            if token==COMMENT:
                out_data = self.process_comment(data)
            elif token==INPUT:
                (out_data, input_lines, output, is_doctest, image_file,
                    image_directive) = \
                          self.process_input(data, input_prompt, lineno)
            elif token==OUTPUT:
                out_data = \
                    self.process_output(data, output_prompt,
                                        input_lines, output, is_doctest,
                                        image_file)
            if out_data:
                ret.extend(out_data)

        # save the image files
        if image_file is not None:
            self.save_image(image_file)

        return ret, image_directive

    def ensure_pyplot(self):
        if self._pyplot_imported:
            return
        self.process_input_line('import matplotlib.pyplot as plt',
                                store_history=False)

    def process_pure_python(self, content):
        """
        content is a list of strings. it is unedited directive conent

        This runs it line by line in the InteractiveShell, prepends
        prompts as needed capturing stderr and stdout, then returns
        the content as a list as if it were ipython code
        """
        output = []
        savefig = False # keep up with this to clear figure
        multiline = False # to handle line continuation
        multiline_start = None
        fmtin = self.promptin

        ct = 0

        for lineno, line in enumerate(content):

            line_stripped = line.strip()
            if not len(line):
                output.append(line)
                continue

            # handle decorators
            if line_stripped.startswith('@'):
                output.extend([line])
                if 'savefig' in line:
                    savefig = True # and need to clear figure
                continue

            # handle comments
            if line_stripped.startswith('#'):
                output.extend([line])
                continue

            # deal with lines checking for multiline
            continuation  = u'   %s:'% ''.join(['.']*(len(str(ct))+2))
            if not multiline:
                modified = u"%s %s" % (fmtin % ct, line_stripped)
                output.append(modified)
                ct += 1
                try:
                    ast.parse(line_stripped)
                    output.append(u'')
                except Exception: # on a multiline
                    multiline = True
                    multiline_start = lineno
            else: # still on a multiline
                modified = u'%s %s' % (continuation, line)
                output.append(modified)
                try:
                    mod = ast.parse(
                            '\n'.join(content[multiline_start:lineno+1]))
                    if isinstance(mod.body[0], ast.FunctionDef):
                        # check to see if we have the whole function
                        for element in mod.body[0].body:
                            if isinstance(element, ast.Return):
                                multiline = False
                    else:
                        output.append(u'')
                        multiline = False
                except Exception:
                    pass

            if savefig: # clear figure if plotted
                self.ensure_pyplot()
                self.process_input_line('plt.clf()', store_history=False)
                self.clear_cout()
                savefig = False

        return output

class IpythonDirective(Directive):

    has_content = True
    required_arguments = 0
    optional_arguments = 4 # python, suppress, verbatim, doctest
    final_argumuent_whitespace = True
    option_spec = { 'python': directives.unchanged,
                    'suppress' : directives.flag,
                    'verbatim' : directives.flag,
                    'doctest' : directives.flag,
                  }

    shell = EmbeddedSphinxShell()

    def get_config_options(self):
        # contains sphinx configuration variables
        config = self.state.document.settings.env.config

        # get config variables to set figure output directory
        confdir = self.state.document.settings.env.app.confdir
        savefig_dir = config.ipython_savefig_dir
        source_dir = os.path.dirname(self.state.document.current_source)
        if savefig_dir is None:
            savefig_dir = config.html_static_path
        if isinstance(savefig_dir, list):
            savefig_dir = savefig_dir[0] # safe to assume only one path?
        savefig_dir = os.path.join(confdir, savefig_dir)

        # get regex and prompt stuff
        rgxin     = config.ipython_rgxin
        rgxout    = config.ipython_rgxout
        promptin  = config.ipython_promptin
        promptout = config.ipython_promptout

        return savefig_dir, source_dir, rgxin, rgxout, promptin, promptout

    def setup(self):
        # reset the execution count if we haven't processed this doc
        #NOTE: this may be borked if there are multiple seen_doc tmp files
        #check time stamp?
        seen_docs = [i for i in os.listdir(tempfile.tempdir)
            if i.startswith('seen_doc')]
        if seen_docs:
            fname = os.path.join(tempfile.tempdir, seen_docs[0])
            docs = open(fname).read().split('\n')
            if not self.state.document.current_source in docs:
                self.shell.IP.history_manager.reset()
                self.shell.IP.execution_count = 1
        else: # haven't processed any docs yet
            docs = []


        # get config values
        (savefig_dir, source_dir, rgxin,
                rgxout, promptin, promptout) = self.get_config_options()

        # and attach to shell so we don't have to pass them around
        self.shell.rgxin = rgxin
        self.shell.rgxout = rgxout
        self.shell.promptin = promptin
        self.shell.promptout = promptout
        self.shell.savefig_dir = savefig_dir
        self.shell.source_dir = source_dir

        # setup bookmark for saving figures directory

        self.shell.process_input_line('bookmark ipy_savedir %s'%savefig_dir,
                                      store_history=False)
        self.shell.clear_cout()

        # write the filename to a tempfile because it's been "seen" now
        if not self.state.document.current_source in docs:
            fd, fname = tempfile.mkstemp(prefix="seen_doc", text=True)
            fout = open(fname, 'a')
            fout.write(self.state.document.current_source+'\n')
            fout.close()

        return rgxin, rgxout, promptin, promptout


    def teardown(self):
        # delete last bookmark
        self.shell.process_input_line('bookmark -d ipy_savedir',
                                      store_history=False)
        self.shell.clear_cout()

    def run(self):
        debug = False

        #TODO, any reason block_parser can't be a method of embeddable shell
        # then we wouldn't have to carry these around
        rgxin, rgxout, promptin, promptout = self.setup()

        options = self.options
        self.shell.is_suppress = 'suppress' in options
        self.shell.is_doctest = 'doctest' in options
        self.shell.is_verbatim = 'verbatim' in options


        # handle pure python code
        if 'python' in self.arguments:
            content = self.content
            self.content = self.shell.process_pure_python(content)

        parts = '\n'.join(self.content).split('\n\n')

        lines = ['.. code-block:: ipython','']
        figures = []

        for part in parts:

            block = block_parser(part, rgxin, rgxout, promptin, promptout)

            if len(block):
                rows, figure = self.shell.process_block(block)
                for row in rows:
                    lines.extend(['   %s'%line for line in row.split('\n')])

                if figure is not None:
                    figures.append(figure)

        #text = '\n'.join(lines)
        #figs = '\n'.join(figures)

        for figure in figures:
            lines.append('')
            lines.extend(figure.split('\n'))
            lines.append('')

        #print lines
        if len(lines)>2:
            if debug:
                print '\n'.join(lines)
            else: #NOTE: this raises some errors, what's it for?
                #print 'INSERTING %d lines'%len(lines)
                self.state_machine.insert_input(
                    lines, self.state_machine.input_lines.source(0))

        text = '\n'.join(lines)
        txtnode = nodes.literal_block(text, text)
        txtnode['language'] = 'ipython'
        #imgnode = nodes.image(figs)

        # cleanup
        self.teardown()

        return []#, imgnode]

# Enable as a proper Sphinx directive
def setup(app):
    setup.app = app

    app.add_directive('ipython', IpythonDirective)
    app.add_config_value('ipython_savefig_dir', None, True)
    app.add_config_value('ipython_rgxin',
                         re.compile('In \[(\d+)\]:\s?(.*)\s*'), True)
    app.add_config_value('ipython_rgxout',
                         re.compile('Out\[(\d+)\]:\s?(.*)\s*'), True)
    app.add_config_value('ipython_promptin', 'In [%d]:', True)
    app.add_config_value('ipython_promptout', 'Out[%d]:', True)


# Simple smoke test, needs to be converted to a proper automatic test.
def test():

    examples = [
        r"""
In [9]: pwd
Out[9]: '/home/jdhunter/py4science/book'

In [10]: cd bookdata/
/home/jdhunter/py4science/book/bookdata

In [2]: from pylab import *

In [2]: ion()

In [3]: im = imread('stinkbug.png')

@savefig mystinkbug.png width=4in
In [4]: imshow(im)
Out[4]: <matplotlib.image.AxesImage object at 0x39ea850>

""",
        r"""

In [1]: x = 'hello world'

# string methods can be
# used to alter the string
@doctest
In [2]: x.upper()
Out[2]: 'HELLO WORLD'

@verbatim
In [3]: x.st<TAB>
x.startswith  x.strip
""",
    r"""

In [130]: url = 'http://ichart.finance.yahoo.com/table.csv?s=CROX\
   .....: &d=9&e=22&f=2009&g=d&a=1&br=8&c=2006&ignore=.csv'

In [131]: print url.split('&')
['http://ichart.finance.yahoo.com/table.csv?s=CROX', 'd=9', 'e=22', 'f=2009', 'g=d', 'a=1', 'b=8', 'c=2006', 'ignore=.csv']

In [60]: import urllib

""",
    r"""\

In [133]: import numpy.random

@suppress
In [134]: numpy.random.seed(2358)

@doctest
In [135]: numpy.random.rand(10,2)
Out[135]:
array([[ 0.64524308,  0.59943846],
       [ 0.47102322,  0.8715456 ],
       [ 0.29370834,  0.74776844],
       [ 0.99539577,  0.1313423 ],
       [ 0.16250302,  0.21103583],
       [ 0.81626524,  0.1312433 ],
       [ 0.67338089,  0.72302393],
       [ 0.7566368 ,  0.07033696],
       [ 0.22591016,  0.77731835],
       [ 0.0072729 ,  0.34273127]])

""",

    r"""
In [106]: print x
jdh

In [109]: for i in range(10):
   .....:     print i
   .....:
   .....:
0
1
2
3
4
5
6
7
8
9
""",

        r"""

In [144]: from pylab import *

In [145]: ion()

# use a semicolon to suppress the output
@savefig test_hist.png width=4in
In [151]: hist(np.random.randn(10000), 100);


@savefig test_plot.png width=4in
In [151]: plot(np.random.randn(10000), 'o');
   """,

        r"""
# use a semicolon to suppress the output
In [151]: plt.clf()

@savefig plot_simple.png width=4in
In [151]: plot([1,2,3])

@savefig hist_simple.png width=4in
In [151]: hist(np.random.randn(10000), 100);

""",
     r"""
# update the current fig
In [151]: ylabel('number')

In [152]: title('normal distribution')


@savefig hist_with_text.png
In [153]: grid(True)

        """,
        ]
    # skip local-file depending first example:
    examples = examples[1:]

    #ipython_directive.DEBUG = True  # dbg
    #options = dict(suppress=True)  # dbg
    options = dict()
    for example in examples:
        content = example.split('\n')
        ipython_directive('debug', arguments=None, options=options,
                          content=content, lineno=0,
                          content_offset=None, block_text=None,
                          state=None, state_machine=None,
                          )

# Run test suite as a script
if __name__=='__main__':
    if not os.path.isdir('_static'):
        os.mkdir('_static')
    test()
    print 'All OK? Check figures in _static/'

########NEW FILE########
__FILENAME__ = comment_eater
from cStringIO import StringIO
import compiler
import inspect
import textwrap
import tokenize

from compiler_unparse import unparse


class Comment(object):
    """ A comment block.
    """
    is_comment = True
    def __init__(self, start_lineno, end_lineno, text):
        # int : The first line number in the block. 1-indexed.
        self.start_lineno = start_lineno
        # int : The last line number. Inclusive!
        self.end_lineno = end_lineno
        # str : The text block including '#' character but not any leading spaces.
        self.text = text

    def add(self, string, start, end, line):
        """ Add a new comment line.
        """
        self.start_lineno = min(self.start_lineno, start[0])
        self.end_lineno = max(self.end_lineno, end[0])
        self.text += string

    def __repr__(self):
        return '%s(%r, %r, %r)' % (self.__class__.__name__, self.start_lineno,
            self.end_lineno, self.text)


class NonComment(object):
    """ A non-comment block of code.
    """
    is_comment = False
    def __init__(self, start_lineno, end_lineno):
        self.start_lineno = start_lineno
        self.end_lineno = end_lineno

    def add(self, string, start, end, line):
        """ Add lines to the block.
        """
        if string.strip():
            # Only add if not entirely whitespace.
            self.start_lineno = min(self.start_lineno, start[0])
            self.end_lineno = max(self.end_lineno, end[0])

    def __repr__(self):
        return '%s(%r, %r)' % (self.__class__.__name__, self.start_lineno,
            self.end_lineno)


class CommentBlocker(object):
    """ Pull out contiguous comment blocks.
    """
    def __init__(self):
        # Start with a dummy.
        self.current_block = NonComment(0, 0)

        # All of the blocks seen so far.
        self.blocks = []

        # The index mapping lines of code to their associated comment blocks.
        self.index = {}

    def process_file(self, file):
        """ Process a file object.
        """
        for token in tokenize.generate_tokens(file.next):
            self.process_token(*token)
        self.make_index()

    def process_token(self, kind, string, start, end, line):
        """ Process a single token.
        """
        if self.current_block.is_comment:
            if kind == tokenize.COMMENT:
                self.current_block.add(string, start, end, line)
            else:
                self.new_noncomment(start[0], end[0])
        else:
            if kind == tokenize.COMMENT:
                self.new_comment(string, start, end, line)
            else:
                self.current_block.add(string, start, end, line)

    def new_noncomment(self, start_lineno, end_lineno):
        """ We are transitioning from a noncomment to a comment.
        """
        block = NonComment(start_lineno, end_lineno)
        self.blocks.append(block)
        self.current_block = block

    def new_comment(self, string, start, end, line):
        """ Possibly add a new comment.
        
        Only adds a new comment if this comment is the only thing on the line.
        Otherwise, it extends the noncomment block.
        """
        prefix = line[:start[1]]
        if prefix.strip():
            # Oops! Trailing comment, not a comment block.
            self.current_block.add(string, start, end, line)
        else:
            # A comment block.
            block = Comment(start[0], end[0], string)
            self.blocks.append(block)
            self.current_block = block

    def make_index(self):
        """ Make the index mapping lines of actual code to their associated
        prefix comments.
        """
        for prev, block in zip(self.blocks[:-1], self.blocks[1:]):
            if not block.is_comment:
                self.index[block.start_lineno] = prev

    def search_for_comment(self, lineno, default=None):
        """ Find the comment block just before the given line number.

        Returns None (or the specified default) if there is no such block.
        """
        if not self.index:
            self.make_index()
        block = self.index.get(lineno, None)
        text = getattr(block, 'text', default)
        return text


def strip_comment_marker(text):
    """ Strip # markers at the front of a block of comment text.
    """
    lines = []
    for line in text.splitlines():
        lines.append(line.lstrip('#'))
    text = textwrap.dedent('\n'.join(lines))
    return text


def get_class_traits(klass):
    """ Yield all of the documentation for trait definitions on a class object.
    """
    # FIXME: gracefully handle errors here or in the caller?
    source = inspect.getsource(klass)
    cb = CommentBlocker()
    cb.process_file(StringIO(source))
    mod_ast = compiler.parse(source)
    class_ast = mod_ast.node.nodes[0]
    for node in class_ast.code.nodes:
        # FIXME: handle other kinds of assignments?
        if isinstance(node, compiler.ast.Assign):
            name = node.nodes[0].name
            rhs = unparse(node.expr).strip()
            doc = strip_comment_marker(cb.search_for_comment(node.lineno, default=''))
            yield name, rhs, doc


########NEW FILE########
__FILENAME__ = compiler_unparse
""" Turn compiler.ast structures back into executable python code.

    The unparse method takes a compiler.ast tree and transforms it back into
    valid python code.  It is incomplete and currently only works for
    import statements, function calls, function definitions, assignments, and
    basic expressions.

    Inspired by python-2.5-svn/Demo/parser/unparse.py

    fixme: We may want to move to using _ast trees because the compiler for
           them is about 6 times faster than compiler.compile.
"""

import sys
import cStringIO
from compiler.ast import Const, Name, Tuple, Div, Mul, Sub, Add

def unparse(ast, single_line_functions=False):
    s = cStringIO.StringIO()
    UnparseCompilerAst(ast, s, single_line_functions)
    return s.getvalue().lstrip()

op_precedence = { 'compiler.ast.Power':3, 'compiler.ast.Mul':2, 'compiler.ast.Div':2,
                  'compiler.ast.Add':1, 'compiler.ast.Sub':1 }

class UnparseCompilerAst:
    """ Methods in this class recursively traverse an AST and
        output source code for the abstract syntax; original formatting
        is disregarged.
    """

    #########################################################################
    # object interface.
    #########################################################################

    def __init__(self, tree, file = sys.stdout, single_line_functions=False):
        """ Unparser(tree, file=sys.stdout) -> None.

            Print the source for tree to file.
        """
        self.f = file
        self._single_func = single_line_functions
        self._do_indent = True
        self._indent = 0
        self._dispatch(tree)
        self._write("\n")
        self.f.flush()

    #########################################################################
    # Unparser private interface.
    #########################################################################

    ### format, output, and dispatch methods ################################

    def _fill(self, text = ""):
        "Indent a piece of text, according to the current indentation level"
        if self._do_indent:
            self._write("\n"+"    "*self._indent + text)
        else:
            self._write(text)

    def _write(self, text):
        "Append a piece of text to the current line."
        self.f.write(text)

    def _enter(self):
        "Print ':', and increase the indentation."
        self._write(": ")
        self._indent += 1

    def _leave(self):
        "Decrease the indentation level."
        self._indent -= 1

    def _dispatch(self, tree):
        "_dispatcher function, _dispatching tree type T to method _T."
        if isinstance(tree, list):
            for t in tree:
                self._dispatch(t)
            return
        meth = getattr(self, "_"+tree.__class__.__name__)
        if tree.__class__.__name__ == 'NoneType' and not self._do_indent:
            return
        meth(tree)


    #########################################################################
    # compiler.ast unparsing methods.
    #
    # There should be one method per concrete grammar type. They are
    # organized in alphabetical order.
    #########################################################################

    def _Add(self, t):
        self.__binary_op(t, '+')

    def _And(self, t):
        self._write(" (")
        for i, node in enumerate(t.nodes):
            self._dispatch(node)
            if i != len(t.nodes)-1:
                self._write(") and (")
        self._write(")")
               
    def _AssAttr(self, t):
        """ Handle assigning an attribute of an object
        """
        self._dispatch(t.expr)
        self._write('.'+t.attrname)
 
    def _Assign(self, t):
        """ Expression Assignment such as "a = 1".

            This only handles assignment in expressions.  Keyword assignment
            is handled separately.
        """
        self._fill()
        for target in t.nodes:
            self._dispatch(target)
            self._write(" = ")
        self._dispatch(t.expr)
        if not self._do_indent:
            self._write('; ')

    def _AssName(self, t):
        """ Name on left hand side of expression.

            Treat just like a name on the right side of an expression.
        """
        self._Name(t)

    def _AssTuple(self, t):
        """ Tuple on left hand side of an expression.
        """

        # _write each elements, separated by a comma.
        for element in t.nodes[:-1]:
            self._dispatch(element)
            self._write(", ")

        # Handle the last one without writing comma
        last_element = t.nodes[-1]
        self._dispatch(last_element)

    def _AugAssign(self, t):
        """ +=,-=,*=,/=,**=, etc. operations
        """
        
        self._fill()
        self._dispatch(t.node)
        self._write(' '+t.op+' ')
        self._dispatch(t.expr)
        if not self._do_indent:
            self._write(';')
            
    def _Bitand(self, t):
        """ Bit and operation.
        """
        
        for i, node in enumerate(t.nodes):
            self._write("(")
            self._dispatch(node)
            self._write(")")
            if i != len(t.nodes)-1:
                self._write(" & ")
                
    def _Bitor(self, t):
        """ Bit or operation
        """
        
        for i, node in enumerate(t.nodes):
            self._write("(")
            self._dispatch(node)
            self._write(")")
            if i != len(t.nodes)-1:
                self._write(" | ")
                
    def _CallFunc(self, t):
        """ Function call.
        """
        self._dispatch(t.node)
        self._write("(")
        comma = False
        for e in t.args:
            if comma: self._write(", ")
            else: comma = True
            self._dispatch(e)
        if t.star_args:
            if comma: self._write(", ")
            else: comma = True
            self._write("*")
            self._dispatch(t.star_args)
        if t.dstar_args:
            if comma: self._write(", ")
            else: comma = True
            self._write("**")
            self._dispatch(t.dstar_args)
        self._write(")")

    def _Compare(self, t):
        self._dispatch(t.expr)
        for op, expr in t.ops:
            self._write(" " + op + " ")
            self._dispatch(expr)

    def _Const(self, t):
        """ A constant value such as an integer value, 3, or a string, "hello".
        """
        self._dispatch(t.value)

    def _Decorators(self, t):
        """ Handle function decorators (eg. @has_units)
        """
        for node in t.nodes:
            self._dispatch(node)

    def _Dict(self, t):
        self._write("{")
        for  i, (k, v) in enumerate(t.items):
            self._dispatch(k)
            self._write(": ")
            self._dispatch(v)
            if i < len(t.items)-1:
                self._write(", ")
        self._write("}")

    def _Discard(self, t):
        """ Node for when return value is ignored such as in "foo(a)".
        """
        self._fill()
        self._dispatch(t.expr)

    def _Div(self, t):
        self.__binary_op(t, '/')

    def _Ellipsis(self, t):
        self._write("...")

    def _From(self, t):
        """ Handle "from xyz import foo, bar as baz".
        """
        # fixme: Are From and ImportFrom handled differently?
        self._fill("from ")
        self._write(t.modname)
        self._write(" import ")
        for i, (name,asname) in enumerate(t.names):
            if i != 0:
                self._write(", ")
            self._write(name)
            if asname is not None:
                self._write(" as "+asname)
                
    def _Function(self, t):
        """ Handle function definitions
        """
        if t.decorators is not None:
            self._fill("@")
            self._dispatch(t.decorators)
        self._fill("def "+t.name + "(")
        defaults = [None] * (len(t.argnames) - len(t.defaults)) + list(t.defaults)
        for i, arg in enumerate(zip(t.argnames, defaults)):
            self._write(arg[0])
            if arg[1] is not None:
                self._write('=')
                self._dispatch(arg[1])
            if i < len(t.argnames)-1:
                self._write(', ')
        self._write(")")
        if self._single_func:
            self._do_indent = False
        self._enter()
        self._dispatch(t.code)
        self._leave()
        self._do_indent = True

    def _Getattr(self, t):
        """ Handle getting an attribute of an object
        """
        if isinstance(t.expr, (Div, Mul, Sub, Add)):
            self._write('(')
            self._dispatch(t.expr)
            self._write(')')
        else:
            self._dispatch(t.expr)
            
        self._write('.'+t.attrname)
        
    def _If(self, t):
        self._fill()
        
        for i, (compare,code) in enumerate(t.tests):
            if i == 0:
                self._write("if ")
            else:
                self._write("elif ")
            self._dispatch(compare)
            self._enter()
            self._fill()
            self._dispatch(code)
            self._leave()
            self._write("\n")

        if t.else_ is not None:
            self._write("else")
            self._enter()
            self._fill()
            self._dispatch(t.else_)
            self._leave()
            self._write("\n")
            
    def _IfExp(self, t):
        self._dispatch(t.then)
        self._write(" if ")
        self._dispatch(t.test)

        if t.else_ is not None:
            self._write(" else (")
            self._dispatch(t.else_)
            self._write(")")

    def _Import(self, t):
        """ Handle "import xyz.foo".
        """
        self._fill("import ")
        
        for i, (name,asname) in enumerate(t.names):
            if i != 0:
                self._write(", ")
            self._write(name)
            if asname is not None:
                self._write(" as "+asname)

    def _Keyword(self, t):
        """ Keyword value assignment within function calls and definitions.
        """
        self._write(t.name)
        self._write("=")
        self._dispatch(t.expr)
        
    def _List(self, t):
        self._write("[")
        for  i,node in enumerate(t.nodes):
            self._dispatch(node)
            if i < len(t.nodes)-1:
                self._write(", ")
        self._write("]")

    def _Module(self, t):
        if t.doc is not None:
            self._dispatch(t.doc)
        self._dispatch(t.node)

    def _Mul(self, t):
        self.__binary_op(t, '*')

    def _Name(self, t):
        self._write(t.name)

    def _NoneType(self, t):
        self._write("None")
        
    def _Not(self, t):
        self._write('not (')
        self._dispatch(t.expr)
        self._write(')')
        
    def _Or(self, t):
        self._write(" (")
        for i, node in enumerate(t.nodes):
            self._dispatch(node)
            if i != len(t.nodes)-1:
                self._write(") or (")
        self._write(")")
                
    def _Pass(self, t):
        self._write("pass\n")

    def _Printnl(self, t):
        self._fill("print ")
        if t.dest:
            self._write(">> ")
            self._dispatch(t.dest)
            self._write(", ")
        comma = False
        for node in t.nodes:
            if comma: self._write(', ')
            else: comma = True
            self._dispatch(node)

    def _Power(self, t):
        self.__binary_op(t, '**')

    def _Return(self, t):
        self._fill("return ")
        if t.value:
            if isinstance(t.value, Tuple):
                text = ', '.join([ name.name for name in t.value.asList() ])
                self._write(text)
            else:
                self._dispatch(t.value)
            if not self._do_indent:
                self._write('; ')

    def _Slice(self, t):
        self._dispatch(t.expr)
        self._write("[")
        if t.lower:
            self._dispatch(t.lower)
        self._write(":")
        if t.upper:
            self._dispatch(t.upper)
        #if t.step:
        #    self._write(":")
        #    self._dispatch(t.step)
        self._write("]")

    def _Sliceobj(self, t):
        for i, node in enumerate(t.nodes):
            if i != 0:
                self._write(":")
            if not (isinstance(node, Const) and node.value is None):
                self._dispatch(node)

    def _Stmt(self, tree):
        for node in tree.nodes:
            self._dispatch(node)

    def _Sub(self, t):
        self.__binary_op(t, '-')

    def _Subscript(self, t):
        self._dispatch(t.expr)
        self._write("[")
        for i, value in enumerate(t.subs):
            if i != 0:
                self._write(",")
            self._dispatch(value)
        self._write("]")

    def _TryExcept(self, t):
        self._fill("try")
        self._enter()
        self._dispatch(t.body)
        self._leave()

        for handler in t.handlers:
            self._fill('except ')
            self._dispatch(handler[0])
            if handler[1] is not None:
                self._write(', ')
                self._dispatch(handler[1])
            self._enter()
            self._dispatch(handler[2])
            self._leave()
            
        if t.else_:
            self._fill("else")
            self._enter()
            self._dispatch(t.else_)
            self._leave()

    def _Tuple(self, t):

        if not t.nodes:
            # Empty tuple.
            self._write("()")
        else:
            self._write("(")

            # _write each elements, separated by a comma.
            for element in t.nodes[:-1]:
                self._dispatch(element)
                self._write(", ")

            # Handle the last one without writing comma
            last_element = t.nodes[-1]
            self._dispatch(last_element)

            self._write(")")
            
    def _UnaryAdd(self, t):
        self._write("+")
        self._dispatch(t.expr)
        
    def _UnarySub(self, t):
        self._write("-")
        self._dispatch(t.expr)        

    def _With(self, t):
        self._fill('with ')
        self._dispatch(t.expr)
        if t.vars:
            self._write(' as ')
            self._dispatch(t.vars.name)
        self._enter()
        self._dispatch(t.body)
        self._leave()
        self._write('\n')
        
    def _int(self, t):
        self._write(repr(t))

    def __binary_op(self, t, symbol):
        # Check if parenthesis are needed on left side and then dispatch
        has_paren = False
        left_class = str(t.left.__class__)
        if (left_class in op_precedence.keys() and
            op_precedence[left_class] < op_precedence[str(t.__class__)]):
            has_paren = True
        if has_paren:
            self._write('(')
        self._dispatch(t.left)
        if has_paren:
            self._write(')')
        # Write the appropriate symbol for operator
        self._write(symbol)
        # Check if parenthesis are needed on the right side and then dispatch
        has_paren = False
        right_class = str(t.right.__class__)
        if (right_class in op_precedence.keys() and
            op_precedence[right_class] < op_precedence[str(t.__class__)]):
            has_paren = True
        if has_paren:
            self._write('(')
        self._dispatch(t.right)
        if has_paren:
            self._write(')')

    def _float(self, t):
        # if t is 0.1, str(t)->'0.1' while repr(t)->'0.1000000000001'
        # We prefer str here.
        self._write(str(t))

    def _str(self, t):
        self._write(repr(t))
        
    def _tuple(self, t):
        self._write(str(t))

    #########################################################################
    # These are the methods from the _ast modules unparse.
    #
    # As our needs to handle more advanced code increase, we may want to
    # modify some of the methods below so that they work for compiler.ast.
    #########################################################################

#    # stmt
#    def _Expr(self, tree):
#        self._fill()
#        self._dispatch(tree.value)
#
#    def _Import(self, t):
#        self._fill("import ")
#        first = True
#        for a in t.names:
#            if first:
#                first = False
#            else:
#                self._write(", ")
#            self._write(a.name)
#            if a.asname:
#                self._write(" as "+a.asname)
#
##    def _ImportFrom(self, t):
##        self._fill("from ")
##        self._write(t.module)
##        self._write(" import ")
##        for i, a in enumerate(t.names):
##            if i == 0:
##                self._write(", ")
##            self._write(a.name)
##            if a.asname:
##                self._write(" as "+a.asname)
##        # XXX(jpe) what is level for?
##
#
#    def _Break(self, t):
#        self._fill("break")
#
#    def _Continue(self, t):
#        self._fill("continue")
#
#    def _Delete(self, t):
#        self._fill("del ")
#        self._dispatch(t.targets)
#
#    def _Assert(self, t):
#        self._fill("assert ")
#        self._dispatch(t.test)
#        if t.msg:
#            self._write(", ")
#            self._dispatch(t.msg)
#
#    def _Exec(self, t):
#        self._fill("exec ")
#        self._dispatch(t.body)
#        if t.globals:
#            self._write(" in ")
#            self._dispatch(t.globals)
#        if t.locals:
#            self._write(", ")
#            self._dispatch(t.locals)
#
#    def _Print(self, t):
#        self._fill("print ")
#        do_comma = False
#        if t.dest:
#            self._write(">>")
#            self._dispatch(t.dest)
#            do_comma = True
#        for e in t.values:
#            if do_comma:self._write(", ")
#            else:do_comma=True
#            self._dispatch(e)
#        if not t.nl:
#            self._write(",")
#
#    def _Global(self, t):
#        self._fill("global")
#        for i, n in enumerate(t.names):
#            if i != 0:
#                self._write(",")
#            self._write(" " + n)
#
#    def _Yield(self, t):
#        self._fill("yield")
#        if t.value:
#            self._write(" (")
#            self._dispatch(t.value)
#            self._write(")")
#
#    def _Raise(self, t):
#        self._fill('raise ')
#        if t.type:
#            self._dispatch(t.type)
#        if t.inst:
#            self._write(", ")
#            self._dispatch(t.inst)
#        if t.tback:
#            self._write(", ")
#            self._dispatch(t.tback)
#
#
#    def _TryFinally(self, t):
#        self._fill("try")
#        self._enter()
#        self._dispatch(t.body)
#        self._leave()
#
#        self._fill("finally")
#        self._enter()
#        self._dispatch(t.finalbody)
#        self._leave()
#
#    def _excepthandler(self, t):
#        self._fill("except ")
#        if t.type:
#            self._dispatch(t.type)
#        if t.name:
#            self._write(", ")
#            self._dispatch(t.name)
#        self._enter()
#        self._dispatch(t.body)
#        self._leave()
#
#    def _ClassDef(self, t):
#        self._write("\n")
#        self._fill("class "+t.name)
#        if t.bases:
#            self._write("(")
#            for a in t.bases:
#                self._dispatch(a)
#                self._write(", ")
#            self._write(")")
#        self._enter()
#        self._dispatch(t.body)
#        self._leave()
#
#    def _FunctionDef(self, t):
#        self._write("\n")
#        for deco in t.decorators:
#            self._fill("@")
#            self._dispatch(deco)
#        self._fill("def "+t.name + "(")
#        self._dispatch(t.args)
#        self._write(")")
#        self._enter()
#        self._dispatch(t.body)
#        self._leave()
#
#    def _For(self, t):
#        self._fill("for ")
#        self._dispatch(t.target)
#        self._write(" in ")
#        self._dispatch(t.iter)
#        self._enter()
#        self._dispatch(t.body)
#        self._leave()
#        if t.orelse:
#            self._fill("else")
#            self._enter()
#            self._dispatch(t.orelse)
#            self._leave
#
#    def _While(self, t):
#        self._fill("while ")
#        self._dispatch(t.test)
#        self._enter()
#        self._dispatch(t.body)
#        self._leave()
#        if t.orelse:
#            self._fill("else")
#            self._enter()
#            self._dispatch(t.orelse)
#            self._leave
#
#    # expr
#    def _Str(self, tree):
#        self._write(repr(tree.s))
##
#    def _Repr(self, t):
#        self._write("`")
#        self._dispatch(t.value)
#        self._write("`")
#
#    def _Num(self, t):
#        self._write(repr(t.n))
#
#    def _ListComp(self, t):
#        self._write("[")
#        self._dispatch(t.elt)
#        for gen in t.generators:
#            self._dispatch(gen)
#        self._write("]")
#
#    def _GeneratorExp(self, t):
#        self._write("(")
#        self._dispatch(t.elt)
#        for gen in t.generators:
#            self._dispatch(gen)
#        self._write(")")
#
#    def _comprehension(self, t):
#        self._write(" for ")
#        self._dispatch(t.target)
#        self._write(" in ")
#        self._dispatch(t.iter)
#        for if_clause in t.ifs:
#            self._write(" if ")
#            self._dispatch(if_clause)
#
#    def _IfExp(self, t):
#        self._dispatch(t.body)
#        self._write(" if ")
#        self._dispatch(t.test)
#        if t.orelse:
#            self._write(" else ")
#            self._dispatch(t.orelse)
#
#    unop = {"Invert":"~", "Not": "not", "UAdd":"+", "USub":"-"}
#    def _UnaryOp(self, t):
#        self._write(self.unop[t.op.__class__.__name__])
#        self._write("(")
#        self._dispatch(t.operand)
#        self._write(")")
#
#    binop = { "Add":"+", "Sub":"-", "Mult":"*", "Div":"/", "Mod":"%",
#                    "LShift":">>", "RShift":"<<", "BitOr":"|", "BitXor":"^", "BitAnd":"&",
#                    "FloorDiv":"//", "Pow": "**"}
#    def _BinOp(self, t):
#        self._write("(")
#        self._dispatch(t.left)
#        self._write(")" + self.binop[t.op.__class__.__name__] + "(")
#        self._dispatch(t.right)
#        self._write(")")
#
#    boolops = {_ast.And: 'and', _ast.Or: 'or'}
#    def _BoolOp(self, t):
#        self._write("(")
#        self._dispatch(t.values[0])
#        for v in t.values[1:]:
#            self._write(" %s " % self.boolops[t.op.__class__])
#            self._dispatch(v)
#        self._write(")")
#
#    def _Attribute(self,t):
#        self._dispatch(t.value)
#        self._write(".")
#        self._write(t.attr)
#
##    def _Call(self, t):
##        self._dispatch(t.func)
##        self._write("(")
##        comma = False
##        for e in t.args:
##            if comma: self._write(", ")
##            else: comma = True
##            self._dispatch(e)
##        for e in t.keywords:
##            if comma: self._write(", ")
##            else: comma = True
##            self._dispatch(e)
##        if t.starargs:
##            if comma: self._write(", ")
##            else: comma = True
##            self._write("*")
##            self._dispatch(t.starargs)
##        if t.kwargs:
##            if comma: self._write(", ")
##            else: comma = True
##            self._write("**")
##            self._dispatch(t.kwargs)
##        self._write(")")
#
#    # slice
#    def _Index(self, t):
#        self._dispatch(t.value)
#
#    def _ExtSlice(self, t):
#        for i, d in enumerate(t.dims):
#            if i != 0:
#                self._write(': ')
#            self._dispatch(d)
#
#    # others
#    def _arguments(self, t):
#        first = True
#        nonDef = len(t.args)-len(t.defaults)
#        for a in t.args[0:nonDef]:
#            if first:first = False
#            else: self._write(", ")
#            self._dispatch(a)
#        for a,d in zip(t.args[nonDef:], t.defaults):
#            if first:first = False
#            else: self._write(", ")
#            self._dispatch(a),
#            self._write("=")
#            self._dispatch(d)
#        if t.vararg:
#            if first:first = False
#            else: self._write(", ")
#            self._write("*"+t.vararg)
#        if t.kwarg:
#            if first:first = False
#            else: self._write(", ")
#            self._write("**"+t.kwarg)
#
##    def _keyword(self, t):
##        self._write(t.arg)
##        self._write("=")
##        self._dispatch(t.value)
#
#    def _Lambda(self, t):
#        self._write("lambda ")
#        self._dispatch(t.args)
#        self._write(": ")
#        self._dispatch(t.body)




########NEW FILE########
__FILENAME__ = docscrape
"""Extract reference documentation from the NumPy source tree.

"""

import inspect
import textwrap
import re
import pydoc
from StringIO import StringIO
from warnings import warn

class Reader(object):
    """A line-based string reader.

    """
    def __init__(self, data):
        """
        Parameters
        ----------
        data : str
           String with lines separated by '\n'.

        """
        if isinstance(data,list):
            self._str = data
        else:
            self._str = data.split('\n') # store string as list of lines

        self.reset()

    def __getitem__(self, n):
        return self._str[n]

    def reset(self):
        self._l = 0 # current line nr

    def read(self):
        if not self.eof():
            out = self[self._l]
            self._l += 1
            return out
        else:
            return ''

    def seek_next_non_empty_line(self):
        for l in self[self._l:]:
            if l.strip():
                break
            else:
                self._l += 1

    def eof(self):
        return self._l >= len(self._str)

    def read_to_condition(self, condition_func):
        start = self._l
        for line in self[start:]:
            if condition_func(line):
                return self[start:self._l]
            self._l += 1
            if self.eof():
                return self[start:self._l+1]
        return []

    def read_to_next_empty_line(self):
        self.seek_next_non_empty_line()
        def is_empty(line):
            return not line.strip()
        return self.read_to_condition(is_empty)

    def read_to_next_unindented_line(self):
        def is_unindented(line):
            return (line.strip() and (len(line.lstrip()) == len(line)))
        return self.read_to_condition(is_unindented)

    def peek(self,n=0):
        if self._l + n < len(self._str):
            return self[self._l + n]
        else:
            return ''

    def is_empty(self):
        return not ''.join(self._str).strip()


class NumpyDocString(object):
    def __init__(self, docstring, config={}):
        docstring = textwrap.dedent(docstring).split('\n')

        self._doc = Reader(docstring)
        self._parsed_data = {
            'Signature': '',
            'Summary': [''],
            'Extended Summary': [],
            'Parameters': [],
            'Returns': [],
            'Raises': [],
            'Warns': [],
            'Other Parameters': [],
            'Attributes': [],
            'Methods': [],
            'See Also': [],
            'Notes': [],
            'Warnings': [],
            'References': '',
            'Examples': '',
            'index': {}
            }

        self._parse()

    def __getitem__(self,key):
        return self._parsed_data[key]

    def __setitem__(self,key,val):
        if not self._parsed_data.has_key(key):
            warn("Unknown section %s" % key)
        else:
            self._parsed_data[key] = val

    def _is_at_section(self):
        self._doc.seek_next_non_empty_line()

        if self._doc.eof():
            return False

        l1 = self._doc.peek().strip()  # e.g. Parameters

        if l1.startswith('.. index::'):
            return True

        l2 = self._doc.peek(1).strip() #    ---------- or ==========
        return l2.startswith('-'*len(l1)) or l2.startswith('='*len(l1))

    def _strip(self,doc):
        i = 0
        j = 0
        for i,line in enumerate(doc):
            if line.strip(): break

        for j,line in enumerate(doc[::-1]):
            if line.strip(): break

        return doc[i:len(doc)-j]

    def _read_to_next_section(self):
        section = self._doc.read_to_next_empty_line()

        while not self._is_at_section() and not self._doc.eof():
            if not self._doc.peek(-1).strip(): # previous line was empty
                section += ['']

            section += self._doc.read_to_next_empty_line()

        return section

    def _read_sections(self):
        while not self._doc.eof():
            data = self._read_to_next_section()
            name = data[0].strip()

            if name.startswith('..'): # index section
                yield name, data[1:]
            elif len(data) < 2:
                yield StopIteration
            else:
                yield name, self._strip(data[2:])

    def _parse_param_list(self,content):
        r = Reader(content)
        params = []
        while not r.eof():
            header = r.read().strip()
            if ' : ' in header:
                arg_name, arg_type = header.split(' : ')[:2]
            else:
                arg_name, arg_type = header, ''

            desc = r.read_to_next_unindented_line()
            desc = dedent_lines(desc)

            params.append((arg_name,arg_type,desc))

        return params


    _name_rgx = re.compile(r"^\s*(:(?P<role>\w+):`(?P<name>[a-zA-Z0-9_.-]+)`|"
                           r" (?P<name2>[a-zA-Z0-9_.-]+))\s*", re.X)
    def _parse_see_also(self, content):
        """
        func_name : Descriptive text
            continued text
        another_func_name : Descriptive text
        func_name1, func_name2, :meth:`func_name`, func_name3

        """
        items = []

        def parse_item_name(text):
            """Match ':role:`name`' or 'name'"""
            m = self._name_rgx.match(text)
            if m:
                g = m.groups()
                if g[1] is None:
                    return g[3], None
                else:
                    return g[2], g[1]
            raise ValueError("%s is not a item name" % text)

        def push_item(name, rest):
            if not name:
                return
            name, role = parse_item_name(name)
            items.append((name, list(rest), role))
            del rest[:]

        current_func = None
        rest = []

        for line in content:
            if not line.strip(): continue

            m = self._name_rgx.match(line)
            if m and line[m.end():].strip().startswith(':'):
                push_item(current_func, rest)
                current_func, line = line[:m.end()], line[m.end():]
                rest = [line.split(':', 1)[1].strip()]
                if not rest[0]:
                    rest = []
            elif not line.startswith(' '):
                push_item(current_func, rest)
                current_func = None
                if ',' in line:
                    for func in line.split(','):
                        if func.strip():
                            push_item(func, [])
                elif line.strip():
                    current_func = line
            elif current_func is not None:
                rest.append(line.strip())
        push_item(current_func, rest)
        return items

    def _parse_index(self, section, content):
        """
        .. index: default
           :refguide: something, else, and more

        """
        def strip_each_in(lst):
            return [s.strip() for s in lst]

        out = {}
        section = section.split('::')
        if len(section) > 1:
            out['default'] = strip_each_in(section[1].split(','))[0]
        for line in content:
            line = line.split(':')
            if len(line) > 2:
                out[line[1]] = strip_each_in(line[2].split(','))
        return out

    def _parse_summary(self):
        """Grab signature (if given) and summary"""
        if self._is_at_section():
            return

        summary = self._doc.read_to_next_empty_line()
        summary_str = " ".join([s.strip() for s in summary]).strip()
        if re.compile('^([\w., ]+=)?\s*[\w\.]+\(.*\)$').match(summary_str):
            self['Signature'] = summary_str
            if not self._is_at_section():
                self['Summary'] = self._doc.read_to_next_empty_line()
        else:
            self['Summary'] = summary

        if not self._is_at_section():
            self['Extended Summary'] = self._read_to_next_section()

    def _parse(self):
        self._doc.reset()
        self._parse_summary()

        for (section,content) in self._read_sections():
            if not section.startswith('..'):
                section = ' '.join([s.capitalize() for s in section.split(' ')])
            if section in ('Parameters', 'Returns', 'Raises', 'Warns',
                           'Other Parameters', 'Attributes', 'Methods'):
                self[section] = self._parse_param_list(content)
            elif section.startswith('.. index::'):
                self['index'] = self._parse_index(section, content)
            elif section == 'See Also':
                self['See Also'] = self._parse_see_also(content)
            else:
                self[section] = content

    # string conversion routines

    def _str_header(self, name, symbol='-'):
        return [name, len(name)*symbol]

    def _str_indent(self, doc, indent=4):
        out = []
        for line in doc:
            out += [' '*indent + line]
        return out

    def _str_signature(self):
        if self['Signature']:
            return [self['Signature'].replace('*','\*')] + ['']
        else:
            return ['']

    def _str_summary(self):
        if self['Summary']:
            return self['Summary'] + ['']
        else:
            return []

    def _str_extended_summary(self):
        if self['Extended Summary']:
            return self['Extended Summary'] + ['']
        else:
            return []

    def _str_param_list(self, name):
        out = []
        if self[name]:
            out += self._str_header(name)
            for param,param_type,desc in self[name]:
                out += ['%s : %s' % (param, param_type)]
                out += self._str_indent(desc)
            out += ['']
        return out

    def _str_section(self, name):
        out = []
        if self[name]:
            out += self._str_header(name)
            out += self[name]
            out += ['']
        return out

    def _str_see_also(self, func_role):
        if not self['See Also']: return []
        out = []
        out += self._str_header("See Also")
        last_had_desc = True
        for func, desc, role in self['See Also']:
            if role:
                link = ':%s:`%s`' % (role, func)
            elif func_role:
                link = ':%s:`%s`' % (func_role, func)
            else:
                link = "`%s`_" % func
            if desc or last_had_desc:
                out += ['']
                out += [link]
            else:
                out[-1] += ", %s" % link
            if desc:
                out += self._str_indent([' '.join(desc)])
                last_had_desc = True
            else:
                last_had_desc = False
        out += ['']
        return out

    def _str_index(self):
        idx = self['index']
        out = []
        out += ['.. index:: %s' % idx.get('default','')]
        for section, references in idx.iteritems():
            if section == 'default':
                continue
            out += ['   :%s: %s' % (section, ', '.join(references))]
        return out

    def __str__(self, func_role=''):
        out = []
        out += self._str_signature()
        out += self._str_summary()
        out += self._str_extended_summary()
        for param_list in ('Parameters', 'Returns', 'Other Parameters',
                           'Raises', 'Warns'):
            out += self._str_param_list(param_list)
        out += self._str_section('Warnings')
        out += self._str_see_also(func_role)
        for s in ('Notes','References','Examples'):
            out += self._str_section(s)
        for param_list in ('Attributes', 'Methods'):
            out += self._str_param_list(param_list)
        out += self._str_index()
        return '\n'.join(out)


def indent(str,indent=4):
    indent_str = ' '*indent
    if str is None:
        return indent_str
    lines = str.split('\n')
    return '\n'.join(indent_str + l for l in lines)

def dedent_lines(lines):
    """Deindent a list of lines maximally"""
    return textwrap.dedent("\n".join(lines)).split("\n")

def header(text, style='-'):
    return text + '\n' + style*len(text) + '\n'


class FunctionDoc(NumpyDocString):
    def __init__(self, func, role='func', doc=None, config={}):
        self._f = func
        self._role = role # e.g. "func" or "meth"

        if doc is None:
            if func is None:
                raise ValueError("No function or docstring given")
            doc = inspect.getdoc(func) or ''
        NumpyDocString.__init__(self, doc)

        if not self['Signature'] and func is not None:
            func, func_name = self.get_func()
            try:
                # try to read signature
                argspec = inspect.getargspec(func)
                argspec = inspect.formatargspec(*argspec)
                argspec = argspec.replace('*','\*')
                signature = '%s%s' % (func_name, argspec)
            except TypeError, e:
                signature = '%s()' % func_name
            self['Signature'] = signature

    def get_func(self):
        func_name = getattr(self._f, '__name__', self.__class__.__name__)
        if inspect.isclass(self._f):
            func = getattr(self._f, '__call__', self._f.__init__)
        else:
            func = self._f
        return func, func_name

    def __str__(self):
        out = ''

        func, func_name = self.get_func()
        signature = self['Signature'].replace('*', '\*')

        roles = {'func': 'function',
                 'meth': 'method'}

        if self._role:
            if not roles.has_key(self._role):
                print "Warning: invalid role %s" % self._role
            out += '.. %s:: %s\n    \n\n' % (roles.get(self._role,''),
                                             func_name)

        out += super(FunctionDoc, self).__str__(func_role=self._role)
        return out


class ClassDoc(NumpyDocString):
    def __init__(self, cls, doc=None, modulename='', func_doc=FunctionDoc,
                 config={}):
        if not inspect.isclass(cls) and cls is not None:
            raise ValueError("Expected a class or None, but got %r" % cls)
        self._cls = cls

        if modulename and not modulename.endswith('.'):
            modulename += '.'
        self._mod = modulename

        if doc is None:
            if cls is None:
                raise ValueError("No class or documentation string given")
            doc = pydoc.getdoc(cls)

        NumpyDocString.__init__(self, doc)

        if config.get('show_class_members', True):
            if not self['Methods']:
                self['Methods'] = [(name, '', '')
                                   for name in sorted(self.methods)]
            if not self['Attributes']:
                self['Attributes'] = [(name, '', '')
                                      for name in sorted(self.properties)]

    @property
    def methods(self):
        if self._cls is None:
            return []
        return [name for name,func in inspect.getmembers(self._cls)
                if not name.startswith('_') and callable(func)]

    @property
    def properties(self):
        if self._cls is None:
            return []
        return [name for name,func in inspect.getmembers(self._cls)
                if not name.startswith('_') and func is None]

########NEW FILE########
__FILENAME__ = docscrape_sphinx
import re, inspect, textwrap, pydoc
import sphinx
from docscrape import NumpyDocString, FunctionDoc, ClassDoc

class SphinxDocString(NumpyDocString):
    def __init__(self, docstring, config={}):
        self.use_plots = config.get('use_plots', False)
        NumpyDocString.__init__(self, docstring, config=config)

    # string conversion routines
    def _str_header(self, name, symbol='`'):
        return ['.. rubric:: ' + name, '']

    def _str_field_list(self, name):
        return [':' + name + ':']

    def _str_indent(self, doc, indent=4):
        out = []
        for line in doc:
            out += [' '*indent + line]
        return out

    def _str_signature(self):
        return ['']
        if self['Signature']:
            return ['``%s``' % self['Signature']] + ['']
        else:
            return ['']

    def _str_summary(self):
        return self['Summary'] + ['']

    def _str_extended_summary(self):
        return self['Extended Summary'] + ['']

    def _str_param_list(self, name):
        out = []
        if self[name]:
            out += self._str_field_list(name)
            out += ['']
            for param,param_type,desc in self[name]:
                out += self._str_indent(['**%s** : %s' % (param.strip(),
                                                          param_type)])
                out += ['']
                out += self._str_indent(desc,8)
                out += ['']
        return out

    @property
    def _obj(self):
        if hasattr(self, '_cls'):
            return self._cls
        elif hasattr(self, '_f'):
            return self._f
        return None

    def _str_member_list(self, name):
        """
        Generate a member listing, autosummary:: table where possible,
        and a table where not.

        """
        out = []
        if self[name]:
            out += ['.. rubric:: %s' % name, '']
            prefix = getattr(self, '_name', '')

            if prefix:
                prefix = '~%s.' % prefix

            autosum = []
            others = []
            for param, param_type, desc in self[name]:
                param = param.strip()
                if not self._obj or hasattr(self._obj, param):
                    autosum += ["   %s%s" % (prefix, param)]
                else:
                    others.append((param, param_type, desc))

            if autosum:
                out += ['.. autosummary::', '   :toctree:', '']
                out += autosum

            if others:
                maxlen_0 = max([len(x[0]) for x in others])
                maxlen_1 = max([len(x[1]) for x in others])
                hdr = "="*maxlen_0 + "  " + "="*maxlen_1 + "  " + "="*10
                fmt = '%%%ds  %%%ds  ' % (maxlen_0, maxlen_1)
                n_indent = maxlen_0 + maxlen_1 + 4
                out += [hdr]
                for param, param_type, desc in others:
                    out += [fmt % (param.strip(), param_type)]
                    out += self._str_indent(desc, n_indent)
                out += [hdr]
            out += ['']
        return out

    def _str_section(self, name):
        out = []
        if self[name]:
            out += self._str_header(name)
            out += ['']
            content = textwrap.dedent("\n".join(self[name])).split("\n")
            out += content
            out += ['']
        return out

    def _str_see_also(self, func_role):
        out = []
        if self['See Also']:
            see_also = super(SphinxDocString, self)._str_see_also(func_role)
            out = ['.. seealso::', '']
            out += self._str_indent(see_also[2:])
        return out

    def _str_warnings(self):
        out = []
        if self['Warnings']:
            out = ['.. warning::', '']
            out += self._str_indent(self['Warnings'])
        return out

    def _str_index(self):
        idx = self['index']
        out = []
        if len(idx) == 0:
            return out

        out += ['.. index:: %s' % idx.get('default','')]
        for section, references in idx.iteritems():
            if section == 'default':
                continue
            elif section == 'refguide':
                out += ['   single: %s' % (', '.join(references))]
            else:
                out += ['   %s: %s' % (section, ','.join(references))]
        return out

    def _str_references(self):
        out = []
        if self['References']:
            out += self._str_header('References')
            if isinstance(self['References'], str):
                self['References'] = [self['References']]
            out.extend(self['References'])
            out += ['']
            # Latex collects all references to a separate bibliography,
            # so we need to insert links to it
            if sphinx.__version__ >= "0.6":
                out += ['.. only:: latex','']
            else:
                out += ['.. latexonly::','']
            items = []
            for line in self['References']:
                m = re.match(r'.. \[([a-z0-9._-]+)\]', line, re.I)
                if m:
                    items.append(m.group(1))
            out += ['   ' + ", ".join(["[%s]_" % item for item in items]), '']
        return out

    def _str_examples(self):
        examples_str = "\n".join(self['Examples'])

        if (self.use_plots and 'import matplotlib' in examples_str
                and 'plot::' not in examples_str):
            out = []
            out += self._str_header('Examples')
            out += ['.. plot::', '']
            out += self._str_indent(self['Examples'])
            out += ['']
            return out
        else:
            return self._str_section('Examples')

    def __str__(self, indent=0, func_role="obj"):
        out = []
        out += self._str_signature()
        out += self._str_index() + ['']
        out += self._str_summary()
        out += self._str_extended_summary()
        for param_list in ('Parameters', 'Returns', 'Other Parameters',
                           'Raises', 'Warns'):
            out += self._str_param_list(param_list)
        out += self._str_warnings()
        out += self._str_see_also(func_role)
        out += self._str_section('Notes')
        out += self._str_references()
        out += self._str_examples()
        for param_list in ('Attributes', 'Methods'):
            out += self._str_member_list(param_list)
        out = self._str_indent(out,indent)
        return '\n'.join(out)

class SphinxFunctionDoc(SphinxDocString, FunctionDoc):
    def __init__(self, obj, doc=None, config={}):
        self.use_plots = config.get('use_plots', False)
        FunctionDoc.__init__(self, obj, doc=doc, config=config)

class SphinxClassDoc(SphinxDocString, ClassDoc):
    def __init__(self, obj, doc=None, func_doc=None, config={}):
        self.use_plots = config.get('use_plots', False)
        ClassDoc.__init__(self, obj, doc=doc, func_doc=None, config=config)

class SphinxObjDoc(SphinxDocString):
    def __init__(self, obj, doc=None, config={}):
        self._f = obj
        SphinxDocString.__init__(self, doc, config=config)

def get_doc_object(obj, what=None, doc=None, config={}):
    if what is None:
        if inspect.isclass(obj):
            what = 'class'
        elif inspect.ismodule(obj):
            what = 'module'
        elif callable(obj):
            what = 'function'
        else:
            what = 'object'
    if what == 'class':
        return SphinxClassDoc(obj, func_doc=SphinxFunctionDoc, doc=doc,
                              config=config)
    elif what in ('function', 'method'):
        return SphinxFunctionDoc(obj, doc=doc, config=config)
    else:
        if doc is None:
            doc = pydoc.getdoc(obj)
        return SphinxObjDoc(obj, doc, config=config)

########NEW FILE########
__FILENAME__ = numpydoc
"""
========
numpydoc
========

Sphinx extension that handles docstrings in the Numpy standard format. [1]

It will:

- Convert Parameters etc. sections to field lists.
- Convert See Also section to a See also entry.
- Renumber references.
- Extract the signature from the docstring, if it can't be determined otherwise.

.. [1] http://projects.scipy.org/numpy/wiki/CodingStyleGuidelines#docstring-standard

"""

import os, re, pydoc
from docscrape_sphinx import get_doc_object, SphinxDocString
from sphinx.util.compat import Directive
import inspect

def mangle_docstrings(app, what, name, obj, options, lines,
                      reference_offset=[0]):

    cfg = dict(use_plots=app.config.numpydoc_use_plots,
               show_class_members=app.config.numpydoc_show_class_members)

    if what == 'module':
        # Strip top title
        title_re = re.compile(ur'^\s*[#*=]{4,}\n[a-z0-9 -]+\n[#*=]{4,}\s*',
                              re.I|re.S)
        lines[:] = title_re.sub(u'', u"\n".join(lines)).split(u"\n")
    else:
        doc = get_doc_object(obj, what, u"\n".join(lines), config=cfg)
        lines[:] = unicode(doc).split(u"\n")

    if app.config.numpydoc_edit_link and hasattr(obj, '__name__') and \
           obj.__name__:
        if hasattr(obj, '__module__'):
            v = dict(full_name=u"%s.%s" % (obj.__module__, obj.__name__))
        else:
            v = dict(full_name=obj.__name__)
        lines += [u'', u'.. htmlonly::', '']
        lines += [u'    %s' % x for x in
                  (app.config.numpydoc_edit_link % v).split("\n")]

    # replace reference numbers so that there are no duplicates
    references = []
    for line in lines:
        line = line.strip()
        m = re.match(ur'^.. \[([a-z0-9_.-])\]', line, re.I)
        if m:
            references.append(m.group(1))

    # start renaming from the longest string, to avoid overwriting parts
    references.sort(key=lambda x: -len(x))
    if references:
        for i, line in enumerate(lines):
            for r in references:
                if re.match(ur'^\d+$', r):
                    new_r = u"R%d" % (reference_offset[0] + int(r))
                else:
                    new_r = u"%s%d" % (r, reference_offset[0])
                lines[i] = lines[i].replace(u'[%s]_' % r,
                                            u'[%s]_' % new_r)
                lines[i] = lines[i].replace(u'.. [%s]' % r,
                                            u'.. [%s]' % new_r)

    reference_offset[0] += len(references)

def mangle_signature(app, what, name, obj, options, sig, retann):
    # Do not try to inspect classes that don't define `__init__`
    if (inspect.isclass(obj) and
        (not hasattr(obj, '__init__') or
        'initializes x; see ' in pydoc.getdoc(obj.__init__))):
        return '', ''

    if not (callable(obj) or hasattr(obj, '__argspec_is_invalid_')): return
    if not hasattr(obj, '__doc__'): return

    doc = SphinxDocString(pydoc.getdoc(obj))
    if doc['Signature']:
        sig = re.sub(u"^[^(]*", u"", doc['Signature'])
        return sig, u''

def setup(app, get_doc_object_=get_doc_object):
    global get_doc_object
    get_doc_object = get_doc_object_

    app.connect('autodoc-process-docstring', mangle_docstrings)
    app.connect('autodoc-process-signature', mangle_signature)
    app.add_config_value('numpydoc_edit_link', None, False)
    app.add_config_value('numpydoc_use_plots', None, False)
    app.add_config_value('numpydoc_show_class_members', True, True)

    # Extra mangling domains
    #app.add_domain(NumpyPythonDomain)
    #app.add_domain(NumpyCDomain)

#------------------------------------------------------------------------------
# Docstring-mangling domains
#------------------------------------------------------------------------------

from docutils.statemachine import ViewList
from sphinx.domains.c import CDomain
from sphinx.domains.python import PythonDomain

class ManglingDomainBase(object):
    directive_mangling_map = {}

    def __init__(self, *a, **kw):
        super(ManglingDomainBase, self).__init__(*a, **kw)
        self.wrap_mangling_directives()

    def wrap_mangling_directives(self):
        for name, objtype in self.directive_mangling_map.items():
            self.directives[name] = wrap_mangling_directive(
                self.directives[name], objtype)

class NumpyPythonDomain(ManglingDomainBase, PythonDomain):
    name = 'np'
    directive_mangling_map = {
        'function': 'function',
        'class': 'class',
        'exception': 'class',
        'method': 'function',
        'classmethod': 'function',
        'staticmethod': 'function',
        'attribute': 'attribute',
    }

class NumpyCDomain(ManglingDomainBase, CDomain):
    name = 'np-c'
    directive_mangling_map = {
        'function': 'function',
        'member': 'attribute',
        'macro': 'function',
        'type': 'class',
        'var': 'object',
    }

def wrap_mangling_directive(base_directive, objtype):
    class directive(base_directive):
        def run(self):
            env = self.state.document.settings.env

            name = None
            if self.arguments:
                m = re.match(r'^(.*\s+)?(.*?)(\(.*)?', self.arguments[0])
                name = m.group(2).strip()

            if not name:
                name = self.arguments[0]

            lines = list(self.content)
            mangle_docstrings(env.app, objtype, name, None, None, lines)
            self.content = ViewList(lines, self.content.parent)

            return base_directive.run(self)

    return directive


########NEW FILE########
__FILENAME__ = phantom_import
"""
==============
phantom_import
==============

Sphinx extension to make directives from ``sphinx.ext.autodoc`` and similar
extensions to use docstrings loaded from an XML file.

This extension loads an XML file in the Pydocweb format [1] and
creates a dummy module that contains the specified docstrings. This
can be used to get the current docstrings from a Pydocweb instance
without needing to rebuild the documented module.

.. [1] http://code.google.com/p/pydocweb

"""
import imp, sys, compiler, types, os, inspect, re

def setup(app):
    app.connect('builder-inited', initialize)
    app.add_config_value('phantom_import_file', None, True)

def initialize(app):
    fn = app.config.phantom_import_file
    if (fn and os.path.isfile(fn)):
        print "[numpydoc] Phantom importing modules from", fn, "..."
        import_phantom_module(fn)

#------------------------------------------------------------------------------
# Creating 'phantom' modules from an XML description
#------------------------------------------------------------------------------
def import_phantom_module(xml_file):
    """
    Insert a fake Python module to sys.modules, based on a XML file.

    The XML file is expected to conform to Pydocweb DTD. The fake
    module will contain dummy objects, which guarantee the following:

    - Docstrings are correct.
    - Class inheritance relationships are correct (if present in XML).
    - Function argspec is *NOT* correct (even if present in XML).
      Instead, the function signature is prepended to the function docstring.
    - Class attributes are *NOT* correct; instead, they are dummy objects.

    Parameters
    ----------
    xml_file : str
        Name of an XML file to read
    
    """
    import lxml.etree as etree

    object_cache = {}

    tree = etree.parse(xml_file)
    root = tree.getroot()

    # Sort items so that
    # - Base classes come before classes inherited from them
    # - Modules come before their contents
    all_nodes = dict([(n.attrib['id'], n) for n in root])
    
    def _get_bases(node, recurse=False):
        bases = [x.attrib['ref'] for x in node.findall('base')]
        if recurse:
            j = 0
            while True:
                try:
                    b = bases[j]
                except IndexError: break
                if b in all_nodes:
                    bases.extend(_get_bases(all_nodes[b]))
                j += 1
        return bases

    type_index = ['module', 'class', 'callable', 'object']
    
    def base_cmp(a, b):
        x = cmp(type_index.index(a.tag), type_index.index(b.tag))
        if x != 0: return x

        if a.tag == 'class' and b.tag == 'class':
            a_bases = _get_bases(a, recurse=True)
            b_bases = _get_bases(b, recurse=True)
            x = cmp(len(a_bases), len(b_bases))
            if x != 0: return x
            if a.attrib['id'] in b_bases: return -1
            if b.attrib['id'] in a_bases: return 1
        
        return cmp(a.attrib['id'].count('.'), b.attrib['id'].count('.'))

    nodes = root.getchildren()
    nodes.sort(base_cmp)

    # Create phantom items
    for node in nodes:
        name = node.attrib['id']
        doc = (node.text or '').decode('string-escape') + "\n"
        if doc == "\n": doc = ""

        # create parent, if missing
        parent = name
        while True:
            parent = '.'.join(parent.split('.')[:-1])
            if not parent: break
            if parent in object_cache: break
            obj = imp.new_module(parent)
            object_cache[parent] = obj
            sys.modules[parent] = obj

        # create object
        if node.tag == 'module':
            obj = imp.new_module(name)
            obj.__doc__ = doc
            sys.modules[name] = obj
        elif node.tag == 'class':
            bases = [object_cache[b] for b in _get_bases(node)
                     if b in object_cache]
            bases.append(object)
            init = lambda self: None
            init.__doc__ = doc
            obj = type(name, tuple(bases), {'__doc__': doc, '__init__': init})
            obj.__name__ = name.split('.')[-1]
        elif node.tag == 'callable':
            funcname = node.attrib['id'].split('.')[-1]
            argspec = node.attrib.get('argspec')
            if argspec:
                argspec = re.sub('^[^(]*', '', argspec)
                doc = "%s%s\n\n%s" % (funcname, argspec, doc)
            obj = lambda: 0
            obj.__argspec_is_invalid_ = True
            obj.func_name = funcname
            obj.__name__ = name
            obj.__doc__ = doc
            if inspect.isclass(object_cache[parent]):
                obj.__objclass__ = object_cache[parent]
        else:
            class Dummy(object): pass
            obj = Dummy()
            obj.__name__ = name
            obj.__doc__ = doc
            if inspect.isclass(object_cache[parent]):
                obj.__get__ = lambda: None
        object_cache[name] = obj

        if parent:
            if inspect.ismodule(object_cache[parent]):
                obj.__module__ = parent
                setattr(object_cache[parent], name.split('.')[-1], obj)

    # Populate items
    for node in root:
        obj = object_cache.get(node.attrib['id'])
        if obj is None: continue
        for ref in node.findall('ref'):
            if node.tag == 'class':
                if ref.attrib['ref'].startswith(node.attrib['id'] + '.'):
                    setattr(obj, ref.attrib['name'],
                            object_cache.get(ref.attrib['ref']))
            else:
                setattr(obj, ref.attrib['name'],
                        object_cache.get(ref.attrib['ref']))

########NEW FILE########
__FILENAME__ = plot_directive
"""
A special directive for generating a matplotlib plot.

.. warning::

   This is a hacked version of plot_directive.py from Matplotlib.
   It's very much subject to change!


Usage
-----

Can be used like this::

    .. plot:: examples/example.py

    .. plot::

       import matplotlib.pyplot as plt
       plt.plot([1,2,3], [4,5,6])

    .. plot::

       A plotting example:

       >>> import matplotlib.pyplot as plt
       >>> plt.plot([1,2,3], [4,5,6])

The content is interpreted as doctest formatted if it has a line starting
with ``>>>``.

The ``plot`` directive supports the options

    format : {'python', 'doctest'}
        Specify the format of the input

    include-source : bool
        Whether to display the source code. Default can be changed in conf.py
    
and the ``image`` directive options ``alt``, ``height``, ``width``,
``scale``, ``align``, ``class``.

Configuration options
---------------------

The plot directive has the following configuration options:

    plot_include_source
        Default value for the include-source option

    plot_pre_code
        Code that should be executed before each plot.

    plot_basedir
        Base directory, to which plot:: file names are relative to.
        (If None or empty, file names are relative to the directoly where
        the file containing the directive is.)

    plot_formats
        File formats to generate. List of tuples or strings::

            [(suffix, dpi), suffix, ...]

        that determine the file format and the DPI. For entries whose
        DPI was omitted, sensible defaults are chosen.

    plot_html_show_formats
        Whether to show links to the files in HTML.

TODO
----

* Refactor Latex output; now it's plain images, but it would be nice
  to make them appear side-by-side, or in floats.

"""

import sys, os, glob, shutil, imp, warnings, cStringIO, re, textwrap, traceback
import sphinx

import warnings
warnings.warn("A plot_directive module is also available under "
              "matplotlib.sphinxext; expect this numpydoc.plot_directive "
              "module to be deprecated after relevant features have been "
              "integrated there.",
              FutureWarning, stacklevel=2)


#------------------------------------------------------------------------------
# Registration hook
#------------------------------------------------------------------------------

def setup(app):
    setup.app = app
    setup.config = app.config
    setup.confdir = app.confdir
    
    app.add_config_value('plot_pre_code', '', True)
    app.add_config_value('plot_include_source', False, True)
    app.add_config_value('plot_formats', ['png', 'hires.png', 'pdf'], True)
    app.add_config_value('plot_basedir', None, True)
    app.add_config_value('plot_html_show_formats', True, True)

    app.add_directive('plot', plot_directive, True, (0, 1, False),
                      **plot_directive_options)

#------------------------------------------------------------------------------
# plot:: directive
#------------------------------------------------------------------------------
from docutils.parsers.rst import directives
from docutils import nodes

def plot_directive(name, arguments, options, content, lineno,
                   content_offset, block_text, state, state_machine):
    return run(arguments, content, options, state_machine, state, lineno)
plot_directive.__doc__ = __doc__

def _option_boolean(arg):
    if not arg or not arg.strip():
        # no argument given, assume used as a flag
        return True
    elif arg.strip().lower() in ('no', '0', 'false'):
        return False
    elif arg.strip().lower() in ('yes', '1', 'true'):
        return True
    else:
        raise ValueError('"%s" unknown boolean' % arg)

def _option_format(arg):
    return directives.choice(arg, ('python', 'lisp'))

def _option_align(arg):
    return directives.choice(arg, ("top", "middle", "bottom", "left", "center",
                                   "right"))

plot_directive_options = {'alt': directives.unchanged,
                          'height': directives.length_or_unitless,
                          'width': directives.length_or_percentage_or_unitless,
                          'scale': directives.nonnegative_int,
                          'align': _option_align,
                          'class': directives.class_option,
                          'include-source': _option_boolean,
                          'format': _option_format,
                          }

#------------------------------------------------------------------------------
# Generating output
#------------------------------------------------------------------------------

from docutils import nodes, utils

try:
    # Sphinx depends on either Jinja or Jinja2
    import jinja2
    def format_template(template, **kw):
        return jinja2.Template(template).render(**kw)
except ImportError:
    import jinja
    def format_template(template, **kw):
        return jinja.from_string(template, **kw)

TEMPLATE = """
{{ source_code }}

{{ only_html }}

   {% if source_link or (html_show_formats and not multi_image) %}
   (
   {%- if source_link -%}
   `Source code <{{ source_link }}>`__
   {%- endif -%}
   {%- if html_show_formats and not multi_image -%}
     {%- for img in images -%}
       {%- for fmt in img.formats -%}
         {%- if source_link or not loop.first -%}, {% endif -%}
         `{{ fmt }} <{{ dest_dir }}/{{ img.basename }}.{{ fmt }}>`__
       {%- endfor -%}
     {%- endfor -%}
   {%- endif -%}
   )
   {% endif %}

   {% for img in images %}
   .. figure:: {{ build_dir }}/{{ img.basename }}.png
      {%- for option in options %}
      {{ option }}
      {% endfor %}

      {% if html_show_formats and multi_image -%}
        (
        {%- for fmt in img.formats -%}
        {%- if not loop.first -%}, {% endif -%}
        `{{ fmt }} <{{ dest_dir }}/{{ img.basename }}.{{ fmt }}>`__
        {%- endfor -%}
        )
      {%- endif -%}
   {% endfor %}

{{ only_latex }}

   {% for img in images %}
   .. image:: {{ build_dir }}/{{ img.basename }}.pdf
   {% endfor %}

"""

class ImageFile(object):
    def __init__(self, basename, dirname):
        self.basename = basename
        self.dirname = dirname
        self.formats = []

    def filename(self, format):
        return os.path.join(self.dirname, "%s.%s" % (self.basename, format))

    def filenames(self):
        return [self.filename(fmt) for fmt in self.formats]

def run(arguments, content, options, state_machine, state, lineno):
    if arguments and content:
        raise RuntimeError("plot:: directive can't have both args and content")

    document = state_machine.document
    config = document.settings.env.config

    options.setdefault('include-source', config.plot_include_source)

    # determine input
    rst_file = document.attributes['source']
    rst_dir = os.path.dirname(rst_file)

    if arguments:
        if not config.plot_basedir:
            source_file_name = os.path.join(rst_dir,
                                            directives.uri(arguments[0]))
        else:
            source_file_name = os.path.join(setup.confdir, config.plot_basedir,
                                            directives.uri(arguments[0]))
        code = open(source_file_name, 'r').read()
        output_base = os.path.basename(source_file_name)
    else:
        source_file_name = rst_file
        code = textwrap.dedent("\n".join(map(str, content)))
        counter = document.attributes.get('_plot_counter', 0) + 1
        document.attributes['_plot_counter'] = counter
        base, ext = os.path.splitext(os.path.basename(source_file_name))
        output_base = '%s-%d.py' % (base, counter)

    base, source_ext = os.path.splitext(output_base)
    if source_ext in ('.py', '.rst', '.txt'):
        output_base = base
    else:
        source_ext = ''

    # ensure that LaTeX includegraphics doesn't choke in foo.bar.pdf filenames
    output_base = output_base.replace('.', '-')

    # is it in doctest format?
    is_doctest = contains_doctest(code)
    if options.has_key('format'):
        if options['format'] == 'python':
            is_doctest = False
        else:
            is_doctest = True

    # determine output directory name fragment
    source_rel_name = relpath(source_file_name, setup.confdir)
    source_rel_dir = os.path.dirname(source_rel_name)
    while source_rel_dir.startswith(os.path.sep):
        source_rel_dir = source_rel_dir[1:]

    # build_dir: where to place output files (temporarily)
    build_dir = os.path.join(os.path.dirname(setup.app.doctreedir),
                             'plot_directive',
                             source_rel_dir)
    if not os.path.exists(build_dir):
        os.makedirs(build_dir)

    # output_dir: final location in the builder's directory
    dest_dir = os.path.abspath(os.path.join(setup.app.builder.outdir,
                                            source_rel_dir))

    # how to link to files from the RST file
    dest_dir_link = os.path.join(relpath(setup.confdir, rst_dir),
                                 source_rel_dir).replace(os.path.sep, '/')
    build_dir_link = relpath(build_dir, rst_dir).replace(os.path.sep, '/')
    source_link = dest_dir_link + '/' + output_base + source_ext

    # make figures
    try:
        results = makefig(code, source_file_name, build_dir, output_base,
                          config)
        errors = []
    except PlotError, err:
        reporter = state.memo.reporter
        sm = reporter.system_message(
            2, "Exception occurred in plotting %s: %s" % (output_base, err),
            line=lineno)
        results = [(code, [])]
        errors = [sm]

    # generate output restructuredtext
    total_lines = []
    for j, (code_piece, images) in enumerate(results):
        if options['include-source']:
            if is_doctest:
                lines = ['']
                lines += [row.rstrip() for row in code_piece.split('\n')]
            else:
                lines = ['.. code-block:: python', '']
                lines += ['    %s' % row.rstrip()
                          for row in code_piece.split('\n')]
            source_code = "\n".join(lines)
        else:
            source_code = ""

        opts = [':%s: %s' % (key, val) for key, val in options.items()
                if key in ('alt', 'height', 'width', 'scale', 'align', 'class')]

        only_html = ".. only:: html"
        only_latex = ".. only:: latex"

        if j == 0:
            src_link = source_link
        else:
            src_link = None

        result = format_template(
            TEMPLATE,
            dest_dir=dest_dir_link,
            build_dir=build_dir_link,
            source_link=src_link,
            multi_image=len(images) > 1,
            only_html=only_html,
            only_latex=only_latex,
            options=opts,
            images=images,
            source_code=source_code,
            html_show_formats=config.plot_html_show_formats)

        total_lines.extend(result.split("\n"))
        total_lines.extend("\n")

    if total_lines:
        state_machine.insert_input(total_lines, source=source_file_name)

    # copy image files to builder's output directory
    if not os.path.exists(dest_dir):
        os.makedirs(dest_dir)

    for code_piece, images in results:
        for img in images:
            for fn in img.filenames():
                shutil.copyfile(fn, os.path.join(dest_dir,
                                                 os.path.basename(fn)))

    # copy script (if necessary)
    if source_file_name == rst_file:
        target_name = os.path.join(dest_dir, output_base + source_ext)
        f = open(target_name, 'w')
        f.write(unescape_doctest(code))
        f.close()

    return errors


#------------------------------------------------------------------------------
# Run code and capture figures
#------------------------------------------------------------------------------

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.image as image
from matplotlib import _pylab_helpers

import exceptions

def contains_doctest(text):
    try:
        # check if it's valid Python as-is
        compile(text, '<string>', 'exec')
        return False
    except SyntaxError:
        pass
    r = re.compile(r'^\s*>>>', re.M)
    m = r.search(text)
    return bool(m)

def unescape_doctest(text):
    """
    Extract code from a piece of text, which contains either Python code
    or doctests.

    """
    if not contains_doctest(text):
        return text

    code = ""
    for line in text.split("\n"):
        m = re.match(r'^\s*(>>>|\.\.\.) (.*)$', line)
        if m:
            code += m.group(2) + "\n"
        elif line.strip():
            code += "# " + line.strip() + "\n"
        else:
            code += "\n"
    return code

def split_code_at_show(text):
    """
    Split code at plt.show()

    """

    parts = []
    is_doctest = contains_doctest(text)

    part = []
    for line in text.split("\n"):
        if (not is_doctest and line.strip() == 'plt.show()') or \
               (is_doctest and line.strip() == '>>> plt.show()'):
            part.append(line)
            parts.append("\n".join(part))
            part = []
        else:
            part.append(line)
    if "\n".join(part).strip():
        parts.append("\n".join(part))
    return parts

class PlotError(RuntimeError):
    pass

def run_code(code, code_path, ns=None):
    # Change the working directory to the directory of the example, so
    # it can get at its data files, if any.
    pwd = os.getcwd()
    old_sys_path = list(sys.path)
    if code_path is not None:
        dirname = os.path.abspath(os.path.dirname(code_path))
        os.chdir(dirname)
        sys.path.insert(0, dirname)

    # Redirect stdout
    stdout = sys.stdout
    sys.stdout = cStringIO.StringIO()

    # Reset sys.argv
    old_sys_argv = sys.argv
    sys.argv = [code_path]
    
    try:
        try:
            code = unescape_doctest(code)
            if ns is None:
                ns = {}
            if not ns:
                exec setup.config.plot_pre_code in ns
            exec code in ns
        except (Exception, SystemExit), err:
            raise PlotError(traceback.format_exc())
    finally:
        os.chdir(pwd)
        sys.argv = old_sys_argv
        sys.path[:] = old_sys_path
        sys.stdout = stdout
    return ns


#------------------------------------------------------------------------------
# Generating figures
#------------------------------------------------------------------------------

def out_of_date(original, derived):
    """
    Returns True if derivative is out-of-date wrt original,
    both of which are full file paths.
    """
    return (not os.path.exists(derived)
            or os.stat(derived).st_mtime < os.stat(original).st_mtime)


def makefig(code, code_path, output_dir, output_base, config):
    """
    Run a pyplot script *code* and save the images under *output_dir*
    with file names derived from *output_base*

    """

    # -- Parse format list
    default_dpi = {'png': 80, 'hires.png': 200, 'pdf': 50}
    formats = []
    for fmt in config.plot_formats:
        if isinstance(fmt, str):
            formats.append((fmt, default_dpi.get(fmt, 80)))
        elif type(fmt) in (tuple, list) and len(fmt)==2:
            formats.append((str(fmt[0]), int(fmt[1])))
        else:
            raise PlotError('invalid image format "%r" in plot_formats' % fmt)

    # -- Try to determine if all images already exist

    code_pieces = split_code_at_show(code)

    # Look for single-figure output files first
    all_exists = True
    img = ImageFile(output_base, output_dir)
    for format, dpi in formats:
        if out_of_date(code_path, img.filename(format)):
            all_exists = False
            break
        img.formats.append(format)

    if all_exists:
        return [(code, [img])]

    # Then look for multi-figure output files
    results = []
    all_exists = True
    for i, code_piece in enumerate(code_pieces):
        images = []
        for j in xrange(1000):
            img = ImageFile('%s_%02d_%02d' % (output_base, i, j), output_dir)
            for format, dpi in formats:
                if out_of_date(code_path, img.filename(format)):
                    all_exists = False
                    break
                img.formats.append(format)

            # assume that if we have one, we have them all
            if not all_exists:
                all_exists = (j > 0)
                break
            images.append(img)
        if not all_exists:
            break
        results.append((code_piece, images))

    if all_exists:
        return results

    # -- We didn't find the files, so build them

    results = []
    ns = {}

    for i, code_piece in enumerate(code_pieces):
        # Clear between runs
        plt.close('all')

        # Run code
        run_code(code_piece, code_path, ns)

        # Collect images
        images = []
        fig_managers = _pylab_helpers.Gcf.get_all_fig_managers()
        for j, figman in enumerate(fig_managers):
            if len(fig_managers) == 1 and len(code_pieces) == 1:
                img = ImageFile(output_base, output_dir)
            else:
                img = ImageFile("%s_%02d_%02d" % (output_base, i, j),
                                output_dir)
            images.append(img)
            for format, dpi in formats:
                try:
                    figman.canvas.figure.savefig(img.filename(format), dpi=dpi)
                except exceptions.BaseException, err:
                    raise PlotError(traceback.format_exc())
                img.formats.append(format)

        # Results
        results.append((code_piece, images))

    return results


#------------------------------------------------------------------------------
# Relative pathnames
#------------------------------------------------------------------------------

try:
    from os.path import relpath
except ImportError:
    def relpath(target, base=os.curdir):
        """
        Return a relative path to the target from either the current
        dir or an optional base dir.  Base can be a directory
        specified either as absolute or relative to current dir.
        """

        if not os.path.exists(target):
            raise OSError, 'Target does not exist: '+target

        if not os.path.isdir(base):
            raise OSError, 'Base is not a directory or does not exist: '+base

        base_list = (os.path.abspath(base)).split(os.sep)
        target_list = (os.path.abspath(target)).split(os.sep)

        # On the windows platform the target may be on a completely
        # different drive from the base.
        if os.name in ['nt','dos','os2'] and base_list[0] <> target_list[0]:
            raise OSError, 'Target is on a different drive to base. Target: '+target_list[0].upper()+', base: '+base_list[0].upper()

        # Starting from the filepath root, work out how much of the
        # filepath is shared by base and target.
        for i in range(min(len(base_list), len(target_list))):
            if base_list[i] <> target_list[i]: break
        else:
            # If we broke out of the loop, i is pointing to the first
            # differing path elements.  If we didn't break out of the
            # loop, i is pointing to identical path elements.
            # Increment i so that in all cases it points to the first
            # differing path elements.
            i+=1

        rel_list = [os.pardir] * (len(base_list)-i) + target_list[i:]
        return os.path.join(*rel_list)

########NEW FILE########
__FILENAME__ = traitsdoc
"""
=========
traitsdoc
=========

Sphinx extension that handles docstrings in the Numpy standard format, [1]
and support Traits [2].

This extension can be used as a replacement for ``numpydoc`` when support
for Traits is required.

.. [1] http://projects.scipy.org/numpy/wiki/CodingStyleGuidelines#docstring-standard
.. [2] http://code.enthought.com/projects/traits/

"""

import inspect
import os
import pydoc

import docscrape
import docscrape_sphinx
from docscrape_sphinx import SphinxClassDoc, SphinxFunctionDoc, SphinxDocString

import numpydoc

import comment_eater

class SphinxTraitsDoc(SphinxClassDoc):
    def __init__(self, cls, modulename='', func_doc=SphinxFunctionDoc):
        if not inspect.isclass(cls):
            raise ValueError("Initialise using a class. Got %r" % cls)
        self._cls = cls

        if modulename and not modulename.endswith('.'):
            modulename += '.'
        self._mod = modulename
        self._name = cls.__name__
        self._func_doc = func_doc

        docstring = pydoc.getdoc(cls)
        docstring = docstring.split('\n')

        # De-indent paragraph
        try:
            indent = min(len(s) - len(s.lstrip()) for s in docstring
                         if s.strip())
        except ValueError:
            indent = 0

        for n,line in enumerate(docstring):
            docstring[n] = docstring[n][indent:]

        self._doc = docscrape.Reader(docstring)
        self._parsed_data = {
            'Signature': '',
            'Summary': '',
            'Description': [],
            'Extended Summary': [],
            'Parameters': [],
            'Returns': [],
            'Raises': [],
            'Warns': [],
            'Other Parameters': [],
            'Traits': [],
            'Methods': [],
            'See Also': [],
            'Notes': [],
            'References': '',
            'Example': '',
            'Examples': '',
            'index': {}
            }

        self._parse()

    def _str_summary(self):
        return self['Summary'] + ['']

    def _str_extended_summary(self):
        return self['Description'] + self['Extended Summary'] + ['']

    def __str__(self, indent=0, func_role="func"):
        out = []
        out += self._str_signature()
        out += self._str_index() + ['']
        out += self._str_summary()
        out += self._str_extended_summary()
        for param_list in ('Parameters', 'Traits', 'Methods',
                           'Returns','Raises'):
            out += self._str_param_list(param_list)
        out += self._str_see_also("obj")
        out += self._str_section('Notes')
        out += self._str_references()
        out += self._str_section('Example')
        out += self._str_section('Examples')
        out = self._str_indent(out,indent)
        return '\n'.join(out)

def looks_like_issubclass(obj, classname):
    """ Return True if the object has a class or superclass with the given class
    name.

    Ignores old-style classes.
    """
    t = obj
    if t.__name__ == classname:
        return True
    for klass in t.__mro__:
        if klass.__name__ == classname:
            return True
    return False

def get_doc_object(obj, what=None, config=None):
    if what is None:
        if inspect.isclass(obj):
            what = 'class'
        elif inspect.ismodule(obj):
            what = 'module'
        elif callable(obj):
            what = 'function'
        else:
            what = 'object'
    if what == 'class':
        doc = SphinxTraitsDoc(obj, '', func_doc=SphinxFunctionDoc, config=config)
        if looks_like_issubclass(obj, 'HasTraits'):
            for name, trait, comment in comment_eater.get_class_traits(obj):
                # Exclude private traits.
                if not name.startswith('_'):
                    doc['Traits'].append((name, trait, comment.splitlines()))
        return doc
    elif what in ('function', 'method'):
        return SphinxFunctionDoc(obj, '', config=config)
    else:
        return SphinxDocString(pydoc.getdoc(obj), config=config)

def setup(app):
    # init numpydoc
    numpydoc.setup(app, get_doc_object)


########NEW FILE########
__FILENAME__ = ansi
# -*- coding: utf-8 -*-
# Copyright (c) 2010, Sebastian Wiesner <lunaryorn@googlemail.com>
# All rights reserved.

# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:

# 1. Redistributions of source code must retain the above copyright notice,
#    this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.

# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.


"""
    sphinxcontrib.ansi
    ==================

    This extension parses ANSI color codes in literal blocks.

    .. moduleauthor::  Sebastian Wiesner  <lunaryorn@googlemail.com>
"""


import re
from os import path

from docutils import nodes
from docutils.parsers import rst
from docutils.parsers.rst.directives import flag
from sphinx.util.osutil import copyfile
from sphinx.util.console import bold


class ansi_literal_block(nodes.literal_block):
    """
    Represent a literal block, that contains ANSI color codes.
    """
    pass


#: the pattern to find ANSI color codes
COLOR_PATTERN = re.compile('\x1b\\[([^m]+)m')

#: map ANSI color codes to class names
CODE_CLASS_MAP = {
    1: 'bold',
    4: 'underscore',
    30: 'black',
    31: 'red',
    32: 'green',
    33: 'yellow',
    34: 'blue',
    35: 'magenta',
    36: 'cyan',
    37: 'white',
    }


class ANSIColorParser(object):
    """
    Traverse a document, look for ansi_literal_block nodes, parse these
    nodes, and replace them with literal blocks, containing proper child
    nodes for ANSI color sequences.
    """

    def _finalize_pending_nodes(self):
        """
        Finalize all pending nodes.

        Pending nodes will be append to the new nodes.
        """
        while self.pending_nodes:
            self.new_nodes.append(self.pending_nodes.pop())

    def _add_text(self, text):
        """
        If ``text`` is not empty, append a new Text node to the most recent
        pending node, if there is any, or to the new nodes, if there are no
        pending nodes.
        """
        if text:
            if self.pending_nodes:
                self.pending_nodes[-1].append(nodes.Text(text))
            else:
                self.new_nodes.append(nodes.Text(text))

    def __call__(self, app, doctree, docname):
        """
        Extract and parse all ansi escapes in ansi_literal_block nodes.
        """
        for ansi_block in doctree.traverse(ansi_literal_block):
            raw = ansi_block.rawsource
            # create the "super" node, which contains to while block and all
            # it sub nodes, and replace the old block with it
            literal_node = nodes.literal_block()
            literal_node['classes'].append('ansi-block')
            ansi_block.replace_self(literal_node)

            # this contains "pending" nodes.  A node representing an ANSI
            # color is "pending", if it has not yet seen a reset
            self.pending_nodes = []
            # these are the nodes, that will finally be added to the
            # literal_node
            self.new_nodes = []
            # this holds the end of the last regex match
            last_end = 0
            # iterate over all color codes
            for match in COLOR_PATTERN.finditer(raw):
                # add any text preceeding this match
                head = raw[last_end:match.start()]
                self._add_text(head)
                # update the match end
                last_end = match.end()
                # get the single format codes
                codes = [int(c) for c in match.group(1).split(';')]
                if codes[-1] == 0:
                    # the last code is a reset, so finalize all pending
                    # nodes.
                    self._finalize_pending_nodes()
                else:
                    # create a new color node
                    code_node = nodes.inline()
                    self.pending_nodes.append(code_node)
                    # and set the classes for its colors
                    for code in codes:
                        code_node['classes'].append(
                            'ansi-%s' % CODE_CLASS_MAP[code])
            # add any trailing text
            tail = raw[last_end:]
            self._add_text(tail)
            # move all pending nodes to new_nodes
            self._finalize_pending_nodes()
            # and add the new nodes to the block
            literal_node.extend(self.new_nodes)


def add_stylesheet(app):
    if app.config.html_ansi_stylesheet:
        app.add_stylesheet('ansi.css')


def copy_stylesheet(app, exception):
    if app.builder.name != 'html' or exception:
        return
    stylesheet = app.config.html_ansi_stylesheet
    if stylesheet:
        app.info(bold('Copying ansi stylesheet... '))
        dest = path.join(app.builder.outdir, '_static', 'ansi.css')
        source = path.abspath(path.dirname(__file__))
        copyfile(path.join(source, stylesheet), dest)
        app.info('done')


class ANSIBlockDirective(rst.Directive):
    """
    This directive interprets its content as literal block with ANSI color
    codes.

    The content is decoded using ``string-escape`` to allow symbolic names
    as \x1b being used instead of the real escape character.
    """

    has_content = True

    option_spec = dict(string_escape=flag)

    def run(self):
        text = '\n'.join(self.content)
        if 'string_escape' in self.options:
            text = text.decode('string-escape')
        return [ansi_literal_block(text, text)]


def setup(app):
    app.require_sphinx('1.0')
    app.add_config_value('html_ansi_stylesheet', None, 'env')
    app.add_directive('ansi-block', ANSIBlockDirective)
    app.connect('builder-inited', add_stylesheet)
    app.connect('build-finished', copy_stylesheet)
    app.connect('doctree-resolved', ANSIColorParser())

########NEW FILE########
__FILENAME__ = programoutput
# -*- coding: utf-8 -*-
# Copyright (c) 2010, 2011, 2012, Sebastian Wiesner <lunaryorn@gmail.com>
# All rights reserved.

# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:

# 1. Redistributions of source code must retain the above copyright notice,
#    this list of conditions and the following disclaimer.
# 2. Redistributions in binary form must reproduce the above copyright
#    notice, this list of conditions and the following disclaimer in the
#    documentation and/or other materials provided with the distribution.

# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

"""
    sphinxcontrib.programoutput
    ===========================

    This extension provides a directive to include the output of commands as
    literal block while building the docs.

    .. moduleauthor::  Sebastian Wiesner  <lunaryorn@gmail.com>
"""

from __future__ import (print_function, division, unicode_literals,
                        absolute_import)

import sys
import os
import shlex
from subprocess import Popen, PIPE, STDOUT
from collections import defaultdict, namedtuple

from docutils import nodes
from docutils.parsers import rst
from docutils.parsers.rst.directives import flag, unchanged, nonnegative_int


__version__ = '0.8'


class program_output(nodes.Element):
    pass


def _slice(value):
    parts = [int(v.strip()) for v in value.split(',')]
    if len(parts) > 2:
        raise ValueError('too many slice parts')
    return tuple((parts + [None] * 2)[:2])


class ProgramOutputDirective(rst.Directive):
    has_content = False
    final_argument_whitespace = True
    required_arguments = 1

    option_spec = dict(shell=flag, prompt=flag, nostderr=flag,
                       ellipsis=_slice, extraargs=unchanged,
                       returncode=nonnegative_int, cwd=unchanged)

    def run(self):
        env = self.state.document.settings.env

        node = program_output()
        node.line = self.lineno
        node['command'] = self.arguments[0]

        if self.name == 'command-output':
            node['show_prompt'] = True
        else:
            node['show_prompt'] = 'prompt' in self.options

        node['hide_standard_error'] = 'nostderr' in self.options
        node['extraargs'] = self.options.get('extraargs', '')
        _, cwd = env.relfn2path(self.options.get('cwd', '/'))
        node['working_directory'] = cwd
        node['use_shell'] = 'shell' in self.options
        node['returncode'] = self.options.get('returncode', 0)
        if 'ellipsis' in self.options:
            node['strip_lines'] = self.options['ellipsis']
        return [node]


_Command = namedtuple(
    'Command', 'command shell hide_standard_error working_directory')


class Command(_Command):
    """
    A command to be executed.
    """

    def __new__(cls, command, shell=False, hide_standard_error=False,
                working_directory='/'):
        if isinstance(command, list):
            command = tuple(command)
        # `chdir()` resolves symlinks, so we need to resolve them too for
        # caching to make sure that different symlinks to the same directory
        # don't result in different cache keys.  Also normalize paths to make
        # sure that identical paths are also equal as strings.
        working_directory = os.path.normpath(os.path.realpath(
            working_directory))
        return _Command.__new__(cls, command, shell, hide_standard_error,
                                working_directory)

    @classmethod
    def from_program_output_node(cls, node):
        """
        Create a command from a :class:`program_output` node.
        """
        extraargs = node.get('extraargs', '')
        command = (node['command'] + ' ' + extraargs).strip()
        return cls(command, node['use_shell'],
                   node['hide_standard_error'], node['working_directory'])

    def execute(self):
        """
        Execute this command.

        Return the :class:`~subprocess.Popen` object representing the running
        command.
        """
        if self.shell:
            if sys.version_info[0] < 3 and isinstance(self.command, unicode):
                command = self.command.encode(sys.getfilesystemencoding())
            else:
                command = self.command
        else:
            if sys.version_info[0] < 3 and isinstance(self.command, unicode):
                command = shlex.split(self.command.encode(
                    sys.getfilesystemencoding()))
            elif isinstance(self.command, str):
                command = shlex.split(self.command)
            else:
                command = self.command
        return Popen(command, shell=self.shell, stdout=PIPE,
                     stderr=PIPE if self.hide_standard_error else STDOUT,
                     cwd=self.working_directory)

    def get_output(self):
        """
        Get the output of this command.

        Return a tuple ``(returncode, output)``.  ``returncode`` is the
        integral return code of the process, ``output`` is the output as
        unicode string, with final trailing spaces and new lines stripped.
        """
        process = self.execute()
        output = process.communicate()[0].decode(
            sys.getfilesystemencoding()).rstrip()
        return process.returncode, output

    def __str__(self):
        if isinstance(self.command, tuple):
            return repr(list(self.command))
        return repr(self.command)


class ProgramOutputCache(defaultdict):
    """
    Execute command and cache their output.

    This class is a mapping.  Its keys are :class:`Command` objects represeting
    command invocations.  Its values are tuples of the form ``(returncode,
    output)``, where ``returncode`` is the integral return code of the command,
    and ``output`` is the output as unicode string.

    The first time, a key is retrieved from this object, the command is
    invoked, and its result is cached.  Subsequent access to the same key
    returns the cached value.
    """

    def __missing__(self, command):
        """
        Called, if a command was not found in the cache.

        ``command`` is an instance of :class:`Command`.
        """
        result = command.get_output()
        self[command] = result
        return result


def run_programs(app, doctree):
    """
    Execute all programs represented by ``program_output`` nodes in
    ``doctree``.  Each ``program_output`` node in ``doctree`` is then
    replaced with a node, that represents the output of this program.

    The program output is retrieved from the cache in
    ``app.env.programoutput_cache``.
    """
    if app.config.programoutput_use_ansi:
        # enable ANSI support, if requested by config
        from sphinxcontrib.ansi import ansi_literal_block
        node_class = ansi_literal_block
    else:
        node_class = nodes.literal_block

    cache = app.env.programoutput_cache

    for node in doctree.traverse(program_output):
        command = Command.from_program_output_node(node)
        try:
            returncode, output = cache[command]
        except EnvironmentError as error:
            error_message = 'Command {0} failed: {1}'.format(command, error)
            error_node = doctree.reporter.error(error_message, base_node=node)
            node.replace_self(error_node)
        else:
            if returncode != node['returncode']:
                app.warn('Unexpected return code {0} from command {1}'.format(
                    returncode, command))

            # replace lines with ..., if ellipsis is specified
            if 'strip_lines' in node:
                lines = output.splitlines()
                start, stop = node['strip_lines']
                lines[start:stop] = ['...']
                output = '\n'.join(lines)

            if node['show_prompt']:
                tmpl = app.config.programoutput_prompt_template
                output = tmpl.format(command=node['command'], output=output,
                                     returncode=returncode)

            new_node = node_class(output, output)
            new_node['language'] = 'text'
            node.replace_self(new_node)


def init_cache(app):
    """
    Initialize the cache for program output at
    ``app.env.programoutput_cache``, if not already present (e.g. being
    loaded from a pickled environment).

    The cache is of type :class:`ProgramOutputCache`.
    """
    if not hasattr(app.env, 'programoutput_cache'):
        app.env.programoutput_cache = ProgramOutputCache()


def setup(app):
    app.add_config_value('programoutput_use_ansi', False, 'env')
    app.add_config_value('programoutput_prompt_template',
                         '$ {command}\n{output}', 'env')
    app.add_directive('program-output', ProgramOutputDirective)
    app.add_directive('command-output', ProgramOutputDirective)
    app.connect(str('builder-inited'), init_cache)
    app.connect(str('doctree-read'), run_programs)

########NEW FILE########
__FILENAME__ = plot_hist_fill_array
#!/usr/bin/env python
"""
===================================
Fill a histogram with a NumPy array
===================================

This example demonstrates how a 1D, 2D, or 3D ROOT histogram can be efficiently
filled with a NumPy array.
"""
print __doc__
from rootpy.interactive import wait
from rootpy.plotting import Canvas, Hist, Hist2D, Hist3D
from rootpy.plotting.style import set_style
import numpy as np

set_style('ATLAS')

c1 = Canvas()
a = Hist(1000, -5, 5)
a.fill_array(np.random.randn(1000000))
a.Draw('hist')

c2 = Canvas()
c2.SetRightMargin(0.1)
b = Hist2D(100, -5, 5, 100, -5, 5)
b.fill_array(np.random.randn(1000000, 2))
b.Draw('LEGO20')

c3 = Canvas()
c3.SetRightMargin(0.1)
c = Hist3D(10, -5, 5, 10, -5, 5, 10, -5, 5)
c.markersize = .3
c.fill_array(np.random.randn(10000, 3))
c.Draw('SCAT')
wait(True)

########NEW FILE########
__FILENAME__ = tree_to_array
#!/usr/bin/env python
"""
=================================
Convert a tree into a NumPy array
=================================

This example demonstrates how to convert a Tree into a NumPy ndarray or
recarray.
"""
print __doc__
from rootpy.tree import Tree, TreeModel, FloatCol, IntCol
from rootpy.io import root_open
from random import gauss


f = root_open("test.root", "recreate")


# define the model
class Event(TreeModel):
    x = FloatCol()
    y = FloatCol()
    z = FloatCol()
    i = IntCol()

tree = Tree("test", model=Event)

# fill the tree
for i in xrange(100):
    tree.x = gauss(.5, 1.)
    tree.y = gauss(.3, 2.)
    tree.z = gauss(13., 42.)
    tree.i = i
    tree.fill()
tree.write()

# convert tree into a numpy record array
from root_numpy import tree2rec
array = tree2rec(tree)
print array
print array.x
print array.i
print tree.to_array()

f.close()

########NEW FILE########
__FILENAME__ = file
#!/usr/bin/env python
"""
==============================
ROOT.TFile made easy by rootpy
==============================

This example demonstrates how basic file operations are made easier in rootpy.
"""
print __doc__
import os
import shutil
from rootpy.io import root_open, DoesNotExist
from rootpy.plotting import Hist, Hist2D
from rootpy import testdata
from rootpy import asrootpy

shutil.copyfile(testdata.get_filepath('test_file_2.root'), 'data.root')
f = root_open('data.root')

print f.a
print f.a.b

try:
    print f.a.b.c.d.e.f
except AttributeError, e:
    print e

for thing in f.walk():
    print thing

f.close()

# supports with statements
with root_open('data.root', 'update') as f:
    print f

    # write some histograms
    h1 = Hist(100, 0, 100, name='h1', type='I')
    # variable bin widths
    h2 = Hist2D((0,3,5,20,50), (10,20,30,40,1000), name='h2')

    h1.Write()
    h2.Write()
# file is automatically closed after with statement

# retrieve the histograms previously saved
with root_open('data.root') as f:

    h1 = f.h1
    # or h1 = f.Get('h1')
    h2 = f.h2
    # or h2 = f.Get('h2')

    # ROOT classes are automatically converted into
    # rootpy form when retrieved from a ROOT file as
    # long as their module was previously imported
    print h1.__class__.__name__
    print h2.__class__.__name__

    # you may also do this to convert an object into
    # rootpy form (again, assuming the relevant module
    # was previously imported)
    h1 = asrootpy(h1)
    # if it is already in rootpy form or if no rootpy form
    # exists then asrootpy does nothing
    print h1.__class__.__name__

os.unlink('data.root')

########NEW FILE########
__FILENAME__ = plot_autobinning
#!/usr/bin/env python
"""
==================================================
Fill histograms from arrays with automatic binning
==================================================

This example demonstrates how to fill a histogram from an array of data
and to automatically choose a binning with various methods.

The automatic binning requires numpy/scipy
"""
print __doc__
from rootpy.plotting import histogram, Canvas
from rootpy.interactive import wait
import time

import ROOT
import numpy as np

ROOT.gStyle.SetOptStat(0)


class Timer(object):
    def __enter__(self):
        self.__start = time.time()

    def __exit__(self, type, value, traceback):
        self.__finish = time.time()

    def duration_in_seconds(self):
        return self.__finish - self.__start


data0 = "normal_small", np.random.normal(0.5, 1, 200)
data1 = "normal", np.random.normal(0.5, 1, 100000)
data2 = "uniform", np.random.random(100000)
data3 = "normal+uniform", np.concatenate((data1[1], 10 * data2[1]))
data4 = "normal+normal", np.concatenate((data1[1], np.random.normal(2.5, 0.1, 100000)))

if ROOT.gROOT.IsBatch():
    datas = (data0, data1)
else:
    datas = (data0, data1, data2, data3, data4)

recipes = (
    "manual1", "sturges", "sturges-doane", "scott", "sqrt",
    "doane", "freedman-diaconis", "risk", "knuth")
objs = []
canvas = Canvas()
canvas.Divide(len(recipes), len(datas), 1E-3, 1E-3)
print '-' * 57
print '\t\t{0:<20s}{1:>10s}   {2:<6s}'.format('method', 'bins', 'time [s]')
print '-' * 57
for id, (dataname, d) in enumerate(datas):
    print dataname
    for ir, r in enumerate(recipes):
        canvas.cd(id * len(recipes) + ir + 1)
        timer = Timer()
        if r == "manual1":
            with timer:
                bins, h = histogram(d, 50, np.min(d), np.max(d),
                                    drawstyle='hist')
        else:
            with timer:
                bins, h = histogram(d, binning=r, drawstyle='hist')
        print '\t\t{0:<20s}{1:>10d}   {2:<6.2f}'.format(
            r, h.GetNbinsX(), timer.duration_in_seconds())
        h.Draw()
        h.GetYaxis().SetRangeUser(0, h.GetMaximum() * 1.2)
        l = ROOT.TLatex(0.15, 0.8, "{0}: {1:d}".format(r, h.GetNbinsX()))
        l.SetNDC()
        l.SetTextSize(0.1)
        l.Draw()
        canvas.Update()

wait()

########NEW FILE########
__FILENAME__ = plot_bin_merging
#!/usr/bin/env python
"""
=====================
Merge Histograms Bins
=====================

rootpy implements an additional histogram bin merging method making it easier
to merge bins in specified windows of bin indices.
"""
print __doc__
import ROOT
from rootpy.interactive import wait
from rootpy.plotting import Canvas, Hist, Hist2D
from rootpy.plotting.style import set_style
import numpy as np
from random import randint, choice
import time
import os

set_style('ATLAS')
BATCH = ROOT.gROOT.IsBatch()


def random_bin_merge(h):
    # randomly choose axis
    if h.GetDimension() > 1:
        axis = choice([
            axis for axis in range(h.GetDimension()) if h.nbins(axis) > 1])
    else:
        axis = 0
    # randomly choose starting bin
    start = randint(1, h.nbins(axis) - 1)
    end = randint(start + 1, min(start + 5 * h.GetDimension(), h.nbins(axis)))
    return h.merge_bins([(start, end)], axis=axis)

# create an animation of a 1D histogram
c1 = Canvas()
if not BATCH and os.path.isfile('binmerge1d.gif'):
    os.unlink('binmerge1d.gif')
a = Hist(100, -5, 5)
a.fill_array(np.random.randn(10000))
while a.nbins(0) > 1:
    a = random_bin_merge(a)
    a.Draw('hist')
    if not BATCH:
        c1.Print('binmerge1d.gif+20')
        time.sleep(.1)
if not BATCH:
    c1.Print('binmerge1d.gif++')

# create an animation of a 2D histogram
c2 = Canvas()
if not BATCH and os.path.isfile('binmerge2d.gif'):
    os.unlink('binmerge2d.gif')
c2.SetRightMargin(0.1)
b = Hist2D(100, -5, 5, 100, -5, 5)
b.fill_array(np.random.randn(10000, 2))
while b.nbins(0) > 1 or b.nbins(1) > 1:
    b = random_bin_merge(b)
    b.Draw('LEGO20')
    if not BATCH:
        c2.Print('binmerge2d.gif+20')
        time.sleep(.1)
if not BATCH:
    c2.Print('binmerge2d.gif++')

########NEW FILE########
__FILENAME__ = plot_hist
#!/usr/bin/env python
"""
============================
Working with ROOT histograms
============================

This example demonstrates how to create and work with ROOT histogram in rootpy.
"""
print __doc__
from rootpy.plotting import Hist, Hist2D, Hist3D, HistStack, Legend, Canvas
from rootpy.interactive import wait
import random

# create a simple 1D histogram with 10 constant-width bins between 0 and 1
h_simple = Hist(10, 0, 1)
print h_simple.name

# If the name is not specified, a UUID is used so that ROOT never complains
# about two histograms having the same name.
# Alternatively you can specify the name (and the title or any other style
# attributes) in the constructor:
h_simple = Hist(10, -4, 12, name='my hist', title='Some Data',
                drawstyle='hist',
                legendstyle='F',
                fillstyle='/')

# fill the histogram
for i in xrange(1000):
    # all ROOT CamelCase methods are aliased by equivalent snake_case methods
    # so you can call fill() instead of Fill()
    h_simple.Fill(random.gauss(4, 3))

# easily set visual attributes
h_simple.linecolor = 'blue'
h_simple.fillcolor = 'green'
h_simple.fillstyle = '/'

# attributes may be accessed in the same way
print h_simple.name
print h_simple.title
print h_simple.markersize

# plot
canvas = Canvas(width=700, height=500)
canvas.SetLeftMargin(0.15)
canvas.SetBottomMargin(0.15)
canvas.SetTopMargin(0.10)
canvas.SetRightMargin(0.05)
h_simple.Draw()

# create the legend
legend = Legend([h_simple], pad=canvas,
                header='Header',
                leftmargin=0.05,
                rightmargin=0.5)
legend.Draw()

# 2D and 3D histograms are handled in the same way
# the constructor arguments are repetitions of #bins, left bound, right bound.
h2d = Hist2D(10, 0, 1, 50, -40, 10, name='2d hist')
h3d = Hist3D(3, -1, 4, 10, -1000, -200, 2, 0, 1, name='3d hist')

# variable-width bins may be created by passing the bin edges directly:
h1d_variable = Hist([1, 4, 10, 100])
h2d_variable = Hist2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20])
h3d_variable = Hist3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20])

# variable-width and constant-width bins can be mixed:
h2d_mixed = Hist2D([2, 10, 30], 10, 1, 5)

# wait for you to close all open canvases before exiting
# wait() will have no effect if ROOT is in batch mode:
# ROOT.gROOT.SetBatch(True)
wait()

########NEW FILE########
__FILENAME__ = plot_matplotlib_graph
#!/usr/bin/env python
"""
=====================================
Plot a ROOT graph with matplotlib
=====================================

This example demonstrates how a ROOT graph can be styled with simple
attributes and displayed via ROOT or matplotlib.
"""
print __doc__
import ROOT
import numpy as np
from rootpy.plotting import Canvas, Graph
from rootpy.plotting.style import get_style, set_style
from rootpy.interactive import wait
import rootpy.plotting.root2matplotlib as rplt
import matplotlib.pyplot as plt
from matplotlib.ticker import AutoMinorLocator, MultipleLocator

# set the random seed
ROOT.gRandom.SetSeed(42)
np.random.seed(42)

# points
x = np.sort(np.random.random(10)) * 3500
y = np.random.random(10)

# set style for ROOT
set_style('ATLAS')

# create graph
graph = Graph(x.shape[0])
for i, (xx, yy) in enumerate(zip(x, y)):
    graph.SetPoint(i, xx, yy)

# set visual attributes
graph.linecolor = 'blue'
graph.markercolor = 'blue'
graph.xaxis.SetTitle("E_{T} [GeV]")
graph.yaxis.SetTitle("d#sigma_{jet}/dE_{T,jet} [fb/GeV]")
graph.xaxis.SetRangeUser(0, 3500)
graph.yaxis.SetRangeUser(0, 1)

# plot with ROOT
canvas = Canvas()
graph.Draw("APL")

label = ROOT.TText(0.4, 0.8, "ROOT")
label.SetTextFont(43)
label.SetTextSize(25)
label.SetNDC()
label.Draw()
canvas.Modified()
canvas.Update()

# plot with matplotlib

def plot_with_matplotlib():
    fig, axes = plt.subplots()

    axes.plot(x, y, 'o-', markeredgewidth=0)
    axes.set_xlabel(r"$E_T$ [GeV]",
                    horizontalalignment="right", x=1, labelpad=20)
    axes.set_ylabel(r"$d\sigma_{jet}/dE_{T,jet}$ [fb/GeV]",
                    horizontalalignment="right", y=1, labelpad=32)
    axes.set_xlim(0, 3500)
    axes.set_ylim(0, 1)

    return fig, axes

# plot without style
fig1, axes1 = plot_with_matplotlib()
axes1.text(0.4, 0.8, 'matplotlib (no style)',
           verticalalignment='center', horizontalalignment='center',
           transform=axes1.transAxes, fontsize=20)

# plot with ATLAS style
set_style('ATLAS', mpl=True)
fig2, axes2 = plot_with_matplotlib()
axes2.text(0.4, 0.8, 'matplotlib',
           verticalalignment='center', horizontalalignment='center',
           transform=axes2.transAxes, fontsize=20)
axes2.xaxis.set_minor_locator(AutoMinorLocator())
axes2.yaxis.set_minor_locator(AutoMinorLocator())

if not ROOT.gROOT.IsBatch():
    plt.show()

# wait for you to close the canvas before exiting
wait(True)

########NEW FILE########
__FILENAME__ = plot_matplotlib_hist
#!/usr/bin/env python
"""
=====================================
Plot a ROOT histogram with matplotlib
=====================================

This example demonstrates how a ROOT histogram can be styled with simple
attributes and displayed via ROOT or matplotlib.
"""
print __doc__
import ROOT
import numpy as np
from rootpy.plotting import Hist, HistStack, Legend, Canvas
from rootpy.plotting.style import get_style, set_style
from rootpy.plotting.utils import get_limits
from rootpy.interactive import wait
import rootpy.plotting.root2matplotlib as rplt
import matplotlib.pyplot as plt
from matplotlib.ticker import AutoMinorLocator, MultipleLocator

# set the style
style = get_style('ATLAS')
style.SetEndErrorSize(3)
set_style(style)

# set the random seed
ROOT.gRandom.SetSeed(42)
np.random.seed(42)

# signal distribution
signal = 126 + 10 * np.random.randn(100)
signal_obs = 126 + 10 * np.random.randn(100)

# create histograms
h1 = Hist(30, 40, 200, title='Background', markersize=0)
h2 = h1.Clone(title='Signal')
h3 = h1.Clone(title='Data')
h3.markersize = 1.2

# fill the histograms with our distributions
h1.FillRandom('landau', 1000)
map(h2.Fill, signal)
h3.FillRandom('landau', 1000)
map(h3.Fill, signal_obs)

# set visual attributes
h1.fillstyle = 'solid'
h1.fillcolor = 'green'
h1.linecolor = 'green'
h1.linewidth = 0

h2.fillstyle = 'solid'
h2.fillcolor = 'red'
h2.linecolor = 'red'
h2.linewidth = 0

stack = HistStack()
stack.Add(h1)
stack.Add(h2)

# plot with ROOT
canvas = Canvas(width=700, height=500)

# try setting logy=True and uncommenting the two lines below
xmin, xmax, ymin, ymax = get_limits([stack, h3], logy=False)
stack.SetMaximum(ymax)
#stack.SetMinimum(ymin)
#canvas.SetLogy()

stack.Draw('HIST E1 X0')
h3.Draw('SAME E1 X0')
stack.xaxis.SetTitle('Mass')
stack.yaxis.SetTitle('Events')
# set the number of expected legend entries
legend = Legend(3, leftmargin=0.45, margin=0.3)
legend.AddEntry(h1, style='F')
legend.AddEntry(h2, style='F')
legend.AddEntry(h3, style='LEP')
legend.Draw()
label = ROOT.TText(0.3, 0.8, 'ROOT')
label.SetTextFont(43)
label.SetTextSize(25)
label.SetNDC()
label.Draw()
canvas.Modified()
canvas.Update()

# plot with matplotlib
set_style('ATLAS', mpl=True)
fig = plt.figure(figsize=(7, 5), dpi=100)
axes = plt.axes()
axes.xaxis.set_minor_locator(AutoMinorLocator())
axes.yaxis.set_minor_locator(AutoMinorLocator())
axes.yaxis.set_major_locator(MultipleLocator(20))
rplt.bar(stack, stacked=True, axes=axes)
rplt.errorbar(h3, xerr=False, emptybins=False, axes=axes)
plt.xlabel('Mass', position=(1., 0.), va='bottom', ha='right')
plt.ylabel('Events', position=(0., 1.), va='top', ha='right')
axes.xaxis.set_label_coords(1., -0.20)
axes.yaxis.set_label_coords(-0.18, 1.)
leg = plt.legend()
axes.text(0.3, 0.8, 'matplotlib',
          verticalalignment='center', horizontalalignment='center',
          transform=axes.transAxes, fontsize=20)

if not ROOT.gROOT.IsBatch():
    plt.show()
    # wait for you to close the ROOT canvas before exiting
    wait(True)

########NEW FILE########
__FILENAME__ = plot_matplotlib_hist2d
#!/usr/bin/env python
"""
========================================
Plot a 2D ROOT histogram with matplotlib
========================================

This example demonstrates how a 2D ROOT histogram can be displayed with
matplotlib.
"""
print __doc__
import ROOT
from matplotlib import pyplot as plt
from rootpy.plotting import root2matplotlib as rplt
from rootpy.plotting import Hist2D
import numpy as np

a = Hist2D(100, -3, 3, 100, 0, 6)
a.fill_array(np.random.multivariate_normal(
    mean=(0, 3),
    cov=np.arange(4).reshape(2, 2),
    size=(1E6,)))

fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))

ax1.set_title('hist2d')
rplt.hist2d(a, axes=ax1)

ax2.set_title('imshow')
im = rplt.imshow(a, axes=ax2)

ax3.set_title('contour')
rplt.contour(a, axes=ax3)

fig.subplots_adjust(right=0.8)
cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])
fig.colorbar(im, cax=cbar_ax)

if not ROOT.gROOT.IsBatch():
    plt.show()

########NEW FILE########
__FILENAME__ = plot_overlay
#!/usr/bin/env python
"""
============================
Overlay Histograms or Graphs
============================

This example demonstrates how to overlay multiple histograms or graphs while
automatically setting axis limits that are visually pleasing.
"""
print __doc__
from rootpy.plotting import F1, Hist, HistStack, Graph, Canvas, set_style
from rootpy.plotting.utils import draw
from rootpy.interactive import wait
from math import sin

set_style('ATLAS')

mus = (0, -1, 2)
sigmas = (2, 1, 0.5)
events = (1000, 2000, 100)
colors = ('lawngreen', 'forestgreen', 'mistyrose')
styles = ('\\', '/', '-')

canvas = Canvas()
objects = []

# create a stack
stack = HistStack()
stack.Add(Hist(100, -5, 5, color='salmon', drawstyle='hist').FillRandom(
          F1('TMath::Gaus(x, 2, 1)'), 500))
stack.Add(Hist(100, -5, 5, color='powderblue', drawstyle='hist').FillRandom(
          F1('TMath::Gaus(x, 2, 0.6)'), 300))
objects.append(stack)

# create some random histograms
for i, (mu, sigma, n, c, s) in enumerate(zip(mus, sigmas, events, colors, styles)):
    hist = Hist(100, -5, 5, color=c, fillstyle=s, drawstyle='hist' if i % 2 == 0 else '')
    hist.FillRandom(F1('TMath::Gaus(x,{0},{1})'.format(mu, sigma)), n)
    objects.append(hist)

# create a graph
graph = Graph(10, drawstyle='P')
for i in xrange(10):
    x = -2 + i * 4 / 10.
    graph.SetPoint(i, x, 40 + 10 * sin(x))
objects.append(graph)

draw(objects, xtitle='Some Variable [Units]', ytitle='Events', ypadding=0.05)
# see rootpy.plotting.utils.get_limits for details on what arguments are
# supported for setting the axes ranges.
wait()

########NEW FILE########
__FILENAME__ = plot_style
#!/usr/bin/env python
"""
==========================
Setting the plotting style
==========================

This example demonstrates how to set the plotting style.
"""
print __doc__

from rootpy.extern.argparse import ArgumentParser

parser = ArgumentParser()
parser.add_argument('style', default='ATLAS', nargs='?')
args, extra = parser.parse_known_args()

import ROOT
from rootpy.plotting import Canvas, Hist
from rootpy.plotting.style import get_style
from rootpy.interactive import wait

try:
    kwargs = {}
    for arg in extra:
        name, value = arg.lstrip('--').split('=')
        kwargs[name] = value
except ValueError:
    print("specify style parameters with --name=value")

try:
    style = get_style(args.style, **kwargs)
except ValueError:
    print('Invalid style: `{0}`. Using the `ATLAS` style.'.format(args.style))
    style = get_style('ATLAS')

# Use styles as context managers. The selected style will only apply
# within the following context:
with style:
    c = Canvas()
    hpx = Hist(100, -4, 4, name="hpx", title="This is the px distribution")
    # generate some random data
    ROOT.gRandom.SetSeed()
    for i in xrange(25000):
        hpx.Fill(ROOT.gRandom.Gaus())
    hpx.GetXaxis().SetTitle("random variable [unit]")
    hpx.GetYaxis().SetTitle("#frac{dN}{dr} [unit^{-1}]")
    hpx.SetMaximum(1000.)
    hpx.Draw()
    wait()

########NEW FILE########
__FILENAME__ = plot_quantiles
#!/usr/bin/env python
"""
=================================================
Draw a Quantile-Quantile Plot and Confidence Band
=================================================

This is an example of drawing a quantile-quantile plot with a confidence level
(CL) band.
"""
print __doc__
import ROOT
from rootpy.interactive import wait
from rootpy.plotting import Hist, Canvas, Legend, set_style
from rootpy.plotting.contrib.quantiles import qqgraph

set_style('ATLAS')

c = Canvas(width=1200, height=600)
c.Divide(2, 1, 1e-3, 1e-3)

rand = ROOT.TRandom3()
h1 = Hist(100, -5, 5, name="h1", title="Histogram 1",
          linecolor='red', legendstyle='l')
h2 = Hist(100, -5, 5, name="h2", title="Histogram 2",
          linecolor='blue', legendstyle='l')

for ievt in xrange(10000):
    h1.Fill(rand.Gaus(0, 0.8))
    h2.Fill(rand.Gaus(0, 1))

pad = c.cd(1)

h1.Draw('hist')
h2.Draw('hist same')

leg = Legend([h1, h2], pad=pad, leftmargin=0.5,
             topmargin=0.11, rightmargin=0.05,
             textsize=20)
leg.Draw()

pad = c.cd(2)

gr = qqgraph(h1, h2)

gr.xaxis.title = h1.title
gr.yaxis.title = h2.title
gr.fillcolor = 17
gr.fillstyle = 'solid'
gr.linecolor = 17
gr.markercolor = 'darkred'
gr.markerstyle = 20
gr.title = "QQ with CL"

gr.Draw("ap")
x_min = gr.GetXaxis().GetXmin()
x_max = gr.GetXaxis().GetXmax()
y_min = gr.GetXaxis().GetXmin()
y_max = gr.GetXaxis().GetXmax()
gr.Draw('a3')
gr.Draw('Xp same')

# a straight line y=x to be a reference
f_dia = ROOT.TF1("f_dia", "x",
                 h1.GetXaxis().GetXmin(),
                 h1.GetXaxis().GetXmax())
f_dia.SetLineColor(9)
f_dia.SetLineWidth(2)
f_dia.SetLineStyle(2)
f_dia.Draw("same")

leg = Legend(3, pad=pad, leftmargin=0.45,
             topmargin=0.45, rightmargin=0.05,
             textsize=20)
leg.AddEntry(gr, "QQ points", "p")
leg.AddEntry(gr, "68% CL band", "f")
leg.AddEntry(f_dia, "Diagonal line", "l")
leg.Draw()

c.Modified()
c.Update()
c.Draw()
wait()

########NEW FILE########
__FILENAME__ = chain
#!/usr/bin/env python
"""
=============================================
The TreeChain class, a replacement for TChain
=============================================

This example demonstrates how to use the TreeChain class, a more Python-friendly
TChain replacement.
"""
print __doc__
from random import gauss
from rootpy.io import root_open
from rootpy.tree import Tree, TreeChain
from rootpy.plotting import Hist

# Make two files, each with a Tree called "test"

print "Creating test tree in chaintest1.root"
f = root_open("chaintest1.root", "recreate")

tree = Tree("test")
branches = {
     'x': 'F',
     'y': 'F',
     'z': 'F',
     'i': 'I'}
tree.create_branches(branches)

for i in xrange(10000):
    tree.x = gauss(.5, 1.)
    tree.y = gauss(.3, 2.)
    tree.z = gauss(13., 42.)
    tree.i = i
    tree.fill()

# Make a histogram of x when y > 1
hist1 = Hist(100, -10, 10, name='hist1')
tree.Draw('x', 'y > 1', hist=hist1)
hist1.SetDirectory(0) # memory resident
print "The first tree has {0:f} entries where y > 1".format(hist1.Integral())

tree.write()
f.close()

print "Creating test tree in chaintest2.root"
f = root_open("chaintest2.root", "recreate")

tree = Tree("test")
tree.create_branches(branches)

for i in xrange(10000):
    tree.x = gauss(.5, 1.)
    tree.y = gauss(.3, 2.)
    tree.z = gauss(13., 42.)
    tree.i = i
    tree.fill()
tree.write()

# Make a histogram of the second tree
hist2 = Hist(100, -10, 10, name='hist2')
tree.Draw('x', 'y > 1', hist=hist2)
hist2.SetDirectory(0) # memory resident
print "The second tree has {0:f} entries where y > 1".format(hist2.Integral())
f.close()

combined_hist = hist1 + hist2

print "Building TreeChain"
chain = TreeChain('test', ['chaintest2.root', 'chaintest1.root'])
# Make the equivalent of the combined_hist
combined_hist_chain = Hist(100, -10, 10, name='combined')
chain.Draw('x', 'y > 1', hist=combined_hist_chain)

residual = combined_hist_chain - combined_hist
print (
    "The combined histogram (separately) minus "
    "the combined from the chain has {0:f} entries".format(
        residual.Integral()))

########NEW FILE########
__FILENAME__ = chain_overwrite
#!/usr/bin/env python
"""
============================================
Copy a tree chain while overwriting branches
============================================

This is an example showing how to copy a tree chain while overwriting one or
more of its branches with new values.
"""
print __doc__
from rootpy.tree import Tree, TreeModel, TreeChain, FloatCol, IntCol
from rootpy.io import root_open
from random import gauss

"""
This first section of code only creates an example tree chain.
"""

class Event(TreeModel):
    """Event model definition"""
    x = FloatCol()
    y = FloatCol()
    z = FloatCol()
    i = IntCol()

# first create several example trees in separate files
fnames = ["test_{0:d}.root".format(i) for i in xrange(5)]

for fname in fnames:
    with root_open(fname, "recreate") as f:

        tree = Tree("test", model=Event)

        # fill the tree
        for i in xrange(100):
            tree.x = gauss(.5, 1.)
            tree.y = gauss(.3, 2.)
            tree.z = gauss(13., 42.)
            tree.i = i
            tree.fill()
        tree.write()

"""
This section below takes the example trees and copies it while overwriting a
branch with new values.
"""

# first define the chain of trees
chain = TreeChain(name="test", files=fnames)

# Now we want to copy the tree above into a new file while overwriting a branch
# First create a new file to save the new tree in:
f_copy = root_open("test_copy.root", "recreate")

# You may not know the entire model of the original tree but only the branches
# you intend to overwrite, so I am not specifying the model=Event below as an
# example of how to deal with this in general:
tree_copy = Tree("test_copy")

# If the original tree was not handed to you through rootpy don't forget to:
# >>> from rootpy import asrootpy
# >>> tree = asrootpy(tree)

# Here we specify the buffer for the new tree to use. We use the same buffer as
# the original tree. This creates all the same branches in the new tree but
# their addresses point to the same memory used by the original tree.
tree_copy.set_buffer(
        chain._buffer,
        create_branches=True)

# Now loop over the original tree and fill the new tree
for entry in chain:
    # Overwrite a branch value. This changes the value that will be written to
    # the new tree but leaves the value unchanged in the original tree on disk.
    entry.x = 3.141
    # "entry" is actually the buffer, which is shared between both trees.
    tree_copy.Fill()

# tree_copy is now a copy of tree where the "x" branch has been overwritten
# with new values
tree_copy.Write()
f_copy.Close()

########NEW FILE########
__FILENAME__ = model
#!/usr/bin/env python
"""
==================================
Tree models and object collections
==================================

This example demonstrates how to define a tree model and collections of objects
associated to sets of tree branches.
"""
print __doc__
from rootpy.tree import Tree, TreeModel, FloatCol, IntCol
from rootpy.io import root_open
from rootpy.vector import LorentzVector
from rootpy import stl
from random import gauss, randint


f = root_open("test.root", "recreate")


# define the model
class Event(TreeModel):
    # properties of particle "a"
    a_x = FloatCol()
    a_y = FloatCol()
    a_z = FloatCol()
    # properties of particle "b"
    b_x = FloatCol()
    b_y = FloatCol()
    b_z = FloatCol()
    # a collection of particles
    col_x = stl.vector("float")
    col_y = stl.vector("float")
    col_z = stl.vector("float")
    col_n = IntCol()
    # a TLorentzVector
    p = LorentzVector
    i = IntCol()

tree = Tree("test", model=Event)

# fill the tree
for i in xrange(10):
    tree.a_x = gauss(.5, 1.)
    tree.a_y = gauss(.3, 2.)
    tree.a_z = gauss(13., 42.)

    tree.b_x = gauss(.5, 1.)
    tree.b_y = gauss(.3, 2.)
    tree.b_z = gauss(13., 42.)

    n = randint(1, 10)
    for j in xrange(n):
        tree.col_x.push_back(gauss(.5, 1.))
        tree.col_y.push_back(gauss(.3, 2.))
        tree.col_z.push_back(gauss(13., 42.))
    tree.col_n = n

    tree.p.SetPtEtaPhiM(gauss(.5, 1.),
                        gauss(.5, 1.),
                        gauss(.5, 1.),
                        gauss(.5, 1.))

    tree.i = i
    tree.fill(reset=True)
tree.write()

f.close()
f = root_open("test.root")

tree = f.test

# define objects by prefix:
tree.define_object(name='a', prefix='a_')
tree.define_object(name='b', prefix='b_')


# define a mixin class to add functionality to a tree object
class Particle(object):

    def who_is_your_daddy(self):
        print "You are!"

# define collections of objects by prefix
tree.define_collection(name='particles',
                       prefix='col_',
                       size='col_n',
                       mix=Particle)

# loop over "events" in tree
for event in tree:
    print "a.x: {0:f}".format(event.a.x)
    print "b.y: {0:f}".format(event.b.y)
    # loop over "particles" in current event
    for p in event.particles:
        print "p.x: {0:f}".format(p.x)
        p.who_is_your_daddy()
    print event.p.Eta()

f.close()

########NEW FILE########
__FILENAME__ = model_hierarchy
#!/usr/bin/env python
"""
==================================
A complex hierarchy of tree models
==================================

This example demonstrates how to construct complex tree models by combining
multiple simple models.
"""
print __doc__
from rootpy.tree import TreeModel, BoolCol, IntCol
from rootpy.vector import LorentzVector, Vector2


class FourMomentum(TreeModel):
    """
    Base model for all four-momentum objects
    """
    fourmomentum = LorentzVector


class MatchedObject(TreeModel):
    """
    Base model for all objects which may be matched
    to other objects
    """
    matched = BoolCol()


class Jet(FourMomentum, MatchedObject):
    """
    A jet is a matchable four-momentum and
    a boolean flag signifying whether ot not it
    has been flagged as a b-jet
    """
    btagged = BoolCol()


class Tau(FourMomentum, MatchedObject):
    """
    A tau is a matchable four-momentum
    with a number of tracks and a charge
    """
    numtrack = IntCol()
    charge = IntCol()


class Event(Jet.prefix('jet1_'), Jet.prefix('jet2_'),
            Tau.prefix('tau1_'), Tau.prefix('tau2_')):
    """
    An event is composed of two jets and two taus
    an event number and some missing transverse energy
    """
    eventnumber = IntCol()
    missingET = Vector2

print Event

print '=' * 30
# you may also generate classes with simple addition (and subtraction)
print(Jet.prefix('jet1_') + Jet.prefix('jet2_') +
      Tau.prefix('tau1_') + Tau.prefix('tau2_'))

print '=' * 30
# create a TreeBuffer from a TreeModel
buffer = Event()
print type(buffer)
print buffer

print '=' * 30
# convert the Event into a compiled C struct
Event_struct = Event.to_struct()

event = Event_struct()

print event
print dir(event)

event.jet2_matched = True
print event.jet2_matched

########NEW FILE########
__FILENAME__ = model_simple
#!/usr/bin/env python
"""
===================
A simple tree model
===================

This example demonstrates how to define a simple tree model.
"""
print __doc__
from rootpy.tree import Tree, TreeModel
from rootpy.tree import IntCol, FloatCol, FloatArrayCol, CharCol, CharArrayCol
from rootpy.io import root_open
from random import gauss, choice, sample
from string import letters

f = root_open("test.root", "recreate")

# define the model
class Event(TreeModel):
    s = CharCol()
    string = CharArrayCol(5)
    x = FloatCol()
    y = FloatCol()
    z = FloatCol()
    f = FloatArrayCol(5)
    i = IntCol()

tree = Tree("test", model=Event)

# fill the tree
for i in xrange(100):
    tree.s = choice(letters)
    tree.string = ''.join(sample(letters, 4))
    tree.x = gauss(.5, 1.)
    tree.y = gauss(.3, 2.)
    tree.z = gauss(13., 42.)
    for j in xrange(5):
        tree.f[j] = gauss(-2, 5)
    tree.i = i
    tree.fill()
tree.write()

# write tree in CSV format
tree.csv()

f.close()

########NEW FILE########
__FILENAME__ = ntuple
#!/usr/bin/env python
"""
=======================
A simple Ntuple example
=======================

This example demonstrates how to create a simple Ntuple.
"""
print __doc__
from rootpy.tree import Ntuple
from rootpy.io import root_open
from random import gauss

f = root_open("test.root", "recreate")

# create an ntuple with three float fields: a, b, c
ntuple = Ntuple(('a', 'b', 'c'), name="test")

# fill the ntuple with random data
for i in xrange(20):
    ntuple.Fill(gauss(.5, 1.), gauss(.3, 2.), gauss(13., 42.))
ntuple.write()

# write as CSV
ntuple.csv()

f.close()

########NEW FILE########
__FILENAME__ = object_branch
#!/usr/bin/env python
"""
===============
Object branches
===============

This simple example demonstrates how to define a TreeModel with a branch of type
std::vector<TLorentzVector>.
"""
print __doc__
from rootpy.vector import LorentzVector
from rootpy.tree import Tree, TreeModel, IntCol
from rootpy.io import root_open
from rootpy import stl
from random import gauss


f = root_open("test.root", "recreate")

# define the model
class Event(TreeModel):

    x = stl.vector('TLorentzVector')
    i = IntCol()

tree = Tree("test", model=Event)

# fill the tree
for i in xrange(100):
    tree.x.clear()
    for j in xrange(5):
        vect = LorentzVector(
                gauss(.5, 1.),
                gauss(.5, 1.),
                gauss(.5, 1.),
                gauss(.5, 1.))
        tree.x.push_back(vect)
    tree.i = i
    tree.fill()

tree.write()
f.close()

########NEW FILE########
__FILENAME__ = overwrite
#!/usr/bin/env python
"""
======================================
Copy a tree while overwriting branches
======================================

This is an example showing how to copy a tree while overwriting one or more of
its branches with new values.
"""
print __doc__
from rootpy.tree import Tree, TreeModel, FloatCol, IntCol
from rootpy.io import root_open
from random import gauss

"""
This first section of code only creates an example tree.
"""

# define the model
class Event(TreeModel):
    x = FloatCol()
    y = FloatCol()
    z = FloatCol()
    i = IntCol()

# first create a tree "test" in a file "test.root"
f = root_open("test.root", "recreate")

tree = Tree("test", model=Event)

# fill the tree
for i in xrange(10000):
    tree.x = gauss(.5, 1.)
    tree.y = gauss(.3, 2.)
    tree.z = gauss(13., 42.)
    tree.i = i
    tree.fill()
tree.write()

"""
This section below takes the example tree and copies it while overwriting a
branch with new values.
"""

# Now we want to copy the tree above into a new file while overwriting a branch
# First create a new file to save the new tree in:
f_copy = root_open("test_copy.root", "recreate")

# You may not know the entire model of the original tree but only the branches
# you intend to overwrite, so I am not specifying the model=Event below as an
# example of how to deal with this in general:
tree_copy = Tree("test_copy")

# Here we specify the buffer for the new tree to use. We use the same buffer as
# the original tree. This creates all the same branches in the new tree but
# their addresses point to the same memory used by the original tree.
tree_copy.set_buffer(tree._buffer, create_branches=True)

# Now loop over the original tree and fill the new tree
for entry in tree:
    # Overwrite a branch value. This changes the value that will be written to
    # the new tree but leaves the value unchanged in the original tree on disk.
    entry.x = 3.141
    # "entry" is actually the buffer, which is shared between both trees.
    tree_copy.Fill()

# tree_copy is now a copy of tree where the "x" branch has been overwritten
# with new values
tree_copy.Write()
f_copy.Close()
f.Close()

########NEW FILE########
__FILENAME__ = simple
#!/usr/bin/env python
"""
=====================
A simple Tree example
=====================

This example demonstrates how to create a simple tree.
"""
print __doc__
from rootpy.tree import Tree
from rootpy.io import root_open
from random import gauss

f = root_open("test.root", "recreate")

tree = Tree("test")
tree.create_branches(
    {'x': 'F',
     'y': 'F',
     'z': 'F',
     'i': 'I'})

for i in xrange(10000):
    tree.x = gauss(.5, 1.)
    tree.y = gauss(.3, 2.)
    tree.z = gauss(13., 42.)
    tree.i = i
    tree.fill()
tree.write()

f.close()

########NEW FILE########
__FILENAME__ = user_object
#!/usr/bin/env python
"""
================================================
Create trees with branches of user-defined types
================================================

This example demonstrates how to fill and read trees with branches containing
user-defined types.
"""
print __doc__
from rootpy.tree import Tree, TreeModel, IntCol, ObjectCol
from rootpy.io import root_open
import rootpy.compiled as C
from random import gauss

# compile our new type
C.register_code("""

class Thingy {
    public:
        int i;
        float x;
        double y;
};

""", ["Thingy"])

# alternatively you can ROOT.gSystem.Load() your library

# define the model
class Event(TreeModel):
    event_number = IntCol()
    thingy = ObjectCol(C.Thingy)


f = root_open("test.root", "recreate")
tree = Tree("test", model=Event)

# fill the tree
for i in xrange(20):
    tree.event_number = i
    tree.thingy.i = i
    tree.thingy.x = gauss(.3, 2.)
    tree.thingy.y = gauss(13., 42.)
    tree.fill()

tree.write()
f.close()

# now to read the same tree
with root_open("test.root") as f:
    tree = f.test
    for event in tree:
        thing = event.thingy
        print event.event_number, thing.i, thing.x, thing.y

########NEW FILE########
__FILENAME__ = base
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module contains base classes defining core functionality
"""
from __future__ import absolute_import

import ROOT
import uuid

__all__ = [
    'isbasictype',
    'Object',
    'NamedObject',
    'NameOnlyObject',
    'NamelessConstructorObject',
]


def isbasictype(thing):
    """
    Is this thing a basic builtin numeric type?
    """
    return isinstance(thing, (float, int, long))


class Object(object):
    """
    The rootpy-side base class of all ROOT subclasses in rootpy
    Classes that inherit from this class must also inherit from ROOT.TObject.
    """
    def Clone(self, name=None, title=None, shallow=False, **kwargs):
        if name is None:
            name = uuid.uuid4().hex
        if shallow:
            # use the copy constructor
            clone = self._ROOT(self)
            clone.SetName(name)
        else:
            # a complete clone
            clone = super(Object, self).Clone(name)
        # cast
        clone.__class__ = self.__class__
        if title is not None:
            clone.SetTitle(title)
        if hasattr(clone, '_clone_post_init'):
            clone._clone_post_init(obj=self, **kwargs)
        elif hasattr(clone, '_post_init'):
            clone._post_init(**kwargs)
        return clone

    def copy_from(self, other):
        # not all classes implement Copy() correctly in ROOT, so use copy
        # constructor directly. Then again, not all classes in ROOT implement a
        # copy constructor or implement one correctly, so this might not work
        # everywhere...
        self._ROOT.__init__(self, other)

    @property
    def name(self):
        return self.GetName()

    @name.setter
    def name(self, _name):
        self.SetName(_name)

    @property
    def title(self):
        return self.GetTitle()

    @title.setter
    def title(self, _title):
        self.SetTitle(_title)

    def __copy__(self):
        return self.Clone(shallow=True)

    def __deepcopy__(self, memo):
        return self.Clone()

    def __str__(self):
        return self.__repr__()

    def __repr__(self):
        return "{0}('{1}')".format(
            self.__class__.__name__, self.GetName())


class NamedObject(Object):
    """
    Name and title for TNamed-derived classes are optional. If no name is
    specified, a UUID is used to ensure uniqueness.
    """
    def __init__(self, *args, **kwargs):
        name = kwargs.pop('name', None)
        title = kwargs.pop('title', None)
        if name is None:
            name = uuid.uuid4().hex
        if title is None:
            title = ''
        super(NamedObject, self).__init__(name, title, *args, **kwargs)


class NameOnlyObject(Object):
    """
    Handle special cases like TF1 where the constructor only takes a name.
    """
    def __init__(self, *args, **kwargs):
        name = kwargs.pop('name', None)
        if name is None:
            name = uuid.uuid4().hex
        super(NameOnlyObject, self).__init__(name, *args, **kwargs)


class NamelessConstructorObject(Object):
    """
    Handle special cases like TGraph where the ROOT constructor does not
    take name/title.
    """
    def __init__(self, *args, **kwargs):
        name = kwargs.pop('name', None)
        title = kwargs.pop('title', None)
        if name is None:
            name = uuid.uuid4().hex
        if title is None:
            title = ''
        super(NamelessConstructorObject, self).__init__(*args, **kwargs)
        self.SetName(name)
        self.SetTitle(title)

########NEW FILE########
__FILENAME__ = student
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

import os
import sys
import multiprocessing
from multiprocessing import Process
import uuid
import traceback
import signal
import cProfile as profile
import subprocess
import logging
try:
    logging.captureWarnings(True)
except AttributeError:
    pass

from .. import log; log = log[__name__]
from ..logger import multilogging
from ..io import root_open

__all__ = [
    'Student',
]


class Student(Process):

    def __init__(self,
                 name,
                 files,
                 output_queue,
                 logging_queue,
                 gridmode=False,
                 metadata=None,
                 profile=False,
                 nice=0,
                 **kwargs):

        super(Student, self).__init__()
        self.uuid = uuid.uuid4().hex
        self.filters = {}
        self.name = name
        self.files = files
        self.metadata = metadata
        self.logging_queue = logging_queue
        self.output_queue = output_queue
        self.output = None
        self.gridmode = gridmode
        self.nice = nice
        self.kwargs = kwargs
        self.output = None
        if self.gridmode:
            self.queuemode = False
        else:
            self.queuemode = isinstance(files, multiprocessing.queues.Queue)
        self.profile = profile

    def __repr__(self):
        return '{0}(id={1})'.format(self.name, self.uuid)

    def run(self):

        if not self.gridmode:
            # ignore sigterm signal and let the supervisor process handle this
            signal.signal(signal.SIGINT, signal.SIG_IGN)
            h = multilogging.QueueHandler(self.logging_queue)
            # get the top-level logger
            log_root = logging.getLogger()
            # clear any existing handlers in the top-level logger
            log_root.handlers = []
            # add the queuehandler
            log_root.addHandler(h)
            # direct stdout and stderr to the local logger
            sys.stdout = multilogging.stdout(log)
            sys.stderr = multilogging.stderr(log)

        ROOT.gROOT.SetBatch()

        os.nice(self.nice)

        try:
            filename = 'student-{0}-{1}.root'.format(
                self.name, self.uuid)
            with root_open(os.path.join(
                    os.getcwd(), filename), 'recreate') as self.output:
                if self.queuemode:
                    log.info("Receiving files from Supervisor's queue")
                else:
                    log.info(
                        "Received {0:d} files from Supervisor "
                        "for processing".format(
                            len(self.files)))
                self.output.cd()
                if self.profile:
                    profile_filename = 'student-{0}-{1}.profile'.format(
                        self.name, self.uuid)
                    profile.runctx(
                        'self.work()',
                        globals=globals(),
                        locals=locals(),
                        filename=profile_filename)
                    result = (
                        self.uuid,
                        [self.filters,
                         self.output.GetName(),
                         profile_filename])
                else:
                    self.work()
                    result = (
                        self.uuid,
                        [self.filters,
                         self.output.GetName()])
        except:
            if self.gridmode:
                raise
            print sys.exc_info()
            traceback.print_tb(sys.exc_info()[2])
            result = (self.uuid, None)

        if self.gridmode:
            id, result = result
            self.output_queue.append(result)
        else:
            self.output_queue.put(result)
            self.output_queue.close()
            self.logging_queue.close()

    @staticmethod
    def merge(inputs, output, metadata):
        """
        Default merging mechanism.
        Override this method to define merging behaviour suitable
        to your needs.
        """
        subprocess.call(['hadd', output + '.root'] + inputs)

    def work(self):
        """
        You must implement this method in your Student-derived class
        """
        raise NotImplementedError(
            "implement this method in your Student-derived class")

########NEW FILE########
__FILENAME__ = supervisor
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT
import time
import os
import sys
import multiprocessing
from multiprocessing import Process
# multiprocessing uses the exceptions from the Queue module
import Queue
import traceback
import signal
import pstats
import cStringIO as StringIO
import shutil
import logging
try:
    logging.captureWarnings(True)
except AttributeError:
    pass

from ..tree.filtering import FilterList
from ..io import root_open
from ..plotting import Hist
from ..logger import multilogging
from .. import log; log = log[__name__]
from .student import Student

__all__ = [
    'Supervisor',
]

NCPUS = multiprocessing.cpu_count()


class QueueFeeder(Process):

    def __init__(self, connection, objects, queue, numclients, sentinel=None):

        Process.__init__(self)
        self.connection = connection
        self.objects = objects
        self.queue = queue
        self.numclients = numclients
        self.sentinel = sentinel

    def run(self):

        # ignore sigterm signal and let parent take care of this
        signal.signal(signal.SIGINT, signal.SIG_IGN)

        self.queue.cancel_join_thread()
        self.objects = ([self.sentinel] * self.numclients) + \
            self.objects
        while self.objects:
            if self.connection.poll():
                print "queue feeder is shutting down..."
                break
            try:
                self.queue.put(self.objects[-1], 1)
                self.objects.pop()
            except Queue.Full:
                pass
        self.connection.close()
        print "queue feeder is closing the queue..."
        self.queue.close()
        print "queue feeder will now terminate"


class Supervisor(Process):

    def __init__(self,
                 student,
                 files,
                 outputname,
                 outputpath='.',
                 metadata=None,
                 nstudents=NCPUS,
                 connection=None,
                 gridmode=False,
                 queuemode=True,
                 nice=0,
                 name=None,
                 profile=False,
                 args=None,
                 **kwargs):

        super(Supervisor, self).__init__()
        self.process = student
        if isinstance(student, basestring):
            # remove .py extension if present
            student = os.path.splitext(student)[0]
            log.info("importing {0} ...".format(student))
            namespace = {}
            exec "from {0} import {1}".format(student, student) in namespace
            self.process = namespace[student]
        if not issubclass(self.process, Student):
            raise TypeError(
                "`{0}` must be a subclass of `Student`".format(student))
        if name is None:
            self.name = self.process.__name__
        else:
            self.name = name
        self.files = files[:]
        self.metadata = metadata
        self.outputname = '.'.join([self.name, outputname])
        self.outputpath = outputpath
        self.gridmode = gridmode
        self.nice = nice
        if self.gridmode:
            self.nstudents = 1
            queuemode = False
        else:
            if nstudents < 1:
                raise ValueError("`nstudents` must be at least 1")
            self.nstudents = min(nstudents, len(self.files))
        self.queuemode = queuemode
        self.kwargs = kwargs
        self.args = args
        self.connection = connection
        self.profile = profile
        self.student_outputs = list()
        self.process_table = dict()

    def run(self):

        if not self.gridmode:
            # ignore sigterm signal and let parent take care of this
            signal.signal(signal.SIGINT, signal.SIG_IGN)
            # logging
            self.logging_queue = multiprocessing.Queue(-1)
            self.listener = multilogging.Listener(os.path.join(
                self.outputpath,
                "supervisor-{0}-{1}.log".format(
                    self.name, self.outputname)),
                self.logging_queue)
            self.listener.start()
            h = multilogging.QueueHandler(self.logging_queue)
            # get the top-level logger
            log_root = logging.getLogger()
            # clear any existing handlers in the top-level logger
            log_root.handlers = []
            # add the queuehandler
            log_root.addHandler(h)
            # direct stdout and stderr to the local logger
            sys.stdout = multilogging.stdout(log)
            sys.stderr = multilogging.stderr(log)
            self.output_queue = multiprocessing.Queue(-1)
        else:
            self.output_queue = []

        ROOT.gROOT.SetBatch()

        if self.queuemode:
            self.file_queue = multiprocessing.Queue(self.nstudents * 2)
            self.file_queue_feeder_conn, connection = multiprocessing.Pipe()
            self.file_queue_feeder = QueueFeeder(
                connection=connection,
                objects=self.files,
                queue=self.file_queue,
                numclients=self.nstudents,
                sentinel=None)

        nfiles = len(self.files)
        log.info("Will run on {0:d} file{1}:".format(
            nfiles,
            's' if nfiles != 1 else ''))
        for filename in self.files:
            log.info(filename)
        if not self.gridmode:
            sys.stdout.flush()
        self.hire_students()
        try:
            if self.supervise():
                self.publish()
        except:
            print sys.exc_info()
            traceback.print_tb(sys.exc_info()[2])
        if not self.gridmode:
            self.retire()

    def hire_students(self):
        """
        Create students for each block of files
        """
        log.info("defining students...")
        if self.gridmode:
            students = [
                self.process(
                    name=self.name,
                    files=self.files,
                    output_queue=self.student_outputs,
                    logging_queue=None,
                    gridmode=self.gridmode,
                    metadata=self.metadata,
                    profile=self.profile,
                    nice=self.nice,
                    args=self.args,
                    **self.kwargs
                )]
        elif self.queuemode:
            students = [
                self.process(
                    name=self.name,
                    files=self.file_queue,
                    output_queue=self.output_queue,
                    logging_queue=self.logging_queue,
                    gridmode=self.gridmode,
                    metadata=self.metadata,
                    profile=self.profile,
                    nice=self.nice,
                    args=self.args,
                    **self.kwargs
                ) for _ in xrange(self.nstudents)]
        else:
            # deal out files
            filesets = [[] for _ in xrange(self.nstudents)]
            while len(self.files) > 0:
                for fileset in filesets:
                    if len(self.files) > 0:
                        fileset.append(self.files.pop(0))
                    else:
                        break
            students = [
                self.process(
                    name=self.name,
                    files=fileset,
                    output_queue=self.output_queue,
                    logging_queue=self.logging_queue,
                    gridmode=self.gridmode,
                    metadata=self.metadata,
                    profile=self.profile,
                    nice=self.nice,
                    args=self.args,
                    **self.kwargs
                ) for fileset in filesets]
        for p in students:
            log.info("initialized student {0}".format(p))
            self.process_table[p.uuid] = p

    def supervise(self):
        """
        Supervise students until they have finished or until one fails
        """
        log.info("supervising students...")
        if self.gridmode:
            if len(self.process_table) != 1:
                raise RuntimeError("gridmode is True while the process table "
                                   "does not contain one student")
            id = self.process_table.keys()[0]
            student = self.process_table[id]
            log.info("starting student {0}".format(student))
            student.run()
            return True
        if self.queuemode:
            self.file_queue_feeder.start()
        for student in self.process_table.values():
            log.info("starting student {0}".format(student))
            student.start()
        while self.process_table:
            if self.connection is not None and self.connection.poll():
                msg = self.connection.recv()
                if msg is None:
                    log.info("received termination command")
                    return False
            while not self.output_queue.empty():
                id, output = self.output_queue.get()
                process = self.process_table[id]
                process.join()
                del self.process_table[id]
                if output is not None and process.exitcode == 0:
                    self.student_outputs.append(output)
                    log.info("student {0} finished successfully".format(
                        process))
                else:
                    log.error("student {0} failed".format(process))
                    return False
            time.sleep(1)
        return True

    def publish(self):
        """
        Combine the output from all students
        """
        log.info("publishing output...")
        if len(self.student_outputs) == 0:
            return
        outputs = []
        all_filters = []
        if self.profile:
            profiles = []
            for filters, output, profile in self.student_outputs:
                all_filters.append(filters)
                outputs.append(output)
                profiles.append(profile)
            profile_output = StringIO.StringIO()
            profile_stats = pstats.Stats(profiles[0],
                                            stream=profile_output)
            for profile in profiles[1:]:
                profile_stats.add(profile)
            profile_stats.sort_stats('cumulative').print_stats(50)
            print "\nProfiling Results: \n {0}".format(
                profile_output.getvalue())
            for profile in profiles:
                os.unlink(profile)
        else:
            for filters, output in self.student_outputs:
                all_filters.append(filters)
                outputs.append(output)

        write_cutflows = False
        if all_filters[0]:
            write_cutflows = True
            print("\n===== Cut-flow of filters for dataset "
                  "{0}: ====\n".format(self.outputname))

            merged_filters = dict([(
                name,
                reduce(
                    FilterList.merge,
                    [all_filters[i][name]
                        for i in xrange(len(all_filters))]))
                for name in all_filters[0].keys()])

            for name, filterlist in merged_filters.items():
                print "\n{0} cut-flow\n{1}\n".format(name, filterlist)

        outputname = os.path.join(
            self.outputpath, '{0}.root'.format(self.outputname))
        if os.path.exists(outputname):
            os.unlink(outputname)
        if len(outputs) == 1:
            shutil.move(outputs[0], outputname)
        else:
            self.process.merge(
                outputs,
                os.path.join(self.outputpath, self.outputname),
                self.metadata)
            for output in outputs:
                os.unlink(output)
        if not write_cutflows:
            return
        # write cut-flow in ROOT file as TH1
        with root_open(outputname, 'UPDATE'):
            for name, filterlist in merged_filters.items():
                cutflow = Hist(
                    len(filterlist) + 1, .5,
                    len(filterlist) + 1.5,
                    name="cutflow_{0}".format(name),
                    title="{0} cut-flow".format(name),
                    type='d')
                cutflow[1].value = filterlist[0].total
                cutflow.GetXaxis().SetBinLabel(1, "Total")
                for i, filter in enumerate(filterlist):
                    cutflow[i + 2].value = filter.passing
                    cutflow.GetXaxis().SetBinLabel(i + 2, filter.name)
                cutflow.Write()
                # write count_func cutflow
                for func_name in filterlist[0].count_funcs.keys():
                    cutflow = Hist(
                        len(filterlist) + 1, .5,
                        len(filterlist) + 1.5,
                        name="cutflow_{0}_{1}".format(
                            name, func_name),
                        title="{0} {1} cut-flow".format(
                            name, func_name),
                        type='d')
                    cutflow[1].value = filterlist[0].count_funcs_total[func_name]
                    cutflow.GetXaxis().SetBinLabel(1, "Total")
                    for i, filter in enumerate(filterlist):
                        # assume func_name in all filters
                        cutflow[i + 2].value = filter.count_funcs_passing[func_name]
                        cutflow.GetXaxis().SetBinLabel(i + 2, filter.name)
                    cutflow.Write()

    def retire(self):
        """
        Shutdown the queues and terminate the remaining students
        """
        log.info("terminating...")
        for student in self.process_table.values():
            log.warning("terminating student {0}...".format(student))
            student.terminate()
        if self.queuemode:
            # tell queue feeder to quit
            log.debug("shutting down the file queue feeder...")
            self.file_queue_feeder_conn.send(None)
            log.debug("joining the file queue feeder process...")
            self.file_queue_feeder.join()
            log.debug("the file queue feeder process is terminated")
            self.file_queue_feeder_conn.close()
            log.debug("closing the file queue...")
            self.file_queue.close()
        log.debug("closing the output queue...")
        self.output_queue.close()
        log.debug("closing the logging queue...")
        self.logging_queue.put(None)
        self.listener.join()

########NEW FILE########
__FILENAME__ = collection
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from collections import namedtuple

import ROOT

from . import QROOT, asrootpy
from .base import Object

__all__ = [
    'List',
    'ObjArray',
]


TListItemWithOption = namedtuple("TListItemWithOption", "item option")


class List(Object, QROOT.TList):
    """
    rootpy wrapper on ROOT's TList. Primarily provides the ability to do slice
    assignments whilst preserving options, which makes it useful for
    manipulating TLists such as ROOT's ``TCanvas::GetListOfPrimitives``.

    Note: this class is rather inefficient as is only intended for manipulating
    small numbers of objects. In modern computing, a linked list wouldn't be
    used in this case. Since a TList is what we have, this provides some sane
    ways to use them.
    """
    _ROOT = QROOT.TList

    @property
    def as_list_with_options(self):
        """
        Similar to list(self) except elements which have an option associated
        with them are returned as a ``TListItemWithOption``
        """
        it = ROOT.TIter(self)
        elem = it.Next()
        result = []
        while elem:
            if it.GetOption():
                result.append(TListItemWithOption(elem, it.GetOption()))
            else:
                result.append(elem)
            elem = it.Next()
        return result

    def Add(self, value, *optional):
        """
        Overload ROOT's basic TList::Add to support supplying
        TListItemWithOption
        """
        if isinstance(value, TListItemWithOption):
            if optional:
                raise RuntimeError(
                    "option specified along with "
                    "TListItemWithOption. Specify one or the "
                    "other but not both.")
            return super(List, self).Add(value.item, value.option)
        return super(List, self).Add(value, *optional)

    def __setitem__(self, idx, desired):
        """
        Support slice assignment to a TList
        """
        if not isinstance(idx, slice):
            super(List, self)[idx] = desired

        if not isinstance(desired, (list, tuple)):
            raise NotImplementedError(
                "Only support list or tuple in slice assignment")

        # Implementation: completely clear the list and rebuild it.
        # If we own objects, manually delete the ones which don't get re-added
        # to the list.

        original_values = self.as_list_with_options

        self.Clear("nodelete")

        first_idx, last_idx, stride = idx.indices(len(original_values))

        newlist = (original_values[:first_idx:stride]
                   + list(desired)
                   + original_values[last_idx::stride])

        for item in newlist:
            # TODO: Potentially fix up the "same" keyword intelligently *if*
            #       the first item is a TFrame, we know we're probably a list
            #       of items which is being drawn. For example, we might want
            #       objects which are specified repeatedly to use the "same"
            #       keyword the second time, or to ensure that the first
            #       does not have the "same" keyword.
            pass

        # Set of objects which were used (and don't need deleting)
        added = set()

        # Rebuild the list
        for value in newlist:
            self.Add(value)
            added.add(value)

        to_disown = set(original_values) - set(added)
        if self.IsOwner() and to_disown:
            # These items need deleting if we own them.
            # Add them to a temporary TList which we then delete in order to
            # get the correct deletion semantics.

            templist = List()
            templist.SetOwner()
            for item in to_disown:
                templist.Add(item)

            # Causes deletion of heap based objects with the usual root
            # semantics.
            templist.Clear()

    def __getitem__(self, idx):
        """
        Similar to list(self)[idx] except it uses
        ``List.as_list_with_options``.
        """
        return self.as_list_with_options[idx]

    def __iter__(self):
        for item in super(List, self).__iter__():
            yield asrootpy(item)

    def __repr__(self):
        return "rootpy.List{0}".format(list(self))


class ObjArray(Object, QROOT.TObjArray):
    """
    Make ObjArray return asrootpy'd versions of the objects contained within.
    """
    _ROOT = QROOT.TObjArray

    # TODO: override other TObjArray methods which return TObject*
    def At(self, idx):
        return asrootpy(super(ObjArray, self).At(idx))

    def __getitem__(self, idx):
        if isinstance(idx, slice):
            return [self[i] for i in xrange(*idx.indices(len(self)))]
        return self.At(idx)

    def __iter__(self):
        for item in super(ObjArray, self).__iter__():
            yield asrootpy(item)

########NEW FILE########
__FILENAME__ = compiled
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Easily compile and load C++ code from multiline Python strings or from external
C++ files. The compiled libraries are cached in ``~/.cache/rootpy`` and loaded
from there when requested again.

Examples
--------

Create the file ``test_compiled.cxx`` containing:

.. sourcecode:: c++

   int AnswerToLtUaE() {
       return 42;
   }

   class RootpyTestCompiled {
   public:
       int blah() { return 84; }
   };


Now automatically compile and load that file or C++ code in a string with:

.. sourcecode:: python

   >>> import rootpy.compiled as C
   >>> C.register_file("test_compiled.cxx",
   ...                 ["AnswerToLtUaE", "RootpyTestCompiled"])
   >>> C.register_code(\"\"\"
   ... #include <string>
   ... std::string _rootpy_test() { return "Hello, world"; }
   ... \"\"\", ["_rootpy_test"])
   >>> C.AnswerToLtUaE()
   42
   >>> C.RootpyTestCompiled().blah()
   84
   >>> C._rootpy_test()
   'Hello, world'

"""
from __future__ import absolute_import

import hashlib
import inspect
import os
import pkg_resources
import sys
import textwrap
from commands import getstatusoutput
from os.path import basename, dirname, exists, join as pjoin

import ROOT

from .utils.module_facade import Facade, computed_once_classproperty

from . import userdata
from .utils.path import mkdir_p
from .utils.lock import lock
from . import log; log = log[__name__]
from . import QROOT
from .defaults import extra_initialization

__all__ = []


def mtime(path):
    return os.stat(path).st_mtime

MODULES_PATH = pjoin(userdata.BINARY_PATH, 'modules')
if not exists(MODULES_PATH):
    # avoid race condition by ignoring OSError if path exists by the time we
    # try to create it. See https://github.com/rootpy/rootpy/issues/328
    mkdir_p(MODULES_PATH)


@extra_initialization
def initialize():
    # Used instead of AddDynamicPath for ordering
    path = ":".join([MODULES_PATH, ROOT.gSystem.GetDynamicPath()])
    ROOT.gSystem.SetDynamicPath(path)


class Namespace(object):
    """
    Represents a sub-namespace
    """


class FileCode(object):

    def __init__(self, filename, callermodule):
        self.filename = filename
        self.module = callermodule
        self.name = self.module + "." + basename(self.filename)
        self.loaded = False

    @property
    def mtime(self):
        return mtime(self.filename)

    @property
    def compiled_path(self):
        ext = "." + ROOT.gSystem.GetSoExt()
        return pjoin(MODULES_PATH, self.name + ext)

    @property
    def compiled(self):
        return (exists(self.compiled_path) and
                mtime(self.compiled_path) > self.mtime)

    def load(self):
        if not self.compiled:
            log.info("Compiling {0}".format(self.compiled_path))
            with lock(pjoin(MODULES_PATH, "lock"), poll_interval=5, max_age=60):
                ROOT.gSystem.CompileMacro(self.filename, 'k-',
                                          self.name, MODULES_PATH)
        else:
            log.debug("Loading existing {0}".format(self.compiled_path))
            ROOT.gInterpreter.Load(self.compiled_path)
        self.loaded = True

    def get(self, name):
        if not self.loaded:
            self.load()
        return getattr(ROOT, name)


@Facade(__name__, expose_internal=False)
class Compiled(object):

    registered_code = {}
    debug = False
    optimize = True

    def caller_location(self, depth=0):
        caller = sys._getframe(depth+2)
        caller_file = inspect.getfile(caller)
        caller_module = inspect.getmodule(caller)
        if caller_module:
            caller_module = caller_module.__name__
            # Note: caller_file may be a relative path from $PWD at python
            # startup, therefore, to get a solid abspath:
            caller_directory = pkg_resources.get_provider(
                caller_module).module_path
        else:
            caller_module = "..unknown.."
            caller_directory = dirname(caller_file)

        return caller_directory, caller_module, caller.f_lineno

    def get_symbol(self, symbol):
        if symbol in self.registered_code:
            return self.registered_code[symbol].get(symbol)

    def __getattr__(self, what):
        return self.get_symbol(what)

    def register_code(self, code, symbols):
        """Register C++ code in a multiline string

        Parameters
        ----------
        code : str
            A string containing the C++ code
        symbols : list
            A list of symbol names to extract from the compiled C++ code

        Notes
        -----
        This assumes that call site occurs exactly once.
        If you don't do that, you're better off writing to a temporary
        file and calling `register_file`
        """
        filename = hashlib.sha1(code).hexdigest()[:8] + ".cxx"
        filepath = pjoin(MODULES_PATH, filename)

        _, caller_modulename, lineno = self.caller_location()

        #code += "#line {0} {1}".format(caller_modulename, lineno)
        if not exists(filepath):
            # Only write it if it doesn't exist
            # (1/4billion chance of collision)
            with open(filepath, "w") as fd:
                fd.write(textwrap.dedent(code))

        code = FileCode(filepath, caller_modulename)
        self.register(code, symbols)

    def register(self, code, symbols):
        for s in symbols:
            self.registered_code[s] = code

    def register_file(self, filename, symbols):
        """Register C++ code in an external C++ file

        Parameters
        ----------
        filename : str
            The path to a file containing C++ code
        symbols : list
            A list of symbol names to extract from the compiled C++ code
        """
        caller_directory, caller_modulename, _ = self.caller_location()

        absfile = pjoin(caller_directory, filename)

        if not exists(absfile):
            raise RuntimeError("Can't find file {0}".format(absfile))

        code = FileCode(absfile, caller_modulename)
        self.register(code, symbols)

    @computed_once_classproperty
    def python_include_path(self):
        """
        Determine the path to Python.h
        """
        pydir = "python{0.major}.{0.minor}".format(sys.version_info)

        def pkgconfig():
            cmd = "pkg-config python --variable=includedir"
            status, output = getstatusoutput(cmd)
            log.debug("Used pkgconfig: {0}, {1}".format(status, output))
            if status == 0:
                return output
            return None

        real_prefix = None
        if hasattr(sys, "real_prefix"):
            real_prefix = pjoin(sys.real_prefix, "include")

        paths = [
            real_prefix,
            pjoin(sys.prefix, "include"),
            pjoin(sys.exec_prefix, "include"),
            # Last resort - maybe pkgconfig knows?
            pkgconfig,
        ]

        # Try each path in turn, call it if callable,
        # skip it if it doesn't exist
        for path in paths:
            if path and callable(path):
                path = path()
            if not path:
                continue
            incdir = pjoin(path, pydir)
            py_h = pjoin(incdir, "Python.h")
            if exists(py_h):
                return incdir
        raise RuntimeError("BUG: Unable to determine Python.h include path.")

    def add_python_includepath(self):
        """
        Add Python.h to the include path
        """
        if hasattr(self, "_add_python_includepath_done"):
            return
        self._add_python_includepath_done = True
        QROOT.gSystem.AddIncludePath(
            '-I"{0}"'.format(self.python_include_path))

########NEW FILE########
__FILENAME__ = context
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import os
from contextlib import contextmanager
# Note about locks: we don't need this in cases where ROOT has a
# thread-specific variable, so gDirectory and gPad are safe.
# Not so for gStyle, IsBatch and TH1.AddDirectory, so we use a lock in these
# cases. To prevent out-of-order lock grabbing, just use one reentrant lock for
# all of them.
import threading
LOCK = threading.RLock()

from . import ROOT
from . import log; log = log[__name__]

__all__ = [
    'preserve_current_style',
    'preserve_current_canvas',
    'preserve_current_directory',
    'preserve_batch_state',
    'invisible_canvas',
    'thread_specific_tmprootdir',
    'set_directory',
    'preserve_set_th1_add_directory',
    'working_directory',
    'do_nothing',
]


@contextmanager
def preserve_current_style():
    """
    Context manager which ensures that the current style remains the current
    style when the context is left.
    """
    # this should be 'Modern' by default
    with LOCK:
        old = ROOT.gStyle
        try:
            yield
        finally:
            old.cd()


@contextmanager
def preserve_current_canvas():
    """
    Context manager which ensures that the current canvas remains the current
    canvas when the context is left.
    """
    old = ROOT.gPad.func()
    try:
        yield
    finally:
        if old:
            old.cd()
        elif ROOT.gPad.func():
            # Put things back how they were before.
            with invisible_canvas():
                # This is a round-about way of resetting gPad to None.
                # No other technique I tried could do it.
                pass


@contextmanager
def preserve_current_directory():
    """
    Context manager which ensures that the current directory remains the
    current directory when the context is left.
    """
    old = ROOT.gDirectory.func()
    try:
        yield
    finally:
        assert old, "BUG: assumptions were invalid. Please report this"
        # old is always valid and refers to ROOT.TROOT if no file is created.
        old.cd()


@contextmanager
def preserve_batch_state():
    """
    Context manager which ensures the batch state is the same on exit as it was
    on entry.
    """
    with LOCK:
        old = ROOT.gROOT.IsBatch()
        try:
            yield
        finally:
            ROOT.gROOT.SetBatch(old)


@contextmanager
def invisible_canvas():
    """
    Context manager yielding a temporary canvas drawn in batch mode, invisible
    to the user. Original state is restored on exit.

    Example use; obtain X axis object without interfering with anything::

        with invisible_canvas() as c:
            efficiency.Draw()
            g = efficiency.GetPaintedGraph()
            return g.GetXaxis()
    """
    with preserve_current_canvas():
        with preserve_batch_state():
            ROOT.gROOT.SetBatch()
            c = ROOT.TCanvas()
        try:
            c.cd()
            yield c
        finally:
            c.Close()
            c.IsA().Destructor(c)


@contextmanager
def thread_specific_tmprootdir():
    """
    Context manager which makes a thread specific gDirectory to avoid
    interfering with the current file.

    Use cases:

        A TTree Draw function which doesn't want to interfere with whatever
        gDirectory happens to be.

        Multi-threading where there are two threads creating objects with the
        same name which must reside in a directory. (again, this happens with
        TTree draw)
    """
    with preserve_current_directory():
        dname = "rootpy-tmp/thread/{0}".format(
                threading.current_thread().ident)
        d = ROOT.gROOT.mkdir(dname)
        if not d:
            d = ROOT.gROOT.GetDirectory(dname)
            assert d, "Unexpected failure, can't cd to tmpdir."
        d.cd()
        yield d


@contextmanager
def set_directory(robject):
    """
    Context manager to temporarily set the directory of a ROOT object
    (if possible)
    """
    if (not hasattr(robject, 'GetDirectory') or
        not hasattr(robject, 'SetDirectory')):
        log.warning("Cannot set the directory of a `{0}`".format(
            type(robject)))
        # Do nothing
        yield
    else:
        old_dir = robject.GetDirectory()
        try:
            robject.SetDirectory(ROOT.gDirectory.func())
            yield
        finally:
            robject.SetDirectory(old_dir)


@contextmanager
def preserve_set_th1_add_directory(state=True):
    """
    Context manager to temporarily set TH1.AddDirectory() state
    """
    with LOCK:
        status = ROOT.TH1.AddDirectoryStatus()
        try:
            ROOT.TH1.AddDirectory(state)
            yield
        finally:
            ROOT.TH1.AddDirectory(status)


@contextmanager
def working_directory(path):
    """
    A context manager that changes the working directory to the given
    path, and then changes it back to its previous value on exit.
    """
    prev_cwd = os.getcwd()
    os.chdir(path)
    try:
        yield
    finally:
        os.chdir(prev_cwd)


@contextmanager
def do_nothing(*args, **kwargs):
    """
    A context manager that does... nothing!
    """
    yield

########NEW FILE########
__FILENAME__ = decorators
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import os
import re
import inspect
import warnings

from .context import preserve_current_directory
from .extern.decorator import decorator
from . import ROOT, ROOT_VERSION

__all__ = [
    'requires_ROOT',
    'method_file_check',
    'method_file_cd',
    'chainable',
    'camel_to_snake',
    'snake_case_methods',
    'sync',
    'cached_property',
]


CONVERT_SNAKE_CASE = os.getenv('NO_ROOTPY_SNAKE_CASE', False) is False


def requires_ROOT(version, exception=False):
    """
    A decorator for functions or methods that require a minimum ROOT version.
    If `exception` is False (the default) a warning is issued and None is
    returned, otherwise a `NotImplementedError` exception is raised.
    `exception` may also be an `Exception` in which case it will be raised
    instead of `NotImplementedError`.
    """
    @decorator
    def wrap(f, *args, **kwargs):
        if ROOT_VERSION < version:
            msg = ("{0} requires at least ROOT {1} "
                   "but you are using {2}".format(
                       f.__name__, version, ROOT_VERSION))
            if inspect.isclass(exception) and issubclass(exception, Exception):
                raise exception
            elif exception:
                raise NotImplementedError(msg)
            warnings.warn(msg)
            return None
        return f(*args, **kwargs)
    return wrap


def _get_qualified_name(thing):
    if inspect.ismodule(thing):
        return thing.__file__
    if inspect.isclass(thing):
        return '{0}.{1}'.format(thing.__module__, thing.__name__)
    if inspect.ismethod(thing):
        return '{0}.{1}'.format(thing.im_class.__name__, thing.__name__)
    if inspect.isfunction(thing):
        return thing.__name__
    return repr(thing)


@decorator
def method_file_check(f, self, *args, **kwargs):
    """
    A decorator to check that a TFile as been created before f is called.
    This function can decorate methods.
    """
    # This requires special treatment since in Python 3 unbound methods are
    # just functions: http://stackoverflow.com/a/3589335/1002176 but to get
    # consistent access to the class in both 2.x and 3.x, we need self.
    curr_dir = ROOT.gDirectory.func()
    if isinstance(curr_dir, ROOT.TROOT):
        raise RuntimeError(
            "You must first create a File before calling {0}.{1}".format(
                self.__class__.__name__, _get_qualified_name(f)))
    if not curr_dir.IsWritable():
        raise RuntimeError(
            "Calling {0}.{1} requires that the "
            "current File is writable".format(
                self.__class__.__name__, _get_qualified_name(f)))
    return f(self, *args, **kwargs)


@decorator
def method_file_cd(f, self, *args, **kwargs):
    """
    A decorator to cd back to the original directory where this object was
    created (useful for any calls to TObject.Write).
    This function can decorate methods.
    """
    with preserve_current_directory():
        self.GetDirectory().cd()
        return f(self, *args, **kwargs)


@decorator
def chainable(f, self, *args, **kwargs):
    """
    Decorator which causes a 'void' function to return self

    Allows chaining of multiple modifier class methods.
    """
    # perform action
    f(self, *args, **kwargs)
    # return reference to class.
    return self


FIRST_CAP_RE = re.compile('(.)([A-Z][a-z]+)')
ALL_CAP_RE = re.compile('([a-z0-9])([A-Z])')


def camel_to_snake(name):
    """
    http://stackoverflow.com/questions/1175208/
    elegant-python-function-to-convert-camelcase-to-camel-case
    """
    s1 = FIRST_CAP_RE.sub(r'\1_\2', name)
    return ALL_CAP_RE.sub(r'\1_\2', s1).lower()


def snake_case_methods(cls, debug=False):
    """
    A class decorator adding snake_case methods
    that alias capitalized ROOT methods. cls must subclass
    a ROOT class and define the _ROOT class variable.
    """
    if not CONVERT_SNAKE_CASE:
        return cls
    # get the ROOT base class
    root_base = cls._ROOT
    members = inspect.getmembers(root_base)
    # filter out any methods that already exist in lower and uppercase forms
    # i.e. TDirectory::cd and Cd...
    names = {}
    for name, member in members:
        lower_name = name.lower()
        if lower_name in names:
            del names[lower_name]
        else:
            names[lower_name] = None

    for name, member in members:
        if name.lower() not in names:
            continue
        # Don't touch special methods or methods without cap letters
        if name[0] == '_' or name.islower():
            continue
        # Is this a method of the ROOT base class?
        if not inspect.ismethod(member) and not inspect.isfunction(member):
            continue
        # convert CamelCase to snake_case
        new_name = camel_to_snake(name)
        # Use a __dict__ lookup rather than getattr because we _want_ to
        # obtain the _descriptor_, and not what the descriptor gives us
        # when it is `getattr`'d.
        value = None
        skip = False
        for c in cls.mro():
            # skip methods that are already overridden
            if new_name in c.__dict__:
                skip = True
                break
            if name in c.__dict__:
                value = c.__dict__[name]
                break
        # <neo>Woah, a use for for-else</neo>
        else:
            # Weird. Maybe the item lives somewhere else, such as on the
            # metaclass?
            value = getattr(cls, name)
        if skip:
            continue
        setattr(cls, new_name, value)
    return cls


def sync(lock):
    """
    A synchronization decorator
    """
    @decorator
    def sync(f):
        def new_function(*args, **kw):
            lock.acquire()
            try:
                return f(*args, **kw)
            finally:
                lock.release()
        return new_function
    return sync


class cached_property(object):
    """
    Computes attribute value and caches it in the instance.
    Written by Denis Otkidach and published in the Python Cookbook.
    This decorator allows you to create a property which can be computed once
    and accessed many times. Sort of like memoization.
    """
    def __init__(self, method, name=None):
        # record the unbound-method and the name
        self.method = method
        self.name = name or method.__name__
        self.__doc__ = method.__doc__

    def __get__(self, inst, cls):
        # self: <__main__.cache object at 0xb781340c>
        # inst: <__main__.Foo object at 0xb781348c>
        # cls: <class '__main__.Foo'>
        if inst is None:
            # instance attribute accessed on class, return self
            # You get here if you write `Foo.bar`
            return self
        # compute, cache and return the instance's attribute value
        result = self.method(inst)
        # setattr redefines the instance's attribute so this doesn't get called again
        setattr(inst, self.name, result)
        return result

########NEW FILE########
__FILENAME__ = defaults
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ctypes as C
import os
from functools import wraps

import ROOT
# This doesn't trigger finalSetup()
ROOT.PyConfig.IgnoreCommandLineOptions = True

from . import log; log = log[__name__]
from . import QROOT
from .logger import set_error_handler, python_logging_error_handler
from .logger.magic import DANGER, fix_ipython_startup


__all__ = []


if not log["/"].have_handlers():
    # The root logger doesn't have any handlers.
    # Therefore, the application hasn't specified any behaviour, and rootpy
    # uses maximum verbosity.
    log["/"].setLevel(log.NOTSET)

use_rootpy_handler = not os.environ.get('NO_ROOTPY_HANDLER', False)
use_rootpy_magic = not os.environ.get('NO_ROOTPY_MAGIC', False)

if use_rootpy_handler:
    if use_rootpy_magic:
        # See magic module for more details
        DANGER.enabled = True
    else:
        log.debug('logger magic disabled')
        DANGER.enabled = False
    # Show python backtrace if there is a segfault
    log["/ROOT.TUnixSystem.DispatchSignals"].show_stack(min_level=log.ERROR)
    orig_error_handler = set_error_handler(python_logging_error_handler)
else:
    log.debug('ROOT error handler disabled')

DICTS_PATH = MODS_PATH = None

# Activate the storage of the sum of squares of errors by default.
QROOT.TH1.SetDefaultSumw2(True)
# Activate use of underflows and overflows in `Fill()` in the
# computation of statistics (mean value, RMS) by default.
QROOT.TH1.StatOverflows(True)
# Setting the above static parameters below in the configure_defaults function
# may be too late. For example, the first histogram will be inited before these
# are set.

_initializations = []


def extra_initialization(fn):
    """
    Function decorator which adds `fn` to the list of functions to be called
    at some point after ROOT has been initialized.
    """
    if initialized:
        fn()
    else:
        _initializations.append(fn)
    return fn


def configure_defaults():
    """
    This function is executed immediately after ROOT's finalSetup
    """
    log.debug("configure_defaults()")

    global initialized
    initialized = True

    if use_rootpy_handler:
        # Need to do it again here, since it is overridden by ROOT.
        set_error_handler(python_logging_error_handler)

    if os.environ.get('ROOTPY_BATCH', False):
        ROOT.gROOT.SetBatch(True)
        log.debug('ROOT is running in batch mode')

    ROOT.gErrorIgnoreLevel = 0

    this_dll = C.CDLL(None)
    try:
        EnableAutoDictionary = C.c_int.in_dll(
            this_dll, "G__EnableAutoDictionary")
    except ValueError:
        pass
    else:
        # Disable automatic dictionary generation
        EnableAutoDictionary.value = 0

    # TODO(pwaller): idea, `execfile("userdata/initrc.py")` here?
    #                note: that wouldn't allow the user to override the default
    #                      canvas size, for example.

    for init in _initializations:
        init()


def rp_module_level_in_stack():
    """
    Returns true if we're during a rootpy import
    """
    from traceback import extract_stack
    from rootpy import _ROOTPY_SOURCE_PATH
    modlevel_files = [filename for filename, _, func, _ in extract_stack()
                      if func == "<module>"]

    return any(path.startswith(_ROOTPY_SOURCE_PATH) for path in modlevel_files)


# Check in case the horse has already bolted.
# If initialization has already taken place, we can't wrap it.
if hasattr(ROOT.__class__, "_ModuleFacade__finalSetup"):
    initialized = False

    # Inject our own wrapper in place of ROOT's finalSetup so that we can
    # trigger our default options then.

    finalSetup = ROOT.__class__._ModuleFacade__finalSetup

    @wraps(finalSetup)
    def wrapFinalSetup(*args, **kwargs):

        log.debug("PyROOT's finalSetup() has been triggered")

        if os.environ.get("ROOTPY_DEBUG", None) and rp_module_level_in_stack():
            # Check to see if we're at module level anywhere in rootpy.
            # If so, that's not ideal.
            l = log["bug"]
            l.show_stack()
            l.debug("PyROOT's finalSetup() triggered from rootpy at "
                    "module-level. Please report this.")

        # if running in the ATLAS environment suppress a known harmless warning
        if os.environ.get("AtlasVersion", None):
            regex = "^duplicate entry .* vectorbool.dll> for level 0; ignored$"
            c = log["/ROOT.TEnvRec.ChangeValue"].ignore(regex)
            with c:
                result = finalSetup(*args, **kwargs)
        else:
            result = finalSetup(*args, **kwargs)

        log.debug(
            "PyROOT's finalSetup() has been called "
            "(gROOT.IsBatch()=={0})".format(ROOT.gROOT.IsBatch()))

        configure_defaults()

        return result

    wrapFinalSetup._orig_func = finalSetup

    ROOT.__class__._ModuleFacade__finalSetup = wrapFinalSetup

    if '__IPYTHON__' in __builtins__:
        # ROOT has a bug causing it to print (Bool_t)1 to the console.
        fix_ipython_startup(finalSetup)

else:
    initialized = True
    configure_defaults()

########NEW FILE########
__FILENAME__ = argparse
# Author: Steven J. Bethard <steven.bethard@gmail.com>.

"""Command-line parsing library

This module is an optparse-inspired command-line parsing library that:

    - handles both optional and positional arguments
    - produces highly informative usage messages
    - supports parsers that dispatch to sub-parsers

The following is a simple usage example that sums integers from the
command-line and writes the result to a file::

    parser = argparse.ArgumentParser(
        description='sum the integers at the command line')
    parser.add_argument(
        'integers', metavar='int', nargs='+', type=int,
        help='an integer to be summed')
    parser.add_argument(
        '--log', default=sys.stdout, type=argparse.FileType('w'),
        help='the file where the sum should be written')
    args = parser.parse_args()
    args.log.write('%s' % sum(args.integers))
    args.log.close()

The module contains the following public classes:

    - ArgumentParser -- The main entry point for command-line parsing. As the
        example above shows, the add_argument() method is used to populate
        the parser with actions for optional and positional arguments. Then
        the parse_args() method is invoked to convert the args at the
        command-line into an object with attributes.

    - ArgumentError -- The exception raised by ArgumentParser objects when
        there are errors with the parser's actions. Errors raised while
        parsing the command-line are caught by ArgumentParser and emitted
        as command-line messages.

    - FileType -- A factory for defining types of files to be created. As the
        example above shows, instances of FileType are typically passed as
        the type= argument of add_argument() calls.

    - Action -- The base class for parser actions. Typically actions are
        selected by passing strings like 'store_true' or 'append_const' to
        the action= argument of add_argument(). However, for greater
        customization of ArgumentParser actions, subclasses of Action may
        be defined and passed as the action= argument.

    - HelpFormatter, RawDescriptionHelpFormatter, RawTextHelpFormatter,
        ArgumentDefaultsHelpFormatter -- Formatter classes which
        may be passed as the formatter_class= argument to the
        ArgumentParser constructor. HelpFormatter is the default,
        RawDescriptionHelpFormatter and RawTextHelpFormatter tell the parser
        not to change the formatting for help text, and
        ArgumentDefaultsHelpFormatter adds information about argument defaults
        to the help.

All other classes in this module are considered implementation details.
(Also note that HelpFormatter and RawDescriptionHelpFormatter are only
considered public as object names -- the API of the formatter objects is
still considered an implementation detail.)
"""

__version__ = '1.2.1'
__all__ = [
    'ArgumentParser',
    'ArgumentError',
    'ArgumentTypeError',
    'FileType',
    'HelpFormatter',
    'ArgumentDefaultsHelpFormatter',
    'RawDescriptionHelpFormatter',
    'RawTextHelpFormatter',
    'Namespace',
    'Action',
    'ONE_OR_MORE',
    'OPTIONAL',
    'PARSER',
    'REMAINDER',
    'SUPPRESS',
    'ZERO_OR_MORE',
]


import copy as _copy
import os as _os
import re as _re
import sys as _sys
import textwrap as _textwrap

from gettext import gettext as _

try:
    set
except NameError:
    # for python < 2.4 compatibility (sets module is there since 2.3):
    from sets import Set as set

try:
    basestring
except NameError:
    basestring = str

try:
    sorted
except NameError:
    # for python < 2.4 compatibility:
    def sorted(iterable, reverse=False):
        result = list(iterable)
        result.sort()
        if reverse:
            result.reverse()
        return result


def _callable(obj):
    return hasattr(obj, '__call__') or hasattr(obj, '__bases__')


SUPPRESS = '==SUPPRESS=='

OPTIONAL = '?'
ZERO_OR_MORE = '*'
ONE_OR_MORE = '+'
PARSER = 'A...'
REMAINDER = '...'
_UNRECOGNIZED_ARGS_ATTR = '_unrecognized_args'

# =============================
# Utility functions and classes
# =============================

class _AttributeHolder(object):
    """Abstract base class that provides __repr__.

    The __repr__ method returns a string in the format::
        ClassName(attr=name, attr=name, ...)
    The attributes are determined either by a class-level attribute,
    '_kwarg_names', or by inspecting the instance __dict__.
    """

    def __repr__(self):
        type_name = type(self).__name__
        arg_strings = []
        for arg in self._get_args():
            arg_strings.append(repr(arg))
        for name, value in self._get_kwargs():
            arg_strings.append('%s=%r' % (name, value))
        return '%s(%s)' % (type_name, ', '.join(arg_strings))

    def _get_kwargs(self):
        return sorted(self.__dict__.items())

    def _get_args(self):
        return []


def _ensure_value(namespace, name, value):
    if getattr(namespace, name, None) is None:
        setattr(namespace, name, value)
    return getattr(namespace, name)


# ===============
# Formatting Help
# ===============

class HelpFormatter(object):
    """Formatter for generating usage messages and argument help strings.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    """

    def __init__(self,
                 prog,
                 indent_increment=2,
                 max_help_position=24,
                 width=None):

        # default setting for width
        if width is None:
            try:
                width = int(_os.environ['COLUMNS'])
            except (KeyError, ValueError):
                width = 80
            width -= 2

        self._prog = prog
        self._indent_increment = indent_increment
        self._max_help_position = max_help_position
        self._width = width

        self._current_indent = 0
        self._level = 0
        self._action_max_length = 0

        self._root_section = self._Section(self, None)
        self._current_section = self._root_section

        self._whitespace_matcher = _re.compile(r'\s+')
        self._long_break_matcher = _re.compile(r'\n\n\n+')

    # ===============================
    # Section and indentation methods
    # ===============================
    def _indent(self):
        self._current_indent += self._indent_increment
        self._level += 1

    def _dedent(self):
        self._current_indent -= self._indent_increment
        assert self._current_indent >= 0, 'Indent decreased below 0.'
        self._level -= 1

    class _Section(object):

        def __init__(self, formatter, parent, heading=None):
            self.formatter = formatter
            self.parent = parent
            self.heading = heading
            self.items = []

        def format_help(self):
            # format the indented section
            if self.parent is not None:
                self.formatter._indent()
            join = self.formatter._join_parts
            for func, args in self.items:
                func(*args)
            item_help = join([func(*args) for func, args in self.items])
            if self.parent is not None:
                self.formatter._dedent()

            # return nothing if the section was empty
            if not item_help:
                return ''

            # add the heading if the section was non-empty
            if self.heading is not SUPPRESS and self.heading is not None:
                current_indent = self.formatter._current_indent
                heading = '%*s%s:\n' % (current_indent, '', self.heading)
            else:
                heading = ''

            # join the section-initial newline, the heading and the help
            return join(['\n', heading, item_help, '\n'])

    def _add_item(self, func, args):
        self._current_section.items.append((func, args))

    # ========================
    # Message building methods
    # ========================
    def start_section(self, heading):
        self._indent()
        section = self._Section(self, self._current_section, heading)
        self._add_item(section.format_help, [])
        self._current_section = section

    def end_section(self):
        self._current_section = self._current_section.parent
        self._dedent()

    def add_text(self, text):
        if text is not SUPPRESS and text is not None:
            self._add_item(self._format_text, [text])

    def add_usage(self, usage, actions, groups, prefix=None):
        if usage is not SUPPRESS:
            args = usage, actions, groups, prefix
            self._add_item(self._format_usage, args)

    def add_argument(self, action):
        if action.help is not SUPPRESS:

            # find all invocations
            get_invocation = self._format_action_invocation
            invocations = [get_invocation(action)]
            for subaction in self._iter_indented_subactions(action):
                invocations.append(get_invocation(subaction))

            # update the maximum item length
            invocation_length = max([len(s) for s in invocations])
            action_length = invocation_length + self._current_indent
            self._action_max_length = max(self._action_max_length,
                                          action_length)

            # add the item to the list
            self._add_item(self._format_action, [action])

    def add_arguments(self, actions):
        for action in actions:
            self.add_argument(action)

    # =======================
    # Help-formatting methods
    # =======================
    def format_help(self):
        help = self._root_section.format_help()
        if help:
            help = self._long_break_matcher.sub('\n\n', help)
            help = help.strip('\n') + '\n'
        return help

    def _join_parts(self, part_strings):
        return ''.join([part
                        for part in part_strings
                        if part and part is not SUPPRESS])

    def _format_usage(self, usage, actions, groups, prefix):
        if prefix is None:
            prefix = _('usage: ')

        # if usage is specified, use that
        if usage is not None:
            usage = usage % dict(prog=self._prog)

        # if no optionals or positionals are available, usage is just prog
        elif usage is None and not actions:
            usage = '%(prog)s' % dict(prog=self._prog)

        # if optionals and positionals are available, calculate usage
        elif usage is None:
            prog = '%(prog)s' % dict(prog=self._prog)

            # split optionals from positionals
            optionals = []
            positionals = []
            for action in actions:
                if action.option_strings:
                    optionals.append(action)
                else:
                    positionals.append(action)

            # build full usage string
            format = self._format_actions_usage
            action_usage = format(optionals + positionals, groups)
            usage = ' '.join([s for s in [prog, action_usage] if s])

            # wrap the usage parts if it's too long
            text_width = self._width - self._current_indent
            if len(prefix) + len(usage) > text_width:

                # break usage into wrappable parts
                part_regexp = r'\(.*?\)+|\[.*?\]+|\S+'
                opt_usage = format(optionals, groups)
                pos_usage = format(positionals, groups)
                opt_parts = _re.findall(part_regexp, opt_usage)
                pos_parts = _re.findall(part_regexp, pos_usage)
                assert ' '.join(opt_parts) == opt_usage
                assert ' '.join(pos_parts) == pos_usage

                # helper for wrapping lines
                def get_lines(parts, indent, prefix=None):
                    lines = []
                    line = []
                    if prefix is not None:
                        line_len = len(prefix) - 1
                    else:
                        line_len = len(indent) - 1
                    for part in parts:
                        if line_len + 1 + len(part) > text_width:
                            lines.append(indent + ' '.join(line))
                            line = []
                            line_len = len(indent) - 1
                        line.append(part)
                        line_len += len(part) + 1
                    if line:
                        lines.append(indent + ' '.join(line))
                    if prefix is not None:
                        lines[0] = lines[0][len(indent):]
                    return lines

                # if prog is short, follow it with optionals or positionals
                if len(prefix) + len(prog) <= 0.75 * text_width:
                    indent = ' ' * (len(prefix) + len(prog) + 1)
                    if opt_parts:
                        lines = get_lines([prog] + opt_parts, indent, prefix)
                        lines.extend(get_lines(pos_parts, indent))
                    elif pos_parts:
                        lines = get_lines([prog] + pos_parts, indent, prefix)
                    else:
                        lines = [prog]

                # if prog is long, put it on its own line
                else:
                    indent = ' ' * len(prefix)
                    parts = opt_parts + pos_parts
                    lines = get_lines(parts, indent)
                    if len(lines) > 1:
                        lines = []
                        lines.extend(get_lines(opt_parts, indent))
                        lines.extend(get_lines(pos_parts, indent))
                    lines = [prog] + lines

                # join lines into usage
                usage = '\n'.join(lines)

        # prefix with 'usage:'
        return '%s%s\n\n' % (prefix, usage)

    def _format_actions_usage(self, actions, groups):
        # find group indices and identify actions in groups
        group_actions = set()
        inserts = {}
        for group in groups:
            try:
                start = actions.index(group._group_actions[0])
            except ValueError:
                continue
            else:
                end = start + len(group._group_actions)
                if actions[start:end] == group._group_actions:
                    for action in group._group_actions:
                        group_actions.add(action)
                    if not group.required:
                        if start in inserts:
                            inserts[start] += ' ['
                        else:
                            inserts[start] = '['
                        inserts[end] = ']'
                    else:
                        if start in inserts:
                            inserts[start] += ' ('
                        else:
                            inserts[start] = '('
                        inserts[end] = ')'
                    for i in range(start + 1, end):
                        inserts[i] = '|'

        # collect all actions format strings
        parts = []
        for i, action in enumerate(actions):

            # suppressed arguments are marked with None
            # remove | separators for suppressed arguments
            if action.help is SUPPRESS:
                parts.append(None)
                if inserts.get(i) == '|':
                    inserts.pop(i)
                elif inserts.get(i + 1) == '|':
                    inserts.pop(i + 1)

            # produce all arg strings
            elif not action.option_strings:
                part = self._format_args(action, action.dest)

                # if it's in a group, strip the outer []
                if action in group_actions:
                    if part[0] == '[' and part[-1] == ']':
                        part = part[1:-1]

                # add the action string to the list
                parts.append(part)

            # produce the first way to invoke the option in brackets
            else:
                option_string = action.option_strings[0]

                # if the Optional doesn't take a value, format is:
                #    -s or --long
                if action.nargs == 0:
                    part = '%s' % option_string

                # if the Optional takes a value, format is:
                #    -s ARGS or --long ARGS
                else:
                    default = action.dest.upper()
                    args_string = self._format_args(action, default)
                    part = '%s %s' % (option_string, args_string)

                # make it look optional if it's not required or in a group
                if not action.required and action not in group_actions:
                    part = '[%s]' % part

                # add the action string to the list
                parts.append(part)

        # insert things at the necessary indices
        for i in sorted(inserts, reverse=True):
            parts[i:i] = [inserts[i]]

        # join all the action items with spaces
        text = ' '.join([item for item in parts if item is not None])

        # clean up separators for mutually exclusive groups
        open = r'[\[(]'
        close = r'[\])]'
        text = _re.sub(r'(%s) ' % open, r'\1', text)
        text = _re.sub(r' (%s)' % close, r'\1', text)
        text = _re.sub(r'%s *%s' % (open, close), r'', text)
        text = _re.sub(r'\(([^|]*)\)', r'\1', text)
        text = text.strip()

        # return the text
        return text

    def _format_text(self, text):
        if '%(prog)' in text:
            text = text % dict(prog=self._prog)
        text_width = self._width - self._current_indent
        indent = ' ' * self._current_indent
        return self._fill_text(text, text_width, indent) + '\n\n'

    def _format_action(self, action):
        # determine the required width and the entry label
        help_position = min(self._action_max_length + 2,
                            self._max_help_position)
        help_width = self._width - help_position
        action_width = help_position - self._current_indent - 2
        action_header = self._format_action_invocation(action)

        # ho nelp; start on same line and add a final newline
        if not action.help:
            tup = self._current_indent, '', action_header
            action_header = '%*s%s\n' % tup

        # short action name; start on the same line and pad two spaces
        elif len(action_header) <= action_width:
            tup = self._current_indent, '', action_width, action_header
            action_header = '%*s%-*s  ' % tup
            indent_first = 0

        # long action name; start on the next line
        else:
            tup = self._current_indent, '', action_header
            action_header = '%*s%s\n' % tup
            indent_first = help_position

        # collect the pieces of the action help
        parts = [action_header]

        # if there was help for the action, add lines of help text
        if action.help:
            help_text = self._expand_help(action)
            help_lines = self._split_lines(help_text, help_width)
            parts.append('%*s%s\n' % (indent_first, '', help_lines[0]))
            for line in help_lines[1:]:
                parts.append('%*s%s\n' % (help_position, '', line))

        # or add a newline if the description doesn't end with one
        elif not action_header.endswith('\n'):
            parts.append('\n')

        # if there are any sub-actions, add their help as well
        for subaction in self._iter_indented_subactions(action):
            parts.append(self._format_action(subaction))

        # return a single string
        return self._join_parts(parts)

    def _format_action_invocation(self, action):
        if not action.option_strings:
            metavar, = self._metavar_formatter(action, action.dest)(1)
            return metavar

        else:
            parts = []

            # if the Optional doesn't take a value, format is:
            #    -s, --long
            if action.nargs == 0:
                parts.extend(action.option_strings)

            # if the Optional takes a value, format is:
            #    -s ARGS, --long ARGS
            else:
                default = action.dest.upper()
                args_string = self._format_args(action, default)
                for option_string in action.option_strings:
                    parts.append('%s %s' % (option_string, args_string))

            return ', '.join(parts)

    def _metavar_formatter(self, action, default_metavar):
        if action.metavar is not None:
            result = action.metavar
        elif action.choices is not None:
            choice_strs = [str(choice) for choice in action.choices]
            result = '{%s}' % ','.join(choice_strs)
        else:
            result = default_metavar

        def format(tuple_size):
            if isinstance(result, tuple):
                return result
            else:
                return (result, ) * tuple_size
        return format

    def _format_args(self, action, default_metavar):
        get_metavar = self._metavar_formatter(action, default_metavar)
        if action.nargs is None:
            result = '%s' % get_metavar(1)
        elif action.nargs == OPTIONAL:
            result = '[%s]' % get_metavar(1)
        elif action.nargs == ZERO_OR_MORE:
            result = '[%s [%s ...]]' % get_metavar(2)
        elif action.nargs == ONE_OR_MORE:
            result = '%s [%s ...]' % get_metavar(2)
        elif action.nargs == REMAINDER:
            result = '...'
        elif action.nargs == PARSER:
            result = '%s ...' % get_metavar(1)
        else:
            formats = ['%s' for _ in range(action.nargs)]
            result = ' '.join(formats) % get_metavar(action.nargs)
        return result

    def _expand_help(self, action):
        params = dict(vars(action), prog=self._prog)
        for name in list(params):
            if params[name] is SUPPRESS:
                del params[name]
        for name in list(params):
            if hasattr(params[name], '__name__'):
                params[name] = params[name].__name__
        if params.get('choices') is not None:
            choices_str = ', '.join([str(c) for c in params['choices']])
            params['choices'] = choices_str
        return self._get_help_string(action) % params

    def _iter_indented_subactions(self, action):
        try:
            get_subactions = action._get_subactions
        except AttributeError:
            pass
        else:
            self._indent()
            for subaction in get_subactions():
                yield subaction
            self._dedent()

    def _split_lines(self, text, width):
        text = self._whitespace_matcher.sub(' ', text).strip()
        return _textwrap.wrap(text, width)

    def _fill_text(self, text, width, indent):
        text = self._whitespace_matcher.sub(' ', text).strip()
        return _textwrap.fill(text, width, initial_indent=indent,
                                           subsequent_indent=indent)

    def _get_help_string(self, action):
        return action.help


class RawDescriptionHelpFormatter(HelpFormatter):
    """Help message formatter which retains any formatting in descriptions.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    """

    def _fill_text(self, text, width, indent):
        return ''.join([indent + line for line in text.splitlines(True)])


class RawTextHelpFormatter(RawDescriptionHelpFormatter):
    """Help message formatter which retains formatting of all help text.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    """

    def _split_lines(self, text, width):
        return text.splitlines()


class ArgumentDefaultsHelpFormatter(HelpFormatter):
    """Help message formatter which adds default values to argument help.

    Only the name of this class is considered a public API. All the methods
    provided by the class are considered an implementation detail.
    """

    def _get_help_string(self, action):
        help = action.help
        if '%(default)' not in action.help:
            if action.default is not SUPPRESS:
                defaulting_nargs = [OPTIONAL, ZERO_OR_MORE]
                if action.option_strings or action.nargs in defaulting_nargs:
                    help += ' (default: %(default)s)'
        return help


# =====================
# Options and Arguments
# =====================

def _get_action_name(argument):
    if argument is None:
        return None
    elif argument.option_strings:
        return  '/'.join(argument.option_strings)
    elif argument.metavar not in (None, SUPPRESS):
        return argument.metavar
    elif argument.dest not in (None, SUPPRESS):
        return argument.dest
    else:
        return None


class ArgumentError(Exception):
    """An error from creating or using an argument (optional or positional).

    The string value of this exception is the message, augmented with
    information about the argument that caused it.
    """

    def __init__(self, argument, message):
        self.argument_name = _get_action_name(argument)
        self.message = message

    def __str__(self):
        if self.argument_name is None:
            format = '%(message)s'
        else:
            format = 'argument %(argument_name)s: %(message)s'
        return format % dict(message=self.message,
                             argument_name=self.argument_name)


class ArgumentTypeError(Exception):
    """An error from trying to convert a command line string to a type."""
    pass


# ==============
# Action classes
# ==============

class Action(_AttributeHolder):
    """Information about how to convert command line strings to Python objects.

    Action objects are used by an ArgumentParser to represent the information
    needed to parse a single argument from one or more strings from the
    command line. The keyword arguments to the Action constructor are also
    all attributes of Action instances.

    Keyword Arguments:

        - option_strings -- A list of command-line option strings which
            should be associated with this action.

        - dest -- The name of the attribute to hold the created object(s)

        - nargs -- The number of command-line arguments that should be
            consumed. By default, one argument will be consumed and a single
            value will be produced.  Other values include:
                - N (an integer) consumes N arguments (and produces a list)
                - '?' consumes zero or one arguments
                - '*' consumes zero or more arguments (and produces a list)
                - '+' consumes one or more arguments (and produces a list)
            Note that the difference between the default and nargs=1 is that
            with the default, a single value will be produced, while with
            nargs=1, a list containing a single value will be produced.

        - const -- The value to be produced if the option is specified and the
            option uses an action that takes no values.

        - default -- The value to be produced if the option is not specified.

        - type -- The type which the command-line arguments should be converted
            to, should be one of 'string', 'int', 'float', 'complex' or a
            callable object that accepts a single string argument. If None,
            'string' is assumed.

        - choices -- A container of values that should be allowed. If not None,
            after a command-line argument has been converted to the appropriate
            type, an exception will be raised if it is not a member of this
            collection.

        - required -- True if the action must always be specified at the
            command line. This is only meaningful for optional command-line
            arguments.

        - help -- The help string describing the argument.

        - metavar -- The name to be used for the option's argument with the
            help string. If None, the 'dest' value will be used as the name.
    """

    def __init__(self,
                 option_strings,
                 dest,
                 nargs=None,
                 const=None,
                 default=None,
                 type=None,
                 choices=None,
                 required=False,
                 help=None,
                 metavar=None):
        self.option_strings = option_strings
        self.dest = dest
        self.nargs = nargs
        self.const = const
        self.default = default
        self.type = type
        self.choices = choices
        self.required = required
        self.help = help
        self.metavar = metavar

    def _get_kwargs(self):
        names = [
            'option_strings',
            'dest',
            'nargs',
            'const',
            'default',
            'type',
            'choices',
            'help',
            'metavar',
        ]
        return [(name, getattr(self, name)) for name in names]

    def __call__(self, parser, namespace, values, option_string=None):
        raise NotImplementedError(_('.__call__() not defined'))


class _StoreAction(Action):

    def __init__(self,
                 option_strings,
                 dest,
                 nargs=None,
                 const=None,
                 default=None,
                 type=None,
                 choices=None,
                 required=False,
                 help=None,
                 metavar=None):
        if nargs == 0:
            raise ValueError('nargs for store actions must be > 0; if you '
                             'have nothing to store, actions such as store '
                             'true or store const may be more appropriate')
        if const is not None and nargs != OPTIONAL:
            raise ValueError('nargs must be %r to supply const' % OPTIONAL)
        super(_StoreAction, self).__init__(
            option_strings=option_strings,
            dest=dest,
            nargs=nargs,
            const=const,
            default=default,
            type=type,
            choices=choices,
            required=required,
            help=help,
            metavar=metavar)

    def __call__(self, parser, namespace, values, option_string=None):
        setattr(namespace, self.dest, values)


class _StoreConstAction(Action):

    def __init__(self,
                 option_strings,
                 dest,
                 const,
                 default=None,
                 required=False,
                 help=None,
                 metavar=None):
        super(_StoreConstAction, self).__init__(
            option_strings=option_strings,
            dest=dest,
            nargs=0,
            const=const,
            default=default,
            required=required,
            help=help)

    def __call__(self, parser, namespace, values, option_string=None):
        setattr(namespace, self.dest, self.const)


class _StoreTrueAction(_StoreConstAction):

    def __init__(self,
                 option_strings,
                 dest,
                 default=False,
                 required=False,
                 help=None):
        super(_StoreTrueAction, self).__init__(
            option_strings=option_strings,
            dest=dest,
            const=True,
            default=default,
            required=required,
            help=help)


class _StoreFalseAction(_StoreConstAction):

    def __init__(self,
                 option_strings,
                 dest,
                 default=True,
                 required=False,
                 help=None):
        super(_StoreFalseAction, self).__init__(
            option_strings=option_strings,
            dest=dest,
            const=False,
            default=default,
            required=required,
            help=help)


class _AppendAction(Action):

    def __init__(self,
                 option_strings,
                 dest,
                 nargs=None,
                 const=None,
                 default=None,
                 type=None,
                 choices=None,
                 required=False,
                 help=None,
                 metavar=None):
        if nargs == 0:
            raise ValueError('nargs for append actions must be > 0; if arg '
                             'strings are not supplying the value to append, '
                             'the append const action may be more appropriate')
        if const is not None and nargs != OPTIONAL:
            raise ValueError('nargs must be %r to supply const' % OPTIONAL)
        super(_AppendAction, self).__init__(
            option_strings=option_strings,
            dest=dest,
            nargs=nargs,
            const=const,
            default=default,
            type=type,
            choices=choices,
            required=required,
            help=help,
            metavar=metavar)

    def __call__(self, parser, namespace, values, option_string=None):
        items = _copy.copy(_ensure_value(namespace, self.dest, []))
        items.append(values)
        setattr(namespace, self.dest, items)


class _AppendConstAction(Action):

    def __init__(self,
                 option_strings,
                 dest,
                 const,
                 default=None,
                 required=False,
                 help=None,
                 metavar=None):
        super(_AppendConstAction, self).__init__(
            option_strings=option_strings,
            dest=dest,
            nargs=0,
            const=const,
            default=default,
            required=required,
            help=help,
            metavar=metavar)

    def __call__(self, parser, namespace, values, option_string=None):
        items = _copy.copy(_ensure_value(namespace, self.dest, []))
        items.append(self.const)
        setattr(namespace, self.dest, items)


class _CountAction(Action):

    def __init__(self,
                 option_strings,
                 dest,
                 default=None,
                 required=False,
                 help=None):
        super(_CountAction, self).__init__(
            option_strings=option_strings,
            dest=dest,
            nargs=0,
            default=default,
            required=required,
            help=help)

    def __call__(self, parser, namespace, values, option_string=None):
        new_count = _ensure_value(namespace, self.dest, 0) + 1
        setattr(namespace, self.dest, new_count)


class _HelpAction(Action):

    def __init__(self,
                 option_strings,
                 dest=SUPPRESS,
                 default=SUPPRESS,
                 help=None):
        super(_HelpAction, self).__init__(
            option_strings=option_strings,
            dest=dest,
            default=default,
            nargs=0,
            help=help)

    def __call__(self, parser, namespace, values, option_string=None):
        parser.print_help()
        parser.exit()


class _VersionAction(Action):

    def __init__(self,
                 option_strings,
                 version=None,
                 dest=SUPPRESS,
                 default=SUPPRESS,
                 help="show program's version number and exit"):
        super(_VersionAction, self).__init__(
            option_strings=option_strings,
            dest=dest,
            default=default,
            nargs=0,
            help=help)
        self.version = version

    def __call__(self, parser, namespace, values, option_string=None):
        version = self.version
        if version is None:
            version = parser.version
        formatter = parser._get_formatter()
        formatter.add_text(version)
        parser.exit(message=formatter.format_help())


class _SubParsersAction(Action):

    class _ChoicesPseudoAction(Action):

        def __init__(self, name, help):
            sup = super(_SubParsersAction._ChoicesPseudoAction, self)
            sup.__init__(option_strings=[], dest=name, help=help)

    def __init__(self,
                 option_strings,
                 prog,
                 parser_class,
                 dest=SUPPRESS,
                 help=None,
                 metavar=None):

        self._prog_prefix = prog
        self._parser_class = parser_class
        self._name_parser_map = {}
        self._choices_actions = []

        super(_SubParsersAction, self).__init__(
            option_strings=option_strings,
            dest=dest,
            nargs=PARSER,
            choices=self._name_parser_map,
            help=help,
            metavar=metavar)

    def add_parser(self, name, **kwargs):
        # set prog from the existing prefix
        if kwargs.get('prog') is None:
            kwargs['prog'] = '%s %s' % (self._prog_prefix, name)

        # create a pseudo-action to hold the choice help
        if 'help' in kwargs:
            help = kwargs.pop('help')
            choice_action = self._ChoicesPseudoAction(name, help)
            self._choices_actions.append(choice_action)

        # create the parser and add it to the map
        parser = self._parser_class(**kwargs)
        self._name_parser_map[name] = parser
        return parser

    def _get_subactions(self):
        return self._choices_actions

    def __call__(self, parser, namespace, values, option_string=None):
        parser_name = values[0]
        arg_strings = values[1:]

        # set the parser name if requested
        if self.dest is not SUPPRESS:
            setattr(namespace, self.dest, parser_name)

        # select the parser
        try:
            parser = self._name_parser_map[parser_name]
        except KeyError:
            tup = parser_name, ', '.join(self._name_parser_map)
            msg = _('unknown parser %r (choices: %s)' % tup)
            raise ArgumentError(self, msg)

        # parse all the remaining options into the namespace
        # store any unrecognized options on the object, so that the top
        # level parser can decide what to do with them
        namespace, arg_strings = parser.parse_known_args(arg_strings, namespace)
        if arg_strings:
            vars(namespace).setdefault(_UNRECOGNIZED_ARGS_ATTR, [])
            getattr(namespace, _UNRECOGNIZED_ARGS_ATTR).extend(arg_strings)


# ==============
# Type classes
# ==============

class FileType(object):
    """Factory for creating file object types

    Instances of FileType are typically passed as type= arguments to the
    ArgumentParser add_argument() method.

    Keyword Arguments:
        - mode -- A string indicating how the file is to be opened. Accepts the
            same values as the builtin open() function.
        - bufsize -- The file's desired buffer size. Accepts the same values as
            the builtin open() function.
    """

    def __init__(self, mode='r', bufsize=None):
        self._mode = mode
        self._bufsize = bufsize

    def __call__(self, string):
        # the special argument "-" means sys.std{in,out}
        if string == '-':
            if 'r' in self._mode:
                return _sys.stdin
            elif 'w' in self._mode:
                return _sys.stdout
            else:
                msg = _('argument "-" with mode %r' % self._mode)
                raise ValueError(msg)

        # all other arguments are used as file names
        if self._bufsize:
            return open(string, self._mode, self._bufsize)
        else:
            return open(string, self._mode)

    def __repr__(self):
        args = [self._mode, self._bufsize]
        args_str = ', '.join([repr(arg) for arg in args if arg is not None])
        return '%s(%s)' % (type(self).__name__, args_str)

# ===========================
# Optional and Positional Parsing
# ===========================

class Namespace(_AttributeHolder):
    """Simple object for storing attributes.

    Implements equality by attribute names and values, and provides a simple
    string representation.
    """

    def __init__(self, **kwargs):
        for name in kwargs:
            setattr(self, name, kwargs[name])

    __hash__ = None

    def __eq__(self, other):
        return vars(self) == vars(other)

    def __ne__(self, other):
        return not (self == other)

    def __contains__(self, key):
        return key in self.__dict__


class _ActionsContainer(object):

    def __init__(self,
                 description,
                 prefix_chars,
                 argument_default,
                 conflict_handler):
        super(_ActionsContainer, self).__init__()

        self.description = description
        self.argument_default = argument_default
        self.prefix_chars = prefix_chars
        self.conflict_handler = conflict_handler

        # set up registries
        self._registries = {}

        # register actions
        self.register('action', None, _StoreAction)
        self.register('action', 'store', _StoreAction)
        self.register('action', 'store_const', _StoreConstAction)
        self.register('action', 'store_true', _StoreTrueAction)
        self.register('action', 'store_false', _StoreFalseAction)
        self.register('action', 'append', _AppendAction)
        self.register('action', 'append_const', _AppendConstAction)
        self.register('action', 'count', _CountAction)
        self.register('action', 'help', _HelpAction)
        self.register('action', 'version', _VersionAction)
        self.register('action', 'parsers', _SubParsersAction)

        # raise an exception if the conflict handler is invalid
        self._get_handler()

        # action storage
        self._actions = []
        self._option_string_actions = {}

        # groups
        self._action_groups = []
        self._mutually_exclusive_groups = []

        # defaults storage
        self._defaults = {}

        # determines whether an "option" looks like a negative number
        self._negative_number_matcher = _re.compile(r'^-\d+$|^-\d*\.\d+$')

        # whether or not there are any optionals that look like negative
        # numbers -- uses a list so it can be shared and edited
        self._has_negative_number_optionals = []

    # ====================
    # Registration methods
    # ====================
    def register(self, registry_name, value, object):
        registry = self._registries.setdefault(registry_name, {})
        registry[value] = object

    def _registry_get(self, registry_name, value, default=None):
        return self._registries[registry_name].get(value, default)

    # ==================================
    # Namespace default accessor methods
    # ==================================
    def set_defaults(self, **kwargs):
        self._defaults.update(kwargs)

        # if these defaults match any existing arguments, replace
        # the previous default on the object with the new one
        for action in self._actions:
            if action.dest in kwargs:
                action.default = kwargs[action.dest]

    def get_default(self, dest):
        for action in self._actions:
            if action.dest == dest and action.default is not None:
                return action.default
        return self._defaults.get(dest, None)


    # =======================
    # Adding argument actions
    # =======================
    def add_argument(self, *args, **kwargs):
        """
        add_argument(dest, ..., name=value, ...)
        add_argument(option_string, option_string, ..., name=value, ...)
        """

        # if no positional args are supplied or only one is supplied and
        # it doesn't look like an option string, parse a positional
        # argument
        chars = self.prefix_chars
        if not args or len(args) == 1 and args[0][0] not in chars:
            if args and 'dest' in kwargs:
                raise ValueError('dest supplied twice for positional argument')
            kwargs = self._get_positional_kwargs(*args, **kwargs)

        # otherwise, we're adding an optional argument
        else:
            kwargs = self._get_optional_kwargs(*args, **kwargs)

        # if no default was supplied, use the parser-level default
        if 'default' not in kwargs:
            dest = kwargs['dest']
            if dest in self._defaults:
                kwargs['default'] = self._defaults[dest]
            elif self.argument_default is not None:
                kwargs['default'] = self.argument_default

        # create the action object, and add it to the parser
        action_class = self._pop_action_class(kwargs)
        if not _callable(action_class):
            raise ValueError('unknown action "%s"' % action_class)
        action = action_class(**kwargs)

        # raise an error if the action type is not callable
        type_func = self._registry_get('type', action.type, action.type)
        if not _callable(type_func):
            raise ValueError('%r is not callable' % type_func)

        return self._add_action(action)

    def add_argument_group(self, *args, **kwargs):
        group = _ArgumentGroup(self, *args, **kwargs)
        self._action_groups.append(group)
        return group

    def add_mutually_exclusive_group(self, **kwargs):
        group = _MutuallyExclusiveGroup(self, **kwargs)
        self._mutually_exclusive_groups.append(group)
        return group

    def _add_action(self, action):
        # resolve any conflicts
        self._check_conflict(action)

        # add to actions list
        self._actions.append(action)
        action.container = self

        # index the action by any option strings it has
        for option_string in action.option_strings:
            self._option_string_actions[option_string] = action

        # set the flag if any option strings look like negative numbers
        for option_string in action.option_strings:
            if self._negative_number_matcher.match(option_string):
                if not self._has_negative_number_optionals:
                    self._has_negative_number_optionals.append(True)

        # return the created action
        return action

    def _remove_action(self, action):
        self._actions.remove(action)

    def _add_container_actions(self, container):
        # collect groups by titles
        title_group_map = {}
        for group in self._action_groups:
            if group.title in title_group_map:
                msg = _('cannot merge actions - two groups are named %r')
                raise ValueError(msg % (group.title))
            title_group_map[group.title] = group

        # map each action to its group
        group_map = {}
        for group in container._action_groups:

            # if a group with the title exists, use that, otherwise
            # create a new group matching the container's group
            if group.title not in title_group_map:
                title_group_map[group.title] = self.add_argument_group(
                    title=group.title,
                    description=group.description,
                    conflict_handler=group.conflict_handler)

            # map the actions to their new group
            for action in group._group_actions:
                group_map[action] = title_group_map[group.title]

        # add container's mutually exclusive groups
        # NOTE: if add_mutually_exclusive_group ever gains title= and
        # description= then this code will need to be expanded as above
        for group in container._mutually_exclusive_groups:
            mutex_group = self.add_mutually_exclusive_group(
                required=group.required)

            # map the actions to their new mutex group
            for action in group._group_actions:
                group_map[action] = mutex_group

        # add all actions to this container or their group
        for action in container._actions:
            group_map.get(action, self)._add_action(action)

    def _get_positional_kwargs(self, dest, **kwargs):
        # make sure required is not specified
        if 'required' in kwargs:
            msg = _("'required' is an invalid argument for positionals")
            raise TypeError(msg)

        # mark positional arguments as required if at least one is
        # always required
        if kwargs.get('nargs') not in [OPTIONAL, ZERO_OR_MORE]:
            kwargs['required'] = True
        if kwargs.get('nargs') == ZERO_OR_MORE and 'default' not in kwargs:
            kwargs['required'] = True

        # return the keyword arguments with no option strings
        return dict(kwargs, dest=dest, option_strings=[])

    def _get_optional_kwargs(self, *args, **kwargs):
        # determine short and long option strings
        option_strings = []
        long_option_strings = []
        for option_string in args:
            # error on strings that don't start with an appropriate prefix
            if not option_string[0] in self.prefix_chars:
                msg = _('invalid option string %r: '
                        'must start with a character %r')
                tup = option_string, self.prefix_chars
                raise ValueError(msg % tup)

            # strings starting with two prefix characters are long options
            option_strings.append(option_string)
            if option_string[0] in self.prefix_chars:
                if len(option_string) > 1:
                    if option_string[1] in self.prefix_chars:
                        long_option_strings.append(option_string)

        # infer destination, '--foo-bar' -> 'foo_bar' and '-x' -> 'x'
        dest = kwargs.pop('dest', None)
        if dest is None:
            if long_option_strings:
                dest_option_string = long_option_strings[0]
            else:
                dest_option_string = option_strings[0]
            dest = dest_option_string.lstrip(self.prefix_chars)
            if not dest:
                msg = _('dest= is required for options like %r')
                raise ValueError(msg % option_string)
            dest = dest.replace('-', '_')

        # return the updated keyword arguments
        return dict(kwargs, dest=dest, option_strings=option_strings)

    def _pop_action_class(self, kwargs, default=None):
        action = kwargs.pop('action', default)
        return self._registry_get('action', action, action)

    def _get_handler(self):
        # determine function from conflict handler string
        handler_func_name = '_handle_conflict_%s' % self.conflict_handler
        try:
            return getattr(self, handler_func_name)
        except AttributeError:
            msg = _('invalid conflict_resolution value: %r')
            raise ValueError(msg % self.conflict_handler)

    def _check_conflict(self, action):

        # find all options that conflict with this option
        confl_optionals = []
        for option_string in action.option_strings:
            if option_string in self._option_string_actions:
                confl_optional = self._option_string_actions[option_string]
                confl_optionals.append((option_string, confl_optional))

        # resolve any conflicts
        if confl_optionals:
            conflict_handler = self._get_handler()
            conflict_handler(action, confl_optionals)

    def _handle_conflict_error(self, action, conflicting_actions):
        message = _('conflicting option string(s): %s')
        conflict_string = ', '.join([option_string
                                     for option_string, action
                                     in conflicting_actions])
        raise ArgumentError(action, message % conflict_string)

    def _handle_conflict_resolve(self, action, conflicting_actions):

        # remove all conflicting options
        for option_string, action in conflicting_actions:

            # remove the conflicting option
            action.option_strings.remove(option_string)
            self._option_string_actions.pop(option_string, None)

            # if the option now has no option string, remove it from the
            # container holding it
            if not action.option_strings:
                action.container._remove_action(action)


class _ArgumentGroup(_ActionsContainer):

    def __init__(self, container, title=None, description=None, **kwargs):
        # add any missing keyword arguments by checking the container
        update = kwargs.setdefault
        update('conflict_handler', container.conflict_handler)
        update('prefix_chars', container.prefix_chars)
        update('argument_default', container.argument_default)
        super_init = super(_ArgumentGroup, self).__init__
        super_init(description=description, **kwargs)

        # group attributes
        self.title = title
        self._group_actions = []

        # share most attributes with the container
        self._registries = container._registries
        self._actions = container._actions
        self._option_string_actions = container._option_string_actions
        self._defaults = container._defaults
        self._has_negative_number_optionals = \
            container._has_negative_number_optionals

    def _add_action(self, action):
        action = super(_ArgumentGroup, self)._add_action(action)
        self._group_actions.append(action)
        return action

    def _remove_action(self, action):
        super(_ArgumentGroup, self)._remove_action(action)
        self._group_actions.remove(action)


class _MutuallyExclusiveGroup(_ArgumentGroup):

    def __init__(self, container, required=False):
        super(_MutuallyExclusiveGroup, self).__init__(container)
        self.required = required
        self._container = container

    def _add_action(self, action):
        if action.required:
            msg = _('mutually exclusive arguments must be optional')
            raise ValueError(msg)
        action = self._container._add_action(action)
        self._group_actions.append(action)
        return action

    def _remove_action(self, action):
        self._container._remove_action(action)
        self._group_actions.remove(action)


class ArgumentParser(_AttributeHolder, _ActionsContainer):
    """Object for parsing command line strings into Python objects.

    Keyword Arguments:
        - prog -- The name of the program (default: sys.argv[0])
        - usage -- A usage message (default: auto-generated from arguments)
        - description -- A description of what the program does
        - epilog -- Text following the argument descriptions
        - parents -- Parsers whose arguments should be copied into this one
        - formatter_class -- HelpFormatter class for printing help messages
        - prefix_chars -- Characters that prefix optional arguments
        - fromfile_prefix_chars -- Characters that prefix files containing
            additional arguments
        - argument_default -- The default value for all arguments
        - conflict_handler -- String indicating how to handle conflicts
        - add_help -- Add a -h/-help option
    """

    def __init__(self,
                 prog=None,
                 usage=None,
                 description=None,
                 epilog=None,
                 version=None,
                 parents=[],
                 formatter_class=HelpFormatter,
                 prefix_chars='-',
                 fromfile_prefix_chars=None,
                 argument_default=None,
                 conflict_handler='error',
                 add_help=True):

        if version is not None:
            import warnings
            warnings.warn(
                """The "version" argument to ArgumentParser is deprecated. """
                """Please use """
                """"add_argument(..., action='version', version="N", ...)" """
                """instead""", DeprecationWarning)

        superinit = super(ArgumentParser, self).__init__
        superinit(description=description,
                  prefix_chars=prefix_chars,
                  argument_default=argument_default,
                  conflict_handler=conflict_handler)

        # default setting for prog
        if prog is None:
            prog = _os.path.basename(_sys.argv[0])

        self.prog = prog
        self.usage = usage
        self.epilog = epilog
        self.version = version
        self.formatter_class = formatter_class
        self.fromfile_prefix_chars = fromfile_prefix_chars
        self.add_help = add_help

        add_group = self.add_argument_group
        self._positionals = add_group(_('positional arguments'))
        self._optionals = add_group(_('optional arguments'))
        self._subparsers = None

        # register types
        def identity(string):
            return string
        self.register('type', None, identity)

        # add help and version arguments if necessary
        # (using explicit default to override global argument_default)
        if '-' in prefix_chars:
            default_prefix = '-'
        else:
            default_prefix = prefix_chars[0]
        if self.add_help:
            self.add_argument(
                default_prefix+'h', default_prefix*2+'help',
                action='help', default=SUPPRESS,
                help=_('show this help message and exit'))
        if self.version:
            self.add_argument(
                default_prefix+'v', default_prefix*2+'version',
                action='version', default=SUPPRESS,
                version=self.version,
                help=_("show program's version number and exit"))

        # add parent arguments and defaults
        for parent in parents:
            self._add_container_actions(parent)
            try:
                defaults = parent._defaults
            except AttributeError:
                pass
            else:
                self._defaults.update(defaults)

    # =======================
    # Pretty __repr__ methods
    # =======================
    def _get_kwargs(self):
        names = [
            'prog',
            'usage',
            'description',
            'version',
            'formatter_class',
            'conflict_handler',
            'add_help',
        ]
        return [(name, getattr(self, name)) for name in names]

    # ==================================
    # Optional/Positional adding methods
    # ==================================
    def add_subparsers(self, **kwargs):
        if self._subparsers is not None:
            self.error(_('cannot have multiple subparser arguments'))

        # add the parser class to the arguments if it's not present
        kwargs.setdefault('parser_class', type(self))

        if 'title' in kwargs or 'description' in kwargs:
            title = _(kwargs.pop('title', 'subcommands'))
            description = _(kwargs.pop('description', None))
            self._subparsers = self.add_argument_group(title, description)
        else:
            self._subparsers = self._positionals

        # prog defaults to the usage message of this parser, skipping
        # optional arguments and with no "usage:" prefix
        if kwargs.get('prog') is None:
            formatter = self._get_formatter()
            positionals = self._get_positional_actions()
            groups = self._mutually_exclusive_groups
            formatter.add_usage(self.usage, positionals, groups, '')
            kwargs['prog'] = formatter.format_help().strip()

        # create the parsers action and add it to the positionals list
        parsers_class = self._pop_action_class(kwargs, 'parsers')
        action = parsers_class(option_strings=[], **kwargs)
        self._subparsers._add_action(action)

        # return the created parsers action
        return action

    def _add_action(self, action):
        if action.option_strings:
            self._optionals._add_action(action)
        else:
            self._positionals._add_action(action)
        return action

    def _get_optional_actions(self):
        return [action
                for action in self._actions
                if action.option_strings]

    def _get_positional_actions(self):
        return [action
                for action in self._actions
                if not action.option_strings]

    # =====================================
    # Command line argument parsing methods
    # =====================================
    def parse_args(self, args=None, namespace=None):
        args, argv = self.parse_known_args(args, namespace)
        if argv:
            msg = _('unrecognized arguments: %s')
            self.error(msg % ' '.join(argv))
        return args

    def parse_known_args(self, args=None, namespace=None):
        # args default to the system args
        if args is None:
            args = _sys.argv[1:]

        # default Namespace built from parser defaults
        if namespace is None:
            namespace = Namespace()

        # add any action defaults that aren't present
        for action in self._actions:
            if action.dest is not SUPPRESS:
                if not hasattr(namespace, action.dest):
                    if action.default is not SUPPRESS:
                        default = action.default
                        if isinstance(action.default, basestring):
                            default = self._get_value(action, default)
                        setattr(namespace, action.dest, default)

        # add any parser defaults that aren't present
        for dest in self._defaults:
            if not hasattr(namespace, dest):
                setattr(namespace, dest, self._defaults[dest])

        # parse the arguments and exit if there are any errors
        try:
            namespace, args = self._parse_known_args(args, namespace)
            if hasattr(namespace, _UNRECOGNIZED_ARGS_ATTR):
                args.extend(getattr(namespace, _UNRECOGNIZED_ARGS_ATTR))
                delattr(namespace, _UNRECOGNIZED_ARGS_ATTR)
            return namespace, args
        except ArgumentError:
            err = _sys.exc_info()[1]
            self.error(str(err))

    def _parse_known_args(self, arg_strings, namespace):
        # replace arg strings that are file references
        if self.fromfile_prefix_chars is not None:
            arg_strings = self._read_args_from_files(arg_strings)

        # map all mutually exclusive arguments to the other arguments
        # they can't occur with
        action_conflicts = {}
        for mutex_group in self._mutually_exclusive_groups:
            group_actions = mutex_group._group_actions
            for i, mutex_action in enumerate(mutex_group._group_actions):
                conflicts = action_conflicts.setdefault(mutex_action, [])
                conflicts.extend(group_actions[:i])
                conflicts.extend(group_actions[i + 1:])

        # find all option indices, and determine the arg_string_pattern
        # which has an 'O' if there is an option at an index,
        # an 'A' if there is an argument, or a '-' if there is a '--'
        option_string_indices = {}
        arg_string_pattern_parts = []
        arg_strings_iter = iter(arg_strings)
        for i, arg_string in enumerate(arg_strings_iter):

            # all args after -- are non-options
            if arg_string == '--':
                arg_string_pattern_parts.append('-')
                for arg_string in arg_strings_iter:
                    arg_string_pattern_parts.append('A')

            # otherwise, add the arg to the arg strings
            # and note the index if it was an option
            else:
                option_tuple = self._parse_optional(arg_string)
                if option_tuple is None:
                    pattern = 'A'
                else:
                    option_string_indices[i] = option_tuple
                    pattern = 'O'
                arg_string_pattern_parts.append(pattern)

        # join the pieces together to form the pattern
        arg_strings_pattern = ''.join(arg_string_pattern_parts)

        # converts arg strings to the appropriate and then takes the action
        seen_actions = set()
        seen_non_default_actions = set()

        def take_action(action, argument_strings, option_string=None):
            seen_actions.add(action)
            argument_values = self._get_values(action, argument_strings)

            # error if this argument is not allowed with other previously
            # seen arguments, assuming that actions that use the default
            # value don't really count as "present"
            if argument_values is not action.default:
                seen_non_default_actions.add(action)
                for conflict_action in action_conflicts.get(action, []):
                    if conflict_action in seen_non_default_actions:
                        msg = _('not allowed with argument %s')
                        action_name = _get_action_name(conflict_action)
                        raise ArgumentError(action, msg % action_name)

            # take the action if we didn't receive a SUPPRESS value
            # (e.g. from a default)
            if argument_values is not SUPPRESS:
                action(self, namespace, argument_values, option_string)

        # function to convert arg_strings into an optional action
        def consume_optional(start_index):

            # get the optional identified at this index
            option_tuple = option_string_indices[start_index]
            action, option_string, explicit_arg = option_tuple

            # identify additional optionals in the same arg string
            # (e.g. -xyz is the same as -x -y -z if no args are required)
            match_argument = self._match_argument
            action_tuples = []
            while True:

                # if we found no optional action, skip it
                if action is None:
                    extras.append(arg_strings[start_index])
                    return start_index + 1

                # if there is an explicit argument, try to match the
                # optional's string arguments to only this
                if explicit_arg is not None:
                    arg_count = match_argument(action, 'A')

                    # if the action is a single-dash option and takes no
                    # arguments, try to parse more single-dash options out
                    # of the tail of the option string
                    chars = self.prefix_chars
                    if arg_count == 0 and option_string[1] not in chars:
                        action_tuples.append((action, [], option_string))
                        char = option_string[0]
                        option_string = char + explicit_arg[0]
                        new_explicit_arg = explicit_arg[1:] or None
                        optionals_map = self._option_string_actions
                        if option_string in optionals_map:
                            action = optionals_map[option_string]
                            explicit_arg = new_explicit_arg
                        else:
                            msg = _('ignored explicit argument %r')
                            raise ArgumentError(action, msg % explicit_arg)

                    # if the action expect exactly one argument, we've
                    # successfully matched the option; exit the loop
                    elif arg_count == 1:
                        stop = start_index + 1
                        args = [explicit_arg]
                        action_tuples.append((action, args, option_string))
                        break

                    # error if a double-dash option did not use the
                    # explicit argument
                    else:
                        msg = _('ignored explicit argument %r')
                        raise ArgumentError(action, msg % explicit_arg)

                # if there is no explicit argument, try to match the
                # optional's string arguments with the following strings
                # if successful, exit the loop
                else:
                    start = start_index + 1
                    selected_patterns = arg_strings_pattern[start:]
                    arg_count = match_argument(action, selected_patterns)
                    stop = start + arg_count
                    args = arg_strings[start:stop]
                    action_tuples.append((action, args, option_string))
                    break

            # add the Optional to the list and return the index at which
            # the Optional's string args stopped
            assert action_tuples
            for action, args, option_string in action_tuples:
                take_action(action, args, option_string)
            return stop

        # the list of Positionals left to be parsed; this is modified
        # by consume_positionals()
        positionals = self._get_positional_actions()

        # function to convert arg_strings into positional actions
        def consume_positionals(start_index):
            # match as many Positionals as possible
            match_partial = self._match_arguments_partial
            selected_pattern = arg_strings_pattern[start_index:]
            arg_counts = match_partial(positionals, selected_pattern)

            # slice off the appropriate arg strings for each Positional
            # and add the Positional and its args to the list
            for action, arg_count in zip(positionals, arg_counts):
                args = arg_strings[start_index: start_index + arg_count]
                start_index += arg_count
                take_action(action, args)

            # slice off the Positionals that we just parsed and return the
            # index at which the Positionals' string args stopped
            positionals[:] = positionals[len(arg_counts):]
            return start_index

        # consume Positionals and Optionals alternately, until we have
        # passed the last option string
        extras = []
        start_index = 0
        if option_string_indices:
            max_option_string_index = max(option_string_indices)
        else:
            max_option_string_index = -1
        while start_index <= max_option_string_index:

            # consume any Positionals preceding the next option
            next_option_string_index = min([
                index
                for index in option_string_indices
                if index >= start_index])
            if start_index != next_option_string_index:
                positionals_end_index = consume_positionals(start_index)

                # only try to parse the next optional if we didn't consume
                # the option string during the positionals parsing
                if positionals_end_index > start_index:
                    start_index = positionals_end_index
                    continue
                else:
                    start_index = positionals_end_index

            # if we consumed all the positionals we could and we're not
            # at the index of an option string, there were extra arguments
            if start_index not in option_string_indices:
                strings = arg_strings[start_index:next_option_string_index]
                extras.extend(strings)
                start_index = next_option_string_index

            # consume the next optional and any arguments for it
            start_index = consume_optional(start_index)

        # consume any positionals following the last Optional
        stop_index = consume_positionals(start_index)

        # if we didn't consume all the argument strings, there were extras
        extras.extend(arg_strings[stop_index:])

        # if we didn't use all the Positional objects, there were too few
        # arg strings supplied.
        if positionals:
            self.error(_('too few arguments'))

        # make sure all required actions were present
        for action in self._actions:
            if action.required:
                if action not in seen_actions:
                    name = _get_action_name(action)
                    self.error(_('argument %s is required') % name)

        # make sure all required groups had one option present
        for group in self._mutually_exclusive_groups:
            if group.required:
                for action in group._group_actions:
                    if action in seen_non_default_actions:
                        break

                # if no actions were used, report the error
                else:
                    names = [_get_action_name(action)
                             for action in group._group_actions
                             if action.help is not SUPPRESS]
                    msg = _('one of the arguments %s is required')
                    self.error(msg % ' '.join(names))

        # return the updated namespace and the extra arguments
        return namespace, extras

    def _read_args_from_files(self, arg_strings):
        # expand arguments referencing files
        new_arg_strings = []
        for arg_string in arg_strings:

            # for regular arguments, just add them back into the list
            if arg_string[0] not in self.fromfile_prefix_chars:
                new_arg_strings.append(arg_string)

            # replace arguments referencing files with the file content
            else:
                try:
                    args_file = open(arg_string[1:])
                    try:
                        arg_strings = []
                        for arg_line in args_file.read().splitlines():
                            for arg in self.convert_arg_line_to_args(arg_line):
                                arg_strings.append(arg)
                        arg_strings = self._read_args_from_files(arg_strings)
                        new_arg_strings.extend(arg_strings)
                    finally:
                        args_file.close()
                except IOError:
                    err = _sys.exc_info()[1]
                    self.error(str(err))

        # return the modified argument list
        return new_arg_strings

    def convert_arg_line_to_args(self, arg_line):
        return [arg_line]

    def _match_argument(self, action, arg_strings_pattern):
        # match the pattern for this action to the arg strings
        nargs_pattern = self._get_nargs_pattern(action)
        match = _re.match(nargs_pattern, arg_strings_pattern)

        # raise an exception if we weren't able to find a match
        if match is None:
            nargs_errors = {
                None: _('expected one argument'),
                OPTIONAL: _('expected at most one argument'),
                ONE_OR_MORE: _('expected at least one argument'),
            }
            default = _('expected %s argument(s)') % action.nargs
            msg = nargs_errors.get(action.nargs, default)
            raise ArgumentError(action, msg)

        # return the number of arguments matched
        return len(match.group(1))

    def _match_arguments_partial(self, actions, arg_strings_pattern):
        # progressively shorten the actions list by slicing off the
        # final actions until we find a match
        result = []
        for i in range(len(actions), 0, -1):
            actions_slice = actions[:i]
            pattern = ''.join([self._get_nargs_pattern(action)
                               for action in actions_slice])
            match = _re.match(pattern, arg_strings_pattern)
            if match is not None:
                result.extend([len(string) for string in match.groups()])
                break

        # return the list of arg string counts
        return result

    def _parse_optional(self, arg_string):
        # if it's an empty string, it was meant to be a positional
        if not arg_string:
            return None

        # if it doesn't start with a prefix, it was meant to be positional
        if not arg_string[0] in self.prefix_chars:
            return None

        # if the option string is present in the parser, return the action
        if arg_string in self._option_string_actions:
            action = self._option_string_actions[arg_string]
            return action, arg_string, None

        # if it's just a single character, it was meant to be positional
        if len(arg_string) == 1:
            return None

        # if the option string before the "=" is present, return the action
        if '=' in arg_string:
            option_string, explicit_arg = arg_string.split('=', 1)
            if option_string in self._option_string_actions:
                action = self._option_string_actions[option_string]
                return action, option_string, explicit_arg

        # search through all possible prefixes of the option string
        # and all actions in the parser for possible interpretations
        option_tuples = self._get_option_tuples(arg_string)

        # if multiple actions match, the option string was ambiguous
        if len(option_tuples) > 1:
            options = ', '.join([option_string
                for action, option_string, explicit_arg in option_tuples])
            tup = arg_string, options
            self.error(_('ambiguous option: %s could match %s') % tup)

        # if exactly one action matched, this segmentation is good,
        # so return the parsed action
        elif len(option_tuples) == 1:
            option_tuple, = option_tuples
            return option_tuple

        # if it was not found as an option, but it looks like a negative
        # number, it was meant to be positional
        # unless there are negative-number-like options
        if self._negative_number_matcher.match(arg_string):
            if not self._has_negative_number_optionals:
                return None

        # if it contains a space, it was meant to be a positional
        if ' ' in arg_string:
            return None

        # it was meant to be an optional but there is no such option
        # in this parser (though it might be a valid option in a subparser)
        return None, arg_string, None

    def _get_option_tuples(self, option_string):
        result = []

        # option strings starting with two prefix characters are only
        # split at the '='
        chars = self.prefix_chars
        if option_string[0] in chars and option_string[1] in chars:
            if '=' in option_string:
                option_prefix, explicit_arg = option_string.split('=', 1)
            else:
                option_prefix = option_string
                explicit_arg = None
            for option_string in self._option_string_actions:
                if option_string.startswith(option_prefix):
                    action = self._option_string_actions[option_string]
                    tup = action, option_string, explicit_arg
                    result.append(tup)

        # single character options can be concatenated with their arguments
        # but multiple character options always have to have their argument
        # separate
        elif option_string[0] in chars and option_string[1] not in chars:
            option_prefix = option_string
            explicit_arg = None
            short_option_prefix = option_string[:2]
            short_explicit_arg = option_string[2:]

            for option_string in self._option_string_actions:
                if option_string == short_option_prefix:
                    action = self._option_string_actions[option_string]
                    tup = action, option_string, short_explicit_arg
                    result.append(tup)
                elif option_string.startswith(option_prefix):
                    action = self._option_string_actions[option_string]
                    tup = action, option_string, explicit_arg
                    result.append(tup)

        # shouldn't ever get here
        else:
            self.error(_('unexpected option string: %s') % option_string)

        # return the collected option tuples
        return result

    def _get_nargs_pattern(self, action):
        # in all examples below, we have to allow for '--' args
        # which are represented as '-' in the pattern
        nargs = action.nargs

        # the default (None) is assumed to be a single argument
        if nargs is None:
            nargs_pattern = '(-*A-*)'

        # allow zero or one arguments
        elif nargs == OPTIONAL:
            nargs_pattern = '(-*A?-*)'

        # allow zero or more arguments
        elif nargs == ZERO_OR_MORE:
            nargs_pattern = '(-*[A-]*)'

        # allow one or more arguments
        elif nargs == ONE_OR_MORE:
            nargs_pattern = '(-*A[A-]*)'

        # allow any number of options or arguments
        elif nargs == REMAINDER:
            nargs_pattern = '([-AO]*)'

        # allow one argument followed by any number of options or arguments
        elif nargs == PARSER:
            nargs_pattern = '(-*A[-AO]*)'

        # all others should be integers
        else:
            nargs_pattern = '(-*%s-*)' % '-*'.join('A' * nargs)

        # if this is an optional action, -- is not allowed
        if action.option_strings:
            nargs_pattern = nargs_pattern.replace('-*', '')
            nargs_pattern = nargs_pattern.replace('-', '')

        # return the pattern
        return nargs_pattern

    # ========================
    # Value conversion methods
    # ========================
    def _get_values(self, action, arg_strings):
        # for everything but PARSER args, strip out '--'
        if action.nargs not in [PARSER, REMAINDER]:
            arg_strings = [s for s in arg_strings if s != '--']

        # optional argument produces a default when not present
        if not arg_strings and action.nargs == OPTIONAL:
            if action.option_strings:
                value = action.const
            else:
                value = action.default
            if isinstance(value, basestring):
                value = self._get_value(action, value)
                self._check_value(action, value)

        # when nargs='*' on a positional, if there were no command-line
        # args, use the default if it is anything other than None
        elif (not arg_strings and action.nargs == ZERO_OR_MORE and
              not action.option_strings):
            if action.default is not None:
                value = action.default
            else:
                value = arg_strings
            self._check_value(action, value)

        # single argument or optional argument produces a single value
        elif len(arg_strings) == 1 and action.nargs in [None, OPTIONAL]:
            arg_string, = arg_strings
            value = self._get_value(action, arg_string)
            self._check_value(action, value)

        # REMAINDER arguments convert all values, checking none
        elif action.nargs == REMAINDER:
            value = [self._get_value(action, v) for v in arg_strings]

        # PARSER arguments convert all values, but check only the first
        elif action.nargs == PARSER:
            value = [self._get_value(action, v) for v in arg_strings]
            self._check_value(action, value[0])

        # all other types of nargs produce a list
        else:
            value = [self._get_value(action, v) for v in arg_strings]
            for v in value:
                self._check_value(action, v)

        # return the converted value
        return value

    def _get_value(self, action, arg_string):
        type_func = self._registry_get('type', action.type, action.type)
        if not _callable(type_func):
            msg = _('%r is not callable')
            raise ArgumentError(action, msg % type_func)

        # convert the value to the appropriate type
        try:
            result = type_func(arg_string)

        # ArgumentTypeErrors indicate errors
        except ArgumentTypeError:
            name = getattr(action.type, '__name__', repr(action.type))
            msg = str(_sys.exc_info()[1])
            raise ArgumentError(action, msg)

        # TypeErrors or ValueErrors also indicate errors
        except (TypeError, ValueError):
            name = getattr(action.type, '__name__', repr(action.type))
            msg = _('invalid %s value: %r')
            raise ArgumentError(action, msg % (name, arg_string))

        # return the converted value
        return result

    def _check_value(self, action, value):
        # converted value must be one of the choices (if specified)
        if action.choices is not None and value not in action.choices:
            tup = value, ', '.join(map(repr, action.choices))
            msg = _('invalid choice: %r (choose from %s)') % tup
            raise ArgumentError(action, msg)

    # =======================
    # Help-formatting methods
    # =======================
    def format_usage(self):
        formatter = self._get_formatter()
        formatter.add_usage(self.usage, self._actions,
                            self._mutually_exclusive_groups)
        return formatter.format_help()

    def format_help(self):
        formatter = self._get_formatter()

        # usage
        formatter.add_usage(self.usage, self._actions,
                            self._mutually_exclusive_groups)

        # description
        formatter.add_text(self.description)

        # positionals, optionals and user-defined groups
        for action_group in self._action_groups:
            formatter.start_section(action_group.title)
            formatter.add_text(action_group.description)
            formatter.add_arguments(action_group._group_actions)
            formatter.end_section()

        # epilog
        formatter.add_text(self.epilog)

        # determine help from format above
        return formatter.format_help()

    def format_version(self):
        import warnings
        warnings.warn(
            'The format_version method is deprecated -- the "version" '
            'argument to ArgumentParser is no longer supported.',
            DeprecationWarning)
        formatter = self._get_formatter()
        formatter.add_text(self.version)
        return formatter.format_help()

    def _get_formatter(self):
        return self.formatter_class(prog=self.prog)

    # =====================
    # Help-printing methods
    # =====================
    def print_usage(self, file=None):
        if file is None:
            file = _sys.stdout
        self._print_message(self.format_usage(), file)

    def print_help(self, file=None):
        if file is None:
            file = _sys.stdout
        self._print_message(self.format_help(), file)

    def print_version(self, file=None):
        import warnings
        warnings.warn(
            'The print_version method is deprecated -- the "version" '
            'argument to ArgumentParser is no longer supported.',
            DeprecationWarning)
        self._print_message(self.format_version(), file)

    def _print_message(self, message, file=None):
        if message:
            if file is None:
                file = _sys.stderr
            file.write(message)

    # ===============
    # Exiting methods
    # ===============
    def exit(self, status=0, message=None):
        if message:
            self._print_message(message, _sys.stderr)
        _sys.exit(status)

    def error(self, message):
        """error(message: string)

        Prints a usage message incorporating the message to stderr and
        exits.

        If you override this in a subclass, it should not return -- it
        should either exit or raise an exception.
        """
        self.print_usage(_sys.stderr)
        self.exit(2, _('%s: error: %s\n') % (self.prog, message))

########NEW FILE########
__FILENAME__ = byteplay
# byteplay - Python bytecode assembler/disassembler.
# Copyright (C) 2006-2010 Noam Yorav-Raphael
# Homepage: http://code.google.com/p/byteplay
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA

# Many thanks to Greg X for adding support for Python 2.6 and 2.7!

__version__ = '0.2'

__all__ = ['opmap', 'opname', 'opcodes',
           'cmp_op', 'hasarg', 'hasname', 'hasjrel', 'hasjabs',
           'hasjump', 'haslocal', 'hascompare', 'hasfree', 'hascode',
           'hasflow', 'getse',
           'Opcode', 'SetLineno', 'Label', 'isopcode', 'Code',
           'CodeList', 'printcodelist']

import opcode
from dis import findlabels
import types
from array import array
import operator
import itertools
import sys
import warnings
from cStringIO import StringIO

######################################################################
# Define opcodes and information about them

python_version = '.'.join(str(x) for x in sys.version_info[:2])
if python_version not in ('2.4', '2.5', '2.6', '2.7'):
    warnings.warn("byteplay doesn't support Python version "+python_version)

class Opcode(int):
    """An int which represents an opcode - has a nicer repr."""
    def __repr__(self):
        return opname[self]
    __str__ = __repr__

class CodeList(list):
    """A list for storing opcode tuples - has a nicer __str__."""
    def __str__(self):
        f = StringIO()
        printcodelist(self, f)
        return f.getvalue()

opmap = dict((name.replace('+', '_'), Opcode(code))
             for name, code in opcode.opmap.iteritems()
             if name != 'EXTENDED_ARG')
opname = dict((code, name) for name, code in opmap.iteritems())
opcodes = set(opname)

def globalize_opcodes():
    for name, code in opmap.iteritems():
        globals()[name] = code
        __all__.append(name)
globalize_opcodes()

cmp_op = opcode.cmp_op

hasarg = set(x for x in opcodes if x >= opcode.HAVE_ARGUMENT)
hasconst = set(Opcode(x) for x in opcode.hasconst)
hasname = set(Opcode(x) for x in opcode.hasname)
hasjrel = set(Opcode(x) for x in opcode.hasjrel)
hasjabs = set(Opcode(x) for x in opcode.hasjabs)
hasjump = hasjrel.union(hasjabs)
haslocal = set(Opcode(x) for x in opcode.haslocal)
hascompare = set(Opcode(x) for x in opcode.hascompare)
hasfree = set(Opcode(x) for x in opcode.hasfree)
hascode = set([MAKE_FUNCTION, MAKE_CLOSURE])

class _se:
    """Quick way of defining static stack effects of opcodes"""
    # Taken from assembler.py by Phillip J. Eby
    NOP       = 0,0

    POP_TOP   = 1,0
    ROT_TWO   = 2,2
    ROT_THREE = 3,3
    ROT_FOUR  = 4,4
    DUP_TOP   = 1,2

    UNARY_POSITIVE = UNARY_NEGATIVE = UNARY_NOT = UNARY_CONVERT = \
        UNARY_INVERT = GET_ITER = LOAD_ATTR = 1,1

    IMPORT_FROM = 1,2

    BINARY_POWER = BINARY_MULTIPLY = BINARY_DIVIDE = BINARY_FLOOR_DIVIDE = \
        BINARY_TRUE_DIVIDE = BINARY_MODULO = BINARY_ADD = BINARY_SUBTRACT = \
        BINARY_SUBSCR = BINARY_LSHIFT = BINARY_RSHIFT = BINARY_AND = \
        BINARY_XOR = BINARY_OR = COMPARE_OP = 2,1

    INPLACE_POWER = INPLACE_MULTIPLY = INPLACE_DIVIDE = \
        INPLACE_FLOOR_DIVIDE = INPLACE_TRUE_DIVIDE = INPLACE_MODULO = \
        INPLACE_ADD = INPLACE_SUBTRACT = INPLACE_LSHIFT = INPLACE_RSHIFT = \
        INPLACE_AND = INPLACE_XOR = INPLACE_OR = 2,1

    SLICE_0, SLICE_1, SLICE_2, SLICE_3 = \
        (1,1),(2,1),(2,1),(3,1)
    STORE_SLICE_0, STORE_SLICE_1, STORE_SLICE_2, STORE_SLICE_3 = \
        (2,0),(3,0),(3,0),(4,0)
    DELETE_SLICE_0, DELETE_SLICE_1, DELETE_SLICE_2, DELETE_SLICE_3 = \
        (1,0),(2,0),(2,0),(3,0)

    STORE_SUBSCR = 3,0
    DELETE_SUBSCR = STORE_ATTR = 2,0
    DELETE_ATTR = STORE_DEREF = 1,0
    PRINT_NEWLINE = 0,0
    PRINT_EXPR = PRINT_ITEM = PRINT_NEWLINE_TO = IMPORT_STAR = 1,0
    STORE_NAME = STORE_GLOBAL = STORE_FAST = 1,0
    PRINT_ITEM_TO = 2,0

    LOAD_LOCALS = LOAD_CONST = LOAD_NAME = LOAD_GLOBAL = LOAD_FAST = \
        LOAD_CLOSURE = LOAD_DEREF = BUILD_MAP = 0,1

    DELETE_FAST = DELETE_GLOBAL = DELETE_NAME = 0,0

    EXEC_STMT = 3,0
    BUILD_CLASS = 3,1

    STORE_MAP = MAP_ADD = 2,0
    SET_ADD = 1,0

    if   python_version == '2.4':
      YIELD_VALUE = 1,0
      IMPORT_NAME = 1,1
      LIST_APPEND = 2,0
    elif python_version == '2.5':
      YIELD_VALUE = 1,1
      IMPORT_NAME = 2,1
      LIST_APPEND = 2,0
    elif python_version == '2.6':
      YIELD_VALUE = 1,1
      IMPORT_NAME = 2,1
      LIST_APPEND = 2,0
    elif python_version == '2.7':
      YIELD_VALUE = 1,1
      IMPORT_NAME = 2,1
      LIST_APPEND = 1,0


_se = dict((op, getattr(_se, opname[op]))
           for op in opcodes
           if hasattr(_se, opname[op]))

hasflow = opcodes - set(_se) - \
          set([CALL_FUNCTION, CALL_FUNCTION_VAR, CALL_FUNCTION_KW,
               CALL_FUNCTION_VAR_KW, BUILD_TUPLE, BUILD_LIST,
               UNPACK_SEQUENCE, BUILD_SLICE, DUP_TOPX,
               RAISE_VARARGS, MAKE_FUNCTION, MAKE_CLOSURE])
if python_version == '2.7':
  hasflow = hasflow - set([BUILD_SET])

def getse(op, arg=None):
    """Get the stack effect of an opcode, as a (pop, push) tuple.

    If an arg is needed and is not given, a ValueError is raised.
    If op isn't a simple opcode, that is, the flow doesn't always continue
    to the next opcode, a ValueError is raised.
    """
    try:
        return _se[op]
    except KeyError:
        # Continue to opcodes with an effect that depends on arg
        pass

    if arg is None:
        raise ValueError, "Opcode stack behaviour depends on arg"

    def get_func_tup(arg, nextra):
        if arg > 0xFFFF:
            raise ValueError, "Can only split a two-byte argument"
        return (nextra + 1 + (arg & 0xFF) + 2*((arg >> 8) & 0xFF),
                1)

    if op == CALL_FUNCTION:
        return get_func_tup(arg, 0)
    elif op == CALL_FUNCTION_VAR:
        return get_func_tup(arg, 1)
    elif op == CALL_FUNCTION_KW:
        return get_func_tup(arg, 1)
    elif op == CALL_FUNCTION_VAR_KW:
        return get_func_tup(arg, 2)

    elif op == BUILD_TUPLE:
        return arg, 1
    elif op == BUILD_LIST:
        return arg, 1
    elif python_version == '2.7' and op == BUILD_SET:
        return arg, 1
    elif op == UNPACK_SEQUENCE:
        return 1, arg
    elif op == BUILD_SLICE:
        return arg, 1
    elif op == DUP_TOPX:
        return arg, arg*2
    elif op == RAISE_VARARGS:
        return 1+arg, 1
    elif op == MAKE_FUNCTION:
        return 1+arg, 1
    elif op == MAKE_CLOSURE:
        if python_version == '2.4':
            raise ValueError, "The stack effect of MAKE_CLOSURE depends on TOS"
        else:
            return 2+arg, 1
    else:
        raise ValueError, "The opcode %r isn't recognized or has a special "\
              "flow control" % op

class SetLinenoType(object):
    def __repr__(self):
        return 'SetLineno'
SetLineno = SetLinenoType()

class Label(object):
    pass

def isopcode(obj):
    """Return whether obj is an opcode - not SetLineno or Label"""
    return obj is not SetLineno and not isinstance(obj, Label)

# Flags from code.h
CO_OPTIMIZED              = 0x0001      # use LOAD/STORE_FAST instead of _NAME
CO_NEWLOCALS              = 0x0002      # only cleared for module/exec code
CO_VARARGS                = 0x0004
CO_VARKEYWORDS            = 0x0008
CO_NESTED                 = 0x0010      # ???
CO_GENERATOR              = 0x0020
CO_NOFREE                 = 0x0040      # set if no free or cell vars
CO_GENERATOR_ALLOWED      = 0x1000      # unused
# The future flags are only used on code generation, so we can ignore them.
# (It does cause some warnings, though.)
CO_FUTURE_DIVISION        = 0x2000
CO_FUTURE_ABSOLUTE_IMPORT = 0x4000
CO_FUTURE_WITH_STATEMENT  = 0x8000


######################################################################
# Define the Code class

class Code(object):
    """An object which holds all the information which a Python code object
    holds, but in an easy-to-play-with representation.

    The attributes are:

    Affecting action
    ----------------
    code - list of 2-tuples: the code
    freevars - list of strings: the free vars of the code (those are names
               of variables created in outer functions and used in the function)
    args - list of strings: the arguments of the code
    varargs - boolean: Does args end with a '*args' argument
    varkwargs - boolean: Does args end with a '**kwargs' argument
    newlocals - boolean: Should a new local namespace be created.
                (True in functions, False for module and exec code)

    Not affecting action
    --------------------
    name - string: the name of the code (co_name)
    filename - string: the file name of the code (co_filename)
    firstlineno - int: the first line number (co_firstlineno)
    docstring - string or None: the docstring (the first item of co_consts,
                if it's str or unicode)

    code is a list of 2-tuples. The first item is an opcode, or SetLineno, or a
    Label instance. The second item is the argument, if applicable, or None.
    code can be a CodeList instance, which will produce nicer output when
    being printed.
    """
    def __init__(self, code, freevars, args, varargs, varkwargs, newlocals,
                 name, filename, firstlineno, docstring):
        self.code = code
        self.freevars = freevars
        self.args = args
        self.varargs = varargs
        self.varkwargs = varkwargs
        self.newlocals = newlocals
        self.name = name
        self.filename = filename
        self.firstlineno = firstlineno
        self.docstring = docstring

    @staticmethod
    def _findlinestarts(code):
        """Find the offsets in a byte code which are start of lines in the
        source.

        Generate pairs (offset, lineno) as described in Python/compile.c.

        This is a modified version of dis.findlinestarts, which allows multiple
        "line starts" with the same line number.
        """
        byte_increments = [ord(c) for c in code.co_lnotab[0::2]]
        line_increments = [ord(c) for c in code.co_lnotab[1::2]]

        lineno = code.co_firstlineno
        addr = 0
        for byte_incr, line_incr in zip(byte_increments, line_increments):
            if byte_incr:
                yield (addr, lineno)
                addr += byte_incr
            lineno += line_incr
        yield (addr, lineno)

    @classmethod
    def from_code(cls, co):
        """Disassemble a Python code object into a Code object."""
        co_code = co.co_code
        labels = dict((addr, Label()) for addr in findlabels(co_code))
        linestarts = dict(cls._findlinestarts(co))
        cellfree = co.co_cellvars + co.co_freevars

        code = CodeList()
        n = len(co_code)
        i = 0
        extended_arg = 0
        while i < n:
            op = Opcode(ord(co_code[i]))
            if i in labels:
                code.append((labels[i], None))
            if i in linestarts:
                code.append((SetLineno, linestarts[i]))
            i += 1
            if op in hascode:
                lastop, lastarg = code[-1]
                if lastop != LOAD_CONST:
                    raise ValueError, \
                          "%s should be preceded by LOAD_CONST code" % op
                code[-1] = (LOAD_CONST, Code.from_code(lastarg))
            if op not in hasarg:
                code.append((op, None))
            else:
                arg = ord(co_code[i]) + ord(co_code[i+1])*256 + extended_arg
                extended_arg = 0
                i += 2
                if op == opcode.EXTENDED_ARG:
                    extended_arg = arg << 16
                elif op in hasconst:
                    code.append((op, co.co_consts[arg]))
                elif op in hasname:
                    code.append((op, co.co_names[arg]))
                elif op in hasjabs:
                    code.append((op, labels[arg]))
                elif op in hasjrel:
                    code.append((op, labels[i + arg]))
                elif op in haslocal:
                    code.append((op, co.co_varnames[arg]))
                elif op in hascompare:
                    code.append((op, cmp_op[arg]))
                elif op in hasfree:
                    code.append((op, cellfree[arg]))
                else:
                    code.append((op, arg))

        varargs = bool(co.co_flags & CO_VARARGS)
        varkwargs = bool(co.co_flags & CO_VARKEYWORDS)
        newlocals = bool(co.co_flags & CO_NEWLOCALS)
        args = co.co_varnames[:co.co_argcount + varargs + varkwargs]
        if co.co_consts and isinstance(co.co_consts[0], basestring):
            docstring = co.co_consts[0]
        else:
            docstring = None
        return cls(code = code,
                   freevars = co.co_freevars,
                   args = args,
                   varargs = varargs,
                   varkwargs = varkwargs,
                   newlocals = newlocals,
                   name = co.co_name,
                   filename = co.co_filename,
                   firstlineno = co.co_firstlineno,
                   docstring = docstring,
                   )

    def __eq__(self, other):
        if (self.freevars != other.freevars or
            self.args != other.args or
            self.varargs != other.varargs or
            self.varkwargs != other.varkwargs or
            self.newlocals != other.newlocals or
            self.name != other.name or
            self.filename != other.filename or
            self.firstlineno != other.firstlineno or
            self.docstring != other.docstring or
            len(self.code) != len(other.code)
            ):
            return False

        # Compare code. This isn't trivial because labels should be matching,
        # not equal.
        labelmapping = {}
        for (op1, arg1), (op2, arg2) in itertools.izip(self.code, other.code):
            if isinstance(op1, Label):
                if labelmapping.setdefault(op1, op2) is not op2:
                    return False
            else:
                if op1 != op2:
                    return False
                if op1 in hasjump:
                    if labelmapping.setdefault(arg1, arg2) is not arg2:
                        return False
                elif op1 in hasarg:
                    if arg1 != arg2:
                        return False
        return True

    def _compute_flags(self):
        opcodes = set(op for op, arg in self.code if isopcode(op))

        optimized = (STORE_NAME not in opcodes and
                     LOAD_NAME not in opcodes and
                     DELETE_NAME not in opcodes)
        generator = (YIELD_VALUE in opcodes)
        nofree = not (opcodes.intersection(hasfree))

        flags = 0
        if optimized: flags |= CO_OPTIMIZED
        if self.newlocals: flags |= CO_NEWLOCALS
        if self.varargs: flags |= CO_VARARGS
        if self.varkwargs: flags |= CO_VARKEYWORDS
        if generator: flags |= CO_GENERATOR
        if nofree: flags |= CO_NOFREE
        return flags

    def _compute_stacksize(self):
        """Get a code list, compute its maximal stack usage."""
        # This is done by scanning the code, and computing for each opcode
        # the stack state at the opcode.
        code = self.code

        # A mapping from labels to their positions in the code list
        label_pos = dict((op, pos)
                         for pos, (op, arg) in enumerate(code)
                         if isinstance(op, Label))

        # sf_targets are the targets of SETUP_FINALLY opcodes. They are recorded
        # because they have special stack behaviour. If an exception was raised
        # in the block pushed by a SETUP_FINALLY opcode, the block is popped
        # and 3 objects are pushed. On return or continue, the block is popped
        # and 2 objects are pushed. If nothing happened, the block is popped by
        # a POP_BLOCK opcode and 1 object is pushed by a (LOAD_CONST, None)
        # operation.
        #
        # Our solution is to record the stack state of SETUP_FINALLY targets
        # as having 3 objects pushed, which is the maximum. However, to make
        # stack recording consistent, the get_next_stacks function will always
        # yield the stack state of the target as if 1 object was pushed, but
        # this will be corrected in the actual stack recording.

        sf_targets = set(label_pos[arg]
                         for op, arg in code
                         if op == SETUP_FINALLY)

        # What we compute - for each opcode, its stack state, as an n-tuple.
        # n is the number of blocks pushed. For each block, we record the number
        # of objects pushed.
        stacks = [None] * len(code)

        def get_next_stacks(pos, curstack):
            """Get a code position and the stack state before the operation
            was done, and yield pairs (pos, curstack) for the next positions
            to be explored - those are the positions to which you can get
            from the given (pos, curstack).

            If the given position was already explored, nothing will be yielded.
            """
            op, arg = code[pos]

            if isinstance(op, Label):
                # We should check if we already reached a node only if it is
                # a label.
                if pos in sf_targets:
                    curstack = curstack[:-1] + (curstack[-1] + 2,)
                if stacks[pos] is None:
                    stacks[pos] = curstack
                else:
                    if stacks[pos] != curstack:
                        raise ValueError, "Inconsistent code"
                    return

            def newstack(n):
                # Return a new stack, modified by adding n elements to the last
                # block
                if curstack[-1] + n < 0:
                    raise ValueError, "Popped a non-existing element"
                return curstack[:-1] + (curstack[-1]+n,)

            if not isopcode(op):
                # label or SetLineno - just continue to next line
                yield pos+1, curstack

            elif op in (STOP_CODE, RETURN_VALUE, RAISE_VARARGS):
                # No place in particular to continue to
                pass

            elif op == MAKE_CLOSURE and python_version == '2.4':
                # This is only relevant in Python 2.4 - in Python 2.5 the stack
                # effect of MAKE_CLOSURE can be calculated from the arg.
                # In Python 2.4, it depends on the number of freevars of TOS,
                # which should be a code object.
                if pos == 0:
                    raise ValueError, \
                          "MAKE_CLOSURE can't be the first opcode"
                lastop, lastarg = code[pos-1]
                if lastop != LOAD_CONST:
                    raise ValueError, \
                          "MAKE_CLOSURE should come after a LOAD_CONST op"
                try:
                    nextrapops = len(lastarg.freevars)
                except AttributeError:
                    try:
                        nextrapops = len(lastarg.co_freevars)
                    except AttributeError:
                        raise ValueError, \
                              "MAKE_CLOSURE preceding const should "\
                              "be a code or a Code object"

                yield pos+1, newstack(-arg-nextrapops)

            elif op not in hasflow:
                # Simple change of stack
                pop, push = getse(op, arg)
                yield pos+1, newstack(push - pop)

            elif op in (JUMP_FORWARD, JUMP_ABSOLUTE):
                # One possibility for a jump
                yield label_pos[arg], curstack

            elif python_version < '2.7' and op in (JUMP_IF_FALSE, JUMP_IF_TRUE):
                # Two possibilities for a jump
                yield label_pos[arg], curstack
                yield pos+1, curstack

            elif python_version >= '2.7' and op in (POP_JUMP_IF_FALSE, POP_JUMP_IF_TRUE):
                # Two possibilities for a jump
                yield label_pos[arg], newstack(-1)
                yield pos+1, newstack(-1)

            elif python_version >= '2.7' and op in (JUMP_IF_TRUE_OR_POP, JUMP_IF_FALSE_OR_POP):
                # Two possibilities for a jump
                yield label_pos[arg], curstack
                yield pos+1, newstack(-1)

            elif op == FOR_ITER:
                # FOR_ITER pushes next(TOS) on success, and pops TOS and jumps
                # on failure
                yield label_pos[arg], newstack(-1)
                yield pos+1, newstack(1)

            elif op == BREAK_LOOP:
                # BREAK_LOOP jumps to a place specified on block creation, so
                # it is ignored here
                pass

            elif op == CONTINUE_LOOP:
                # CONTINUE_LOOP jumps to the beginning of a loop which should
                # already ave been discovered, but we verify anyway.
                # It pops a block.
                if python_version == '2.6':
                  pos, stack = label_pos[arg], curstack[:-1]
                  if stacks[pos] != stack: #this could be a loop with a 'with' inside
                    yield pos, stack[:-1] + (stack[-1]-1,)
                  else:
                    yield pos, stack
                else:
                  yield label_pos[arg], curstack[:-1]

            elif op == SETUP_LOOP:
                # We continue with a new block.
                # On break, we jump to the label and return to current stack
                # state.
                yield label_pos[arg], curstack
                yield pos+1, curstack + (0,)

            elif op == SETUP_EXCEPT:
                # We continue with a new block.
                # On exception, we jump to the label with 3 extra objects on
                # stack
                yield label_pos[arg], newstack(3)
                yield pos+1, curstack + (0,)

            elif op == SETUP_FINALLY:
                # We continue with a new block.
                # On exception, we jump to the label with 3 extra objects on
                # stack, but to keep stack recording consistent, we behave as
                # if we add only 1 object. Extra 2 will be added to the actual
                # recording.
                yield label_pos[arg], newstack(1)
                yield pos+1, curstack + (0,)

            elif python_version == '2.7' and op == SETUP_WITH:
                yield label_pos[arg], curstack
                yield pos+1, newstack(-1) + (1,)

            elif op == POP_BLOCK:
                # Just pop the block
                yield pos+1, curstack[:-1]

            elif op == END_FINALLY:
                # Since stack recording of SETUP_FINALLY targets is of 3 pushed
                # objects (as when an exception is raised), we pop 3 objects.
                yield pos+1, newstack(-3)

            elif op == WITH_CLEANUP:
                # Since WITH_CLEANUP is always found after SETUP_FINALLY
                # targets, and the stack recording is that of a raised
                # exception, we can simply pop 1 object and let END_FINALLY
                # pop the remaining 3.
                if python_version == '2.7':
                  yield pos+1, newstack(2)
                else:
                  yield pos+1, newstack(-1)

            else:
                assert False, "Unhandled opcode: %r" % op


        # Now comes the calculation: open_positions holds positions which are
        # yet to be explored. In each step we take one open position, and
        # explore it by adding the positions to which you can get from it, to
        # open_positions. On the way, we update maxsize.
        # open_positions is a list of tuples: (pos, stack state)
        maxsize = 0
        open_positions = [(0, (0,))]
        while open_positions:
            pos, curstack = open_positions.pop()
            maxsize = max(maxsize, sum(curstack))
            open_positions.extend(get_next_stacks(pos, curstack))

        return maxsize

    def to_code(self):
        """Assemble a Python code object from a Code object."""
        co_argcount = len(self.args) - self.varargs - self.varkwargs
        co_stacksize = self._compute_stacksize()
        co_flags = self._compute_flags()

        co_consts = [self.docstring]
        co_names = []
        co_varnames = list(self.args)

        co_freevars = tuple(self.freevars)

        # We find all cellvars beforehand, for two reasons:
        # 1. We need the number of them to construct the numeric argument
        #    for ops in "hasfree".
        # 2. We need to put arguments which are cell vars in the beginning
        #    of co_cellvars
        cellvars = set(arg for op, arg in self.code
                       if isopcode(op) and op in hasfree
                       and arg not in co_freevars)
        co_cellvars = [x for x in self.args if x in cellvars]

        def index(seq, item, eq=operator.eq, can_append=True):
            """Find the index of item in a sequence and return it.
            If it is not found in the sequence, and can_append is True,
            it is appended to the sequence.

            eq is the equality operator to use.
            """
            for i, x in enumerate(seq):
                if eq(x, item):
                    return i
            else:
                if can_append:
                    seq.append(item)
                    return len(seq) - 1
                else:
                    raise IndexError, "Item not found"

        # List of tuples (pos, label) to be filled later
        jumps = []
        # A mapping from a label to its position
        label_pos = {}
        # Last SetLineno
        lastlineno = self.firstlineno
        lastlinepos = 0

        co_code = array('B')
        co_lnotab = array('B')
        for i, (op, arg) in enumerate(self.code):
            if isinstance(op, Label):
                label_pos[op] = len(co_code)

            elif op is SetLineno:
                incr_lineno = arg - lastlineno
                incr_pos = len(co_code) - lastlinepos
                lastlineno = arg
                lastlinepos = len(co_code)

                if incr_lineno == 0 and incr_pos == 0:
                    co_lnotab.append(0)
                    co_lnotab.append(0)
                else:
                    while incr_pos > 255:
                        co_lnotab.append(255)
                        co_lnotab.append(0)
                        incr_pos -= 255
                    while incr_lineno > 255:
                        co_lnotab.append(incr_pos)
                        co_lnotab.append(255)
                        incr_pos = 0
                        incr_lineno -= 255
                    if incr_pos or incr_lineno:
                        co_lnotab.append(incr_pos)
                        co_lnotab.append(incr_lineno)

            elif op == opcode.EXTENDED_ARG:
                raise ValueError, "EXTENDED_ARG not supported in Code objects"

            elif not op in hasarg:
                co_code.append(op)

            else:
                if op in hasconst:
                    if isinstance(arg, Code) and i < len(self.code)-1 and \
                       self.code[i+1][0] in hascode:
                        arg = arg.to_code()
                    arg = index(co_consts, arg, operator.is_)
                elif op in hasname:
                    arg = index(co_names, arg)
                elif op in hasjump:
                    # arg will be filled later
                    jumps.append((len(co_code), arg))
                    arg = 0
                elif op in haslocal:
                    arg = index(co_varnames, arg)
                elif op in hascompare:
                    arg = index(cmp_op, arg, can_append=False)
                elif op in hasfree:
                    try:
                        arg = index(co_freevars, arg, can_append=False) \
                              + len(cellvars)
                    except IndexError:
                        arg = index(co_cellvars, arg)
                else:
                    # arg is ok
                    pass

                if arg > 0xFFFF:
                    co_code.append(opcode.EXTENDED_ARG)
                    co_code.append((arg >> 16) & 0xFF)
                    co_code.append((arg >> 24) & 0xFF)
                co_code.append(op)
                co_code.append(arg & 0xFF)
                co_code.append((arg >> 8) & 0xFF)

        for pos, label in jumps:
            jump = label_pos[label]
            if co_code[pos] in hasjrel:
                jump -= pos+3
            if jump > 0xFFFF:
                raise NotImplementedError, "Extended jumps not implemented"
            co_code[pos+1] = jump & 0xFF
            co_code[pos+2] = (jump >> 8) & 0xFF

        co_code = co_code.tostring()
        co_lnotab = co_lnotab.tostring()

        co_consts = tuple(co_consts)
        co_names = tuple(co_names)
        co_varnames = tuple(co_varnames)
        co_nlocals = len(co_varnames)
        co_cellvars = tuple(co_cellvars)

        return types.CodeType(co_argcount, co_nlocals, co_stacksize, co_flags,
                              co_code, co_consts, co_names, co_varnames,
                              self.filename, self.name, self.firstlineno, co_lnotab,
                              co_freevars, co_cellvars)


def printcodelist(codelist, to=sys.stdout):
    """Get a code list. Print it nicely."""

    labeldict = {}
    pendinglabels = []
    for i, (op, arg) in enumerate(codelist):
        if isinstance(op, Label):
            pendinglabels.append(op)
        elif op is SetLineno:
            pass
        else:
            while pendinglabels:
                labeldict[pendinglabels.pop()] = i

    lineno = None
    islabel = False
    for i, (op, arg) in enumerate(codelist):
        if op is SetLineno:
            lineno = arg
            print >> to
            continue

        if isinstance(op, Label):
            islabel = True
            continue

        if lineno is None:
            linenostr = ''
        else:
            linenostr = str(lineno)
            lineno = None

        if islabel:
            islabelstr = '>>'
            islabel = False
        else:
            islabelstr = ''

        if op in hasconst:
            argstr = repr(arg)
        elif op in hasjump:
            try:
                argstr = 'to ' + str(labeldict[arg])
            except KeyError:
                argstr = repr(arg)
        elif op in hasarg:
            argstr = str(arg)
        else:
            argstr = ''

        print >> to, '%3s     %2s %4d %-20s %s' % (
            linenostr,
            islabelstr,
            i,
            op,
            argstr)

def recompile(filename):
    """Create a .pyc by disassembling the file and assembling it again, printing
    a message that the reassembled file was loaded."""
    # Most of the code here based on the compile.py module.
    import os
    import imp
    import marshal
    import struct

    f = open(filename, 'U')
    try:
        timestamp = long(os.fstat(f.fileno()).st_mtime)
    except AttributeError:
        timestamp = long(os.stat(filename).st_mtime)
    codestring = f.read()
    f.close()
    if codestring and codestring[-1] != '\n':
        codestring = codestring + '\n'
    try:
        codeobject = compile(codestring, filename, 'exec')
    except SyntaxError:
        print >> sys.stderr, "Skipping %s - syntax error." % filename
        return
    cod = Code.from_code(codeobject)
    message = "reassembled %r imported.\n" % filename
    cod.code[:0] = [ # __import__('sys').stderr.write(message)
        (LOAD_GLOBAL, '__import__'),
        (LOAD_CONST, 'sys'),
        (CALL_FUNCTION, 1),
        (LOAD_ATTR, 'stderr'),
        (LOAD_ATTR, 'write'),
        (LOAD_CONST, message),
        (CALL_FUNCTION, 1),
        (POP_TOP, None),
        ]
    codeobject2 = cod.to_code()
    fc = open(filename+'c', 'wb')
    fc.write('\0\0\0\0')
    fc.write(struct.pack('<l', timestamp))
    marshal.dump(codeobject2, fc)
    fc.flush()
    fc.seek(0, 0)
    fc.write(imp.get_magic())
    fc.close()

def recompile_all(path):
    """recursively recompile all .py files in the directory"""
    import os
    if os.path.isdir(path):
        for root, dirs, files in os.walk(path):
            for name in files:
                if name.endswith('.py'):
                    filename = os.path.abspath(os.path.join(root, name))
                    print >> sys.stderr, filename
                    recompile(filename)
    else:
        filename = os.path.abspath(path)
        recompile(filename)

def main():
    import os
    if len(sys.argv) != 2 or not os.path.exists(sys.argv[1]):
        print """\
Usage: %s dir

Search recursively for *.py in the given directory, disassemble and assemble
them, adding a note when each file is imported.

Use it to test byteplay like this:
> byteplay.py Lib
> make test

Some FutureWarnings may be raised, but that's expected.

Tip: before doing this, check to see which tests fail even without reassembling
them...
""" % sys.argv[0]
        sys.exit(1)
    recompile_all(sys.argv[1])

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = close_variable
# Code taken from http://stackoverflow.com/questions/3908335/python-function-local-name-binding-from-an-outer-scope

# Opcode constants used for comparison and replacecment
LOAD_FAST = opcode.opmap['LOAD_FAST']
LOAD_GLOBAL = opcode.opmap['LOAD_GLOBAL']
STORE_FAST = opcode.opmap['STORE_FAST']

DEBUGGING = True

def append_arguments(code_obj, new_locals):
    co_varnames = code_obj.co_varnames   # Old locals
    co_names = code_obj.co_names      # Old globals
    co_argcount = code_obj.co_argcount     # Argument count
    co_code = code_obj.co_code         # The actual bytecode as a string

    # Make one pass over the bytecode to identify names that should be
    # left in code_obj.co_names.
    not_removed = set(opcode.hasname) - set([LOAD_GLOBAL])
    saved_names = set()
    for inst in instructions(co_code):
        if inst[0] in not_removed:
            saved_names.add(co_names[inst[1]])

    # Build co_names for the new code object. This should consist of 
    # globals that were only accessed via LOAD_GLOBAL
    names = tuple(name for name in co_names
                  if name not in set(new_locals) - saved_names)

    # Build a dictionary that maps the indices of the entries in co_names
    # to their entry in the new co_names
    name_translations = dict((co_names.index(name), i)
                             for i, name in enumerate(names))

    # Build co_varnames for the new code object. This should consist of
    # the entirety of co_varnames with new_locals spliced in after the
    # arguments
    new_locals_len = len(new_locals)
    varnames = (co_varnames[:co_argcount] + new_locals +
                co_varnames[co_argcount:])

    # Build the dictionary that maps indices of entries in the old co_varnames
    # to their indices in the new co_varnames
    range1, range2 = xrange(co_argcount), xrange(co_argcount, len(co_varnames))
    varname_translations = dict((i, i) for i in range1)
    varname_translations.update((i, i + new_locals_len) for i in range2)

    # Build the dictionary that maps indices of deleted entries of co_names
    # to their indices in the new co_varnames
    names_to_varnames = dict((co_names.index(name), varnames.index(name))
                             for name in new_locals)

    # Now we modify the actual bytecode
    modified = []
    for inst in instructions(code_obj.co_code):
        # If the instruction is a LOAD_GLOBAL, we have to check to see if
        # it's one of the globals that we are replacing. Either way,
        # update its arg using the appropriate dict.
        if inst[0] == LOAD_GLOBAL:
            print "LOAD_GLOBAL: {0}".format(inst[1])
            if inst[1] in names_to_varnames:
                print "replacing with {0}: ".format(names_to_varnames[inst[1]])
                inst[0] = LOAD_FAST
                inst[1] = names_to_varnames[inst[1]]
            elif inst[1] in name_translations:    
                inst[1] = name_translations[inst[1]]
            else:
                raise ValueError("a name was lost in translation")
        # If it accesses co_varnames or co_names then update its argument.
        elif inst[0] in opcode.haslocal:
            inst[1] = varname_translations[inst[1]]
        elif inst[0] in opcode.hasname:
            inst[1] = name_translations[inst[1]]
        modified.extend(write_instruction(inst))

    code = ''.join(modified)
    # Done modifying codestring - make the code object

    return types.CodeType(co_argcount + new_locals_len,
                          code_obj.co_nlocals + new_locals_len,
                          code_obj.co_stacksize,
                          code_obj.co_flags,
                          code,
                          code_obj.co_consts,
                          names,
                          varnames,
                          code_obj.co_filename,
                          code_obj.co_name,
                          code_obj.co_firstlineno,
                          code_obj.co_lnotab)

def instructions(code):
    code = map(ord, code)
    i, L = 0, len(code)
    extended_arg = 0
    while i < L:
        op = code[i]
        i+= 1
        if op < opcode.HAVE_ARGUMENT:
            yield [op, None]
            continue
        oparg = code[i] + (code[i+1] << 8) + extended_arg
        extended_arg = 0
        i += 2
        if op == opcode.EXTENDED_ARG:
            extended_arg = oparg << 16
            continue
        yield [op, oparg]
########NEW FILE########
__FILENAME__ = decorator
##########################     LICENCE     ###############################

# Copyright (c) 2005-2012, Michele Simionato
# All rights reserved.

# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are
# met:

#   Redistributions of source code must retain the above copyright 
#   notice, this list of conditions and the following disclaimer.
#   Redistributions in bytecode form must reproduce the above copyright
#   notice, this list of conditions and the following disclaimer in
#   the documentation and/or other materials provided with the
#   distribution. 

# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
# HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS
# OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR
# TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
# USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
# DAMAGE.

"""
Decorator module, see http://pypi.python.org/pypi/decorator
for the documentation.
"""

__version__ = '3.4.0'

__all__ = ["decorator", "FunctionMaker", "contextmanager"]

import sys, re, inspect
if sys.version >= '3':
    from inspect import getfullargspec
    def get_init(cls):
        return cls.__init__
else:
    class getfullargspec(object):
        "A quick and dirty replacement for getfullargspec for Python 2.X"
        def __init__(self, f):
            self.args, self.varargs, self.varkw, self.defaults = \
                inspect.getargspec(f)
            self.kwonlyargs = []
            self.kwonlydefaults = None
        def __iter__(self):
            yield self.args
            yield self.varargs
            yield self.varkw
            yield self.defaults
    def get_init(cls):
        return cls.__init__.im_func

DEF = re.compile('\s*def\s*([_\w][_\w\d]*)\s*\(')

# basic functionality
class FunctionMaker(object):
    """
    An object with the ability to create functions with a given signature.
    It has attributes name, doc, module, signature, defaults, dict and
    methods update and make.
    """
    def __init__(self, func=None, name=None, signature=None,
                 defaults=None, doc=None, module=None, funcdict=None):
        self.shortsignature = signature
        if func:
            # func can be a class or a callable, but not an instance method
            self.name = func.__name__
            if self.name == '<lambda>': # small hack for lambda functions
                self.name = '_lambda_' 
            self.doc = func.__doc__
            self.module = func.__module__
            if inspect.isfunction(func):
                argspec = getfullargspec(func)
                self.annotations = getattr(func, '__annotations__', {})
                for a in ('args', 'varargs', 'varkw', 'defaults', 'kwonlyargs',
                          'kwonlydefaults'):
                    setattr(self, a, getattr(argspec, a))
                for i, arg in enumerate(self.args):
                    setattr(self, 'arg%d' % i, arg)
                if sys.version < '3': # easy way
                    self.shortsignature = self.signature = \
                        inspect.formatargspec(
                        formatvalue=lambda val: "", *argspec)[1:-1]
                else: # Python 3 way
                    allargs = list(self.args)
                    allshortargs = list(self.args)
                    if self.varargs:
                        allargs.append('*' + self.varargs)
                        allshortargs.append('*' + self.varargs)
                    elif self.kwonlyargs:
                        allargs.append('*') # single star syntax
                    for a in self.kwonlyargs:
                        allargs.append('%s=None' % a)
                        allshortargs.append('%s=%s' % (a, a))
                    if self.varkw:
                        allargs.append('**' + self.varkw)
                        allshortargs.append('**' + self.varkw)
                    self.signature = ', '.join(allargs)
                    self.shortsignature = ', '.join(allshortargs)
                self.dict = func.__dict__.copy()
        # func=None happens when decorating a caller
        if name:
            self.name = name
        if signature is not None:
            self.signature = signature
        if defaults:
            self.defaults = defaults
        if doc:
            self.doc = doc
        if module:
            self.module = module
        if funcdict:
            self.dict = funcdict
        # check existence required attributes
        assert hasattr(self, 'name')
        if not hasattr(self, 'signature'):
            raise TypeError('You are decorating a non function: %s' % func)

    def update(self, func, **kw):
        "Update the signature of func with the data in self"
        func.__name__ = self.name
        func.__doc__ = getattr(self, 'doc', None)
        func.__dict__ = getattr(self, 'dict', {})
        func.func_defaults = getattr(self, 'defaults', ())
        func.__kwdefaults__ = getattr(self, 'kwonlydefaults', None)
        func.__annotations__ = getattr(self, 'annotations', None)
        callermodule = sys._getframe(3).f_globals.get('__name__', '?')
        func.__module__ = getattr(self, 'module', callermodule)
        func.__dict__.update(kw)

    def make(self, src_templ, evaldict=None, addsource=False, **attrs):
        "Make a new function from a given template and update the signature"
        src = src_templ % vars(self) # expand name and signature
        evaldict = evaldict or {}
        mo = DEF.match(src)
        if mo is None:
            raise SyntaxError('not a valid function template\n%s' % src)
        name = mo.group(1) # extract the function name
        names = set([name] + [arg.strip(' *') for arg in 
                             self.shortsignature.split(',')])
        for n in names:
            if n in ('_func_', '_call_'):
                raise NameError('%s is overridden in\n%s' % (n, src))
        if not src.endswith('\n'): # add a newline just for safety
            src += '\n' # this is needed in old versions of Python
        try:
            code = compile(src, '<string>', 'single')
            # print >> sys.stderr, 'Compiling %s' % src
            exec code in evaldict
        except:
            print >> sys.stderr, 'Error in generated code:'
            print >> sys.stderr, src
            raise
        func = evaldict[name]
        if addsource:
            attrs['__source__'] = src
        self.update(func, **attrs)
        return func

    @classmethod
    def create(cls, obj, body, evaldict, defaults=None,
               doc=None, module=None, addsource=True, **attrs):
        """
        Create a function from the strings name, signature and body.
        evaldict is the evaluation dictionary. If addsource is true an attribute
        __source__ is added to the result. The attributes attrs are added,
        if any.
        """
        if isinstance(obj, str): # "name(signature)"
            name, rest = obj.strip().split('(', 1)
            signature = rest[:-1] #strip a right parens            
            func = None
        else: # a function
            name = None
            signature = None
            func = obj
        self = cls(func, name, signature, defaults, doc, module)
        ibody = '\n'.join('    ' + line for line in body.splitlines())
        return self.make('def %(name)s(%(signature)s):\n' + ibody, 
                        evaldict, addsource, **attrs)
  
def decorator(caller, func=None):
    """
    decorator(caller) converts a caller function into a decorator;
    decorator(caller, func) decorates a function using a caller.
    """
    if func is not None: # returns a decorated function
        evaldict = func.func_globals.copy()
        evaldict['_call_'] = caller
        evaldict['_func_'] = func
        return FunctionMaker.create(
            func, "return _call_(_func_, %(shortsignature)s)",
            evaldict, undecorated=func, __wrapped__=func)
    else: # returns a decorator
        if inspect.isclass(caller):
            name = caller.__name__.lower()
            callerfunc = get_init(caller)
            doc = 'decorator(%s) converts functions/generators into ' \
                'factories of %s objects' % (caller.__name__, caller.__name__)
            fun = getfullargspec(callerfunc).args[1] # second arg
        elif inspect.isfunction(caller):
            name = '_lambda_' if caller.__name__ == '<lambda>' \
                else caller.__name__
            callerfunc = caller
            doc = caller.__doc__
            fun = getfullargspec(callerfunc).args[0] # first arg
        else: # assume caller is an object with a __call__ method
            name = caller.__class__.__name__.lower()
            callerfunc = caller.__call__.im_func
            doc = caller.__call__.__doc__
            fun = getfullargspec(callerfunc).args[1] # second arg
        evaldict = callerfunc.func_globals.copy()
        evaldict['_call_'] = caller
        evaldict['decorator'] = decorator
        return FunctionMaker.create(
            '%s(%s)' % (name, fun), 
            'return decorator(_call_, %s)' % fun,
            evaldict, undecorated=caller, __wrapped__=caller,
            doc=doc, module=caller.__module__)

######################### contextmanager ########################

def __call__(self, func):
    'Context manager decorator'
    return FunctionMaker.create(
        func, "with _self_: return _func_(%(shortsignature)s)",
        dict(_self_=self, _func_=func), __wrapped__=func)

try: # Python >= 3.2

    from contextlib import _GeneratorContextManager 
    ContextManager = type(
        'ContextManager', (_GeneratorContextManager,), dict(__call__=__call__))

except ImportError: # Python >= 2.5

    from contextlib import GeneratorContextManager
    def __init__(self, f, *a, **k):
        return GeneratorContextManager.__init__(self, f(*a, **k))
    ContextManager = type(
        'ContextManager', (GeneratorContextManager,), 
        dict(__call__=__call__, __init__=__init__))
    
contextmanager = decorator(ContextManager)

########NEW FILE########
__FILENAME__ = pdg
#
# $Id: PDG.py,v 1.5 2009-01-26 03:05:43 ssnyder Exp $
# File: PDG.py
# Created: sss, Mar 2005
# Purpose: Define PDG ID codes.
#

# NOTE: This is external code.
# We don't do automatic Eclipse PyDev code analysis for it.
#@PydevCodeAnalysisIgnore
"""
This module contains names for the various PDG particle ID codes.
The names are the same as in EventKernel/PdtPdg.h.

This module also contains a dictionary pdgid_names mapping ID codes
back to printable strings, and a function pdgid_to_name to do this
conversion.  Similarly, root_names and pdgid_to_root_name translate to
strings with root markup.
"""
from __future__ import absolute_import

from ROOT import TDatabasePDG
from pkg_resources import resource_filename
import os

db = TDatabasePDG()
db.ReadPDGTable(resource_filename('rootpy', 'etc/pdg_table.txt'))


def GetParticle(id):
    return db.GetParticle(id)

# Table to translate from PDG IDs to printable strings.
pdgid_names = {}

# Table to translate from PDG IDs to strings with root markup.
root_names = {}


def id_to_name (id):
    """
    Convert a PDG ID to a printable string.
    """
    name = pdgid_names.get(id)
    if not name: name = `id`
    return name


def id_to_root_name (id):
    """
    Convert a PDG ID to a string with root markup.
    """
    name = root_names.get(id)
    if not name: name = `id`
    return name

#
# Table of PDG IDs, associating the ID codes with up to several names.
# This is formatted as one big string to make it easier to maintain
# (don't need to quote everything individually).
# The format of each line is like this:
#
#    mname = id     pname   rname
#
# An attribute mname will be added to this module with a value of id.
# These names are intended to match those in PdgPdt.h.
# pname is a printable name for the entry, and rname is a name
# with root-style markup.  These names will be put into the pdgid_names
# and root_names dictionaries, respectively.  They can be left as `!'
# if no name is available.  pname and rname should not contain spaces.
# Blank lines or those starting with `#' will be ignored.
#
_pdgtable = \
"""
d = 1                                 D            d
anti_d = -1                           DBAR         #bar{d}
u = 2                                 U            u
anti_u = -2                           UBAR         #bar{u}
s = 3                                 S            s
anti_s = -3                           SBAR         #bar{s}
c = 4                                 C            c
anti_c = -4                           CBAR         #bar{c}
b = 5                                 B            b
anti_b = -5                           BBAR         #bar{b}
t = 6                                 T            t
anti_t = -6                           TBAR         #bar{t}
l = 7                                 LPRIME       !
anti_l = -7                           LPRIMEBAR    !
h = 8                                 !            !
anti_h = -8                           !            !
g = 21                                GLUE         g
e_minus = 11                          E-           e^{-}
e_plus = -11                          E+           e^{+}
nu_e = 12                             NUE          #nu_{e}
anti_nu_e = -12                       ANUE         #bar{#nu}_{e}
mu_minus = 13                         MU-          #mu^{-}
mu_plus = -13                         MU+          #mu^{+}
nu_mu = 14                            NUM          #nu_{#mu}
anti_nu_mu = -14                      ANUM         #bar{#nu}_{#mu}
tau_minus = 15                        TAU-         #tau^{-}
tau_plus = -15                        TAU+         #tau^{+}
nu_tau = 16                           NUT          #nu_{#tau}
anti_nu_tau = -16                     ANUT         #bar{nu}_{#tau}
L_minus = 17                          !            !
L_plus = -17                          !            !
nu_L = 18                             !            !
anti_nu_L = -18                       !            !
gamma = 22                            PHOT         #gamma
Z0 = 23                               Z0           Z
W_plus = 24                           W+           W^{+}
W_minus = -24                         W-           W^{-}
Higgs0 = 25                           H0           h^{0}
reggeon = 28                          !            !
pomeron = 29                          !            !
Z_prime0 = 32                         !            !
Z_prime_prime0 = 33                   !            !
W_prime_plus = 34                     !            !
W_prime_minus = -34                   !            !
Higgs_prime0 = 35                     !            !
A0 = 36                               !            !
Higgs_plus = 37                       !            !
Higgs_minus = -37                     !            !
R0 = 40                               !            !
anti_R0 = -40                         !            !
specflav = 81                         !            !
rndmflav = 82                         !            !
anti_rndmflav = -82                   !            !
phasespa = 83                         !            !
c_minushadron = 84                    !            !
anti_c_minushadron = -84              !            !
b_minushadron = 85                    !            !
anti_b_minushadron = -85              !            !
t_minushadron = 86                    !            !
anti_t_minushadron = -86              !            !
Wvirt_plus = 89                       !            !
Wvirt_minus = -89                     !            !
diquark = 90                          !            !
anti_diquark = -90                    !            !
cluster = 91                          CLUSTER      cluster
string = 92                           !            !
indep = 93                            !            !
CMshower = 94                         !            !
SPHEaxis = 95                         !            !
THRUaxis = 96                         !            !
CLUSjet = 97                          !            !
CELLjet = 98                          !            !
table = 99                            !            !
pi0 = 111                             PI0          #pi^{0}
pi_plus = 211                         PI+          #pi^{+}
pi_minus = -211                       PI-          #pi^{-}
pi_diffr_plus = 210                   !            !
pi_diffr_minus = -210                 !            !
pi_2S0 = 20111                        !            !
pi_2S_plus = 20211                    !            !
pi_2S_minus = -20211                  !            !
eta = 221                             ETA          #eta
eta_2S = 20221                        !            !
eta_prime = 331                       !            !
rho0 = 113                            !            #rho^{0}
rho_plus = 213                        RHO+         #rho^{+}
rho_minus = -213                      RHO-         #rho^{-}
rho_2S0 = 30113                       !            !
rho_2S_plus = 30213                   !            !
rho_2S_minus = -30213                 !            !
rho_3S0 = 40113                       !            !
rho_3S_plus = 40213                   !            !
rho_3S_minus = -40213                 !            !
omega = 223                           !            !
omega_2S = 30223                      !            !
phi = 333                             PHI          #phi
a_00 = 10111                          !            !
a_0_plus = 10211                      !            !
a_0_minus = -10211                    !            !
f_0 = 10221                           !            !
f_prime_0 = 10331                     !            !
b_10 = 10113                          !            !
b_1_plus = 10213                      !            !
b_1_minus = -10213                    !            !
h_1 = 10223                           h_1          h_{1}
h_prime_1 = 10333                     !            !
a_10 = 20113                          !            !
a_1_plus = 20213                      !            !
a_1_minus = -20213                    !            !
f_1 = 20223                           !            !
f_prime_1 = 20333                     !            !
a_20 = 115                            !            !
a_2_plus = 215                        a_2+         a_{2}^{+}
a_2_minus = -215                      a_2-         a_{2}^{-}
f_2 = 225                             !            !
f_prime_2 = 335                       !            !
K0 = 311                              K0           K^{0}
anti_K0 = -311                        K0BAR        #bar{K}^0
K_S0 = 310                            K_S0         K_{S}^{0}
K_L0 = 130                            K_L0         K_{L}^{0}
K_plus = 321                          K+           K^{+}
K_minus = -321                        K-           K^{-}
K_star0 = 313                         K*           K^{*}
anti_K_star0 = -313                   K*BAR        #bar{K}^{*}
K_star_plus = 323                     !            !
K_star_minus = -323                   !            !
K_0_star0 = 10311                     !            !
anti_K_0_star0 = -10311               !            !
K_0_star_plus = 10321                 !            !
K_0_star_minus = -10321               !            !
K_10 = 10313                          !            !
anti_K_10 = -10313                    !            !
K_1_plus = 10323                      !            !
K_1_minus = -10323                    !            !
K_2_star0 = 315                       !            !
anti_K_2_star0 = -315                 !            !
K_2_star_plus = 325                   K_2*+        K_{2}^{*+}
K_2_star_minus = -325                 K_2*-        K_{2}^{*-}
K_prime_10 = 20313                    !            !
anti_K_prime_10 = -20313              !            !
K_prime_1_plus = 20323                !            !
K_prime_1_minus = -20323              !            !
D_plus = 411                          D+           D^{+}
D_minus = -411                        D-           D^{-}
D0 = 421                              D0           D^{0}
anti_D0 = -421                        D0BAR        #bar{D}^{0}
D_star_plus = 413                     !            !
D_star_minus = -413                   !            !
D_star0 = 423                         !            !
anti_D_star0 = -423                   !            !
D_0_star_plus = 10411                 !            !
D_0_star_minus = -10411               !            !
D_0_star0 = 10421                     !            !
anti_D_0_star0 = -10421               !            !
D_1_plus = 10413                      !            !
D_1_minus = -10413                    !            !
D_10 = 10423                          !            !
anti_D_10 = -10423                    !            !
D_2_star_plus = 415                   !            !
D_2_star_minus = -415                 !            !
D_2_star0 = 425                       !            !
anti_D_2_star0 = -425                 !            !
D_prime_1_plus = 20413                !            !
D_prime_1_minus = -20413              !            !
D_prime_10 = 20423                    !            !
anti_D_prime_10 = -20423              !            !
D_s_plus = 431                        D_S+         D_{s}^{+}
D_s_minus = -431                      D_S-         D_{s}^{-}
D_s_star_plus = 433                   !            !
D_s_star_minus = -433                 !            !
D_s0_star_plus = 10431                !            !
D_s0_star_minus = -10431              !            !
D_s1_plus = 10433                     !            !
D_s1_minus = -10433                   !            !
D_s2_star_plus = 435                  !            !
D_s2_star_minus = -435                !            !
D_prime_s1_plus = 20433               !            !
D_prime_s1_minus = -20433             !            !
B0 = 511                              B0           B^{0}
anti_B0 = -511                        B0BAR        #bar{B}^{0}
B_plus = 521                          B+           B^{+}
B_minus = -521                        B-           B^{-}
B_star0 = 513                         !            !
anti_B_star0 = -513                   !            !
B_star_plus = 523                     !            !
B_star_minus = -523                   !            !
B_0_star0 = 10511                     !            !
anti_B_0_star0 = -10511               !            !
B_0_star_plus = 10521                 !            !
B_0_star_minus = -10521               !            !
B_10 = 10513                          !            !
anti_B_10 = -10513                    !            !
B_1_plus = 10523                      !            !
B_1_minus = -10523                    !            !
B_2_star0 = 515                       !            !
anti_B_2_star0 = -515                 !            !
B_2_star_plus = 525                   !            !
B_2_star_minus = -525                 !            !
B_prime_10 = 20513                    !            !
anti_B_prime_10 = -20513              !            !
B_prime_1_plus = 20523                !            !
B_prime_1_minus = -20523              !            !
B_s0 = 531                            B_S0         B_{s}^{0}
anti_B_s0 = -531                      B_S0BAR      #bar{B}_{s}^{0}
B_s_star0 = 533                       !            !
anti_B_s_star0 = -533                 !            !
B_s0_star0 = 10531                    !            !
anti_B_s0_star0 = -10531              !            !
B_s10 = 10533                         !            !
anti_B_s10 = -10533                   !            !
B_s2_star0 = 535                      !            !
anti_B_s2_star0 = -535                !            !
B_prime_s10 = 20533                   !            !
anti_B_prime_s10 = -20533             !            !
B_c_plus = 541                        BC+          B_{c}^{+}
B_c_minus = -541                      BC-          B_{c}^{-}
B_c_star_plus = 543                   BC*+         B_{c}^{*+}
B_c_star_minus = -543                 BC*-         B_{c}^{*-}
B_c0_star_plus = 10541                !            !
B_c0_star_minus = -10541              !            !
B_c1_plus = 10543                     !            !
B_c1_minus = -10543                   !            !
B_c2_star_plus = 545                  !            !
B_c2_star_minus = -545                !            !
B_prime_c1_plus = 20543               !            !
B_prime_c1_minus = -20543             !            !
eta_c = 441                           !            !
eta_c_2S = 20441                      !            !
J_psi = 443                           JPSI         J/#psi
psi_2S = 20443                        !            !
chi_c0 = 10441                        !            !
chi_c1 = 10443                        !            !
chi_c2 = 445                          !            !
eta_b_2S = 20551                      !            !
eta_b_3S = 40551                      !            !
Upsilon = 553                         !            !
Upsilon_2S = 20553                    !            !
Upsilon_3S = 60553                    !            !
Upsilon_4S = 70553                    !            !
Upsilon_5S = 80553                    !            !
h_b = 10553                           !            !
h_b_2P = 40553                        !            !
h_b_3P = 100553                       !            !
chi_b0 = 551                          !            !
chi_b1 = 20553                        !            !
chi_b2 = 555                          !            !
chi_b0_2P = 30551                     !            !
chi_b1_2P = 50553                     !            !
chi_b2_2P = 10555                     !            !
chi_b0_3P = 50551                     !            !
chi_b1_3P = 110553                    !            !
chi_b2_3P = 20555                     !            !
eta_b2_1D = 40555                     !            !
eta_b2_2D = 60555                     !            !
Upsilon_1_1D = 120553                 !            !
Upsilon_2_1D = 30555                  !            !
Upsilon_3_1D = 557                    !            !
Upsilon_1_2D = 130553                 !            !
Upsilon_2_2D = 50555                  !            !
Upsilon_3_2D = 10557                  !            !
Delta_minus = 1114                    DELTA-       #Delta^{-}
anti_Delta_plus = -1114               DELTA+       #Delta^{+}
n_diffr = 2110                        !            !
anti_n_diffr = -2110                  !            !
n0 = 2112                             N            n
anti_n0 = -2112                       NBAR         #bar{n}
Delta0 = 2114                         !            !
anti_Delta0 = -2114                   !            !
p_diffr_plus = 2210                   !            !
anti_p_diffr_minus = -2210            !            !
p_plus = 2212                         P+           p^{+}
anti_p_minus = -2212                  P-           p^{-}
Delta_plus = 2214                     !            !
anti_Delta_minus = -2214              !            !
Delta_plus_plus = 2224                !            !
anti_Delta_minus_minus = -2224        !            !
Sigma_minus = 3112                    SIGMA-       #Sigma^{-}
anti_Sigma_plus = -3112               SIGMABAR+    #bar{#Sigma}^{+}
Sigma_star_minus = 3114               !            !
anti_Sigma_star_plus = -3114          !            !
Lambda0 = 3122                        LAMBDA_D0    #Lambda^{0}
anti_Lambda0 = -3122                  LAMBDABAR_D0 #bar{#Lambda}^{0}
Sigma0 = 3212                         !            !
anti_Sigma0 = -3212                   !            !
Sigma_star0 = 3214                    !            !
anti_Sigma_star0 = -3214              !            !
Sigma_plus = 3222                     SIGMA+       #Sigma^{+}
anti_Sigma_minus = -3222              SIGMABAR-    #bar{#Sigma}^{-}
Sigma_star_plus = 3224                !            !
anti_Sigma_star_minus = -3224         !            !
Xi_minus = 3312                       XI-          #Xi^{-}
anti_Xi_plus = -3312                  XI+          #Xi^{+}
Xi_star_minus = 3314                  !            !
anti_Xi_star_plus = -3314             !            !
Xi0 = 3322                            XI0          #Xi^{0}
anti_Xi0 = -3322                      XIBAR0       #bar{Xi}^{0}
Xi_star0 = 3324                       !            !
anti_Xi_star0 = -3324                 !            !
Omega_minus = 3334                    !            !
anti_Omega_plus = -3334               !            !
Sigma_c0 = 4112                       !            !
anti_Sigma_c0 = -4112                 !            !
Sigma_c_star0 = 4114                  SIGMA_C0*    #Sigma_{c}^{*0}
anti_Sigma_c_star0 = -4114            SIGMABAR_C0* #bar{#Sigma}_{c}^{*0}
Lambda_c_plus = 4122                  LAMBDA_C+    #Lambda_{c}^{+}
anti_Lambda_c_minus = -4122           LAMBDA_C-    #Lambda_{c}^{-}
Xi_c0 = 4132                          XI_C0        #Xi_{c}^{0}
anti_Xi_c0 = -4132                    XIBAR_C0     #bar{#Xi}_{c}^{0}
Sigma_c_plus = 4212                   SIGMA_C+     #Sigma_{c}^{+}
anti_Sigma_c_minus = -4212            SIGMA_C-     #Sigma_{c}^{-}
Sigma_c_star_plus = 4214              SIGMA_C+*    #Sigma_{c}^{*+}
anti_Sigma_c_star_minus = -4214       SIGMA_C-*    #Sigma_{c}^{*-}
Sigma_c_plus_plus = 4222              SIGMA_C++    #Sigma_{c}^{++}
anti_Sigma_c_minus_minus = -4222      SIGMA_C--    #Sigma_{c}^{--}
Sigma_c_star_plus_plus = 4224         SIGMA_C++*   #Sigma_{c}^{*++}
anti_Sigma_c_star_minus_minus = -4224 SIGMA_C--*   #Sigma_{c}^{*--}
Xi_c_plus = 4322                      XI_C+        #Xi_{c}^{+}
anti_Xi_c_minus = -4322               XI_C-        #Xi_{c}^{-}
Xi_prime_c0 = 4312                    XI'_C0       #Xi\'_{c}^{0}
Xi_primeanti__c0 = -4312              XIBAR'_C0    #bar{#Xi}\'_{c}^{0}
Xi_c_star0 = 4314                     XI_C0*       #Xi_{c}^{*0}
anti_Xi_c_star0 = -4314               XIBAR_C0*    #bar{#Xi}_{c}^{*0}
Xi_prime_c_plus = 4232                XI'_C+       #Xi\'_{c}^{+}
Xi_primeanti__c_minus = -4232         XIBAR'_C-    #Xi\'_{c}^{-}
Xi_c_star_plus = 4324                 XI_C+*       #Xi_{c}^{*+}
anti_Xi_c_star_minus = -4324          XI_C-*       #Xi_{c}^{*-}
Omega_c0 = 4332                       OMEGA_C0     #Omega_{c}^{0}
anti_Omega_c0 = -4332                 OMEGABAR_C0  #bar{#Omega}_{c}^{0}
Omega_c_star0 = 4334                  OMEGA_C0*    #Omega_{c}^{*0}
anti_Omega_c_star0 = -4334            OMEGA_C0*    #bar{#Omega}_{c}^{*0}
Sigma_b_minus = 5112                  SIGMA_B-     #Sigma_{b}^{-}'
anti_Sigma_b_plus = -5112             SIGMA_B+     #Sigma_{b}^{+}'
Sigma_b_star_minus = 5114             !            !
anti_Sigma_b_star_plus = -5114        !            !
Lambda_b0 = 5122                      LAMBDA_B0    #Lambda_{b}^{0}
anti_Lambda_b0 = -5122                LAMBDA_B0BAR #bar{#Lambda}_{b}^0
Xi_b_minus = 5132                     !            !
anti_Xi_b_plus = -5132                !            !
Sigma_b0 = 5212                       SIGMA_B0     #Sigma_{b}^{0}
anti_Sigma_b0 = -5212                 SIGMABAR_B0  #bar{#Sigma}_{b}^{0}
Sigma_b_star0 = 5214                  !            !
anti_Sigma_b_star0 = -5214            !            !
Sigma_b_plus = 5222                   !            !
anti_Sigma_b_minus = -5222            !            !
Sigma_star_ = 5224                    !            !
anti_Sigma_b_star_minus = -5224       !            !
Xi_b0 = 5232                          XI_B0        #Xi_b^{0}
anti_Xi_b0 = -5232                    XIBAR_B0     #bar{#Xi}_b^{0}
Xi_prime_b_minus = 5312               !            !
anti_Xi_prime_b_plus = -5312          !            !
Xi_b_star_minus = 5314                !            !
anti_Xi_b_star_plus = -5314           !            !
Xi_prime_b0 = 5322                    !            !
anti_Xi_prime_b0 = -5322              !            !
Xi_b_star0 = 5324                     !            !
anti_Xi_b_star0 = -5324               !            !
Omega_b_minus = 5332                  !            !
anti_Omega_b_plus = -5332             !            !
Omega_b_star_minus = 5334             !            !
anti_Omega_b_star_plus = -5334        !            !
dd_0 = 1101                           !            !
anti_dd_0 = -1101                     !            !
ud_0 = 2101                           UD0          !
anti_ud_0 = -2101                     UD0BAR       !
uu_0 = 2201                           !            !
anti_uu_0 = -2201                     !            !
sd_0 = 3101                           !            !
anti_sd_0 = -3101                     !            !
su_0 = 3201                           !            !
anti_su_0 = -3201                     !            !
ss_0 = 3301                           !            !
anti_ss_0 = -3301                     !            !
cd_0 = 4101                           !            !
anti_cd_0 = -4101                     !            !
cu_0 = 4201                           !            !
anti_cu_0 = -4201                     !            !
cs_0 = 4301                           !            !
anti_cs_0 = -4301                     !            !
cc_0 = 4401                           !            !
anti_cc_0 = -4401                     !            !
bd_0 = 5101                           !            !
anti_bd_0 = -5101                     !            !
bu_0 = 5201                           !            !
anti_bu_0 = -5201                     !            !
bs_0 = 5301                           !            !
anti_bs_0 = -5301                     !            !
bc_0 = 5401                           !            !
anti_bc_0 = -5401                     !            !
bb_0 = 5501                           !            !
anti_bb_0 = -5501                     !            !
dd_1 = 1103                           !            !
anti_dd_1 = -1103                     !            !
ud_1 = 2103                           !            !
anti_ud_1 = -2103                     !            !
uu_1 = 2203                           !            !
anti_uu_1 = -2203                     !            !
sd_1 = 3103                           !            !
anti_sd_1 = -3103                     !            !
su_1 = 3203                           !            !
anti_su_1 = -3203                     !            !
ss_1 = 3303                           !            !
anti_ss_1 = -3303                     !            !
cd_1 = 4103                           !            !
anti_cd_1 = -4103                     !            !
cu_1 = 4203                           !            !
anti_cu_1 = -4203                     !            !
cs_1 = 4303                           !            !
anti_cs_1 = -4303                     !            !
cc_1 = 4403                           !            !
anti_cc_1 = -4403                     !            !
bd_1 = 5103                           !            !
anti_bd_1 = -5103                     !            !
bu_1 = 5203                           !            !
anti_bu_1 = -5203                     !            !
bs_1 = 5303                           !            !
anti_bs_1 = -5303                     !            !
bc_1 = 5403                           !            !
anti_bc_1 = -5403                     !            !
bb_1 = 5503                           !            !
anti_bb_1 = -5503                     !            !

# SUSY Particles names modified from /Control/AthenaCommon/PDGTABLE.MeV
# naming convention change
#      '~' to 's_'
#      '(' to '_'
#      ')' to nothing
#      '+' to 'plus'
#      '' to '_'
#      for the negatively charged particles so I add "minus" to the name and a corresponding "plus" entry with -pdg code
#      for the neutrals I add a corresponding "anti" entry with -pdg code
#      for the particles with positive charge entries I add a corresponding "minus" entry with -pdg code
# ************ (the above is not consistent with the convention that minus=particle plus=anti-particle
#
#      Next remove Majorana particles and rename L-R stau to mass eigenstates.
#
#      This is all ugly but sort of consistent with previous naming convention

s_e_minus_L    =1000011               !            !
s_e_plus_L     =-1000011              !            !

s_nu_e_L       =1000012               !            !
s_anti_nu_e_L  =-1000012              !            !

s_mu_minus_L   =1000013               !            !
s_mu_plus_L    =-1000013              !            !

s_nu_mu_L      =1000014               !            !
s_anti_nu_mu_L =-1000014              !            !

#    s_tau_minus_L  =1000015
#    s_tau_plus_L   =-1000015

# L-R mixing significant use _1 and _2 for names instead
s_tau_minus_1  =1000015               !            !
s_tau_plus_1   =-1000015              !            !

s_nu_tau_L     =1000016               !            !
s_anti_nu_tau_L=-1000016              !            !

s_e_minus_R    =2000011               !            !
s_e_plus_R     =-2000011              !            !

s_mu_minus_R   =2000013               !            !
s_mu_plus_R    =-2000013              !            !

s_tau_minus_2  =2000015               !            !
s_tau_plus_2   =-2000015              !            !

s_g            =1000021               !            !
#    s_anti_g       =-1000021 # Majorana

s_chi_0_1      =1000022               !            !
#    s_anti_chi_0_1 =-1000022 # Majorana

s_chi_0_2      =1000023               !            !
#    s_anti_chi_0_2 =-1000023 # Majorana

s_chi_plus_1   =1000024               !            !
# Majorana
s_chi_minus_1  =-1000024              !            !

s_chi_0_3      =1000025               !            !
#    s_anti_chi_0_3 =-1000025 # Majorana

s_chi_0_4      =1000035               !            !
#    s_anti_chi_0_4 =-1000035 # Majorana

s_chi_plus_2   =1000037               !            !
s_chi_minus_2  =-1000037              !            !

s_G            =1000039               !            !
#    s_anti_G       =-1000039 # Majorana

# note mismatch with PDGTable and pre-existing PdtPdg.h
#M     999                          0.E+00         +0.0E+00 -0.0E+00 Geantino        0
#W     999                          0.E+00         +0.0E+00 -0.0E+00 Geantino        0

# doubly charged Higgs
Higgs_plus_plus_L = 9900041           !            !
Higgs_minus_minus_L = -9900041        !            !
Higgs_plus_plus_R = 9900042           !            !
Higgs_minus_minus_R = -9900042        !            !


# Null particles
deuteron = 0                          !            !
tritium = 0                           !            !
alpha = 0                             !            !
geantino = 0                          !            !
He3 = 0                               !            !
Cerenkov = 0                          !            !
null = 0                              !            !


# Some extra particles that weren't in PdgPdt.h
Xi_cc_plus = 4412                     XI_CC+       #Xi_{cc}^{+}
anti_Xi_cc_minus = -4412              XI_CC-       #Xi_{cc}^{-}
Xi_cc_plus_plus = 4422                XI_CC++      #Xi_{cc}^{++}
anti_Xi_cc_minus_minus = -4422        XI_CC--      #Xi_{cc}^{--}
Xi_cc_star_plus = 4414                XI_CC+*      #Xi_{cc}^{*+}
anti_Xi_cc_star_minus = -4414         XI_CC-*      #Xi_{cc}^{*-}
Xi_cc_star_plus_plus = 4424           XI_CC++*     #Xi_{cc}^{*++}
anti_Xi_cc_star_minus_minus = -4424   XI_CC--*     #Xi_{cc}^{*--}
Omega_cc_plus = 4432                  OMEGA_CC+    #Omega_{cc}^{+}
anti_Omega_cc_minus = -4432           OMEGA_CC-    #Omega_{cc}^{-}
Omega_cc_star_plus = 4434             OMEGA_CC+*   #Omega_{cc}^{*+}
anti_Omega_cc_star_minus = -4434      OMEGA_CC-*   #Omega_{cc}^{*-}
Omega_ccc_plus_plus = 4444            OMEGA_CCC++  #Omega_{ccc}^{++}
anti_Omega_ccc_minus_minus = -4444    OMEGA_CCC--  #Omega_{ccc}^{--}


# A couple extra synonyms that weren't in PdgPdt.h.
e = e_minus                           !            !
mu = mu_minus                         !            !
tau = tau_minus                       !            !
W = W_plus                            !            !
"""


# Parse _pdgtable and fill in dictionaries.
def _fill_dicts():
    import string
    pdgid_names.clear()
    root_names.clear()
    for line in _pdgtable.split ('\n'):
        line = line.strip()
        if len(line) == 0 or line[0] == '#': continue
        ll = line.split('=', 1)
        if len(ll) < 2:
            print 'bad line', line
            continue
        mname = string.strip(ll[0])
        ll = ll[1].split()
        if len(ll) < 1:
            print 'bad line', line
            continue
        id = ll[0]
        pname = None
        if len(ll) >= 2 and ll[1] != '!':
            pname = ll[1]
        rname = None
        if len(ll) >= 3 and ll[2] != '!':
            rname = ll[2]
        try:
            id = int(id)
        except ValueError:
            id = globals().get(id)
            if id == None:
                print 'bad line', line
                continue

        if pname == None:
            pname = mname
        if rname == None:
            rname = pname

        globals()[mname] = id
        if not pdgid_names.has_key(id):
            pdgid_names[id] = pname
        if not root_names.has_key(id):
            root_names[id] = rname
    return

# Fill the dictionaries.
_fill_dicts()

# Kill these now to save memory.
del _pdgtable
del _fill_dicts

########NEW FILE########
__FILENAME__ = linklockfile
from __future__ import absolute_import

import time
import os

from . import (LockBase, LockFailed, NotLocked, NotMyLock, LockTimeout,
               AlreadyLocked)

class LinkLockFile(LockBase):
    """Lock access to a file using atomic property of link(2).

    >>> lock = LinkLockFile('somefile')
    >>> lock = LinkLockFile('somefile', threaded=False)
    """

    def acquire(self, timeout=None):
        try:
            open(self.unique_name, "wb").close()
        except IOError:
            raise LockFailed("failed to create %s" % self.unique_name)

        end_time = time.time()
        if timeout is not None and timeout > 0:
            end_time += timeout

        while True:
            # Try and create a hard link to it.
            try:
                os.link(self.unique_name, self.lock_file)
            except OSError:
                # Link creation failed.  Maybe we've double-locked?
                nlinks = os.stat(self.unique_name).st_nlink
                if nlinks == 2:
                    # The original link plus the one I created == 2.  We're
                    # good to go.
                    return
                else:
                    # Otherwise the lock creation failed.
                    if timeout is not None and time.time() > end_time:
                        os.unlink(self.unique_name)
                        if timeout > 0:
                            raise LockTimeout
                        else:
                            raise AlreadyLocked
                    time.sleep(timeout is not None and timeout/10 or 0.1)
            else:
                # Link creation succeeded.  We're good to go.
                return

    def release(self):
        if not self.is_locked():
            raise NotLocked
        elif not os.path.exists(self.unique_name):
            raise NotMyLock
        os.unlink(self.unique_name)
        os.unlink(self.lock_file)

    def is_locked(self):
        return os.path.exists(self.lock_file)

    def i_am_locking(self):
        return (self.is_locked() and
                os.path.exists(self.unique_name) and
                os.stat(self.unique_name).st_nlink == 2)

    def break_lock(self):
        if os.path.exists(self.lock_file):
            os.unlink(self.lock_file)


########NEW FILE########
__FILENAME__ = mkdirlockfile
from __future__ import absolute_import, division

import time
import os
import sys
import errno

from . import (LockBase, LockFailed, NotLocked, NotMyLock, LockTimeout,
               AlreadyLocked)

class MkdirLockFile(LockBase):
    """Lock file by creating a directory."""
    def __init__(self, path, threaded=True):
        """
        >>> lock = MkdirLockFile('somefile')
        >>> lock = MkdirLockFile('somefile', threaded=False)
        """
        LockBase.__init__(self, path, threaded)
        # Lock file itself is a directory.  Place the unique file name into
        # it.
        self.unique_name  = os.path.join(self.lock_file,
                                         "%s.%s%s" % (self.hostname,
                                                      self.tname,
                                                      self.pid))

    def acquire(self, timeout=None):
        end_time = time.time()
        if timeout is not None and timeout > 0:
            end_time += timeout

        if timeout is None:
            wait = 0.1
        else:
            wait = max(0, timeout / 10)

        while True:
            try:
                os.mkdir(self.lock_file)
            except OSError:
                err = sys.exc_info()[1]
                if err.errno == errno.EEXIST:
                    # Already locked.
                    if os.path.exists(self.unique_name):
                        # Already locked by me.
                        return
                    if timeout is not None and time.time() > end_time:
                        if timeout > 0:
                            raise LockTimeout
                        else:
                            # Someone else has the lock.
                            raise AlreadyLocked
                    time.sleep(wait)
                else:
                    # Couldn't create the lock for some other reason
                    raise LockFailed("failed to create %s" % self.lock_file)
            else:
                open(self.unique_name, "wb").close()
                return

    def release(self):
        if not self.is_locked():
            raise NotLocked
        elif not os.path.exists(self.unique_name):
            raise NotMyLock
        os.unlink(self.unique_name)
        os.rmdir(self.lock_file)

    def is_locked(self):
        return os.path.exists(self.lock_file)

    def i_am_locking(self):
        return (self.is_locked() and
                os.path.exists(self.unique_name))

    def break_lock(self):
        if os.path.exists(self.lock_file):
            for name in os.listdir(self.lock_file):
                os.unlink(os.path.join(self.lock_file, name))
            os.rmdir(self.lock_file)

########NEW FILE########
__FILENAME__ = pidlockfile
# -*- coding: utf-8 -*-

# pidlockfile.py
#
# Copyright © 2008–2009 Ben Finney <ben+python@benfinney.id.au>
#
# This is free software: you may copy, modify, and/or distribute this work
# under the terms of the Python Software Foundation License, version 2 or
# later as published by the Python Software Foundation.
# No warranty expressed or implied. See the file LICENSE.PSF-2 for details.

""" Lockfile behaviour implemented via Unix PID files.
    """

from __future__ import absolute_import

import os
import sys
import errno
import time

from . import (LockBase, AlreadyLocked, LockFailed, NotLocked, NotMyLock,
               LockTimeout)


class PIDLockFile(LockBase):
    """ Lockfile implemented as a Unix PID file.

    The lock file is a normal file named by the attribute `path`.
    A lock's PID file contains a single line of text, containing
    the process ID (PID) of the process that acquired the lock.

    >>> lock = PIDLockFile('somefile')
    >>> lock = PIDLockFile('somefile')
    """

    def __init__(self, path, threaded=False):
        # pid lockfiles don't support threaded operation, so always force
        # False as the threaded arg.
        LockBase.__init__(self, path, False)
        dirname = os.path.dirname(self.lock_file)
        basename = os.path.split(self.path)[-1]
        self.unique_name = self.path

    def read_pid(self):
        """ Get the PID from the lock file.
            """
        return read_pid_from_pidfile(self.path)

    def is_locked(self):
        """ Test if the lock is currently held.

            The lock is held if the PID file for this lock exists.

            """
        return os.path.exists(self.path)

    def i_am_locking(self):
        """ Test if the lock is held by the current process.

        Returns ``True`` if the current process ID matches the
        number stored in the PID file.
        """
        return self.is_locked() and os.getpid() == self.read_pid()

    def acquire(self, timeout=None):
        """ Acquire the lock.

        Creates the PID file for this lock, or raises an error if
        the lock could not be acquired.
        """

        end_time = time.time()
        if timeout is not None and timeout > 0:
            end_time += timeout

        while True:
            try:
                write_pid_to_pidfile(self.path)
            except OSError, exc:
                if exc.errno == errno.EEXIST:
                    # The lock creation failed.  Maybe sleep a bit.
                    if timeout is not None and time.time() > end_time:
                        if timeout > 0:
                            raise LockTimeout
                        else:
                            raise AlreadyLocked
                    time.sleep(timeout is not None and timeout/10 or 0.1)
                else:
                    raise LockFailed
            else:
                return

    def release(self):
        """ Release the lock.

            Removes the PID file to release the lock, or raises an
            error if the current process does not hold the lock.

            """
        if not self.is_locked():
            raise NotLocked
        if not self.i_am_locking():
            raise NotMyLock
        remove_existing_pidfile(self.path)

    def break_lock(self):
        """ Break an existing lock.

            Removes the PID file if it already exists, otherwise does
            nothing.

            """
        remove_existing_pidfile(self.path)

def read_pid_from_pidfile(pidfile_path):
    """ Read the PID recorded in the named PID file.

        Read and return the numeric PID recorded as text in the named
        PID file. If the PID file cannot be read, or if the content is
        not a valid PID, return ``None``.

        """
    pid = None
    try:
        pidfile = open(pidfile_path, 'r')
    except IOError:
        pass
    else:
        # According to the FHS 2.3 section on PID files in /var/run:
        # 
        #   The file must consist of the process identifier in
        #   ASCII-encoded decimal, followed by a newline character.
        # 
        #   Programs that read PID files should be somewhat flexible
        #   in what they accept; i.e., they should ignore extra
        #   whitespace, leading zeroes, absence of the trailing
        #   newline, or additional lines in the PID file.

        line = pidfile.readline().strip()
        try:
            pid = int(line)
        except ValueError:
            pass
        pidfile.close()

    return pid


def write_pid_to_pidfile(pidfile_path):
    """ Write the PID in the named PID file.

        Get the numeric process ID (“PID”) of the current process
        and write it to the named file as a line of text.

        """
    open_flags = (os.O_CREAT | os.O_EXCL | os.O_WRONLY)
    open_mode = 0644
    pidfile_fd = os.open(pidfile_path, open_flags, open_mode)
    pidfile = os.fdopen(pidfile_fd, 'w')

    # According to the FHS 2.3 section on PID files in /var/run:
    #
    #   The file must consist of the process identifier in
    #   ASCII-encoded decimal, followed by a newline character. For
    #   example, if crond was process number 25, /var/run/crond.pid
    #   would contain three characters: two, five, and newline.

    pid = os.getpid()
    line = "%(pid)d\n" % vars()
    pidfile.write(line)
    pidfile.close()


def remove_existing_pidfile(pidfile_path):
    """ Remove the named PID file if it exists.

        Removing a PID file that doesn't already exist puts us in the
        desired state, so we ignore the condition if the file does not
        exist.

        """
    try:
        os.remove(pidfile_path)
    except OSError, exc:
        if exc.errno == errno.ENOENT:
            pass
        else:
            raise

########NEW FILE########
__FILENAME__ = sqlitelockfile
from __future__ import absolute_import, division

import time
import os

from . import LockBase, NotLocked, NotMyLock, LockTimeout, AlreadyLocked

class SQLiteLockFile(LockBase):
    "Demonstrate SQL-based locking."

    testdb = None

    def __init__(self, path, threaded=True):
        """
        >>> lock = SQLiteLockFile('somefile')
        >>> lock = SQLiteLockFile('somefile', threaded=False)
        """
        LockBase.__init__(self, path, threaded)
        self.lock_file = unicode(self.lock_file)
        self.unique_name = unicode(self.unique_name)

        if SQLiteLockFile.testdb is None:
            import tempfile
            _fd, testdb = tempfile.mkstemp()
            os.close(_fd)
            os.unlink(testdb)
            del _fd, tempfile
            SQLiteLockFile.testdb = testdb

        import sqlite3
        self.connection = sqlite3.connect(SQLiteLockFile.testdb)
        
        c = self.connection.cursor()
        try:
            c.execute("create table locks"
                      "("
                      "   lock_file varchar(32),"
                      "   unique_name varchar(32)"
                      ")")
        except sqlite3.OperationalError:
            pass
        else:
            self.connection.commit()
            import atexit
            atexit.register(os.unlink, SQLiteLockFile.testdb)

    def acquire(self, timeout=None):
        end_time = time.time()
        if timeout is not None and timeout > 0:
            end_time += timeout

        if timeout is None:
            wait = 0.1
        elif timeout <= 0:
            wait = 0
        else:
            wait = timeout / 10

        cursor = self.connection.cursor()

        while True:
            if not self.is_locked():
                # Not locked.  Try to lock it.
                cursor.execute("insert into locks"
                               "  (lock_file, unique_name)"
                               "  values"
                               "  (?, ?)",
                               (self.lock_file, self.unique_name))
                self.connection.commit()

                # Check to see if we are the only lock holder.
                cursor.execute("select * from locks"
                               "  where unique_name = ?",
                               (self.unique_name,))
                rows = cursor.fetchall()
                if len(rows) > 1:
                    # Nope.  Someone else got there.  Remove our lock.
                    cursor.execute("delete from locks"
                                   "  where unique_name = ?",
                                   (self.unique_name,))
                    self.connection.commit()
                else:
                    # Yup.  We're done, so go home.
                    return
            else:
                # Check to see if we are the only lock holder.
                cursor.execute("select * from locks"
                               "  where unique_name = ?",
                               (self.unique_name,))
                rows = cursor.fetchall()
                if len(rows) == 1:
                    # We're the locker, so go home.
                    return
                    
            # Maybe we should wait a bit longer.
            if timeout is not None and time.time() > end_time:
                if timeout > 0:
                    # No more waiting.
                    raise LockTimeout
                else:
                    # Someone else has the lock and we are impatient..
                    raise AlreadyLocked

            # Well, okay.  We'll give it a bit longer.
            time.sleep(wait)

    def release(self):
        if not self.is_locked():
            raise NotLocked
        if not self.i_am_locking():
            raise NotMyLock((self._who_is_locking(), self.unique_name))
        cursor = self.connection.cursor()
        cursor.execute("delete from locks"
                       "  where unique_name = ?",
                       (self.unique_name,))
        self.connection.commit()

    def _who_is_locking(self):
        cursor = self.connection.cursor()
        cursor.execute("select unique_name from locks"
                       "  where lock_file = ?",
                       (self.lock_file,))
        return cursor.fetchone()[0]
        
    def is_locked(self):
        cursor = self.connection.cursor()
        cursor.execute("select * from locks"
                       "  where lock_file = ?",
                       (self.lock_file,))
        rows = cursor.fetchall()
        return not not rows

    def i_am_locking(self):
        cursor = self.connection.cursor()
        cursor.execute("select * from locks"
                       "  where lock_file = ?"
                       "    and unique_name = ?",
                       (self.lock_file, self.unique_name))
        return not not cursor.fetchall()

    def break_lock(self):
        cursor = self.connection.cursor()
        cursor.execute("delete from locks"
                       "  where lock_file = ?",
                       (self.lock_file,))
        self.connection.commit()

########NEW FILE########
__FILENAME__ = ordereddict
# Copyright (c) 2009 Raymond Hettinger
#
# Permission is hereby granted, free of charge, to any person
# obtaining a copy of this software and associated documentation files
# (the "Software"), to deal in the Software without restriction,
# including without limitation the rights to use, copy, modify, merge,
# publish, distribute, sublicense, and/or sell copies of the Software,
# and to permit persons to whom the Software is furnished to do so,
# subject to the following conditions:
#
#     The above copyright notice and this permission notice shall be
#     included in all copies or substantial portions of the Software.
#
#     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
#     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
#     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
#     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
#     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
#     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
#     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
#     OTHER DEALINGS IN THE SOFTWARE.

from UserDict import DictMixin

class OrderedDict(dict, DictMixin):

    def __init__(self, *args, **kwds):
        if len(args) > 1:
            raise TypeError('expected at most 1 arguments, got %d' % len(args))
        try:
            self.__end
        except AttributeError:
            self.clear()
        self.update(*args, **kwds)

    def clear(self):
        self.__end = end = []
        end += [None, end, end]         # sentinel node for doubly linked list
        self.__map = {}                 # key --> [key, prev, next]
        dict.clear(self)

    def __setitem__(self, key, value):
        if key not in self:
            end = self.__end
            curr = end[1]
            curr[2] = end[1] = self.__map[key] = [key, curr, end]
        dict.__setitem__(self, key, value)

    def __delitem__(self, key):
        dict.__delitem__(self, key)
        key, prev, next = self.__map.pop(key)
        prev[2] = next
        next[1] = prev

    def __iter__(self):
        end = self.__end
        curr = end[2]
        while curr is not end:
            yield curr[0]
            curr = curr[2]

    def __reversed__(self):
        end = self.__end
        curr = end[1]
        while curr is not end:
            yield curr[0]
            curr = curr[1]

    def popitem(self, last=True):
        if not self:
            raise KeyError('dictionary is empty')
        if last:
            key = reversed(self).next()
        else:
            key = iter(self).next()
        value = self.pop(key)
        return key, value

    def __reduce__(self):
        items = [[k, self[k]] for k in self]
        tmp = self.__map, self.__end
        del self.__map, self.__end
        inst_dict = vars(self).copy()
        self.__map, self.__end = tmp
        if inst_dict:
            return (self.__class__, (items,), inst_dict)
        return self.__class__, (items,)

    def keys(self):
        return list(self)

    setdefault = DictMixin.setdefault
    update = DictMixin.update
    pop = DictMixin.pop
    values = DictMixin.values
    items = DictMixin.items
    iterkeys = DictMixin.iterkeys
    itervalues = DictMixin.itervalues
    iteritems = DictMixin.iteritems

    def __repr__(self):
        if not self:
            return '%s()' % (self.__class__.__name__,)
        return '%s(%r)' % (self.__class__.__name__, self.items())

    def copy(self):
        return self.__class__(self)

    @classmethod
    def fromkeys(cls, iterable, value=None):
        d = cls()
        for key in iterable:
            d[key] = value
        return d

    def __eq__(self, other):
        if isinstance(other, OrderedDict):
            if len(self) != len(other):
                return False
            for p, q in  zip(self.items(), other.items()):
                if p != q:
                    return False
            return True
        return dict.__eq__(self, other)

    def __ne__(self, other):
        return not self == other

########NEW FILE########
__FILENAME__ = compat
#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# progressbar  - Text progress bar library for Python.
# Copyright (c) 2005 Nilton Volpato
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA

'''Compatability methods and classes for the progressbar module'''


# Python 3.x (and backports) use a modified iterator syntax
# This will allow 2.x to behave with 3.x iterators
if not hasattr(__builtins__, 'next'):
    def next(iter):
        try:
            # Try new style iterators
            return iter.__next__()
        except AttributeError:
            # Fallback in case of a "native" iterator
            return iter.next()


# Python < 2.5 does not have "any"
if not hasattr(__builtins__, 'any'):
   def any(iterator):
      for item in iterator:
         if item: return True

      return False

########NEW FILE########
__FILENAME__ = widgets
#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# progressbar  - Text progress bar library for Python.
# Copyright (c) 2005 Nilton Volpato
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA

'''Default ProgressBar widgets'''

from __future__ import division

import datetime
import math

try:
    from abc import ABCMeta, abstractmethod
except ImportError:
    AbstractWidget = object
    abstractmethod = lambda fn: fn
else:
    AbstractWidget = ABCMeta('AbstractWidget', (object,), {})


def format_updatable(updatable, pbar):
    if hasattr(updatable, 'update'): return updatable.update(pbar)
    else: return updatable


class Widget(AbstractWidget):
    '''The base class for all widgets

    The ProgressBar will call the widget's update value when the widget should
    be updated. The widget's size may change between calls, but the widget may
    display incorrectly if the size changes drastically and repeatedly.

    The boolean TIME_SENSITIVE informs the ProgressBar that it should be
    updated more often because it is time sensitive.
    '''

    TIME_SENSITIVE = False
    __slots__ = ()

    @abstractmethod
    def update(self, pbar):
        '''Updates the widget.

        pbar - a reference to the calling ProgressBar
        '''


class WidgetHFill(Widget):
    '''The base class for all variable width widgets.

    This widget is much like the \\hfill command in TeX, it will expand to
    fill the line. You can use more than one in the same line, and they will
    all have the same width, and together will fill the line.
    '''

    @abstractmethod
    def update(self, pbar, width):
        '''Updates the widget providing the total width the widget must fill.

        pbar - a reference to the calling ProgressBar
        width - The total width the widget must fill
        '''


class Timer(Widget):
    'Widget which displays the elapsed seconds.'

    __slots__ = ('format',)
    TIME_SENSITIVE = True

    def __init__(self, format='Elapsed Time: %s'):
        self.format = format

    @staticmethod
    def format_time(seconds):
        'Formats time as the string "HH:MM:SS".'

        return str(datetime.timedelta(seconds=int(seconds)))


    def update(self, pbar):
        'Updates the widget to show the elapsed time.'

        return self.format % self.format_time(pbar.seconds_elapsed)


class ETA(Timer):
    'Widget which attempts to estimate the time of arrival.'

    TIME_SENSITIVE = True

    def update(self, pbar):
        'Updates the widget to show the ETA or total time when finished.'

        if pbar.currval == 0:
            return 'ETA:  --:--:--'
        elif pbar.finished:
            return 'Time: %s' % self.format_time(pbar.seconds_elapsed)
        else:
            elapsed = pbar.seconds_elapsed
            eta = elapsed * pbar.maxval / pbar.currval - elapsed
            return 'ETA:  %s' % self.format_time(eta)


class FileTransferSpeed(Widget):
    'Widget for showing the transfer speed (useful for file transfers).'

    format = '%6.2f %s%s/s'
    prefixes = ' kMGTPEZY'
    __slots__ = ('unit', 'format')

    def __init__(self, unit='B'):
        self.unit = unit

    def update(self, pbar):
        'Updates the widget with the current SI prefixed speed.'

        if pbar.seconds_elapsed < 2e-6 or pbar.currval < 2e-6: # =~ 0
            scaled = power = 0
        else:
            speed = pbar.currval / pbar.seconds_elapsed
            power = int(math.log(speed, 1000))
            scaled = speed / 1000.**power

        return self.format % (scaled, self.prefixes[power], self.unit)


class AnimatedMarker(Widget):
    '''An animated marker for the progress bar which defaults to appear as if
    it were rotating.
    '''

    __slots__ = ('markers', 'curmark')

    def __init__(self, markers='|/-\\'):
        self.markers = markers
        self.curmark = -1

    def update(self, pbar):
        '''Updates the widget to show the next marker or the first marker when
        finished'''

        if pbar.finished: return self.markers[0]

        self.curmark = (self.curmark + 1) % len(self.markers)
        return self.markers[self.curmark]

# Alias for backwards compatibility
RotatingMarker = AnimatedMarker


class Counter(Widget):
    'Displays the current count'

    __slots__ = ('format',)

    def __init__(self, format='%d'):
        self.format = format

    def update(self, pbar):
        return self.format % pbar.currval


class Percentage(Widget):
    'Displays the current percentage as a number with a percent sign.'

    def update(self, pbar):
        return '%3d%%' % pbar.percentage()


class FormatLabel(Timer):
    'Displays a formatted label'

    mapping = {
        'elapsed': ('seconds_elapsed', Timer.format_time),
        'finished': ('finished', None),
        'last_update': ('last_update_time', None),
        'max': ('maxval', None),
        'seconds': ('seconds_elapsed', None),
        'start': ('start_time', None),
        'value': ('currval', None)
    }

    __slots__ = ('format',)
    def __init__(self, format):
        self.format = format

    def update(self, pbar):
        context = {}
        for name, (key, transform) in self.mapping.items():
            try:
                value = getattr(pbar, key)

                if transform is None:
                   context[name] = value
                else:
                   context[name] = transform(value)
            except: pass

        return self.format % context


class SimpleProgress(Widget):
    'Returns progress as a count of the total (e.g.: "5 of 47")'

    __slots__ = ('sep',)

    def __init__(self, sep=' of '):
        self.sep = sep

    def update(self, pbar):
        return '%d%s%d' % (pbar.currval, self.sep, pbar.maxval)


class Bar(WidgetHFill):
    'A progress bar which stretches to fill the line.'

    __slots__ = ('marker', 'left', 'right', 'fill', 'fill_left')

    def __init__(self, marker='#', left='|', right='|', fill=' ',
                 fill_left=True):
        '''Creates a customizable progress bar.

        marker - string or updatable object to use as a marker
        left - string or updatable object to use as a left border
        right - string or updatable object to use as a right border
        fill - character to use for the empty part of the progress bar
        fill_left - whether to fill from the left or the right
        '''
        self.marker = marker
        self.left = left
        self.right = right
        self.fill = fill
        self.fill_left = fill_left


    def update(self, pbar, width):
        'Updates the progress bar and its subcomponents'

        left, marker, right = (format_updatable(i, pbar) for i in
                               (self.left, self.marker, self.right))

        width -= len(left) + len(right)
        # Marker must *always* have length of 1
        marker *= int(pbar.currval / pbar.maxval * width)

        if self.fill_left:
            return '%s%s%s' % (left, marker.ljust(width, self.fill), right)
        else:
            return '%s%s%s' % (left, marker.rjust(width, self.fill), right)


class ReverseBar(Bar):
    'A bar which has a marker which bounces from side to side.'

    def __init__(self, marker='#', left='|', right='|', fill=' ',
                 fill_left=False):
        '''Creates a customizable progress bar.

        marker - string or updatable object to use as a marker
        left - string or updatable object to use as a left border
        right - string or updatable object to use as a right border
        fill - character to use for the empty part of the progress bar
        fill_left - whether to fill from the left or the right
        '''
        self.marker = marker
        self.left = left
        self.right = right
        self.fill = fill
        self.fill_left = fill_left


class BouncingBar(Bar):
    def update(self, pbar, width):
        'Updates the progress bar and its subcomponents'

        left, marker, right = (format_updatable(i, pbar) for i in
                               (self.left, self.marker, self.right))

        width -= len(left) + len(right)

        if pbar.finished: return '%s%s%s' % (left, width * marker, right)

        position = int(pbar.currval % (width * 2 - 1))
        if position > width: position = width * 2 - position
        lpad = self.fill * (position - 1)
        rpad = self.fill * (width - len(marker) - len(lpad))

        # Swap if we want to bounce the other way
        if not self.fill_left: rpad, lpad = lpad, rpad

        return '%s%s%s%s%s' % (left, lpad, marker, rpad, right)

########NEW FILE########
__FILENAME__ = pyparsing
# module pyparsing.py
#
# Copyright (c) 2003-2011  Paul T. McGuire
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
# CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
# TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
# SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#
#from __future__ import generators

__doc__ = \
"""
pyparsing module - Classes and methods to define and execute parsing grammars

The pyparsing module is an alternative approach to creating and executing simple grammars,
vs. the traditional lex/yacc approach, or the use of regular expressions.  With pyparsing, you
don't need to learn a new syntax for defining grammars or matching expressions - the parsing module
provides a library of classes that you use to construct the grammar directly in Python.

Here is a program to parse "Hello, World!" (or any greeting of the form C{"<salutation>, <addressee>!"})::

    from pyparsing import Word, alphas

    # define grammar of a greeting
    greet = Word( alphas ) + "," + Word( alphas ) + "!"

    hello = "Hello, World!"
    print hello, "->", greet.parseString( hello )

The program outputs the following::

    Hello, World! -> ['Hello', ',', 'World', '!']

The Python representation of the grammar is quite readable, owing to the self-explanatory
class names, and the use of '+', '|' and '^' operators.

The parsed results returned from C{parseString()} can be accessed as a nested list, a dictionary, or an
object with named attributes.

The pyparsing module handles some of the problems that are typically vexing when writing text parsers:
 - extra or missing whitespace (the above program will also handle "Hello,World!", "Hello  ,  World  !", etc.)
 - quoted strings
 - embedded comments
"""

__version__ = "1.5.7"
__versionTime__ = "17 November 2012 16:18"
__author__ = "Paul McGuire <ptmcg@users.sourceforge.net>"

import string
from weakref import ref as wkref
import copy
import sys
import warnings
import re
import sre_constants
#~ sys.stderr.write( "testing pyparsing module, version %s, %s\n" % (__version__,__versionTime__ ) )

__all__ = [
'And', 'CaselessKeyword', 'CaselessLiteral', 'CharsNotIn', 'Combine', 'Dict', 'Each', 'Empty',
'FollowedBy', 'Forward', 'GoToColumn', 'Group', 'Keyword', 'LineEnd', 'LineStart', 'Literal',
'MatchFirst', 'NoMatch', 'NotAny', 'OneOrMore', 'OnlyOnce', 'Optional', 'Or',
'ParseBaseException', 'ParseElementEnhance', 'ParseException', 'ParseExpression', 'ParseFatalException',
'ParseResults', 'ParseSyntaxException', 'ParserElement', 'QuotedString', 'RecursiveGrammarException',
'Regex', 'SkipTo', 'StringEnd', 'StringStart', 'Suppress', 'Token', 'TokenConverter', 'Upcase',
'White', 'Word', 'WordEnd', 'WordStart', 'ZeroOrMore',
'alphanums', 'alphas', 'alphas8bit', 'anyCloseTag', 'anyOpenTag', 'cStyleComment', 'col',
'commaSeparatedList', 'commonHTMLEntity', 'countedArray', 'cppStyleComment', 'dblQuotedString',
'dblSlashComment', 'delimitedList', 'dictOf', 'downcaseTokens', 'empty', 'hexnums',
'htmlComment', 'javaStyleComment', 'keepOriginalText', 'line', 'lineEnd', 'lineStart', 'lineno',
'makeHTMLTags', 'makeXMLTags', 'matchOnlyAtCol', 'matchPreviousExpr', 'matchPreviousLiteral',
'nestedExpr', 'nullDebugAction', 'nums', 'oneOf', 'opAssoc', 'operatorPrecedence', 'printables',
'punc8bit', 'pythonStyleComment', 'quotedString', 'removeQuotes', 'replaceHTMLEntity', 
'replaceWith', 'restOfLine', 'sglQuotedString', 'srange', 'stringEnd',
'stringStart', 'traceParseAction', 'unicodeString', 'upcaseTokens', 'withAttribute',
'indentedBlock', 'originalTextFor', 'ungroup', 'infixNotation',
]

_MAX_INT = sys.maxint
range = xrange
set = lambda s : dict( [(c,0) for c in s] )

def _ustr(obj):
    """Drop-in replacement for str(obj) that tries to be Unicode friendly. It first tries
       str(obj). If that fails with a UnicodeEncodeError, then it tries unicode(obj). It
       then < returns the unicode object | encodes it with the default encoding | ... >.
    """
    if isinstance(obj,unicode):
        return obj

    try:
        # If this works, then _ustr(obj) has the same behaviour as str(obj), so
        # it won't break any existing code.
        return str(obj)

    except UnicodeEncodeError:
        # The Python docs (http://docs.python.org/ref/customization.html#l2h-182)
        # state that "The return value must be a string object". However, does a
        # unicode object (being a subclass of basestring) count as a "string
        # object"?
        # If so, then return a unicode object:
        return unicode(obj)
        # Else encode it... but how? There are many choices... :)
        # Replace unprintables with escape codes?
        #return unicode(obj).encode(sys.getdefaultencoding(), 'backslashreplace_errors')
        # Replace unprintables with question marks?
        #return unicode(obj).encode(sys.getdefaultencoding(), 'replace')
        # ...

# build list of single arg builtins, tolerant of Python version, that can be used as parse actions
singleArgBuiltins = []
import __builtin__
for fname in "sum len sorted reversed list tuple set any all min max".split():
    try:
        singleArgBuiltins.append(getattr(__builtin__,fname))
    except AttributeError:
        continue

def _xml_escape(data):
    """Escape &, <, >, ", ', etc. in a string of data."""

    # ampersand must be replaced first
    from_symbols = '&><"\''
    to_symbols = ['&'+s+';' for s in "amp gt lt quot apos".split()]
    for from_,to_ in zip(from_symbols, to_symbols):
        data = data.replace(from_, to_)
    return data

class _Constants(object):
    pass

alphas     = string.ascii_lowercase + string.ascii_uppercase
nums       = "0123456789"
hexnums    = nums + "ABCDEFabcdef"
alphanums  = alphas + nums
_bslash    = chr(92)
printables = "".join( [ c for c in string.printable if c not in string.whitespace ] )

class ParseBaseException(Exception):
    """base exception class for all parsing runtime exceptions"""
    # Performance tuning: we construct a *lot* of these, so keep this
    # constructor as small and fast as possible
    def __init__( self, pstr, loc=0, msg=None, elem=None ):
        self.loc = loc
        if msg is None:
            self.msg = pstr
            self.pstr = ""
        else:
            self.msg = msg
            self.pstr = pstr
        self.parserElement = elem

    def __getattr__( self, aname ):
        """supported attributes by name are:
            - lineno - returns the line number of the exception text
            - col - returns the column number of the exception text
            - line - returns the line containing the exception text
        """
        if( aname == "lineno" ):
            return lineno( self.loc, self.pstr )
        elif( aname in ("col", "column") ):
            return col( self.loc, self.pstr )
        elif( aname == "line" ):
            return line( self.loc, self.pstr )
        else:
            raise AttributeError(aname)

    def __str__( self ):
        return "%s (at char %d), (line:%d, col:%d)" % \
                ( self.msg, self.loc, self.lineno, self.column )
    def __repr__( self ):
        return _ustr(self)
    def markInputline( self, markerString = ">!<" ):
        """Extracts the exception line from the input string, and marks
           the location of the exception with a special symbol.
        """
        line_str = self.line
        line_column = self.column - 1
        if markerString:
            line_str = "".join( [line_str[:line_column],
                                markerString, line_str[line_column:]])
        return line_str.strip()
    def __dir__(self):
        return "loc msg pstr parserElement lineno col line " \
               "markInputline __str__ __repr__".split()

class ParseException(ParseBaseException):
    """exception thrown when parse expressions don't match class;
       supported attributes by name are:
        - lineno - returns the line number of the exception text
        - col - returns the column number of the exception text
        - line - returns the line containing the exception text
    """
    pass

class ParseFatalException(ParseBaseException):
    """user-throwable exception thrown when inconsistent parse content
       is found; stops all parsing immediately"""
    pass

class ParseSyntaxException(ParseFatalException):
    """just like C{L{ParseFatalException}}, but thrown internally when an
       C{L{ErrorStop<And._ErrorStop>}} ('-' operator) indicates that parsing is to stop immediately because
       an unbacktrackable syntax error has been found"""
    def __init__(self, pe):
        super(ParseSyntaxException, self).__init__(
                                    pe.pstr, pe.loc, pe.msg, pe.parserElement)

#~ class ReparseException(ParseBaseException):
    #~ """Experimental class - parse actions can raise this exception to cause
       #~ pyparsing to reparse the input string:
        #~ - with a modified input string, and/or
        #~ - with a modified start location
       #~ Set the values of the ReparseException in the constructor, and raise the
       #~ exception in a parse action to cause pyparsing to use the new string/location.
       #~ Setting the values as None causes no change to be made.
       #~ """
    #~ def __init_( self, newstring, restartLoc ):
        #~ self.newParseText = newstring
        #~ self.reparseLoc = restartLoc

class RecursiveGrammarException(Exception):
    """exception thrown by C{validate()} if the grammar could be improperly recursive"""
    def __init__( self, parseElementList ):
        self.parseElementTrace = parseElementList

    def __str__( self ):
        return "RecursiveGrammarException: %s" % self.parseElementTrace

class _ParseResultsWithOffset(object):
    def __init__(self,p1,p2):
        self.tup = (p1,p2)
    def __getitem__(self,i):
        return self.tup[i]
    def __repr__(self):
        return repr(self.tup)
    def setOffset(self,i):
        self.tup = (self.tup[0],i)

class ParseResults(object):
    """Structured parse results, to provide multiple means of access to the parsed data:
       - as a list (C{len(results)})
       - by list index (C{results[0], results[1]}, etc.)
       - by attribute (C{results.<resultsName>})
       """
    #~ __slots__ = ( "__toklist", "__tokdict", "__doinit", "__name", "__parent", "__accumNames", "__weakref__" )
    def __new__(cls, toklist, name=None, asList=True, modal=True ):
        if isinstance(toklist, cls):
            return toklist
        retobj = object.__new__(cls)
        retobj.__doinit = True
        return retobj

    # Performance tuning: we construct a *lot* of these, so keep this
    # constructor as small and fast as possible
    def __init__( self, toklist, name=None, asList=True, modal=True, isinstance=isinstance ):
        if self.__doinit:
            self.__doinit = False
            self.__name = None
            self.__parent = None
            self.__accumNames = {}
            if isinstance(toklist, list):
                self.__toklist = toklist[:]
            else:
                self.__toklist = [toklist]
            self.__tokdict = dict()

        if name is not None and name:
            if not modal:
                self.__accumNames[name] = 0
            if isinstance(name,int):
                name = _ustr(name) # will always return a str, but use _ustr for consistency
            self.__name = name
            if not toklist in (None,'',[]):
                if isinstance(toklist,basestring):
                    toklist = [ toklist ]
                if asList:
                    if isinstance(toklist,ParseResults):
                        self[name] = _ParseResultsWithOffset(toklist.copy(),0)
                    else:
                        self[name] = _ParseResultsWithOffset(ParseResults(toklist[0]),0)
                    self[name].__name = name
                else:
                    try:
                        self[name] = toklist[0]
                    except (KeyError,TypeError,IndexError):
                        self[name] = toklist

    def __getitem__( self, i ):
        if isinstance( i, (int,slice) ):
            return self.__toklist[i]
        else:
            if i not in self.__accumNames:
                return self.__tokdict[i][-1][0]
            else:
                return ParseResults([ v[0] for v in self.__tokdict[i] ])

    def __setitem__( self, k, v, isinstance=isinstance ):
        if isinstance(v,_ParseResultsWithOffset):
            self.__tokdict[k] = self.__tokdict.get(k,list()) + [v]
            sub = v[0]
        elif isinstance(k,int):
            self.__toklist[k] = v
            sub = v
        else:
            self.__tokdict[k] = self.__tokdict.get(k,list()) + [_ParseResultsWithOffset(v,0)]
            sub = v
        if isinstance(sub,ParseResults):
            sub.__parent = wkref(self)

    def __delitem__( self, i ):
        if isinstance(i,(int,slice)):
            mylen = len( self.__toklist )
            del self.__toklist[i]

            # convert int to slice
            if isinstance(i, int):
                if i < 0:
                    i += mylen
                i = slice(i, i+1)
            # get removed indices
            removed = list(range(*i.indices(mylen)))
            removed.reverse()
            # fixup indices in token dictionary
            for name in self.__tokdict:
                occurrences = self.__tokdict[name]
                for j in removed:
                    for k, (value, position) in enumerate(occurrences):
                        occurrences[k] = _ParseResultsWithOffset(value, position - (position > j))
        else:
            del self.__tokdict[i]

    def __contains__( self, k ):
        return k in self.__tokdict

    def __len__( self ): return len( self.__toklist )
    def __bool__(self): return len( self.__toklist ) > 0
    __nonzero__ = __bool__
    def __iter__( self ): return iter( self.__toklist )
    def __reversed__( self ): return iter( self.__toklist[::-1] )
    def keys( self ):
        """Returns all named result keys."""
        return self.__tokdict.keys()

    def pop( self, index=-1 ):
        """Removes and returns item at specified index (default=last).
           Will work with either numeric indices or dict-key indicies."""
        ret = self[index]
        del self[index]
        return ret

    def get(self, key, defaultValue=None):
        """Returns named result matching the given key, or if there is no
           such name, then returns the given C{defaultValue} or C{None} if no
           C{defaultValue} is specified."""
        if key in self:
            return self[key]
        else:
            return defaultValue

    def insert( self, index, insStr ):
        """Inserts new element at location index in the list of parsed tokens."""
        self.__toklist.insert(index, insStr)
        # fixup indices in token dictionary
        for name in self.__tokdict:
            occurrences = self.__tokdict[name]
            for k, (value, position) in enumerate(occurrences):
                occurrences[k] = _ParseResultsWithOffset(value, position + (position > index))

    def items( self ):
        """Returns all named result keys and values as a list of tuples."""
        return [(k,self[k]) for k in self.__tokdict]

    def values( self ):
        """Returns all named result values."""
        return [ v[-1][0] for v in self.__tokdict.values() ]

    def __getattr__( self, name ):
        if True: #name not in self.__slots__:
            if name in self.__tokdict:
                if name not in self.__accumNames:
                    return self.__tokdict[name][-1][0]
                else:
                    return ParseResults([ v[0] for v in self.__tokdict[name] ])
            else:
                return ""
        return None

    def __add__( self, other ):
        ret = self.copy()
        ret += other
        return ret

    def __iadd__( self, other ):
        if other.__tokdict:
            offset = len(self.__toklist)
            addoffset = ( lambda a: (a<0 and offset) or (a+offset) )
            otheritems = other.__tokdict.items()
            otherdictitems = [(k, _ParseResultsWithOffset(v[0],addoffset(v[1])) )
                                for (k,vlist) in otheritems for v in vlist]
            for k,v in otherdictitems:
                self[k] = v
                if isinstance(v[0],ParseResults):
                    v[0].__parent = wkref(self)
            
        self.__toklist += other.__toklist
        self.__accumNames.update( other.__accumNames )
        return self

    def __radd__(self, other):
        if isinstance(other,int) and other == 0:
            return self.copy()
        
    def __repr__( self ):
        return "(%s, %s)" % ( repr( self.__toklist ), repr( self.__tokdict ) )

    def __str__( self ):
        out = []
        for i in self.__toklist:
            if isinstance(i, ParseResults):
                out.append(_ustr(i))
            else:
                out.append(repr(i))
        return '[' + ', '.join(out) + ']'

    def _asStringList( self, sep='' ):
        out = []
        for item in self.__toklist:
            if out and sep:
                out.append(sep)
            if isinstance( item, ParseResults ):
                out += item._asStringList()
            else:
                out.append( _ustr(item) )
        return out

    def asList( self ):
        """Returns the parse results as a nested list of matching tokens, all converted to strings."""
        out = []
        for res in self.__toklist:
            if isinstance(res,ParseResults):
                out.append( res.asList() )
            else:
                out.append( res )
        return out

    def asDict( self ):
        """Returns the named parse results as dictionary."""
        return dict( self.items() )

    def copy( self ):
        """Returns a new copy of a C{ParseResults} object."""
        ret = ParseResults( self.__toklist )
        ret.__tokdict = self.__tokdict.copy()
        ret.__parent = self.__parent
        ret.__accumNames.update( self.__accumNames )
        ret.__name = self.__name
        return ret

    def asXML( self, doctag=None, namedItemsOnly=False, indent="", formatted=True ):
        """Returns the parse results as XML. Tags are created for tokens and lists that have defined results names."""
        nl = "\n"
        out = []
        namedItems = dict( [ (v[1],k) for (k,vlist) in self.__tokdict.items()
                                                            for v in vlist ] )
        nextLevelIndent = indent + "  "

        # collapse out indents if formatting is not desired
        if not formatted:
            indent = ""
            nextLevelIndent = ""
            nl = ""

        selfTag = None
        if doctag is not None:
            selfTag = doctag
        else:
            if self.__name:
                selfTag = self.__name

        if not selfTag:
            if namedItemsOnly:
                return ""
            else:
                selfTag = "ITEM"

        out += [ nl, indent, "<", selfTag, ">" ]

        worklist = self.__toklist
        for i,res in enumerate(worklist):
            if isinstance(res,ParseResults):
                if i in namedItems:
                    out += [ res.asXML(namedItems[i],
                                        namedItemsOnly and doctag is None,
                                        nextLevelIndent,
                                        formatted)]
                else:
                    out += [ res.asXML(None,
                                        namedItemsOnly and doctag is None,
                                        nextLevelIndent,
                                        formatted)]
            else:
                # individual token, see if there is a name for it
                resTag = None
                if i in namedItems:
                    resTag = namedItems[i]
                if not resTag:
                    if namedItemsOnly:
                        continue
                    else:
                        resTag = "ITEM"
                xmlBodyText = _xml_escape(_ustr(res))
                out += [ nl, nextLevelIndent, "<", resTag, ">",
                                                xmlBodyText,
                                                "</", resTag, ">" ]

        out += [ nl, indent, "</", selfTag, ">" ]
        return "".join(out)

    def __lookup(self,sub):
        for k,vlist in self.__tokdict.items():
            for v,loc in vlist:
                if sub is v:
                    return k
        return None

    def getName(self):
        """Returns the results name for this token expression."""
        if self.__name:
            return self.__name
        elif self.__parent:
            par = self.__parent()
            if par:
                return par.__lookup(self)
            else:
                return None
        elif (len(self) == 1 and
               len(self.__tokdict) == 1 and
               self.__tokdict.values()[0][0][1] in (0,-1)):
            return self.__tokdict.keys()[0]
        else:
            return None

    def dump(self,indent='',depth=0):
        """Diagnostic method for listing out the contents of a C{ParseResults}.
           Accepts an optional C{indent} argument so that this string can be embedded
           in a nested display of other data."""
        out = []
        out.append( indent+_ustr(self.asList()) )
        keys = self.items()
        keys.sort()
        for k,v in keys:
            if out:
                out.append('\n')
            out.append( "%s%s- %s: " % (indent,('  '*depth), k) )
            if isinstance(v,ParseResults):
                if v.keys():
                    out.append( v.dump(indent,depth+1) )
                else:
                    out.append(_ustr(v))
            else:
                out.append(_ustr(v))
        return "".join(out)

    # add support for pickle protocol
    def __getstate__(self):
        return ( self.__toklist,
                 ( self.__tokdict.copy(),
                   self.__parent is not None and self.__parent() or None,
                   self.__accumNames,
                   self.__name ) )

    def __setstate__(self,state):
        self.__toklist = state[0]
        (self.__tokdict,
         par,
         inAccumNames,
         self.__name) = state[1]
        self.__accumNames = {}
        self.__accumNames.update(inAccumNames)
        if par is not None:
            self.__parent = wkref(par)
        else:
            self.__parent = None

    def __dir__(self):
        return dir(super(ParseResults,self)) + list(self.keys())

def col (loc,strg):
    """Returns current column within a string, counting newlines as line separators.
   The first column is number 1.

   Note: the default parsing behavior is to expand tabs in the input string
   before starting the parsing process.  See L{I{ParserElement.parseString}<ParserElement.parseString>} for more information
   on parsing strings containing C{<TAB>}s, and suggested methods to maintain a
   consistent view of the parsed string, the parse location, and line and column
   positions within the parsed string.
   """
    return (loc<len(strg) and strg[loc] == '\n') and 1 or loc - strg.rfind("\n", 0, loc)

def lineno(loc,strg):
    """Returns current line number within a string, counting newlines as line separators.
   The first line is number 1.

   Note: the default parsing behavior is to expand tabs in the input string
   before starting the parsing process.  See L{I{ParserElement.parseString}<ParserElement.parseString>} for more information
   on parsing strings containing C{<TAB>}s, and suggested methods to maintain a
   consistent view of the parsed string, the parse location, and line and column
   positions within the parsed string.
   """
    return strg.count("\n",0,loc) + 1

def line( loc, strg ):
    """Returns the line of text containing loc within a string, counting newlines as line separators.
       """
    lastCR = strg.rfind("\n", 0, loc)
    nextCR = strg.find("\n", loc)
    if nextCR >= 0:
        return strg[lastCR+1:nextCR]
    else:
        return strg[lastCR+1:]

def _defaultStartDebugAction( instring, loc, expr ):
    print ("Match " + _ustr(expr) + " at loc " + _ustr(loc) + "(%d,%d)" % ( lineno(loc,instring), col(loc,instring) ))

def _defaultSuccessDebugAction( instring, startloc, endloc, expr, toks ):
    print ("Matched " + _ustr(expr) + " -> " + str(toks.asList()))

def _defaultExceptionDebugAction( instring, loc, expr, exc ):
    print ("Exception raised:" + _ustr(exc))

def nullDebugAction(*args):
    """'Do-nothing' debug action, to suppress debugging output during parsing."""
    pass

'decorator to trim function calls to match the arity of the target'
def _trim_arity(func, maxargs=2):
    if func in singleArgBuiltins:
        return lambda s,l,t: func(t)
    limit = [0]
    foundArity = [False]
    def wrapper(*args):
        while 1:
            try:
                ret = func(*args[limit[0]:])
                foundArity[0] = True
                return ret
            except TypeError:
                if limit[0] <= maxargs and not foundArity[0]:
                    limit[0] += 1
                    continue
                raise
    return wrapper
    
class ParserElement(object):
    """Abstract base level parser element class."""
    DEFAULT_WHITE_CHARS = " \n\t\r"
    verbose_stacktrace = False

    def setDefaultWhitespaceChars( chars ):
        """Overrides the default whitespace chars
        """
        ParserElement.DEFAULT_WHITE_CHARS = chars
    setDefaultWhitespaceChars = staticmethod(setDefaultWhitespaceChars)

    def inlineLiteralsUsing(cls):
        """
        Set class to be used for inclusion of string literals into a parser.
        """
        ParserElement.literalStringClass = cls
    inlineLiteralsUsing = staticmethod(inlineLiteralsUsing)

    def __init__( self, savelist=False ):
        self.parseAction = list()
        self.failAction = None
        #~ self.name = "<unknown>"  # don't define self.name, let subclasses try/except upcall
        self.strRepr = None
        self.resultsName = None
        self.saveAsList = savelist
        self.skipWhitespace = True
        self.whiteChars = ParserElement.DEFAULT_WHITE_CHARS
        self.copyDefaultWhiteChars = True
        self.mayReturnEmpty = False # used when checking for left-recursion
        self.keepTabs = False
        self.ignoreExprs = list()
        self.debug = False
        self.streamlined = False
        self.mayIndexError = True # used to optimize exception handling for subclasses that don't advance parse index
        self.errmsg = ""
        self.modalResults = True # used to mark results names as modal (report only last) or cumulative (list all)
        self.debugActions = ( None, None, None ) #custom debug actions
        self.re = None
        self.callPreparse = True # used to avoid redundant calls to preParse
        self.callDuringTry = False

    def copy( self ):
        """Make a copy of this C{ParserElement}.  Useful for defining different parse actions
           for the same parsing pattern, using copies of the original parse element."""
        cpy = copy.copy( self )
        cpy.parseAction = self.parseAction[:]
        cpy.ignoreExprs = self.ignoreExprs[:]
        if self.copyDefaultWhiteChars:
            cpy.whiteChars = ParserElement.DEFAULT_WHITE_CHARS
        return cpy

    def setName( self, name ):
        """Define name for this expression, for use in debugging."""
        self.name = name
        self.errmsg = "Expected " + self.name
        if hasattr(self,"exception"):
            self.exception.msg = self.errmsg
        return self

    def setResultsName( self, name, listAllMatches=False ):
        """Define name for referencing matching tokens as a nested attribute
           of the returned parse results.
           NOTE: this returns a *copy* of the original C{ParserElement} object;
           this is so that the client can define a basic element, such as an
           integer, and reference it in multiple places with different names.
           
           You can also set results names using the abbreviated syntax,
           C{expr("name")} in place of C{expr.setResultsName("name")} - 
           see L{I{__call__}<__call__>}.
        """
        newself = self.copy()
        if name.endswith("*"):
            name = name[:-1]
            listAllMatches=True
        newself.resultsName = name
        newself.modalResults = not listAllMatches
        return newself

    def setBreak(self,breakFlag = True):
        """Method to invoke the Python pdb debugger when this element is
           about to be parsed. Set C{breakFlag} to True to enable, False to
           disable.
        """
        if breakFlag:
            _parseMethod = self._parse
            def breaker(instring, loc, doActions=True, callPreParse=True):
                import pdb
                pdb.set_trace()
                return _parseMethod( instring, loc, doActions, callPreParse )
            breaker._originalParseMethod = _parseMethod
            self._parse = breaker
        else:
            if hasattr(self._parse,"_originalParseMethod"):
                self._parse = self._parse._originalParseMethod
        return self

    def setParseAction( self, *fns, **kwargs ):
        """Define action to perform when successfully matching parse element definition.
           Parse action fn is a callable method with 0-3 arguments, called as C{fn(s,loc,toks)},
           C{fn(loc,toks)}, C{fn(toks)}, or just C{fn()}, where:
            - s   = the original string being parsed (see note below)
            - loc = the location of the matching substring
            - toks = a list of the matched tokens, packaged as a C{L{ParseResults}} object
           If the functions in fns modify the tokens, they can return them as the return
           value from fn, and the modified list of tokens will replace the original.
           Otherwise, fn does not need to return any value.

           Note: the default parsing behavior is to expand tabs in the input string
           before starting the parsing process.  See L{I{parseString}<parseString>} for more information
           on parsing strings containing C{<TAB>}s, and suggested methods to maintain a
           consistent view of the parsed string, the parse location, and line and column
           positions within the parsed string.
           """
        self.parseAction = list(map(_trim_arity, list(fns)))
        self.callDuringTry = ("callDuringTry" in kwargs and kwargs["callDuringTry"])
        return self

    def addParseAction( self, *fns, **kwargs ):
        """Add parse action to expression's list of parse actions. See L{I{setParseAction}<setParseAction>}."""
        self.parseAction += list(map(_trim_arity, list(fns)))
        self.callDuringTry = self.callDuringTry or ("callDuringTry" in kwargs and kwargs["callDuringTry"])
        return self

    def setFailAction( self, fn ):
        """Define action to perform if parsing fails at this expression.
           Fail acton fn is a callable function that takes the arguments
           C{fn(s,loc,expr,err)} where:
            - s = string being parsed
            - loc = location where expression match was attempted and failed
            - expr = the parse expression that failed
            - err = the exception thrown
           The function returns no value.  It may throw C{L{ParseFatalException}}
           if it is desired to stop parsing immediately."""
        self.failAction = fn
        return self

    def _skipIgnorables( self, instring, loc ):
        exprsFound = True
        while exprsFound:
            exprsFound = False
            for e in self.ignoreExprs:
                try:
                    while 1:
                        loc,dummy = e._parse( instring, loc )
                        exprsFound = True
                except ParseException:
                    pass
        return loc

    def preParse( self, instring, loc ):
        if self.ignoreExprs:
            loc = self._skipIgnorables( instring, loc )

        if self.skipWhitespace:
            wt = self.whiteChars
            instrlen = len(instring)
            while loc < instrlen and instring[loc] in wt:
                loc += 1

        return loc

    def parseImpl( self, instring, loc, doActions=True ):
        return loc, []

    def postParse( self, instring, loc, tokenlist ):
        return tokenlist

    #~ @profile
    def _parseNoCache( self, instring, loc, doActions=True, callPreParse=True ):
        debugging = ( self.debug ) #and doActions )

        if debugging or self.failAction:
            #~ print ("Match",self,"at loc",loc,"(%d,%d)" % ( lineno(loc,instring), col(loc,instring) ))
            if (self.debugActions[0] ):
                self.debugActions[0]( instring, loc, self )
            if callPreParse and self.callPreparse:
                preloc = self.preParse( instring, loc )
            else:
                preloc = loc
            tokensStart = preloc
            try:
                try:
                    loc,tokens = self.parseImpl( instring, preloc, doActions )
                except IndexError:
                    raise ParseException( instring, len(instring), self.errmsg, self )
            except ParseBaseException, err:
                #~ print ("Exception raised:", err)
                err = None
                if self.debugActions[2]:
                    self.debugActions[2]( instring, tokensStart, self, err )
                if self.failAction:
                    self.failAction( instring, tokensStart, self, err )
                raise
        else:
            if callPreParse and self.callPreparse:
                preloc = self.preParse( instring, loc )
            else:
                preloc = loc
            tokensStart = preloc
            if self.mayIndexError or loc >= len(instring):
                try:
                    loc,tokens = self.parseImpl( instring, preloc, doActions )
                except IndexError:
                    raise ParseException( instring, len(instring), self.errmsg, self )
            else:
                loc,tokens = self.parseImpl( instring, preloc, doActions )

        tokens = self.postParse( instring, loc, tokens )

        retTokens = ParseResults( tokens, self.resultsName, asList=self.saveAsList, modal=self.modalResults )
        if self.parseAction and (doActions or self.callDuringTry):
            if debugging:
                try:
                    for fn in self.parseAction:
                        tokens = fn( instring, tokensStart, retTokens )
                        if tokens is not None:
                            retTokens = ParseResults( tokens,
                                                      self.resultsName,
                                                      asList=self.saveAsList and isinstance(tokens,(ParseResults,list)),
                                                      modal=self.modalResults )
                except ParseBaseException, err:
                    #~ print "Exception raised in user parse action:", err
                    if (self.debugActions[2] ):
                        self.debugActions[2]( instring, tokensStart, self, err )
                    raise
            else:
                for fn in self.parseAction:
                    tokens = fn( instring, tokensStart, retTokens )
                    if tokens is not None:
                        retTokens = ParseResults( tokens,
                                                  self.resultsName,
                                                  asList=self.saveAsList and isinstance(tokens,(ParseResults,list)),
                                                  modal=self.modalResults )

        if debugging:
            #~ print ("Matched",self,"->",retTokens.asList())
            if (self.debugActions[1] ):
                self.debugActions[1]( instring, tokensStart, loc, self, retTokens )

        return loc, retTokens

    def tryParse( self, instring, loc ):
        try:
            return self._parse( instring, loc, doActions=False )[0]
        except ParseFatalException:
            raise ParseException( instring, loc, self.errmsg, self)

    # this method gets repeatedly called during backtracking with the same arguments -
    # we can cache these arguments and save ourselves the trouble of re-parsing the contained expression
    def _parseCache( self, instring, loc, doActions=True, callPreParse=True ):
        lookup = (self,instring,loc,callPreParse,doActions)
        if lookup in ParserElement._exprArgCache:
            value = ParserElement._exprArgCache[ lookup ]
            if isinstance(value, Exception):
                raise value
            return (value[0],value[1].copy())
        else:
            try:
                value = self._parseNoCache( instring, loc, doActions, callPreParse )
                ParserElement._exprArgCache[ lookup ] = (value[0],value[1].copy())
                return value
            except ParseBaseException, pe:
                ParserElement._exprArgCache[ lookup ] = pe
                raise

    _parse = _parseNoCache

    # argument cache for optimizing repeated calls when backtracking through recursive expressions
    _exprArgCache = {}
    def resetCache():
        ParserElement._exprArgCache.clear()
    resetCache = staticmethod(resetCache)

    _packratEnabled = False
    def enablePackrat():
        """Enables "packrat" parsing, which adds memoizing to the parsing logic.
           Repeated parse attempts at the same string location (which happens
           often in many complex grammars) can immediately return a cached value,
           instead of re-executing parsing/validating code.  Memoizing is done of
           both valid results and parsing exceptions.

           This speedup may break existing programs that use parse actions that
           have side-effects.  For this reason, packrat parsing is disabled when
           you first import pyparsing.  To activate the packrat feature, your
           program must call the class method C{ParserElement.enablePackrat()}.  If
           your program uses C{psyco} to "compile as you go", you must call
           C{enablePackrat} before calling C{psyco.full()}.  If you do not do this,
           Python will crash.  For best results, call C{enablePackrat()} immediately
           after importing pyparsing.
        """
        if not ParserElement._packratEnabled:
            ParserElement._packratEnabled = True
            ParserElement._parse = ParserElement._parseCache
    enablePackrat = staticmethod(enablePackrat)

    def parseString( self, instring, parseAll=False ):
        """Execute the parse expression with the given string.
           This is the main interface to the client code, once the complete
           expression has been built.

           If you want the grammar to require that the entire input string be
           successfully parsed, then set C{parseAll} to True (equivalent to ending
           the grammar with C{L{StringEnd()}}).

           Note: C{parseString} implicitly calls C{expandtabs()} on the input string,
           in order to report proper column numbers in parse actions.
           If the input string contains tabs and
           the grammar uses parse actions that use the C{loc} argument to index into the
           string being parsed, you can ensure you have a consistent view of the input
           string by:
            - calling C{parseWithTabs} on your grammar before calling C{parseString}
              (see L{I{parseWithTabs}<parseWithTabs>})
            - define your parse action using the full C{(s,loc,toks)} signature, and
              reference the input string using the parse action's C{s} argument
            - explictly expand the tabs in your input string before calling
              C{parseString}
        """
        ParserElement.resetCache()
        if not self.streamlined:
            self.streamline()
            #~ self.saveAsList = True
        for e in self.ignoreExprs:
            e.streamline()
        if not self.keepTabs:
            instring = instring.expandtabs()
        try:
            loc, tokens = self._parse( instring, 0 )
            if parseAll:
                loc = self.preParse( instring, loc )
                se = Empty() + StringEnd()
                se._parse( instring, loc )
        except ParseBaseException, exc:
            if ParserElement.verbose_stacktrace:
                raise
            else:
                # catch and re-raise exception from here, clears out pyparsing internal stack trace
                raise exc
        else:
            return tokens

    def scanString( self, instring, maxMatches=_MAX_INT, overlap=False ):
        """Scan the input string for expression matches.  Each match will return the
           matching tokens, start location, and end location.  May be called with optional
           C{maxMatches} argument, to clip scanning after 'n' matches are found.  If
           C{overlap} is specified, then overlapping matches will be reported.

           Note that the start and end locations are reported relative to the string
           being parsed.  See L{I{parseString}<parseString>} for more information on parsing
           strings with embedded tabs."""
        if not self.streamlined:
            self.streamline()
        for e in self.ignoreExprs:
            e.streamline()

        if not self.keepTabs:
            instring = _ustr(instring).expandtabs()
        instrlen = len(instring)
        loc = 0
        preparseFn = self.preParse
        parseFn = self._parse
        ParserElement.resetCache()
        matches = 0
        try:
            while loc <= instrlen and matches < maxMatches:
                try:
                    preloc = preparseFn( instring, loc )
                    nextLoc,tokens = parseFn( instring, preloc, callPreParse=False )
                except ParseException:
                    loc = preloc+1
                else:
                    if nextLoc > loc:
                        matches += 1
                        yield tokens, preloc, nextLoc
                        if overlap:
                            nextloc = preparseFn( instring, loc )
                            if nextloc > loc:
                                loc = nextLoc
                            else:
                                loc += 1
                        else:
                            loc = nextLoc
                    else:
                        loc = preloc+1
        except ParseBaseException, exc:
            if ParserElement.verbose_stacktrace:
                raise
            else:
                # catch and re-raise exception from here, clears out pyparsing internal stack trace
                raise exc

    def transformString( self, instring ):
        """Extension to C{L{scanString}}, to modify matching text with modified tokens that may
           be returned from a parse action.  To use C{transformString}, define a grammar and
           attach a parse action to it that modifies the returned token list.
           Invoking C{transformString()} on a target string will then scan for matches,
           and replace the matched text patterns according to the logic in the parse
           action.  C{transformString()} returns the resulting transformed string."""
        out = []
        lastE = 0
        # force preservation of <TAB>s, to minimize unwanted transformation of string, and to
        # keep string locs straight between transformString and scanString
        self.keepTabs = True
        try:
            for t,s,e in self.scanString( instring ):
                out.append( instring[lastE:s] )
                if t:
                    if isinstance(t,ParseResults):
                        out += t.asList()
                    elif isinstance(t,list):
                        out += t
                    else:
                        out.append(t)
                lastE = e
            out.append(instring[lastE:])
            out = [o for o in out if o]
            return "".join(map(_ustr,_flatten(out)))
        except ParseBaseException, exc:
            if ParserElement.verbose_stacktrace:
                raise
            else:
                # catch and re-raise exception from here, clears out pyparsing internal stack trace
                raise exc

    def searchString( self, instring, maxMatches=_MAX_INT ):
        """Another extension to C{L{scanString}}, simplifying the access to the tokens found
           to match the given parse expression.  May be called with optional
           C{maxMatches} argument, to clip searching after 'n' matches are found.
        """
        try:
            return ParseResults([ t for t,s,e in self.scanString( instring, maxMatches ) ])
        except ParseBaseException, exc:
            if ParserElement.verbose_stacktrace:
                raise
            else:
                # catch and re-raise exception from here, clears out pyparsing internal stack trace
                raise exc

    def __add__(self, other ):
        """Implementation of + operator - returns C{L{And}}"""
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        if not isinstance( other, ParserElement ):
            warnings.warn("Cannot combine element of type %s with ParserElement" % type(other),
                    SyntaxWarning, stacklevel=2)
            return None
        return And( [ self, other ] )

    def __radd__(self, other ):
        """Implementation of + operator when left operand is not a C{L{ParserElement}}"""
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        if not isinstance( other, ParserElement ):
            warnings.warn("Cannot combine element of type %s with ParserElement" % type(other),
                    SyntaxWarning, stacklevel=2)
            return None
        return other + self

    def __sub__(self, other):
        """Implementation of - operator, returns C{L{And}} with error stop"""
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        if not isinstance( other, ParserElement ):
            warnings.warn("Cannot combine element of type %s with ParserElement" % type(other),
                    SyntaxWarning, stacklevel=2)
            return None
        return And( [ self, And._ErrorStop(), other ] )

    def __rsub__(self, other ):
        """Implementation of - operator when left operand is not a C{L{ParserElement}}"""
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        if not isinstance( other, ParserElement ):
            warnings.warn("Cannot combine element of type %s with ParserElement" % type(other),
                    SyntaxWarning, stacklevel=2)
            return None
        return other - self

    def __mul__(self,other):
        """Implementation of * operator, allows use of C{expr * 3} in place of
           C{expr + expr + expr}.  Expressions may also me multiplied by a 2-integer
           tuple, similar to C{{min,max}} multipliers in regular expressions.  Tuples
           may also include C{None} as in:
            - C{expr*(n,None)} or C{expr*(n,)} is equivalent
              to C{expr*n + L{ZeroOrMore}(expr)}
              (read as "at least n instances of C{expr}")
            - C{expr*(None,n)} is equivalent to C{expr*(0,n)}
              (read as "0 to n instances of C{expr}")
            - C{expr*(None,None)} is equivalent to C{L{ZeroOrMore}(expr)}
            - C{expr*(1,None)} is equivalent to C{L{OneOrMore}(expr)}

           Note that C{expr*(None,n)} does not raise an exception if
           more than n exprs exist in the input stream; that is,
           C{expr*(None,n)} does not enforce a maximum number of expr
           occurrences.  If this behavior is desired, then write
           C{expr*(None,n) + ~expr}

        """
        if isinstance(other,int):
            minElements, optElements = other,0
        elif isinstance(other,tuple):
            other = (other + (None, None))[:2]
            if other[0] is None:
                other = (0, other[1])
            if isinstance(other[0],int) and other[1] is None:
                if other[0] == 0:
                    return ZeroOrMore(self)
                if other[0] == 1:
                    return OneOrMore(self)
                else:
                    return self*other[0] + ZeroOrMore(self)
            elif isinstance(other[0],int) and isinstance(other[1],int):
                minElements, optElements = other
                optElements -= minElements
            else:
                raise TypeError("cannot multiply 'ParserElement' and ('%s','%s') objects", type(other[0]),type(other[1]))
        else:
            raise TypeError("cannot multiply 'ParserElement' and '%s' objects", type(other))

        if minElements < 0:
            raise ValueError("cannot multiply ParserElement by negative value")
        if optElements < 0:
            raise ValueError("second tuple value must be greater or equal to first tuple value")
        if minElements == optElements == 0:
            raise ValueError("cannot multiply ParserElement by 0 or (0,0)")

        if (optElements):
            def makeOptionalList(n):
                if n>1:
                    return Optional(self + makeOptionalList(n-1))
                else:
                    return Optional(self)
            if minElements:
                if minElements == 1:
                    ret = self + makeOptionalList(optElements)
                else:
                    ret = And([self]*minElements) + makeOptionalList(optElements)
            else:
                ret = makeOptionalList(optElements)
        else:
            if minElements == 1:
                ret = self
            else:
                ret = And([self]*minElements)
        return ret

    def __rmul__(self, other):
        return self.__mul__(other)

    def __or__(self, other ):
        """Implementation of | operator - returns C{L{MatchFirst}}"""
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        if not isinstance( other, ParserElement ):
            warnings.warn("Cannot combine element of type %s with ParserElement" % type(other),
                    SyntaxWarning, stacklevel=2)
            return None
        return MatchFirst( [ self, other ] )

    def __ror__(self, other ):
        """Implementation of | operator when left operand is not a C{L{ParserElement}}"""
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        if not isinstance( other, ParserElement ):
            warnings.warn("Cannot combine element of type %s with ParserElement" % type(other),
                    SyntaxWarning, stacklevel=2)
            return None
        return other | self

    def __xor__(self, other ):
        """Implementation of ^ operator - returns C{L{Or}}"""
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        if not isinstance( other, ParserElement ):
            warnings.warn("Cannot combine element of type %s with ParserElement" % type(other),
                    SyntaxWarning, stacklevel=2)
            return None
        return Or( [ self, other ] )

    def __rxor__(self, other ):
        """Implementation of ^ operator when left operand is not a C{L{ParserElement}}"""
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        if not isinstance( other, ParserElement ):
            warnings.warn("Cannot combine element of type %s with ParserElement" % type(other),
                    SyntaxWarning, stacklevel=2)
            return None
        return other ^ self

    def __and__(self, other ):
        """Implementation of & operator - returns C{L{Each}}"""
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        if not isinstance( other, ParserElement ):
            warnings.warn("Cannot combine element of type %s with ParserElement" % type(other),
                    SyntaxWarning, stacklevel=2)
            return None
        return Each( [ self, other ] )

    def __rand__(self, other ):
        """Implementation of & operator when left operand is not a C{L{ParserElement}}"""
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        if not isinstance( other, ParserElement ):
            warnings.warn("Cannot combine element of type %s with ParserElement" % type(other),
                    SyntaxWarning, stacklevel=2)
            return None
        return other & self

    def __invert__( self ):
        """Implementation of ~ operator - returns C{L{NotAny}}"""
        return NotAny( self )

    def __call__(self, name):
        """Shortcut for C{L{setResultsName}}, with C{listAllMatches=default}::
             userdata = Word(alphas).setResultsName("name") + Word(nums+"-").setResultsName("socsecno")
           could be written as::
             userdata = Word(alphas)("name") + Word(nums+"-")("socsecno")
             
           If C{name} is given with a trailing C{'*'} character, then C{listAllMatches} will be
           passed as C{True}.
           """
        return self.setResultsName(name)

    def suppress( self ):
        """Suppresses the output of this C{ParserElement}; useful to keep punctuation from
           cluttering up returned output.
        """
        return Suppress( self )

    def leaveWhitespace( self ):
        """Disables the skipping of whitespace before matching the characters in the
           C{ParserElement}'s defined pattern.  This is normally only used internally by
           the pyparsing module, but may be needed in some whitespace-sensitive grammars.
        """
        self.skipWhitespace = False
        return self

    def setWhitespaceChars( self, chars ):
        """Overrides the default whitespace chars
        """
        self.skipWhitespace = True
        self.whiteChars = chars
        self.copyDefaultWhiteChars = False
        return self

    def parseWithTabs( self ):
        """Overrides default behavior to expand C{<TAB>}s to spaces before parsing the input string.
           Must be called before C{parseString} when the input grammar contains elements that
           match C{<TAB>} characters."""
        self.keepTabs = True
        return self

    def ignore( self, other ):
        """Define expression to be ignored (e.g., comments) while doing pattern
           matching; may be called repeatedly, to define multiple comment or other
           ignorable patterns.
        """
        if isinstance( other, Suppress ):
            if other not in self.ignoreExprs:
                self.ignoreExprs.append( other.copy() )
        else:
            self.ignoreExprs.append( Suppress( other.copy() ) )
        return self

    def setDebugActions( self, startAction, successAction, exceptionAction ):
        """Enable display of debugging messages while doing pattern matching."""
        self.debugActions = (startAction or _defaultStartDebugAction,
                             successAction or _defaultSuccessDebugAction,
                             exceptionAction or _defaultExceptionDebugAction)
        self.debug = True
        return self

    def setDebug( self, flag=True ):
        """Enable display of debugging messages while doing pattern matching.
           Set C{flag} to True to enable, False to disable."""
        if flag:
            self.setDebugActions( _defaultStartDebugAction, _defaultSuccessDebugAction, _defaultExceptionDebugAction )
        else:
            self.debug = False
        return self

    def __str__( self ):
        return self.name

    def __repr__( self ):
        return _ustr(self)

    def streamline( self ):
        self.streamlined = True
        self.strRepr = None
        return self

    def checkRecursion( self, parseElementList ):
        pass

    def validate( self, validateTrace=[] ):
        """Check defined expressions for valid structure, check for infinite recursive definitions."""
        self.checkRecursion( [] )

    def parseFile( self, file_or_filename, parseAll=False ):
        """Execute the parse expression on the given file or filename.
           If a filename is specified (instead of a file object),
           the entire file is opened, read, and closed before parsing.
        """
        try:
            file_contents = file_or_filename.read()
        except AttributeError:
            f = open(file_or_filename, "r")
            file_contents = f.read()
            f.close()
        try:
            return self.parseString(file_contents, parseAll)
        except ParseBaseException, exc:
            if ParserElement.verbose_stacktrace:
                raise
            else:
                # catch and re-raise exception from here, clears out pyparsing internal stack trace
                raise exc

    def getException(self):
        return ParseException("",0,self.errmsg,self)

    def __getattr__(self,aname):
        if aname == "myException":
            self.myException = ret = self.getException();
            return ret;
        else:
            raise AttributeError("no such attribute " + aname)

    def __eq__(self,other):
        if isinstance(other, ParserElement):
            return self is other or self.__dict__ == other.__dict__
        elif isinstance(other, basestring):
            try:
                self.parseString(_ustr(other), parseAll=True)
                return True
            except ParseBaseException:
                return False
        else:
            return super(ParserElement,self)==other

    def __ne__(self,other):
        return not (self == other)

    def __hash__(self):
        return hash(id(self))

    def __req__(self,other):
        return self == other

    def __rne__(self,other):
        return not (self == other)


class Token(ParserElement):
    """Abstract C{ParserElement} subclass, for defining atomic matching patterns."""
    def __init__( self ):
        super(Token,self).__init__( savelist=False )

    def setName(self, name):
        s = super(Token,self).setName(name)
        self.errmsg = "Expected " + self.name
        return s


class Empty(Token):
    """An empty token, will always match."""
    def __init__( self ):
        super(Empty,self).__init__()
        self.name = "Empty"
        self.mayReturnEmpty = True
        self.mayIndexError = False


class NoMatch(Token):
    """A token that will never match."""
    def __init__( self ):
        super(NoMatch,self).__init__()
        self.name = "NoMatch"
        self.mayReturnEmpty = True
        self.mayIndexError = False
        self.errmsg = "Unmatchable token"

    def parseImpl( self, instring, loc, doActions=True ):
        exc = self.myException
        exc.loc = loc
        exc.pstr = instring
        raise exc


class Literal(Token):
    """Token to exactly match a specified string."""
    def __init__( self, matchString ):
        super(Literal,self).__init__()
        self.match = matchString
        self.matchLen = len(matchString)
        try:
            self.firstMatchChar = matchString[0]
        except IndexError:
            warnings.warn("null string passed to Literal; use Empty() instead",
                            SyntaxWarning, stacklevel=2)
            self.__class__ = Empty
        self.name = '"%s"' % _ustr(self.match)
        self.errmsg = "Expected " + self.name
        self.mayReturnEmpty = False
        self.mayIndexError = False

    # Performance tuning: this routine gets called a *lot*
    # if this is a single character match string  and the first character matches,
    # short-circuit as quickly as possible, and avoid calling startswith
    #~ @profile
    def parseImpl( self, instring, loc, doActions=True ):
        if (instring[loc] == self.firstMatchChar and
            (self.matchLen==1 or instring.startswith(self.match,loc)) ):
            return loc+self.matchLen, self.match
        #~ raise ParseException( instring, loc, self.errmsg )
        exc = self.myException
        exc.loc = loc
        exc.pstr = instring
        raise exc
_L = Literal
ParserElement.literalStringClass = Literal

class Keyword(Token):
    """Token to exactly match a specified string as a keyword, that is, it must be
       immediately followed by a non-keyword character.  Compare with C{L{Literal}}::
         Literal("if") will match the leading C{'if'} in C{'ifAndOnlyIf'}.
         Keyword("if") will not; it will only match the leading C{'if'} in C{'if x=1'}, or C{'if(y==2)'}
       Accepts two optional constructor arguments in addition to the keyword string:
       C{identChars} is a string of characters that would be valid identifier characters,
       defaulting to all alphanumerics + "_" and "$"; C{caseless} allows case-insensitive
       matching, default is C{False}.
    """
    DEFAULT_KEYWORD_CHARS = alphanums+"_$"

    def __init__( self, matchString, identChars=DEFAULT_KEYWORD_CHARS, caseless=False ):
        super(Keyword,self).__init__()
        self.match = matchString
        self.matchLen = len(matchString)
        try:
            self.firstMatchChar = matchString[0]
        except IndexError:
            warnings.warn("null string passed to Keyword; use Empty() instead",
                            SyntaxWarning, stacklevel=2)
        self.name = '"%s"' % self.match
        self.errmsg = "Expected " + self.name
        self.mayReturnEmpty = False
        self.mayIndexError = False
        self.caseless = caseless
        if caseless:
            self.caselessmatch = matchString.upper()
            identChars = identChars.upper()
        self.identChars = set(identChars)

    def parseImpl( self, instring, loc, doActions=True ):
        if self.caseless:
            if ( (instring[ loc:loc+self.matchLen ].upper() == self.caselessmatch) and
                 (loc >= len(instring)-self.matchLen or instring[loc+self.matchLen].upper() not in self.identChars) and
                 (loc == 0 or instring[loc-1].upper() not in self.identChars) ):
                return loc+self.matchLen, self.match
        else:
            if (instring[loc] == self.firstMatchChar and
                (self.matchLen==1 or instring.startswith(self.match,loc)) and
                (loc >= len(instring)-self.matchLen or instring[loc+self.matchLen] not in self.identChars) and
                (loc == 0 or instring[loc-1] not in self.identChars) ):
                return loc+self.matchLen, self.match
        #~ raise ParseException( instring, loc, self.errmsg )
        exc = self.myException
        exc.loc = loc
        exc.pstr = instring
        raise exc

    def copy(self):
        c = super(Keyword,self).copy()
        c.identChars = Keyword.DEFAULT_KEYWORD_CHARS
        return c

    def setDefaultKeywordChars( chars ):
        """Overrides the default Keyword chars
        """
        Keyword.DEFAULT_KEYWORD_CHARS = chars
    setDefaultKeywordChars = staticmethod(setDefaultKeywordChars)

class CaselessLiteral(Literal):
    """Token to match a specified string, ignoring case of letters.
       Note: the matched results will always be in the case of the given
       match string, NOT the case of the input text.
    """
    def __init__( self, matchString ):
        super(CaselessLiteral,self).__init__( matchString.upper() )
        # Preserve the defining literal.
        self.returnString = matchString
        self.name = "'%s'" % self.returnString
        self.errmsg = "Expected " + self.name

    def parseImpl( self, instring, loc, doActions=True ):
        if instring[ loc:loc+self.matchLen ].upper() == self.match:
            return loc+self.matchLen, self.returnString
        #~ raise ParseException( instring, loc, self.errmsg )
        exc = self.myException
        exc.loc = loc
        exc.pstr = instring
        raise exc

class CaselessKeyword(Keyword):
    def __init__( self, matchString, identChars=Keyword.DEFAULT_KEYWORD_CHARS ):
        super(CaselessKeyword,self).__init__( matchString, identChars, caseless=True )

    def parseImpl( self, instring, loc, doActions=True ):
        if ( (instring[ loc:loc+self.matchLen ].upper() == self.caselessmatch) and
             (loc >= len(instring)-self.matchLen or instring[loc+self.matchLen].upper() not in self.identChars) ):
            return loc+self.matchLen, self.match
        #~ raise ParseException( instring, loc, self.errmsg )
        exc = self.myException
        exc.loc = loc
        exc.pstr = instring
        raise exc

class Word(Token):
    """Token for matching words composed of allowed character sets.
       Defined with string containing all allowed initial characters,
       an optional string containing allowed body characters (if omitted,
       defaults to the initial character set), and an optional minimum,
       maximum, and/or exact length.  The default value for C{min} is 1 (a
       minimum value < 1 is not valid); the default values for C{max} and C{exact}
       are 0, meaning no maximum or exact length restriction. An optional
       C{exclude} parameter can list characters that might be found in 
       the input C{bodyChars} string; useful to define a word of all printables
       except for one or two characters, for instance.
    """
    def __init__( self, initChars, bodyChars=None, min=1, max=0, exact=0, asKeyword=False, excludeChars=None ):
        super(Word,self).__init__()
        if excludeChars:
            initChars = ''.join([c for c in initChars if c not in excludeChars])
            if bodyChars:
                bodyChars = ''.join([c for c in bodyChars if c not in excludeChars])
        self.initCharsOrig = initChars
        self.initChars = set(initChars)
        if bodyChars :
            self.bodyCharsOrig = bodyChars
            self.bodyChars = set(bodyChars)
        else:
            self.bodyCharsOrig = initChars
            self.bodyChars = set(initChars)

        self.maxSpecified = max > 0

        if min < 1:
            raise ValueError("cannot specify a minimum length < 1; use Optional(Word()) if zero-length word is permitted")

        self.minLen = min

        if max > 0:
            self.maxLen = max
        else:
            self.maxLen = _MAX_INT

        if exact > 0:
            self.maxLen = exact
            self.minLen = exact

        self.name = _ustr(self)
        self.errmsg = "Expected " + self.name
        self.mayIndexError = False
        self.asKeyword = asKeyword

        if ' ' not in self.initCharsOrig+self.bodyCharsOrig and (min==1 and max==0 and exact==0):
            if self.bodyCharsOrig == self.initCharsOrig:
                self.reString = "[%s]+" % _escapeRegexRangeChars(self.initCharsOrig)
            elif len(self.bodyCharsOrig) == 1:
                self.reString = "%s[%s]*" % \
                                      (re.escape(self.initCharsOrig),
                                      _escapeRegexRangeChars(self.bodyCharsOrig),)
            else:
                self.reString = "[%s][%s]*" % \
                                      (_escapeRegexRangeChars(self.initCharsOrig),
                                      _escapeRegexRangeChars(self.bodyCharsOrig),)
            if self.asKeyword:
                self.reString = r"\b"+self.reString+r"\b"
            try:
                self.re = re.compile( self.reString )
            except:
                self.re = None

    def parseImpl( self, instring, loc, doActions=True ):
        if self.re:
            result = self.re.match(instring,loc)
            if not result:
                exc = self.myException
                exc.loc = loc
                exc.pstr = instring
                raise exc

            loc = result.end()
            return loc, result.group()

        if not(instring[ loc ] in self.initChars):
            #~ raise ParseException( instring, loc, self.errmsg )
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc
        start = loc
        loc += 1
        instrlen = len(instring)
        bodychars = self.bodyChars
        maxloc = start + self.maxLen
        maxloc = min( maxloc, instrlen )
        while loc < maxloc and instring[loc] in bodychars:
            loc += 1

        throwException = False
        if loc - start < self.minLen:
            throwException = True
        if self.maxSpecified and loc < instrlen and instring[loc] in bodychars:
            throwException = True
        if self.asKeyword:
            if (start>0 and instring[start-1] in bodychars) or (loc<instrlen and instring[loc] in bodychars):
                throwException = True

        if throwException:
            #~ raise ParseException( instring, loc, self.errmsg )
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc

        return loc, instring[start:loc]

    def __str__( self ):
        try:
            return super(Word,self).__str__()
        except:
            pass


        if self.strRepr is None:

            def charsAsStr(s):
                if len(s)>4:
                    return s[:4]+"..."
                else:
                    return s

            if ( self.initCharsOrig != self.bodyCharsOrig ):
                self.strRepr = "W:(%s,%s)" % ( charsAsStr(self.initCharsOrig), charsAsStr(self.bodyCharsOrig) )
            else:
                self.strRepr = "W:(%s)" % charsAsStr(self.initCharsOrig)

        return self.strRepr


class Regex(Token):
    """Token for matching strings that match a given regular expression.
       Defined with string specifying the regular expression in a form recognized by the inbuilt Python re module.
    """
    compiledREtype = type(re.compile("[A-Z]"))
    def __init__( self, pattern, flags=0):
        """The parameters C{pattern} and C{flags} are passed to the C{re.compile()} function as-is. See the Python C{re} module for an explanation of the acceptable patterns and flags."""
        super(Regex,self).__init__()

        if isinstance(pattern, basestring):
            if len(pattern) == 0:
                warnings.warn("null string passed to Regex; use Empty() instead",
                        SyntaxWarning, stacklevel=2)

            self.pattern = pattern
            self.flags = flags

            try:
                self.re = re.compile(self.pattern, self.flags)
                self.reString = self.pattern
            except sre_constants.error:
                warnings.warn("invalid pattern (%s) passed to Regex" % pattern,
                    SyntaxWarning, stacklevel=2)
                raise

        elif isinstance(pattern, Regex.compiledREtype):
            self.re = pattern
            self.pattern = \
            self.reString = str(pattern)
            self.flags = flags
            
        else:
            raise ValueError("Regex may only be constructed with a string or a compiled RE object")

        self.name = _ustr(self)
        self.errmsg = "Expected " + self.name
        self.mayIndexError = False
        self.mayReturnEmpty = True

    def parseImpl( self, instring, loc, doActions=True ):
        result = self.re.match(instring,loc)
        if not result:
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc

        loc = result.end()
        d = result.groupdict()
        ret = ParseResults(result.group())
        if d:
            for k in d:
                ret[k] = d[k]
        return loc,ret

    def __str__( self ):
        try:
            return super(Regex,self).__str__()
        except:
            pass

        if self.strRepr is None:
            self.strRepr = "Re:(%s)" % repr(self.pattern)

        return self.strRepr


class QuotedString(Token):
    """Token for matching strings that are delimited by quoting characters.
    """
    def __init__( self, quoteChar, escChar=None, escQuote=None, multiline=False, unquoteResults=True, endQuoteChar=None):
        """
           Defined with the following parameters:
            - quoteChar - string of one or more characters defining the quote delimiting string
            - escChar - character to escape quotes, typically backslash (default=None)
            - escQuote - special quote sequence to escape an embedded quote string (such as SQL's "" to escape an embedded ") (default=None)
            - multiline - boolean indicating whether quotes can span multiple lines (default=C{False})
            - unquoteResults - boolean indicating whether the matched text should be unquoted (default=C{True})
            - endQuoteChar - string of one or more characters defining the end of the quote delimited string (default=C{None} => same as quoteChar)
        """
        super(QuotedString,self).__init__()

        # remove white space from quote chars - wont work anyway
        quoteChar = quoteChar.strip()
        if len(quoteChar) == 0:
            warnings.warn("quoteChar cannot be the empty string",SyntaxWarning,stacklevel=2)
            raise SyntaxError()

        if endQuoteChar is None:
            endQuoteChar = quoteChar
        else:
            endQuoteChar = endQuoteChar.strip()
            if len(endQuoteChar) == 0:
                warnings.warn("endQuoteChar cannot be the empty string",SyntaxWarning,stacklevel=2)
                raise SyntaxError()

        self.quoteChar = quoteChar
        self.quoteCharLen = len(quoteChar)
        self.firstQuoteChar = quoteChar[0]
        self.endQuoteChar = endQuoteChar
        self.endQuoteCharLen = len(endQuoteChar)
        self.escChar = escChar
        self.escQuote = escQuote
        self.unquoteResults = unquoteResults

        if multiline:
            self.flags = re.MULTILINE | re.DOTALL
            self.pattern = r'%s(?:[^%s%s]' % \
                ( re.escape(self.quoteChar),
                  _escapeRegexRangeChars(self.endQuoteChar[0]),
                  (escChar is not None and _escapeRegexRangeChars(escChar) or '') )
        else:
            self.flags = 0
            self.pattern = r'%s(?:[^%s\n\r%s]' % \
                ( re.escape(self.quoteChar),
                  _escapeRegexRangeChars(self.endQuoteChar[0]),
                  (escChar is not None and _escapeRegexRangeChars(escChar) or '') )
        if len(self.endQuoteChar) > 1:
            self.pattern += (
                '|(?:' + ')|(?:'.join(["%s[^%s]" % (re.escape(self.endQuoteChar[:i]),
                                               _escapeRegexRangeChars(self.endQuoteChar[i]))
                                    for i in range(len(self.endQuoteChar)-1,0,-1)]) + ')'
                )
        if escQuote:
            self.pattern += (r'|(?:%s)' % re.escape(escQuote))
        if escChar:
            self.pattern += (r'|(?:%s.)' % re.escape(escChar))
            charset = ''.join(set(self.quoteChar[0]+self.endQuoteChar[0])).replace('^',r'\^').replace('-',r'\-')
            self.escCharReplacePattern = re.escape(self.escChar)+("([%s])" % charset)
        self.pattern += (r')*%s' % re.escape(self.endQuoteChar))

        try:
            self.re = re.compile(self.pattern, self.flags)
            self.reString = self.pattern
        except sre_constants.error:
            warnings.warn("invalid pattern (%s) passed to Regex" % self.pattern,
                SyntaxWarning, stacklevel=2)
            raise

        self.name = _ustr(self)
        self.errmsg = "Expected " + self.name
        self.mayIndexError = False
        self.mayReturnEmpty = True

    def parseImpl( self, instring, loc, doActions=True ):
        result = instring[loc] == self.firstQuoteChar and self.re.match(instring,loc) or None
        if not result:
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc

        loc = result.end()
        ret = result.group()

        if self.unquoteResults:

            # strip off quotes
            ret = ret[self.quoteCharLen:-self.endQuoteCharLen]

            if isinstance(ret,basestring):
                # replace escaped characters
                if self.escChar:
                    ret = re.sub(self.escCharReplacePattern,"\g<1>",ret)

                # replace escaped quotes
                if self.escQuote:
                    ret = ret.replace(self.escQuote, self.endQuoteChar)

        return loc, ret

    def __str__( self ):
        try:
            return super(QuotedString,self).__str__()
        except:
            pass

        if self.strRepr is None:
            self.strRepr = "quoted string, starting with %s ending with %s" % (self.quoteChar, self.endQuoteChar)

        return self.strRepr


class CharsNotIn(Token):
    """Token for matching words composed of characters *not* in a given set.
       Defined with string containing all disallowed characters, and an optional
       minimum, maximum, and/or exact length.  The default value for C{min} is 1 (a
       minimum value < 1 is not valid); the default values for C{max} and C{exact}
       are 0, meaning no maximum or exact length restriction.
    """
    def __init__( self, notChars, min=1, max=0, exact=0 ):
        super(CharsNotIn,self).__init__()
        self.skipWhitespace = False
        self.notChars = notChars

        if min < 1:
            raise ValueError("cannot specify a minimum length < 1; use Optional(CharsNotIn()) if zero-length char group is permitted")

        self.minLen = min

        if max > 0:
            self.maxLen = max
        else:
            self.maxLen = _MAX_INT

        if exact > 0:
            self.maxLen = exact
            self.minLen = exact

        self.name = _ustr(self)
        self.errmsg = "Expected " + self.name
        self.mayReturnEmpty = ( self.minLen == 0 )
        self.mayIndexError = False

    def parseImpl( self, instring, loc, doActions=True ):
        if instring[loc] in self.notChars:
            #~ raise ParseException( instring, loc, self.errmsg )
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc

        start = loc
        loc += 1
        notchars = self.notChars
        maxlen = min( start+self.maxLen, len(instring) )
        while loc < maxlen and \
              (instring[loc] not in notchars):
            loc += 1

        if loc - start < self.minLen:
            #~ raise ParseException( instring, loc, self.errmsg )
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc

        return loc, instring[start:loc]

    def __str__( self ):
        try:
            return super(CharsNotIn, self).__str__()
        except:
            pass

        if self.strRepr is None:
            if len(self.notChars) > 4:
                self.strRepr = "!W:(%s...)" % self.notChars[:4]
            else:
                self.strRepr = "!W:(%s)" % self.notChars

        return self.strRepr

class White(Token):
    """Special matching class for matching whitespace.  Normally, whitespace is ignored
       by pyparsing grammars.  This class is included when some whitespace structures
       are significant.  Define with a string containing the whitespace characters to be
       matched; default is C{" \\t\\r\\n"}.  Also takes optional C{min}, C{max}, and C{exact} arguments,
       as defined for the C{L{Word}} class."""
    whiteStrs = {
        " " : "<SPC>",
        "\t": "<TAB>",
        "\n": "<LF>",
        "\r": "<CR>",
        "\f": "<FF>",
        }
    def __init__(self, ws=" \t\r\n", min=1, max=0, exact=0):
        super(White,self).__init__()
        self.matchWhite = ws
        self.setWhitespaceChars( "".join([c for c in self.whiteChars if c not in self.matchWhite]) )
        #~ self.leaveWhitespace()
        self.name = ("".join([White.whiteStrs[c] for c in self.matchWhite]))
        self.mayReturnEmpty = True
        self.errmsg = "Expected " + self.name

        self.minLen = min

        if max > 0:
            self.maxLen = max
        else:
            self.maxLen = _MAX_INT

        if exact > 0:
            self.maxLen = exact
            self.minLen = exact

    def parseImpl( self, instring, loc, doActions=True ):
        if not(instring[ loc ] in self.matchWhite):
            #~ raise ParseException( instring, loc, self.errmsg )
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc
        start = loc
        loc += 1
        maxloc = start + self.maxLen
        maxloc = min( maxloc, len(instring) )
        while loc < maxloc and instring[loc] in self.matchWhite:
            loc += 1

        if loc - start < self.minLen:
            #~ raise ParseException( instring, loc, self.errmsg )
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc

        return loc, instring[start:loc]


class _PositionToken(Token):
    def __init__( self ):
        super(_PositionToken,self).__init__()
        self.name=self.__class__.__name__
        self.mayReturnEmpty = True
        self.mayIndexError = False

class GoToColumn(_PositionToken):
    """Token to advance to a specific column of input text; useful for tabular report scraping."""
    def __init__( self, colno ):
        super(GoToColumn,self).__init__()
        self.col = colno

    def preParse( self, instring, loc ):
        if col(loc,instring) != self.col:
            instrlen = len(instring)
            if self.ignoreExprs:
                loc = self._skipIgnorables( instring, loc )
            while loc < instrlen and instring[loc].isspace() and col( loc, instring ) != self.col :
                loc += 1
        return loc

    def parseImpl( self, instring, loc, doActions=True ):
        thiscol = col( loc, instring )
        if thiscol > self.col:
            raise ParseException( instring, loc, "Text not in expected column", self )
        newloc = loc + self.col - thiscol
        ret = instring[ loc: newloc ]
        return newloc, ret

class LineStart(_PositionToken):
    """Matches if current position is at the beginning of a line within the parse string"""
    def __init__( self ):
        super(LineStart,self).__init__()
        self.setWhitespaceChars( ParserElement.DEFAULT_WHITE_CHARS.replace("\n","") )
        self.errmsg = "Expected start of line"

    def preParse( self, instring, loc ):
        preloc = super(LineStart,self).preParse(instring,loc)
        if instring[preloc] == "\n":
            loc += 1
        return loc

    def parseImpl( self, instring, loc, doActions=True ):
        if not( loc==0 or
            (loc == self.preParse( instring, 0 )) or
            (instring[loc-1] == "\n") ): #col(loc, instring) != 1:
            #~ raise ParseException( instring, loc, "Expected start of line" )
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc
        return loc, []

class LineEnd(_PositionToken):
    """Matches if current position is at the end of a line within the parse string"""
    def __init__( self ):
        super(LineEnd,self).__init__()
        self.setWhitespaceChars( ParserElement.DEFAULT_WHITE_CHARS.replace("\n","") )
        self.errmsg = "Expected end of line"

    def parseImpl( self, instring, loc, doActions=True ):
        if loc<len(instring):
            if instring[loc] == "\n":
                return loc+1, "\n"
            else:
                #~ raise ParseException( instring, loc, "Expected end of line" )
                exc = self.myException
                exc.loc = loc
                exc.pstr = instring
                raise exc
        elif loc == len(instring):
            return loc+1, []
        else:
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc

class StringStart(_PositionToken):
    """Matches if current position is at the beginning of the parse string"""
    def __init__( self ):
        super(StringStart,self).__init__()
        self.errmsg = "Expected start of text"

    def parseImpl( self, instring, loc, doActions=True ):
        if loc != 0:
            # see if entire string up to here is just whitespace and ignoreables
            if loc != self.preParse( instring, 0 ):
                #~ raise ParseException( instring, loc, "Expected start of text" )
                exc = self.myException
                exc.loc = loc
                exc.pstr = instring
                raise exc
        return loc, []

class StringEnd(_PositionToken):
    """Matches if current position is at the end of the parse string"""
    def __init__( self ):
        super(StringEnd,self).__init__()
        self.errmsg = "Expected end of text"

    def parseImpl( self, instring, loc, doActions=True ):
        if loc < len(instring):
            #~ raise ParseException( instring, loc, "Expected end of text" )
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc
        elif loc == len(instring):
            return loc+1, []
        elif loc > len(instring):
            return loc, []
        else:
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc

class WordStart(_PositionToken):
    """Matches if the current position is at the beginning of a Word, and
       is not preceded by any character in a given set of C{wordChars}
       (default=C{printables}). To emulate the C{\b} behavior of regular expressions,
       use C{WordStart(alphanums)}. C{WordStart} will also match at the beginning of
       the string being parsed, or at the beginning of a line.
    """
    def __init__(self, wordChars = printables):
        super(WordStart,self).__init__()
        self.wordChars = set(wordChars)
        self.errmsg = "Not at the start of a word"

    def parseImpl(self, instring, loc, doActions=True ):
        if loc != 0:
            if (instring[loc-1] in self.wordChars or
                instring[loc] not in self.wordChars):
                exc = self.myException
                exc.loc = loc
                exc.pstr = instring
                raise exc
        return loc, []

class WordEnd(_PositionToken):
    """Matches if the current position is at the end of a Word, and
       is not followed by any character in a given set of C{wordChars}
       (default=C{printables}). To emulate the C{\b} behavior of regular expressions,
       use C{WordEnd(alphanums)}. C{WordEnd} will also match at the end of
       the string being parsed, or at the end of a line.
    """
    def __init__(self, wordChars = printables):
        super(WordEnd,self).__init__()
        self.wordChars = set(wordChars)
        self.skipWhitespace = False
        self.errmsg = "Not at the end of a word"

    def parseImpl(self, instring, loc, doActions=True ):
        instrlen = len(instring)
        if instrlen>0 and loc<instrlen:
            if (instring[loc] in self.wordChars or
                instring[loc-1] not in self.wordChars):
                #~ raise ParseException( instring, loc, "Expected end of word" )
                exc = self.myException
                exc.loc = loc
                exc.pstr = instring
                raise exc
        return loc, []


class ParseExpression(ParserElement):
    """Abstract subclass of ParserElement, for combining and post-processing parsed tokens."""
    def __init__( self, exprs, savelist = False ):
        super(ParseExpression,self).__init__(savelist)
        if isinstance( exprs, list ):
            self.exprs = exprs
        elif isinstance( exprs, basestring ):
            self.exprs = [ Literal( exprs ) ]
        else:
            try:
                self.exprs = list( exprs )
            except TypeError:
                self.exprs = [ exprs ]
        self.callPreparse = False

    def __getitem__( self, i ):
        return self.exprs[i]

    def append( self, other ):
        self.exprs.append( other )
        self.strRepr = None
        return self

    def leaveWhitespace( self ):
        """Extends C{leaveWhitespace} defined in base class, and also invokes C{leaveWhitespace} on
           all contained expressions."""
        self.skipWhitespace = False
        self.exprs = [ e.copy() for e in self.exprs ]
        for e in self.exprs:
            e.leaveWhitespace()
        return self

    def ignore( self, other ):
        if isinstance( other, Suppress ):
            if other not in self.ignoreExprs:
                super( ParseExpression, self).ignore( other )
                for e in self.exprs:
                    e.ignore( self.ignoreExprs[-1] )
        else:
            super( ParseExpression, self).ignore( other )
            for e in self.exprs:
                e.ignore( self.ignoreExprs[-1] )
        return self

    def __str__( self ):
        try:
            return super(ParseExpression,self).__str__()
        except:
            pass

        if self.strRepr is None:
            self.strRepr = "%s:(%s)" % ( self.__class__.__name__, _ustr(self.exprs) )
        return self.strRepr

    def streamline( self ):
        super(ParseExpression,self).streamline()

        for e in self.exprs:
            e.streamline()

        # collapse nested And's of the form And( And( And( a,b), c), d) to And( a,b,c,d )
        # but only if there are no parse actions or resultsNames on the nested And's
        # (likewise for Or's and MatchFirst's)
        if ( len(self.exprs) == 2 ):
            other = self.exprs[0]
            if ( isinstance( other, self.__class__ ) and
                  not(other.parseAction) and
                  other.resultsName is None and
                  not other.debug ):
                self.exprs = other.exprs[:] + [ self.exprs[1] ]
                self.strRepr = None
                self.mayReturnEmpty |= other.mayReturnEmpty
                self.mayIndexError  |= other.mayIndexError

            other = self.exprs[-1]
            if ( isinstance( other, self.__class__ ) and
                  not(other.parseAction) and
                  other.resultsName is None and
                  not other.debug ):
                self.exprs = self.exprs[:-1] + other.exprs[:]
                self.strRepr = None
                self.mayReturnEmpty |= other.mayReturnEmpty
                self.mayIndexError  |= other.mayIndexError

        return self

    def setResultsName( self, name, listAllMatches=False ):
        ret = super(ParseExpression,self).setResultsName(name,listAllMatches)
        return ret

    def validate( self, validateTrace=[] ):
        tmp = validateTrace[:]+[self]
        for e in self.exprs:
            e.validate(tmp)
        self.checkRecursion( [] )
        
    def copy(self):
        ret = super(ParseExpression,self).copy()
        ret.exprs = [e.copy() for e in self.exprs]
        return ret

class And(ParseExpression):
    """Requires all given C{ParseExpression}s to be found in the given order.
       Expressions may be separated by whitespace.
       May be constructed using the C{'+'} operator.
    """

    class _ErrorStop(Empty):
        def __init__(self, *args, **kwargs):
            super(And._ErrorStop,self).__init__(*args, **kwargs)
            self.name = '-'
            self.leaveWhitespace()

    def __init__( self, exprs, savelist = True ):
        super(And,self).__init__(exprs, savelist)
        self.mayReturnEmpty = True
        for e in self.exprs:
            if not e.mayReturnEmpty:
                self.mayReturnEmpty = False
                break
        self.setWhitespaceChars( exprs[0].whiteChars )
        self.skipWhitespace = exprs[0].skipWhitespace
        self.callPreparse = True

    def parseImpl( self, instring, loc, doActions=True ):
        # pass False as last arg to _parse for first element, since we already
        # pre-parsed the string as part of our And pre-parsing
        loc, resultlist = self.exprs[0]._parse( instring, loc, doActions, callPreParse=False )
        errorStop = False
        for e in self.exprs[1:]:
            if isinstance(e, And._ErrorStop):
                errorStop = True
                continue
            if errorStop:
                try:
                    loc, exprtokens = e._parse( instring, loc, doActions )
                except ParseSyntaxException:
                    raise
                except ParseBaseException, pe:
                    raise ParseSyntaxException(pe)
                except IndexError:
                    raise ParseSyntaxException( ParseException(instring, len(instring), self.errmsg, self) )
            else:
                loc, exprtokens = e._parse( instring, loc, doActions )
            if exprtokens or exprtokens.keys():
                resultlist += exprtokens
        return loc, resultlist

    def __iadd__(self, other ):
        if isinstance( other, basestring ):
            other = Literal( other )
        return self.append( other ) #And( [ self, other ] )

    def checkRecursion( self, parseElementList ):
        subRecCheckList = parseElementList[:] + [ self ]
        for e in self.exprs:
            e.checkRecursion( subRecCheckList )
            if not e.mayReturnEmpty:
                break

    def __str__( self ):
        if hasattr(self,"name"):
            return self.name

        if self.strRepr is None:
            self.strRepr = "{" + " ".join( [ _ustr(e) for e in self.exprs ] ) + "}"

        return self.strRepr


class Or(ParseExpression):
    """Requires that at least one C{ParseExpression} is found.
       If two expressions match, the expression that matches the longest string will be used.
       May be constructed using the C{'^'} operator.
    """
    def __init__( self, exprs, savelist = False ):
        super(Or,self).__init__(exprs, savelist)
        self.mayReturnEmpty = False
        for e in self.exprs:
            if e.mayReturnEmpty:
                self.mayReturnEmpty = True
                break

    def parseImpl( self, instring, loc, doActions=True ):
        maxExcLoc = -1
        maxMatchLoc = -1
        maxException = None
        for e in self.exprs:
            try:
                loc2 = e.tryParse( instring, loc )
            except ParseException, err:
                if err.loc > maxExcLoc:
                    maxException = err
                    maxExcLoc = err.loc
            except IndexError:
                if len(instring) > maxExcLoc:
                    maxException = ParseException(instring,len(instring),e.errmsg,self)
                    maxExcLoc = len(instring)
            else:
                if loc2 > maxMatchLoc:
                    maxMatchLoc = loc2
                    maxMatchExp = e

        if maxMatchLoc < 0:
            if maxException is not None:
                raise maxException
            else:
                raise ParseException(instring, loc, "no defined alternatives to match", self)

        return maxMatchExp._parse( instring, loc, doActions )

    def __ixor__(self, other ):
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        return self.append( other ) #Or( [ self, other ] )

    def __str__( self ):
        if hasattr(self,"name"):
            return self.name

        if self.strRepr is None:
            self.strRepr = "{" + " ^ ".join( [ _ustr(e) for e in self.exprs ] ) + "}"

        return self.strRepr

    def checkRecursion( self, parseElementList ):
        subRecCheckList = parseElementList[:] + [ self ]
        for e in self.exprs:
            e.checkRecursion( subRecCheckList )


class MatchFirst(ParseExpression):
    """Requires that at least one C{ParseExpression} is found.
       If two expressions match, the first one listed is the one that will match.
       May be constructed using the C{'|'} operator.
    """
    def __init__( self, exprs, savelist = False ):
        super(MatchFirst,self).__init__(exprs, savelist)
        if exprs:
            self.mayReturnEmpty = False
            for e in self.exprs:
                if e.mayReturnEmpty:
                    self.mayReturnEmpty = True
                    break
        else:
            self.mayReturnEmpty = True

    def parseImpl( self, instring, loc, doActions=True ):
        maxExcLoc = -1
        maxException = None
        for e in self.exprs:
            try:
                ret = e._parse( instring, loc, doActions )
                return ret
            except ParseException, err:
                if err.loc > maxExcLoc:
                    maxException = err
                    maxExcLoc = err.loc
            except IndexError:
                if len(instring) > maxExcLoc:
                    maxException = ParseException(instring,len(instring),e.errmsg,self)
                    maxExcLoc = len(instring)

        # only got here if no expression matched, raise exception for match that made it the furthest
        else:
            if maxException is not None:
                raise maxException
            else:
                raise ParseException(instring, loc, "no defined alternatives to match", self)

    def __ior__(self, other ):
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass( other )
        return self.append( other ) #MatchFirst( [ self, other ] )

    def __str__( self ):
        if hasattr(self,"name"):
            return self.name

        if self.strRepr is None:
            self.strRepr = "{" + " | ".join( [ _ustr(e) for e in self.exprs ] ) + "}"

        return self.strRepr

    def checkRecursion( self, parseElementList ):
        subRecCheckList = parseElementList[:] + [ self ]
        for e in self.exprs:
            e.checkRecursion( subRecCheckList )


class Each(ParseExpression):
    """Requires all given C{ParseExpression}s to be found, but in any order.
       Expressions may be separated by whitespace.
       May be constructed using the C{'&'} operator.
    """
    def __init__( self, exprs, savelist = True ):
        super(Each,self).__init__(exprs, savelist)
        self.mayReturnEmpty = True
        for e in self.exprs:
            if not e.mayReturnEmpty:
                self.mayReturnEmpty = False
                break
        self.skipWhitespace = True
        self.initExprGroups = True

    def parseImpl( self, instring, loc, doActions=True ):
        if self.initExprGroups:
            opt1 = [ e.expr for e in self.exprs if isinstance(e,Optional) ]
            opt2 = [ e for e in self.exprs if e.mayReturnEmpty and e not in opt1 ]
            self.optionals = opt1 + opt2
            self.multioptionals = [ e.expr for e in self.exprs if isinstance(e,ZeroOrMore) ]
            self.multirequired = [ e.expr for e in self.exprs if isinstance(e,OneOrMore) ]
            self.required = [ e for e in self.exprs if not isinstance(e,(Optional,ZeroOrMore,OneOrMore)) ]
            self.required += self.multirequired
            self.initExprGroups = False
        tmpLoc = loc
        tmpReqd = self.required[:]
        tmpOpt  = self.optionals[:]
        matchOrder = []

        keepMatching = True
        while keepMatching:
            tmpExprs = tmpReqd + tmpOpt + self.multioptionals + self.multirequired
            failed = []
            for e in tmpExprs:
                try:
                    tmpLoc = e.tryParse( instring, tmpLoc )
                except ParseException:
                    failed.append(e)
                else:
                    matchOrder.append(e)
                    if e in tmpReqd:
                        tmpReqd.remove(e)
                    elif e in tmpOpt:
                        tmpOpt.remove(e)
            if len(failed) == len(tmpExprs):
                keepMatching = False

        if tmpReqd:
            missing = ", ".join( [ _ustr(e) for e in tmpReqd ] )
            raise ParseException(instring,loc,"Missing one or more required elements (%s)" % missing )

        # add any unmatched Optionals, in case they have default values defined
        matchOrder += [e for e in self.exprs if isinstance(e,Optional) and e.expr in tmpOpt]

        resultlist = []
        for e in matchOrder:
            loc,results = e._parse(instring,loc,doActions)
            resultlist.append(results)

        finalResults = ParseResults([])
        for r in resultlist:
            dups = {}
            for k in r.keys():
                if k in finalResults.keys():
                    tmp = ParseResults(finalResults[k])
                    tmp += ParseResults(r[k])
                    dups[k] = tmp
            finalResults += ParseResults(r)
            for k,v in dups.items():
                finalResults[k] = v
        return loc, finalResults

    def __str__( self ):
        if hasattr(self,"name"):
            return self.name

        if self.strRepr is None:
            self.strRepr = "{" + " & ".join( [ _ustr(e) for e in self.exprs ] ) + "}"

        return self.strRepr

    def checkRecursion( self, parseElementList ):
        subRecCheckList = parseElementList[:] + [ self ]
        for e in self.exprs:
            e.checkRecursion( subRecCheckList )


class ParseElementEnhance(ParserElement):
    """Abstract subclass of C{ParserElement}, for combining and post-processing parsed tokens."""
    def __init__( self, expr, savelist=False ):
        super(ParseElementEnhance,self).__init__(savelist)
        if isinstance( expr, basestring ):
            expr = Literal(expr)
        self.expr = expr
        self.strRepr = None
        if expr is not None:
            self.mayIndexError = expr.mayIndexError
            self.mayReturnEmpty = expr.mayReturnEmpty
            self.setWhitespaceChars( expr.whiteChars )
            self.skipWhitespace = expr.skipWhitespace
            self.saveAsList = expr.saveAsList
            self.callPreparse = expr.callPreparse
            self.ignoreExprs.extend(expr.ignoreExprs)

    def parseImpl( self, instring, loc, doActions=True ):
        if self.expr is not None:
            return self.expr._parse( instring, loc, doActions, callPreParse=False )
        else:
            raise ParseException("",loc,self.errmsg,self)

    def leaveWhitespace( self ):
        self.skipWhitespace = False
        self.expr = self.expr.copy()
        if self.expr is not None:
            self.expr.leaveWhitespace()
        return self

    def ignore( self, other ):
        if isinstance( other, Suppress ):
            if other not in self.ignoreExprs:
                super( ParseElementEnhance, self).ignore( other )
                if self.expr is not None:
                    self.expr.ignore( self.ignoreExprs[-1] )
        else:
            super( ParseElementEnhance, self).ignore( other )
            if self.expr is not None:
                self.expr.ignore( self.ignoreExprs[-1] )
        return self

    def streamline( self ):
        super(ParseElementEnhance,self).streamline()
        if self.expr is not None:
            self.expr.streamline()
        return self

    def checkRecursion( self, parseElementList ):
        if self in parseElementList:
            raise RecursiveGrammarException( parseElementList+[self] )
        subRecCheckList = parseElementList[:] + [ self ]
        if self.expr is not None:
            self.expr.checkRecursion( subRecCheckList )

    def validate( self, validateTrace=[] ):
        tmp = validateTrace[:]+[self]
        if self.expr is not None:
            self.expr.validate(tmp)
        self.checkRecursion( [] )

    def __str__( self ):
        try:
            return super(ParseElementEnhance,self).__str__()
        except:
            pass

        if self.strRepr is None and self.expr is not None:
            self.strRepr = "%s:(%s)" % ( self.__class__.__name__, _ustr(self.expr) )
        return self.strRepr


class FollowedBy(ParseElementEnhance):
    """Lookahead matching of the given parse expression.  C{FollowedBy}
    does *not* advance the parsing position within the input string, it only
    verifies that the specified parse expression matches at the current
    position.  C{FollowedBy} always returns a null token list."""
    def __init__( self, expr ):
        super(FollowedBy,self).__init__(expr)
        self.mayReturnEmpty = True

    def parseImpl( self, instring, loc, doActions=True ):
        self.expr.tryParse( instring, loc )
        return loc, []


class NotAny(ParseElementEnhance):
    """Lookahead to disallow matching with the given parse expression.  C{NotAny}
    does *not* advance the parsing position within the input string, it only
    verifies that the specified parse expression does *not* match at the current
    position.  Also, C{NotAny} does *not* skip over leading whitespace. C{NotAny}
    always returns a null token list.  May be constructed using the '~' operator."""
    def __init__( self, expr ):
        super(NotAny,self).__init__(expr)
        #~ self.leaveWhitespace()
        self.skipWhitespace = False  # do NOT use self.leaveWhitespace(), don't want to propagate to exprs
        self.mayReturnEmpty = True
        self.errmsg = "Found unwanted token, "+_ustr(self.expr)

    def parseImpl( self, instring, loc, doActions=True ):
        try:
            self.expr.tryParse( instring, loc )
        except (ParseException,IndexError):
            pass
        else:
            #~ raise ParseException(instring, loc, self.errmsg )
            exc = self.myException
            exc.loc = loc
            exc.pstr = instring
            raise exc
        return loc, []

    def __str__( self ):
        if hasattr(self,"name"):
            return self.name

        if self.strRepr is None:
            self.strRepr = "~{" + _ustr(self.expr) + "}"

        return self.strRepr


class ZeroOrMore(ParseElementEnhance):
    """Optional repetition of zero or more of the given expression."""
    def __init__( self, expr ):
        super(ZeroOrMore,self).__init__(expr)
        self.mayReturnEmpty = True

    def parseImpl( self, instring, loc, doActions=True ):
        tokens = []
        try:
            loc, tokens = self.expr._parse( instring, loc, doActions, callPreParse=False )
            hasIgnoreExprs = ( len(self.ignoreExprs) > 0 )
            while 1:
                if hasIgnoreExprs:
                    preloc = self._skipIgnorables( instring, loc )
                else:
                    preloc = loc
                loc, tmptokens = self.expr._parse( instring, preloc, doActions )
                if tmptokens or tmptokens.keys():
                    tokens += tmptokens
        except (ParseException,IndexError):
            pass

        return loc, tokens

    def __str__( self ):
        if hasattr(self,"name"):
            return self.name

        if self.strRepr is None:
            self.strRepr = "[" + _ustr(self.expr) + "]..."

        return self.strRepr

    def setResultsName( self, name, listAllMatches=False ):
        ret = super(ZeroOrMore,self).setResultsName(name,listAllMatches)
        ret.saveAsList = True
        return ret


class OneOrMore(ParseElementEnhance):
    """Repetition of one or more of the given expression."""
    def parseImpl( self, instring, loc, doActions=True ):
        # must be at least one
        loc, tokens = self.expr._parse( instring, loc, doActions, callPreParse=False )
        try:
            hasIgnoreExprs = ( len(self.ignoreExprs) > 0 )
            while 1:
                if hasIgnoreExprs:
                    preloc = self._skipIgnorables( instring, loc )
                else:
                    preloc = loc
                loc, tmptokens = self.expr._parse( instring, preloc, doActions )
                if tmptokens or tmptokens.keys():
                    tokens += tmptokens
        except (ParseException,IndexError):
            pass

        return loc, tokens

    def __str__( self ):
        if hasattr(self,"name"):
            return self.name

        if self.strRepr is None:
            self.strRepr = "{" + _ustr(self.expr) + "}..."

        return self.strRepr

    def setResultsName( self, name, listAllMatches=False ):
        ret = super(OneOrMore,self).setResultsName(name,listAllMatches)
        ret.saveAsList = True
        return ret

class _NullToken(object):
    def __bool__(self):
        return False
    __nonzero__ = __bool__
    def __str__(self):
        return ""

_optionalNotMatched = _NullToken()
class Optional(ParseElementEnhance):
    """Optional matching of the given expression.
       A default return string can also be specified, if the optional expression
       is not found.
    """
    def __init__( self, exprs, default=_optionalNotMatched ):
        super(Optional,self).__init__( exprs, savelist=False )
        self.defaultValue = default
        self.mayReturnEmpty = True

    def parseImpl( self, instring, loc, doActions=True ):
        try:
            loc, tokens = self.expr._parse( instring, loc, doActions, callPreParse=False )
        except (ParseException,IndexError):
            if self.defaultValue is not _optionalNotMatched:
                if self.expr.resultsName:
                    tokens = ParseResults([ self.defaultValue ])
                    tokens[self.expr.resultsName] = self.defaultValue
                else:
                    tokens = [ self.defaultValue ]
            else:
                tokens = []
        return loc, tokens

    def __str__( self ):
        if hasattr(self,"name"):
            return self.name

        if self.strRepr is None:
            self.strRepr = "[" + _ustr(self.expr) + "]"

        return self.strRepr


class SkipTo(ParseElementEnhance):
    """Token for skipping over all undefined text until the matched expression is found.
       If C{include} is set to true, the matched expression is also parsed (the skipped text
       and matched expression are returned as a 2-element list).  The C{ignore}
       argument is used to define grammars (typically quoted strings and comments) that
       might contain false matches.
    """
    def __init__( self, other, include=False, ignore=None, failOn=None ):
        super( SkipTo, self ).__init__( other )
        self.ignoreExpr = ignore
        self.mayReturnEmpty = True
        self.mayIndexError = False
        self.includeMatch = include
        self.asList = False
        if failOn is not None and isinstance(failOn, basestring):
            self.failOn = Literal(failOn)
        else:
            self.failOn = failOn
        self.errmsg = "No match found for "+_ustr(self.expr)

    def parseImpl( self, instring, loc, doActions=True ):
        startLoc = loc
        instrlen = len(instring)
        expr = self.expr
        failParse = False
        while loc <= instrlen:
            try:
                if self.failOn:
                    try:
                        self.failOn.tryParse(instring, loc)
                    except ParseBaseException:
                        pass
                    else:
                        failParse = True
                        raise ParseException(instring, loc, "Found expression " + str(self.failOn))
                    failParse = False
                if self.ignoreExpr is not None:
                    while 1:
                        try:
                            loc = self.ignoreExpr.tryParse(instring,loc)
                            # print "found ignoreExpr, advance to", loc
                        except ParseBaseException:
                            break
                expr._parse( instring, loc, doActions=False, callPreParse=False )
                skipText = instring[startLoc:loc]
                if self.includeMatch:
                    loc,mat = expr._parse(instring,loc,doActions,callPreParse=False)
                    if mat:
                        skipRes = ParseResults( skipText )
                        skipRes += mat
                        return loc, [ skipRes ]
                    else:
                        return loc, [ skipText ]
                else:
                    return loc, [ skipText ]
            except (ParseException,IndexError):
                if failParse:
                    raise
                else:
                    loc += 1
        exc = self.myException
        exc.loc = loc
        exc.pstr = instring
        raise exc

class Forward(ParseElementEnhance):
    """Forward declaration of an expression to be defined later -
       used for recursive grammars, such as algebraic infix notation.
       When the expression is known, it is assigned to the C{Forward} variable using the '<<' operator.

       Note: take care when assigning to C{Forward} not to overlook precedence of operators.
       Specifically, '|' has a lower precedence than '<<', so that::
          fwdExpr << a | b | c
       will actually be evaluated as::
          (fwdExpr << a) | b | c
       thereby leaving b and c out as parseable alternatives.  It is recommended that you
       explicitly group the values inserted into the C{Forward}::
          fwdExpr << (a | b | c)
       Converting to use the '<<=' operator instead will avoid this problem.
    """
    def __init__( self, other=None ):
        super(Forward,self).__init__( other, savelist=False )

    def __lshift__( self, other ):
        if isinstance( other, basestring ):
            other = ParserElement.literalStringClass(other)
        self.expr = other
        self.mayReturnEmpty = other.mayReturnEmpty
        self.strRepr = None
        self.mayIndexError = self.expr.mayIndexError
        self.mayReturnEmpty = self.expr.mayReturnEmpty
        self.setWhitespaceChars( self.expr.whiteChars )
        self.skipWhitespace = self.expr.skipWhitespace
        self.saveAsList = self.expr.saveAsList
        self.ignoreExprs.extend(self.expr.ignoreExprs)
        return None
    __ilshift__ = __lshift__
    
    def leaveWhitespace( self ):
        self.skipWhitespace = False
        return self

    def streamline( self ):
        if not self.streamlined:
            self.streamlined = True
            if self.expr is not None:
                self.expr.streamline()
        return self

    def validate( self, validateTrace=[] ):
        if self not in validateTrace:
            tmp = validateTrace[:]+[self]
            if self.expr is not None:
                self.expr.validate(tmp)
        self.checkRecursion([])

    def __str__( self ):
        if hasattr(self,"name"):
            return self.name

        self._revertClass = self.__class__
        self.__class__ = _ForwardNoRecurse
        try:
            if self.expr is not None:
                retString = _ustr(self.expr)
            else:
                retString = "None"
        finally:
            self.__class__ = self._revertClass
        return self.__class__.__name__ + ": " + retString

    def copy(self):
        if self.expr is not None:
            return super(Forward,self).copy()
        else:
            ret = Forward()
            ret << self
            return ret

class _ForwardNoRecurse(Forward):
    def __str__( self ):
        return "..."

class TokenConverter(ParseElementEnhance):
    """Abstract subclass of C{ParseExpression}, for converting parsed results."""
    def __init__( self, expr, savelist=False ):
        super(TokenConverter,self).__init__( expr )#, savelist )
        self.saveAsList = False

class Upcase(TokenConverter):
    """Converter to upper case all matching tokens."""
    def __init__(self, *args):
        super(Upcase,self).__init__(*args)
        warnings.warn("Upcase class is deprecated, use upcaseTokens parse action instead",
                       DeprecationWarning,stacklevel=2)

    def postParse( self, instring, loc, tokenlist ):
        return list(map( str.upper, tokenlist ))


class Combine(TokenConverter):
    """Converter to concatenate all matching tokens to a single string.
       By default, the matching patterns must also be contiguous in the input string;
       this can be disabled by specifying C{'adjacent=False'} in the constructor.
    """
    def __init__( self, expr, joinString="", adjacent=True ):
        super(Combine,self).__init__( expr )
        # suppress whitespace-stripping in contained parse expressions, but re-enable it on the Combine itself
        if adjacent:
            self.leaveWhitespace()
        self.adjacent = adjacent
        self.skipWhitespace = True
        self.joinString = joinString
        self.callPreparse = True

    def ignore( self, other ):
        if self.adjacent:
            ParserElement.ignore(self, other)
        else:
            super( Combine, self).ignore( other )
        return self

    def postParse( self, instring, loc, tokenlist ):
        retToks = tokenlist.copy()
        del retToks[:]
        retToks += ParseResults([ "".join(tokenlist._asStringList(self.joinString)) ], modal=self.modalResults)

        if self.resultsName and len(retToks.keys())>0:
            return [ retToks ]
        else:
            return retToks

class Group(TokenConverter):
    """Converter to return the matched tokens as a list - useful for returning tokens of C{L{ZeroOrMore}} and C{L{OneOrMore}} expressions."""
    def __init__( self, expr ):
        super(Group,self).__init__( expr )
        self.saveAsList = True

    def postParse( self, instring, loc, tokenlist ):
        return [ tokenlist ]

class Dict(TokenConverter):
    """Converter to return a repetitive expression as a list, but also as a dictionary.
       Each element can also be referenced using the first token in the expression as its key.
       Useful for tabular report scraping when the first column can be used as a item key.
    """
    def __init__( self, exprs ):
        super(Dict,self).__init__( exprs )
        self.saveAsList = True

    def postParse( self, instring, loc, tokenlist ):
        for i,tok in enumerate(tokenlist):
            if len(tok) == 0:
                continue
            ikey = tok[0]
            if isinstance(ikey,int):
                ikey = _ustr(tok[0]).strip()
            if len(tok)==1:
                tokenlist[ikey] = _ParseResultsWithOffset("",i)
            elif len(tok)==2 and not isinstance(tok[1],ParseResults):
                tokenlist[ikey] = _ParseResultsWithOffset(tok[1],i)
            else:
                dictvalue = tok.copy() #ParseResults(i)
                del dictvalue[0]
                if len(dictvalue)!= 1 or (isinstance(dictvalue,ParseResults) and dictvalue.keys()):
                    tokenlist[ikey] = _ParseResultsWithOffset(dictvalue,i)
                else:
                    tokenlist[ikey] = _ParseResultsWithOffset(dictvalue[0],i)

        if self.resultsName:
            return [ tokenlist ]
        else:
            return tokenlist


class Suppress(TokenConverter):
    """Converter for ignoring the results of a parsed expression."""
    def postParse( self, instring, loc, tokenlist ):
        return []

    def suppress( self ):
        return self


class OnlyOnce(object):
    """Wrapper for parse actions, to ensure they are only called once."""
    def __init__(self, methodCall):
        self.callable = _trim_arity(methodCall)
        self.called = False
    def __call__(self,s,l,t):
        if not self.called:
            results = self.callable(s,l,t)
            self.called = True
            return results
        raise ParseException(s,l,"")
    def reset(self):
        self.called = False

def traceParseAction(f):
    """Decorator for debugging parse actions."""
    f = _trim_arity(f)
    def z(*paArgs):
        thisFunc = f.func_name
        s,l,t = paArgs[-3:]
        if len(paArgs)>3:
            thisFunc = paArgs[0].__class__.__name__ + '.' + thisFunc
        sys.stderr.write( ">>entering %s(line: '%s', %d, %s)\n" % (thisFunc,line(l,s),l,t) )
        try:
            ret = f(*paArgs)
        except Exception, exc:
            sys.stderr.write( "<<leaving %s (exception: %s)\n" % (thisFunc,exc) )
            raise
        sys.stderr.write( "<<leaving %s (ret: %s)\n" % (thisFunc,ret) )
        return ret
    try:
        z.__name__ = f.__name__
    except AttributeError:
        pass
    return z

#
# global helpers
#
def delimitedList( expr, delim=",", combine=False ):
    """Helper to define a delimited list of expressions - the delimiter defaults to ','.
       By default, the list elements and delimiters can have intervening whitespace, and
       comments, but this can be overridden by passing C{combine=True} in the constructor.
       If C{combine} is set to C{True}, the matching tokens are returned as a single token
       string, with the delimiters included; otherwise, the matching tokens are returned
       as a list of tokens, with the delimiters suppressed.
    """
    dlName = _ustr(expr)+" ["+_ustr(delim)+" "+_ustr(expr)+"]..."
    if combine:
        return Combine( expr + ZeroOrMore( delim + expr ) ).setName(dlName)
    else:
        return ( expr + ZeroOrMore( Suppress( delim ) + expr ) ).setName(dlName)

def countedArray( expr, intExpr=None ):
    """Helper to define a counted list of expressions.
       This helper defines a pattern of the form::
           integer expr expr expr...
       where the leading integer tells how many expr expressions follow.
       The matched tokens returns the array of expr tokens as a list - the leading count token is suppressed.
    """
    arrayExpr = Forward()
    def countFieldParseAction(s,l,t):
        n = t[0]
        arrayExpr << (n and Group(And([expr]*n)) or Group(empty))
        return []
    if intExpr is None:
        intExpr = Word(nums).setParseAction(lambda t:int(t[0]))
    else:
        intExpr = intExpr.copy()
    intExpr.setName("arrayLen")
    intExpr.addParseAction(countFieldParseAction, callDuringTry=True)
    return ( intExpr + arrayExpr )

def _flatten(L):
    ret = []
    for i in L:
        if isinstance(i,list):
            ret.extend(_flatten(i))
        else:
            ret.append(i)
    return ret

def matchPreviousLiteral(expr):
    """Helper to define an expression that is indirectly defined from
       the tokens matched in a previous expression, that is, it looks
       for a 'repeat' of a previous expression.  For example::
           first = Word(nums)
           second = matchPreviousLiteral(first)
           matchExpr = first + ":" + second
       will match C{"1:1"}, but not C{"1:2"}.  Because this matches a
       previous literal, will also match the leading C{"1:1"} in C{"1:10"}.
       If this is not desired, use C{matchPreviousExpr}.
       Do *not* use with packrat parsing enabled.
    """
    rep = Forward()
    def copyTokenToRepeater(s,l,t):
        if t:
            if len(t) == 1:
                rep << t[0]
            else:
                # flatten t tokens
                tflat = _flatten(t.asList())
                rep << And( [ Literal(tt) for tt in tflat ] )
        else:
            rep << Empty()
    expr.addParseAction(copyTokenToRepeater, callDuringTry=True)
    return rep

def matchPreviousExpr(expr):
    """Helper to define an expression that is indirectly defined from
       the tokens matched in a previous expression, that is, it looks
       for a 'repeat' of a previous expression.  For example::
           first = Word(nums)
           second = matchPreviousExpr(first)
           matchExpr = first + ":" + second
       will match C{"1:1"}, but not C{"1:2"}.  Because this matches by
       expressions, will *not* match the leading C{"1:1"} in C{"1:10"};
       the expressions are evaluated first, and then compared, so
       C{"1"} is compared with C{"10"}.
       Do *not* use with packrat parsing enabled.
    """
    rep = Forward()
    e2 = expr.copy()
    rep << e2
    def copyTokenToRepeater(s,l,t):
        matchTokens = _flatten(t.asList())
        def mustMatchTheseTokens(s,l,t):
            theseTokens = _flatten(t.asList())
            if  theseTokens != matchTokens:
                raise ParseException("",0,"")
        rep.setParseAction( mustMatchTheseTokens, callDuringTry=True )
    expr.addParseAction(copyTokenToRepeater, callDuringTry=True)
    return rep

def _escapeRegexRangeChars(s):
    #~  escape these chars: ^-]
    for c in r"\^-]":
        s = s.replace(c,_bslash+c)
    s = s.replace("\n",r"\n")
    s = s.replace("\t",r"\t")
    return _ustr(s)

def oneOf( strs, caseless=False, useRegex=True ):
    """Helper to quickly define a set of alternative Literals, and makes sure to do
       longest-first testing when there is a conflict, regardless of the input order,
       but returns a C{L{MatchFirst}} for best performance.

       Parameters:
        - strs - a string of space-delimited literals, or a list of string literals
        - caseless - (default=False) - treat all literals as caseless
        - useRegex - (default=True) - as an optimization, will generate a Regex
          object; otherwise, will generate a C{MatchFirst} object (if C{caseless=True}, or
          if creating a C{Regex} raises an exception)
    """
    if caseless:
        isequal = ( lambda a,b: a.upper() == b.upper() )
        masks = ( lambda a,b: b.upper().startswith(a.upper()) )
        parseElementClass = CaselessLiteral
    else:
        isequal = ( lambda a,b: a == b )
        masks = ( lambda a,b: b.startswith(a) )
        parseElementClass = Literal

    if isinstance(strs,(list,tuple)):
        symbols = list(strs[:])
    elif isinstance(strs,basestring):
        symbols = strs.split()
    else:
        warnings.warn("Invalid argument to oneOf, expected string or list",
                SyntaxWarning, stacklevel=2)

    i = 0
    while i < len(symbols)-1:
        cur = symbols[i]
        for j,other in enumerate(symbols[i+1:]):
            if ( isequal(other, cur) ):
                del symbols[i+j+1]
                break
            elif ( masks(cur, other) ):
                del symbols[i+j+1]
                symbols.insert(i,other)
                cur = other
                break
        else:
            i += 1

    if not caseless and useRegex:
        #~ print (strs,"->", "|".join( [ _escapeRegexChars(sym) for sym in symbols] ))
        try:
            if len(symbols)==len("".join(symbols)):
                return Regex( "[%s]" % "".join( [ _escapeRegexRangeChars(sym) for sym in symbols] ) )
            else:
                return Regex( "|".join( [ re.escape(sym) for sym in symbols] ) )
        except:
            warnings.warn("Exception creating Regex for oneOf, building MatchFirst",
                    SyntaxWarning, stacklevel=2)


    # last resort, just use MatchFirst
    return MatchFirst( [ parseElementClass(sym) for sym in symbols ] )

def dictOf( key, value ):
    """Helper to easily and clearly define a dictionary by specifying the respective patterns
       for the key and value.  Takes care of defining the C{L{Dict}}, C{L{ZeroOrMore}}, and C{L{Group}} tokens
       in the proper order.  The key pattern can include delimiting markers or punctuation,
       as long as they are suppressed, thereby leaving the significant key text.  The value
       pattern can include named results, so that the C{Dict} results can include named token
       fields.
    """
    return Dict( ZeroOrMore( Group ( key + value ) ) )

def originalTextFor(expr, asString=True):
    """Helper to return the original, untokenized text for a given expression.  Useful to
       restore the parsed fields of an HTML start tag into the raw tag text itself, or to
       revert separate tokens with intervening whitespace back to the original matching
       input text. Simpler to use than the parse action C{L{keepOriginalText}}, and does not
       require the inspect module to chase up the call stack.  By default, returns a 
       string containing the original parsed text.  
       
       If the optional C{asString} argument is passed as C{False}, then the return value is a 
       C{L{ParseResults}} containing any results names that were originally matched, and a 
       single token containing the original matched text from the input string.  So if 
       the expression passed to C{L{originalTextFor}} contains expressions with defined
       results names, you must set C{asString} to C{False} if you want to preserve those
       results name values."""
    locMarker = Empty().setParseAction(lambda s,loc,t: loc)
    endlocMarker = locMarker.copy()
    endlocMarker.callPreparse = False
    matchExpr = locMarker("_original_start") + expr + endlocMarker("_original_end")
    if asString:
        extractText = lambda s,l,t: s[t._original_start:t._original_end]
    else:
        def extractText(s,l,t):
            del t[:]
            t.insert(0, s[t._original_start:t._original_end])
            del t["_original_start"]
            del t["_original_end"]
    matchExpr.setParseAction(extractText)
    return matchExpr

def ungroup(expr): 
    """Helper to undo pyparsing's default grouping of And expressions, even
       if all but one are non-empty."""
    return TokenConverter(expr).setParseAction(lambda t:t[0])

# convenience constants for positional expressions
empty       = Empty().setName("empty")
lineStart   = LineStart().setName("lineStart")
lineEnd     = LineEnd().setName("lineEnd")
stringStart = StringStart().setName("stringStart")
stringEnd   = StringEnd().setName("stringEnd")

_escapedPunc = Word( _bslash, r"\[]-*.$+^?()~ ", exact=2 ).setParseAction(lambda s,l,t:t[0][1])
_printables_less_backslash = "".join([ c for c in printables if c not in  r"\]" ])
_escapedHexChar = Regex(r"\\0?[xX][0-9a-fA-F]+").setParseAction(lambda s,l,t:unichr(int(t[0].lstrip(r'\0x'),16)))
_escapedOctChar = Regex(r"\\0[0-7]+").setParseAction(lambda s,l,t:unichr(int(t[0][1:],8)))
_singleChar = _escapedPunc | _escapedHexChar | _escapedOctChar | Word(_printables_less_backslash,exact=1)
_charRange = Group(_singleChar + Suppress("-") + _singleChar)
_reBracketExpr = Literal("[") + Optional("^").setResultsName("negate") + Group( OneOrMore( _charRange | _singleChar ) ).setResultsName("body") + "]"

_expanded = lambda p: (isinstance(p,ParseResults) and ''.join([ unichr(c) for c in range(ord(p[0]),ord(p[1])+1) ]) or p)

def srange(s):
    r"""Helper to easily define string ranges for use in Word construction.  Borrows
       syntax from regexp '[]' string range definitions::
          srange("[0-9]")   -> "0123456789"
          srange("[a-z]")   -> "abcdefghijklmnopqrstuvwxyz"
          srange("[a-z$_]") -> "abcdefghijklmnopqrstuvwxyz$_"
       The input string must be enclosed in []'s, and the returned string is the expanded
       character set joined into a single string.
       The values enclosed in the []'s may be::
          a single character
          an escaped character with a leading backslash (such as \- or \])
          an escaped hex character with a leading '\x' (\x21, which is a '!' character) 
            (\0x## is also supported for backwards compatibility) 
          an escaped octal character with a leading '\0' (\041, which is a '!' character)
          a range of any of the above, separated by a dash ('a-z', etc.)
          any combination of the above ('aeiouy', 'a-zA-Z0-9_$', etc.)
    """
    try:
        return "".join([_expanded(part) for part in _reBracketExpr.parseString(s).body])
    except:
        return ""

def matchOnlyAtCol(n):
    """Helper method for defining parse actions that require matching at a specific
       column in the input text.
    """
    def verifyCol(strg,locn,toks):
        if col(locn,strg) != n:
            raise ParseException(strg,locn,"matched token not at column %d" % n)
    return verifyCol

def replaceWith(replStr):
    """Helper method for common parse actions that simply return a literal value.  Especially
       useful when used with C{L{transformString<ParserElement.transformString>}()}.
    """
    def _replFunc(*args):
        return [replStr]
    return _replFunc

def removeQuotes(s,l,t):
    """Helper parse action for removing quotation marks from parsed quoted strings.
       To use, add this parse action to quoted string using::
         quotedString.setParseAction( removeQuotes )
    """
    return t[0][1:-1]

def upcaseTokens(s,l,t):
    """Helper parse action to convert tokens to upper case."""
    return [ tt.upper() for tt in map(_ustr,t) ]

def downcaseTokens(s,l,t):
    """Helper parse action to convert tokens to lower case."""
    return [ tt.lower() for tt in map(_ustr,t) ]

def keepOriginalText(s,startLoc,t):
    """DEPRECATED - use new helper method C{L{originalTextFor}}.
       Helper parse action to preserve original parsed text,
       overriding any nested parse actions."""
    try:
        endloc = getTokensEndLoc()
    except ParseException:
        raise ParseFatalException("incorrect usage of keepOriginalText - may only be called as a parse action")
    del t[:]
    t += ParseResults(s[startLoc:endloc])
    return t

def getTokensEndLoc():
    """Method to be called from within a parse action to determine the end
       location of the parsed tokens."""
    import inspect
    fstack = inspect.stack()
    try:
        # search up the stack (through intervening argument normalizers) for correct calling routine
        for f in fstack[2:]:
            if f[3] == "_parseNoCache":
                endloc = f[0].f_locals["loc"]
                return endloc
        else:
            raise ParseFatalException("incorrect usage of getTokensEndLoc - may only be called from within a parse action")
    finally:
        del fstack

def _makeTags(tagStr, xml):
    """Internal helper to construct opening and closing tag expressions, given a tag name"""
    if isinstance(tagStr,basestring):
        resname = tagStr
        tagStr = Keyword(tagStr, caseless=not xml)
    else:
        resname = tagStr.name

    tagAttrName = Word(alphas,alphanums+"_-:")
    if (xml):
        tagAttrValue = dblQuotedString.copy().setParseAction( removeQuotes )
        openTag = Suppress("<") + tagStr("tag") + \
                Dict(ZeroOrMore(Group( tagAttrName + Suppress("=") + tagAttrValue ))) + \
                Optional("/",default=[False]).setResultsName("empty").setParseAction(lambda s,l,t:t[0]=='/') + Suppress(">")
    else:
        printablesLessRAbrack = "".join( [ c for c in printables if c not in ">" ] )
        tagAttrValue = quotedString.copy().setParseAction( removeQuotes ) | Word(printablesLessRAbrack)
        openTag = Suppress("<") + tagStr("tag") + \
                Dict(ZeroOrMore(Group( tagAttrName.setParseAction(downcaseTokens) + \
                Optional( Suppress("=") + tagAttrValue ) ))) + \
                Optional("/",default=[False]).setResultsName("empty").setParseAction(lambda s,l,t:t[0]=='/') + Suppress(">")
    closeTag = Combine(_L("</") + tagStr + ">")

    openTag = openTag.setResultsName("start"+"".join(resname.replace(":"," ").title().split())).setName("<%s>" % tagStr)
    closeTag = closeTag.setResultsName("end"+"".join(resname.replace(":"," ").title().split())).setName("</%s>" % tagStr)
    openTag.tag = resname
    closeTag.tag = resname
    return openTag, closeTag

def makeHTMLTags(tagStr):
    """Helper to construct opening and closing tag expressions for HTML, given a tag name"""
    return _makeTags( tagStr, False )

def makeXMLTags(tagStr):
    """Helper to construct opening and closing tag expressions for XML, given a tag name"""
    return _makeTags( tagStr, True )

def withAttribute(*args,**attrDict):
    """Helper to create a validating parse action to be used with start tags created
       with C{L{makeXMLTags}} or C{L{makeHTMLTags}}. Use C{withAttribute} to qualify a starting tag
       with a required attribute value, to avoid false matches on common tags such as
       C{<TD>} or C{<DIV>}.

       Call C{withAttribute} with a series of attribute names and values. Specify the list
       of filter attributes names and values as:
        - keyword arguments, as in C{(align="right")}, or
        - as an explicit dict with C{**} operator, when an attribute name is also a Python
          reserved word, as in C{**{"class":"Customer", "align":"right"}}
        - a list of name-value tuples, as in ( ("ns1:class", "Customer"), ("ns2:align","right") )
       For attribute names with a namespace prefix, you must use the second form.  Attribute
       names are matched insensitive to upper/lower case.

       To verify that the attribute exists, but without specifying a value, pass
       C{withAttribute.ANY_VALUE} as the value.
       """
    if args:
        attrs = args[:]
    else:
        attrs = attrDict.items()
    attrs = [(k,v) for k,v in attrs]
    def pa(s,l,tokens):
        for attrName,attrValue in attrs:
            if attrName not in tokens:
                raise ParseException(s,l,"no matching attribute " + attrName)
            if attrValue != withAttribute.ANY_VALUE and tokens[attrName] != attrValue:
                raise ParseException(s,l,"attribute '%s' has value '%s', must be '%s'" %
                                            (attrName, tokens[attrName], attrValue))
    return pa
withAttribute.ANY_VALUE = object()

opAssoc = _Constants()
opAssoc.LEFT = object()
opAssoc.RIGHT = object()

def infixNotation( baseExpr, opList, lpar=Suppress('('), rpar=Suppress(')') ):
    """Helper method for constructing grammars of expressions made up of
       operators working in a precedence hierarchy.  Operators may be unary or
       binary, left- or right-associative.  Parse actions can also be attached
       to operator expressions.

       Parameters:
        - baseExpr - expression representing the most basic element for the nested
        - opList - list of tuples, one for each operator precedence level in the
          expression grammar; each tuple is of the form
          (opExpr, numTerms, rightLeftAssoc, parseAction), where:
           - opExpr is the pyparsing expression for the operator;
              may also be a string, which will be converted to a Literal;
              if numTerms is 3, opExpr is a tuple of two expressions, for the
              two operators separating the 3 terms
           - numTerms is the number of terms for this operator (must
              be 1, 2, or 3)
           - rightLeftAssoc is the indicator whether the operator is
              right or left associative, using the pyparsing-defined
              constants C{opAssoc.RIGHT} and C{opAssoc.LEFT}.
           - parseAction is the parse action to be associated with
              expressions matching this operator expression (the
              parse action tuple member may be omitted)
        - lpar - expression for matching left-parentheses (default=Suppress('('))
        - rpar - expression for matching right-parentheses (default=Suppress(')'))
    """
    ret = Forward()
    lastExpr = baseExpr | ( lpar + ret + rpar )
    for i,operDef in enumerate(opList):
        opExpr,arity,rightLeftAssoc,pa = (operDef + (None,))[:4]
        if arity == 3:
            if opExpr is None or len(opExpr) != 2:
                raise ValueError("if numterms=3, opExpr must be a tuple or list of two expressions")
            opExpr1, opExpr2 = opExpr
        thisExpr = Forward()#.setName("expr%d" % i)
        if rightLeftAssoc == opAssoc.LEFT:
            if arity == 1:
                matchExpr = FollowedBy(lastExpr + opExpr) + Group( lastExpr + OneOrMore( opExpr ) )
            elif arity == 2:
                if opExpr is not None:
                    matchExpr = FollowedBy(lastExpr + opExpr + lastExpr) + Group( lastExpr + OneOrMore( opExpr + lastExpr ) )
                else:
                    matchExpr = FollowedBy(lastExpr+lastExpr) + Group( lastExpr + OneOrMore(lastExpr) )
            elif arity == 3:
                matchExpr = FollowedBy(lastExpr + opExpr1 + lastExpr + opExpr2 + lastExpr) + \
                            Group( lastExpr + opExpr1 + lastExpr + opExpr2 + lastExpr )
            else:
                raise ValueError("operator must be unary (1), binary (2), or ternary (3)")
        elif rightLeftAssoc == opAssoc.RIGHT:
            if arity == 1:
                # try to avoid LR with this extra test
                if not isinstance(opExpr, Optional):
                    opExpr = Optional(opExpr)
                matchExpr = FollowedBy(opExpr.expr + thisExpr) + Group( opExpr + thisExpr )
            elif arity == 2:
                if opExpr is not None:
                    matchExpr = FollowedBy(lastExpr + opExpr + thisExpr) + Group( lastExpr + OneOrMore( opExpr + thisExpr ) )
                else:
                    matchExpr = FollowedBy(lastExpr + thisExpr) + Group( lastExpr + OneOrMore( thisExpr ) )
            elif arity == 3:
                matchExpr = FollowedBy(lastExpr + opExpr1 + thisExpr + opExpr2 + thisExpr) + \
                            Group( lastExpr + opExpr1 + thisExpr + opExpr2 + thisExpr )
            else:
                raise ValueError("operator must be unary (1), binary (2), or ternary (3)")
        else:
            raise ValueError("operator must indicate right or left associativity")
        if pa:
            matchExpr.setParseAction( pa )
        thisExpr << ( matchExpr | lastExpr )
        lastExpr = thisExpr
    ret << lastExpr
    return ret
operatorPrecedence = infixNotation

dblQuotedString = Regex(r'"(?:[^"\n\r\\]|(?:"")|(?:\\x[0-9a-fA-F]+)|(?:\\.))*"').setName("string enclosed in double quotes")
sglQuotedString = Regex(r"'(?:[^'\n\r\\]|(?:'')|(?:\\x[0-9a-fA-F]+)|(?:\\.))*'").setName("string enclosed in single quotes")
quotedString = Regex(r'''(?:"(?:[^"\n\r\\]|(?:"")|(?:\\x[0-9a-fA-F]+)|(?:\\.))*")|(?:'(?:[^'\n\r\\]|(?:'')|(?:\\x[0-9a-fA-F]+)|(?:\\.))*')''').setName("quotedString using single or double quotes")
unicodeString = Combine(_L('u') + quotedString.copy())

def nestedExpr(opener="(", closer=")", content=None, ignoreExpr=quotedString.copy()):
    """Helper method for defining nested lists enclosed in opening and closing
       delimiters ("(" and ")" are the default).

       Parameters:
        - opener - opening character for a nested list (default="("); can also be a pyparsing expression
        - closer - closing character for a nested list (default=")"); can also be a pyparsing expression
        - content - expression for items within the nested lists (default=None)
        - ignoreExpr - expression for ignoring opening and closing delimiters (default=quotedString)

       If an expression is not provided for the content argument, the nested
       expression will capture all whitespace-delimited content between delimiters
       as a list of separate values.

       Use the C{ignoreExpr} argument to define expressions that may contain
       opening or closing characters that should not be treated as opening
       or closing characters for nesting, such as quotedString or a comment
       expression.  Specify multiple expressions using an C{L{Or}} or C{L{MatchFirst}}.
       The default is L{quotedString}, but if no expressions are to be ignored,
       then pass C{None} for this argument.
    """
    if opener == closer:
        raise ValueError("opening and closing strings cannot be the same")
    if content is None:
        if isinstance(opener,basestring) and isinstance(closer,basestring):
            if len(opener) == 1 and len(closer)==1:
                if ignoreExpr is not None:
                    content = (Combine(OneOrMore(~ignoreExpr +
                                    CharsNotIn(opener+closer+ParserElement.DEFAULT_WHITE_CHARS,exact=1))
                                ).setParseAction(lambda t:t[0].strip()))
                else:
                    content = (empty.copy()+CharsNotIn(opener+closer+ParserElement.DEFAULT_WHITE_CHARS
                                ).setParseAction(lambda t:t[0].strip()))
            else:
                if ignoreExpr is not None:
                    content = (Combine(OneOrMore(~ignoreExpr + 
                                    ~Literal(opener) + ~Literal(closer) +
                                    CharsNotIn(ParserElement.DEFAULT_WHITE_CHARS,exact=1))
                                ).setParseAction(lambda t:t[0].strip()))
                else:
                    content = (Combine(OneOrMore(~Literal(opener) + ~Literal(closer) +
                                    CharsNotIn(ParserElement.DEFAULT_WHITE_CHARS,exact=1))
                                ).setParseAction(lambda t:t[0].strip()))
        else:
            raise ValueError("opening and closing arguments must be strings if no content expression is given")
    ret = Forward()
    if ignoreExpr is not None:
        ret << Group( Suppress(opener) + ZeroOrMore( ignoreExpr | ret | content ) + Suppress(closer) )
    else:
        ret << Group( Suppress(opener) + ZeroOrMore( ret | content )  + Suppress(closer) )
    return ret

def indentedBlock(blockStatementExpr, indentStack, indent=True):
    """Helper method for defining space-delimited indentation blocks, such as
       those used to define block statements in Python source code.

       Parameters:
        - blockStatementExpr - expression defining syntax of statement that
            is repeated within the indented block
        - indentStack - list created by caller to manage indentation stack
            (multiple statementWithIndentedBlock expressions within a single grammar
            should share a common indentStack)
        - indent - boolean indicating whether block must be indented beyond the
            the current level; set to False for block of left-most statements
            (default=True)

       A valid block must contain at least one C{blockStatement}.
    """
    def checkPeerIndent(s,l,t):
        if l >= len(s): return
        curCol = col(l,s)
        if curCol != indentStack[-1]:
            if curCol > indentStack[-1]:
                raise ParseFatalException(s,l,"illegal nesting")
            raise ParseException(s,l,"not a peer entry")

    def checkSubIndent(s,l,t):
        curCol = col(l,s)
        if curCol > indentStack[-1]:
            indentStack.append( curCol )
        else:
            raise ParseException(s,l,"not a subentry")

    def checkUnindent(s,l,t):
        if l >= len(s): return
        curCol = col(l,s)
        if not(indentStack and curCol < indentStack[-1] and curCol <= indentStack[-2]):
            raise ParseException(s,l,"not an unindent")
        indentStack.pop()

    NL = OneOrMore(LineEnd().setWhitespaceChars("\t ").suppress())
    INDENT = Empty() + Empty().setParseAction(checkSubIndent)
    PEER   = Empty().setParseAction(checkPeerIndent)
    UNDENT = Empty().setParseAction(checkUnindent)
    if indent:
        smExpr = Group( Optional(NL) +
            #~ FollowedBy(blockStatementExpr) +
            INDENT + (OneOrMore( PEER + Group(blockStatementExpr) + Optional(NL) )) + UNDENT)
    else:
        smExpr = Group( Optional(NL) +
            (OneOrMore( PEER + Group(blockStatementExpr) + Optional(NL) )) )
    blockStatementExpr.ignore(_bslash + LineEnd())
    return smExpr

alphas8bit = srange(r"[\0xc0-\0xd6\0xd8-\0xf6\0xf8-\0xff]")
punc8bit = srange(r"[\0xa1-\0xbf\0xd7\0xf7]")

anyOpenTag,anyCloseTag = makeHTMLTags(Word(alphas,alphanums+"_:"))
commonHTMLEntity = Combine(_L("&") + oneOf("gt lt amp nbsp quot").setResultsName("entity") +";").streamline()
_htmlEntityMap = dict(zip("gt lt amp nbsp quot".split(),'><& "'))
replaceHTMLEntity = lambda t : t.entity in _htmlEntityMap and _htmlEntityMap[t.entity] or None

# it's easy to get these comment structures wrong - they're very common, so may as well make them available
cStyleComment = Regex(r"/\*(?:[^*]*\*+)+?/").setName("C style comment")

htmlComment = Regex(r"<!--[\s\S]*?-->")
restOfLine = Regex(r".*").leaveWhitespace()
dblSlashComment = Regex(r"\/\/(\\\n|.)*").setName("// comment")
cppStyleComment = Regex(r"/(?:\*(?:[^*]*\*+)+?/|/[^\n]*(?:\n[^\n]*)*?(?:(?<!\\)|\Z))").setName("C++ style comment")

javaStyleComment = cppStyleComment
pythonStyleComment = Regex(r"#.*").setName("Python style comment")
_noncomma = "".join( [ c for c in printables if c != "," ] )
_commasepitem = Combine(OneOrMore(Word(_noncomma) +
                                  Optional( Word(" \t") +
                                            ~Literal(",") + ~LineEnd() ) ) ).streamline().setName("commaItem")
commaSeparatedList = delimitedList( Optional( quotedString.copy() | _commasepitem, default="") ).setName("commaSeparatedList")


if __name__ == "__main__":

    def test( teststring ):
        try:
            tokens = simpleSQL.parseString( teststring )
            tokenlist = tokens.asList()
            print (teststring + "->"   + str(tokenlist))
            print ("tokens = "         + str(tokens))
            print ("tokens.columns = " + str(tokens.columns))
            print ("tokens.tables = "  + str(tokens.tables))
            print (tokens.asXML("SQL",True))
        except ParseBaseException, err:
            print (teststring + "->")
            print (err.line)
            print (" "*(err.column-1) + "^")
            print (err)
        print()

    selectToken    = CaselessLiteral( "select" )
    fromToken      = CaselessLiteral( "from" )

    ident          = Word( alphas, alphanums + "_$" )
    columnName     = delimitedList( ident, ".", combine=True ).setParseAction( upcaseTokens )
    columnNameList = Group( delimitedList( columnName ) )#.setName("columns")
    tableName      = delimitedList( ident, ".", combine=True ).setParseAction( upcaseTokens )
    tableNameList  = Group( delimitedList( tableName ) )#.setName("tables")
    simpleSQL      = ( selectToken + \
                     ( '*' | columnNameList ).setResultsName( "columns" ) + \
                     fromToken + \
                     tableNameList.setResultsName( "tables" ) )

    test( "SELECT * from XYZZY, ABC" )
    test( "select * from SYS.XYZZY" )
    test( "Select A from Sys.dual" )
    test( "Select AA,BB,CC from Sys.dual" )
    test( "Select A, B, C from Sys.dual" )
    test( "Select A, B, C from Sys.dual" )
    test( "Xelect A, B, C from Sys.dual" )
    test( "Select A, B, C frox Sys.dual" )
    test( "Select" )
    test( "Select ^^^ frox Sys.dual" )
    test( "Select A, B, C from Sys.dual, Table2   " )

########NEW FILE########
__FILENAME__ = prettytable
#!/usr/bin/env python
#
# Copyright (c) 2009, Luke Maurits <luke@maurits.id.au>
# All rights reserved.
# With contributions from:
#  * Chris Clark
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
# * Redistributions of source code must retain the above copyright notice,
#   this list of conditions and the following disclaimer.
# * Redistributions in binary form must reproduce the above copyright notice,
#   this list of conditions and the following disclaimer in the documentation
#   and/or other materials provided with the distribution.
# * The name of the author may not be used to endorse or promote products
#   derived from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.

# NOTE: This is external code.
# We don't do automatic Eclipse PyDev code analysis for it.
#@PydevCodeAnalysisIgnore

__version__ = "TRUNK"

import cgi
import copy
import cPickle
import random
import sys

# hrule styles
FRAME = 0
ALL   = 1
NONE  = 2

# Table styles
DEFAULT = 10
MSWORD_FRIENDLY = 11
PLAIN_COLUMNS = 12
RANDOM = 20

def cache_clearing(method):
    def wrapper(self, *args, **kwargs):
        method(self, *args, **kwargs)
        self._cache = {}
        self.html_cache = {}
    return wrapper

def _get_size(text):
    max_width = 0
    max_height = 0
    text = _unicode(text)
    for line in text.split("\n"):
        max_height += 1
        if len(line) > max_width:
            max_width = len(line)

    return (max_width, max_height)

def _get_row_height(row):
    max_height = 0
    for c in row:
        h = _get_size(c)[1]
        if h > max_height:
            max_height = h

    return max_height

def _unicode(value, encoding="UTF-8"):
    if not isinstance(value, basestring):
        value = str(value)
    if not isinstance(value, unicode):
        value = unicode(value, encoding, "replace")
    return value

class PrettyTable(object):

    def __init__(self, field_names=None, **kwargs):

        """Return a new PrettyTable instance

        Arguments:

        field_names - list or tuple of field names
        fields - list or tuple of field names to include in displays
        caching - boolean value to turn string caching on/off
        start - index of first data row to include in output
        end - index of last data row to include in output PLUS ONE (list slice style)
        fields - names of fields (columns) to include
        header - print a header showing field names (True or False)
        border - print a border around the table (True or False)
        hrules - controls printing of horizontal rules after rows.  Allowed values: FRAME, ALL, NONE
        padding_width - number of spaces on either side of column data (only used if left and right paddings are None)
        left_padding_width - number of spaces on left hand side of column data
        right_padding_width - number of spaces on right hand side of column data
        vertical_char - single character string used to draw vertical lines
        horizontal_char - single character string used to draw horizontal lines
        junction_char - single character string used to draw line junctions
        sortby - name of field to sort rows by
        reversesort - True or False to sort in descending or ascending order"""

        # Data
        self._field_names = []
        self._align = {}
        self._rows = []
        if field_names:
            self.field_names = field_names
        else:
            self._widths = []
        self._rows = []
        self._cache = {}
        self.html_cache = {}

        # Options
        self._options = "start end fields header border sortby reversesort attributes format hrules caching".split()
        self._options.extend("padding_width left_padding_width right_padding_width".split())
        self._options.extend("vertical_char horizontal_char junction_char".split())
        for option in self._options:
            if option in kwargs:
                self._validate_option(option, kwargs[option])
            else:
                kwargs[option] = None

        self._caching = kwargs["caching"] or True

        self._start = kwargs["start"] or 0
        self._end = kwargs["end"] or None
        self._fields = kwargs["fields"] or None

        self._header = kwargs["header"] or True
        self._border = kwargs["border"] or True
        self._hrules = kwargs["hrules"] or FRAME

        self._sortby = kwargs["sortby"] or None
        self._reversesort = kwargs["reversesort"] or False

        self._padding_width = kwargs["padding_width"] or 1
        self._left_padding_width = kwargs["left_padding_width"] or None
        self._right_padding_width = kwargs["right_padding_width"] or None

        self._vertical_char = kwargs["vertical_char"] or "|"
        self._horizontal_char = kwargs["horizontal_char"] or "-"
        self._junction_char = kwargs["junction_char"] or "+"

        self._format = kwargs["format"] or False
        self._attributes = kwargs["attributes"] or {}

    def __getattr__(self, name):

        if name == "rowcount":
            return len(self._rows)
        elif name == "colcount":
            return len(self._field_names)
        else:
            raise AttributeError, name

    def __getslice__(self, i, j):
        """Return a new PrettyTable whose data rows are a slice of this one's

        Arguments:

        i - beginning slice index
        j - ending slice index"""

        newtable = copy.deepcopy(self)
        newtable.rows = self._rows[i:j]
        return newtable

    def __str__(self):
        return self.get_string().encode("ascii","replace")

    def __unicode__(self):
        return self.get_string()

    ##############################
    # ATTRIBUTE VALIDATORS       #
    ##############################

    # The method _validate_option is all that should be used elsewhere in the code base to validate options.
    # It will call the appropriate validation method for that option.  The individual validation methods should
    # never need to be called directly (although nothing bad will happen if they *are*).
    # Validation happens in TWO places.
    # Firstly, in the property setters defined in the ATTRIBUTE MANAGMENT section.
    # Secondly, in the _get_options method, where keyword arguments are mixed with persistent settings

    def _validate_option(self, option, val):
        if option in ("start", "end", "padding_width", "left_padding_width", "right_padding_width", "format"):
            self._validate_nonnegative_int(option, val)
        elif option in ("sortby"):
            self._validate_field_name(option, val)
        elif option in ("hrules"):
            self._validate_hrules(option, val)
        elif option in ("fields"):
            self._validate_all_field_names(option, val)
        elif option in ("header", "border", "caching", "reversesort"):
            self._validate_true_or_false(option, val)
        elif option in ("vertical_char", "horizontal_char", "junction_char"):
            self._validate_single_char(option, val)
        elif option in ("attributes"):
            self._validate_attributes(option, val)
        else:
            raise Exception("Unrecognised option: %s!" % option)

    def _validate_align(self, val):
        try:
            assert val in ["l","c","r"]
        except AssertionError:
            raise Exception("Alignment %s is invalid, use l, c or r!" % val)

    def _validate_nonnegative_int(self, name, val):
        try:
            assert int(val) >= 0
        except AssertionError:
            raise Exception("Invalid value for %s: %s!" % (name, _unicode(val)))

    def _validate_true_or_false(self, name, val):
        try:
            assert val in (True, False)
        except AssertionError:
            raise Exception("Invalid value for %s!  Must be True or False." % name)

    def _validate_hrules(self, name, val):
        try:
            assert val in (ALL, FRAME, NONE)
        except AssertionError:
            raise Exception("Invalid value for %s!  Must be ALL, FRAME or NONE." % name)

    def _validate_field_name(self, name, val):
        try:
            assert val in self._field_names
        except AssertionError:
            raise Exception("Invalid field name: %s!" % val)

    def _validate_all_field_names(self, name, val):
        try:
            for x in val:
                self._validate_field_name(name, x)
        except AssertionError:
            raise Exception("fields must be a sequence of field names!")

    def _validate_single_char(self, name, val):
        try:
            assert len(_unicode(val)) == 1
        except AssertionError:
            raise Exception("Invalid value for %s!  Must be a string of length 1." % name)

    def _validate_attributes(self, name, val):
        try:
            assert isinstance(val, dict)
        except AssertionError:
            raise Exception("attributes must be a dictionary of name/value pairs!")

    ##############################
    # ATTRIBUTE MANAGEMENT       #
    ##############################

    def _get_field_names(self):
        return self._field_names
        """The names of the fields

        Arguments:

        fields - list or tuple of field names"""
    @cache_clearing
    def _set_field_names(self, val):
        if self._field_names:
            old_names = self._field_names[:]
        self._field_names = val
        self._recompute_widths()
        if self._align:
            for old_name, new_name in zip(old_names, val):
                self._align[new_name] = self._align[old_name]
            for old_name in old_names:
                self._align.pop(old_name)
        else:
            for field in self._field_names:
                self._align[field] = "c"
    field_names = property(_get_field_names, _set_field_names)

    def _get_align(self):
        return self._align

    @cache_clearing
    def _set_align(self, val):
        self._validate_align(val)
        for field in self._field_names:
            self._align[field] = val
    align = property(_get_align, _set_align)

    def _get_start(self):
        """Start index of the range of rows to print

        Arguments:

        start - index of first data row to include in output"""
        return self._start

    def _set_start(self, val):
        self._validate_option("start", val)
        self._start = val
    start = property(_get_start, _set_start)

    def _get_end(self):
        """End index of the range of rows to print

        Arguments:

        end - index of last data row to include in output PLUS ONE (list slice style)"""
        return self._end
    def _set_end(self, val):
        self._validate_option("end", val)
        self._end = val
    end = property(_get_end, _set_end)

    def _get_sortby(self):
        """Name of field by which to sort rows

        Arguments:

        sortby - field name to sort by"""
        return self._sortby
    def _set_sortby(self, val):
        self._validate_option("sortby", val)
        self._sortby = val
    sortby = property(_get_sortby, _set_sortby)

    def _get_reversesort(self):
        """Controls direction of sorting (ascending vs descending)

        Arguments:

        reveresort - set to True to sort by descending order, or False to sort by ascending order"""
        return self._reversesort
    def _set_reversesort(self, val):
        self._validate_option("reversesort", val)
        self._reversesort = val
    reversesort = property(_get_reversesort, _set_reversesort)

    def _get_header(self):
        """Controls printing of table header with field names

        Arguments:

        header - print a header showing field names (True or False)"""
        return self._header
    def _set_header(self, val):
        self._validate_option("header", val)
        self._header = val
    header = property(_get_header, _set_header)

    def _get_border(self):
        """Controls printing of border around table

        Arguments:

        border - print a border around the table (True or False)"""
        return self._border
    def _set_border(self, val):
        self._validate_option("border", val)
        self._border = val
    border = property(_get_border, _set_border)

    def _get_hrules(self):
        """Controls printing of horizontal rules after rows

        Arguments:

        hrules - horizontal rules style.  Allowed values: FRAME, ALL, NONE"""
        return self._hrules
    def _set_hrules(self, val):
        self._validate_option("hrules", val)
        self._hrules = val
    hrules = property(_get_hrules, _set_hrules)

    def _get_padding_width(self):
        """The number of empty spaces between a column's edge and its content

        Arguments:

        padding_width - number of spaces, must be a positive integer"""
        return self._padding_width
    def _set_padding_width(self, val):
        self._validate_option("padding_width", val)
        self._padding_width = val
    padding_width = property(_get_padding_width, _set_padding_width)

    def _get_left_padding_width(self):
        """The number of empty spaces between a column's left edge and its content

        Arguments:

        left_padding - number of spaces, must be a positive integer"""
        return self._left_padding_width
    def _set_left_padding_width(self, val):
        self._validate_option("left_padding_width", val)
        self._left_padding_width = val
    left_padding_width = property(_get_left_padding_width, _set_left_padding_width)

    def _get_right_padding_width(self):
        """The number of empty spaces between a column's right edge and its content

        Arguments:

        right_padding - number of spaces, must be a positive integer"""
        return self._right_padding_width
    def _set_right_padding_width(self, val):
        self._validate_option("right_padding_width", val)
        self._right_padding_width = val
    right_padding_width = property(_get_right_padding_width, _set_right_padding_width)

    def _get_vertical_char(self):
        """The charcter used when printing table borders to draw vertical lines

        Arguments:

        vertical_char - single character string used to draw vertical lines"""
        return self._vertical_char
    def _set_vertical_char(self, val):
        self._validate_option("vertical_char", val)
        self._vertical_char = val
    vertical_char = property(_get_vertical_char, _set_vertical_char)

    def _get_horizontal_char(self):
        """The charcter used when printing table borders to draw horizontal lines

        Arguments:

        horizontal_char - single character string used to draw horizontal lines"""
        return self._horizontal_char
    def _set_horizontal_char(self, val):
        self._validate_option("horizontal_char", val)
        self._horizontal_char = val
    horizontal_char = property(_get_horizontal_char, _set_horizontal_char)

    def _get_junction_char(self):
        """The charcter used when printing table borders to draw line junctions

        Arguments:

        junction_char - single character string used to draw line junctions"""
        return self._junction_char
    def _set_junction_char(self, val):
        self._validate_option("vertical_char", val)
        self._junction_char = val
    junction_char = property(_get_junction_char, _set_junction_char)

    def _get_format(self):
        """Controls whether or not HTML tables are formatted to match styling options

        Arguments:

        format - True or False"""
        return self._format
    def _set_format(self, val):
        self._validate_option("format", val)
        self._format = val
    format = property(_get_format, _set_format)

    def _get_attributes(self):
        """A dictionary of HTML attribute name/value pairs to be included in the <table> tag when printing HTML

        Arguments:

        attributes - dictionary of attributes"""
        return self._attributes
    def _set_attributes(self, val):
        self.validate_option("attributes", val)
        self._attributes = val
    attributes = property(_get_attributes, _set_attributes)

    ##############################
    # OPTION MIXER               #
    ##############################

    def _get_options(self, kwargs):

        options = {}
        for option in self._options:
            if option in kwargs:
                self._validate_option(option, kwargs[option])
                options[option] = kwargs[option]
            else:
                options[option] = getattr(self, "_"+option)
        return options

    ##############################
    # PRESET STYLE LOGIC         #
    ##############################

    def set_style(self, style):

        if style == DEFAULT:
            self._set_default_style()
        elif style == MSWORD_FRIENDLY:
            self._set_msword_style()
        elif style == PLAIN_COLUMNS:
            self._set_columns_style()
        elif style == RANDOM:
            self._set_random_style()
        else:
            raise Exception("Invalid pre-set style!")

    def _set_default_style(self):

        self.header = True
        self.border = True
        self.hrules = FRAME
        self.padding_width = 1
        self.left_padding_width = 1
        self.right_padding_width = 1
        self.vertical_char = "|"
        self.horizontal_char = "-"
        self.junction_char = "+"

    def _set_msword_style(self):

        self.header = True
        self.border = True
        self.hrules = NONE
        self.padding_width = 1
        self.left_padding_width = 1
        self.right_padding_width = 1
        self.vertical_char = "|"

    def _set_columns_style(self):

        self.header = True
        self.border = False
        self.padding_width = 1
        self.left_padding_width = 0
        self.right_padding_width = 8

    def _set_random_style(self):

        # Just for fun!
        self.header = random.choice((True, False))
        self.border = random.choice((True, False))
        self.hrules = random.choice((ALL, FRAME, NONE))
        self.left_padding_width = random.randint(0,5)
        self.right_padding_width = random.randint(0,5)
        self.vertical_char = random.choice("~!@#$%^&*()_+|-=\{}[];':\",./;<>?")
        self.horizontal_char = random.choice("~!@#$%^&*()_+|-=\{}[];':\",./;<>?")
        self.junction_char = random.choice("~!@#$%^&*()_+|-=\{}[];':\",./;<>?")

    ##############################
    # DATA INPUT METHODS         #
    ##############################

    @cache_clearing
    def add_row(self, row):

        """Add a row to the table

        Arguments:

        row - row of data, should be a list with as many elements as the table
        has fields"""

        if len(row) != len(self._field_names):
            raise Exception("Row has incorrect number of values, (actual) %d!=%d (expected)" %(len(row),len(self._field_names)))
        self._rows.append(row)
        for i in range(0,len(row)):
            if _get_size(_unicode(row[i]))[0] > self._widths[i]:
                self._widths[i] = _get_size(_unicode(row[i]))[0]

    @cache_clearing
    def del_row(self, row_index):

        """Delete a row to the table

        Arguments:

        row_index - The index of the row you want to delete.  Indexing starts at 0."""

        if row_index > len(self._rows)-1:
            raise Exception("Cant delete row at index %d, table only has %d rows!" % (row_index, len(self._rows)))
        del self._rows[row_index]
        self._recompute_widths()

    @cache_clearing
    def add_column(self, fieldname, column, align="c"):

        """Add a column to the table.

        Arguments:

        fieldname - name of the field to contain the new column of data
        column - column of data, should be a list with as many elements as the
        table has rows
        align - desired alignment for this column - "l" for left, "c" for centre and "r" for right"""

        if len(self._rows) in (0, len(column)):
            self._validate_align(align)
            self._field_names.append(fieldname)
            self._widths.append(_get_size(fieldname)[0])
            self._align[fieldname] = align
            for i in range(0, len(column)):
                if len(self._rows) < i+1:
                    self._rows.append([])
                self._rows[i].append(column[i])
                if _get_size(_unicode(column[i]))[0] > self._widths[-1]:
                    self._widths[-1] = _get_size(_unicode(column[i]))[0]
        else:
            raise Exception("Column length %d does not match number of rows %d!" % (len(column), len(self._rows)))

    @cache_clearing
    def clear_rows(self):

        """Delete all rows from the table but keep the current field names"""

        self._rows = []
        self._widths = [_get_size(_unicode(field_name))[0] for field_name in self._field_names]

    @cache_clearing
    def clear(self):

        """Delete all rows and field names from the table, maintaining nothing but styling options"""

        self._rows = []
        self._field_names = []
        self._widths = []

    ##############################
    # MISC PUBLIC METHODS        #
    ##############################

    def copy(self):
        return copy.deepcopy(self)

    ##############################
    # MISC PRIVATE METHODS       #
    ##############################

    def _recompute_widths(self):
        self._widths = [_get_size(field)[0] for field in self._field_names]
        for row in self._rows:
            for i in range(0,len(row)):
                if _get_size(_unicode(row[i]))[0] > self._widths[i]:
                    self._widths[i] = _get_size(_unicode(row[i]))[0]

    def _get_padding_widths(self, options):

        if options["left_padding_width"] is not None:
            lpad = options["left_padding_width"]
        else:
            lpad = options["padding_width"]
        if options["right_padding_width"] is not None:
            rpad = options["right_padding_width"]
        else:
            rpad = options["padding_width"]
        return lpad, rpad

    def _get_sorted_rows(self, options):
        # Sort rows using the "Decorate, Sort, Undecorate" (DSU) paradigm
        rows = copy.deepcopy(self._rows[options["start"]:options["end"]])
        sortindex = self._field_names.index(options["sortby"])
        # Decorate
        rows = [[row[sortindex]]+row for row in rows]
        # Sort
        rows.sort(reverse=options["reversesort"])
        # Undecorate
        rows = [row[1:] for row in rows]
        return rows

    ##############################
    # ASCII PRINT/STRING METHODS #
    ##############################

    def printt(self, **kwargs):

        """Print table in current state to stdout.

        Arguments:

        start - index of first data row to include in output
        end - index of last data row to include in output PLUS ONE (list slice style)
        fields - names of fields (columns) to include
        header - print a header showing field names (True or False)
        border - print a border around the table (True or False)
        hrules - controls printing of horizontal rules after rows.  Allowed values: FRAME, ALL, NONE
        padding_width - number of spaces on either side of column data (only used if left and right paddings are None)
        left_padding_width - number of spaces on left hand side of column data
        right_padding_width - number of spaces on right hand side of column data
        vertical_char - single character string used to draw vertical lines
        horizontal_char - single character string used to draw horizontal lines
        junction_char - single character string used to draw line junctions
        sortby - name of field to sort rows by
        reversesort - True or False to sort in descending or ascending order"""

        print self.get_string(**kwargs)

    def get_string(self, **kwargs):

        """Return string representation of table in current state.

        Arguments:

        start - index of first data row to include in output
        end - index of last data row to include in output PLUS ONE (list slice style)
        fields - names of fields (columns) to include
        header - print a header showing field names (True or False)
        border - print a border around the table (True or False)
        hrules - controls printing of horizontal rules after rows.  Allowed values: FRAME, ALL, NONE
        padding_width - number of spaces on either side of column data (only used if left and right paddings are None)
        left_padding_width - number of spaces on left hand side of column data
        right_padding_width - number of spaces on right hand side of column data
        vertical_char - single character string used to draw vertical lines
        horizontal_char - single character string used to draw horizontal lines
        junction_char - single character string used to draw line junctions
        sortby - name of field to sort rows by
        reversesort - True or False to sort in descending or ascending order"""

        options = self._get_options(kwargs)

        if self._caching:
            key = cPickle.dumps(options)
            if key in self._cache:
                return self._cache[key]

        bits = []
        if not self._field_names:
            return ""
        if not options["header"]:
            # Recalculate widths - avoids tables with long field names but narrow data looking odd
            old_widths = self._widths[:]
            self._widths = [0]*_get_size(self._field_names)[0]
            for row in self._rows:
                for i in range(0,len(row)):
                    if _get_size(_unicode(row[i]))[0] > self._widths[i]:
                        self._widths[i] = _get_size(_unicode(row[i]))[0]
        if options["header"]:
            bits.append(self._stringify_header(options))
        elif options["border"] and options["hrules"] != NONE:
            bits.append(self._stringify_hrule(options))
        if options["sortby"]:
            rows = self._get_sorted_rows(options)
        else:
            rows = self._rows[options["start"]:options["end"]]
        for row in rows:
            bits.append(self._stringify_row(row, options))
        if options["border"] and not options["hrules"]:
            bits.append(self._stringify_hrule(options))
        string = "\n".join(bits)

        if self._caching:
            self._cache[key] = string

        if not options["header"]:
            # Restore previous widths
            self._widths = old_widths
            for row in self._rows:
                for i in range(0,len(row)):
                    if _get_size(_unicode(row[i]))[0] > self._widths[i]:
                        self._widths[i] = _get_size(_unicode(row[i]))[0]

        self._nonunicode = string
        return _unicode(string)

    def _stringify_hrule(self, options):

        if not options["border"]:
            return ""
        lpad, rpad = self._get_padding_widths(options)
        bits = [options["junction_char"]]
        for field, width in zip(self._field_names, self._widths):
            if options["fields"] and field not in options["fields"]:
                continue
            bits.append((width+lpad+rpad)*options["horizontal_char"])
            bits.append(options["junction_char"])
        return "".join(bits)

    def _stringify_header(self, options):

        bits = []
        lpad, rpad = self._get_padding_widths(options)
        if options["border"]:
            if options["hrules"] != NONE:
                bits.append(self._stringify_hrule(options))
                bits.append("\n")
            bits.append(options["vertical_char"])
        for field, width, in zip(self._field_names, self._widths):
            if options["fields"] and field not in options["fields"]:
                continue
            if self._align[field] == "l":
                bits.append(" " * lpad + _unicode(field).ljust(width) + " " * rpad)
            elif self._align[field] == "r":
                bits.append(" " * lpad + _unicode(field).rjust(width) + " " * rpad)
            else:
                bits.append(" " * lpad + _unicode(field).center(width) + " " * rpad)
            if options["border"]:
                bits.append(options["vertical_char"])
        if options["border"] and options["hrules"] != NONE:
            bits.append("\n")
            bits.append(self._stringify_hrule(options))
        return "".join(bits)

    def _stringify_row(self, row, options):
        row_height = _get_row_height(row)

        bits = []
        lpad, rpad = self._get_padding_widths(options)
        for y in range(0, row_height):
            bits.append([])
            if options["border"]:
                bits[y].append(self.vertical_char)

        for field, value, width, in zip(self._field_names, row, self._widths):
            lines = _unicode(value).split("\n")
            if len(lines) < row_height:
                lines = lines + ([""] * (row_height-len(lines)))

            y = 0
            for l in lines:
                if options["fields"] and field not in options["fields"]:
                    continue

                if self._align[field] == "l":
                    bits[y].append(" " * lpad + _unicode(l).ljust(width) + " " * rpad)
                elif self._align[field] == "r":
                    bits[y].append(" " * lpad + _unicode(l).rjust(width) + " " * rpad)
                else:
                    bits[y].append(" " * lpad + _unicode(l).center(width) + " " * rpad)
                if options["border"]:
                    bits[y].append(self.vertical_char)

                y += 1

        if options["border"] and options["hrules"]== ALL:
            bits[row_height-1].append("\n")
            bits[row_height-1].append(self._stringify_hrule(options))

        for y in range(0, row_height):
            bits[y] = "".join(bits[y])

        return "\n".join(bits)

    ##############################
    # HTML PRINT/STRING METHODS  #
    ##############################

    def print_html(self, **kwargs):

        """Print HTML formatted version of table in current state to stdout.

        Arguments:

        start - index of first data row to include in output
        end - index of last data row to include in output PLUS ONE (list slice style)
        fields - names of fields (columns) to include
        sortby - name of field to sort rows by
        format - should be True or False to attempt to format alignmet, padding, etc. or not
        header - should be True or False to print a header showing field names or not
        border - should be True or False to print or not print borders
        hrules - include horizontal rule after each row
        attributes - dictionary of name/value pairs to include as HTML attributes in the <table> tag"""

        print self.get_html_string(**kwargs)

    def get_html_string(self, **kwargs):

        """Return string representation of HTML formatted version of table in current state.

        Arguments:

        start - index of first data row to include in output
        end - index of last data row to include in output PLUS ONE (list slice style)
        fields - names of fields (columns) to include
        sortby - name of
        border - should be True or False to print or not print borders
        format - should be True or False to attempt to format alignmet, padding, etc. or not
        header - should be True or False to print a header showing field names or not
        border - should be True or False to print or not print borders
        hrules - include horizontal rule after each row
        attributes - dictionary of name/value pairs to include as HTML attributes in the <table> tag"""

        options = self._get_options(kwargs)

        if self._caching:
            key = cPickle.dumps(options)
            if key in self.html_cache:
                return self.html_cache[key]

        if options["format"]:
            string = self._get_formatted_html_string(options)
        else:
            string = self._get_simple_html_string(options)

        if self._caching:
            self.html_cache[key] = string

        return string

    def _get_simple_html_string(self, options):

        bits = []
        # Slow but works
        table_tag = '<table'
        if options["border"]:
            table_tag += ' border="1"'
        if options["attributes"]:
            for attr_name in options["attributes"]:
                table_tag += ' %s="%s"' % (attr_name, options["attributes"][attr_name])
        table_tag += '>'
        bits.append(table_tag)
        # Headers
        bits.append("    <tr>")
        for field in self._field_names:
            if options["fields"] and field not in options["fields"]:
                continue
            bits.append("        <th>%s</th>" % cgi.escape(_unicode(field)).replace("\n", "<br />"))
        bits.append("    </tr>")
        # Data
        if options["sortby"]:
            rows = self._get_sorted_rows(options)
        else:
            rows = self._rows
        for row in rows:
            bits.append("    <tr>")
            for field, datum in zip(self._field_names, row):
                if options["fields"] and field not in options["fields"]:
                    continue
                bits.append("        <td>%s</td>" % cgi.escape(_unicode(datum)).replace("\n", "<br />"))
            bits.append("    </tr>")
        bits.append("</table>")
        string = "\n".join(bits)

        return string

    def _get_formatted_html_string(self, options):

        bits = []
        lpad, rpad = self._get_padding_widths(options)
        # Slow but works
        table_tag = '<table'
        if options["border"]:
            table_tag += ' border="1"'
        if options["hrules"] == NONE:
            table_tag += ' frame="vsides" rules="cols"'
        if options["attributes"]:
            for attr_name in options["attributes"]:
                table_tag += ' %s="%s"' % (attr_name, options["attributes"][attr_name])
        table_tag += '>'
        bits.append(table_tag)
        # Headers
        if options["header"]:
            bits.append("    <tr>")
            for field in self._field_names:
                if options["fields"] and field not in options["fields"]:
                    continue
                bits.append("        <th style=\"padding-left: %dem; padding-right: %dem; text-align: center\">%s</th>" % (lpad, rpad, cgi.escape(_unicode(field)).replace("\n", "<br />")))
            bits.append("    </tr>")
        # Data
        if options["sortby"]:
            rows = self._get_sorted_rows(options)
        else:
            rows = self._rows
        for row in self._rows:
            bits.append("    <tr>")
            for field, datum in zip(self._field_names, row):
                if options["fields"] and field not in options["fields"]:
                    continue
                if self._align[field] == "l":
                    bits.append("        <td style=\"padding-left: %dem; padding-right: %dem; text-align: left\">%s</td>" % (lpad, rpad, cgi.escape(_unicode(datum)).replace("\n", "<br />")))
                elif self._align[field] == "r":
                    bits.append("        <td style=\"padding-left: %dem; padding-right: %dem; text-align: right\">%s</td>" % (lpad, rpad, cgi.escape(_unicode(datum)).replace("\n", "<br />")))
                else:
                    bits.append("        <td style=\"padding-left: %dem; padding-right: %dem; text-align: center\">%s</td>" % (lpad, rpad, cgi.escape(_unicode(datum)).replace("\n", "<br />")))
            bits.append("    </tr>")
        bits.append("</table>")
        string = "\n".join(bits)

        return _unicode(string)

def main():

    x = PrettyTable(["City name", "Area", "Population", "Annual Rainfall"])
    x.align["City name"] = "l" # Left align city names
    x.add_row(["Adelaide", 1295, 1158259, 600.5])
    x.add_row(["Brisbane", 5905, 1857594, 1146.4])
    x.add_row(["Darwin", 112, 120900, 1714.7])
    x.add_row(["Hobart", 1357, 205556, 619.5])
    x.add_row(["Sydney", 2058, 4336374, 1214.8])
    x.add_row(["Melbourne", 1566, 3806092, 646.9])
    x.add_row(["Perth", 5386, 1554769, 869.4])
    print x

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = texttable
#!/usr/bin/env python
#
# texttable - module for creating simple ASCII tables
# Copyright (C) 2003-2011 Gerome Fournier <jef(at)foutaise.org>
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301  USA

# NOTE: This is external code.
# We don't do automatic Eclipse PyDev code analysis for it.
#@PydevCodeAnalysisIgnore

"""module for creating simple ASCII tables


Example:

    table = TextTable()
    table.set_cols_align(["l", "r", "c"])
    table.set_cols_valign(["t", "m", "b"])
    table.add_rows([ ["Name", "Age", "Nickname"],
                     ["Mr\\nXavier\\nHuon", 32, "Xav'"],
                     ["Mr\\nBaptiste\\nClement", 1, "Baby"] ])
    print table.draw() + "\\n"

    table = TextTable()
    table.set_deco(TextTable.HEADER)
    table.set_cols_dtype(['t',  # text
                          'f',  # float (decimal)
                          'e',  # float (exponent)
                          'i',  # integer
                          'a']) # automatic
    table.set_cols_align(["l", "r", "r", "r", "l"])
    table.add_rows([["text",    "float", "exp", "int", "auto"],
                    ["abcd",    "67",    654,   89,    128.001],
                    ["efghijk", 67.5434, .654,  89.6,  12800000000000000000000.00023],
                    ["lmn",     5e-78,   5e-78, 89.4,  .000000000000128],
                    ["opqrstu", .023,    5e+78, 92.,   12800000000000000000000]])
    print table.draw()

Result:

    +----------+-----+----------+
    |   Name   | Age | Nickname |
    +==========+=====+==========+
    | Mr       |     |          |
    | Xavier   |  32 |          |
    | Huon     |     |   Xav'   |
    +----------+-----+----------+
    | Mr       |     |          |
    | Baptiste |   1 |          |
    | Clement  |     |   Baby   |
    +----------+-----+----------+

    text   float       exp      int     auto
    ===========================================
    abcd   67.000   6.540e+02   89    128.001
    efgh   67.543   6.540e-01   90    1.280e+22
    ijkl   0.000    5.000e-78   89    0.000
    mnop   0.023    5.000e+78   92    1.280e+22
"""

__all__ = ["TextTable", "ArraySizeError"]

__author__ = 'Gerome Fournier <jef(at)foutaise.org>'
__license__ = 'GPL'
__version__ = '0.8'
__revision__ = '$Id: texttable.py 132 2011-10-02 11:51:00Z jef $'
__credits__ = """\
Jeff Kowalczyk:
    - textwrap improved import
    - comment concerning header output

Anonymous:
    - add_rows method, for adding rows in one go

Sergey Simonenko:
    - redefined len() function to deal with non-ASCII characters

Roger Lew:
    - columns datatype specifications

Brian Peterson:
    - better handling of unicode errors
"""

import sys
import string

try:
    if sys.version >= '2.3':
        import textwrap
    elif sys.version >= '2.2':
        from optparse import textwrap
    else:
        from optik import textwrap
except ImportError:
    sys.stderr.write("Can't import textwrap module!\n")
    raise

try:
    True, False
except NameError:
    (True, False) = (1, 0)

def len(iterable):
    """Redefining len here so it will be able to work with non-ASCII characters
    """
    if not isinstance(iterable, str):
        return iterable.__len__()

    try:
        return len(unicode(iterable, 'utf'))
    except:
        return iterable.__len__()

class ArraySizeError(Exception):
    """Exception raised when specified rows don't fit the required size
    """

    def __init__(self, msg):
        self.msg = msg
        Exception.__init__(self, msg, '')

    def __str__(self):
        return self.msg

class TextTable:

    BORDER = 1
    HEADER = 1 << 1
    HLINES = 1 << 2
    VLINES = 1 << 3

    def __init__(self, max_width=80):
        """Constructor

        - max_width is an integer, specifying the maximum width of the table
        - if set to 0, size is unlimited, therefore cells won't be wrapped
        """

        if max_width <= 0:
            max_width = False
        self._max_width = max_width
        self._precision = 3

        self._deco = TextTable.VLINES | TextTable.HLINES | TextTable.BORDER | \
            TextTable.HEADER
        self.set_chars(['-', '|', '+', '='])
        self.reset()

    def reset(self):
        """Reset the instance

        - reset rows and header
        """

        self._hline_string = None
        self._row_size = None
        self._header = []
        self._rows = []

    def set_chars(self, array):
        """Set the characters used to draw lines between rows and columns

        - the array should contain 4 fields:

            [horizontal, vertical, corner, header]

        - default is set to:

            ['-', '|', '+', '=']
        """

        if len(array) != 4:
            raise ArraySizeError, "array should contain 4 characters"
        array = [ x[:1] for x in [ str(s) for s in array ] ]
        (self._char_horiz, self._char_vert,
            self._char_corner, self._char_header) = array

    def set_deco(self, deco):
        """Set the table decoration

        - 'deco' can be a combinaison of:

            TextTable.BORDER: Border around the table
            TextTable.HEADER: Horizontal line below the header
            TextTable.HLINES: Horizontal lines between rows
            TextTable.VLINES: Vertical lines between columns

           All of them are enabled by default

        - example:

            TextTable.BORDER | TextTable.HEADER
        """

        self._deco = deco

    def set_cols_align(self, array):
        """Set the desired columns alignment

        - the elements of the array should be either "l", "c" or "r":

            * "l": column flushed left
            * "c": column centered
            * "r": column flushed right
        """

        self._check_row_size(array)
        self._align = array

    def set_cols_valign(self, array):
        """Set the desired columns vertical alignment

        - the elements of the array should be either "t", "m" or "b":

            * "t": column aligned on the top of the cell
            * "m": column aligned on the middle of the cell
            * "b": column aligned on the bottom of the cell
        """

        self._check_row_size(array)
        self._valign = array

    def set_cols_dtype(self, array):
        """Set the desired columns datatype for the cols.

        - the elements of the array should be either "a", "t", "f", "e" or "i":

            * "a": automatic (try to use the most appropriate datatype)
            * "t": treat as text
            * "f": treat as float in decimal format
            * "e": treat as float in exponential format
            * "i": treat as int

        - by default, automatic datatyping is used for each column
        """

        self._check_row_size(array)
        self._dtype = array

    def set_cols_width(self, array):
        """Set the desired columns width

        - the elements of the array should be integers, specifying the
          width of each column. For example:

                [10, 20, 5]
        """

        self._check_row_size(array)
        try:
            array = map(int, array)
            if reduce(min, array) <= 0:
                raise ValueError
        except ValueError:
            sys.stderr.write("Wrong argument in column width specification\n")
            raise
        self._width = array

    def set_precision(self, width):
        """Set the desired precision for float/exponential formats

        - width must be an integer >= 0

        - default value is set to 3
        """

        if not type(width) is int or width < 0:
            raise ValueError('width must be an integer greater then 0')
        self._precision = width

    def header(self, array):
        """Specify the header of the table
        """

        self._check_row_size(array)
        self._header = map(str, array)

    def add_row(self, array):
        """Add a row in the rows stack

        - cells can contain newlines and tabs
        """

        self._check_row_size(array)

        if not hasattr(self, "_dtype"):
            self._dtype = ["a"] * self._row_size

        cells = []
        for i,x in enumerate(array):
            cells.append(self._str(i,x))
        self._rows.append(cells)

    def add_rows(self, rows, header=True):
        """Add several rows in the rows stack

        - The 'rows' argument can be either an iterator returning arrays,
          or a by-dimensional array
        - 'header' specifies if the first row should be used as the header
          of the table
        """

        # nb: don't use 'iter' on by-dimensional arrays, to get a
        #     usable code for python 2.1
        if header:
            if hasattr(rows, '__iter__') and hasattr(rows, 'next'):
                self.header(rows.next())
            else:
                self.header(rows[0])
                rows = rows[1:]
        for row in rows:
            self.add_row(row)

    def draw(self):
        """Draw the table

        - the table is returned as a whole string
        """

        if not self._header and not self._rows:
            return
        self._compute_cols_width()
        self._check_align()
        out = ""
        if self._has_border():
            out += self._hline()
        if self._header:
            out += self._draw_line(self._header, isheader=True)
            if self._has_header():
                out += self._hline_header()
        length = 0
        for row in self._rows:
            length += 1
            out += self._draw_line(row)
            if self._has_hlines() and length < len(self._rows):
                out += self._hline()
        if self._has_border():
            out += self._hline()
        return out[:-1]

    def _str(self, i, x):
        """Handles string formatting of cell data

            i - index of the cell datatype in self._dtype
            x - cell data to format
        """
        try:
            f = float(x)
        except:
            return str(x)

        n = self._precision
        dtype = self._dtype[i]

        if dtype == 'i':
            return str(int(round(f)))
        elif dtype == 'f':
            return '%.*f' % (n, f)
        elif dtype == 'e':
            return '%.*e' % (n, f)
        elif dtype == 't':
            return str(x)
        else:
            if f - round(f) == 0:
                if abs(f) > 1e8:
                    return '%.*e' % (n, f)
                else:
                    return str(int(round(f)))
            else:
                if abs(f) > 1e8:
                    return '%.*e' % (n, f)
                else:
                    return '%.*f' % (n, f)

    def _check_row_size(self, array):
        """Check that the specified array fits the previous rows size
        """

        if not self._row_size:
            self._row_size = len(array)
        elif self._row_size != len(array):
            raise ArraySizeError, "array should contain %d elements" \
                % self._row_size

    def _has_vlines(self):
        """Return a boolean, if vlines are required or not
        """

        return self._deco & TextTable.VLINES > 0

    def _has_hlines(self):
        """Return a boolean, if hlines are required or not
        """

        return self._deco & TextTable.HLINES > 0

    def _has_border(self):
        """Return a boolean, if border is required or not
        """

        return self._deco & TextTable.BORDER > 0

    def _has_header(self):
        """Return a boolean, if header line is required or not
        """

        return self._deco & TextTable.HEADER > 0

    def _hline_header(self):
        """Print header's horizontal line
        """

        return self._build_hline(True)

    def _hline(self):
        """Print an horizontal line
        """

        if not self._hline_string:
            self._hline_string = self._build_hline()
        return self._hline_string

    def _build_hline(self, is_header=False):
        """Return a string used to separated rows or separate header from
        rows
        """
        horiz = self._char_horiz
        if (is_header):
            horiz = self._char_header
        # compute cell separator
        s = "%s%s%s" % (horiz, [horiz, self._char_corner][self._has_vlines()],
            horiz)
        # build the line
        l = string.join([horiz * n for n in self._width], s)
        # add border if needed
        if self._has_border():
            l = "%s%s%s%s%s\n" % (self._char_corner, horiz, l, horiz,
                self._char_corner)
        else:
            l += "\n"
        return l

    def _len_cell(self, cell):
        """Return the width of the cell

        Special characters are taken into account to return the width of the
        cell, such like newlines and tabs
        """

        cell_lines = cell.split('\n')
        maxi = 0
        for line in cell_lines:
            length = 0
            parts = line.split('\t')
            for part, i in zip(parts, range(1, len(parts) + 1)):
                length = length + len(part)
                if i < len(parts):
                    length = (length/8 + 1) * 8
            maxi = max(maxi, length)
        return maxi

    def _compute_cols_width(self):
        """Return an array with the width of each column

        If a specific width has been specified, exit. If the total of the
        columns width exceed the table desired width, another width will be
        computed to fit, and cells will be wrapped.
        """

        if hasattr(self, "_width"):
            return
        maxi = []
        if self._header:
            maxi = [ self._len_cell(x) for x in self._header ]
        for row in self._rows:
            for cell,i in zip(row, range(len(row))):
                try:
                    maxi[i] = max(maxi[i], self._len_cell(cell))
                except (TypeError, IndexError):
                    maxi.append(self._len_cell(cell))
        items = len(maxi)
        length = reduce(lambda x,y: x+y, maxi)
        if self._max_width and length + items * 3 + 1 > self._max_width:
            maxi = [(self._max_width - items * 3 -1) / items \
                for n in range(items)]
        self._width = maxi

    def _check_align(self):
        """Check if alignment has been specified, set default one if not
        """

        if not hasattr(self, "_align"):
            self._align = ["l"] * self._row_size
        if not hasattr(self, "_valign"):
            self._valign = ["t"] * self._row_size

    def _draw_line(self, line, isheader=False):
        """Draw a line

        Loop over a single cell length, over all the cells
        """

        line = self._splitit(line, isheader)
        space = " "
        out  = ""
        for i in range(len(line[0])):
            if self._has_border():
                out += "%s " % self._char_vert
            length = 0
            for cell, width, align in zip(line, self._width, self._align):
                length += 1
                cell_line = cell[i]
                fill = width - len(cell_line)
                if isheader:
                    align = "c"
                if align == "r":
                    out += "%s " % (fill * space + cell_line)
                elif align == "c":
                    out += "%s " % (fill/2 * space + cell_line \
                            + (fill/2 + fill%2) * space)
                else:
                    out += "%s " % (cell_line + fill * space)
                if length < len(line):
                    out += "%s " % [space, self._char_vert][self._has_vlines()]
            out += "%s\n" % ['', self._char_vert][self._has_border()]
        return out

    def _splitit(self, line, isheader):
        """Split each element of line to fit the column width

        Each element is turned into a list, result of the wrapping of the
        string to the desired width
        """

        line_wrapped = []
        for cell, width in zip(line, self._width):
            array = []
            for c in cell.split('\n'):
                try:
                    c = unicode(c, 'utf')
                except UnicodeDecodeError as strerror:
                    sys.stderr.write("UnicodeDecodeError exception for string '%s': %s\n" % (c, strerror))
                    c = unicode(c, 'utf', 'replace')
                array.extend(textwrap.wrap(c, width))
            line_wrapped.append(array)
        max_cell_lines = reduce(max, map(len, line_wrapped))
        for cell, valign in zip(line_wrapped, self._valign):
            if isheader:
                valign = "t"
            if valign == "m":
                missing = max_cell_lines - len(cell)
                cell[:0] = [""] * (missing / 2)
                cell.extend([""] * (missing / 2 + missing % 2))
            elif valign == "b":
                cell[:0] = [""] * (max_cell_lines - len(cell))
            else:
                cell.extend([""] * (max_cell_lines - len(cell)))
        return line_wrapped

if __name__ == '__main__':
    table = TextTable()
    table.set_cols_align(["l", "r", "c"])
    table.set_cols_valign(["t", "m", "b"])
    table.add_rows([ ["Name", "Age", "Nickname"],
                     ["Mr\nXavier\nHuon", 32, "Xav'"],
                     ["Mr\nBaptiste\nClement", 1, "Baby"] ])
    print table.draw() + "\n"

    table = TextTable()
    table.set_deco(TextTable.HEADER)
    table.set_cols_dtype(['t',  # text
                          'f',  # float (decimal)
                          'e',  # float (exponent)
                          'i',  # integer
                          'a']) # automatic
    table.set_cols_align(["l", "r", "r", "r", "l"])
    table.add_rows([["text",    "float", "exp", "int", "auto"],
                    ["abcd",    "67",    654,   89,    128.001],
                    ["efghijk", 67.5434, .654,  89.6,  12800000000000000000000.00023],
                    ["lmn",     5e-78,   5e-78, 89.4,  .000000000000128],
                    ["opqrstu", .023,    5e+78, 92.,   12800000000000000000000]])
    print table.draw()


########NEW FILE########
__FILENAME__ = info
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
                 _
 _ __ ___   ___ | |_ _ __  _   _
| '__/ _ \ / _ \| __| '_ \| | | |
| | | (_) | (_) | |_| |_) | |_| |
|_|  \___/ \___/ \__| .__/ \__, |
                    |_|    |___/
      {0}
"""
from __future__ import absolute_import

from collections import namedtuple


_version_info_base = namedtuple(
    'version_info',
    ['major',
     'minor',
     'micro'])


class version_info(_version_info_base):

    DEV = (999, 9, 9)

    def __new__(cls, version):

        if version == 'dev':
            return super(version_info, cls).__new__(cls, *version_info.DEV)
        else:
            return super(version_info, cls).__new__(cls, *version.split('.'))

    def __repr__(self):

        return 'rootpy.{0}'.format(super(version_info, self).__repr__())

    def __str__(self):

        if self == version_info.DEV:
            return 'dev'
        return '{0}.{1}.{2}'.format(*self)


__version_info__ = version_info('dev')
__version__ = str(__version_info__)
__url__ = 'http://rootpy.github.com/rootpy'
__repo_url__ = 'https://github.com/rootpy/rootpy/'
__download_url__ = ('http://pypi.python.org/packages/source/r/'
                    'rootpy/rootpy-{0}.tar.gz').format(__version__)
__doc__ = __doc__.format(__version__)

########NEW FILE########
__FILENAME__ = canvas_events
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from .. import compiled as C

__all__ = [
    'close_on_esc_or_middlemouse',
    'attach_event_handler',
]

C.register_code("""
#include <TPython.h>
#include <TPyDispatcher.h>

class TPyDispatcherProcessedEvent : public TPyDispatcher {
public:
    TPyDispatcherProcessedEvent(PyObject* callable) : TPyDispatcher(callable){}

    PyObject* Dispatch(int p1, int p2, int p3, void* p4) {
        if (!p4) return NULL;
        PyObject* p4_aspyobj = TPython::ObjectProxy_FromVoidPtr(p4,
            reinterpret_cast<TObject*>(p4)->ClassName());
        PyObject* result = DispatchVA("lllO", p1, p2, p3, p4_aspyobj);
        return result;
    }

    ClassDef(TPyDispatcherProcessedEvent, 0);
};

ClassImp(TPyDispatcherProcessedEvent);
""", ["TPyDispatcherProcessedEvent"])


def close_on_esc_or_middlemouse(event, x, y, obj):
    """
    Closes canvases when escape is pressed or the canvas area is clicked with
    the middle mouse button. (ROOT requires that the mouse is over the canvas
    area itself before sending signals of any kind.)
    """
    #print "Event handler called:", args

    if (event == ROOT.kButton2Down
            # User pressed middle mouse
        or (event == ROOT.kMouseMotion and
            x == y == 0 and
            # User pressed escape. Yes. Don't ask me why kMouseMotion.
            ROOT.gROOT.IsEscaped())):

        # Defer the close because otherwise root segfaults when it tries to
        # run gPad->Modified()
        obj._py_closetimer = ROOT.TTimer()
        obj._py_closetimer.Connect("Timeout()", "TCanvas", obj, "Close()")
        # Single shot after 10ms
        obj._py_closetimer.Start(10, ROOT.kTRUE)


def attach_event_handler(canvas, handler=close_on_esc_or_middlemouse):
    """
    Attach a handler function to the ProcessedEvent slot, defaulting to
    closing when middle mouse is clicked or escape is pressed

    Note that escape only works if the pad has focus, which in ROOT-land means
    the mouse has to be over the canvas area.
    """
    if getattr(canvas, "_py_event_dispatcher_attached", None):
        return

    event_dispatcher = C.TPyDispatcherProcessedEvent(handler)
    canvas.Connect("ProcessedEvent(int,int,int,TObject*)",
                   "TPyDispatcherProcessedEvent", event_dispatcher,
                   "Dispatch(int,int,int,TObject*)")

    # Attach a handler only once to each canvas, and keep the dispatcher alive
    canvas._py_event_dispatcher_attached = event_dispatcher

########NEW FILE########
__FILENAME__ = console
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Spawn an interactive python console in the current frame.

For example::

    from rootpy.interactive import interact
    x = 1
    interact()
    # Now you're in a python console.

"""
from __future__ import absolute_import

import code
import readline
import sys

import ROOT as R

from ..logger.magic import fix_ipython_startup

__all__ = [
    'interact',
]

# overridden if importing ipython is successful
have_ipython = False

# Make it so that a subsequent \n has no effect
UP_LINE = '\r\x1b[1A'


def interact_plain(header=UP_LINE, local_ns=None,
                   module=None, dummy=None,
                   stack_depth=1, global_ns=None):
    """
    Create an interactive python console
    """
    frame = sys._getframe(stack_depth)

    variables = {}

    if local_ns is not None:
        variables.update(local_ns)
    else:
        variables.update(frame.f_locals)

    if global_ns is not None:
        variables.update(local_ns)
    else:
        variables.update(frame.f_globals)

    shell = code.InteractiveConsole(variables)
    return shell.interact(banner=header)

try:
    from IPython.terminal.embed import InteractiveShellEmbed
    have_ipython = True

except ImportError:
    interact = interact_plain

else:
    # ROOT has a bug causing it to print (Bool_t)1 to the console.
    # This is fixed in defaults.py if rootpy is imported under the ipython
    # interpreter, but at this point that is too late, so we need to try again
    _finalSetup = getattr(R.__class__, "_ModuleFacade__finalSetup", None)
    if _finalSetup:
        _orig_func = getattr(_finalSetup, "_orig_func", None)
        if _orig_func:
            _finalSetup = _orig_func
        fix_ipython_startup(_finalSetup)

    interact_ipython_ = None

    def interact_ipython(header='', *args, **kwargs):
        global interact_ipython_

        def pre_prompt_hook(_):
            R.gInterpreter.EndOfLineAction()

        # Interact is a callable which starts an ipython shell
        if not interact_ipython_:
            interact_ipython_ = InteractiveShellEmbed(banner1=UP_LINE)
        # needed for graphics to work correctly
        interact_ipython_.set_hook('pre_prompt_hook', pre_prompt_hook)
        stack_depth = kwargs.pop("stack_depth", 0) + 2
        kwargs["stack_depth"] = stack_depth
        interact_ipython_(header, *args, **kwargs)

    interact = interact_ipython

########NEW FILE########
__FILENAME__ = notebook
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Register display formatters for ROOT objects when running in an interactive
IPython notebook.

Based on an implementation here: https://gist.github.com/mazurov/6194738
"""
import tempfile

from .. import IN_IPYTHON
from ..plotting import Canvas
from ..context import preserve_current_canvas
from ..utils.hook import classhook, super_overridden

if IN_IPYTHON:
    from IPython.core import display

__all__ = [
    'configure',
]


def _display_canvas(canvas):
    file_handle = tempfile.NamedTemporaryFile(suffix='.png')
    canvas.SaveAs(file_handle.name)
    ip_img = display.Image(filename=file_handle.name, format='png', embed=True)
    return ip_img._repr_png_()


def _draw_image(meth, *args, **kwargs):
    file_handle = tempfile.NamedTemporaryFile(suffix='.png')
    with preserve_current_canvas():
        canvas = Canvas()
        meth(*args, **kwargs)
        canvas.SaveAs(file_handle.name)
    return display.Image(filename=file_handle.name, format='png', embed=True)


def _display_any(obj):
    return _draw_image(obj.Draw)._repr_png_()


def configure():
    if not IN_IPYTHON:
        raise RuntimeError("not currently running in IPython")
    import ROOT
    # trigger PyROOT's finalSetup()
    ROOT.kTRUE
    # canvases will be displayed inline
    ROOT.gROOT.SetBatch()
    # only available if running in IPython:
    shell = get_ipython()
    # register display functions with PNG formatter:
    png_formatter = shell.display_formatter.formatters['image/png']
    png_formatter.for_type(ROOT.TCanvas, _display_canvas)
    png_formatter.for_type(ROOT.TF1, _display_any)
    png_formatter.for_type(ROOT.TH1, _display_any)
    png_formatter.for_type(ROOT.THStack, _display_any)
    png_formatter.for_type(ROOT.TGraph, _display_any)
    png_formatter.for_type(ROOT.TGraph2D, _display_any)

########NEW FILE########
__FILENAME__ = rootwait
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
The functions in this module provide a way of pausing code execution until
canvases are closed. This can be useful when testing code and you don't want to
keep the objects alive outside of your function.

The wait function can be called repeatedly to pause multiple times.

wait_for_zero_canvases()
    Keeps root alive until CTRL-c is pressed or all canvases are closed

wait_for_zero_canvases(middle_mouse_close=True)
    allows canvases to be closed with the middle mouse button (see below)

wait is shorthand for wait_for_zero_canvases

Examples
--------

    from rootpy.plotting import Canvas
    from rootpy.interactive import wait

    c = Canvas()
    c.Update()
    wait()

    c2 = Canvas()
    c2.Update()
    wait(True)
    # This canvas can be killed by middle clicking on it or hitting
    # escape whilst it has focus

"""
from __future__ import absolute_import

import threading
from atexit import register

import ROOT

from . import log; log = log[__name__]
from ..defaults import extra_initialization
from ..memory.keepalive import keepalive
from .canvas_events import attach_event_handler

__all__ = [
    'wait_for_zero_canvases',
    'wait_for_browser_close',
    'wait',
]

_processRootEvents = None
_finishSchedule = None
__ACTIVE = False


@extra_initialization
def fetch_vars():
    global _processRootEvents, _finishSchedule, __ACTIVE
    PyGUIThread = getattr(ROOT, 'PyGUIThread', None)
    if PyGUIThread is not None:
        _processRootEvents = getattr(PyGUIThread, "_Thread__target", None)
        _finishSchedule = getattr(PyGUIThread, "finishSchedule", None)
    if _processRootEvents is None:
        log.warning(
            "unable to access ROOT's GUI thread either because "
            "PyROOT's finalSetup() was called while in batch mode "
            "or because PyROOT is using the new PyOS_InputHook "
            "based mechanism that is not yet supported in rootpy "
            "(PyConfig.StartGuiThread == 'inputhook' or "
            "gSystem.InheritsFrom('TMacOSXSystem')). wait() etc. will "
            "instead call raw_input() and wait for [Enter]")
    else:
        __ACTIVE = True


def wait_failover(caller):
    if not ROOT.gROOT.IsBatch():
        log.warning(
            "{0} is failing over to raw_input()".format(caller.__name__))
        raw_input("press [Enter] to continue")


def start_new_gui_thread():
    """
    Attempt to start a new GUI thread, if possible.

    It is only possible to start one if there was one running on module import.
    """
    PyGUIThread = getattr(ROOT, 'PyGUIThread', None)

    if PyGUIThread is not None:
        assert not PyGUIThread.isAlive(), "GUI thread already running!"

    assert _processRootEvents, (
        "GUI thread wasn't started when rootwait was imported, "
        "so it can't be restarted")

    ROOT.keeppolling = 1
    ROOT.PyGUIThread = threading.Thread(
        None, _processRootEvents, None, (ROOT,))

    ROOT.PyGUIThread.finishSchedule = _finishSchedule
    ROOT.PyGUIThread.setDaemon(1)
    ROOT.PyGUIThread.start()
    log.debug("successfully started a new GUI thread")


def stop_gui_thread():
    """
    Try to stop the GUI thread. If it was running returns True,
    otherwise False.
    """
    PyGUIThread = getattr(ROOT, 'PyGUIThread', None)

    if PyGUIThread is None or not PyGUIThread.isAlive():
        log.debug("no existing GUI thread is runnng")
        return False

    ROOT.keeppolling = 0
    try:
        PyGUIThread.finishSchedule()
    except AttributeError:
        log.debug("unable to call finishSchedule() on PyGUIThread")
        pass
    PyGUIThread.join()
    log.debug("successfully stopped the existing GUI thread")
    return True


def get_visible_canvases():
    """
    Return a list of active GUI canvases
    (as opposed to invisible Batch canvases)
    """
    try:
        return [c for c in ROOT.gROOT.GetListOfCanvases() if not c.IsBatch()]
    except AttributeError:
        # We might be exiting and ROOT.gROOT will raise an AttributeError
        return []


def run_application_until_done():

    had_gui_thread = stop_gui_thread()

    ROOT.gApplication._threaded = True
    ROOT.gApplication.Run(True)

    if had_gui_thread:
        start_new_gui_thread()


def dispatcher(f):
    disp = ROOT.TPyDispatcher(f)
    keepalive(disp, f)
    return disp


def wait_for_zero_canvases(middle_mouse_close=False):
    """
    Wait for all canvases to be closed, or CTRL-c.

    If `middle_mouse_close`, middle click will shut the canvas.

    incpy.ignore
    """
    if not __ACTIVE:
        wait_failover(wait_for_zero_canvases)
        return

    @dispatcher
    def count_canvases():
        """
        Count the number of active canvases and finish gApplication.Run()
        if there are none remaining.

        incpy.ignore
        """
        if not get_visible_canvases():
            try:
                ROOT.gSystem.ExitLoop()
            except AttributeError:
                # We might be exiting and ROOT.gROOT will raise an AttributeError
                pass

    @dispatcher
    def exit_application_loop():
        """
        Signal handler for CTRL-c to cause gApplication.Run() to finish.

        incpy.ignore
        """
        ROOT.gSystem.ExitLoop()

    # Handle CTRL-c
    sh = ROOT.TSignalHandler(ROOT.kSigInterrupt, True)
    sh.Add()
    sh.Connect("Notified()", "TPyDispatcher",
               exit_application_loop, "Dispatch()")

    visible_canvases = get_visible_canvases()

    for canvas in visible_canvases:
        log.debug("waiting for canvas {0} to close".format(canvas.GetName()))
        canvas.Update()

        if middle_mouse_close:
            attach_event_handler(canvas)

        if not getattr(canvas, "_py_close_dispatcher_attached", False):
            # Attach a handler only once to each canvas
            canvas._py_close_dispatcher_attached = True
            canvas.Connect("Closed()", "TPyDispatcher",
                           count_canvases, "Dispatch()")
            keepalive(canvas, count_canvases)

    if visible_canvases and not ROOT.gROOT.IsBatch():
        run_application_until_done()

        # Disconnect from canvases
        for canvas in visible_canvases:
            if getattr(canvas, "_py_close_dispatcher_attached", False):
                canvas._py_close_dispatcher_attached = False
                canvas.Disconnect("Closed()", count_canvases, "Dispatch()")

wait = wait_for_zero_canvases


def wait_for_frame(frame):
    """
    wait until a TGMainFrame is closed or ctrl-c
    """
    if not frame:
        # It's already closed or maybe we're in batch mode
        return

    @dispatcher
    def close():
        ROOT.gSystem.ExitLoop()

    if not getattr(frame, "_py_close_dispatcher_attached", False):
        frame._py_close_dispatcher_attached = True
        frame.Connect("CloseWindow()", "TPyDispatcher", close, "Dispatch()")

    @dispatcher
    def exit_application_loop():
        """
        Signal handler for CTRL-c to cause gApplication.Run() to finish.

        incpy.ignore
        """
        ROOT.gSystem.ExitLoop()

    # Handle CTRL-c
    sh = ROOT.TSignalHandler(ROOT.kSigInterrupt, True)
    sh.Add()
    sh.Connect("Notified()", "TPyDispatcher",
               exit_application_loop, "Dispatch()")

    if not ROOT.gROOT.IsBatch():
        run_application_until_done()
        # Need to disconnect to prevent close handler from running when python
        # teardown has already commenced.
        frame.Disconnect("CloseWindow()", close, "Dispatch()")


def wait_for_browser_close(b):
    """
    Can be used to wait until a TBrowser is closed
    """
    if b:
        if not __ACTIVE:
            wait_failover(wait_for_browser_close)
            return
        wait_for_frame(b.GetBrowserImp().GetMainFrame())


def prevent_close_with_canvases():
    """
    Register a handler which prevents python from exiting until
    all canvases are closed
    """
    register(wait_for_zero_canvases)

########NEW FILE########
__FILENAME__ = file
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module enhances IO-related ROOT functionality
"""
from __future__ import absolute_import

import os
import re
import uuid
import tempfile
import warnings
import itertools
from fnmatch import fnmatch
from collections import defaultdict

from .. import ROOT
from .. import asrootpy, QROOT
from ..base import Object, NamedObject
from ..decorators import snake_case_methods
from ..context import preserve_current_directory
from ..utils.path import expand as expand_path
from ..memory.keepalive import keepalive

__all__ = [
    'DoesNotExist',
    'Key',
    'Directory',
    'File',
    'MemFile',
    'TemporaryFile',
    'root_open',
]


VALIDPATH = '^(?P<file>.+.root)(?:[/](?P<path>.+))?$'


class DoesNotExist(Exception):
    """
    This exception is raised if an attempt is made to access an object
    that does not exist in a directory.
    """
    pass


def autovivitree():
    # http://en.wikipedia.org/wiki/Autovivification#Python
    return defaultdict(autovivitree)


def splitfile(path):
    filename, _, path = path.partition(':' + os.path.sep)
    return filename, os.path.sep + path


def wrap_path_handling(f):

    def get(self, name, *args, **kwargs):
        _name = os.path.normpath(name)
        if _name == '.':
            return self
        if _name == '..':
            return self._parent
        try:
            dirpath, _, path = _name.partition(os.path.sep)
            if path:
                if dirpath == '..':
                    return self._parent.Get(path, *args, **kwargs)
                else:
                    _dir = self.Get(dirpath)
                    if not isinstance(_dir, _DirectoryBase):
                        raise DoesNotExist
                    _dir._parent = self
                    _dir._path = os.path.join(self._path, dirpath)
                    thing = f(_dir, path, *args, **kwargs)
            else:
                thing = f(self, _name, *args, **kwargs)
                if isinstance(thing, _DirectoryBase):
                    thing._parent = self
            if isinstance(thing, _DirectoryBase):
                if isinstance(self, File):
                    thing._path = os.path.normpath(
                        (':' + os.path.sep).join([self._path, _name]))
                else:
                    thing._path = os.path.normpath(
                        os.path.join(self._path, _name))
            return thing
        except DoesNotExist:
            raise DoesNotExist(
                "requested path '{0}' does not exist in {1}".format(
                    name, self._path))
    return get


def root_open(filename, mode=''):
    """
    Open a ROOT file via ROOT's static ROOT.TFile.Open [1] function and return
    an asrootpy'd File.

    Parameters
    ----------

    filename : string
        The absolute or relative path to the ROOT file.

    mode : string, optional (default='')
        The ROOT option for opening a file [2].

    Returns
    -------

    root_file : File
        an instance of rootpy's File subclass of ROOT's TFile.

    References
    ----------

    .. [1] http://root.cern.ch/root/html/TFile.html#TFile:Open
    .. [2] http://root.cern.ch/root/html/TFile.html#TFile:TFile@2

    """
    filename = expand_path(filename)
    prev_dir = ROOT.gDirectory.func()
    root_file = ROOT.R.TFile.Open(filename, mode)
    if not root_file:
        raise IOError("could not open file: '{0}'".format(filename))
    root_file.__class__ = File
    root_file._path = filename
    root_file._parent = root_file
    root_file._prev_dir = prev_dir
    root_file._inited = True
    # give Python ownership of the TFile so we can delete it
    ROOT.SetOwnership(root_file, True)
    return root_file


@snake_case_methods
class Key(NamedObject, QROOT.TKey):
    """
    A subclass of ROOT's TKey [1]

    References
    ----------

    .. [1] http://root.cern.ch/root/html/TKey.html

    """
    _ROOT = QROOT.TKey


class _DirectoryBase(Object):

    def __str__(self):
        return "{0}('{1}')".format(self.__class__.__name__, self._path)

    def __repr__(self):
        return self.__str__()

    def __getattr__(self, attr):
        """
        Natural naming support. Now you can get an object from a
        File/Directory with::

            myfile.somedir.otherdir.histname
        """
        # Be careful! If ``__getattr__`` ends up being called again here,
        # this can end up in an "infinite" recursion and stack overflow.

        # Directly call ROOT's Get() here since ``attr`` must anyway be a valid
        # identifier (not a path including subdirectories).
        thing = super(_DirectoryBase, self).Get(attr)
        if not thing:
            raise AttributeError(
                "{0} has no attribute '{1}'".format(self, attr))
        thing = asrootpy(thing)
        if isinstance(thing, Directory):
            thing._path = os.path.join(self._path, thing.GetName())
            thing._parent = self
        return thing

    def __setattr__(self, attr, value):
        if ('_inited' not in self.__dict__ or
            attr in self.__dict__ or
                not isinstance(value, ROOT.R.TObject)):
            return super(_DirectoryBase, self).__setattr__(attr, value)

        self.__setitem__(attr, value)

    def __getitem__(self, name):
        return self.Get(name)

    def __setitem__(self, name, thing):
        """
        Allow writing objects in a file with ``myfile['thing'] = myobject``
        """
        with preserve_current_directory():
            self.cd()
            thing.Write(name)

    def __iter__(self):
        return self.objects()

    def __enter__(self):
        curr_dir = ROOT.gDirectory.func()
        if curr_dir != self:
            self._prev_dir = curr_dir
        self.cd()
        return self

    def __exit__(self, type, value, traceback):
        self.Close()
        return False

    def cd_previous(self):
        """
        cd to the gDirectory before this file was open.
        """
        if isinstance(self._prev_dir, ROOT.TROOT):
            return False
        if isinstance(self._prev_dir, ROOT.TFile):
            if self._prev_dir.IsOpen() and self._prev_dir.IsWritable():
                self._prev_dir.cd()
                return True
            return False
        if not self._prev_dir.IsWritable():
            # avoid warning from ROOT stating file is not writable
            return False
        prev_file = self._prev_dir.GetFile()
        if prev_file and prev_file.IsOpen():
            self._prev_dir.cd()
            return True
        return False

    def Close(self, *args):
        """
        Like ROOT's Close but reverts to the gDirectory before this file was
        opened.
        """
        super(_DirectoryBase, self).Close(*args)
        return self.cd_previous()

    def objects(self, cls=None):
        """
        Return an iterater over all objects in this directory which are
        instances of `cls`. By default, iterate over all objects (`cls=None`).

        Parameters
        ----------

        cls : a class, optional (default=None)
            If a class is specified, only iterate over objects that are
            instances of this class.

        Returns
        -------

        A generator over the objects in this directory.

        Examples
        --------

            $ rootpy browse myfile.root

            In [1]: list(f1.objects(R.Directory))
            Out[1]: [Directory('mydirectory')]

        """
        objs = (asrootpy(x.ReadObj(), warn=False)
                for x in self.GetListOfKeys())
        if cls is not None:
            objs = (obj for obj in objs if isinstance(obj, cls))
        return objs

    def keys(self, latest=False):
        """
        Return a list of the keys in this directory.

        Parameters
        ----------

        latest : bool, optional (default=False)
            If True then return a list of keys with unique names where only the
            key with the highest cycle number is included where multiple keys
            exist with the same name.

        Returns
        -------

        keys : list
            List of keys

        """
        if latest:
            keys = {}
            for key in self.keys():
                name = key.GetName()
                if name in keys:
                    if key.GetCycle() > keys[name].GetCycle():
                        keys[name] = key
                else:
                    keys[name] = key
            return keys.values()
        return [asrootpy(key) for key in self.GetListOfKeys()]

    @wrap_path_handling
    def Get(self, path, rootpy=True, **kwargs):
        """
        Return the requested object cast as its corresponding subclass in
        rootpy if one exists and ``rootpy=True``, otherwise return the
        unadulterated TObject.
        """
        thing = super(_DirectoryBase, self).Get(path)
        if not thing:
            raise DoesNotExist

        # Ensure that the file we took the object from is alive at least as
        # long as the object being taken from it.

        # Note, Python does *not* own `thing`, it is ROOT's responsibility to
        # delete it in the C++ sense. (SetOwnership is False). However, ROOT
        # will delete the object when the TFile's destructor is run.
        # Therefore, when `thing` goes out of scope and the file referred to
        # by `this` has no references left, the file is destructed and calls
        # `thing`'s delete.

        # (this is thanks to the fact that weak referents (used by keepalive)
        #  are notified when they are dead).

        keepalive(thing, self)

        if rootpy:
            return asrootpy(thing, **kwargs)
        return thing

    @wrap_path_handling
    def GetDirectory(self, path, rootpy=True, **kwargs):
        rdir = super(_DirectoryBase, self).GetDirectory(path)
        if not rdir:
            raise DoesNotExist
        if rootpy:
            return asrootpy(rdir, **kwargs)
        return rdir

    @wrap_path_handling
    def GetKey(self, path, cycle=9999, rootpy=True, **kwargs):
        """
        Override TDirectory's GetKey and also handle accessing keys nested
        arbitrarily deep in subdirectories.
        """
        key = super(_DirectoryBase, self).GetKey(path, cycle)
        if not key:
            raise DoesNotExist
        if rootpy:
            return asrootpy(key, **kwargs)
        return key

    def __contains__(self, path):
        """
        Determine if a an object exists in the file at the path `path`::

            if 'some/thing' in file:
                # do something
        """
        try:
            self.GetKey(path)
            return True
        except DoesNotExist:
            return False

    def mkdir(self, path, title="", recurse=False):
        """
        Make a new directory. If recurse is True, create parent directories
        as required. Return the newly created TDirectory.
        """
        head, tail = os.path.split(os.path.normpath(path))
        if tail == "":
            raise ValueError("invalid directory name: {0}".format(path))
        with preserve_current_directory():
            dest = self
            if recurse:
                parent_dirs = head.split('/')
                for parent_dir in parent_dirs:
                    try:
                        newdest = dest.GetDirectory(parent_dir)
                        dest = newdest
                    except DoesNotExist:
                        dest = dest.mkdir(parent_dir)
            elif head != "":
                dest = dest.GetDirectory(head)
            if tail in dest:
                raise ValueError("{0} already exists".format(path))
            newdir = asrootpy(super(_DirectoryBase, dest).mkdir(tail, title))
        return newdir

    def rm(self, path, cycle=';*'):
        """
        Delete an object at `path` relative to this directory
        """
        rdir = self
        with preserve_current_directory():
            dirname, objname = os.path.split(os.path.normpath(path))
            if dirname:
                rdir = rdir.Get(dirname)
            rdir.Delete(objname + cycle)

    # TODO:
    # def move(self, src, dest, newname=None):

    def copytree(self, dest_dir, src=None, newname=None,
                 exclude=None, overwrite=False):
        """
        Copy this directory or just one contained object into another
        directory.

        Parameters
        ----------

        dest_dir : string or Directory
            The destination directory.

        src : string, optional (default=None)
            If ``src`` is None then this entire directory is copied recursively
            otherwise if ``src`` is a string path to an object relative to this
            directory, only that object will be copied. The copied object can
            optionally be given a ``newname``.

        newname : string, optional (default=None)
            An optional new name for the copied object.

        exclude : callable, optional (default=None)
            ``exclude`` can optionally be a function which takes
            ``(path, object_name)`` and if returns True excludes
            objects from being copied if the entire directory is being copied
            recursively.

        overwrite : bool, optional (default=False)
            If True, then overwrite existing objects with the same name.

        """
        def copy_object(obj, dest, name=None):
            if name is None:
                name = obj.GetName()
            if not overwrite and name in dest:
                raise ValueError(
                    "{0} already exists in {1} and `overwrite=False`".format(
                        name, dest._path))
            dest.cd()
            if isinstance(obj, ROOT.R.TTree):
                new_obj = obj.CloneTree(-1, "fast")
                new_obj.Write(name, ROOT.R.TObject.kOverwrite)
            else:
                obj.Write(name, ROOT.R.TObject.kOverwrite)

        with preserve_current_directory():
            if isinstance(src, basestring):
                src = asrootpy(self.Get(src))
            else:
                src = self
            if isinstance(dest_dir, basestring):
                try:
                    dest_dir = asrootpy(self.GetDirectory(dest_dir))
                except DoesNotExist:
                    dest_dir = self.mkdir(dest_dir)
            if isinstance(src, ROOT.R.TDirectory):
                # Copy a directory
                cp_name = newname if newname is not None else src.GetName()
                # See if the directory already exists
                if cp_name not in dest_dir:
                    # Destination directory doesn't exist, so make a new one
                    new_dir = dest_dir.mkdir(cp_name)
                # Copy everything in the src directory to the destination
                for (path, dirnames, objects) in src.walk(maxdepth=0):
                    # Copy all the objects
                    for object_name in objects:
                        if exclude and exclude(path, object_name):
                            continue
                        thing = src.Get(object_name)
                        copy_object(thing, new_dir)
                    for dirname in dirnames:
                        if exclude and exclude(path, dirname):
                            continue
                        rdir = src.GetDirectory(dirname)
                        # Recursively copy objects in subdirectories
                        rdir.copytree(
                            new_dir,
                            exclude=exclude, overwrite=overwrite)
            else:
                # Copy an object
                copy_object(src, dest_dir, name=newname)

    def walk(self,
             top=None,
             path=None,
             depth=0,
             maxdepth=-1,
             class_pattern=None,
             return_classname=False,
             treat_dirs_as_objs=False):
        """
        Walk the directory structure and content in and below a directory.
        For each directory in the directory tree rooted at ``top`` (including
        ``top`` itself, but excluding '.' and '..'), yield a 3-tuple
        ``dirpath, dirnames, filenames``.

        Parameters
        ----------

        top : string, optional (default=None)
            A path to a starting directory relative to this directory,
            otherwise start at this directory.

        path : string, optional (default=None)
            A path prepended as a prefix on the ``dirpath``. This argument is
            used internally as the recursion traverses down through
            subdirectories.

        depth : int, optional (default=0)
            The current depth, used internally as the recursion traverses down
            through subdirectories.

        max_depth : int, optional (default=-1)
            The maximum depth in the directory hierarchy to traverse. There is
            no limit applied by default.

        class_pattern : string, optional (default=None)
            If not None then only include objects in ``filenames`` with class
            names that match ``class_pattern``. ``class_pattern`` should be a
            Unix shell-style wildcarded string.

        return_classname : bool, optional (default=False)
            If True, then each entry in ``filenames`` is a tuple of
            the form ``(filename, classname)``.

        treat_dirs_as_objs : bool, optional (default=False)
            If True, ``filenames`` contains directories as well.

        Returns
        -------

        dirpath, dirnames, filenames : iterator
            An iterator over the 3-tuples ``dirpath, dirnames, filenames``.
            ``dirpath`` is a string, the path to the directory. ``dirnames`` is
            a list of the names of the subdirectories in ``dirpath``
            (excluding '.' and '..'). ``filenames`` is a list of the names of
            the non-directory files/objects in ``dirpath``.

        Notes
        -----

        The names in the lists are just names, with no path components.
        To get a full path (which begins with top) to a file or directory
        in ``dirpath``, use ``os.path.join(dirpath, name)``.

        """
        dirnames, objectnames = [], []
        tdirectory = self.GetDirectory(top) if top else self
        for key in tdirectory.keys(latest=True):
            name = key.GetName()
            classname = key.GetClassName()
            is_directory = classname.startswith('TDirectory')
            if is_directory:
                dirnames.append(name)
            if not is_directory or treat_dirs_as_objs:
                if class_pattern is not None:
                    if not fnmatch(classname, class_pattern):
                        continue
                name = (name if not return_classname else (name, classname))
                objectnames.append(name)
        if path:
            dirpath = os.path.join(path, tdirectory.GetName())
        elif not isinstance(tdirectory, ROOT.R.TFile):
            dirpath = tdirectory.GetName()
        else:
            dirpath = ''
        yield dirpath, dirnames, objectnames
        if depth == maxdepth:
            return
        for dirname in dirnames:
            rdir = tdirectory.GetDirectory(dirname)
            for x in rdir.walk(
                    class_pattern=class_pattern,
                    depth=depth + 1,
                    maxdepth=maxdepth,
                    path=dirpath,
                    return_classname=return_classname,
                    treat_dirs_as_objs=treat_dirs_as_objs):
                yield x


@snake_case_methods
class Directory(_DirectoryBase, QROOT.TDirectoryFile):
    """
    A subclass of ROOT's TDirectoryFile [1]

    References
    ----------

    .. [1] http://root.cern.ch/root/html/TDirectoryFile.html

    """
    _ROOT = QROOT.TDirectoryFile

    def __init__(self, name, title=None, classname='', parent=None):
        if title is None:
            title = name
        super(Directory, self).__init__(name, title, classname, parent or 0)
        self._post_init()

    def _post_init(self):
        self._path = self.GetName()
        self._parent = ROOT.gDirectory.func()
        self._prev_dir = None
        self._inited = True


class _FileBase(_DirectoryBase):

    def __init__(self, name, *args, **kwargs):
        # trigger finalSetup
        ROOT.R.kTRUE
        self._prev_dir = ROOT.gDirectory.func()
        super(_FileBase, self).__init__(name, *args, **kwargs)
        self._post_init()

    def _post_init(self):
        self._path = self.GetName()
        self._parent = self
        self._inited = True

    def _populate_cache(self):
        """
        Walk through the whole file and populate the cache
        all objects below the current path are added, i.e.
        for the contents with ina, inb and inab TH1F histograms::

           /a/ina
           /b/inb
           /a/b/inab

        the cache is (omitting the directories)::

            cache[""]["obj"] = [("a", ("ina", "TH1F")),
                                ("b", ("inb", "TH1F")),
                                ("a/b", ("inab", "TH1F"))]

            ...

            cache[""]["a"]["b"]["obj"] = [("a/b", ("inab", "TH1F"))]

        """
        self.cache = autovivitree()

        for path, dirs, objects in self.walk(return_classname=True,
                                             treat_dirs_as_objs=True):
            b = self.cache
            for d in ['']+path.split('/'):
                b = b[d]
                obj = [(path, o) for o in objects]
                if 'obj' in b:
                    b['obj'] += obj
                else:
                    b['obj'] = obj

    def find(self,
             regexp, negate_regexp=False,
             class_pattern=None,
             find_fnc=re.search,
             refresh_cache=False):
        """
        yield the full path of the matching regular expression and the
        match itself
        """
        if refresh_cache or not hasattr(self, 'cache'):
            self._populate_cache()

        b = self.cache
        split_regexp = regexp.split('/')

        # traverse as deep as possible in the cache
        # special case if the first character is not the root, i.e. not ""
        if split_regexp[0] == '':
            for d in split_regexp:
                if d in b:
                    b = b[d]
                else:
                    break
        else:
            b = b['']

        # perform the search
        for path, (obj, classname) in b['obj']:
            if class_pattern:
                if not fnmatch(classname, class_pattern):
                    continue
            joined_path = os.path.join(*['/', path, obj])
            result = find_fnc(regexp, joined_path)
            if (result is not None) ^ negate_regexp:
                yield joined_path, result


@snake_case_methods
class File(_FileBase, QROOT.TFile):
    """
    A subclass of ROOT's TFile [1]

    Examples
    --------

    >>> from rootpy.io import File
    >>> from rootpy.testdata import get_filepath
    >>> f = File(get_filepath(), 'read')
    >>> list(f)
    [Directory('means'), Directory('scales'), Directory('gaps'), Directory('efficiencies'), Directory('dimensions'), Directory('graphs')]
    >>> f.means
    Directory('rootpy/testdata/test_file.root/means')

    References
    ----------

    .. [1] http://root.cern.ch/root/html/TFile.html

    """
    _ROOT = QROOT.TFile
    # Override .Open
    open = staticmethod(root_open)
    Open = staticmethod(root_open)


@snake_case_methods
class MemFile(_FileBase, QROOT.TMemFile):
    """
    A subclass of ROOT's TMemFile [1]

    Examples
    --------

    >>> from rootpy.io import MemFile
    >>> f = MemFile()

    References
    ----------

    .. [1] http://root.cern.ch/root/html/TMemFile.html

    """
    _ROOT = QROOT.TMemFile

    def __init__(self, name=None, mode='recreate'):
        if name is None:
            name = uuid.uuid4().hex
        super(MemFile, self).__init__(name, mode)


@snake_case_methods
class TemporaryFile(File):
    """
    A temporary ROOT file that is automatically deleted when closed.
    Python's :func:`tempfile.mkstemp` [1] is used to obtain a temporary file
    in the most secure manner possible.

    Keyword arguments are passed directly to :func:`tempfile.mkstemp` [1]

    References
    ----------

    .. [1] http://docs.python.org/2/library/tempfile.html#tempfile.mkstemp

    """
    def __init__(self, suffix='.root', **kwargs):
        self.__fd, self.__tmp_path = tempfile.mkstemp(suffix=suffix, **kwargs)
        super(TemporaryFile, self).__init__(self.__tmp_path, 'recreate')

    def Close(self):
        """
        The physical file is automatically deleted after being closed.
        """
        super(TemporaryFile, self).Close()
        os.close(self.__fd)
        os.remove(self.__tmp_path)

########NEW FILE########
__FILENAME__ = pickler
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
# Original author: Scott Snyder scott.snyder(a)cern.ch, 2004.
"""Pickle python data into a ROOT file, preserving references to ROOT objects.

This module allows pickling python objects into a ROOT file. The python
objects may contain references to named ROOT objects. If one has set up a
structure of python objects to hold ROOT histograms, this provides a convenient
way of saving and restoring your histograms. The pickled python data are
stored in an additional string object in the ROOT file; any ROOT objects are
stored as usual. (Thus, ROOT files written by the pickler can be read just
like any other ROOT file if you don't care about the python data.)

Here's an example of writing a pickle::

   from rootpy.plotting import Hist
   from rootpy.io.pickler import dump
   hlist = []
   for i in range(10):
       hlist.append(Hist(10, 0, 10))
   dump(hlist, 'test.root')

This writes a list of histograms to test.root. The histograms may be read back
like this::

   from rootpy.io.pickler import load
   hlist = load('test.root')

The following additional notes apply:

* Pickling may not always work correctly for the case of python objects
  deriving from ROOT objects. It will probably also not work for the case of
  ROOT objects which do not derive from TObject.

* When the pickled data are being read, if a class doesn't exist,
  a dummy class with no methods will be used instead. This is different
  from the standard pickle behavior (where it would be an error), but it
  simplifies usage in the common case where the class is being used to hold
  histograms, and its methods are entirely concerned with filling the
  histograms.

* When restoring a reference to a ROOT object, the default behavior
  is to not read the ROOT object itself, but instead to create a proxy. The
  ROOT object will then be read the first time the proxy is accessed. This can
  help significantly with time and memory usage if you're only accessing a
  small fraction of the ROOT objects, but it does mean that you need to keep
  the ROOT file open. Pass use_proxy=0 to disable this behavior.

"""
from __future__ import absolute_import

from cStringIO import StringIO
import cPickle
import ROOT
import sys

from . import log; log = log[__name__]
from . import root_open
from ..context import preserve_current_directory


__all__ = [
    'dump',
    'load',
    'compat_hooks',
]


_compat_hooks = None
xdict = {}
xserial = 0


# Argh!  We can't store NULs in TObjStrings.
# But pickle protocols > 0 are binary protocols, and will get corrupted
# if we truncate at a NUL.
# So, when we save the pickle data, make the mappings:
#  0x00 -> 0xff 0x01
#  0xff -> 0xff 0xfe


def _protect(s):
    return s.replace('\377', '\377\376').replace('\000', '\377\001')


def _restore(s):
    return s.replace('\377\001', '\000').replace('\377\376', '\377')


class IO_Wrapper:
    def __init__(self):
        return self.reopen()

    def write(self, s):
        return self.__s.write(_protect(s))

    def read(self, i):
        return self.__s.read(i)

    def readline(self):
        return self.__s.readline()

    def getvalue(self):
        return self.__s.getvalue()

    def setvalue(self, s):
        self.__s = StringIO(_restore(s))
        return

    def reopen(self):
        self.__s = StringIO()
        return


class Pickler:
    def __init__(self, file, proto=0):
        """Create a root pickler.
        `file` should be a ROOT TFile. `proto` is the python pickle protocol
        version to use.  The python part will be pickled to a ROOT
        TObjString called _pickle; it will contain references to the
        ROOT objects.
        """
        self.__file = file
        self.__keys = file.GetListOfKeys()
        self.__io = IO_Wrapper()
        self.__pickle = cPickle.Pickler(self.__io, proto)
        self.__pickle.persistent_id = self._persistent_id
        self.__pmap = {}

    def dump(self, o, key=None):
        """Write a pickled representation of o to the open TFile."""
        if key is None:
            key = '_pickle'
        with preserve_current_directory():
            self.__file.cd()
            self.__pickle.dump(o)
            s = ROOT.TObjString(self.__io.getvalue())
            self.__io.reopen()
            s.Write(key)
            self.__file.GetFile().Flush()
            self.__pmap.clear()

    def clear_memo(self):
        """Clears the pickler's internal memo."""
        self.__pickle.memo.clear()

    def _persistent_id(self, o):
        if hasattr(o, '_ROOT_Proxy__obj'):
            o = o._ROOT_Proxy__obj()
        if isinstance(o, ROOT.TObject):
            # Write the object, and return the resulting NAME;CYCLE.
            # We used to to this like this:
            #o.Write()
            #k = self.__file.GetKey(o.GetName())
            #pid = "{0};{1:d}".format(k.GetName(), k.GetCycle())
            # It turns out, though, that destroying the python objects
            # referencing the TKeys is quite expensive (O(logN) where
            # N is the total number of pyroot objects?).  Although
            # we want to allow for the case of saving multiple objects
            # with the same name, the most common case is that the name
            # has not already been written to the file.  So we optimize
            # for that case, doing the key lookup before we write the
            # object, not after.  (Note further: GetKey() is very slow
            # if the key does not actually exist, as it does a linear
            # search of the key list.  We use FindObject instead for the
            # initial lookup, which is a hashed lookup, but it is not
            # guaranteed to find the highest cycle.  So if we do
            # find an existing key, we need to look up again using GetKey.
            nm = o.GetName()
            k = self.__keys.FindObject(nm)
            o.Write()
            if k:
                k = self.__file.GetKey(nm)
                pid = '{0};{1:d}'.format(nm, k.GetCycle())
            else:
                pid = nm + ';1'
            return pid


class ROOT_Proxy:
    def __init__(self, f, pid):
        self.__f = f
        self.__pid = pid
        self.__o = None

    def __getattr__(self, a):
        if self.__o is None:
            self.__o = self.__f.Get(self.__pid)
            if self.__o.__class__.__module__ != 'ROOT':
                self.__o.__class__.__module__ = 'ROOT'
        return getattr(self.__o, a)

    def __obj(self):
        if self.__o is None:
            self.__o = self.__f.Get(self.__pid)
            if self.__o.__class__.__module__ != 'ROOT':
                self.__o.__class__.__module__ = 'ROOT'
        return self.__o


class Unpickler:
    def __init__(self, file, use_proxy=True, use_hash=False):
        """Create a ROOT unpickler.
        `file` should be a ROOT TFile.
        """
        global xserial
        xserial += 1
        self.__use_proxy = use_proxy
        self.__file = file
        self.__io = IO_Wrapper()
        self.__unpickle = cPickle.Unpickler(self.__io)
        self.__unpickle.persistent_load = self._persistent_load
        self.__unpickle.find_global = self._find_class
        self.__n = 0
        self.__serial = '{0:d}-'.format(xserial)
        xdict[self.__serial] = file

        if use_hash:
            htab = {}
            ctab = {}
            for k in file.GetListOfKeys():
                nm = k.GetName()
                cy = k.GetCycle()
                htab[(nm, cy)] = k
                if cy > ctab.get(nm, 0):
                    ctab[nm] = cy
                    htab[(nm, 9999)] = k
            file._htab = htab
            oget = file.Get

            def xget(nm0):
                nm = nm0
                ipos = nm.find(';')
                if ipos >= 0:
                    cy = nm[ipos+1]
                    if cy == '*':
                        cy = 10000
                    else:
                        cy = int(cy)
                    nm = nm[:ipos - 1]
                else:
                    cy = 9999
                ret = htab.get((nm, cy), None)
                if not ret:
                    log.warning(
                        "did't find {0} {1} {2}".format(nm, cy, len(htab)))
                    return oget(nm0)
                #ctx = ROOT.TDirectory.TContext (file)
                ret = ret.ReadObj()
                #del ctx
                return ret
            file.Get = xget

    def load(self, key=None):
        """Read a pickled object representation from the open file."""
        if key is None:
            key = '_pickle'
        o = None
        if _compat_hooks:
            save = _compat_hooks[0]()
        try:
            self.__n += 1
            s = self.__file.Get(key + ';{0:d}'.format(self.__n))
            self.__io.setvalue(s.GetName())
            o = self.__unpickle.load()
            self.__io.reopen()
        finally:
            if _compat_hooks:
                save = _compat_hooks[1](save)
        return o

    def _persistent_load(self, pid):
        if self.__use_proxy:
            o = ROOT_Proxy(self.__file, pid)
        else:
            o = self.__file.Get(pid)
        log.debug("load {0} {1}".format(pid, o))
        xdict[self.__serial + pid] = o
        return o

    def _find_class(self, module, name):
        try:
            try:
                __import__(module)
                mod = sys.modules[module]
            except ImportError:
                log.info("Making dummy module {0}".format(module))

                class DummyModule:
                    pass

                mod = DummyModule()
                sys.modules[module] = mod
            klass = getattr(mod, name)
            return klass
        except AttributeError:
            log.info("Making dummy class {0}.{1}".format(module, name))
            mod = sys.modules[module]

            class Dummy(object):
                pass

            setattr(mod, name, Dummy)
            return Dummy


def compat_hooks(hooks):
    """Set compatibility hooks.
    If this is set, then hooks[0] is called before loading, and hooks[1] is
    called after loading.  hooks[1] is called with the return value of hooks[0]
    as an argument.  This is useful for backwards compatibility in some
    situations.
    """
    global _compat_hooks
    _compat_hooks = hooks


def dump(o, f, proto=0, key=None):
    """Dump object O to the ROOT TFile `f`.

    `f` may be an open ROOT file or directory, or a string path to an existing
    ROOT file.
    """
    if isinstance(f, basestring):
        f = root_open(f, 'recreate')
        own_file = True
    else:
        own_file = False
    ret = Pickler(f, proto).dump(o, key)
    if own_file:
        f.Close()
    return ret


def load(f, use_proxy=1, key=None):
    """Load an object from the ROOT TFile `f`.

    `f` may be an open ROOT file or directory, or a string path to an existing
    ROOT file.
    """
    if isinstance(f, basestring):
        f = root_open(f)
    return Unpickler(f, use_proxy).load(key)

########NEW FILE########
__FILENAME__ = test_file
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Tests for the file module.
"""

from rootpy.context import invisible_canvas
from rootpy.io import TemporaryFile, DoesNotExist, MemFile, File, Directory
from rootpy.io import root_open
from rootpy.plotting import Hist
from rootpy.testdata import get_file
from rootpy import ROOT

from nose.tools import assert_raises, assert_equal

import gc
import os

import ROOT as R


def test_tempfile():

    with TemporaryFile() as f:
        assert_equal(os.path.isfile(f.GetName()), True)
        assert_raises(DoesNotExist, f.Get, 'blah')
        hist = Hist(1, 0, 1, name='test')
        hist.Write()
        hist2 = f.test
        assert_equal(hist2.__class__, hist.__class__)
    assert_equal(os.path.isfile(f.GetName()), False)


def test_memfile():

    with MemFile() as f:
        hist = Hist(1, 0, 1, name='test')
        hist.Write()
        assert_equal(f['test'], hist)


def test_file_open():

    fname = 'test_file_open.root'
    with File.open(fname, 'recreate'):
        pass
    with root_open(fname):
        pass
    os.unlink(fname)


def test_context():

    with MemFile() as a:
        assert_equal(ROOT.gDirectory.func(), a)
        with MemFile() as b:
            d = Directory('test')
            with d:
                assert_equal(ROOT.gDirectory.func(), d)
            assert_equal(ROOT.gDirectory.func(), b)
        assert_equal(ROOT.gDirectory.func(), a)

    # test out of order
    f1 = MemFile()
    f2 = MemFile()
    with f1:
        assert_equal(ROOT.gDirectory.func(), f1)
    assert_equal(ROOT.gDirectory.func(), f2)
    f1.Close()
    f2.Close()

    d = Directory('test')
    d.cd()

    # test without with statement
    f1 = MemFile()
    f2 = TemporaryFile()
    assert_equal(ROOT.gDirectory.func(), f2)
    f2.Close()
    assert_equal(ROOT.gDirectory.func(), f1)
    f1.Close()


def test_file_get():

    with get_file() as f:
        d = f.Get('means', rootpy=False)
        assert_equal(d.__class__.__name__, 'TDirectoryFile')
        d = f.Get('means')
        assert_equal(d.__class__.__name__, 'Directory')
        h = f.Get('means/hist1', rootpy=False)
        assert_equal(h.__class__.__name__, 'TH1F')
        h = f.Get('means/hist1')
        assert_equal(h.__class__.__name__, 'Hist')


def test_file_item():

    with TemporaryFile() as f:
        h = Hist(1, 0, 1, name='test')
        f['myhist'] = h
        f.myhist
        assert_equal(f['myhist'].name, 'test')


def test_file_attr():

    with TemporaryFile() as f:
        h = Hist(1, 0, 1, name='test')
        f.myhist = h
        f.Get('myhist')
        assert_equal(f.myhist.name, 'test')
        f.something = 123
        f.mkdir('hello')
        f.hello.something = h
        assert_equal(f['hello/something'].name, 'test')


def test_file_contains():

    with TemporaryFile() as f:
        assert_equal('some/thing' in f, False)
        rdir = f.mkdir('some')
        thing = Hist(10, 0, 1, name='thing')
        rdir.thing = thing
        assert_equal('some/thing' in f, True)
        assert_equal('thing' in rdir, True)


def test_no_dangling_files():

    def foo():
        f = MemFile()

    foo()

    g = root_open('test_no_dangling_files.root', 'recreate')
    os.unlink('test_no_dangling_files.root')
    del g

    gc.collect()
    assert list(R.gROOT.GetListOfFiles()) == [], "There exist open ROOT files when there should not be"


def test_keepalive():

    gc.collect()
    assert list(R.gROOT.GetListOfFiles()) == [], "There exist open ROOT files when there should not be"

    # Ordinarily this would lead to h with a value of `None`, since the file
    # gets garbage collected. However, File.Get uses keepalive to prevent this.
    # The purpose of this test is to ensure that everything is working as
    # expected.
    h = get_file().Get("means/hist1")

    gc.collect()

    assert h, "hist1 is not being kept alive"

    assert list(R.gROOT.GetListOfFiles()) != [], "Expected an open ROOT file.."

    h = None

    gc.collect()
    assert list(R.gROOT.GetListOfFiles()) == [], "There exist open ROOT files when there should not be"


def test_keepalive_canvas():

    gc.collect()
    assert list(R.gROOT.GetListOfFiles()) == [], "There exist open ROOT files when there should not be"

    with invisible_canvas() as c:
        get_file().Get("means/hist1").Draw()

        gc.collect()
        assert list(R.gROOT.GetListOfFiles()) != [], "Expected an open ROOT file.."

    gc.collect()
    assert list(R.gROOT.GetListOfFiles()) == [], "There exist open ROOT files when there should not be"


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_pickler
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Tests for the file module.
"""

from rootpy.io import TemporaryFile
from rootpy.io.pickler import load, dump
from rootpy.plotting import Hist
import random
from nose.tools import assert_equal


def test_pickler():

    hlist = list()
    for i in range(10):
        hlist.append(Hist(10, 0, 10))

    with TemporaryFile() as tmpfile:
        dump(hlist, tmpfile)
        hlist_out = load(tmpfile)
        assert_equal([h.name for h in hlist_out], [h.name for h in hlist])

    hdict = dict()
    for i in range(100):
        hist = Hist(10, 0, 1, type=random.choice('CSIFD'))
        hdict[hist.name] = hist

    with TemporaryFile() as tmpfile:
        rdir = tmpfile.mkdir('pickle')
        dump(hdict, rdir)
        hdict_out = load(rdir)
        assert_equal(len(hdict_out), 100)
        for name, hist in hdict_out.items():
            assert_equal(name, hist.name)
            assert_equal(hist.TYPE, hdict[hist.name].TYPE)


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = color
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Provides a ``CustomFormatter`` and ``CustomColoredFormatter`` which are enable
to insert ANSI color codes.
"""
from __future__ import absolute_import

import logging

from .utils import check_tty

__all__ = [
    'default_log_handler',
    'CustomFormatter',
    'CustomColoredFormatter',
]

FORCE_COLOR = False

# The background is set with 40 plus the number of the color, and the foreground with 30
RED, YELLOW, BLUE, WHITE = 1, 3, 4, 7

# These are the sequences need to get colored ouput
RESET_SEQ = "\033[0m"
COLOR_SEQ = "\033[1;%dm"
BOLD_SEQ = "\033[1m"
FORMAT = "{color}{levelname}$RESET:$BOLD{name}$RESET] {message}"

def insert_seqs(message):
    return message.replace("$RESET", RESET_SEQ).replace("$BOLD", BOLD_SEQ)

def remove_seqs(message):
    return message.replace("$RESET", "").replace("$BOLD", "")

COLORS = {
    'DEBUG'   : BLUE,
    'INFO'    : WHITE,
    'WARNING' : YELLOW,
    'ERROR'   : RED,
    'CRITICAL'   : RED,
}

class CustomFormatter(logging.Formatter):
    def format(self, record):
        if not hasattr(record, "message"):
            record.message = record.getMessage()
        record.asctime = self.formatTime(record, self.datefmt)
        return self._fmt.format(color="", **record.__dict__)

class CustomColoredFormatter(CustomFormatter):
    def __init__(self, msg, datefmt=None, use_color=True):
        msg = insert_seqs(msg)
        logging.Formatter.__init__(self, msg, datefmt)
        self.use_color = use_color

    def format(self, record):
        levelname = record.levelname
        if self.use_color and levelname in COLORS:
            record.color = COLOR_SEQ % (30 + COLORS[levelname])
        else:
            record.color = ""
        if not hasattr(record, "message"):
            record.message = record.getMessage()
        record.asctime = self.formatTime(record, self.datefmt)
        return self._fmt.format(**record.__dict__)


def check_tty_handler(handler):
    if not hasattr(handler, "stream"):
        return False
    return check_tty(handler.stream)


def default_log_handler(level=logging.DEBUG, singleton={}):
    """
    Instantiates a default log handler, with colour if we're connected to a
    terminal.
    """
    if "value" in singleton:
        return singleton["value"]

    handler = logging.StreamHandler()
    if check_tty_handler(handler) or FORCE_COLOR:
        handler.setFormatter(CustomColoredFormatter(insert_seqs(FORMAT)))
    else:
        handler.setFormatter(CustomFormatter(remove_seqs(FORMAT)))

    # Make the top level logger and make it as verbose as possible.
    # The log messages which make it to the screen are controlled by the handler
    log = logging.getLogger()
    log.addHandler(handler)
    log.setLevel(level)

    singleton["value"] = handler
    return handler


########NEW FILE########
__FILENAME__ = extended_logger
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import logging
import re
import sys
import traceback
import types
import threading

__all__ = [
    'log_stack',
    'ExtendedLogger',
    'RootLoggerWrapper',
]


class ShowingStack(threading.local):
    inside = False

showing_stack = ShowingStack()


def log_stack(logger, level=logging.INFO, limit=None, frame=None):
    """
    Display the current stack on ``logger``.

    This function is designed to be used during emission of log messages, so it
    won't call itself.
    """
    if showing_stack.inside:
        return
    showing_stack.inside = True
    try:
        if frame is None:
            frame = sys._getframe(1)
        stack = "".join(traceback.format_stack(frame, limit))
        for line in (l[2:] for l in stack.split("\n") if l.strip()):
            logger.log(level, line)
    finally:
        showing_stack.inside = False

LoggerClass = logging.getLoggerClass()


class ExtendedLogger(LoggerClass):
    """
    A logger class which provides a few niceties, including automatically
    enabling logging if no handlers are available.
    """
    def __init__(self, name, *args, **kwargs):
        LoggerClass.__init__(self, name, *args, **kwargs)
        self._init(self)

    @staticmethod
    def _init(self):
        if hasattr(self, "shown_stack_frames"):
            # Don't double _init the root logger
            return
        self.__dict__.update(logging._levelNames)
        self.show_stack_regexes = []
        self.shown_stack_frames = set()

    def showdeletion(self, *objects):
        """
        Record a stack trace at the point when an ROOT TObject is deleted
        """
        from ..memory import showdeletion as S
        for o in objects:
            S.monitor_object_cleanup(o)

    def ignore(self, message_regex):
        """
        Gives a context manager which filters out messages exactly matching
        ``message_regex`` on the current filter.

        Example:

        .. sourcecode:: python

            with log["/ROOT"].ignore("^this message is ignored$"):
                ROOT.Warning("location", "this message is ignored")

        """
        from . import LogFilter
        return LogFilter(self, message_regex)

    def trace(self, level=logging.DEBUG, show_enter=True, show_exit=True):
        """
        Functions decorated with this function show function entry and exit with
        values, defaults to debug log level.

        :param level: log severity to use for function tracing
        :param show_enter: log function entry
        :param show_enter: log function exit

        Example use:

        .. sourcecode:: python

            log = rootpy.log["/myapp"]
            @log.trace()
            def salut():
                return

            @log.trace()
            def hello(what):
                salut()
                return "42"

            hello("world")
            # Result:
            #   DEBUG:myapp.trace.hello] > ('world',) {}
            #   DEBUG:myapp.trace.salut]  > () {}
            #   DEBUG:myapp.trace.salut]  < return None [0.00 sec]
            #   DEBUG:myapp.trace.hello] < return 42 [0.00 sec]

        Output:

        .. sourcecode:: none

        """
        from . import log_trace
        return log_trace(self, level, show_enter, show_exit)

    def basic_config_colorized(self):
        """
        Configure logging with a coloured output.
        """
        from .color import default_log_handler
        default_log_handler()

    def have_handlers(self):
        logger = self
        while logger:
            if logger.handlers:
                return True
            logger = logger.parent
        return False

    def show_stack(self, message_regex="^.*$", min_level=logging.DEBUG,
        limit=4096, once=True):
        """
        Enable showing the origin of log messages by dumping a stack trace into
        the ``stack`` logger at the :const:``logging.INFO`` severity.

        :param message_regex: is a full-line regex which the message must
            satisfy in order to trigger stack dump
        :param min_level: the minimum severity the message must have in order to
            trigger the stack dump
        :param limit: Maximum stack depth to show
        :param once: Only show the stack once per unique ``(logger, origin line
            of code)``
        """
        value = re.compile(message_regex), limit, once, min_level
        self.show_stack_regexes.append(value)

    @staticmethod
    def frame_unique(f):
        """
        A tuple representing a value which is unique to a given frame's line of
        execution
        """
        return f.f_code.co_filename, f.f_code.co_name, f.f_lineno

    def show_stack_depth(self, record, frame):
        """
        Compute the maximum stack depth to show requested by any hooks,
        returning -1 if there are none matching, or if we've already emitted
        one for the line of code referred to.
        """
        logger = self

        depths = [-1]
        msg = record.getMessage()

        # For each logger in the hierarchy
        while logger:
            to_match = getattr(logger, "show_stack_regexes", ())
            for regex, depth, once, min_level in to_match:
                if record.levelno < min_level:
                    continue
                if not regex.match(record.msg):
                    continue
                # Only for a given regex, line number and logger
                unique = regex, self.frame_unique(frame), record.name
                if once:
                    if unique in logger.shown_stack_frames:
                        # We've shown this one already.
                        continue
                    # Prevent this stack frame from being shown again
                    logger.shown_stack_frames.add(unique)
                depths.append(depth)
            logger = logger.parent
        return max(depths)

    def maybeShowStack(self, record):
        frame = sys._getframe(5)
        if frame.f_code.co_name == "python_logging_error_handler":
            # Special case, don't show python messsage handler in backtrace
            frame = frame.f_back
        depth = self.show_stack_depth(record, frame)
        if depth > 0:
            log_stack(self["/stack"], record.levelno, limit=depth, frame=frame)

    def callHandlers(self, record):
        if self.isEnabledFor(record.levelno) and not self.have_handlers():
            self.basic_config_colorized()
            l = self.getLogger("rootpy.logger")
            l.debug("Using rootpy's default log handler")
        result = LoggerClass.callHandlers(self, record)
        self.maybeShowStack(record)
        return result

    def getLogger(self, name):
        if not name:
            # The root logger is special, and always has the same class.
            # Therefore, we wrap it here to give it nice methods.
            return RootLoggerWrapper(logging.getLogger())
        return logging.getLogger(name)

    def __getitem__(self, suffix):
        """
        Provides ``log["child"]`` syntactic sugar to obtain a child logger, or
        ``log["/absolute"]`` to get a logger with respect to the root logger.
        """
        if suffix.startswith("/"):
            return self.getLogger(suffix[1:])
        return self.getChild(suffix)

    def getChild(self, suffix):
        """
        Taken from CPython 2.7, modified to remove duplicate prefix and suffixes
        """
        if suffix is None:
            return self
        if self.root is not self:
            if suffix.startswith(self.name + "."):
                # Remove duplicate prefix
                suffix = suffix[len(self.name + "."):]
                suf_parts = suffix.split(".")
                if len(suf_parts) > 1 and suf_parts[-1] == suf_parts[-2]:
                    # If we have a submodule's name equal to the parent's name,
                    # omit it.
                    suffix = ".".join(suf_parts[:-1])
            suffix = '.'.join((self.name, suffix))
        return self.manager.getLogger(suffix)

    def __repr__(self):
        return "<ExtendedLogger {0} at 0x{1:x}>".format(self.name, id(self))


class RootLoggerWrapper(ExtendedLogger):
    """
    Wraps python's ``logging.RootLogger`` with our nicer methods.

    RootLoggerWrapper is obtained through ``log["/"]``
    """
    def __init__(self, root_logger):
        self.__dict__["__root_logger"] = root_logger
        self._init(root_logger)

    def __getattr__(self, key):
        return getattr(self.__dict__["__root_logger"], key)

    def __setattr__(self, key, value):
        return setattr(self.__dict__["__root_logger"], key, value)

    def __repr__(self):
        return "<RootLoggerWrapper {0} at 0x{1:x}>".format(self.name, id(self))

logging.setLoggerClass(ExtendedLogger)

########NEW FILE########
__FILENAME__ = magic
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Here be dragons.

This module contains hackery to bend the CPython interpreter to our will.

It's necessary because it's not possible to throw an exception from within a
ctypes callback. Instead, the exception is thrown from a line tracer which we
forcably insert into the appropriate frame. Then we make that frame's next
opcode a ``JUMP_ABSOLUTE`` to the last line of code. Yes.

This is a bad idea and should never be used anywhere important where reliability
is a concern. Also, if you like your sanity. This thing *will* break backtraces
when you least expect it, leading to you looking at the wrong thing.

What lies within is the product of a sick mind and should never be exposed to
humanity.
"""
from __future__ import absolute_import

import ctypes
import ctypes.util
import dis
import logging
import opcode
import os
import struct
import sys
from ctypes import POINTER, Structure, py_object, c_byte, c_int, c_voidp
from traceback import print_stack

from . import log; log = log[__name__]

__all__ = [
    'get_dll',
    'get_seh',
    'set_error_handler',
    'get_f_code_idx',
    'get_frame_pointers',
    'set_linetrace_on_frame',
    're_execute_with_exception',
    'fix_ipython_startup',
]

# Set this to true if you're feeling lucky.
# (Otherwise the crash-debug-headache code is turned off)
class DANGER:
    enabled = False

ctypes.pythonapi.Py_IncRef.argtypes = ctypes.py_object,
ctypes.pythonapi.Py_DecRef.argtypes = ctypes.py_object,

svp = ctypes.sizeof(ctypes.c_voidp)
_keep_alive = []

ON_RTD = os.environ.get('READTHEDOCS', None) == 'True'


def get_dll(name):
    try:
        return ctypes.cdll.LoadLibrary(name + ".so")
    except OSError:
        pass

    if sys.platform == "darwin":
        try:
            return ctypes.cdll.LoadLibrary(name + ".dylib")
        except OSError:
            pass
    elif sys.platform in ("win32", "cygwin"):
        try:
            return ctypes.cdll.LoadLibrary(name + ".dll")
        except OSError:
            pass

    raise RuntimeError("Unable to find shared object {0}.{{so,dylib,dll}}. "
                       "Did you source thisroot.sh?".format(name))


def get_seh():
    """
    Makes a function which can be used to set the ROOT error handler with a
    python function and returns the existing error handler.
    """
    if ON_RTD:
        return lambda x: x

    ErrorHandlerFunc_t = ctypes.CFUNCTYPE(None, ctypes.c_int, ctypes.c_bool,
        ctypes.c_char_p, ctypes.c_char_p)

    # Required to avoid strange dynamic linker problem on OSX.
    # See https://github.com/rootpy/rootpy/issues/256
    import ROOT

    dll = get_dll("libCore")

    SetErrorHandler = None
    try:
        if dll:
            SetErrorHandler = dll._Z15SetErrorHandlerPFvibPKcS0_E
    except AttributeError:
        pass

    if not SetErrorHandler:
        log.warning("Couldn't find SetErrorHandler, please submit a bug report "
                    "to rootpy.")
        return lambda x: None

    SetErrorHandler.restype = ErrorHandlerFunc_t
    SetErrorHandler.argtypes = ErrorHandlerFunc_t,

    def _SetErrorHandler(fn):
        """
        Set ROOT's warning/error handler. Returns the existing one.
        """
        eh = ErrorHandlerFunc_t(fn)
        # ``eh`` can get garbage collected unless kept alive, leading to a segfault.
        _keep_alive.append(eh)
        return SetErrorHandler(eh)
    return _SetErrorHandler

if not os.environ.get('NO_ROOTPY_HANDLER', False):
    set_error_handler = get_seh()
else:
    set_error_handler = None


def get_f_code_idx():
    """
    How many pointers into PyFrame is the ``f_code`` variable?
    """
    frame = sys._getframe()
    frame_ptr = id(frame)

    LARGE_ENOUGH = 20

    # Look through the frame object until we find the f_tstate variable, whose
    # value we know from above.
    ptrs = [ctypes.c_voidp.from_address(frame_ptr+i*svp)
            for i in range(LARGE_ENOUGH)]

    # Find its index into the structure
    ptrs = [p.value for p in ptrs]

    fcode_ptr = id(frame.f_code)
    try:
        threadstate_idx = ptrs.index(fcode_ptr)
    except ValueError:
        log.critical("BUG! please report this.")
        raise
    return threadstate_idx

F_CODE_IDX = get_f_code_idx()


def get_frame_pointers(frame=None):
    """
    Obtain writable pointers to ``frame.f_trace`` and ``frame.f_lineno``.

    Very dangerous. Unlikely to be portable between python implementations.

    This is hard in general because the ``PyFrameObject`` can have a variable size
    depending on the build configuration. We can get it reliably because we can
    determine the offset to ``f_tstate`` by searching for the value of that pointer.
    """
    if frame is None:
        frame = sys._getframe(2)
    frame = id(frame)

    # http://hg.python.org/cpython/file/3aa530c2db06/Include/frameobject.h#l28
    F_TRACE_OFFSET = 6
    Ppy_object = ctypes.POINTER(ctypes.py_object)
    trace = Ppy_object.from_address(frame+(F_CODE_IDX+F_TRACE_OFFSET)*svp)

    LASTI_OFFSET = F_TRACE_OFFSET + 4

    lasti_addr  = LASTI_OFFSET
    lineno_addr = LASTI_OFFSET + ctypes.sizeof(ctypes.c_int)

    f_lineno = ctypes.c_int.from_address(lineno_addr)
    f_lasti = ctypes.c_int.from_address(lasti_addr)

    return trace, f_lineno, f_lasti


def set_linetrace_on_frame(f, localtrace=None):
    """
    Non-portable function to modify linetracing.

    Remember to enable global tracing with :py:func:`sys.settrace`, otherwise no
    effect!
    """
    traceptr, _, _ = get_frame_pointers(f)
    if localtrace is not None:
        # Need to incref to avoid the frame causing a double-delete
        ctypes.pythonapi.Py_IncRef(localtrace)
        # Not sure if this is the best way to do this, but it works.
        addr = id(localtrace)
    else:
        addr = 0

    traceptr.contents = ctypes.py_object.from_address(addr)


def globaltrace(f, why, arg):
    pass


def re_execute_with_exception(frame, exception, traceback):
    """
    Dark magic. Causes ``frame`` to raise an exception at the current location
    with ``traceback`` appended to it.

    Note that since the line tracer is raising an exception, the interpreter
    disables the global trace, so it's not possible to restore the previous
    tracing conditions.
    """
    if sys.gettrace() == globaltrace:
        # If our trace handler is already installed, that means that this
        # function has been called twice before the line tracer had a chance to
        # run. That can happen if more than one exception was logged.
        return

    call_lineno = frame.f_lineno

    def intercept_next_line(f, why, *args):
        if f is not frame:
            return
        set_linetrace_on_frame(f)
        # Undo modifications to the callers code (ick ick ick)
        back_like_nothing_happened()
        # Raise exception in (almost) the perfect place (except for duplication)
        raise exception.__class__, exception, traceback

    set_linetrace_on_frame(frame, intercept_next_line)

    linestarts = list(dis.findlinestarts(frame.f_code))
    linestarts = [a for a, l in linestarts if l >= call_lineno]

    # Jump target
    dest = linestarts[0]

    oc = frame.f_code.co_code[frame.f_lasti]
    opcode_size = 2 if ord(oc) >= opcode.HAVE_ARGUMENT else 0
    # Opcode to overwrite
    where = frame.f_lasti + 1 + opcode_size

    # dis.disco(frame.f_code)
    pc = PyCodeObject.from_address(id(frame.f_code))
    back_like_nothing_happened = pc.co_code.contents.inject_jump(where, dest)
    # print "#"*100
    # dis.disco(frame.f_code)

    sys.settrace(globaltrace)

# The following code allows direct access to a python strings' bytes.
# Expect bad things to happen if you use this.
# It's necessary because you can't ordinarily modify strings in place, and we
# need it to modify the callers' code.
PyObject_HEAD = "PyObject_HEAD", c_byte * object.__basicsize__


class PyStringObject(Structure):
    _fields_ = [("_", ctypes.c_long),
                ("_", ctypes.c_int),
                ("_", ctypes.c_ubyte*1)]

PyObject_VAR_HEAD = ("PyObject_VAR_HEAD",
    c_byte * (str.__basicsize__ - ctypes.sizeof(PyStringObject)))


class PyStringObject(Structure):
    _fields_ = [PyObject_VAR_HEAD,
                ("ob_shash", ctypes.c_long),
                ("ob_sstate", ctypes.c_int),
                ("ob_sval", ctypes.c_ubyte*1)]

    def inject_jump(self, where, dest):
        """
        Monkeypatch bytecode at ``where`` to force it to jump to ``dest``.

        Returns function which puts things back how they were.
        """
        # We're about to do dangerous things to a functions code content.
        # We can't make a lock to prevent the interpreter from using those
        # bytes, so the best we can do is to set the check interval to be high
        # and just pray that this keeps other threads at bay.
        old_check_interval = sys.getcheckinterval()
        sys.setcheckinterval(2**20)

        pb = ctypes.pointer(self.ob_sval)
        orig_bytes = [pb[where+i][0] for i in xrange(where)]

        v = struct.pack("<BH", opcode.opmap["JUMP_ABSOLUTE"], dest)

        # Overwrite code to cause it to jump to the target
        for i in xrange(3):
            pb[where+i][0] = ord(v[i])

        def tidy_up():
            """
            Put the bytecode back how it was. Good as new.
            """
            sys.setcheckinterval(old_check_interval)
            for i in xrange(3):
                pb[where+i][0] = orig_bytes[i]

        return tidy_up


class PyCodeObject(Structure):
    _fields_ = [PyObject_HEAD,
                ("co_argcount", c_int),
                ("co_nlocals", c_int),
                ("co_stacksize", c_int),
                ("co_flags", c_int),
                ("co_code", POINTER(PyStringObject))]


def fix_ipython_startup(fn):
    """
    Attempt to fix IPython startup to not print (Bool_t)1
    """
    BADSTR = 'TPython::Exec( "" )'
    GOODSTR = 'TPython::Exec( "" );'
    consts = fn.im_func.func_code.co_consts
    if BADSTR not in consts:
        return
    idx = consts.index(BADSTR)
    orig_refcount = sys.getrefcount(consts)
    del consts

    PyTuple_SetItem = ctypes.pythonapi.PyTuple_SetItem
    PyTuple_SetItem.argtypes = ctypes.py_object, ctypes.c_size_t, ctypes.py_object

    consts = ctypes.py_object(fn.im_func.func_code.co_consts)

    for _ in range(orig_refcount-2):
        ctypes.pythonapi.Py_DecRef(consts)
    try:
        ctypes.pythonapi.Py_IncRef(GOODSTR)
        PyTuple_SetItem(consts, idx, GOODSTR)
    finally:
        for _ in range(orig_refcount-2):
            ctypes.pythonapi.Py_IncRef(consts)

########NEW FILE########
__FILENAME__ = multilogging
# rootpy license excluded in this source file

# Copyright (C) 2010 Vinay Sajip. All Rights Reserved.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose and without fee is hereby granted,
# provided that the above copyright notice appear in all copies and that
# both that copyright notice and this permission notice appear in
# supporting documentation, and that the name of Vinay Sajip
# not be used in advertising or publicity pertaining to distribution
# of the software without specific, written prior permission.
# VINAY SAJIP DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING
# ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL
# VINAY SAJIP BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR
# ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER
# IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
#
"""
How to use logging with multiprocessing
---------------------------------------

The basic strategy is to set up a listener process which can have any logging
configuration you want - in this example, writing to rotated log files. Because
only the listener process writes to the log files, you don't have file
corruption caused by multiple processes trying to write to the file.

The listener process is initialised with a queue, and waits for logging events
(LogRecords) to appear in the queue. When they do, they are processed according
to whatever logging configuration is in effect for the listener process.

Other processes can delegate all logging to the listener process. They can have
a much simpler logging configuration: just one handler, a QueueHandler, needs
to be added to the root logger. Other loggers in the configuration can be set
up with levels and filters to achieve the logging verbosity you need.

A QueueHandler processes events by sending them to the multiprocessing queue
that it's initialised with.
"""
from __future__ import absolute_import

import logging
import logging.handlers
import multiprocessing

__all__ = [
    'stdlog',
    'stdout',
    'stderr',
    'QueueHandler',
    'Listener',
]


class stdlog(object):

    def __init__(self, logger):
        self.logger = logger

    def flush(self):
        for handler in self.logger.handlers:
            handler.flush()

    def write(self, s):
        raise NotImplementedError


class stdout(stdlog):

    def write(self, s):
        s = s.strip()
        if s:
            self.logger.info(s)


class stderr(stdlog):

    def write(self, s):
        s = s.strip()
        if s:
            self.logger.error(s)


class QueueHandler(logging.Handler):
    """ This is a logging handler which sends events to a multiprocessing queue.
    The plan is to add it to Python 3.2, but this can be copy pasted into
    user code for use with earlier Python versions.
    """
    def __init__(self, queue):
        """
        Initialise an instance, using the passed queue.
        """
        # fix TypeError: super() argument 1 must be type, not classobj
        # in Python 2.6, don't use super()
        # (in 2.6 the logging.Handler is an old style class)
        logging.Handler.__init__(self)
        self.queue = queue

    def emit(self, record):
        """ Emit a record.
        Writes the LogRecord to the queue.
        """
        try:
            if record.exc_info:
                # just to get traceback text into record.exc_text
                dummy = self.format(record)
                # not needed any more
                record.exc_info = None
            self.queue.put_nowait(record)
        except (KeyboardInterrupt, SystemExit):
            raise
        except:
            self.handleError(record)


class Listener(multiprocessing.Process):
    """
    Because you'll want to define the logging configurations for listener and
    workers, the listener and worker process functions take a configurer
    parameter which is a callable for configuring logging for that process.
    These functions are also passed the queue, which they use for communication.

    In practice, you can configure the listener however you want, but note that
    in this simple example, the listener does not apply level or filter logic to
    received records. In practice, you would probably want to do ths logic in
    the worker processes, to avoid sending events which would be filtered out
    between processes.

    The size of the rotated files is made small so you can see the results
    easily.

    This is the listener process top-level loop: wait for logging events
    (LogRecords) on the queue and handle them, quit when you get a None for a
    LogRecord.
    """
    def __init__(self, name, queue, capacity = 1, *args, **kwargs):

        super(Listener, self).__init__(*args, **kwargs)
        self.capacity = capacity
        self.queue = queue
        self.name = name

    def run(self):

        root = logging.getLogger()
        h = logging.handlers.RotatingFileHandler(
                self.name,
                mode='w')
        memoryHandler = logging.handlers.MemoryHandler(
                capacity=self.capacity,
                target=h)
        f = logging.Formatter(
                '%(asctime)s %(processName)-10s '
                '%(name)s %(levelname)-8s %(message)s')
        h.setFormatter(f)
        root.addHandler(memoryHandler)

        while True:
            try:
                record = self.queue.get()
                # We send this as a sentinel to tell the listener to quit.
                if record is None:
                    break
                logger = logging.getLogger(record.name)
                # No level or filter logic applied - just do it!
                logger.handle(record)
            except (KeyboardInterrupt, SystemExit):
                try:
                    memoryHandler.close()
                except:
                    pass
                raise
            except:
                import sys, traceback
                print >> sys.stderr, 'multilogging problem:'
                traceback.print_exc(file=sys.stderr)

        memoryHandler.close()

########NEW FILE########
__FILENAME__ = roothandler
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ctypes
import logging
import re
import sys

from . import root_logger, log
from .magic import DANGER, set_error_handler, re_execute_with_exception

__all__ = [
    'fixup_msg',
    'python_logging_error_handler',
]


class SHOWTRACE:
    enabled = False

SANE_REGEX = re.compile("^[^\x80-\xFF]*$")


class Initialized:
    value = False

ABORT_LEVEL = log.ERROR


def fixup_msg(lvl, msg):

    # Fixup for this ERROR to a WARNING because it has a reasonable fallback.
    # WARNING:ROOT.TGClient.TGClient] can't open display "localhost:10.0", switching to batch mode...
    #  In case you run from a remote ssh session, reconnect with ssh -Y
    if "switching to batch mode..." in msg and lvl == logging.ERROR:
        return logging.WARNING, msg

    return lvl, msg


def python_logging_error_handler(level, root_says_abort, location, msg):
    """
    A python error handler for ROOT which maps ROOT's errors and warnings on
    to python's.
    """
    from ..utils import quickroot as QROOT

    if not Initialized.value:
        QROOT.kInfo, QROOT.kWarning, QROOT.kError, QROOT.kFatal, QROOT.kSysError
        QROOT.kTRUE
        QROOT.gErrorIgnoreLevel
        Initialized.value = True

    try:
        QROOT.kTRUE
    except RuntimeError:
        # Note: If the above causes us problems, it's because this logging
        #       handler has been called multiple times already with an
        #       exception. In that case we need to force upstream to raise it.
        _, exc, traceback = sys.exc_info()
        caller = sys._getframe(2)
        re_execute_with_exception(caller, exc, traceback)

    if level < QROOT.gErrorIgnoreLevel:
        # Needed to silence some "normal" startup warnings
        # (copied from PyROOT Utility.cxx)
        return

    log = root_logger.getChild(location.replace("::", "."))

    if level >= QROOT.kSysError or level >= QROOT.kFatal:
        lvl = logging.CRITICAL
    elif level >= QROOT.kError:
        lvl = logging.ERROR
    elif level >= QROOT.kWarning:
        lvl = logging.WARNING
    elif level >= QROOT.kInfo:
        lvl = logging.INFO
    else:
        lvl = logging.DEBUG

    if not SANE_REGEX.match(msg):
        # Not ASCII characters. Escape them.
        msg = repr(msg)[1:-1]

    # Apply fixups to improve consistency of errors/warnings
    lvl, msg = fixup_msg(lvl, msg)

    log.log(lvl, msg)

    # String checks are used because we need a way of (un)forcing abort without
    # modifying a global variable (gErrorAbortLevel) for the multithread tests
    abort = lvl >= ABORT_LEVEL or "rootpy.ALWAYSABORT" in msg or root_says_abort
    if abort and not "rootpy.NEVERABORT" in msg:
        caller = sys._getframe(1)

        try:
            # We can't raise an exception from here because ctypes/PyROOT swallows it.
            # Hence the need for dark magic, we re-raise it within a trace.
            from .. import ROOTError
            raise ROOTError(level, location, msg)
        except RuntimeError:
            _, exc, traceback = sys.exc_info()

        if SHOWTRACE.enabled:
            from traceback import print_stack
            print_stack(caller)

        if DANGER.enabled:
            # Avert your eyes, dark magic be within...
            re_execute_with_exception(caller, exc, traceback)

    if root_says_abort:
        log.CRITICAL("abort().. expect a stack trace")
        ctypes.CDLL(None).abort()

########NEW FILE########
__FILENAME__ = logcheck
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
import logging
import re

from functools import wraps

import rootpy

class LogCapture(logging.Handler):
    def __init__(self, logger):
        logging.Handler.__init__(self)
        self.records = []
        self.logger = logger

    def __enter__(self):
        self.logger.addHandler(self)
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.logger.removeHandler(self)

    def emit(self, record):
        self.records.append(record)

    def contains(self, level, message_re):
        return any(r.levelname == level and message_re.search(r.getMessage())
                   for r in self.records)

class EnsureLogContains(object):
    def __init__(self, level, message_pattern):
        self.level = level
        self.message_pattern = message_pattern
        self.msg_re = re.compile(message_pattern)

    def __call__(self, func):
        @wraps(func)
        def wrapped(*args, **kwargs):

            with LogCapture(rootpy.log["/ROOT"]) as captured:
                try:
                    return func(*args, **kwargs)
                finally:
                    assert captured.contains(self.level, self.msg_re), (
                        "Expected `{0}` to emit a {1} message matching '{2}'. "
                        "It did not."
                        .format(func.__name__, self.level, self.message_pattern)
                    )

        return wrapped
########NEW FILE########
__FILENAME__ = test_roothandler
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy.defaults import use_rootpy_handler, use_rootpy_magic

if not use_rootpy_handler or not use_rootpy_magic:
    from nose.plugins.skip import SkipTest
    raise SkipTest()

import logging
import sys

from nose.tools import raises

import ROOT

import rootpy
import rootpy.logger.magic as M

from rootpy import ROOTError
from .logcheck import EnsureLogContains

M.DANGER.enabled = True

NONEXISTENT_FILE = "this-file-should-never-exist-7b078562896325fa8007a0eb0.root"

#rootpy.log["/ROOT.rootpy"].show_stack(".*tracing.*")

@EnsureLogContains("WARNING", "^This is a test message$")
def test_logging_root_messages():
    ROOT.Warning("rootpy.logger.tests", "This is a test message")

@raises(ROOTError)
def test_root_error():
    ROOT.Error("rootpy.logger.tests", "This is a test exception")

@raises(ROOTError)
def test_nonexistent_file():
    ROOT.TFile(NONEXISTENT_FILE)

@raises(ROOTError)
def test_error_finally():
    try:
        ROOT.Error("test", "finally")
    finally:
        test = 1

@raises(ROOTError)
def test_gdebug_finally():
    ROOT.gDebug = 1
    try:
        ROOT.Error("test", "finally [rootpy.ALWAYSABORT]")
    finally:
        ROOT.gDebug = 0

def test_nonexistent_file_redux():
    try:
        ROOT.TFile(NONEXISTENT_FILE)
    except ROOTError as e:
        assert e.location == "TFile::TFile"
        assert e.level == 3000
        assert NONEXISTENT_FILE in e.msg
        assert "does not exist" in e.msg
    else:
        assert False, "Should have thrown"

# The following tests ensure that things work as expected with different constructs

@raises(ROOTError)
def test_nonexistent_file_redux_part_2():
    if True:
        ROOT.TFile(NONEXISTENT_FILE)

@raises(ROOTError)
def test_nonexistent_file_redux_part_3_the_loopening():
    for i in range(10):
        ROOT.TFile(NONEXISTENT_FILE)

@raises(ROOTError)
def test_nonexistent_file_redux_part_4_the_withinating():
    class Context(object):
        def __enter__(*args): pass
        def __exit__(*args): pass

    with Context():
        ROOT.TFile(NONEXISTENT_FILE)

def test_correct_bytecode_functioning():
    # This test ensures that we don't break opcodes which follow exceptions

    fail = True
    class Continued:
        success = False

    def try_fail():
        if fail:
            ROOT.Error("rooypy.logger.tests", "TEST")
        Continued.success = True

    orig_code_bytes = [ord(i) for i in try_fail.func_code.co_code]

    #import dis
    #dis.dis(try_fail)

    try:
        try_fail()
    except ROOTError:
        pass
    else:
        assert False, "Should have thrown"

    #print "#"*80
    #dis.dis(try_fail)
    new_code_bytes = [ord(i) for i in try_fail.func_code.co_code]
    assert orig_code_bytes == new_code_bytes

    fail = False
    try_fail()

    assert Continued.success

def test_tracing_is_broken():
    def mytrace(*args):
        pass

    orig_trace = sys.gettrace()
    sys.settrace(mytrace)

    try:
        ROOT.Error("rootpy.logger.tests", "Test tracing OK")
    except ROOTError:
        pass
    else:
        assert False, "Should have thrown"

    should_be_mytrace = sys.gettrace()
    sys.settrace(orig_trace)

    assert should_be_mytrace != mytrace, "Tracing is fixed?! Awesome. Now fix the test."

########NEW FILE########
__FILENAME__ = test_threading
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import division

from rootpy.defaults import use_rootpy_handler, use_rootpy_magic

if not use_rootpy_handler or not use_rootpy_magic:
    from nose.plugins.skip import SkipTest
    raise SkipTest()

import itertools
import os
import os.path
import platform
import resource
import thread
import threading
import time

from math import ceil
from random import random

import ROOT

import rootpy; log = rootpy.log["rootpy.logger.test.threading"]
rootpy.logger.magic.DANGER.enabled = True

from .logcheck import EnsureLogContains

def optional_fatal(abort=True):
    msg = "[rootpy.ALWAYSABORT]" if abort else "[rootpy.NEVERABORT]"
    ROOT.Error("rootpy.logger.test", msg)

f = optional_fatal
optional_fatal._bytecode = lambda: map(ord, f.func_code.co_code)
optional_fatal._ORIG_BYTECODE = optional_fatal._bytecode()
optional_fatal._unmodified = lambda: f._bytecode() == f._ORIG_BYTECODE

def optional_fatal_bytecode_check():
    assert optional_fatal._unmodified(), (
        "Detected modified bytecode. This should never happen.")

number_of_fatals = itertools.count()
total = itertools.count()

def maybe_fatal():
    try:
        # Throw exceptions 80% of the time
        optional_fatal(random() < 0.8)
    except rootpy.ROOTError:
        number_of_fatals.next()
    finally:
        total.next()
        optional_fatal_bytecode_check()

def randomfatal(should_exit):
    while not should_exit.is_set():
        maybe_fatal()

def spareprocs():
    """
    Compute the maximum number of threads we can start up according to ulimit
    """
    if not os.path.exists("/proc"):
        # Return a decent small value, we just want it to run, more grindy tests
        # can take place on other machines.
        return 10

    nmax, _ = resource.getrlimit(resource.RLIMIT_NPROC)
    me = os.geteuid()
    return nmax - sum(1 for p in os.listdir("/proc")
                       if p.isdigit() and os.stat("/proc/" + p).st_uid == me)

def test_multithread_exceptions():
    should_exit = threading.Event()

    sup_logger = log["/ROOT.rootpy.logger.test"]
    old_level = sup_logger.level
    # Suppress test warnings
    sup_logger.setLevel(log.CRITICAL)

    # Run for 1/4 second or 10s if LONG_TESTS is in the environment
    length = float(os.environ.get("TEST_TIME", 0.25))

    try:
        threads = []
        for i in range(min(100, int(ceil(spareprocs()*0.8)))):
            t = threading.Thread(target=randomfatal, args=(should_exit,))
            try:
                t.start()
                threads.append(t)
            except thread.error:
                log.warning("Unable to start thread")
                break

        assert threads, "Didn't manage to start any threads!"

        time.sleep(length)

        should_exit.set()
        for t in threads:
            t.join()

    finally:
        sup_logger.setLevel(old_level)

    tot = total.next()-1
    fatals = number_of_fatals.next()-1
    fmt = "Success raising exceptions in {0} threads: total: {1} (fatals {2:%})"
    log.debug(fmt.format(len(threads), tot, fatals / tot))

########NEW FILE########
__FILENAME__ = utils
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import os

__all__ = [
    'check_tty',
]


def check_tty(stream):
    if not hasattr(stream, 'fileno'):
        return False
    try:
        fileno = stream.fileno()
        return os.isatty(fileno)
    except (OSError, IOError):
        return False

########NEW FILE########
__FILENAME__ = matrix
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from . import QROOT

__all__ = [
    'Matrix',
    'SymmetricMatrix',
]


class _MatrixBase(object):

    def __getitem__(self, loc):
        if isinstance(loc, tuple):
            i, j = loc
            return self(i, j)
        return super(_MatrixBase, self).__getitem__(loc)

    def __setitem__(self, loc, value):
        if isinstance(loc, tuple):
            i, j = loc
            # this is slow due to creation of temporaries
            self[i][j] = value
            return
        return super(_MatrixBase, self).__setitem__(loc, value)

    def to_numpy(self):
        """
        Convert this matrix into a
        `numpy.matrix <http://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html>`_.
        """
        import numpy as np
        cols, rows = self.GetNcols(), self.GetNrows()
        return np.matrix([[self(i, j)
            for j in xrange(cols)]
            for i in xrange(rows)])


class Matrix(_MatrixBase):
    """
    A factory of subclasses of the template class
    `ROOT.TMatrixT <http://root.cern.ch/root/html/TMatrixT_float_.html>`_.

    Parameters
    ----------

    type : string, optional (default='float')
        The type of the matrix elements.

    """
    @classmethod
    def dynamic_cls(cls, type='float'):

        class Matrix(_MatrixBase, QROOT.TMatrixT(type)):
            _ROOT = QROOT.TMatrixT(type)

        return Matrix

    def __new__(cls, *args, **kwargs):
        type = kwargs.pop('type', 'float')
        return cls.dynamic_cls(type)(*args, **kwargs)


class SymmetricMatrix(Matrix):
    """
    A factory of subclasses of the template class
    `ROOT.TMatrixTSym <http://root.cern.ch/root/html/TMatrixTSym_float_.html>`_.

    Parameters
    ----------

    type : string, optional (default='float')
        The type of the matrix elements.

    """
    @classmethod
    def dynamic_cls(cls, type='float'):

        class SymmetricMatrix(_MatrixBase, QROOT.TMatrixTSym(type)):
            _ROOT = QROOT.TMatrixTSym(type)

        return SymmetricMatrix

########NEW FILE########
__FILENAME__ = deletion
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module supports monitoring TObject deletions.

.. warning::
   This is not recommended for production

"""
from __future__ import absolute_import

from weakref import ref
import ctypes
from ctypes import CFUNCTYPE, py_object, addressof, c_int

from .. import compiled as C
from .. import QROOT, log
from ..utils.cinterface import callback, objectproxy_realaddress


__all__ = [
    'monitor_deletion',
    'monitor_object_deletion',
]


def monitor_deletion():
    """
    Function for checking for correct deletion of weakref-able objects.

    Example usage::

        monitor, is_alive = monitor_deletion()
        obj = set()
        monitor(obj, "obj")
        assert is_alive("obj") # True because there is a ref to `obj` is_alive
        del obj
        assert not is_alive("obj") # True because there `obj` is deleted

    """
    monitors = {}

    def set_deleted(x):
        def _(weakref):
            del monitors[x]
        return _

    def monitor(item, name):
        monitors[name] = ref(item, set_deleted(name))

    def is_alive(name):
        return monitors.get(name, None) is not None

    return monitor, is_alive


cleanuplog = log["memory.cleanup"]
cleanuplog.show_stack()

# Add python to the include path
C.add_python_includepath()

C.register_code("""
    #ifndef __CINT__
    #include <Python.h>
    #endif
    #include <TObject.h>
    #include <TPython.h>

    class RootpyObjectCleanup : public TObject {
    public:
        typedef void (*CleanupCallback)(PyObject*);
        CleanupCallback _callback;

        RootpyObjectCleanup(CleanupCallback callback) : _callback(callback) {}

        virtual void RecursiveRemove(TObject* object) {
            // When arriving here, object->ClassName() will _always_ be TObject
            // since we're called by ~TObject, and virtual method calls don't
            // work as expected from there.
            PyObject* o = TPython::ObjectProxy_FromVoidPtr(object, "TObject");

            PyGILState_STATE gstate;
            gstate = PyGILState_Ensure();
            PyObject *ptype, *pvalue, *ptraceback;
            PyErr_Fetch(&ptype, &pvalue, &ptraceback);

            _callback(o);

            PyErr_Restore(ptype, pvalue, ptraceback);
            PyGILState_Release(gstate);
        }

        ClassDef(RootpyObjectCleanup, 0);
    };

    ClassImp(RootpyObjectCleanup);

""", ["RootpyObjectCleanup"])

MONITORED = {}


@CFUNCTYPE(None, py_object)
def on_cleanup(tobject):
    # Note, when we arrive here, tobject is in its ~TObject, and hence the
    # subclass part of the object doesn't exist, in some sense. Hence why we
    # store information about the object on the MONITORED dict.
    addr = objectproxy_realaddress(tobject)
    if addr in MONITORED:
        args = MONITORED[addr]
        fn, args = args[0], args[1:]
        fn(tobject, *args)
        del MONITORED[addr]

initialized = False


def init():
    global initialized
    if initialized: return
    initialized = True

    cleanup = C.RootpyObjectCleanup(callback(on_cleanup))

    cleanups = QROOT.gROOT.GetListOfCleanups()
    cleanups.Add(cleanup)

    import atexit

    @atexit.register
    def exit():
        # Needed to ensure we don't get called after ROOT has gone away
        cleanups.RecursiveRemove(cleanup)


def monitor_object_deletion(o, fn=lambda *args: None):

    init()

    # Required so that GetListOfCleanups().RecursiveRemove() is called.
    o.SetBit(o.kMustCleanup)

    args = fn, type(o).__name__, o.GetName(), o.GetTitle(), repr(o)
    MONITORED[objectproxy_realaddress(o)] = args

########NEW FILE########
__FILENAME__ = keepalive
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import weakref
import os

from . import log; log = log[__name__]

__all__ = [
    'keepalive',
]

KEEPALIVE = weakref.WeakKeyDictionary()
DISABLED = 'NO_ROOTPY_KEEPALIVE' in os.environ


def keepalive(nurse, *patients):
    """
    Keep ``patients`` alive at least as long as ``nurse`` is around using a
    ``WeakKeyDictionary``.
    """
    if DISABLED:
        return
    for p in patients:
        log.debug("Keeping {0} alive for lifetime of {1}".format(p, nurse))
    KEEPALIVE.setdefault(nurse, set()).update(patients)

########NEW FILE########
__FILENAME__ = ownership
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from .. import compiled as C

__all__ = [
    'GetOwnership',
]

C.register_code("""
    #include <sys/types.h>       // for ssize_t

    struct _object;

    struct TFakeObjectProxy {
       ssize_t fRefCnt;          // PyObject_HEAD
       void* fPyType;            // PyObject_HEAD
       void* fRootObj;
       int fFlags;
    };

    bool GetOwnership(_object* obj) {
       return (reinterpret_cast<TFakeObjectProxy*>(obj))->fFlags & 0x0001;
    }
""", ["GetOwnership"])


def GetOwnership(obj):
    """
    The analagous function to :func:``ROOT.SetOwnership``.
    This function is intended for diagnostic purposes and is not guaranteed to
    keep working.
    """
    # This is not a straight assignment because C.GetOwnership causes
    # finalsetup and compilation.
    return C.GetOwnership(obj)

########NEW FILE########
__FILENAME__ = test_getownership
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License

from rootpy.memory.ownership import GetOwnership

import ROOT as R

def test_getownership():
    o = R.TObject()
    assert GetOwnership(o)
    R.SetOwnership(o, False)
    assert not GetOwnership(o)

########NEW FILE########
__FILENAME__ = test_keepalive
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License

import gc
import weakref

import ROOT as R

import rootpy.plotting
from rootpy.context import invisible_canvas
from rootpy.memory.deletion import monitor_deletion


def test_keepalive():
    class went_away:
        value = False

    def callback(*args):
        went_away.value = True

    with invisible_canvas() as c:
        c.cd()

        # No primitives to start with
        assert c.GetListOfPrimitives().GetSize() == 0

        h = R.TH1F()
        h.Draw()

        hproxy = weakref.proxy(h, callback)

        # Now we've got one primitive on the canvas
        assert c.GetListOfPrimitives().GetSize() == 1

        del h
        gc.collect()
        # We should still have it due to the keepalive
        assert c.GetListOfPrimitives().GetSize() == 1

    # Canvas should now have gone away
    assert not c

    # And so should the histogram object
    assert went_away.value

def test_nokeepalive():
    with invisible_canvas() as c:

        assert c.GetListOfPrimitives().GetSize() == 0

        h = R.TH1F()
        h.Draw()

        assert c.GetListOfPrimitives().GetSize() == 1
        del h
        from rootpy.memory import KEEPALIVE
        KEEPALIVE.clear()

        # ROOT automatically cleans things up like this on deletion, and since
        # we cleared the keepalive dictionary, they should have gone away.
        assert c.GetListOfPrimitives().GetSize() == 0

def test_canvas_divide():
    monitor, is_alive = monitor_deletion()

    with invisible_canvas() as c:
        monitor(c, "c")

        c.Divide(2)

        p = c.cd(1)

        monitor(p, "p")
        assert is_alive("p")

        h = R.TH1F()
        h.Draw()
        monitor(h, "h")

        assert is_alive("h")
        del h
        assert is_alive("h")

        del p
        # p should be kept alive because of the canvas
        assert is_alive("p")
        # h should still be alive because of the pad
        assert is_alive("h")

        c.Clear()

        # clearing the canvas means that the pad (and therefore the hist) should
        # be deleted.
        assert not is_alive("p")
        assert not is_alive("h")

        # -------------
        # Next test, check that when the canvas is deleted, everything goes away

        p = c.cd(2)
        h = R.TH1F()
        h.Draw()

        monitor(p, "p")
        monitor(p, "h")

        del p
        del h

        assert is_alive("p")
        assert is_alive("h")

    # The canvas is deleted by exiting the with statement.
    # Everything should go away.
    assert not is_alive("c")
    assert not is_alive("p")
    assert not is_alive("h")


########NEW FILE########
__FILENAME__ = autobinning
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import types
import numpy as np

from ..extern.decorator import decorator

__all__ = [
    'autobinning',
]


def _minmax(data):
    return np.min(data), np.max(data)


def autobinning(data, method="freedman_diaconis"):
    """
    This method determines the optimal binning for histogramming.

    Parameters
    ----------
    data: 1D array-like
          Input data.
    method: string, one of the following:
          - sturges
          - sturges-doane
          - scott
          - sqrt
          - doane
          - freedman-diaconis
          - risk
          - knuth

    Returns
    -------
    (nbins, min, max): int, type(data), type(data)
         nbins is the optimal number of bin estimated by the method
         min is the minimum of data
         max is the maximum of data

    Notes
    -----
    If the length of data is less than 4 the method retun nbins = 1
    """
    name = method.replace("-", "_")
    try:
        method = getattr(BinningMethods, name)
        if not isinstance(method, types.FunctionType):
            raise AttributeError
    except AttributeError:
        raise ValueError("`{0}` is not a valid binning method".format(name))
    if len(data) < 4:
        return 1, np.min(data), np.max(data)
    return int(np.ceil(method(data))), np.min(data), np.max(data)


class BinningMethods(object):
    """
    Static methods on this class are available as methods for ``autobinning``.
    """
    @classmethod
    def all_methods(cls):
        """
        Return the names of all available binning methods
        """
        def name(fn):
            return fn.__get__(cls).__name__.replace("_", "-")
        return sorted(name(f) for f in cls.__dict__.values()
                      if isinstance(f, staticmethod))

    @staticmethod
    def sturges(data):
        n = len(data)
        return np.log2(n) + 1

    @staticmethod
    def sturges_doane(data):
        """
        References
        ----------
        .. [1] D. Wilkinson, "The Grammar of Graphics", 2005.
               http://books.google.it/books?id=_kRX4LoFfGQC&lpg=PA133&ots=APHb0-p6tY&dq=doane%20binning%20histogram&hl=it&pg=PA133#v=onepage&q=doane%20binning%20histogram&f=false
        """
        n = len(data)
        return np.log10(n) * np.log2(n) + 3

    @staticmethod
    def doane(data):
        """
        Modified Doane modified
        """
        from scipy.stats import skew
        n = len(data)
        sigma = np.sqrt(6. * (n - 2.) / (n + 1.) / (n + 3.))
        return 1 + np.log2(n) + \
            np.log2(1 + np.abs(skew(data)) / sigma)

    @staticmethod
    def scott(data):
        sigma = np.std(data)
        n = len(data)
        h = 3.49 * sigma * n ** (-1. / 3.)
        return (np.max(data) - np.min(data)) / h

    @staticmethod
    def sqrt(data):
        return np.sqrt(len(data))

    @staticmethod
    def freedman_diaconis(data):
        from scipy.stats.mstats import mquantiles
        q = mquantiles(data, prob=[0.25, 0.75])
        IQR = q[1] - q[0]  # interquartile range
        n = len(data)
        h = 2 * IQR / n ** (1. / 3.)
        return (np.max(data) - np.min(data)) / h

    @staticmethod
    def risk(data):
        import scipy.optimize as optimize

        m, M = _minmax(data)

        def f(data):
            def fff(x):  # h is spacing
                h = x[0]
                nbins = (M - m) / h
                binning = np.arange(m, M, h)
                if not len(binning):
                    return float("+inf")
                histo, bincenters = np.histogram(data, binning)
                bincenters = 0.5 * (bincenters[1:] + bincenters[:-1])
                mean = 1. / nbins * np.sum(histo)
                v2 = 1. / nbins * np.sum((histo - mean) ** 2)
                return (2 * mean - v2) / h ** 2
            return fff

        k0 = np.sqrt(len(data))
        h0 = (M - m) / k0
        h = optimize.fmin(f(data), np.array([h0]), disp=False)[0]
        return (M - m) / h

    @staticmethod
    def knuth(data):
        """
        References
        ----------
        .. [1] K. Knuth, "Optimal Data-Based Binning for Histograms", 2006.
               http://arxiv.org/pdf/physics/0605197v1.pdf
        """
        import scipy.optimize as optimize

        def f(data):
            from scipy.special import gammaln

            m, M = _minmax(data)
            n = len(data)

            def fff(x):
                k = x[0]  # number of bins
                if k <= 0:
                    return float("+inf")
                binning = np.linspace(m, M, k + 1)
                histo, bincenters = np.histogram(data, binning)

                return -(n * np.log(k) + gammaln(k / 2.) - gammaln(n + k / 2.) +
                         k * gammaln(1. / 2.) + np.sum(gammaln(histo + 0.5)))
            return fff

        k0 = np.sqrt(len(data))
        return optimize.fmin(f(data), np.array([k0]), disp=False)[0]

    @staticmethod
    def wand(data):
        """
        References
        ----------
        .. [1] M. Wand, "Statistical Computing and Graphics", 1997.
               http://web.ipac.caltech.edu/staff/fmasci/home/statistics_refs/OptimumHistogram.pdf
        """
        raise NotImplementedError

########NEW FILE########
__FILENAME__ = axis
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from .. import QROOT
from ..base import NamedObject
from .utils import canvases_with

__all__ = [
    'Axis',
]


class Axis(NamedObject, QROOT.TAxis):
    _ROOT = QROOT.TAxis

    def __init__(self, name=None, title=None):
        super(Axis, self).__init__(name=name, title=title)

    @property
    def range_user(self):
        first, last = self.GetFirst(), self.GetLast()
        return self.GetBinLowEdge(first), self.GetBinUpEdge(last)

    @range_user.setter
    def range_user(self, r):
        low, high = r
        self.SetRangeUser(low, high)

    def SetRangeUser(self, low, high):
        super(Axis, self).SetRangeUser(low, high)
        # Notify relevant canvases that they are modified.
        # Note: some might be missed if our parent is encapsulated in some
        #       other class.
        for c in canvases_with(self.GetParent()):
            c.Modified()
            c.Update()

    @property
    def limits(self):
        return self.GetXmin(), self.GetXmax()

    @limits.setter
    def limits(self, r):
        low, high = r
        self.SetLimits(low, high)

    def SetLimits(self, low, high):
        super(Axis, self).SetLimits(low, high)
        # Notify relevant canvases that they are modified.
        # Note: some might be missed if our parent is encapsulated in some
        #       other class.
        for c in canvases_with(self.GetParent()):
            c.Modified()
            c.Update()

########NEW FILE########
__FILENAME__ = base
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module contains base classes defining core funcionality
"""
from __future__ import absolute_import

from functools import wraps
import warnings

import ROOT

from .. import asrootpy
from ..decorators import chainable
from ..memory.keepalive import keepalive

__all__ = [
    'dim',
    'Plottable',
]


def dim(thing):
    if hasattr(thing.__class__, 'DIM'):
        return thing.__class__.DIM
    elif hasattr(thing, '__dim__'):
        return thing.__dim__()
    elif hasattr(thing, 'GetDimension'):
        return thing.GetDimension()
    else:
        raise TypeError(
            "Unable to determine dimensionality of "
            "object of type {0}".format(type(thing)))


class Plottable(object):
    """
    This is a mixin to provide additional attributes for plottable classes
    and to override ROOT TAttXXX and Draw methods.
    """
    EXTRA_ATTRS = {
        'norm': None,
        'drawstyle': '',
        'legendstyle': 'P',
        'integermode': False,
        'visible': True,
        'inlegend': True,
        }

    EXTRA_ATTRS_DEPRECATED = {
        'format': 'drawstyle',
        'intmode': 'integermode',
        }

    EXTRA_SETTERS = [
        'color',
        ]

    # TODO: respect current TStyle
    DEFAULT_DECOR = {
        'markerstyle': 'circle',
        'markercolor': 'black',
        'markersize': 1,
        'fillcolor': 'white',
        'fillstyle': 'hollow',
        'linecolor': 'black',
        'linestyle': 'solid',
        'linewidth': 1,
        }

    @classmethod
    def _get_attr_depr(cls, depattr, newattr):
        def f(self):
            warnings.warn(
                "`{0}` is deprecated and will be removed in "
                "future versions. Use `{1}` instead".format(
                    depattr, newattr),
                DeprecationWarning)
            return getattr(self, newattr)
        return f

    @classmethod
    def _set_attr_depr(cls, depattr, newattr):
        def f(self, value):
            warnings.warn(
                "`{0}` is deprecated and will be removed in "
                "future versions. Use `{1}` instead".format(
                    depattr, newattr),
                DeprecationWarning)
            setattr(self, newattr, value)
        return f

    def _post_init(self, **kwargs):
        self._clone_post_init(obj=None, **kwargs)

    def _clone_post_init(self, obj, **kwargs):
        """
        obj must be another Plottable instance. obj is used by Clone to properly
        transfer all attributes onto this object.
        """
        # Initialize the extra attributes
        for attr, value in Plottable.EXTRA_ATTRS.items():
            if obj is not None:
                setattr(self, attr, getattr(obj, attr))
            else:
                # Use the default value
                setattr(self, attr, value)

        # Create aliases from deprecated to current attributes
        for depattr, newattr in Plottable.EXTRA_ATTRS_DEPRECATED.items():
            setattr(Plottable, depattr,
                    property(
                        fget=Plottable._get_attr_depr(depattr, newattr),
                        fset=Plottable._set_attr_depr(depattr, newattr)))

        if obj is not None:
            # Initialize style attrs to style of the other object
            if isinstance(self, ROOT.TAttLine):
                self.SetLineColor(obj.GetLineColor())
                self.SetLineStyle(obj.GetLineStyle())
                self.SetLineWidth(obj.GetLineWidth())
            if isinstance(self, ROOT.TAttFill):
                self.SetFillColor(obj.GetFillColor())
                self.SetFillStyle(obj.GetFillStyle())
            if isinstance(self, ROOT.TAttMarker):
                self.SetMarkerColor(obj.GetMarkerColor())
                self.SetMarkerStyle(obj.GetMarkerStyle())
                self.SetMarkerSize(obj.GetMarkerSize())

        else:
            # Initialize style attrs to style of TObject
            if isinstance(self, ROOT.TAttLine):
                self._linecolor = Color(ROOT.TAttLine.GetLineColor(self))
                self._linestyle = LineStyle(ROOT.TAttLine.GetLineStyle(self))
                self._linewidth = ROOT.TAttLine.GetLineWidth(self)
            if isinstance(self, ROOT.TAttFill):
                self._fillcolor = Color(ROOT.TAttFill.GetFillColor(self))
                self._fillstyle = FillStyle(ROOT.TAttFill.GetFillStyle(self))
            if isinstance(self, ROOT.TAttMarker):
                self._markercolor = Color(ROOT.TAttMarker.GetMarkerColor(self))
                self._markerstyle = MarkerStyle(ROOT.TAttMarker.GetMarkerStyle(self))
                self._markersize = ROOT.TAttMarker.GetMarkerSize(self)

        if obj is None:
            # Populate defaults
            decor = dict(**Plottable.DEFAULT_DECOR)
            decor.update(Plottable.EXTRA_ATTRS)
            if 'color' in kwargs:
                decor.pop('linecolor', None)
                decor.pop('fillcolor', None)
                decor.pop('markercolor', None)
            decor.update(kwargs)
            self.decorate(**decor)
        else:
            self.decorate(**kwargs)

    @chainable
    def decorate(self, **kwargs):
        """
        Apply style options to a Plottable object.

        Returns a reference to self.
        """
        if 'color' in kwargs:
            incompatible = []
            for othercolor in ('linecolor', 'fillcolor', 'markercolor'):
                if othercolor in kwargs:
                    incompatible.append(othercolor)
            if incompatible:
                raise ValueError(
                    "Setting both the `color` and the `{1}` attribute{2} "
                    "is ambiguous. Please set only one.".format(
                        ', '.join(incompatible),
                        's' if len(incompatible) != 1 else ''))
        for key, value in kwargs.items():
            if key in Plottable.EXTRA_ATTRS_DEPRECATED:
                newkey = Plottable.EXTRA_ATTRS_DEPRECATED[key]
                warnings.warn(
                    "`{0}` is deprecated and will be removed in "
                    "future versions. Use `{1}` instead".format(
                        key, newkey),
                    DeprecationWarning)
                key = newkey
            if key in Plottable.EXTRA_ATTRS:
                setattr(self, key, value)
            elif key == 'markerstyle':
                self.SetMarkerStyle(value)
            elif key == 'markercolor':
                self.SetMarkerColor(value)
            elif key == 'markersize':
                self.SetMarkerSize(value)
            elif key == 'fillcolor':
                self.SetFillColor(value)
            elif key == 'fillstyle':
                self.SetFillStyle(value)
            elif key == 'linecolor':
                self.SetLineColor(value)
            elif key == 'linestyle':
                self.SetLineStyle(value)
            elif key == 'linewidth':
                self.SetLineWidth(value)
            elif key == 'color':
                self.SetColor(value)
            else:
                raise AttributeError(
                    "unknown decoration attribute: `{0}`".format(key))
        return self

    @property
    def decorators(self):

        return {
            "norm": self.norm,
            "drawstyle": self.drawstyle,
            "legendstyle": self.legendstyle,
            "integermode": self.integermode,
            "visible": self.visible,
            "inlegend": self.inlegend,
            "markercolor": self.GetMarkerColor(),
            "markerstyle": self.GetMarkerStyle(),
            "markersize": self.GetMarkerSize(),
            "fillcolor": self.GetFillColor(),
            "fillstyle": self.GetFillStyle(),
            "linecolor": self.GetLineColor(),
            "linestyle": self.GetLineStyle(),
            "linewidth": self.GetLineWidth(),
        }

    def SetLineColor(self, color):
        """
        *color* may be any color understood by ROOT or matplotlib.

        For full documentation of accepted *color* arguments, see
        :class:`rootpy.plotting.style.Color`.
        """
        self._linecolor = Color(color)
        if isinstance(self, ROOT.TAttLine):
            ROOT.TAttLine.SetLineColor(self, self._linecolor('root'))

    def GetLineColor(self, mode=None):
        """
        *mode* may be 'root', 'mpl', or None to return the ROOT, matplotlib,
        or input value.
        """
        return self._linecolor(mode)

    @property
    def linecolor(self):
        return self.GetLineColor()

    @linecolor.setter
    def linecolor(self, color):
        self.SetLineColor(color)

    def SetLineStyle(self, style):
        """
        *style* may be any line style understood by ROOT or matplotlib.

        For full documentation of accepted *style* arguments, see
        :class:`rootpy.plotting.style.LineStyle`.
        """
        self._linestyle = LineStyle(style)
        if isinstance(self, ROOT.TAttLine):
            ROOT.TAttLine.SetLineStyle(self, self._linestyle('root'))

    def GetLineStyle(self, mode=None):
        """
        *mode* may be 'root', 'mpl', or None to return the ROOT, matplotlib,
        or input value.
        """
        return self._linestyle(mode)

    @property
    def linestyle(self):
        return self.GetLineStyle()

    @linestyle.setter
    def linestyle(self, style):
        self.SetLineStyle(style)

    def SetLineWidth(self, width):
        if isinstance(self, ROOT.TAttLine):
            ROOT.TAttLine.SetLineWidth(self, width)
        else:
            self._linewidth = width

    def GetLineWidth(self):
        if isinstance(self, ROOT.TAttLine):
            return ROOT.TAttLine.GetLineWidth(self)
        else:
            return self._linewidth

    @property
    def linewidth(self):
        return self.GetLineWidth()

    @linewidth.setter
    def linewidth(self, width):
        self.SetLineWidth(width)

    def SetFillColor(self, color):
        """
        *color* may be any color understood by ROOT or matplotlib.

        For full documentation of accepted *color* arguments, see
        :class:`rootpy.plotting.style.Color`.
        """
        self._fillcolor = Color(color)
        if isinstance(self, ROOT.TAttFill):
            ROOT.TAttFill.SetFillColor(self, self._fillcolor('root'))

    def GetFillColor(self, mode=None):
        """
        *mode* may be 'root', 'mpl', or None to return the ROOT, matplotlib,
        or input value.
        """
        return self._fillcolor(mode)

    @property
    def fillcolor(self):
        return self.GetFillColor()

    @fillcolor.setter
    def fillcolor(self, color):
        self.SetFillColor(color)

    def SetFillStyle(self, style):
        """
        *style* may be any fill style understood by ROOT or matplotlib.

        For full documentation of accepted *style* arguments, see
        :class:`rootpy.plotting.style.FillStyle`.
        """
        self._fillstyle = FillStyle(style)
        if isinstance(self, ROOT.TAttFill):
            ROOT.TAttFill.SetFillStyle(self, self._fillstyle('root'))

    def GetFillStyle(self, mode=None):
        """
        *mode* may be 'root', 'mpl', or None to return the ROOT, matplotlib,
        or input value.
        """
        return self._fillstyle(mode)

    @property
    def fillstyle(self):
        return self.GetFillStyle()

    @fillstyle.setter
    def fillstyle(self, style):
        self.SetFillStyle(style)

    def SetMarkerColor(self, color):
        """
        *color* may be any color understood by ROOT or matplotlib.

        For full documentation of accepted *color* arguments, see
        :class:`rootpy.plotting.style.Color`.
        """
        self._markercolor = Color(color)
        if isinstance(self, ROOT.TAttMarker):
            ROOT.TAttMarker.SetMarkerColor(self, self._markercolor('root'))

    def GetMarkerColor(self, mode=None):
        """
        *mode* may be 'root', 'mpl', or None to return the ROOT, matplotlib,
        or input value.
        """
        return self._markercolor(mode)

    @property
    def markercolor(self):
        return self.GetMarkerColor()

    @markercolor.setter
    def markercolor(self, color):
        self.SetMarkerColor(color)

    def SetMarkerStyle(self, style):
        """
        *style* may be any marker style understood by ROOT or matplotlib.

        For full documentation of accepted *style* arguments, see
        :class:`rootpy.plotting.style.MarkerStyle`.
        """
        self._markerstyle = MarkerStyle(style)
        if isinstance(self, ROOT.TAttMarker):
            ROOT.TAttMarker.SetMarkerStyle(self, self._markerstyle('root'))

    def GetMarkerStyle(self, mode=None):
        """
        *mode* may be 'root', 'mpl', or None to return the ROOT, matplotlib,
        or input value.
        """
        return self._markerstyle(mode)

    @property
    def markerstyle(self):
        return self.GetMarkerStyle()

    @markerstyle.setter
    def markerstyle(self, style):
        self.SetMarkerStyle(style)

    def SetMarkerSize(self, size):
        if isinstance(self, ROOT.TAttMarker):
            ROOT.TAttMarker.SetMarkerSize(self, size)
        else:
            self._markersize = size

    def GetMarkerSize(self):
        if isinstance(self, ROOT.TAttMarker):
            return ROOT.TAttMarker.GetMarkerSize(self)
        else:
            return self._markersize

    @property
    def markersize(self):
        return self.GetMarkerSize()

    @markersize.setter
    def markersize(self, size):
        self.SetMarkerSize(size)

    def SetColor(self, color):
        """
        *color* may be any color understood by ROOT or matplotlib.

        Set all color attributes with one method call.

        For full documentation of accepted *color* arguments, see
        :class:`rootpy.plotting.style.Color`.
        """
        self.SetFillColor(color)
        self.SetLineColor(color)
        self.SetMarkerColor(color)

    def GetColor(self):
        return self.GetMarkerColor(), self.GetLineColor(), self.GetFillColor()

    @property
    def color(self):
        return self.GetColor()

    @color.setter
    def color(self, color):
        self.SetColor(color)

    @property
    def xaxis(self):
        return asrootpy(self.GetXaxis())

    @property
    def yaxis(self):
        return asrootpy(self.GetYaxis())

    @property
    def zaxis(self):
        return asrootpy(self.GetZaxis())

    def Draw(self, *args, **kwargs):
        """
        Parameters
        ----------
        args : positional arguments
            Positional arguments are passed directly to ROOT's Draw
        kwargs : keyword arguments
            If keyword arguments are present, then a clone is drawn instead
            with DrawCopy, where the name, title, and style attributes are
            taken from ``kwargs``.

        Returns
        -------
        If ``kwargs`` is not empty and a clone is drawn, then the clone is
        returned, otherwise None is returned.
        """
        if kwargs:
            return self.DrawCopy(*args, **kwargs)

        pad = ROOT.gPad.func()
        own_pad = False
        if not pad:
            # avoid circular import by delaying import until needed here
            from .canvas import Canvas
            pad = Canvas()
            own_pad = True
        if self.visible:
            if self.drawstyle:
                self.__class__.__bases__[-1].Draw(self,
                    " ".join((self.drawstyle, ) + args))
            else:
                self.__class__.__bases__[-1].Draw(self, " ".join(args))
            pad.Modified()
            pad.Update()
        if own_pad:
            keepalive(self, pad)

    def DrawCopy(self, *args, **kwargs):
        """
        Parameters
        ----------
        args : positional arguments
            Positional arguments are passed directly to ROOT's Draw
        kwargs : keyword arguments
            The name, title, and style attributes of the clone are
            taken from ``kwargs``.

        Returns
        -------
        The clone.
        """
        copy = self.Clone(**kwargs)
        copy.Draw(*args)
        return copy


class _StyleContainer(object):
    """
    Base class for grouping together an input style with ROOT and matplotlib
    styles.
    """
    def __init__(self, value, function):
        self._input = value
        self._root = function(value, 'root')
        self._mpl = function(value, 'mpl')

    def __call__(self, output_type=None):
        if not output_type:
            output_type = 'input'
        return getattr(self, '_' + output_type)

    def __repr__(self):
        return str(self._input)


##############################
#### Markers #################

markerstyles_root2mpl = {
    1: '.',
    2: '+',
    3: '*',
    4: 'o',
    5: 'x',
    20: 'o',
    21: 's',
    22: '^',
    23: 'v',
    24: 'o',
    25: 's',
    26: '^',
    27: 'd',
    28: '+',
    29: '*',
    30: '*',
    31: '*',
    32: 'v',
    33: 'D',
    34: '+',
    }
for i in range(6, 20):
    markerstyles_root2mpl[i] = '.'

markerstyles_mpl2root = {
    '.': 1,
    ',': 1,
    'o': 4,
    'v': 23,
    '^': 22,
    '<': 23,
    '>': 22,
    '1': 23,
    '2': 22,
    '3': 23,
    '4': 22,
    's': 25,
    'p': 25,
    '*': 3,
    'h': 25,
    'H': 25,
    '+': 2,
    'x': 5,
    'D': 33,
    'd': 27,
    '|': 2,
    '_': 2,
    0: 1,  # TICKLEFT
    1: 1,  # TICKRIGHT
    2: 1,  # TICKUP
    3: 1,  # TICKDOWN
    4: 1,  # CARETLEFT
    5: 1,  # CARETRIGHT
    6: 1,  # CARETUP
    7: 1,  # CARETDOWN
    'None': '.',
    ' ': '.',
    '': '.',
    }

markerstyles_text2root = {
    "smalldot": 6,
    "mediumdot": 7,
    "largedot": 8,
    "dot": 9,
    "circle": 20,
    "square": 21,
    "triangle": 22,
    "triangleup": 22,
    "triangledown": 23,
    "opencircle": 24,
    "opensquare": 25,
    "opentriangle": 26,
    "opendiamond": 27,
    "diamond": 33,
    "opencross": 28,
    "cross": 34,
    "openstar": 29,
    "fullstar": 30,
    "star": 29,
    }


def convert_markerstyle(inputstyle, mode, inputmode=None):
    """
    Convert *inputstyle* to ROOT or matplotlib format.

    Output format is determined by *mode* ('root' or 'mpl').  The *inputstyle*
    may be a ROOT marker style, a matplotlib marker style, or a description
    such as 'star' or 'square'.
    """
    mode = mode.lower()
    if mode not in ('mpl', 'root'):
        raise ValueError("`{0}` is not valid `mode`".format(mode))
    if inputmode is None:
        if inputstyle in markerstyles_root2mpl:
            inputmode = 'root'
        elif inputstyle in markerstyles_mpl2root or '$' in str(inputstyle):
            inputmode = 'mpl'
        elif inputstyle in markerstyles_text2root:
            inputmode = 'root'
            inputstyle = markerstyles_text2root[inputstyle]
        else:
            raise ValueError(
                "`{0}` is not a valid `markerstyle`".format(inputstyle))
    if inputmode == 'root':
        if inputstyle not in markerstyles_root2mpl:
            raise ValueError(
                "`{0}` is not a valid ROOT `markerstyle`".format(
                    inputstyle))
        if mode == 'root':
            return inputstyle
        return markerstyles_root2mpl[inputstyle]
    else:
        if '$' in str(inputstyle):
            if mode == 'root':
                return 1
            else:
                return inputstyle
        if inputstyle not in markerstyles_mpl2root:
            raise ValueError(
                "`{0}` is not a valid matplotlib `markerstyle`".format(
                    inputstyle))
        if mode == 'mpl':
            return inputstyle
        return markerstyles_mpl2root[inputstyle]


class MarkerStyle(_StyleContainer):
    """
    Container for grouping together ROOT and matplotlib marker styles.

    The *style* argument to the constructor may be a ROOT marker style,
    a matplotlib marker style, or one of the following descriptions:
    """
    __doc__ = __doc__[:__doc__.rfind('\n') + 1]
    __doc__ += '\n'.join(["    '{0}'".format(x)
                          for x in markerstyles_text2root])
    del x
    __doc__ += """

    Examples
    --------

       >>> style = MarkerStyle('opentriangle')
       >>> style('root')
       26
       >>> style('mpl')
       '^'

    """
    def __init__(self, style):
        _StyleContainer.__init__(self, style, convert_markerstyle)


##############################
#### Lines ###################

linestyles_root2mpl = {
    1: 'solid',
    2: 'dashed',
    3: 'dotted',
    4: 'dashdot',
    5: 'dashdot',
    6: 'dashdot',
    7: 'dashed',
    8: 'dashdot',
    9: 'dashed',
    10: 'dashdot',
    }

linestyles_mpl2root = {
    'solid': 1,
    'dashed': 2,
    'dotted': 3,
    'dashdot': 4,
    }

linestyles_text2root = {
    'solid': 1,
    'dashed': 2,
    'dotted': 3,
    'dashdot': 4,
    'longdashdot': 5,
    'longdashdotdotdot': 6,
    'longdash': 7,
    'longdashdotdot': 8,
    'verylongdash': 9,
    'verylongdashdot': 10
    }


def convert_linestyle(inputstyle, mode, inputmode=None):
    """
    Convert *inputstyle* to ROOT or matplotlib format.

    Output format is determined by *mode* ('root' or 'mpl').  The *inputstyle*
    may be a ROOT line style, a matplotlib line style, or a description
    such as 'solid' or 'dotted'.
    """
    mode = mode.lower()
    if mode not in ('mpl', 'root'):
        raise ValueError(
            "`{0}` is not a valid `mode`".format(mode))
    try:
        inputstyle = int(inputstyle)
        if inputstyle < 1:
            inputstyle = 1
    except (TypeError, ValueError):
        pass
    if inputmode is None:
        if inputstyle in linestyles_root2mpl:
            inputmode = 'root'
        elif inputstyle in linestyles_mpl2root:
            inputmode = 'mpl'
        elif inputstyle in linestyles_text2root:
            inputmode = 'root'
            inputstyle = linestyles_text2root[inputstyle]
        else:
            raise ValueError(
                "`{0}` is not a valid `linestyle`".format(
                    inputstyle))
    if inputmode == 'root':
        if inputstyle not in linestyles_root2mpl:
            raise ValueError(
                "`{0}` is not a valid ROOT `linestyle`".format(
                    inputstyle))
        if mode == 'root':
            return inputstyle
        return linestyles_root2mpl[inputstyle]
    else:
        if inputstyle not in linestyles_mpl2root:
            raise ValueError(
                "`{0}` is not a valid matplotlib `linestyle`".format(
                    inputstyle))
        if mode == 'mpl':
            return inputstyle
        return linestyles_mpl2root[inputstyle]


class LineStyle(_StyleContainer):
    """
    Container for grouping together ROOT and matplotlib line styles.

    The *style* argument to the constructor may be a ROOT line style,
    a matplotlib line style, or one of the following descriptions:
    """
    __doc__ = __doc__[:__doc__.rfind('\n') + 1]
    __doc__ += '\n'.join(["    '{0}'".format(x)
                          for x in linestyles_text2root])
    del x
    __doc__ += """

    Examples
    --------

       >>> style = LineStyle('verylongdashdot')
       >>> style('root')
       10
       >>> style('mpl')
       'dashdot'

    """
    def __init__(self, style):
        _StyleContainer.__init__(self, style, convert_linestyle)


##############################
#### Fills ###################

fillstyles_root2mpl = {
    0: None,
    1001: None,
    3003: '.',
    3345: '\\',
    3354: '/',
    3006: '|',
    3007: '-',
    3011: '*',
    3012: 'o',
    3013: 'x',
    3019: 'O',
    }

fillstyles_mpl2root = {}
for key, value in fillstyles_root2mpl.items():
    fillstyles_mpl2root[value] = key
fillstyles_mpl2root[None] = 0

fillstyles_text2root = {
    'hollow': 0,
    'none': 0,
    'solid': 1001,
    }


def convert_fillstyle(inputstyle, mode, inputmode=None):
    """
    Convert *inputstyle* to ROOT or matplotlib format.

    Output format is determined by *mode* ('root' or 'mpl').  The *inputstyle*
    may be a ROOT fill style, a matplotlib hatch style, None, 'none', 'hollow',
    or 'solid'.
    """
    mode = mode.lower()
    if mode not in ('mpl', 'root'):
        raise ValueError("`{0}` is not a valid `mode`".format(mode))
    if inputmode is None:
        try:
            # inputstyle is a ROOT linestyle
            inputstyle = int(inputstyle)
            inputmode = 'root'
        except (TypeError, ValueError):
            if inputstyle is None:
                inputmode = 'mpl'
            elif inputstyle in fillstyles_text2root:
                inputmode = 'root'
                inputstyle = fillstyles_text2root[inputstyle]
            elif inputstyle[0] in fillstyles_mpl2root:
                inputmode = 'mpl'
            else:
                raise ValueError(
                    "`{0}` is not a valid `fillstyle`".format(inputstyle))
    if inputmode == 'root':
        if mode == 'root':
            return inputstyle
        if inputstyle in fillstyles_root2mpl:
            return fillstyles_root2mpl[inputstyle]
        raise ValueError(
            "`{0}` is not a valid `fillstyle`".format(inputstyle))
    else:
        if inputstyle is not None and inputstyle[0] not in fillstyles_mpl2root:
            raise ValueError(
                "`{0}` is not a valid matplotlib `fillstyle`".format(
                    inputstyle))
        if mode == 'mpl':
            return inputstyle
        if inputstyle is None:
            return fillstyles_mpl2root[inputstyle]
        return fillstyles_mpl2root[inputstyle[0]]


class FillStyle(_StyleContainer):
    """
    Container for grouping together ROOT and matplotlib fill styles.

    The *style* argument to the constructor may be a ROOT fill style,
    a matplotlib fill style, or one of the following descriptions:
    """
    __doc__ = __doc__[:__doc__.rfind('\n') + 1]
    __doc__ += '\n'.join(["    '{0}'".format(x)
                          for x in fillstyles_text2root])
    del x
    __doc__ += """

    For an input value of 'solid', the matplotlib hatch value will be set to
    None, which is the same value as for 'hollow'.  The root2matplotlib
    functions will all check the ROOT value to see whether to make the fill
    solid or hollow.

    Examples
    --------

       >>> style = FillStyle('hollow')
       >>> style('root')
       0
       >>> print style('mpl')
       None

    """
    def __init__(self, style):
        _StyleContainer.__init__(self, style, convert_fillstyle)


##############################
#### Colors ##################

_cnames = {
    'r'                    : '#FF0000', #@IgnorePep8
    'g'                    : '#00FF00',
    'b'                    : '#0000FF',
    'c'                    : '#00BFBF',
    'm'                    : '#BF00BF',
    'y'                    : '#BFBF00',
    'k'                    : '#000000',
    'w'                    : '#FFFFFF',
    'aliceblue'            : '#F0F8FF',
    'antiquewhite'         : '#FAEBD7',
    'aqua'                 : '#00FFFF',
    'aquamarine'           : '#7FFFD4',
    'azure'                : '#F0FFFF',
    'beige'                : '#F5F5DC',
    'bisque'               : '#FFE4C4',
    'black'                : '#000000',
    'blanchedalmond'       : '#FFEBCD',
    'blue'                 : '#0000FF',
    'blueviolet'           : '#8A2BE2',
    'brown'                : '#A52A2A',
    'burlywood'            : '#DEB887',
    'cadetblue'            : '#5F9EA0',
    'chartreuse'           : '#7FFF00',
    'chocolate'            : '#D2691E',
    'coral'                : '#FF7F50',
    'cornflowerblue'       : '#6495ED',
    'cornsilk'             : '#FFF8DC',
    'crimson'              : '#DC143C',
    'cyan'                 : '#00FFFF',
    'darkblue'             : '#00008B',
    'darkcyan'             : '#008B8B',
    'darkgoldenrod'        : '#B8860B',
    'darkgray'             : '#A9A9A9',
    'darkgreen'            : '#006400',
    'darkkhaki'            : '#BDB76B',
    'darkmagenta'          : '#8B008B',
    'darkolivegreen'       : '#556B2F',
    'darkorange'           : '#FF8C00',
    'darkorchid'           : '#9932CC',
    'darkred'              : '#8B0000',
    'darksalmon'           : '#E9967A',
    'darkseagreen'         : '#8FBC8F',
    'darkslateblue'        : '#483D8B',
    'darkslategray'        : '#2F4F4F',
    'darkturquoise'        : '#00CED1',
    'darkviolet'           : '#9400D3',
    'deeppink'             : '#FF1493',
    'deepskyblue'          : '#00BFFF',
    'dimgray'              : '#696969',
    'dodgerblue'           : '#1E90FF',
    'firebrick'            : '#B22222',
    'floralwhite'          : '#FFFAF0',
    'forestgreen'          : '#228B22',
    'fuchsia'              : '#FF00FF',
    'gainsboro'            : '#DCDCDC',
    'ghostwhite'           : '#F8F8FF',
    'gold'                 : '#FFD700',
    'goldenrod'            : '#DAA520',
    'gray'                 : '#808080',
    'green'                : '#008000',
    'greenyellow'          : '#ADFF2F',
    'honeydew'             : '#F0FFF0',
    'hotpink'              : '#FF69B4',
    'indianred'            : '#CD5C5C',
    'indigo'               : '#4B0082',
    'ivory'                : '#FFFFF0',
    'khaki'                : '#F0E68C',
    'lavender'             : '#E6E6FA',
    'lavenderblush'        : '#FFF0F5',
    'lawngreen'            : '#7CFC00',
    'lemonchiffon'         : '#FFFACD',
    'lightblue'            : '#ADD8E6',
    'lightcoral'           : '#F08080',
    'lightcyan'            : '#E0FFFF',
    'lightgoldenrodyellow' : '#FAFAD2',
    'lightgreen'           : '#90EE90',
    'lightgrey'            : '#D3D3D3',
    'lightpink'            : '#FFB6C1',
    'lightsalmon'          : '#FFA07A',
    'lightseagreen'        : '#20B2AA',
    'lightskyblue'         : '#87CEFA',
    'lightslategray'       : '#778899',
    'lightsteelblue'       : '#B0C4DE',
    'lightyellow'          : '#FFFFE0',
    'lime'                 : '#00FF00',
    'limegreen'            : '#32CD32',
    'linen'                : '#FAF0E6',
    'magenta'              : '#FF00FF',
    'maroon'               : '#800000',
    'mediumaquamarine'     : '#66CDAA',
    'mediumblue'           : '#0000CD',
    'mediumorchid'         : '#BA55D3',
    'mediumpurple'         : '#9370DB',
    'mediumseagreen'       : '#3CB371',
    'mediumslateblue'      : '#7B68EE',
    'mediumspringgreen'    : '#00FA9A',
    'mediumturquoise'      : '#48D1CC',
    'mediumvioletred'      : '#C71585',
    'midnightblue'         : '#191970',
    'mintcream'            : '#F5FFFA',
    'mistyrose'            : '#FFE4E1',
    'moccasin'             : '#FFE4B5',
    'navajowhite'          : '#FFDEAD',
    'navy'                 : '#000080',
    'oldlace'              : '#FDF5E6',
    'olive'                : '#808000',
    'olivedrab'            : '#6B8E23',
    'orange'               : '#FFA500',
    'orangered'            : '#FF4500',
    'orchid'               : '#DA70D6',
    'palegoldenrod'        : '#EEE8AA',
    'palegreen'            : '#98FB98',
    'palevioletred'        : '#AFEEEE',
    'papayawhip'           : '#FFEFD5',
    'peachpuff'            : '#FFDAB9',
    'peru'                 : '#CD853F',
    'pink'                 : '#FFC0CB',
    'plum'                 : '#DDA0DD',
    'powderblue'           : '#B0E0E6',
    'purple'               : '#800080',
    'red'                  : '#FF0000',
    'rosybrown'            : '#BC8F8F',
    'royalblue'            : '#4169E1',
    'saddlebrown'          : '#8B4513',
    'salmon'               : '#FA8072',
    'sandybrown'           : '#FAA460',
    'seagreen'             : '#2E8B57',
    'seashell'             : '#FFF5EE',
    'sienna'               : '#A0522D',
    'silver'               : '#C0C0C0',
    'skyblue'              : '#87CEEB',
    'slateblue'            : '#6A5ACD',
    'slategray'            : '#708090',
    'snow'                 : '#FFFAFA',
    'springgreen'          : '#00FF7F',
    'steelblue'            : '#4682B4',
    'tan'                  : '#D2B48C',
    'teal'                 : '#008080',
    'thistle'              : '#D8BFD8',
    'tomato'               : '#FF6347',
    'turquoise'            : '#40E0D0',
    'violet'               : '#EE82EE',
    'wheat'                : '#F5DEB3',
    'white'                : '#FFFFFF',
    'whitesmoke'           : '#F5F5F5',
    'yellow'               : '#FFFF00',
    'yellowgreen'          : '#9ACD32',
    }


def convert_color(color, mode):
    """
    Convert *color* to a TColor if *mode='root'* or to (r,g,b) if 'mpl'.

    The *color* argument can be a ROOT TColor or color index, an *RGB*
    or *RGBA* sequence or a string in any of several forms:

        1) a letter from the set 'rgbcmykw'
        2) a hex color string, like '#00FFFF'
        3) a standard name, like 'aqua'
        4) a float, like '0.4', indicating gray on a 0-1 scale

    if *arg* is *RGBA*, the transparency value will be ignored.
    """
    mode = mode.lower()
    if mode not in ('mpl', 'root'):
        raise ValueError(
            "`{0}` is not a valid `mode`".format(mode))
    try:
        # color is an r,g,b tuple
        color = tuple([float(x) for x in color[:3]])
        if max(color) > 1.:
            color = tuple([x / 255. for x in color])
        if mode == 'root':
            return ROOT.TColor.GetColor(*color)
        return color
    except (ValueError, TypeError):
        pass
    if isinstance(color, basestring):
        if color in _cnames:
            # color is a matplotlib letter or an html color name
            color = _cnames[color]
        if color[0] == '#':
            # color is a hex value
            color = color.lstrip('#')
            lv = len(color)
            color = tuple(int(color[i:i + lv / 3], 16)
                          for i in range(0, lv, lv / 3))
            if lv == 3:
                color = tuple(x * 16 + x for x in color)
            return convert_color(color, mode)
        # color is a shade of gray, i.e. '0.3'
        return convert_color((color, color, color), mode)
    try:
        # color is a TColor
        color = ROOT.TColor(color)
        color = color.GetRed(), color.GetGreen(), color.GetBlue()
        return convert_color(color, mode)
    except (TypeError, ReferenceError):
        pass
    try:
        # color is a ROOT color index
        if color < 0:
            color = 0
        color = ROOT.gROOT.GetColor(color)
        # Protect against the case a histogram with a custom color
        # is saved in a ROOT file
        if not color:
            # Just return black
            color = ROOT.gROOT.GetColor(1)
        color = color.GetRed(), color.GetGreen(), color.GetBlue()
        return convert_color(color, mode)
    except (TypeError, ReferenceError):
        pass
    raise ValueError("'{0!s}' is not a valid `color`".format(color))


class Color(_StyleContainer):
    """
    Container for grouping together ROOT and matplotlib colors.

    The *color* argument to the constructor can be a ROOT TColor or color index.
    If matplotlib is available, it can also accept an *RGB* or *RGBA* sequence,
    or a string in any of several forms:

        1) a letter from the set 'rgbcmykw'
        2) a hex color string, like '#00FFFF'
        3) a standard name, like 'aqua'
        4) a float, like '0.4', indicating gray on a 0-1 scale

    if *color* is *RGBA*, the *A* will simply be discarded.

    Examples
    --------

       >>> color = Color(2)
       >>> color()
       2
       >>> color('mpl')
       (1.0, 0.0, 0.0)
       >>> color = Color('blue')
       >>> color('root')
       4
       >>> color('mpl')
       (0.0, 0.0, 1.0)
       >>> color = Color('0.25')
       >>> color('mpl')
       (0.25, 0.25, 0.25)
       >>> color('root')
       924

    """
    def __init__(self, color):
        _StyleContainer.__init__(self, color, convert_color)

########NEW FILE########
__FILENAME__ = box
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from .. import QROOT
from ..base import Object
from .utils import canvases_with

__all__ = [
    'Pave',
    'PaveStats',
]


# This is another _PadBase hack. See this comment on github
# https://github.com/rootpy/rootpy/pull/342#issuecomment-19864883

class _Positionable(object):

    @property
    def position(self):
        return (self.GetX1NDC(), self.GetY1NDC(),
                self.GetX2NDC(), self.GetY2NDC())

    @position.setter
    def position(self, value):
        x1, y1, x2, y2 = value
        self.SetX1NDC(x1)
        self.SetY1NDC(y1)
        self.SetX2NDC(x2)
        self.SetY2NDC(y2)

        for c in canvases_with(self):
            c.Modified()


class Pave(_Positionable, Object, QROOT.TPave):
    _ROOT = QROOT.TPave


class PaveStats(_Positionable, Object, QROOT.TPaveStats):
    _ROOT = QROOT.TPaveStats

########NEW FILE########
__FILENAME__ = canvas
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module implements python classes which inherit from
and extend the functionality of the ROOT canvas classes.
"""
from __future__ import absolute_import

import ROOT

from .base import convert_color
from ..base import NamedObject
from ..context import invisible_canvas
from ..decorators import snake_case_methods
from .. import QROOT, asrootpy
from ..memory.keepalive import keepalive

from array import array

__all__ = [
    'Pad',
    'Canvas',
]


class _PadBase(NamedObject):

    def cd(self, *args):
        pad = asrootpy(super(_PadBase, self).cd(*args))
        if pad and pad is not self:
            keepalive(self, pad)
        return pad

    def axes(self, ndim=1,
             xlimits=None, ylimits=None, zlimits=None,
             xbins=1, ybins=1, zbins=1):
        """
        Create and return axes on this pad
        """
        if xlimits is None:
            xlimits = (0, 1)
        if ylimits is None:
            ylimits = (0, 1)
        if zlimits is None:
            zlimits = (0, 1)
        if ndim == 1:
            from .hist import Hist
            hist = Hist(1, xlimits[0], xlimits[1])
        elif ndim == 2:
            from .hist import Hist2D
            hist = Hist2D(1, xlimits[0], xlimits[1],
                          1, ylimits[0], ylimits[1])
        elif ndim == 3:
            from .hist import Hist3D
            hist = Hist3D(1, xlimits[0], xlimits[1],
                          1, ylimits[0], ylimits[1],
                          1, zlimits[0], zlimits[1])
        else:
            raise ValueError("ndim must be 1, 2, or 3")
        with self:
            hist.Draw('AXIS')
        xaxis = hist.xaxis
        yaxis = hist.yaxis
        if isinstance(xbins, (list, tuple)):
            xbins = array('d', xbins)
        if hasattr(xbins, '__iter__'):
            xaxis.Set(len(xbins) - 1, xbins)
        else:
            xaxis.Set(xbins, *xlimits)
        if ndim > 1:
            if isinstance(ybins, (list, tuple)):
                ybins = array('d', ybins)
            if hasattr(ybins, '__iter__'):
                yaxis.Set(len(ybins) - 1, ybins)
            else:
                yaxis.Set(ybins, *ylimits)
        else:
            yaxis.limits = ylimits
            yaxis.range_user = ylimits
        if ndim > 1:
            zaxis = hist.zaxis
            if ndim == 3:
                if isinstance(zbins, (list, tuple)):
                    zbins = array('d', zbins)
                if hasattr(zbins, '__iter__'):
                    zaxis.Set(len(zbins) - 1, zbins)
                else:
                    zaxis.Set(zbins, *zlimits)
            else:
                zaxis.limits = zlimits
                zaxis.range_user = zlimits
            return xaxis, yaxis, zaxis
        return xaxis, yaxis

    @property
    def primitives(self):
        return asrootpy(self.GetListOfPrimitives())

    def find_all_primitives(self):
        """
        Recursively find all primities on a pad, even those hiding behind a
        GetListOfFunctions() of a primitive
        """
        # delayed import to avoid circular import
        from .utils import find_all_primitives
        return find_all_primitives(self)

    @property
    def canvas(self):
        return asrootpy(self.GetCanvas())

    @property
    def mother(self):
        return asrootpy(self.GetMother())

    @property
    def margin(self):
        return (self.GetLeftMargin(), self.GetRightMargin(),
                self.GetBottomMargin(), self.GetTopMargin())

    @margin.setter
    def margin(self, bounds):
        left, right, bottom, top = bounds
        super(_PadBase, self).SetMargin(left, right, bottom, top)

    @property
    def range(self):
        x1, y1 = ROOT.Double(), ROOT.Double()
        x2, y2 = ROOT.Double(), ROOT.Double()
        super(_PadBase, self).GetRange(x1, y1, x2, y2)
        return x1, y1, x2, y2

    @range.setter
    def range(self, bounds):
        x1, y1, x2, y2 = bounds
        super(_PadBase, self).Range(x1, y1, x2, y2)

    @property
    def range_axis(self):
        x1, y1 = ROOT.Double(), ROOT.Double()
        x2, y2 = ROOT.Double(), ROOT.Double()
        super(_PadBase, self).GetRangeAxis(x1, y1, x2, y2)
        return x1, y1, x2, y2

    @range_axis.setter
    def range_axis(self, bounds):
        x1, y1, x2, y2 = bounds
        super(_PadBase, self).RangeAxis(x1, y1, x2, y2)

    def __enter__(self):
        self._prev_pad = ROOT.gPad.func()
        self.cd()
        return self

    def __exit__(self, type, value, traceback):
        # similar to preserve_current_canvas in rootpy/context.py
        if self._prev_pad:
            self._prev_pad.cd()
        elif ROOT.gPad.func():
            # Put things back how they were before.
            with invisible_canvas():
                # This is a round-about way of resetting gPad to None.
                # No other technique I tried could do it.
                pass
        self._prev_pad = None
        return False


@snake_case_methods
class Pad(_PadBase, QROOT.TPad):
    _ROOT = QROOT.TPad

    def __init__(self, xlow, ylow, xup, yup,
                 color=-1,
                 bordersize=-1,
                 bordermode=-2,
                 name=None,
                 title=None):
        color = convert_color(color, 'root')
        super(Pad, self).__init__(xlow, ylow, xup, yup,
                                  color, bordersize, bordermode,
                                  name=name,
                                  title=title)

    def Draw(self, *args):
        ret = super(Pad, self).Draw(*args)
        canvas = self.GetCanvas()
        keepalive(canvas, self)
        return ret

    @property
    def width(self):
        return self.GetWNDC()

    @property
    def height(self):
        return self.GetHNDC()

    @property
    def width_pixels(self):
        mother = self.mother
        canvas = self.canvas
        w = self.GetWNDC()
        while mother is not canvas:
            w *= mother.GetWNDC()
            mother = mother.mother
        return int(w * mother.width)

    @property
    def height_pixels(self):
        mother = self.mother
        canvas = self.canvas
        h = self.GetHNDC()
        while mother is not canvas:
            h *= mother.GetHNDC()
            mother = mother.mother
        return int(h * mother.height)


@snake_case_methods
class Canvas(_PadBase, QROOT.TCanvas):
    _ROOT = QROOT.TCanvas

    def __init__(self,
                 width=None, height=None,
                 x=None, y=None,
                 name=None, title=None,
                 size_includes_decorations=False):
        # The following line will trigger finalSetup and start the graphics
        # thread if not started already
        style = ROOT.gStyle
        if width is None:
            width = style.GetCanvasDefW()
        if height is None:
            height = style.GetCanvasDefH()
        if x is None:
            x = style.GetCanvasDefX()
        if y is None:
            y = style.GetCanvasDefY()
        super(Canvas, self).__init__(x, y, width, height,
                                     name=name, title=title)
        if not size_includes_decorations:
            # Canvas dimensions include the window manager's decorations by
            # default in vanilla ROOT. I think this is a bad default.
            # Since in the most common case I don't care about the window
            # decorations, the default will be to set the dimensions of the
            # paintable area of the canvas.
            if self.IsBatch():
                self.SetCanvasSize(width, height)
            else:
                self.SetWindowSize(width + (width - self.GetWw()),
                                   height + (height - self.GetWh()))
        self.size_includes_decorations = size_includes_decorations

    @property
    def width(self):
        return self.GetWw()

    @width.setter
    def width(self, value):
        if self.IsBatch():
            self.SetCanvasSize(value, self.GetWh())
        else:
            curr_height = self.GetWh()
            self.SetWindowSize(value, curr_height)
            if not getattr(self, 'size_includes_decorations', False):
                self.SetWindowSize(value + (value - self.GetWw()),
                                   curr_height + (curr_height - self.GetWh()))

    @property
    def width_pixels(self):
        return self.GetWw()

    @width_pixels.setter
    def width_pixels(self, value):
        self.width = value

    @property
    def height(self):
        return self.GetWh()

    @height.setter
    def height(self, value):
        if self.IsBatch():
            self.SetCanvasSize(self.GetWw(), value)
        else:
            curr_width = self.GetWw()
            self.SetWindowSize(curr_width, value)
            if not getattr(self, 'size_includes_decorations', False):
                self.SetWindowSize(curr_width + (curr_width - self.GetWw()),
                                   value + (value - self.GetWh()))

    @property
    def height_pixels(self):
        return self.GetWh()

    @height_pixels.setter
    def height_pixels(self, value):
        self.height = value

########NEW FILE########
__FILENAME__ = gif
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import subprocess
import os

from . import log; log = log[__name__]

__all__ = [
    'GIF',
]


class GIF(object):

    def __init__(self):

        self.images = []

    def add_frame(self, image):

        self.images.append(image)

    def add_frames(self, images):

        self.images.extend(images)

    def write(self, outname, delay=10, loop=0):

        if not self.images:
            raise RuntimeError(
                "attempting to create an animated GIF without frames")
        name, ext = os.path.splitext(outname)
        if ext != '.gif':
            raise ValueError("output filename must have the .gif extension")
        cmd = [
            'convert',
            '-delay', '{0:d}'.format(delay),
            '-loop', '{0:d}'.format(loop)] + self.images + [outname]
        log.info("creating gif: {0}".format(' '.join(cmd)))
        p = subprocess.Popen(cmd)
        if p.wait():
            raise RuntimeError(
                "failed to create animated GIF: {0}. "
                "Do you have ImageMagick imstalled?".format(outname))

    def clean(self):

        for image in self.images:
            os.unlink(image)
        self.images = []

########NEW FILE########
__FILENAME__ = plot_contour_matrix
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import os
import tempfile
import shutil

from . import log; log = log[__name__]
from .. import Hist2D
from .gif import GIF

__all__ = [
    'plot_contour_matrix',
]

LINES = ['dashed', 'solid', 'dashdot', 'dotted']


def plot_contour_matrix(arrays,
                        fields,
                        filename,
                        weights=None,
                        sample_names=None,
                        sample_lines=None,
                        sample_colors=None,
                        color_map=None,
                        num_bins=20,
                        num_contours=3,
                        cell_width=2,
                        cell_height=2,
                        cell_margin_x=0.05,
                        cell_margin_y=0.05,
                        dpi=100,
                        padding=0,
                        animate_field=None,
                        animate_steps=10,
                        animate_delay=20,
                        animate_loop=0):
    """
    Create a matrix of contour plots showing all possible 2D projections of a
    multivariate dataset. You may optionally animate the contours as a cut on
    one of the fields is increased. ImageMagick must be installed to produce
    animations.

    Parameters
    ----------

    arrays : list of arrays of shape [n_samples, n_fields]
        A list of 2D NumPy arrays for each sample. All arrays must have the
        same number of columns.

    fields : list of strings
        A list of the field names.

    filename : string
        The output filename. If animatation is enabled
        ``animate_field is not None`` then ``filename`` must have the .gif
        extension.

    weights : list of arrays, optional (default=None)
        List of 1D NumPy arrays of sample weights corresponding to the arrays
        in ``arrays``.

    sample_names : list of strings, optional (default=None)
        A list of the sample names for the legend. If None, then no legend will
        be shown.

    sample_lines : list of strings, optional (default=None)
        A list of matplotlib line styles for each sample. If None then line
        styles will cycle through 'dashed', 'solid', 'dashdot', and 'dotted'.
        Elements of this list may also be a list of line styles which will be
        cycled through for the contour lines of the corresponding sample.

    sample_colors : list of matplotlib colors, optional (default=None)
        The color of the contours for each sample. If None, then colors will be
        selected according to regular intervals along the ``color_map``.

    color_map : a matplotlib color map, optional (default=None)
        If ``sample_colors is None`` then select colors according to regular
        intervals along this matplotlib color map. If ``color_map`` is None,
        then the spectral color map is used.

    num_bins : int, optional (default=20)
        The number of bins along both axes of the 2D histograms.

    num_contours : int, optional (default=3)
        The number of contour line to show for each sample.

    cell_width : float, optional (default=2)
        The width, in inches, of each subplot in the matrix.

    cell_height : float, optional (default=2)
        The height, in inches, of each subplot in the matrix.

    cell_margin_x : float, optional (default=0.05)
        The horizontal margin between adjacent subplots, as a fraction
        of the subplot size.

    cell_margin_y : float, optional (default=0.05)
        The vertical margin between adjacent subplots, as a fraction
        of the subplot size.

    dpi : int, optional (default=100)
        The number of pixels per inch.

    padding : float, optional (default=0)
        The padding, as a fraction of the range of the value along each axes to
        guarantee around each sample's contour plot.

    animate_field : string, optional (default=None)
        The field to animate a cut along. By default no animation is produced.
        If ``animate_field is not None`` then ``filename`` must end in the .gif
        extension and an animated GIF is produced.

    animate_steps : int, optional (default=10)
        The number of frames in the animation, corresponding to the number of
        regularly spaced cut values to show along the range of the
        ``animate_field``.

    animate_delay : int, optional (default=20)
        The duration that each frame is shown in the animation as a multiple of
        1 / 100 of a second.

    animate_loop : int, optional (default=0)
        The number of times to loop the animation. If zero, then loop forever.

    Notes
    -----

    NumPy and matplotlib are required

    """
    import numpy as np
    from .. import root2matplotlib as r2m
    import matplotlib.pyplot as plt
    from matplotlib.ticker import MaxNLocator
    from matplotlib import cm
    from matplotlib.lines import Line2D

    # we must have at least two fields (columns)
    num_fields = len(fields)
    if num_fields < 2:
        raise ValueError(
            "record arrays must have at least two fields")
    # check that all arrays have the same number of columns
    for array in arrays:
        if array.shape[1] != num_fields:
            raise ValueError(
                "number of array columns does not match number of fields")

    if sample_colors is None:
        if color_map is None:
            color_map = cm.spectral
        steps = np.linspace(0, 1, len(arrays) + 2)[1:-1]
        sample_colors = [color_map(s) for s in steps]

    # determine range of each field
    low = np.vstack([a.min(axis=0) for a in arrays]).min(axis=0)
    high = np.vstack([a.max(axis=0) for a in arrays]).max(axis=0)
    width = np.abs(high - low)
    width *= padding
    low -= width
    high += width

    def single_frame(arrays, filename, label=None):

        # create the canvas and divide into matrix
        fig, axes = plt.subplots(
            nrows=num_fields,
            ncols=num_fields,
            figsize=(cell_width * num_fields, cell_height * num_fields))
        fig.subplots_adjust(hspace=cell_margin_y, wspace=cell_margin_x)

        for ax in axes.flat:
            # only show the left and bottom axes ticks and labels
            if ax.is_last_row() and not ax.is_last_col():
                ax.xaxis.set_visible(True)
                ax.xaxis.set_ticks_position('bottom')
                ax.xaxis.set_major_locator(MaxNLocator(4, prune='both'))
                for tick in ax.xaxis.get_major_ticks():
                    tick.label.set_rotation('vertical')
            else:
                ax.xaxis.set_visible(False)

            if ax.is_first_col() and not ax.is_first_row():
                ax.yaxis.set_visible(True)
                ax.yaxis.set_ticks_position('left')
                ax.yaxis.set_major_locator(MaxNLocator(4, prune='both'))
            else:
                ax.yaxis.set_visible(False)

        # turn off axes frames in upper triangular matrix
        for ix, iy in zip(*np.triu_indices_from(axes, k=0)):
            axes[ix, iy].axis('off')

        levels = np.linspace(0, 1, num_contours + 2)[1:-1]

        # plot the data
        for iy, ix in zip(*np.tril_indices_from(axes, k=-1)):
            ymin = float(low[iy])
            ymax = float(high[iy])
            xmin = float(low[ix])
            xmax = float(high[ix])
            for isample, a in enumerate(arrays):
                hist = Hist2D(
                    num_bins, xmin, xmax,
                    num_bins, ymin, ymax)
                if weights is not None:
                    hist.fill_array(a[:, [ix, iy]], weights[isample])
                else:
                    hist.fill_array(a[:, [ix, iy]])
                # normalize so maximum is 1.0
                _max = hist.GetMaximum()
                if _max != 0:
                    hist /= _max
                r2m.contour(hist,
                    axes=axes[iy, ix],
                    levels=levels,
                    linestyles=sample_lines[isample] if sample_lines else LINES,
                    colors=sample_colors[isample])

        # label the diagonal subplots
        for i, field in enumerate(fields):
            axes[i, i].annotate(field,
                (0.1, 0.2),
                rotation=45,
                xycoords='axes fraction',
                ha='left', va='center')

        # make proxy artists for legend
        lines = []
        for color in sample_colors:
            lines.append(Line2D([0, 0], [0, 0], color=color))

        if sample_names is not None:
            # draw the legend
            leg = fig.legend(lines, sample_names, loc=(0.65, 0.8))
            leg.set_frame_on(False)

        if label is not None:
            axes[0, 0].annotate(label, (0, 1),
                ha='left', va='top',
                xycoords='axes fraction')

        fig.savefig(filename, bbox_inches='tight', dpi=dpi)
        plt.close(fig)

    if animate_field is not None:
        _, ext = os.path.splitext(filename)
        if ext != '.gif':
            raise ValueError(
                "animation is only supported for .gif files")
        field_idx = fields.index(animate_field)
        cuts = np.linspace(
            low[field_idx],
            high[field_idx],
            animate_steps + 1)[:-1]
        gif = GIF()
        temp_dir = tempfile.mkdtemp()
        for i, cut in enumerate(cuts):
            frame_filename = os.path.join(temp_dir, 'frame_{0:d}.png'.format(i))
            label = '{0} > {1:.2f}'.format(animate_field, cut)
            log.info("creating frame for {0} ...".format(label))
            new_arrays = []
            for array in arrays:
                new_arrays.append(array[array[:, field_idx] > cut])
            single_frame(new_arrays,
                filename=frame_filename,
                label=label)
            gif.add_frame(frame_filename)
        gif.write(filename, delay=animate_delay, loop=animate_loop)
        shutil.rmtree(temp_dir)
    else:
        single_frame(arrays, filename=filename)

########NEW FILE########
__FILENAME__ = plot_corrcoef_matrix
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import


__all__ = [
    'plot_corrcoef_matrix',
]


def plot_corrcoef_matrix(data, fields, output_name,
                         weights=None,
                         repeat_weights=0,
                         bias=1,
                         ddof=None,
                         cmap=None,
                         title=None):
    """
    This function will draw a lower-triangular correlation matrix

    Parameters
    ----------

    data : numpy array
        2-dimensional array with rows for row-wise observations and column-wise
        fields.

    fields : list of strings
        List of the field names

    output_name : string
        Output image file name (including extension)

    weights : numpy array, optional (default=None)
        1-dimensional array containing observation weights with length equal to
        the number of rows in ``data``. By default all events have equal weight
        of 1.

    repeat_weights : int, optional
        The default treatment of weights in the weighted covariance is to first
        normalize them to unit sum and use the biased weighted covariance
        equation. If `repeat_weights` is 1 then the weights must represent an
        integer number of occurrences of each observation and both a biased and
        unbiased weighted covariance is defined because the total sample size
        can be determined.

    bias : int, optional
        Default normalization is by ``(N - 1)``, where ``N`` is the number of
        observations given (unbiased estimate). If `bias` is 1, then
        normalization is by ``N``. These values can be overridden by using
        the keyword ``ddof``.

    ddof : int, optional
        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is
        the number of observations; this overrides the value implied by
        ``bias``. The default value is ``None``.

    cmap : matplotlib color map, optional (default=None)
        Color map used to color the matrix cells.

    title : string, optional (default=None)
        A title to display on the top right of the plot.

    Notes
    -----

    NumPy and matplotlib are required

    """
    import numpy as np
    from matplotlib import pyplot as plt
    from matplotlib import cm

    coef = corrcoef(data.T,
        weights=weights, repeat_weights=repeat_weights,
        bias=bias, ddof=ddof)

    # mask out the upper triangular matrix
    coef[np.triu_indices(len(fields))] = np.nan

    fig = plt.figure()
    ax = fig.add_subplot(111)
    if cmap is None:
        cmap = cm.get_cmap('summer', 100)
    # make NaN pixels white
    cmap.set_bad('w')

    ax.imshow(coef, interpolation='nearest', cmap=cmap, origin='upper')

    ax.set_frame_on(False)
    plt.setp(ax.get_yticklabels(), visible=False)
    plt.setp(ax.get_yticklines(), visible=False)
    plt.setp(ax.get_xticklabels(), visible=False)
    plt.setp(ax.get_xticklines(), visible=False)

    for row, col in zip(*np.tril_indices(len(fields), k=-1)):
        plt.text(
            col, row,
            "{0:d}%".format(int(coef[row][col] * 100)),
            ha='center', va='center')

    for i, field in enumerate(fields):
        ax.annotate(field,
            (i, i), rotation=45,
            ha='left', va='bottom',
            transform=ax.transData)

    if title is not None:
        ax.set_xlabel(title)
        """
        plt.text(0.95, 0.95, title,
            horizontalalignment='right',
            verticalalignment='top',
            transform=ax.transAxes)
        """

    plt.savefig(output_name, bbox_inches='tight')


def cov(m, y=None, rowvar=1, bias=0, ddof=None, weights=None, repeat_weights=0):
    """
    Estimate a covariance matrix, given data.

    Covariance indicates the level to which two variables vary together.
    If we examine N-dimensional samples, :math:`X = [x_1, x_2, ... x_N]^T`,
    then the covariance matrix element :math:`C_{ij}` is the covariance of
    :math:`x_i` and :math:`x_j`. The element :math:`C_{ii}` is the variance
    of :math:`x_i`.

    Parameters
    ----------
    m : array_like
        A 1-D or 2-D array containing multiple variables and observations.
        Each row of `m` represents a variable, and each column a single
        observation of all those variables. Also see `rowvar` below.
    y : array_like, optional
        An additional set of variables and observations. `y` has the same
        form as that of `m`.
    rowvar : int, optional
        If `rowvar` is non-zero (default), then each row represents a
        variable, with observations in the columns. Otherwise, the relationship
        is transposed: each column represents a variable, while the rows
        contain observations.
    bias : int, optional
        Default normalization is by ``(N - 1)``, where ``N`` is the number of
        observations given (unbiased estimate). If `bias` is 1, then
        normalization is by ``N``. These values can be overridden by using
        the keyword ``ddof`` in numpy versions >= 1.5.
    ddof : int, optional
        .. versionadded:: 1.5
        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is
        the number of observations; this overrides the value implied by
        ``bias``. The default value is ``None``.
    weights : array-like, optional
        A 1-D array of weights with a length equal to the number of
        observations.
    repeat_weights : int, optional
        The default treatment of weights in the weighted covariance is to first
        normalize them to unit sum and use the biased weighted covariance
        equation. If `repeat_weights` is 1 then the weights must represent an
        integer number of occurrences of each observation and both a biased and
        unbiased weighted covariance is defined because the total sample size
        can be determined.

    Returns
    -------
    out : ndarray
        The covariance matrix of the variables.

    See Also
    --------
    corrcoef : Normalized covariance matrix

    Examples
    --------
    Consider two variables, :math:`x_0` and :math:`x_1`, which
    correlate perfectly, but in opposite directions:

    >>> x = np.array([[0, 2], [1, 1], [2, 0]]).T
    >>> x
    array([[0, 1, 2],
           [2, 1, 0]])

    Note how :math:`x_0` increases while :math:`x_1` decreases. The covariance
    matrix shows this clearly:

    >>> np.cov(x)
    array([[ 1., -1.],
           [-1.,  1.]])

    Note that element :math:`C_{0,1}`, which shows the correlation between
    :math:`x_0` and :math:`x_1`, is negative.

    Further, note how `x` and `y` are combined:

    >>> x = [-2.1, -1,  4.3]
    >>> y = [3,  1.1,  0.12]
    >>> X = np.vstack((x,y))
    >>> print np.cov(X)
    [[ 11.71        -4.286     ]
     [ -4.286        2.14413333]]
    >>> print np.cov(x, y)
    [[ 11.71        -4.286     ]
     [ -4.286        2.14413333]]
    >>> print np.cov(x)
    11.71

    """
    import numpy as np
    # Check inputs
    if ddof is not None and ddof != int(ddof):
        raise ValueError(
            "ddof must be integer")

    X = np.array(m, ndmin=2, dtype=float)
    if X.size == 0:
        # handle empty arrays
        return np.array(m)
    if X.shape[0] == 1:
        rowvar = 1
    if rowvar:
        axis = 0
        tup = (slice(None), np.newaxis)
    else:
        axis = 1
        tup = (np.newaxis, slice(None))

    if y is not None:
        y = np.array(y, copy=False, ndmin=2, dtype=float)
        X = np.concatenate((X, y), axis)

    if ddof is None:
        if bias == 0:
            ddof = 1
        else:
            ddof = 0

    if weights is not None:
        weights = np.array(weights, dtype=float)
        weights_sum = weights.sum()
        if weights_sum <= 0:
            raise ValueError(
                "sum of weights is non-positive")
        X -= np.average(X, axis=1-axis, weights=weights)[tup]

        if repeat_weights:
            # each weight represents a number of repetitions of an observation
            # the total sample size can be determined in this case and we have
            # both an unbiased and biased weighted covariance
            fact = weights_sum - ddof
        else:
            # normalize weights so they sum to unity
            weights /= weights_sum
            # unbiased weighted covariance is not defined if the weights are
            # not integral frequencies (repeat-type)
            fact = (1. - np.power(weights, 2).sum())
    else:
        weights = 1
        X -= X.mean(axis=1-axis)[tup]
        if rowvar:
            N = X.shape[1]
        else:
            N = X.shape[0]
        fact = float(N - ddof)

    if not rowvar:
        return (np.dot(weights * X.T, X.conj()) / fact).squeeze()
    else:
        return (np.dot(weights * X, X.T.conj()) / fact).squeeze()


def corrcoef(x, y=None, rowvar=1, bias=0, ddof=None, weights=None,
             repeat_weights=0):
    """
    Return correlation coefficients.

    Please refer to the documentation for `cov` for more detail.  The
    relationship between the correlation coefficient matrix, `P`, and the
    covariance matrix, `C`, is

    .. math:: P_{ij} = \\frac{ C_{ij} } { \\sqrt{ C_{ii} * C_{jj} } }

    The values of `P` are between -1 and 1, inclusive.

    Parameters
    ----------
    x : array_like
        A 1-D or 2-D array containing multiple variables and observations.
        Each row of `m` represents a variable, and each column a single
        observation of all those variables. Also see `rowvar` below.
    y : array_like, optional
        An additional set of variables and observations. `y` has the same
        shape as `m`.
    rowvar : int, optional
        If `rowvar` is non-zero (default), then each row represents a
        variable, with observations in the columns. Otherwise, the relationship
        is transposed: each column represents a variable, while the rows
        contain observations.
    bias : int, optional
        Default normalization is by ``(N - 1)``, where ``N`` is the number of
        observations (unbiased estimate). If `bias` is 1, then
        normalization is by ``N``. These values can be overridden by using
        the keyword ``ddof`` in numpy versions >= 1.5.
    ddof : {None, int}, optional
        .. versionadded:: 1.5
        If not ``None`` normalization is by ``(N - ddof)``, where ``N`` is
        the number of observations; this overrides the value implied by
        ``bias``. The default value is ``None``.
    weights : array-like, optional
        A 1-D array of weights with a length equal to the number of
        observations.
    repeat_weights : int, optional
        The default treatment of weights in the weighted covariance is to first
        normalize them to unit sum and use the biased weighted covariance
        equation. If `repeat_weights` is 1 then the weights must represent an
        integer number of occurrences of each observation and both a biased and
        unbiased weighted covariance is defined because the total sample size
        can be determined.

    Returns
    -------
    out : ndarray
        The correlation coefficient matrix of the variables.

    See Also
    --------
    cov : Covariance matrix

    """
    import numpy as np
    c = cov(x, y, rowvar, bias, ddof, weights, repeat_weights)
    if c.size == 0:
        # handle empty arrays
        return c
    try:
        d = np.diag(c)
    except ValueError:  # scalar covariance
        return 1
    return c/np.sqrt(np.multiply.outer(d, d))


########NEW FILE########
__FILENAME__ = quantiles
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Taken from example by Zhiyi Liu, zhiyil@fnal.gov
here: http://root.cern.ch/phpBB3/viewtopic.php?f=3&t=6865
and converted into Python
"""
from __future__ import absolute_import

import ROOT

from math import sqrt
from array import array

from .. import Graph

__all__ = [
    'qqgraph',
]


def qqgraph(h1, h2, quantiles=None):
    """
    Return a Graph of a quantile-quantile (QQ) plot and confidence band
    """
    if quantiles is None:
        quantiles = max(min(len(h1), len(h2)) / 2, 1)
    nq = quantiles
    # position where to compute the quantiles in [0, 1]
    xq = array('d', [0.] * nq)
    # array to contain the quantiles
    yq1 = array('d', [0.] * nq)
    # array to contain the quantiles
    yq2 = array('d', [0.] * nq)

    for i in xrange(nq):
        xq[i] = float(i + 1) / nq

    h1.GetQuantiles(nq, yq1, xq)
    h2.GetQuantiles(nq, yq2, xq)

    xq_plus = array('d', [0.] * nq)
    xq_minus = array('d', [0.] * nq)
    yq2_plus = array('d', [0.] * nq)
    yq2_minus = array('d', [0.] * nq)

    """
    KS_cv: KS critical value

               1.36
    KS_cv = -----------
             sqrt( N )

    Where 1.36 is for alpha = 0.05 (confidence level 1-5%=95%, about 2 sigma)

    For 1 sigma (alpha=0.32, CL=68%), the value in the nominator is 0.9561,
    it is gotten by GetCriticalValue(1, 1 - 0.68).

    Notes
    -----

    * For 1-sample KS test (data and theoretic), N should be n

    * For 2-sample KS test (2 data set), N should be sqrt(m*n/(m+n))!
      Here is the case m or n (size of samples) should be effective size
      for a histogram

    * Critical value here is valid for only for sample size >= 80 (some
      references say 35) which means, for example, for a unweighted histogram,
      it must have more than 80 (or 35) entries filled and then confidence
      band is reliable.

    """

    esum1 = effective_sample_size(h1)
    esum2 = effective_sample_size(h2)

    # one sigma band
    KS_cv = (critical_value(1, 1 - 0.68) /
             sqrt((esum1 * esum2) / (esum1 + esum2)))

    for i in xrange(nq):
        # upper limit
        xq_plus[i] = float(xq[i] + KS_cv)
        # lower limit
        xq_minus[i] = float(xq[i] - KS_cv)

    h2.GetQuantiles(nq, yq2_plus, xq_plus)
    h2.GetQuantiles(nq, yq2_minus, xq_minus)

    yq2_err_plus = array('d', [0.] * nq)
    yq2_err_minus = array('d', [0.] * nq)
    for i in xrange(nq):
        yq2_err_plus[i] = yq2_plus[i] - yq2[i]
        yq2_err_minus[i] = yq2[i] - yq2_minus[i]

    # forget the last point, so number of points: (nq - 1)
    gr = Graph(nq - 1)
    for i in xrange(nq - 1):
        gr[i] = (yq1[i], yq2[i])
        # confidence level band
        gr.SetPointEYlow(i, yq2_err_minus[i])
        gr.SetPointEYhigh(i, yq2_err_plus[i])

    return gr


def effective_sample_size(h):
    """
    Calculate the effective sample size for a histogram
    the same way as ROOT does.
    """
    sum = 0
    ew = 0
    w = 0
    for bin in h.bins(overflow=False):
        sum += bin.value
        ew = bin.error
        w += ew * ew
    esum = sum * sum / w
    return esum


def critical_value(n, p):
    """
    This function calculates the critical value given
    n and p, and confidence level = 1 - p.
    """
    dn = 1
    delta = 0.5
    res = ROOT.TMath.KolmogorovProb(dn * sqrt(n))
    while res > 1.0001 * p or res < 0.9999 * p:
        if (res > 1.0001 * p):
            dn = dn + delta
        if (res < 0.9999 * p):
            dn = dn - delta
        delta = delta / 2.
        res = ROOT.TMath.KolmogorovProb(dn * sqrt(n))
    return dn

########NEW FILE########
__FILENAME__ = test_plot_contour_matrix
import string
from rootpy.plotting.contrib import plot_contour_matrix


if __name__ == '__main__':

    import numpy as np

    n_vars = 5
    var_names = ['var_%s' % s for s in string.lowercase[:n_vars]]

    def random_symm(n):
        a = np.random.random_integers(-10, 10, size=(n, n))
        return (a + a.T) / 2

    data_a = np.random.multivariate_normal(
        -np.random.random(n_vars) * 3, cov=random_symm(n_vars), size=100000)
    data_b = np.random.multivariate_normal(
        np.random.random(n_vars) * 3, cov=random_symm(n_vars), size=100000)

    plot_contour_matrix(
        [data_a, data_b],
        var_names,
        'out.gif',
        sample_names='A B'.split(),
        sample_colors='red blue'.split(),
        sample_lines='solid dashed'.split(),
        num_contours=5,
        cell_width=2,
        cell_height=2,
        animate_field='var_a',
        animate_steps=20)

########NEW FILE########
__FILENAME__ = test_plot_corrcoef_matrix
import string
from rootpy.plotting.contrib import plot_corrcoef_matrix


if __name__ == '__main__':

    import numpy as np

    n_vars = 10
    var_names = ['var_%s' % s for s in string.lowercase[:n_vars]]

    def random_symm(n):
        a = np.random.random_integers(-10, 10, size=(n, n))
        return (a + a.T) / 2

    data = np.random.multivariate_normal(
        -np.random.random(n_vars) * 3, cov=random_symm(n_vars), size=100000)
    weights = np.random.randint(1, 10, 100000)

    plot_corrcoef_matrix(
        data, var_names, 'correlations.png',
        weights=weights, title='correlations')

########NEW FILE########
__FILENAME__ = func
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from .. import QROOT
from ..decorators import snake_case_methods
from .base import Plottable
from ..base import NameOnlyObject


__all__ = [
    'F1',
    'F2',
    'F3',
]


@snake_case_methods
class F1(Plottable, NameOnlyObject, QROOT.TF1):
    _ROOT = QROOT.TF1

    def __init__(self, *args, **kwargs):
        name = kwargs.pop('name', None)
        super(F1, self).__init__(*args, name=name)
        self._post_init(**kwargs)


@snake_case_methods
class F2(Plottable, NameOnlyObject, QROOT.TF2):
    _ROOT = QROOT.TF2

    def __init__(self, *args, **kwargs):
        name = kwargs.pop('name', None)
        super(F2, self).__init__(*args, name=name)
        self._post_init(**kwargs)


@snake_case_methods
class F3(Plottable, NameOnlyObject, QROOT.TF3):
    _ROOT = QROOT.TF3

    def __init__(self, *args, **kwargs):
        name = kwargs.pop('name', None)
        super(F3, self).__init__(*args, name=name)
        self._post_init(**kwargs)

########NEW FILE########
__FILENAME__ = graph
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import math
from operator import add, sub

import ROOT

from .. import log; log = log[__name__]
from .. import QROOT
from ..base import NamelessConstructorObject, isbasictype
from ..decorators import snake_case_methods
from .base import Plottable

__all__ = [
    'Graph',
    'Graph1D',
    'Graph2D',
]


class _GraphBase(object):

    @classmethod
    def from_file(cls, filename, sep=' ', name=None, title=None):
        with open(filename, 'r') as gfile:
            lines = gfile.readlines()
        numpoints = len(lines)
        graph = cls(numpoints, name=name, title=title)
        for idx, line in enumerate(lines):
            point = map(float, line.rstrip().split(sep))
            if len(point) != cls.DIM + 1:
                raise ValueError(
                    "line {0:d} does not contain "
                    "{1:d} values: {2}".format(
                        idx + 1, cls.DIM + 1, line))
            graph.SetPoint(idx, *point)
        graph.Set(numpoints)
        return graph

    def __len__(self):
        return self.GetN()

    def __iter__(self):
        for index in xrange(len(self)):
            yield self[index]

    @property
    def num_points(self):
        return self.GetN()

    @num_points.setter
    def num_points(self, n):
        if n < 0:
            raise ValueError("number of points in a graph must "
                             "be non-negative")
        # ROOT, why not SetN with GetN?
        self.Set(n)

    def x(self, index=None):
        if index is None:
            return (self.GetX()[i] for i in xrange(self.GetN()))
        index = index % len(self)
        return self.GetX()[index]

    def xerr(self, index=None):
        if index is None:
            return ((self.GetEXlow()[i], self.GetEXhigh()[i])
                    for i in xrange(self.GetN()))
        index = index % len(self)
        return (self.GetErrorXlow(index), self.GetErrorXhigh(index))

    def xerrh(self, index=None):
        if index is None:
            return (self.GetEXhigh()[i] for i in xrange(self.GetN()))
        index = index % len(self)
        return self.GetErrorXhigh(index)

    def xerrl(self, index=None):
        if index is None:
            return (self.GetEXlow()[i] for i in xrange(self.GetN()))
        index = index % len(self)
        return self.GetErrorXlow(index)

    def xerravg(self, index=None):
        if index is None:
            return (self.xerravg(i) for i in xrange(self.GetN()))
        index = index % len(self)
        return math.sqrt(self.GetErrorXhigh(index) ** 2 +
                         self.GetErrorXlow(index) ** 2)

    def y(self, index=None):
        if index is None:
            return (self.GetY()[i] for i in xrange(self.GetN()))
        index = index % len(self)
        return self.GetY()[index]

    def yerr(self, index=None):
        if index is None:
            return (self.yerr(i) for i in xrange(self.GetN()))
        index = index % len(self)
        return (self.GetErrorYlow(index), self.GetErrorYhigh(index))

    def yerrh(self, index=None):
        if index is None:
            return (self.GetEYhigh()[i] for i in xrange(self.GetN()))
        index = index % len(self)
        return self.GetEYhigh()[index]

    def yerrl(self, index=None):
        if index is None:
            return (self.GetEYlow()[i] for i in xrange(self.GetN()))
        index = index % len(self)
        return self.GetEYlow()[index]

    def yerravg(self, index=None):
        if index is None:
            return (self.yerravg()[i] for i in xrange(self.GetN()))
        index = index % len(self)
        return math.sqrt(self.GetEYhigh()[index] ** 2 +
                         self.GetEYlow()[index] ** 2)


class _Graph1DBase(_GraphBase):

    def __getitem__(self, index):
        if not 0 <= index < self.GetN():
            raise IndexError("graph point index out of range")
        return (self.GetX()[index], self.GetY()[index])

    def __setitem__(self, index, point):
        if not 0 <= index <= self.GetN():
            raise IndexError("graph point index out of range")
        if not isinstance(point, (list, tuple)):
            raise TypeError("argument must be a tuple or list")
        if len(point) != 2:
            raise ValueError("argument must be of length 2")
        self.SetPoint(index, point[0], point[1])

    def __add__(self, other):
        copy = self.Clone()
        copy += other
        return copy

    def __radd__(self, other):
        return self + other

    def __sub__(self, other):
        copy = self.Clone()
        copy -= other
        return copy

    def __rsub__(self, other):
        return -1 * (self - other)

    def __div__(self, other):
        copy = self.Clone()
        copy /= other
        return copy

    @staticmethod
    def divide(left, right, consistency=True):
        tmp = left.Clone()
        tmp.__idiv__(right, consistency=consistency)
        return tmp

    def __mul__(self, other):
        copy = self.Clone()
        copy *= other
        return copy

    def __rmul__(self, other):
        return self * other

    def __iadd__(self, other):
        if isbasictype(other):
            for index in xrange(len(self)):
                point = self[index]
                self.SetPoint(index, point[0], point[1] + other)
        else:
            if len(other) != len(self):
                raise ValueError(
                    "graphs do not contain the same number of points")
            for index in xrange(len(self)):
                mypoint = self[index]
                otherpoint = other[index]
                if mypoint[0] != otherpoint[0]:
                    raise ValueError(
                        "graphs are not compatible: "
                        "must have same x-coordinate values")
                xlow = self.GetEXlow()[index]
                xhigh = self.GetEXhigh()[index]
                ylow = math.sqrt((self.GetEYlow()[index]) ** 2 +
                                (other.GetEYlow()[index]) ** 2)
                yhigh = math.sqrt((self.GetEYhigh()[index]) ** 2 +
                                 (other.GetEYhigh()[index]) ** 2)
                self.SetPoint(index, mypoint[0], mypoint[1] + otherpoint[1])
                self.SetPointError(index, xlow, xhigh, ylow, yhigh)
        return self

    def __isub__(self, other):
        if isbasictype(other):
            for index in xrange(len(self)):
                point = self[index]
                self.SetPoint(index, point[0], point[1] - other)
        else:
            if len(other) != len(self):
                raise ValueError(
                    "graphs do not contain the same number of points")
            for index in xrange(len(self)):
                mypoint = self[index]
                otherpoint = other[index]
                if mypoint[0] != otherpoint[0]:
                    raise ValueError(
                        "graphs are not compatible: "
                        "must have same x-coordinate values")
                xlow = self.GetEXlow()[index]
                xhigh = self.GetEXhigh()[index]
                ylow = math.sqrt((self.GetEYlow()[index]) ** 2 +
                                (other.GetEYlow()[index]) ** 2)
                yhigh = math.sqrt((self.GetEYhigh()[index]) ** 2 +
                                 (other.GetEYhigh()[index]) ** 2)
                self.SetPoint(index, mypoint[0], mypoint[1] - otherpoint[1])
                self.SetPointError(index, xlow, xhigh, ylow, yhigh)
        return self

    def __idiv__(self, other, consistency=True):
        if isbasictype(other):
            for index in xrange(len(self)):
                point = self[index]
                ylow, yhigh = self.GetEYlow()[index], self.GetEYhigh()[index]
                xlow, xhigh = self.GetEXlow()[index], self.GetEXhigh()[index]
                self.SetPoint(index, point[0], point[1] / other)
                self.SetPointError(index, xlow, xhigh,
                                   ylow / other, yhigh / other)
        else:
            if len(other) != len(self) and consistency:
                raise ValueError(
                    "graphs do not contain the same number of points")
            if not consistency:
                lowerror = Graph(len(other))
                higherror = Graph(len(other))
                for index, (x, (ylow, yhigh)) in enumerate(
                        zip(other.x(), other.yerr())):
                    lowerror[index] = (x, ylow)
                    higherror[index] = (x, yhigh)
            for index in xrange(len(self)):
                mypoint = self[index]
                if not consistency:
                    otherpoint = (mypoint[0], other.Eval(mypoint[0]))
                    xlow = self.GetEXlow()[index]
                    xhigh = self.GetEXhigh()[index]
                    ylow = (
                        (mypoint[1] / otherpoint[1]) *
                        math.sqrt((self.GetEYlow()[index] / mypoint[1]) ** 2 +
                                 (lowerror.Eval(mypoint[0]) /
                                     otherpoint[1]) ** 2))
                    yhigh = (
                        (mypoint[1] / otherpoint[1]) *
                        math.sqrt((self.GetEYhigh()[index] / mypoint[1]) ** 2 +
                                 (higherror.Eval(mypoint[0]) /
                                     otherpoint[1]) ** 2))
                elif mypoint[0] != otherpoint[0]:
                    raise ValueError(
                        "graphs are not compatible: "
                        "must have same x-coordinate values")
                else:
                    otherpoint = other[index]
                    xlow = self.GetEXlow()[index]
                    xhigh = self.GetEXhigh()[index]
                    ylow = (
                        (mypoint[1] / otherpoint[1]) *
                        math.sqrt((self.GetEYlow()[index] / mypoint[1]) ** 2 +
                                 (other.GetEYlow()[index] /
                                     otherpoint[1]) ** 2))
                    yhigh = (
                        (mypoint[1] / otherpoint[1]) *
                        math.sqrt((self.GetEYhigh()[index] / mypoint[1]) ** 2 +
                                 (other.GetEYhigh()[index] /
                                     otherpoint[1]) ** 2))
                self.SetPoint(index, mypoint[0], mypoint[1] / otherpoint[1])
                self.SetPointError(index, xlow, xhigh, ylow, yhigh)
        return self

    def __imul__(self, other):
        if isbasictype(other):
            for index in xrange(len(self)):
                point = self[index]
                ylow, yhigh = self.GetEYlow()[index], self.GetEYhigh()[index]
                xlow, xhigh = self.GetEXlow()[index], self.GetEXhigh()[index]
                self.SetPoint(index, point[0], point[1] * other)
                self.SetPointError(index, xlow, xhigh,
                                   ylow * other, yhigh * other)
        else:
            if len(other) != len(self):
                raise ValueError(
                    "graphs do not contain the same number of points")
            for index in xrange(len(self)):
                mypoint = self[index]
                otherpoint = other[index]
                if mypoint[0] != otherpoint[0]:
                    raise ValueError(
                        "graphs are not compatible: "
                        "must have same x-coordinate values")
                xlow = self.GetEXlow()[index]
                xhigh = self.GetEXhigh()[index]
                ylow = (
                    (mypoint[1] * otherpoint[1]) *
                    math.sqrt((self.GetEYlow()[index] / mypoint[1]) ** 2 +
                             (other.GetEYlow()[index] / otherpoint[1]) ** 2))
                yhigh = (
                    (mypoint[1] * otherpoint[1]) *
                    math.sqrt((self.GetEYhigh()[index] / mypoint[1]) ** 2 +
                             (other.GetEYhigh()[index] / otherpoint[1]) ** 2))
                self.SetPoint(index, mypoint[0], mypoint[1] * otherpoint[1])
                self.SetPointError(index, xlow, xhigh, ylow, yhigh)
        return self

    def GetMaximum(self, include_error=False):
        if not include_error:
            return self.GetYmax()
        summed = map(add, self.y(), self.yerrh())
        return max(summed)

    def GetMinimum(self, include_error=False):
        if not include_error:
            return self.GetYmin()
        summed = map(sub, self.y(), self.yerrl())
        return min(summed)

    def GetXmin(self):
        if len(self) == 0:
            raise ValueError("Attemping to get xmin of empty graph")
        return ROOT.TMath.MinElement(self.GetN(), self.GetX())

    def GetXmax(self):
        if len(self) == 0:
            raise ValueError("Attempting to get xmax of empty graph")
        return ROOT.TMath.MaxElement(self.GetN(), self.GetX())

    def GetYmin(self):
        if len(self) == 0:
            raise ValueError("Attempting to get ymin of empty graph")
        return ROOT.TMath.MinElement(self.GetN(), self.GetY())

    def GetYmax(self):
        if len(self) == 0:
            raise ValueError("Attempting to get ymax of empty graph!")
        return ROOT.TMath.MaxElement(self.GetN(), self.GetY())

    def Crop(self, x1, x2, copy=False):
        """
        Remove points which lie outside of [x1, x2].
        If x1 and/or x2 is below/above the current lowest/highest
        x-coordinates, additional points are added to the graph using a
        linear interpolation
        """
        numPoints = self.GetN()
        if copy:
            cropGraph = self.Clone()
            copyGraph = self
        else:
            cropGraph = self
            copyGraph = self.Clone()
        X = copyGraph.GetX()
        EXlow = copyGraph.GetEXlow()
        EXhigh = copyGraph.GetEXhigh()
        Y = copyGraph.GetY()
        EYlow = copyGraph.GetEYlow()
        EYhigh = copyGraph.GetEYhigh()
        xmin = copyGraph.GetXmin()
        if x1 < xmin:
            cropGraph.Set(numPoints + 1)
            numPoints += 1
        xmax = copyGraph.GetXmax()
        if x2 > xmax:
            cropGraph.Set(numPoints + 1)
            numPoints += 1
        index = 0
        for i in xrange(numPoints):
            if i == 0 and x1 < xmin:
                cropGraph.SetPoint(0, x1, copyGraph.Eval(x1))
            elif i == numPoints - 1 and x2 > xmax:
                cropGraph.SetPoint(i, x2, copyGraph.Eval(x2))
            else:
                cropGraph.SetPoint(i, X[index], Y[index])
                cropGraph.SetPointError(
                    i,
                    EXlow[index], EXhigh[index],
                    EYlow[index], EYhigh[index])
                index += 1
        return cropGraph

    def Reverse(self, copy=False):
        """
        Reverse the order of the points
        """
        numPoints = self.GetN()
        if copy:
            revGraph = self.Clone()
        else:
            revGraph = self
        X = self.GetX()
        EXlow = self.GetEXlow()
        EXhigh = self.GetEXhigh()
        Y = self.GetY()
        EYlow = self.GetEYlow()
        EYhigh = self.GetEYhigh()
        for i in xrange(numPoints):
            index = numPoints - 1 - i
            revGraph.SetPoint(i, X[index], Y[index])
            revGraph.SetPointError(
                i,
                EXlow[index], EXhigh[index],
                EYlow[index], EYhigh[index])
        return revGraph

    def Invert(self, copy=False):
        """
        Interchange the x and y coordinates of all points
        """
        numPoints = self.GetN()
        if copy:
            invGraph = self.Clone()
        else:
            invGraph = self
        X = self.GetX()
        EXlow = self.GetEXlow()
        EXhigh = self.GetEXhigh()
        Y = self.GetY()
        EYlow = self.GetEYlow()
        EYhigh = self.GetEYhigh()
        for i in xrange(numPoints):
            invGraph.SetPoint(i, Y[i], X[i])
            invGraph.SetPointError(
                i,
                EYlow[i], EYhigh[i],
                EXlow[i], EXhigh[i])
        return invGraph

    def Scale(self, value, copy=False):
        """
        Scale the graph vertically by value
        """
        numPoints = self.GetN()
        if copy:
            scaleGraph = self.Clone()
        else:
            scaleGraph = self
        X = self.GetX()
        EXlow = self.GetEXlow()
        EXhigh = self.GetEXhigh()
        Y = self.GetY()
        EYlow = self.GetEYlow()
        EYhigh = self.GetEYhigh()
        for i in xrange(numPoints):
            scaleGraph.SetPoint(i, X[i], Y[i] * value)
            scaleGraph.SetPointError(
                i,
                EXlow[i], EXhigh[i],
                EYlow[i] * value, EYhigh[i] * value)
        return scaleGraph

    def Stretch(self, value, copy=False):
        """
        Stretch the graph horizontally by a factor of value
        """
        numPoints = self.GetN()
        if copy:
            stretchGraph = self.Clone()
        else:
            stretchGraph = self
        X = self.GetX()
        EXlow = self.GetEXlow()
        EXhigh = self.GetEXhigh()
        Y = self.GetY()
        EYlow = self.GetEYlow()
        EYhigh = self.GetEYhigh()
        for i in xrange(numPoints):
            stretchGraph.SetPoint(i, X[i] * value, Y[i])
            stretchGraph.SetPointError(
                i,
                EXlow[i] * value, EXhigh[i] * value,
                EYlow[i], EYhigh[i])
        return stretchGraph

    def Shift(self, value, copy=False):
        """
        Shift the graph left or right by value
        """
        numPoints = self.GetN()
        if copy:
            shiftGraph = self.Clone()
        else:
            shiftGraph = self
        X = self.GetX()
        EXlow = self.GetEXlow()
        EXhigh = self.GetEXhigh()
        Y = self.GetY()
        EYlow = self.GetEYlow()
        EYhigh = self.GetEYhigh()
        for i in xrange(numPoints):
            shiftGraph.SetPoint(i, X[i] + value, Y[i])
            shiftGraph.SetPointError(
                i,
                EXlow[i], EXhigh[i],
                EYlow[i], EYhigh[i])
        return shiftGraph

    def Integrate(self):
        """
        Integrate using the trapazoidal method
        """
        area = 0.
        X = self.GetX()
        Y = self.GetY()
        for i in xrange(self.GetN() - 1):
            area += (X[i + 1] - X[i]) * (Y[i] + Y[i + 1]) / 2.
        return area


class _Graph2DBase(_GraphBase):

    def __getitem__(self, index):
        if not 0 <= index < self.GetN():
            raise IndexError("graph point index out of range")
        return (self.GetX()[index], self.GetY()[index], self.GetZ()[index])

    def __setitem__(self, index, point):
        if not 0 <= index <= self.GetN():
            raise IndexError("graph point index out of range")
        if not isinstance(point, (list, tuple)):
            raise TypeError("argument must be a tuple or list")
        if len(point) != 3:
            raise ValueError("argument must be of length 3")
        self.SetPoint(index, point[0], point[1], point[3])

    def z(self, index=None):
        if index is None:
            return (self.GetZ()[i] for i in xrange(self.GetN()))
        index = index % len(self)
        return self.GetZ()[index]

    def zerr(self, index=None):
        if index is None:
            return (self.zerr(i) for i in xrange(self.GetN()))
        index = index % len(self)
        return self.GetErrorZ(index)


_GRAPH1D_BASES = {
    'default': QROOT.TGraph,
    'asymm': QROOT.TGraphAsymmErrors,
    'errors': QROOT.TGraphErrors,
    'benterrors': QROOT.TGraphBentErrors,
}
_GRAPH1D_CLASSES = {}


def _Graph_class(base):

    class Graph(_Graph1DBase, Plottable, NamelessConstructorObject,
                base):
        _ROOT = base
        DIM = 1

        def __init__(self, npoints_or_hist,
                    name=None,
                    title=None,
                    **kwargs):
            super(Graph, self).__init__(npoints_or_hist, name=name, title=title)
            self._post_init(**kwargs)

    return Graph

for name, base in _GRAPH1D_BASES.items():
    _GRAPH1D_CLASSES[name] = snake_case_methods(_Graph_class(base))


class Graph(_Graph1DBase, QROOT.TGraph):
    """
    Returns a Graph object which inherits from the associated
    ROOT.TGraph* class (TGraph, TGraphErrors, TGraphAsymmErrors)
    """
    _ROOT = QROOT.TGraph
    DIM = 1

    @classmethod
    def dynamic_cls(cls, type='asymm'):
        return _GRAPH1D_CLASSES[type]

    def __new__(cls, *args, **kwargs):
        type = kwargs.pop('type', 'asymm').lower()
        return cls.dynamic_cls(type)(
            *args, **kwargs)


# alias Graph1D -> Graph
Graph1D = Graph

_GRAPH2D_BASES = {
    'default': QROOT.TGraph2D,
    'errors': QROOT.TGraph2DErrors,
}
_GRAPH2D_CLASSES = {}


def _Graph2D_class(base):

    class Graph2D(_Graph2DBase, Plottable, NamelessConstructorObject,
                base):
        _ROOT = base
        DIM = 2

        def __init__(self, npoints_or_hist,
                    name=None,
                    title=None,
                    **kwargs):
            super(Graph2D, self).__init__(npoints_or_hist,
                                          name=name,
                                          title=title)
            if isinstance(npoints_or_hist, int):
                # ROOT bug in TGraph2D
                self.Set(npoints_or_hist)
            self._post_init(**kwargs)

    return Graph2D

for name, base in _GRAPH2D_BASES.items():
    _GRAPH2D_CLASSES[name] = snake_case_methods(_Graph2D_class(base))


class Graph2D(_Graph2DBase, QROOT.TGraph2D):
    """
    Returns a Graph2D object which inherits from the associated
    ROOT.TGraph2D* class (TGraph2D, TGraph2DErrors)
    """
    _ROOT = QROOT.TGraph2D
    DIM = 2

    @classmethod
    def dynamic_cls(cls, type='errors'):
        return _GRAPH2D_CLASSES[type]

    def __new__(cls, *args, **kwargs):
        type = kwargs.pop('type', 'errors').lower()
        return cls.dynamic_cls(type)(
            *args, **kwargs)

########NEW FILE########
__FILENAME__ = hist
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from array import array
from math import sqrt
from itertools import product, izip
import operator
import uuid

import ROOT

from .. import asrootpy, QROOT, log; log = log[__name__]
from ..base import NamedObject, isbasictype
from ..decorators import snake_case_methods, cached_property
from ..context import invisible_canvas
from ..utils.extras import izip_exact
from .base import Plottable, dim
from .graph import Graph


__all__ = [
    'Hist',
    'Hist1D',
    'Hist2D',
    'Hist3D',
    'HistStack',
    'Efficiency',
    'histogram',
]


def canonify_slice(s, n):
    """
    Convert a slice object into a canonical form
    to simplify treatment in histogram bin content
    and edge slicing.
    """
    if isinstance(s, (int, long)):
        return canonify_slice(slice(s, s + 1, None), n)
    start = s.start % n if s.start is not None else 0
    stop = s.stop % n if s.stop is not None else n
    step = s.step if s.step is not None else 1
    return slice(start, stop, step)


def bin_to_edge_slice(s, n):
    """
    Convert a bin slice into a bin edge slice.
    """
    s = canonify_slice(s, n)
    start = s.start
    stop = s.stop
    if start > stop:
        _stop = start + 1
        start = stop + 1
        stop = _stop
    start = max(start - 1, 0)
    step = abs(s.step)
    if stop <= 1 or start >= n - 1 or stop == start + 1:
        return slice(0, None, min(step, n - 2))
    s = slice(start, stop, abs(s.step))
    if len(xrange(*s.indices(n - 1))) < 2:
        return slice(start, stop, stop - start - 1)
    return s


class _HistViewBase(object):

    @staticmethod
    def _slice_repr(s):
        if isinstance(s, slice):
            return '[start={0}, stop={1}, step={2}]'.format(
                s.start, s.stop, s.step)
        else:
            return '{0}'.format(s)


class HistIndexView(_HistViewBase):

    def __init__(self, hist, idx):
        if idx.step is not None and abs(idx.step) != 1:
            raise ValueError(
                "rebinning using the global histogram bin "
                "indices is not supported")
        self.hist = hist
        self.idx = idx

    def __iter__(self):
        return self.hist.bins(idx=self.idx, overflow=True)

    def __repr__(self):
        return '{0}({1}, idx={2})'.format(
            self.__class__.__name__, self.hist, self._slice_repr(self.idx))


class HistView(_HistViewBase):

    def __init__(self, hist, x):
        if isinstance(x, slice) and x.step == 0:
            raise ValueError("rebin cannot be zero")
        self.hist = hist
        self.x = x

    @cached_property
    def xedges(self):
        return list(self.hist.xedges())[
            bin_to_edge_slice(self.x, self.hist.nbins(axis=0, overflow=True))]

    @property
    def points(self):
        return self.hist.bins_xyz(ix=self.x, proxy=False)

    def __iter__(self):
        return self.hist.bins_xyz(ix=self.x)

    def __repr__(self):
        return '{0}({1}, x={2})'.format(
            self.__class__.__name__, self.hist, self._slice_repr(self.x))


class Hist2DView(_HistViewBase):

    def __init__(self, hist, x, y):
        if isinstance(x, slice) and x.step == 0:
            raise ValueError("rebin along x cannot be zero")
        if isinstance(y, slice) and y.step == 0:
            raise ValueError("rebin along y cannot be zero")
        self.hist = hist
        self.x = x
        self.y = y

    @cached_property
    def xedges(self):
        return list(self.hist.xedges())[
            bin_to_edge_slice(self.x, self.hist.nbins(axis=0, overflow=True))]

    @cached_property
    def yedges(self):
        return list(self.hist.yedges())[
            bin_to_edge_slice(self.y, self.hist.nbins(axis=1, overflow=True))]

    @property
    def points(self):
        return self.hist.bins_xyz(ix=self.x, iy=self.y, proxy=False)

    def __iter__(self):
        return self.hist.bins_xyz(ix=self.x, iy=self.y)

    def __repr__(self):
        return '{0}({1}, x={2}, y={3})'.format(
            self.__class__.__name__, self.hist,
            self._slice_repr(self.x),
            self._slice_repr(self.y))


class Hist3DView(_HistViewBase):

    def __init__(self, hist, x, y, z):
        if isinstance(x, slice) and x.step == 0:
            raise ValueError("rebin along x cannot be zero")
        if isinstance(y, slice) and y.step == 0:
            raise ValueError("rebin along y cannot be zero")
        if isinstance(z, slice) and z.step == 0:
            raise ValueError("rebin along z cannot be zero")
        self.hist = hist
        self.x = x
        self.y = y
        self.z = z

    @cached_property
    def xedges(self):
        return list(self.hist.xedges())[
            bin_to_edge_slice(self.x, self.hist.nbins(axis=0, overflow=True))]

    @cached_property
    def yedges(self):
        return list(self.hist.yedges())[
            bin_to_edge_slice(self.y, self.hist.nbins(axis=1, overflow=True))]

    @cached_property
    def zedges(self):
        return list(self.hist.zedges())[
            bin_to_edge_slice(self.z, self.hist.nbins(axis=2, overflow=True))]

    @property
    def points(self):
        return self.hist.bins_xyz(ix=self.x, iy=self.y, iz=self.z, proxy=False)

    def __iter__(self):
        return self.hist.bins_xyz(ix=self.x, iy=self.y, iz=self.z)

    def __repr__(self):
        return '{0}({1}, x={2}, y={3}, z={4})'.format(
            self.__class__.__name__, self.hist,
            self._slice_repr(self.x),
            self._slice_repr(self.y),
            self._slice_repr(self.z))


class BinProxy(object):

    def __init__(self, hist, idx):
        self.hist = hist
        self.idx = idx
        self._sum_w2 = hist.GetSumw2()

    @property
    def xyz(self):
        return self.hist.xyz(self.idx)

    @cached_property
    def overflow(self):
        """
        Returns true if this BinProxy is for an overflow bin
        """
        indices = self.hist.xyz(self.idx)
        for i in xrange(self.hist.GetDimension()):
            if indices[i] == 0 or indices[i] == self.hist.nbins(i) + 1:
                return True
        return False

    @property
    def x(self):
        return self.hist.axis_bininfo(0, self.xyz[0])

    @property
    def y(self):
        return self.hist.axis_bininfo(1, self.xyz[1])

    @property
    def z(self):
        return self.hist.axis_bininfo(2, self.xyz[2])

    @property
    def value(self):
        return self.hist.GetBinContent(self.idx)

    @value.setter
    def value(self, v):
        return self.hist.SetBinContent(self.idx, v)

    @property
    def error(self):
        return self.hist.GetBinError(self.idx)

    @error.setter
    def error(self, e):
        return self.hist.SetBinError(self.idx, e)

    @property
    def sum_w2(self):
        return self._sum_w2.At(self.idx)

    @sum_w2.setter
    def sum_w2(self, w):
        self._sum_w2.SetAt(w, self.idx)

    @property
    def effective_entries(self):
        """
        Number of effective entries in this bin.
        The number of unweighted entries this bin would need to
        contain in order to have the same statistical power as this
        bin with possibly weighted entries, estimated by:

            (sum of weights) ** 2 / (sum of squares of weights)

        """
        sum_w2 = self.sum_w2
        if sum_w2 == 0:
            return abs(self.value)
        return (self.value ** 2) / sum_w2

    def __iadd__(self, other):
        self.value += other.value
        self.sum_w2 += other.sum_w2
        return self

    def __imul__(self, v):
        self.value *= v
        self.error *= v
        return self

    def __idiv__(self, v):
        self.value /= v
        self.error /= v
        return self

    def __ipow__(self, v):
        cur_value = self.value
        if cur_value == 0:
            return self
        new_value = cur_value ** v
        self.value = new_value
        self.error *= new_value / cur_value
        return self

    def __repr__(self):
        return '{0}({1}, {2})'.format(
            self.__class__.__name__, self.hist, self.idx)


class _HistBase(Plottable, NamedObject):

    TYPES = dict(
        (c, [getattr(QROOT, "TH{0}{1}".format(d, c)) for d in (1, 2, 3)])
            for c in "CSIFD")

    def _parse_args(self, args, ignore_extras=False):

        params = [{
            'bins': None,
            'nbins': None,
            'low': None,
            'high': None} for _ in xrange(dim(self))]

        for param in params:
            if len(args) == 0:
                raise TypeError("did not receive expected number of arguments")
            if hasattr(args[0], '__iter__'):
                edges = list(args[0])
                if len(edges) < 2:
                    raise ValueError(
                        "specify at least two bin edges")
                if sorted(edges) != edges:
                    raise ValueError(
                        "bin edges must be sorted in ascending order")
                if len(set(args[0])) != len(args[0]):
                    raise ValueError("bin edges must not be repeated")
                param['bins'] = args[0]
                param['nbins'] = len(args[0]) - 1
                args = args[1:]
            elif len(args) >= 3:
                nbins = args[0]
                if type(nbins) is not int:
                    raise TypeError(
                        "number of bins must be an integer")
                if nbins < 1:
                    raise ValueError(
                        "number of bins must be positive")
                low = args[1]
                if not isbasictype(low):
                    raise TypeError(
                        "lower bound must be an int, float, or long")
                high = args[2]
                if not isbasictype(high):
                    raise TypeError(
                        "upper bound must be an int, float, or long")
                param['nbins'] = nbins
                param['low'] = low
                param['high'] = high
                if low >= high:
                    raise ValueError(
                        "upper bound (you gave {0:f}) "
                        "must be greater than lower "
                        "bound (you gave {1:f})".format(
                            float(low), float(high)))
                args = args[3:]
            else:
                raise TypeError(
                    "did not receive expected number of arguments")

        if ignore_extras:
            # used by Profile where range of profiled axis may be specified
            return params, args

        if len(args) != 0:
            raise TypeError(
                "did not receive expected number of arguments")

        return params

    def xyz(self, i):
        x, y, z = ROOT.Long(0), ROOT.Long(0), ROOT.Long(0)
        self.GetBinXYZ(i, x, y, z)
        return x, y, z

    def axis_bininfo(self, axi, i):
        class bi:
            axis = self.axis(axi)
            low = axis.GetBinLowEdge(i)
            center = axis.GetBinCenter(i)
            high = axis.GetBinUpEdge(i)
            width = axis.GetBinWidth(i)
        return bi

    def bins(self, idx=None, overflow=False):
        if idx is None:
            idx = xrange(self.GetSize())
        elif isinstance(idx, slice):
            idx = xrange(*idx.indices(self.GetSize()))
            overflow = True
        else:
            idx = [self._range_check(idx)]
            overflow = True
        for i in idx:
            bproxy = BinProxy(self, i)
            if not overflow and bproxy.overflow:
                continue
            yield bproxy

    def bins_xyz(self, ix, iy=0, iz=0, proxy=True):
        xl = self.nbins(axis=0, overflow=True)
        yl = self.nbins(axis=1, overflow=True)
        zl = self.nbins(axis=2, overflow=True)
        if isinstance(ix, slice):
            ix = xrange(*ix.indices(xl))
        else:
            ix = [self._range_check(ix, axis=0)]
        if isinstance(iy, slice):
            iy = xrange(*iy.indices(yl))
        else:
            iy = [self._range_check(iy, axis=1)]
        if isinstance(iz, slice):
            iz = xrange(*iz.indices(zl))
        else:
            iz = [self._range_check(iz, axis=2)]
        if proxy:
            for x, y, z in product(ix, iy, iz):
                yield BinProxy(self, xl * yl * z + xl * y + x)
        else:
            for point in product(ix, iy, iz):
                yield point

    @classmethod
    def divide(cls, h1, h2, c1=1., c2=1., option='', fill_value=None):
        ratio = h1.Clone()
        ROOT.TH1.Divide(ratio, h1, h2, c1, c2, option)
        if fill_value is not None:
            for ratiobin, h2bin in izip(ratio.bins(), h2.bins()):
                if h2bin.value == 0:
                    ratiobin.value = fill_value
        return ratio

    def nbins(self, axis=0, overflow=False):
        """
        Get the number of bins along an axis
        """
        if axis == 0:
            nbins = self.GetNbinsX()
        elif axis == 1:
            nbins = self.GetNbinsY()
        elif axis == 2:
            nbins = self.GetNbinsZ()
        else:
            raise ValueError("axis must be 0, 1, or 2")
        if overflow:
            nbins += 2
        return nbins

    def bins_range(self, axis=0, overflow=False):
        """
        Return a range of bin indices for iterating along an axis

        Parameters
        ----------

        axis : int, optional (default=1)
            The axis (0, 1 or 2).

        overflow : bool, optional (default=False)
            If True then include the underflow and overflow bins
            otherwise only include the visible bins.

        Returns
        -------

        an xrange object of bin indices

        """
        nbins = self.nbins(axis=axis, overflow=False)
        if overflow:
            start = 0
            end_offset = 2
        else:
            start = 1
            end_offset = 1
        return xrange(start, nbins + end_offset)

    @property
    def axes(self):
        return [self.axis(i) for i in xrange(self.GetDimension())]

    def axis(self, axis=0):

        if axis == 0:
            return self.GetXaxis()
        elif axis == 1:
            return self.GetYaxis()
        elif axis == 2:
            return self.GetZaxis()
        else:
            raise ValueError("axis must be 0, 1, or 2")

    @property
    def entries(self):
        return self.GetEntries()

    @entries.setter
    def entries(self, value):
        self.SetEntries(value)

    def __len__(self):
        """
        The total number of bins, including overflow bins
        """
        return self.GetSize()

    def __iter__(self):
        """
        Iterate over the bin proxies
        """
        return self.bins(overflow=True)

    def _range_check(self, index, axis=None):

        if axis is None:
            size = self.GetSize()
        else:
            size = self.nbins(axis=axis)
            if axis < self.GetDimension():
                size += 2
        try:
            if index < 0:
                if index < - size:
                    raise IndexError
                return index % size
            elif index >= size:
                raise IndexError
        except IndexError:
            if axis is None:
                raise IndexError(
                    "global bin index {0:d} is out of range".format(index))
            else:
                raise IndexError(
                    "bin index {0:d} along axis {1:d} is out of range".format(
                        index, axis))
        return index

    def GetBin(self, ix, iy=0, iz=0):
        ix = self._range_check(ix, axis=0)
        iy = self._range_check(iy, axis=1)
        iz = self._range_check(iz, axis=2)
        return super(_HistBase, self).GetBin(ix, iy, iz)

    def __getitem__(self, index):
        """
        Return a BinProxy or list of BinProxies if index is a slice.
        """
        if isinstance(index, slice):
            if isinstance(self, _Hist):
                return HistView(self, index)
            return HistIndexView(self, index)
        if isinstance(index, tuple):
            ix, iy, iz = 0, 0, 0
            ndim = self.GetDimension()
            view = False
            if ndim == 2:
                try:
                    ix, iy = index
                except ValueError:
                    raise IndexError(
                        "must index along only two "
                        "axes of a 2D histogram")
                if isinstance(ix, slice) or isinstance(iy, slice):
                    return Hist2DView(self, x=ix, y=iy)
            elif ndim == 3:
                try:
                    ix, iy, iz = index
                except ValueError:
                    raise IndexError(
                        "must index along exactly three "
                        "axes of a 3D histogram")
                if (isinstance(ix, slice) or isinstance(iy, slice)
                        or isinstance(iz, slice)):
                    return Hist3DView(self, x=ix, y=iy, z=iz)
            else:
                raise IndexError(
                    "must index along only one "
                    "axis of a 1D histogram")
            index = self.GetBin(ix, iy, iz)
        else:
            index = self._range_check(index)
        return BinProxy(self, index)

    def __setitem__(self, index, value):
        """
        Set bin contents and additionally bin errors if value is a BinProxy or
        a 2-tuple containing the value and error.
        If index is a slice then value must be a list of values, BinProxies, or
        2-tuples of the same length as the slice.
        """
        is_slice = isinstance(index, slice)
        is_tuple = (not is_slice) and isinstance(index, tuple)
        if is_slice or is_tuple:

            if isinstance(value, _HistBase):
                self[index] = value[index]
                return

            if is_slice:
                indices = xrange(*index.indices(self.GetSize()))

            else:
                ndim = self.GetDimension()
                xl = self.nbins(0, overflow=True)
                yl = self.nbins(1, overflow=True)
                if ndim == 2:
                    try:
                        ix, iy = index
                    except ValueError:
                        raise IndexError(
                            "must index along only two "
                            "axes of a 2D histogram")
                    if isinstance(ix, slice):
                        ix = xrange(*ix.indices(xl))
                    else:
                        ix = [self._range_check(ix, axis=0)]
                    if isinstance(iy, slice):
                        iy = xrange(*iy.indices(yl))
                    else:
                        iy = [self._range_check(iy, axis=1)]
                    iz = [0]
                elif ndim == 3:
                    try:
                        ix, iy, iz = index
                    except ValueError:
                        raise IndexError(
                            "must index along exactly three "
                            "axes of a 3D histogram")
                    if isinstance(ix, slice):
                        ix = xrange(*ix.indices(xl))
                    else:
                        ix = [self._range_check(ix, axis=0)]
                    if isinstance(iy, slice):
                        iy = xrange(*iy.indices(yl))
                    else:
                        iy = [self._range_check(iy, axis=1)]
                    if isinstance(iz, slice):
                        iz = xrange(*iz.indices(self.nbins(2, overflow=True)))
                    else:
                        iz = [self._range_check(iz, axis=2)]
                else:
                    raise IndexError(
                        "must index along only one "
                        "axis of a 1D histogram")
                indices = (xl * yl * z + xl * y + x
                    for (x, y, z) in product(ix, iy, iz))

            if isinstance(value, _HistViewBase):
                for i, v in izip_exact(indices, value):
                    self.SetBinContent(i, v.value)
                    self.SetBinError(i, v.error)
            elif hasattr(value, '__iter__') and not isinstance(value, tuple):
                if value and isinstance(value[0], tuple):
                    for i, v in izip_exact(indices, value):
                        _value, _error = value
                        self.SetBinContent(i, _value)
                        self.SetBinError(i, _error)
                else:
                    for i, v in izip_exact(indices, value):
                        self.SetBinContent(i, v)
            elif isinstance(value, BinProxy):
                v, e = value.value, value.error
                for i in indices:
                    self.SetBinContent(i, v)
                    self.SetBinError(i, e)
            elif isinstance(value, tuple):
                _value, _error = value
                for i in indices:
                    self.SetBinContent(i, _value)
                    self.SetBinError(i, _error)
            else:
                for i in indices:
                    self.SetBinContent(i, value)
            return

        index = self._range_check(index)

        if isinstance(value, BinProxy):
            self.SetBinContent(index, value.value)
            self.SetBinError(index, value.error)
        elif isinstance(value, tuple):
            value, error = value
            self.SetBinContent(index, value)
            self.SetBinError(index, error)
        else:
            self.SetBinContent(index, value)

    def uniform(self, axis=None, precision=1E-7):
        """
        Return True if the binning is uniform along the specified axis.
        If axis is None (the default), then return True if the binning is
        uniform along all axes. Otherwise return False.

        Parameters
        ----------

        axis : int (default=None)
            Axis along which to check if the binning is uniform. If None,
            then check all axes.

        precision : float (default=1E-7)
            The threshold below which differences in bin widths are ignored and
            treated as equal.

        Returns
        -------

        True if the binning is uniform, otherwise False.

        """
        if axis is None:
            for axis in xrange(self.GetDimension()):
                widths = list(self._width(axis=axis))
                if not all(abs(x - widths[0]) < precision for x in widths):
                    return False
            return True
        widths = list(self._width(axis=axis))
        return all(abs(x - widths[0]) < precision for x in widths)

    def uniform_binned(self, name=None):
        """
        Return a new histogram with constant width bins along all axes by
        using the bin indices as the bin edges of the new histogram.
        """
        if self.GetDimension() == 1:
            new_hist = Hist(
                self.GetNbinsX(), 0, self.GetNbinsX(),
                name=name, type=self.TYPE)
        elif self.GetDimension() == 2:
            new_hist = Hist2D(
                self.GetNbinsX(), 0, self.GetNbinsX(),
                self.GetNbinsY(), 0, self.GetNbinsY(),
                name=name, type=self.TYPE)
        else:
            new_hist = Hist3D(
                self.GetNbinsX(), 0, self.GetNbinsX(),
                self.GetNbinsY(), 0, self.GetNbinsY(),
                self.GetNbinsZ(), 0, self.GetNbinsZ(),
                name=name, type=self.TYPE)
        # copy over the bin contents and errors
        for outbin, inbin in izip(new_hist.bins(), self.bins()):
            outbin.value = inbin.value
            outbin.error = inbin.error
        return new_hist

    def underflow(self, axis=0):
        """
        Return the underflow for the given axis.

        Depending on the dimension of the histogram, may return an array.
        """
        if axis not in range(3):
            raise ValueError("axis must be 0, 1, or 2")
        if self.DIM == 1:
            return self.GetBinContent(0)
        elif self.DIM == 2:
            def idx(i):
                arg = [i]
                arg.insert(axis, 0)
                return arg
            return [
                self.GetBinContent(*idx(i))
                for i in self.bins_range(axis=(axis + 1) % 2, overflow=True)]
        elif self.DIM == 3:
            axes = range(3)
            axes.remove(axis)
            axis2, axis3 = axes
            def idx(i, j):
                arg = [i, j]
                arg.insert(axis, 0)
                return arg
            return [[
                self.GetBinContent(*idx(i, j))
                for i in self.bins_range(axis=axis2, overflow=True)]
                for j in self.bins_range(axis=axis3, overflow=True)]

    def overflow(self, axis=0):
        """
        Return the overflow for the given axis.

        Depending on the dimension of the histogram, may return an array.
        """
        if axis not in range(3):
            raise ValueError("axis must be 0, 1, or 2")
        if self.DIM == 1:
            return self.GetBinContent(self.nbins(0) + 1)
        elif self.DIM == 2:
            axes = range(2)
            axes.remove(axis)
            axis2 = axes[0]
            nbins_axis = self.nbins(axis)
            def idx(i):
                arg = [i]
                arg.insert(axis, nbins_axis + 1)
                return arg
            return [
                self.GetBinContent(*idx(i))
                for i in self.bins_range(axis=axis2, overflow=True)]
        elif self.DIM == 3:
            axes = range(3)
            axes.remove(axis)
            axis2, axis3 = axes
            nbins_axis = self.nbins(axis)
            def idx(i, j):
                arg = [i, j]
                arg.insert(axis, nbins_axis + 1)
                return arg
            return [[
                self.GetBinContent(*idx(i, j))
                for i in self.bins_range(axis=axis2, overflow=True)]
                for j in self.bins_range(axis=axis3, overflow=True)]

    def lowerbound(self, axis=0):
        """
        Get the lower bound of the binning along an axis
        """
        if not 0 <= axis < self.GetDimension():
            raise ValueError(
                "axis must be a non-negative integer less than "
                "the dimensionality of the histogram")
        if axis == 0:
            return self.xedges(1)
        if axis == 1:
            return self.yedges(1)
        if axis == 2:
            return self.zedges(1)
        raise TypeError("axis must be an integer")

    def upperbound(self, axis=0):
        """
        Get the upper bound of the binning along an axis
        """
        if not 0 <= axis < self.GetDimension():
            raise ValueError(
                "axis must be a non-negative integer less than "
                "the dimensionality of the histogram")
        if axis == 0:
            return self.xedges(-2)
        if axis == 1:
            return self.yedges(-2)
        if axis == 2:
            return self.zedges(-2)
        raise TypeError("axis must be an integer")

    def bounds(self, axis=0):
        """
        Get the lower and upper bounds of the binning along an axis
        """
        if not 0 <= axis < self.GetDimension():
            raise ValueError(
                "axis must be a non-negative integer less than "
                "the dimensionality of the histogram")
        if axis == 0:
            return self.xedges(1), self.xedges(-2)
        if axis == 1:
            return self.yedges(1), self.yedges(-2)
        if axis == 2:
            return self.zedges(1), self.zedges(-2)
        raise TypeError("axis must be an integer")

    def _centers(self, axis, index=None, overflow=False):
        nbins = self.nbins(axis)
        ax = self.axis(axis)
        if index is None:
            def temp_generator():
                if overflow:
                    yield float('-inf')
                for index in xrange(1, nbins + 1):
                    yield ax.GetBinCenter(index)
                if overflow:
                    yield float('+inf')
            return temp_generator()
        index = index % (nbins + 2)
        if index == 0:
            return float('-inf')
        elif index == nbins + 1:
            return float('+inf')
        return ax.GetBinCenter(index)

    def _edgesl(self, axis, index=None, overflow=False):
        nbins = self.nbins(axis)
        ax = self.axis(axis)
        if index is None:
            def temp_generator():
                if overflow:
                    yield float('-inf')
                for index in xrange(1, nbins + 1):
                    yield ax.GetBinLowEdge(index)
                if overflow:
                    yield ax.GetBinUpEdge(index)
            return temp_generator()
        index = index % (nbins + 2)
        if index == 0:
            return float('-inf')
        return ax.GetBinLowEdge(index)

    def _edgesh(self, axis, index=None, overflow=False):
        nbins = self.nbins(axis)
        ax = self.axis(axis)
        if index is None:
            def temp_generator():
                if overflow:
                    yield ax.GetBinUpEdge(0)
                for index in xrange(1, nbins + 1):
                    yield ax.GetBinUpEdge(index)
                if overflow:
                    yield float('+inf')
            return temp_generator()
        index = index % (nbins + 2)
        if index == nbins + 1:
            return float('+inf')
        return ax.GetBinUpEdge(index)

    def _edges(self, axis, index=None, overflow=False):
        nbins = self.nbins(axis)
        ax = self.axis(axis)
        if index is None:
            def temp_generator():
                if overflow:
                    yield float('-inf')
                for index in xrange(1, nbins + 1):
                    yield ax.GetBinLowEdge(index)
                yield ax.GetBinUpEdge(nbins)
                if overflow:
                    yield float('+inf')
            return temp_generator()
        index = index % (nbins + 3)
        if index == 0:
            return float('-inf')
        if index == nbins + 2:
            return float('+inf')
        return ax.GetBinLowEdge(index)

    def _width(self, axis, index=None, overflow=False):
        nbins = self.nbins(axis)
        ax = self.axis(axis)
        if index is None:
            def temp_generator():
                if overflow:
                    yield float('+inf')
                for index in xrange(1, nbins + 1):
                    yield ax.GetBinWidth(index)
                if overflow:
                    yield float('+inf')
            return temp_generator()
        index = index % (nbins + 2)
        if index in (0, nbins + 1):
            return float('+inf')
        return ax.GetBinWidth(index)

    def _erravg(self, axis, index=None, overflow=False):
        nbins = self.nbins(axis)
        ax = self.axis(axis)
        if index is None:
            def temp_generator():
                if overflow:
                    yield float('+inf')
                for index in xrange(1, nbins + 1):
                    yield ax.GetBinWidth(index) / 2.
                if overflow:
                    yield float('+inf')
            return temp_generator()
        index = index % (nbins + 2)
        if index in (0, nbins + 1):
            return float('+inf')
        return ax.GetBinWidth(index) / 2.

    def _err(self, axis, index=None, overflow=False):
        nbins = self.nbins(axis)
        ax = self.axis(axis)
        if index is None:
            def temp_generator():
                if overflow:
                    yield (float('+inf'), float('+inf'))
                for index in xrange(1, nbins + 1):
                    w = ax.GetBinWidth(index) / 2.
                    yield (w, w)
                if overflow:
                    yield (float('+inf'), float('+inf'))
            return temp_generator()
        index = index % (nbins + 2)
        if index in (0, nbins + 1):
            return (float('+inf'), float('+inf'))
        w = ax.GetBinWidth(index) / 2.
        return (w, w)

    def check_compatibility(self, other, check_edges=False, precision=1E-7):
        """
        Test whether two histograms are considered compatible by the number of
        dimensions, number of bins along each axis, and optionally the bin
        edges.

        Parameters
        ----------

        other : histogram
            A rootpy histogram

        check_edges : bool, optional (default=False)
            If True then also check that the bin edges are equal within
            the specified precision.

        precision : float, optional (default=1E-7)
            The value below which differences between floats are treated as
            nil when comparing bin edges.

        Raises
        ------

        TypeError
            If the histogram dimensionalities do not match

        ValueError
            If the histogram sizes, number of bins along an axis, or
            optionally the bin edges do not match

        """
        if self.GetDimension() != other.GetDimension():
            raise TypeError("histogram dimensionalities do not match")
        if len(self) != len(other):
            raise ValueError("histogram sizes do not match")
        for axis in xrange(self.GetDimension()):
            if self.nbins(axis=axis) != other.nbins(axis=axis):
                raise ValueError(
                    "numbers of bins along axis {0:d} do not match".format(
                        axis))
        if check_edges:
            for axis in xrange(self.GetDimension()):
                if not all([abs(l - r) < precision
                    for l, r in izip(self._edges(axis), other._edges(axis))]):
                    raise ValueError(
                        "edges do not match along axis {0:d}".format(axis))

    def compatible(self, other, check_edges=False, precision=1E-7):
        try:
            self.check_compatibility(other,
                check_edges=check_edges, precision=precision)
        except (TypeError, ValueError):
            return False
        return True

    def __add__(self, other):
        copy = self.Clone()
        copy += other
        return copy

    def __iadd__(self, other):
        if isbasictype(other):
            if other != 0:
                for bin in self.bins(overflow=True):
                    bin.value += other
        else:
            self.Add(other)
        return self

    def __radd__(self, other):
        if isbasictype(other):
            copy = self.Clone()
            if other != 0:
                copy += other
            return copy
        return NotImplemented

    def __sub__(self, other):
        copy = self.Clone()
        copy -= other
        return copy

    def __isub__(self, other):
        if isbasictype(other):
            if other != 0:
                for bin in self.bins(overflow=True):
                    bin.value -= other
        else:
            self.Add(other, -1.)
        return self

    def __rsub__(self, other):
        if isbasictype(other):
            copy = self.Clone()
            if other != 0:
                for bin in copy.bins(overflow=True):
                    bin.value = other - bin.value
            return copy
        return NotImplemented

    def __mul__(self, other):
        copy = self.Clone()
        copy *= other
        return copy

    def __imul__(self, other):
        if isbasictype(other):
            self.Scale(other)
            return self
        self.Multiply(other)
        return self

    def __rmul__(self, other):
        if isbasictype(other):
            copy = self.Clone()
            if other != 1:
                copy *= other
            return copy
        return NotImplemented

    def __div__(self, other):
        copy = self.Clone()
        copy /= other
        return copy

    def __idiv__(self, other):
        if isbasictype(other):
            if other == 0:
                raise ZeroDivisionError(
                    "attempting to divide histogram by zero")
            self.Scale(1. / other)
            return self
        self.Divide(other)
        return self

    def __rdiv__(self, other):
        if isbasictype(other):
            copy = self.Clone()
            for bin in copy.bins(overflow=True):
                v = bin.value
                if v != 0:
                    bin.value = other / v
            return copy
        return NotImplemented

    def __ipow__(self, other, modulo=None):
        if modulo is not None:
            return NotImplemented
        if isbasictype(other):
            for bin in self.bins(overflow=True):
                bin **= other
        elif isinstance(other, _HistBase):
            self.check_compatibility(other)
            for this_bin, other_bin in izip(
                    self.bins(overflow=True),
                    other.bins(overflow=True)):
                this_bin **= other_bin.value
        else:
            return NotImplemented
        return self

    def __pow__(self, other, modulo=None):
        if modulo is not None:
            return NotImplemented
        copy = self.Clone()
        copy **= other
        return copy

    def __cmp__(self, other):
        return cmp(self.Integral(), other.Integral())

    def fill_array(self, array, weights=None):
        """
        Fill this histogram with a NumPy array
        """
        try:
            try:
                from root_numpy import fill_hist as fill_func
            except ImportError:
                from root_numpy import fill_array as fill_func
        except ImportError:
            log.critical(
                "root_numpy is needed for Hist*.fill_array. "
                "Is it installed and importable?")
            raise
        fill_func(self, array, weights=weights)

    def fill_view(self, view):
        """
        Fill this histogram from a view of another histogram
        """
        other = view.hist
        _other_x_center = other.axis(0).GetBinCenter
        _other_y_center = other.axis(1).GetBinCenter
        _other_z_center = other.axis(2).GetBinCenter
        _other_get = other.GetBinContent
        _other_get_bin = super(_HistBase, other).GetBin
        other_sum_w2 = other.GetSumw2()
        _other_sum_w2_at = other_sum_w2.At

        _find = self.FindBin
        sum_w2 = self.GetSumw2()
        _sum_w2_at = sum_w2.At
        _sum_w2_setat = sum_w2.SetAt
        _set = self.SetBinContent
        _get = self.GetBinContent

        for x, y, z in view.points:
            idx = _find(
                _other_x_center(x),
                _other_y_center(y),
                _other_z_center(z))
            other_idx = _other_get_bin(x, y, z)
            _set(idx, _get(idx) + _other_get(other_idx))
            _sum_w2_setat(
                _sum_w2_at(idx) + _other_sum_w2_at(other_idx),
                idx)

    def FillRandom(self, func, ntimes=5000):
        if isinstance(func, QROOT.TF1):
            func = func.GetName()
        super(_HistBase, self).FillRandom(func, ntimes)
        return self

    def get_sum_w2(self, ix, iy=0, iz=0):
        """
        Obtain the true number of entries in the bin weighted by w^2
        """
        if self.GetSumw2N() == 0:
            raise RuntimeError(
                "Attempting to access Sumw2 in histogram "
                "where weights were not stored")
        xl = self.nbins(axis=0, overflow=True)
        yl = self.nbins(axis=1, overflow=True)
        idx = xl * yl * iz + xl * iy + ix
        if not 0 <= idx < self.GetSumw2N():
            raise IndexError("bin index out of range")
        return self.GetSumw2().At(idx)

    def set_sum_w2(self, w, ix, iy=0, iz=0):
        """
        Sets the true number of entries in the bin weighted by w^2
        """
        if self.GetSumw2N() == 0:
            raise RuntimeError(
                "Attempting to access Sumw2 in histogram "
                "where weights were not stored")
        xl = self.nbins(axis=0, overflow=True)
        yl = self.nbins(axis=1, overflow=True)
        idx = xl * yl * iz + xl * iy + ix
        if not 0 <= idx < self.GetSumw2N():
            raise IndexError("bin index out of range")
        self.GetSumw2().SetAt(w, idx)

    def merge_bins(self, bin_ranges, axis=0):
        """
        Merge bins in bin ranges

        Parameters
        ----------

        bin_ranges : list of tuples
            A list of tuples of bin indices for each bin range to be merged
            into one bin.

        axis : int (default=1)
            The integer identifying the axis to merge bins along.

        Returns
        -------

        hist : TH1
            The rebinned histogram.

        Examples
        --------

        Merge the overflow bins into the first and last real bins::

            newhist = hist.merge_bins([(0, 1), (-2, -1)])

        """
        ndim = self.GetDimension()
        if axis > ndim - 1:
            raise ValueError(
                "axis is out of range")
        axis_bins = self.nbins(axis=axis, overflow=True)

        # collect the indices along this axis to be merged
        # support negative indices via slicing
        windows = []
        for window in bin_ranges:
            if len(window) != 2:
                raise ValueError(
                    "bin range tuples must contain two elements")
            l, r = window
            if l == r:
                raise ValueError(
                    "bin indices must not be equal in a merging window")
            if l < 0 and r >= 0:
                raise ValueError(
                    "invalid bin range")
            if r == -1:
                r = axis_bins
            else:
                r += 1
            bin_idx = range(*slice(l, r).indices(axis_bins))
            if bin_idx: # skip []
                windows.append(bin_idx)

        if not windows:
            # no merging will take place so return a clone
            return self.Clone()

        # check that windows do not overlap
        if len(windows) > 1:
            full_list = reduce(operator.add, windows)
            if len(full_list) != len(set(full_list)):
                raise ValueError("bin index windows overlap")

        # construct a mapping from old to new bin index along this axis
        windows.sort()
        mapping = {}
        left_idx = {}
        offset = 0
        for window in windows:
            # put underflow in first bin
            new_idx = window[0] - offset or 1
            left_idx[window[0] or 1] = None
            for idx in window:
                mapping[idx] = new_idx
            offset += len(window) - 1
            if window[0] == 0:
                offset -= 1

        new_axis_bins = axis_bins - offset

        # construct new bin edges
        new_edges = []
        for i, edge in enumerate(self._edges(axis)):
            if (i != axis_bins - 2 and i + 1 in mapping
                and i + 1 not in left_idx):
                continue
            new_edges.append(edge)

        # construct new histogram and fill
        new_hist = self.empty_clone(binning=new_edges, axis=axis)

        this_axis = self.axis(axis)
        new_axis = new_hist.axis(axis)

        def translate(idx):
            if idx in mapping:
                return mapping[idx]
            if idx == 0:
                return 0
            # use TH1.FindBin to determine where the bins should be merged
            return new_axis.FindBin(this_axis.GetBinCenter(idx))

        for bin in self.bins(overflow=True):
            xyz = bin.xyz
            new_xyz = list(xyz)
            new_xyz[axis] = translate(int(xyz[axis]))

            x, y, z = new_xyz

            new_v = new_hist.GetBinContent(x, y, z)
            new_hist.SetBinContent(x, y, z, new_v + bin.value)

            sum_w2 = self.get_sum_w2(*xyz)
            new_sum_w2 = new_hist.get_sum_w2(x, y, z)
            new_hist.set_sum_w2(sum_w2 + new_sum_w2, x, y, z)

        # transfer stats info
        stat_array = array('d', [0.] * 10)
        self.GetStats(stat_array)
        new_hist.PutStats(stat_array)
        entries = self.GetEntries()
        new_hist.SetEntries(entries)
        return new_hist

    def rebinned(self, bins, axis=0):
        """
        Return a new rebinned histogram

        Parameters
        ----------

        bins : int, tuple, or iterable
            If ``bins`` is an int, then return a histogram that is rebinned by
            grouping N=``bins`` bins together along the axis ``axis``.
            If ``bins`` is a tuple, then it must contain the same number of
            elements as there are dimensions of this histogram and each element
            will be used to rebin along the associated axis.
            If ``bins`` is another iterable, then it will define the bin
            edges along the axis ``axis`` in the new rebinned histogram.

        axis : int, optional (default=0)
            The axis to rebin along.

        Returns
        -------

        The rebinned histogram

        """
        ndim = self.GetDimension()
        if axis >= ndim:
            raise ValueError(
                "axis must be less than the dimensionality of the histogram")

        if isinstance(bins, int):
            _bins = [1] * ndim
            try:
                _bins[axis] = bins
            except IndexError:
                raise ValueError("axis must be 0, 1, or 2")
            bins = tuple(_bins)

        if isinstance(bins, tuple):
            if len(bins) != ndim:
                raise ValueError(
                    "bins must be a tuple with the same "
                    "number of elements as histogram axes")
            newname = uuid.uuid4().hex
            if ndim == 1:
                hist = self.Rebin(bins[0], newname)
            elif ndim == 2:
                hist = self.Rebin2D(bins[0], bins[1], newname)
            else:
                hist = self.Rebin3D(bins[0], bins[1], bins[2], newname)
            hist = asrootpy(hist)
        elif hasattr(bins, '__iter__'):
            hist = self.empty_clone(bins, axis=axis)
            nbinsx = self.nbins(0)
            nbinsy = self.nbins(1)
            nbinsz = self.nbins(2)
            xaxis = self.xaxis
            yaxis = self.yaxis
            zaxis = self.zaxis
            sum_w2 = self.GetSumw2()
            _sum_w2_at = sum_w2.At
            new_sum_w2 = hist.GetSumw2()
            _new_sum_w2_at = new_sum_w2.At
            _new_sum_w2_setat = new_sum_w2.SetAt
            _x_center = xaxis.GetBinCenter
            _y_center = yaxis.GetBinCenter
            _z_center = zaxis.GetBinCenter
            _find = hist.FindBin
            _set = hist.SetBinContent
            _get = hist.GetBinContent
            _this_get = self.GetBinContent
            _get_bin = super(_HistBase, self).GetBin
            for z in xrange(1, nbinsz + 1):
                for y in xrange(1, nbinsy + 1):
                    for x in xrange(1, nbinsx + 1):
                        newbin = _find(
                            _x_center(x), _y_center(y), _z_center(z))
                        idx = _get_bin(x, y, z)
                        _set(newbin, _get(newbin) + _this_get(idx))
                        _new_sum_w2_setat(
                            _new_sum_w2_at(newbin) + _sum_w2_at(idx),
                            newbin)
            hist.SetEntries(self.GetEntries())
        else:
            raise TypeError(
                "bins must either be an integer, a tuple, or an iterable")
        return hist

    def smoothed(self, iterations=1):
        """
        Return a smoothed copy of this histogram

        Parameters
        ----------

        iterations : int, optional (default=1)
            The number of smoothing iterations

        Returns
        -------

        hist : asrootpy'd histogram
            The smoothed histogram

        """
        copy = self.Clone(shallow=True)
        copy.Smooth(iterations)
        return copy

    def empty_clone(self, binning=None, axis=0, type=None, **kwargs):
        """
        Return a new empty histogram. The binning may be modified
        along one axis by specifying the binning and axis arguments.
        If binning is False, then the corresponding axis is dropped
        from the returned histogram.
        """
        ndim = self.GetDimension()
        if binning is False and ndim == 1:
            raise ValueError(
                "cannot remove the x-axis of a 1D histogram")
        args = []
        for iaxis in xrange(ndim):
            if iaxis == axis:
                if binning is False:
                    # skip this axis
                    continue
                elif binning is not None:
                    if hasattr(binning, '__iter__'):
                        binning = (binning,)
                    args.extend(binning)
                    continue
            args.append(list(self._edges(axis=iaxis)))
        if type is None:
            type = self.TYPE
        if binning is False:
            ndim -= 1
        cls = [Hist, Hist2D, Hist3D][ndim - 1]
        return cls(*args, type=type, **kwargs)

    def quantiles(self, quantiles,
                  axis=0, strict=False,
                  recompute_integral=False):
        """
        Calculate the quantiles of this histogram.

        Parameters
        ----------

        quantiles : list or int
            A list of cumulative probabilities or an integer used to determine
            equally spaced values between 0 and 1 (inclusive).

        axis : int, optional (default=0)
            The axis to compute the quantiles along. 2D and 3D histograms are
            first projected along the desired axis before computing the
            quantiles.

        strict : bool, optional (default=False)
            If True, then return the sorted unique quantiles corresponding
            exactly to bin edges of this histogram.

        recompute_integral : bool, optional (default=False)
            If this histogram was filled with SetBinContent instead of Fill,
            then the integral must be computed before calculating the
            quantiles.

        Returns
        -------

        output : list or numpy array
            If NumPy is importable then an array of the quantiles is returned,
            otherwise a list is returned.

        """
        if axis >= self.GetDimension():
            raise ValueError(
                "axis must be less than the dimensionality of the histogram")
        if recompute_integral:
            self.ComputeIntegral()
        if isinstance(self, _Hist2D):
            newname = uuid.uuid4().hex
            if axis == 0:
                proj = self.ProjectionX(newname, 1, self.nbins(1))
            elif axis == 1:
                proj = self.ProjectionY(newname, 1, self.nbins(0))
            else:
                raise ValueError("axis must be 0 or 1")
            return asrootpy(proj).quantiles(
                quantiles, strict=strict, recompute_integral=False)
        elif isinstance(self, _Hist3D):
            newname = uuid.uuid4().hex
            if axis == 0:
                proj = self.ProjectionX(
                    newname, 1, self.nbins(1), 1, self.nbins(2))
            elif axis == 1:
                proj = self.ProjectionY(
                    newname, 1, self.nbins(0), 1, self.nbins(2))
            elif axis == 2:
                proj = self.ProjectionZ(
                    newname, 1, self.nbins(0), 1, self.nbins(1))
            else:
                raise ValueError("axis must be 0, 1, or 2")
            return asrootpy(proj).quantiles(
                quantiles, strict=strict, recompute_integral=False)
        try:
            import numpy as np
        except ImportError:
            # use python implementation
            use_numpy = False
        else:
            use_numpy = True
        if isinstance(quantiles, int):
            num_quantiles = quantiles
            if use_numpy:
                qs = np.linspace(0, 1, num_quantiles)
                output = np.empty(num_quantiles, dtype=float)
            else:
                def linspace(start, stop, n):
                    if n == 1:
                        yield start
                        return
                    h = float(stop - start) / (n - 1)
                    for i in range(n):
                        yield start + h * i
                quantiles = list(linspace(0, 1, num_quantiles))
                qs = array('d', quantiles)
                output = array('d', [0.] * num_quantiles)
        else:
            num_quantiles = len(quantiles)
            if use_numpy:
                qs = np.array(quantiles, dtype=float)
                output = np.empty(num_quantiles, dtype=float)
            else:
                qs = array('d', quantiles)
                output = array('d', [0.] * num_quantiles)
        if strict:
            integral = self.GetIntegral()
            nbins = self.nbins(0)
            if use_numpy:
                edges = np.empty(nbins + 1, dtype=float)
                self.GetLowEdge(edges)
                edges[-1] = edges[-2] + self.GetBinWidth(nbins)
                integral = np.ndarray((nbins + 1,), dtype=float, buffer=integral)
                idx = np.searchsorted(integral, qs, side='left')
                output = np.unique(np.take(edges, idx))
            else:
                quantiles = list(set(qs))
                quantiles.sort()
                output = []
                ibin = 0
                for quant in quantiles:
                    # find first bin greater than or equal to quant
                    while integral[ibin] < quant and ibin < nbins + 1:
                        ibin += 1
                    edge = self.GetBinLowEdge(ibin + 1)
                    output.append(edge)
                    if ibin >= nbins + 1:
                        break
                output = list(set(output))
                output.sort()
            return output
        self.GetQuantiles(num_quantiles, output, qs)
        if use_numpy:
            return output
        return list(output)

    def max(self, include_error=False):
        if not include_error:
            return self.GetBinContent(self.GetMaximumBin())
        clone = self.Clone(shallow=True)
        for i in xrange(self.GetSize()):
            clone.SetBinContent(
                i, clone.GetBinContent(i) + clone.GetBinError(i))
        return clone.GetBinContent(clone.GetMaximumBin())

    def min(self, include_error=False):
        if not include_error:
            return self.GetBinContent(self.GetMinimumBin())
        clone = self.Clone(shallow=True)
        for i in xrange(self.GetSize()):
            clone.SetBinContent(
                i, clone.GetBinContent(i) - clone.GetBinError(i))
        return clone.GetBinContent(clone.GetMinimumBin())


class _Hist(_HistBase):

    DIM = 1

    def x(self, index=None, overflow=False):
        return self._centers(0, index, overflow=overflow)

    def xerravg(self, index=None, overflow=False):
        return self._erravg(0, index, overflow=overflow)

    def xerrl(self, index=None, overflow=False):
        return self._erravg(0, index, overflow=overflow)

    def xerrh(self, index=None, overflow=False):
        return self._erravg(0, index, overflow=overflow)

    def xerr(self, index=None, overflow=False):
        return self._err(0, index, overflow=overflow)

    def xwidth(self, index=None, overflow=False):
        return self._width(0, index, overflow=overflow)

    def xedgesl(self, index=None, overflow=False):
        return self._edgesl(0, index, overflow=overflow)

    def xedgesh(self, index=None, overflow=False):
        return self._edgesh(0, index, overflow=overflow)

    def xedges(self, index=None, overflow=False):
        return self._edges(0, index, overflow=overflow)

    def yerrh(self, index=None, overflow=False):
        return self.yerravg(index, overflow=overflow)

    def yerrl(self, index=None, overflow=False):
        return self.yerravg(index, overflow=overflow)

    def y(self, index=None, overflow=False):
        if index is None:
            return (self.GetBinContent(i)
                    for i in self.bins_range(axis=0, overflow=overflow))
        index = index % self.nbins(axis=0, overflow=True)
        return self.GetBinContent(index)

    def yerravg(self, index=None, overflow=False):
        if index is None:
            return (self.GetBinError(i)
                    for i in self.bins_range(axis=0, overflow=overflow))
        index = index % self.nbins(axis=0, overflow=True)
        return self.GetBinError(index)

    def yerr(self, index=None, overflow=False):
        if index is None:
            return ((self.yerrl(i), self.yerrh(i))
                    for i in self.bins_range(axis=0, overflow=overflow))
        index = index % self.nbins(axis=0, overflow=True)
        return (self.yerrl(index), self.yerrh(index))

    def expectation(self, startbin=1, endbin=None):
        if endbin is not None and endbin < startbin:
            raise ValueError("``endbin`` should be greated than ``startbin``")
        if endbin is None:
            endbin = self.nbins(0)
        expect = 0.
        norm = 0.
        for index in xrange(startbin, endbin + 1):
            val = self[index]
            expect += val * self.x(index)
            norm += val
        if norm > 0:
            return expect / norm
        else:
            return (self.xedges(endbin + 1) + self.xedges(startbin)) / 2

    def integral(self, xbin1=None, xbin2=None,
                 width=False, error=False, overflow=False):
        """
        Compute the integral and error over a range of bins
        """
        if xbin1 is None:
            xbin1 = 0 if overflow else 1
        if xbin2 is None:
            xbin2 = -1 if overflow else -2
        nbinsx = self.nbins(axis=0, overflow=True)
        xbin1 %= nbinsx
        xbin2 %= nbinsx
        options = 'width' if width else ''
        if error:
            error = ROOT.Double()
            integral = super(_Hist, self).IntegralAndError(
                xbin1, xbin2, error, options)
            return integral, error
        return super(_Hist, self).Integral(xbin1, xbin2, options)

    def poisson_errors(self):
        """
        Return a TGraphAsymmErrors representation of this histogram where the
        point y errors are Poisson.
        """
        graph = Graph(self.nbins(axis=0), type='asymm')
        graph.SetLineWidth(self.GetLineWidth())
        graph.SetMarkerSize(self.GetMarkerSize())
        chisqr = ROOT.TMath.ChisquareQuantile
        npoints = 0
        for bin in self.bins(overflow=False):
            entries = bin.effective_entries
            if entries <= 0:
                continue
            ey_low = entries - 0.5 * chisqr(0.1586555, 2. * entries)
            ey_high = 0.5 * chisqr(
                1. - 0.1586555, 2. * (entries + 1)) - entries
            ex = bin.x.width / 2.
            graph.SetPoint(npoints, bin.x.center, bin.value)
            graph.SetPointEXlow(npoints, ex)
            graph.SetPointEXhigh(npoints, ex)
            graph.SetPointEYlow(npoints, ey_low)
            graph.SetPointEYhigh(npoints, ey_high)
            npoints += 1
        graph.Set(npoints)
        return graph


class _Hist2D(_HistBase):

    DIM = 2

    def x(self, index=None, overflow=False):
        return self._centers(0, index, overflow=overflow)

    def xerravg(self, index=None, overflow=False):
        return self._erravg(0, index, overflow=overflow)

    def xerrl(self, index=None, overflow=False):
        return self._erravg(0, index, overflow=overflow)

    def xerrh(self, index=None, overflow=False):
        return self._erravg(0, index, overflow=overflow)

    def xerr(self, index=None, overflow=False):
        return self._err(0, index, overflow=overflow)

    def xwidth(self, index=None, overflow=False):
        return self._width(0, index, overflow=overflow)

    def xedgesl(self, index=None, overflow=False):
        return self._edgesl(0, index, overflow=overflow)

    def xedgesh(self, index=None, overflow=False):
        return self._edgesh(0, index, overflow=overflow)

    def xedges(self, index=None, overflow=False):
        return self._edges(0, index, overflow=overflow)

    def y(self, index=None, overflow=False):
        return self._centers(1, index, overflow=overflow)

    def yerravg(self, index=None, overflow=False):
        return self._erravg(1, index, overflow=overflow)

    def yerrl(self, index=None, overflow=False):
        return self._erravg(1, index, overflow=overflow)

    def yerrh(self, index=None, overflow=False):
        return self._erravg(1, index, overflow=overflow)

    def yerr(self, index=None, overflow=False):
        return self._err(1, index, overflow=overflow)

    def ywidth(self, index=None, overflow=False):
        return self._width(1, index, overflow=overflow)

    def yedgesl(self, index=None, overflow=False):
        return self._edgesl(1, index, overflow=overflow)

    def yedgesh(self, index=None, overflow=False):
        return self._edgesh(1, index, overflow=overflow)

    def yedges(self, index=None, overflow=False):
        return self._edges(1, index, overflow=overflow)

    def zerrh(self, index=None, overflow=False):
        return self.zerravg(index, overflow=overflow)

    def zerrl(self, index=None, overflow=False):
        return self.zerravg(index, overflow=overflow)

    def z(self, ix=None, iy=None, overflow=False):
        if ix is None and iy is None:
            return [[self.GetBinContent(ix, iy)
                    for iy in self.bins_range(axis=1, overflow=overflow)]
                    for ix in self.bins_range(axis=0, overflow=overflow)]
        ix = ix % self.nbins(axis=0, overflow=True)
        iy = iy % self.nbins(axis=1, overflow=True)
        return self.GetBinContent(ix, iy)

    def zerravg(self, ix=None, iy=None, overflow=False):
        if ix is None and iy is None:
            return [[self.GetBinError(ix, iy)
                    for iy in self.bins_range(axis=1, overflow=overflow)]
                    for ix in self.bins_range(axis=0, overflow=overflow)]
        ix = ix % self.nbins(axis=0, overflow=True)
        iy = iy % self.nbins(axis=1, overflow=True)
        return self.GetBinError(ix, iy)

    def zerr(self, ix=None, iy=None, overflow=False):
        if ix is None and iy is None:
            return [[(self.GetBinError(ix, iy), self.GetBinError(ix, iy))
                    for iy in self.bins_range(axis=1, overflow=overflow)]
                    for ix in self.bins_range(axis=0, overflow=overflow)]
        ix = ix % self.nbins(axis=0, overflow=True)
        iy = iy % self.nbins(axis=1, overflow=True)
        return (self.GetBinError(ix, iy),
                self.GetBinError(ix, iy))

    def ravel(self, name=None):
        """
        Convert 2D histogram into 1D histogram with the y-axis repeated along
        the x-axis, similar to NumPy's ravel().
        """
        nbinsx = self.nbins(0)
        nbinsy = self.nbins(1)
        left_edge = self.xedgesl(1)
        right_edge = self.xedgesh(nbinsx)
        out = Hist(nbinsx * nbinsy,
                   left_edge, nbinsy * (right_edge - left_edge) + left_edge,
                   type=self.TYPE,
                   name=name,
                   title=self.title,
                   **self.decorators)
        for i, bin in enumerate(self.bins(overflow=False)):
            out.SetBinContent(i + 1, bin.value)
            out.SetBinError(i + 1, bin.error)
        return out

    def integral(self,
                 xbin1=None, xbin2=None,
                 ybin1=None, ybin2=None,
                 width=False,
                 error=False,
                 overflow=False):
        """
        Compute the integral and error over a range of bins
        """
        if xbin1 is None:
            xbin1 = 0 if overflow else 1
        if xbin2 is None:
            xbin2 = -1 if overflow else -2
        if ybin1 is None:
            ybin1 = 0 if overflow else 1
        if ybin2 is None:
            ybin2 = -1 if overflow else -2
        nbinsx = self.nbins(axis=0, overflow=True)
        xbin1 %= nbinsx
        xbin2 %= nbinsx
        nbinsy = self.nbins(axis=1, overflow=True)
        ybin1 %= nbinsy
        ybin2 %= nbinsy
        options = 'width' if width else ''
        if error:
            error = ROOT.Double()
            integral = super(_Hist2D, self).IntegralAndError(
                xbin1, xbin2, ybin1, ybin2, error, options)
            return integral, error
        return super(_Hist2D, self).Integral(
            xbin1, xbin2, ybin1, ybin2, options)


class _Hist3D(_HistBase):

    DIM = 3

    def x(self, index=None, overflow=False):
        return self._centers(0, index, overflow=overflow)

    def xerravg(self, index=None, overflow=False):
        return self._erravg(0, index, overflow=overflow)

    def xerrl(self, index=None, overflow=False):
        return self._erravg(0, index, overflow=overflow)

    def xerrh(self, index=None, overflow=False):
        return self._erravg(0, index, overflow=overflow)

    def xerr(self, index=None, overflow=False):
        return self._err(0, index, overflow=overflow)

    def xwidth(self, index=None, overflow=False):
        return self._width(0, index, overflow=overflow)

    def xedgesl(self, index=None, overflow=False):
        return self._edgesl(0, index, overflow=overflow)

    def xedgesh(self, index=None, overflow=False):
        return self._edgesh(0, index, overflow=overflow)

    def xedges(self, index=None, overflow=False):
        return self._edges(0, index, overflow=overflow)

    def y(self, index=None, overflow=False):
        return self._centers(1, index, overflow=overflow)

    def yerravg(self, index=None, overflow=False):
        return self._erravg(1, index, overflow=overflow)

    def yerrl(self, index=None, overflow=False):
        return self._erravg(1, index, overflow=overflow)

    def yerrh(self, index=None, overflow=False):
        return self._erravg(1, index, overflow=overflow)

    def yerr(self, index=None, overflow=False):
        return self._err(1, index, overflow=overflow)

    def ywidth(self, index=None, overflow=False):
        return self._width(1, index, overflow=overflow)

    def yedgesl(self, index=None, overflow=False):
        return self._edgesl(1, index, overflow=overflow)

    def yedgesh(self, index=None, overflow=False):
        return self._edgesh(1, index, overflow=overflow)

    def yedges(self, index=None, overflow=False):
        return self._edges(1, index, overflow=overflow)

    def z(self, index=None, overflow=False):
        return self._centers(2, index, overflow=overflow)

    def zerravg(self, index=None, overflow=False):
        return self._erravg(2, index, overflow=overflow)

    def zerrl(self, index=None, overflow=False):
        return self._erravg(2, index, overflow=overflow)

    def zerrh(self, index=None, overflow=False):
        return self._erravg(2, index, overflow=overflow)

    def zerr(self, index=None, overflow=False):
        return self._err(2, index, overflow=overflow)

    def zwidth(self, index=None, overflow=False):
        return self._width(2, index, overflow=overflow)

    def zedgesl(self, index=None, overflow=False):
        return self._edgesl(2, index, overflow=overflow)

    def zedgesh(self, index=None, overflow=False):
        return self._edgesh(2, index, overflow=overflow)

    def zedges(self, index=None, overflow=False):
        return self._edges(2, index, overflow=overflow)

    def werrh(self, index=None, overflow=False):
        return self.werravg(index, overflow=overflow)

    def werrl(self, index=None, overflow=False):
        return self.werravg(index, overflow=overflow)

    def w(self, ix=None, iy=None, iz=None, overflow=False):
        if ix is None and iy is None and iz is None:
            return [[[self.GetBinContent(ix, iy, iz)
                    for iz in self.bins_range(axis=2, overflow=overflow)]
                    for iy in self.bins_range(axis=1, overflow=overflow)]
                    for ix in self.bins_range(axis=0, overflow=overflow)]
        ix = ix % self.nbins(axis=0, overflow=True)
        iy = iy % self.nbins(axis=1, overflow=True)
        iz = iz % self.nbins(axis=2, overflow=True)
        return self.GetBinContent(ix, iy, iz)

    def werravg(self, ix=None, iy=None, iz=None, overflow=False):
        if ix is None and iy is None and iz is None:
            return [[[self.GetBinError(ix, iy, iz)
                    for iz in self.bins_range(axis=2, overflow=overflow)]
                    for iy in self.bins_range(axis=1, overflow=overflow)]
                    for ix in self.bins_range(axis=0, overflow=overflow)]
        ix = ix % self.nbins(axis=0, overflow=True)
        iy = iy % self.nbins(axis=1, overflow=True)
        iz = iz % self.nbins(axis=2, overflow=True)
        return self.GetBinError(ix, iy, iz)

    def werr(self, ix=None, iy=None, iz=None, overflow=False):
        if ix is None and iy is None and iz is None:
            return [[[
                (self.GetBinError(ix, iy, iz), self.GetBinError(ix, iy, iz))
                for iz in self.bins_range(axis=2, overflow=overflow)]
                for iy in self.bins_range(axis=1, overflow=overflow)]
                for ix in self.bins_range(axis=0, overflow=overflow)]
        ix = ix % self.nbins(axis=0, overflow=True)
        iy = iy % self.nbins(axis=1, overflow=True)
        iz = iz % self.nbins(axis=2, overflow=True)
        return (self.GetBinError(ix, iy, iz),
                self.GetBinError(ix, iy, iz))

    def integral(self,
                 xbin1=1, xbin2=-2,
                 ybin1=1, ybin2=-2,
                 zbin1=1, zbin2=-2,
                 width=False,
                 error=False,
                 overflow=False):
        """
        Compute the integral and error over a range of bins
        """
        if xbin1 is None:
            xbin1 = 0 if overflow else 1
        if xbin2 is None:
            xbin2 = -1 if overflow else -2
        if ybin1 is None:
            ybin1 = 0 if overflow else 1
        if ybin2 is None:
            ybin2 = -1 if overflow else -2
        if zbin1 is None:
            zbin1 = 0 if overflow else 1
        if zbin2 is None:
            zbin2 = -1 if overflow else -2
        nbinsx = self.nbins(axis=0, overflow=True)
        xbin1 %= nbinsx
        xbin2 %= nbinsx
        nbinsy = self.nbins(axis=1, overflow=True)
        ybin1 %= nbinsy
        ybin2 %= nbinsy
        nbinsz = self.nbins(axis=2, overflow=True)
        zbin1 %= nbinsz
        zbin2 %= nbinsz
        options = 'width' if width else ''
        if error:
            error = ROOT.Double()
            integral = super(_Hist3D, self).IntegralAndError(
                xbin1, xbin2, ybin1, ybin2, zbin1, zbin2, error, options)
            return integral, error
        return super(_Hist3D, self).Integral(
            xbin1, xbin2, ybin1, ybin2, zbin1, zbin2, options)


def _Hist_class(type='F'):
    type = type.upper()
    if type not in _HistBase.TYPES:
        raise TypeError(
            "No histogram available with bin type {0}".format(type))
    rootclass = _HistBase.TYPES[type][0]

    class Hist(_Hist, rootclass):
        _ROOT = rootclass
        TYPE = type

        def __init__(self, *args, **kwargs):
            params = self._parse_args(args)
            name = kwargs.pop('name', None)
            title = kwargs.pop('title', None)
            if params[0]['bins'] is None:
                super(Hist, self).__init__(
                    params[0]['nbins'], params[0]['low'], params[0]['high'],
                    name=name, title=title)
            else:
                super(Hist, self).__init__(
                    params[0]['nbins'], array('d', params[0]['bins']),
                    name=name, title=title)
            self._post_init(**kwargs)

    return Hist


def _Hist2D_class(type='F'):
    type = type.upper()
    if type not in _HistBase.TYPES:
        raise TypeError(
            "No histogram available with bin type {0}".format(type))
    rootclass = _HistBase.TYPES[type][1]

    class Hist2D(_Hist2D, rootclass):
        _ROOT = rootclass
        TYPE = type

        def __init__(self, *args, **kwargs):
            params = self._parse_args(args)
            name = kwargs.pop('name', None)
            title = kwargs.pop('title', None)
            if params[0]['bins'] is None and params[1]['bins'] is None:
                super(Hist2D, self).__init__(
                    params[0]['nbins'], params[0]['low'], params[0]['high'],
                    params[1]['nbins'], params[1]['low'], params[1]['high'],
                    name=name, title=title)
            elif params[0]['bins'] is None and params[1]['bins'] is not None:
                super(Hist2D, self).__init__(
                    params[0]['nbins'], params[0]['low'], params[0]['high'],
                    params[1]['nbins'], array('d', params[1]['bins']),
                    name=name, title=title)
            elif params[0]['bins'] is not None and params[1]['bins'] is None:
                super(Hist2D, self).__init__(
                    params[0]['nbins'], array('d', params[0]['bins']),
                    params[1]['nbins'], params[1]['low'], params[1]['high'],
                    name=name, title=title)
            else:
                super(Hist2D, self).__init__(
                    params[0]['nbins'], array('d', params[0]['bins']),
                    params[1]['nbins'], array('d', params[1]['bins']),
                    name=name, title=title)
            self._post_init(**kwargs)

    return Hist2D


def _Hist3D_class(type='F'):
    type = type.upper()
    if type not in _HistBase.TYPES:
        raise TypeError(
            "No histogram available with bin type {0}".format(type))
    rootclass = _HistBase.TYPES[type][2]

    class Hist3D(_Hist3D, rootclass):
        _ROOT = rootclass
        TYPE = type

        def __init__(self, *args, **kwargs):
            params = self._parse_args(args)
            name = kwargs.pop('name', None)
            title = kwargs.pop('title', None)
            # ROOT is missing constructors for TH3...
            if (params[0]['bins'] is None and
                    params[1]['bins'] is None and
                    params[2]['bins'] is None):
                super(Hist3D, self).__init__(
                    params[0]['nbins'], params[0]['low'], params[0]['high'],
                    params[1]['nbins'], params[1]['low'], params[1]['high'],
                    params[2]['nbins'], params[2]['low'], params[2]['high'],
                    name=name, title=title)
            else:
                if params[0]['bins'] is None:
                    step = ((params[0]['high'] - params[0]['low'])
                            / float(params[0]['nbins']))
                    params[0]['bins'] = [
                        params[0]['low'] + n * step
                        for n in xrange(params[0]['nbins'] + 1)]
                if params[1]['bins'] is None:
                    step = ((params[1]['high'] - params[1]['low'])
                            / float(params[1]['nbins']))
                    params[1]['bins'] = [
                        params[1]['low'] + n * step
                        for n in xrange(params[1]['nbins'] + 1)]
                if params[2]['bins'] is None:
                    step = ((params[2]['high'] - params[2]['low'])
                            / float(params[2]['nbins']))
                    params[2]['bins'] = [
                        params[2]['low'] + n * step
                        for n in xrange(params[2]['nbins'] + 1)]
                super(Hist3D, self).__init__(
                    params[0]['nbins'], array('d', params[0]['bins']),
                    params[1]['nbins'], array('d', params[1]['bins']),
                    params[2]['nbins'], array('d', params[2]['bins']),
                    name=name, title=title)
            self._post_init(**kwargs)

    return Hist3D


_HIST_CLASSES_1D = {}
_HIST_CLASSES_2D = {}
_HIST_CLASSES_3D = {}

for bintype in _HistBase.TYPES.keys():
    cls = _Hist_class(type=bintype)
    snake_case_methods(cls)
    _HIST_CLASSES_1D[bintype] = cls

    cls = _Hist2D_class(type=bintype)
    snake_case_methods(cls)
    _HIST_CLASSES_2D[bintype] = cls

    cls = _Hist3D_class(type=bintype)
    snake_case_methods(cls)
    _HIST_CLASSES_3D[bintype] = cls


class Hist(_Hist, QROOT.TH1):
    """
    Returns a 1-dimensional Hist object which inherits from the associated
    ROOT.TH1* class (where * is C, S, I, F, or D depending on the type
    keyword argument)
    """
    _ROOT = QROOT.TH1

    @classmethod
    def dynamic_cls(cls, type='F'):
        return _HIST_CLASSES_1D[type]

    def __new__(cls, *args, **kwargs):
        if len(args) == 1:
            other = args[0]
            kwargs.setdefault('type', 'F')
            if isinstance(other, HistView):
                obj = Hist(other.xedges, **kwargs)
                obj.fill_view(other.hist[:])
                obj.entries = other.hist.entries
                return obj
            elif isinstance(other, _Hist):
                obj = other.empty_clone(**kwargs)
                obj[:] = other[:]
                obj.entries = other.entries
                return obj
        type = kwargs.pop('type', 'F').upper()
        return cls.dynamic_cls(type)(*args, **kwargs)


# alias Hist1D -> Hist
Hist1D = Hist


class Hist2D(_Hist2D, QROOT.TH2):
    """
    Returns a 2-dimensional Hist object which inherits from the associated
    ROOT.TH1* class (where * is C, S, I, F, or D depending on the type
    keyword argument)
    """
    _ROOT = QROOT.TH2

    @classmethod
    def dynamic_cls(cls, type='F'):
        return _HIST_CLASSES_2D[type]

    def __new__(cls, *args, **kwargs):
        if len(args) == 1:
            other = args[0]
            kwargs.setdefault('type', 'F')
            if isinstance(other, Hist2DView):
                obj = Hist2D(other.xedges, other.yedges, **kwargs)
                obj.fill_view(other.hist[:,:])
                obj.entries = other.hist.entries
                return obj
            elif isinstance(other, _Hist2D):
                obj = other.empty_clone(**kwargs)
                obj[:] = other[:]
                obj.entries = other.entries
                return obj
        type = kwargs.pop('type', 'F').upper()
        return cls.dynamic_cls(type)(*args, **kwargs)


class Hist3D(_Hist3D, QROOT.TH3):
    """
    Returns a 3-dimensional Hist object which inherits from the associated
    ROOT.TH1* class (where * is C, S, I, F, or D depending on the type
    keyword argument)
    """
    _ROOT = QROOT.TH3

    @classmethod
    def dynamic_cls(cls, type='F'):
        return _HIST_CLASSES_3D[type]

    def __new__(cls, *args, **kwargs):
        if len(args) == 1:
            other = args[0]
            kwargs.setdefault('type', 'F')
            if isinstance(other, Hist3DView):
                obj = Hist3D(other.xedges, other.yedges, other.zedges, **kwargs)
                obj.fill_view(other.hist[:,:,:])
                obj.entries = other.hist.entries
                return obj
            elif isinstance(other, _Hist3D):
                obj = other.empty_clone(**kwargs)
                obj[:] = other[:]
                obj.entries = other.entries
                return obj
        type = kwargs.pop('type', 'F').upper()
        return cls.dynamic_cls(type)(
            *args, **kwargs)


class HistStack(Plottable, NamedObject, QROOT.THStack):

    _ROOT = QROOT.THStack

    def __init__(self, hists=None, name=None, title=None, **kwargs):
        super(HistStack, self).__init__(name=name, title=title)
        self._post_init(hists=hists, **kwargs)

    def _post_init(self, hists=None, **kwargs):
        super(HistStack, self)._post_init(**kwargs)
        self.hists = []
        self.dim = 1
        current_hists = super(HistStack, self).GetHists()
        if current_hists:
            for i, hist in enumerate(current_hists):
                hist = asrootpy(hist)
                if i == 0:
                    self.dim = dim(hist)
                elif dim(hist) != self.dim:
                    raise TypeError(
                        "Dimensions of the contained histograms are not equal")
                self.hists.append(hist)
        self.sum = sum(self.hists) if self.hists else None
        if hists:
            for h in hists:
                self.Add(h)

    def __dim__(self):
        return self.dim

    def GetHists(self):
        return [hist for hist in self.hists]

    def Add(self, hist):
        if isinstance(hist, _Hist) or isinstance(hist, _Hist2D):
            if not self:
                self.dim = dim(hist)
                self.sum = hist.Clone()
            elif dim(self) != dim(hist):
                raise TypeError(
                    "Dimension of histogram does not match dimension "
                    "of already contained histograms")
            else:
                self.sum += hist
            self.hists.append(hist)
            super(HistStack, self).Add(hist, hist.drawstyle)
        else:
            raise TypeError(
                "Only 1D and 2D histograms are supported")

    def __add__(self, other):
        if not isinstance(other, HistStack):
            raise TypeError(
                "Addition not supported for HistStack and {0}".format(
                    other.__class__.__name__))
        clone = HistStack()
        for hist in self:
            clone.Add(hist)
        for hist in other:
            clone.Add(hist)
        return clone

    def __iadd__(self, other):
        if not isinstance(other, HistStack):
            raise TypeError(
                "Addition not supported for HistStack and {0}".format(
                    other.__class__.__name__))
        for hist in other:
            self.Add(hist)
        return self

    def __len__(self):
        return len(self.GetHists())

    def __getitem__(self, index):
        return self.GetHists()[index]

    def __iter__(self):
        for hist in self.hists:
            yield hist

    def __nonzero__(self):
        return len(self) != 0

    def __cmp__(self, other):
        diff = self.max() - other.max()
        if diff > 0:
            return 1
        if diff < 0:
            return -1
        return 0

    def Scale(self, value):
        for hist in self:
            hist.Scale(value)

    def Integral(self, start=None, end=None):
        integral = 0
        if start is not None and end is not None:
            for hist in self:
                integral += hist.Integral(start, end)
        else:
            for hist in self:
                integral += hist.Integral()
        return integral

    def lowerbound(self, axis=0):
        if not self:
            return None  # negative infinity
        return min(hist.lowerbound(axis=axis) for hist in self)

    def upperbound(self, axis=0):
        if not self:
            return ()  # positive infinity
        return max(hist.upperbound(axis=axis) for hist in self)

    def max(self, include_error=False):
        if not self:
            return 0
        return self.sum.max(include_error=include_error)

    def min(self, include_error=False):
        if not self:
            return 0
        return self.sum.min(include_error=include_error)

    def Clone(self, newName=None):
        clone = HistStack(name=newName,
                          title=self.GetTitle(),
                          **self.decorators)
        for hist in self:
            clone.Add(hist.Clone())
        return clone


@snake_case_methods
class Efficiency(Plottable, NamedObject, QROOT.TEfficiency):
    _ROOT = QROOT.TEfficiency

    def __init__(self, passed, total, name=None, title=None, **kwargs):
        if passed.GetDimension() != 1 or total.GetDimension() != 1:
            raise TypeError(
                "histograms must be 1 dimensional")
        if len(passed) != len(total):
            raise ValueError(
                "histograms must have the same number of bins")
        if list(passed.xedges()) != list(total.xedges()):
            raise ValueError(
                "histograms do not have the same bin boundaries")
        super(Efficiency, self).__init__(
            len(total), total.xedgesl(1), total.xedgesh(total.nbins(0)),
            name=name, title=title)
        self.passed = passed.Clone()
        self.total = total.Clone()
        self.SetPassedHistogram(self.passed, 'f')
        self.SetTotalHistogram(self.total, 'f')
        self._post_init(**kwargs)

    def __len__(self):
        return len(self.total)

    def __getitem__(self, idx):
        return self.GetEfficiency(idx)

    def __add__(self, other):
        copy = self.Clone()
        copy.Add(other)
        return copy

    def __iadd__(self, other):
        super(Efficiency, self).Add(self, other)
        return self

    def __iter__(self):
        for idx in xrange(len(self) + 2):
            yield self.GetEfficiency(idx)

    def efficiencies(self, overflow=False):
        if overflow:
            start = 0
            end = len(self) + 2
        else:
            start = 1
            end = len(self) + 1
        for idx in xrange(start, end):
            yield self.GetEfficiency(idx)

    def errors(self, overflow=False):
        if overflow:
            start = 0
            end = len(self) + 2
        else:
            start = 1
            end = len(self) + 1
        for idx in xrange(start, end):
            yield (
                self.GetEfficiencyErrorLow(idx),
                self.GetEfficiencyErrorUp(idx))

    def GetGraph(self, overflow=False):
        if overflow:
            start = 0
            end = len(self) + 2
        else:
            start = 1
            end = len(self) + 1
        graph = Graph(end - start)
        for index, (idx, effic, (low, up)) in enumerate(
                izip(xrange(start, end),
                     self.efficiencies(overflow=overflow),
                     self.errors(overflow=overflow))):
            graph.SetPoint(index, self.total.x(index), effic)
            xerror = self.total.xwidth(index) / 2.
            graph.SetPointError(index, xerror, xerror, low, up)
        return graph

    @property
    def painted_graph(self):
        """
        Returns the painted graph for a TEfficiency, or if it isn't
        available, generates one on an `invisible_canvas`.
        """
        if not self.GetPaintedGraph():
            with invisible_canvas():
                self.Draw()
        assert self.GetPaintedGraph(), (
            "Failed to create TEfficiency::GetPaintedGraph")
        the_graph = asrootpy(self.GetPaintedGraph())
        # Ensure it has the same style as this one.
        the_graph.decorate(**self.decorators)
        return the_graph


def histogram(data, *args, **kwargs):
    """
    Create and fill a one-dimensional histogram.

    The same arguments as the ``Hist`` class are expected.
    If the number of bins and the ranges are not specified they are
    automatically deduced with the ``autobinning`` function using the method
    specified by the ``binning`` argument. Only one-dimensional histogramming
    is supported.
    """
    from .autobinning import autobinning
    dim = kwargs.pop('dim', 1)
    if dim != 1:
        raise NotImplementedError
    if 'binning' in kwargs:
        args = autobinning(data, kwargs['binning'])
        del kwargs['binning']
    histo = Hist(*args, **kwargs)
    for d in data:
        histo.Fill(d)
    return list(histo.xedgesl()), histo

########NEW FILE########
__FILENAME__ = legend
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from .. import QROOT, asrootpy
from ..base import Object
from .hist import HistStack
from .box import _Positionable
from ..memory.keepalive import keepalive

__all__ = [
    'Legend',
]


class Legend(_Positionable, Object, QROOT.TLegend):
    _ROOT = QROOT.TLegend

    def __init__(self, entries,
                 pad=None,
                 leftmargin=0.5,
                 topmargin=0.05,
                 rightmargin=0.05,
                 entryheight=0.06,
                 entrysep=0.02,
                 margin=0.3,
                 textfont=None,
                 textsize=None,
                 header=None):
        if pad is None:
            pad = ROOT.gPad.func()
        if not pad:
            raise RuntimeError("create a pad before a legend")

        entries_is_list = False
        if isinstance(entries, (int, long)):
            # entries is the expected number of entries that will be included
            # in the legend
            nentries = entries
        else:
            # entries is a list of objects to become entries in the legend
            entries_is_list = True
            nentries = len(entries)

        if header is not None:
            nentries += 1
        height = (entryheight + entrysep) * nentries - entrysep

        super(Legend, self).__init__(
            pad.GetLeftMargin() + leftmargin,
            (1. - pad.GetTopMargin() - topmargin) - height,
            1. - pad.GetRightMargin() - rightmargin,
            ((1. - pad.GetTopMargin()) - topmargin))

        self.SetEntrySeparation(entrysep)
        self.SetMargin(margin)
        if header is not None:
            self.SetHeader(header)

        # ROOT, why are you filling my legend with a
        # grey background by default?
        self.SetFillStyle(0)
        self.SetFillColor(0)

        if textfont is None:
            textfont = ROOT.gStyle.GetLegendFont()
        if textsize is None:
            textsize = ROOT.gStyle.GetTextSize()

        self.SetTextFont(textfont)
        self.SetTextSize(textsize)

        if entries_is_list:
            for thing in entries:
                self.AddEntry(thing)

    def Height(self):
        return abs(self.GetY2() - self.GetY1())

    def Width(self):
        return abs(self.GetX2() - self.GetX1())

    def Draw(self, *args, **kwargs):
        self.UseCurrentStyle()
        super(Legend, self).Draw(*args, **kwargs)

    def AddEntry(self, thing, label=None, style=None):
        """
        Add an entry to the legend.

        If `label` is None, `thing.GetTitle()` will be used as the label.

        If `style` is None, `thing.legendstyle` is used if present,
        otherwise `P`.
        """
        if isinstance(thing, HistStack):
            things = thing
        else:
            things = [thing]
        for thing in things:
            if getattr(thing, 'inlegend', True):
                if label is None:
                    label = thing.GetTitle()
                if style is None:
                    style = getattr(thing, 'legendstyle', 'P')
                super(Legend, self).AddEntry(thing, label, style)
                keepalive(self, thing)

    @property
    def primitives(self):
        return asrootpy(self.GetListOfPrimitives())

########NEW FILE########
__FILENAME__ = profile
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from array import array

from .. import QROOT, log; log = log[__name__]
from .hist import _Hist, _Hist2D, _Hist3D

__all__ = [
    'Profile',
    'Profile1D',
    'Profile2D',
    'Profile3D',
]


class _ProfileBase(object):
    pass


class Profile(_ProfileBase, _Hist, QROOT.TProfile):
    _ROOT = QROOT.TProfile

    def __init__(self, *args, **kwargs):
        option = kwargs.pop('option', '')
        name = kwargs.pop('name', None)
        title = kwargs.pop('title', None)
        params, args = self._parse_args(args, ignore_extras=True)
        if args:
            if len(args) != 2:
                raise TypeError("Did not receive expected number of arguments")
            low, high = args
            if low >= high:
                raise ValueError(
                    "Upper bound (you gave {0:f}) must be greater than lower "
                    "bound (you gave {1:f})".format(float(low), float(high)))
        args = list(args)
        args.append(option)
        if params[0]['bins'] is None:
            super(Profile, self).__init__(
                params[0]['nbins'], params[0]['low'], params[0]['high'],
                *args, name=name, title=title)
        else:
            super(Profile, self).__init__(
                params[0]['nbins'], array('d', params[0]['bins']),
                *args, name=name, title=title)
        self._post_init(**kwargs)


# alias Profile1D -> Profile
Profile1D = Profile


class Profile2D(_ProfileBase, _Hist2D, QROOT.TProfile2D):
    _ROOT = QROOT.TProfile2D

    def __init__(self, *args, **kwargs):
        option = kwargs.pop('option', '')
        name = kwargs.pop('name', None)
        title = kwargs.pop('title', None)
        params, args = self._parse_args(args, ignore_extras=True)
        if args:
            if len(args) != 2:
                raise TypeError("Did not receive expected number of arguments")
            low, high = args
            if low >= high:
                raise ValueError(
                    "Upper bound (you gave {0:f}) must be greater than lower "
                    "bound (you gave {1:f})".format(float(low), float(high)))
        args = list(args)
        args.append(option)
        if params[0]['bins'] is None and params[1]['bins'] is None:
            super(Profile2D, self).__init__(
                params[0]['nbins'], params[0]['low'], params[0]['high'],
                params[1]['nbins'], params[1]['low'], params[1]['high'],
                *args, name=name, title=title)
        elif params[0]['bins'] is None and params[1]['bins'] is not None:
            super(Profile2D, self).__init__(
                params[0]['nbins'], params[0]['low'], params[0]['high'],
                params[1]['nbins'], array('d', params[1]['bins']),
                *args, name=name, title=title)
        elif params[0]['bins'] is not None and params[1]['bins'] is None:
            super(Profile2D, self).__init__(
                params[0]['nbins'], array('d', params[0]['bins']),
                params[1]['nbins'], params[1]['low'], params[1]['high'],
                *args, name=name, title=title)
        else:
            super(Profile2D, self).__init__(
                params[0]['nbins'], array('d', params[0]['bins']),
                params[1]['nbins'], array('d', params[1]['bins']),
                *args, name=name, title=title)
        self._post_init(**kwargs)


class Profile3D(_ProfileBase, _Hist3D, QROOT.TProfile3D):
    _ROOT = QROOT.TProfile3D

    def __init__(self, *args, **kwargs):
        option = kwargs.pop('option', '')
        name = kwargs.pop('name', None)
        title = kwargs.pop('title', None)
        # Profile3D does not support t_low, t_up
        params = self._parse_args(args)
        # ROOT is missing constructors for TH3...
        if (params[0]['bins'] is None and
                params[1]['bins'] is None and
                params[2]['bins'] is None):
            super(Profile3D, self).__init__(
                params[0]['nbins'], params[0]['low'], params[0]['high'],
                params[1]['nbins'], params[1]['low'], params[1]['high'],
                params[2]['nbins'], params[2]['low'], params[2]['high'],
                option, name=name, title=title)
        else:
            if params[0]['bins'] is None:
                step = ((params[0]['high'] - params[0]['low'])
                        / float(params[0]['nbins']))
                params[0]['bins'] = [
                    params[0]['low'] + n * step
                    for n in xrange(params[0]['nbins'] + 1)]
            if params[1]['bins'] is None:
                step = ((params[1]['high'] - params[1]['low'])
                        / float(params[1]['nbins']))
                params[1]['bins'] = [
                    params[1]['low'] + n * step
                    for n in xrange(params[1]['nbins'] + 1)]
            if params[2]['bins'] is None:
                step = ((params[2]['high'] - params[2]['low'])
                        / float(params[2]['nbins']))
                params[2]['bins'] = [
                    params[2]['low'] + n * step
                    for n in xrange(params[2]['nbins'] + 1)]
            super(Profile3D, self).__init__(
                params[0]['nbins'], array('d', params[0]['bins']),
                params[1]['nbins'], array('d', params[1]['bins']),
                params[2]['nbins'], array('d', params[2]['bins']),
                option, name=name, title=title)
        self._post_init(**kwargs)

########NEW FILE########
__FILENAME__ = root2matplotlib
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module provides functions that allow the plotting of ROOT histograms and
graphs with `matplotlib <http://matplotlib.org/>`_.

If you just want to save image files and don't want matplotlib to attempt to
create a graphical window, tell matplotlib to use a non-interactive backend
such as ``Agg`` when importing it for the first time (i.e. before importing
rootpy.plotting.root2matplotlib)::

   import matplotlib
   matplotlib.use('Agg') # do this before importing pyplot or root2matplotlib

This puts matplotlib in a batch state similar to ``ROOT.gROOT.SetBatch(True)``.
"""
from __future__ import absolute_import

# trigger ROOT's finalSetup (GUI thread) before matplotlib's
import ROOT
ROOT.kTRUE

from math import sqrt
from itertools import izip
import matplotlib.pyplot as plt
import numpy as np

from .hist import _Hist
from .graph import _Graph1DBase
from .utils import get_limits


__all__ = [
    'hist',
    'bar',
    'errorbar',
    'fill_between',
    'step',
    'hist2d',
    'imshow',
    'contour',
]


def _set_defaults(obj, kwargs, types=['common']):
    defaults = {}
    for key in types:
        if key == 'common':
            defaults['label'] = obj.GetTitle()
            defaults['visible'] = getattr(obj, 'visible', True)
            defaults['alpha'] = getattr(obj, 'alpha', None)
        elif key == 'line':
            defaults['linestyle'] = obj.GetLineStyle('mpl')
            defaults['linewidth'] = obj.GetLineWidth()
        elif key == 'fill':
            defaults['edgecolor'] = obj.GetLineColor('mpl')
            defaults['facecolor'] = obj.GetFillColor('mpl')
            root_fillstyle = obj.GetFillStyle('root')
            if root_fillstyle == 0:
                defaults['facecolor'] = 'none'
                defaults['fill'] = False
            elif root_fillstyle == 1001:
                defaults['fill'] = True
            else:
                defaults['hatch'] = obj.GetFillStyle('mpl')
                defaults['facecolor'] = 'none'
        elif key == 'marker':
            defaults['marker'] = obj.GetMarkerStyle('mpl')
            defaults['markersize'] = obj.GetMarkerSize() * 5
            defaults['markeredgecolor'] = obj.GetMarkerColor('mpl')
            defaults['markerfacecolor'] = obj.GetMarkerColor('mpl')
        elif key == 'errors':
            defaults['ecolor'] = obj.GetLineColor('mpl')
        elif key == 'errorbar':
            defaults['fmt'] = obj.GetMarkerStyle('mpl')
    for key, value in defaults.items():
        if key not in kwargs:
            kwargs[key] = value


def _set_bounds(h,
                axes=None,
                was_empty=True,
                prev_xlim=None,
                prev_ylim=None,
                xpadding=0,
                ypadding=.1,
                xerror_in_padding=True,
                yerror_in_padding=True,
                snap=True,
                logx=None,
                logy=None):
    if axes is None:
        axes = plt.gca()
    if prev_xlim is None:
        prev_xlim = plt.xlim()
    if prev_ylim is None:
        prev_ylim = plt.ylim()
    if logx is None:
        logx = axes.get_xscale() == 'log'
    if logy is None:
        logy = axes.get_yscale() == 'log'
    xmin, xmax, ymin, ymax = get_limits(
        h,
        xpadding=xpadding,
        ypadding=ypadding,
        xerror_in_padding=xerror_in_padding,
        yerror_in_padding=yerror_in_padding,
        snap=snap,
        logx=logx,
        logy=logy)
    if was_empty:
        axes.set_xlim([xmin, xmax])
        axes.set_ylim([ymin, ymax])
    else:
        prev_xmin, prev_xmax = prev_xlim
        if logx and prev_xmin <= 0:
            axes.set_xlim([xmin, max(prev_xmax, xmax)])
        else:
            axes.set_xlim([min(prev_xmin, xmin), max(prev_xmax, xmax)])
        prev_ymin, prev_ymax = prev_ylim
        if logy and prev_ymin <= 0:
            axes.set_ylim([ymin, max(prev_ymax, ymax)])
        else:
            axes.set_ylim([min(prev_ymin, ymin), max(prev_ymax, ymax)])


def _get_highest_zorder(axes):
    return max([c.get_zorder() for c in axes.get_children()])


def _maybe_reversed(x, reverse=False):
    if reverse:
        return reversed(x)
    return x


def hist(hists,
         stacked=True,
         reverse=False,
         xpadding=0, ypadding=.1,
         yerror_in_padding=True,
         logy=None,
         snap=True,
         axes=None,
         **kwargs):
    """
    Make a matplotlib hist plot from a ROOT histogram, stack or
    list of histograms.

    Parameters
    ----------

    hists : Hist, list of Hist, HistStack
        The histogram(s) to be plotted

    stacked : bool, optional (default=True)
        If True then stack the histograms with the first histogram on the
        bottom, otherwise overlay them with the first histogram in the
        background.

    reverse : bool, optional (default=False)
        If True then reverse the order of the stack or overlay.

    xpadding : float or 2-tuple of floats, optional (default=0)
        Padding to add on the left and right sides of the plot as a fraction of
        the axes width after the padding has been added. Specify unique left
        and right padding with a 2-tuple.

    ypadding : float or 2-tuple of floats, optional (default=.1)
        Padding to add on the top and bottom of the plot as a fraction of
        the axes height after the padding has been added. Specify unique top
        and bottom padding with a 2-tuple.

    yerror_in_padding : bool, optional (default=True)
        If True then make the padding inclusive of the y errors otherwise
        only pad around the y values.

    logy : bool, optional (default=None)
        Apply special treatment of a log-scale y-axis to display the histogram
        correctly. If None (the default) then automatically determine if the
        y-axis is log-scale.

    snap : bool, optional (default=True)
        If True (the default) then the origin is an implicit lower bound of the
        histogram unless the histogram has both positive and negative bins.

    axes : matplotlib Axes instance, optional (default=None)
        The axes to plot on. If None then use the global current axes.

    kwargs : additional keyword arguments, optional
        All additional keyword arguments are passed to matplotlib's
        fill_between for the filled regions and matplotlib's step function
        for the edges.

    Returns
    -------

    The return value from matplotlib's hist function, or list of such return
    values if a stack or list of histograms was plotted.

    """
    if axes is None:
        axes = plt.gca()
    if logy is None:
        logy = axes.get_yscale() == 'log'
    curr_xlim = axes.get_xlim()
    curr_ylim = axes.get_ylim()
    was_empty = not axes.has_data()
    returns = []
    if isinstance(hists, _Hist):
        # This is a single plottable object.
        returns = _hist(hists, axes=axes, logy=logy, **kwargs)
        _set_bounds(hists, axes=axes,
                    was_empty=was_empty,
                    prev_xlim=curr_xlim,
                    prev_ylim=curr_ylim,
                    xpadding=xpadding, ypadding=ypadding,
                    yerror_in_padding=yerror_in_padding,
                    snap=snap,
                    logy=logy)
    elif stacked:
        # draw the top histogram first so its edges don't cover the histograms
        # beneath it in the stack
        if not reverse:
            hists = list(hists)[::-1]
        for i, h in enumerate(hists):
            kwargs_local = kwargs.copy()
            if i == len(hists) - 1:
                low = h.Clone()
                low.Reset()
            else:
                low = sum(hists[i + 1:])
            high = h + low
            high.alpha = getattr(h, 'alpha', None)
            proxy = _hist(high, bottom=low, axes=axes, logy=logy, **kwargs)
            returns.append(proxy)
        if not reverse:
            returns = returns[::-1]
        _set_bounds(sum(hists), axes=axes,
                    was_empty=was_empty,
                    prev_xlim=curr_xlim,
                    prev_ylim=curr_ylim,
                    xpadding=xpadding, ypadding=ypadding,
                    yerror_in_padding=yerror_in_padding,
                    snap=snap,
                    logy=logy)
    else:
        for h in _maybe_reversed(hists, reverse):
            returns.append(_hist(h, axes=axes, logy=logy, **kwargs))
        if reverse:
            returns = returns[::-1]
        _set_bounds(max(hists), axes=axes,
                    was_empty=was_empty,
                    prev_xlim=curr_xlim,
                    prev_ylim=curr_ylim,
                    xpadding=xpadding, ypadding=ypadding,
                    yerror_in_padding=yerror_in_padding,
                    snap=snap,
                    logy=logy)
    return returns


def _hist(h, axes=None, bottom=None, logy=None, zorder=None, **kwargs):
    if axes is None:
        axes = plt.gca()
    if zorder is None:
        zorder = _get_highest_zorder(axes) + 1
    _set_defaults(h, kwargs, ['common', 'line', 'fill'])
    kwargs_proxy = kwargs.copy()
    fill = kwargs.pop('fill', False) or 'hatch' in kwargs
    if fill:
        # draw the fill without the edge
        if bottom is None:
            bottom = h.Clone()
            bottom.Reset()
        fill_between(bottom, h, axes=axes, logy=logy, linewidth=0,
                     facecolor=kwargs['facecolor'],
                     edgecolor=kwargs['edgecolor'],
                     hatch=kwargs.get('hatch', None),
                     alpha=kwargs['alpha'],
                     zorder=zorder)
    # draw the edge
    step(h, axes=axes, logy=logy, label=None,
         zorder=zorder + 1, alpha=kwargs['alpha'])
    # draw the legend proxy
    if getattr(h, 'legendstyle', '').upper() == 'F':
        proxy = plt.Rectangle((0, 0), 0, 0, **kwargs_proxy)
        axes.add_patch(proxy)
    else:
        # be sure the linewidth is greater than zero...
        proxy = plt.Line2D((0, 0), (0, 0),
                           linestyle=kwargs_proxy['linestyle'],
                           linewidth=kwargs_proxy['linewidth'],
                           color=kwargs_proxy['edgecolor'],
                           alpha=kwargs['alpha'],
                           label=kwargs_proxy['label'])
        axes.add_line(proxy)
    return proxy


def bar(hists,
        stacked=True,
        reverse=False,
        xerr=False, yerr=True,
        xpadding=0, ypadding=.1,
        yerror_in_padding=True,
        rwidth=0.8,
        snap=True,
        axes=None,
        **kwargs):
    """
    Make a matplotlib bar plot from a ROOT histogram, stack or
    list of histograms.

    Parameters
    ----------

    hists : Hist, list of Hist, HistStack
        The histogram(s) to be plotted

    stacked : bool or string, optional (default=True)
        If True then stack the histograms with the first histogram on the
        bottom, otherwise overlay them with the first histogram in the
        background. If 'cluster', then the bars will be arranged side-by-side.

    reverse : bool, optional (default=False)
        If True then reverse the order of the stack or overlay.

    xerr : bool, optional (default=False)
        If True, x error bars will be displayed.

    yerr : bool or string, optional (default=True)
        If False, no y errors are displayed.  If True, an individual y
        error will be displayed for each hist in the stack.  If 'linear' or
        'quadratic', a single error bar will be displayed with either the
        linear or quadratic sum of the individual errors.

    xpadding : float or 2-tuple of floats, optional (default=0)
        Padding to add on the left and right sides of the plot as a fraction of
        the axes width after the padding has been added. Specify unique left
        and right padding with a 2-tuple.

    ypadding : float or 2-tuple of floats, optional (default=.1)
        Padding to add on the top and bottom of the plot as a fraction of
        the axes height after the padding has been added. Specify unique top
        and bottom padding with a 2-tuple.

    yerror_in_padding : bool, optional (default=True)
        If True then make the padding inclusive of the y errors otherwise
        only pad around the y values.

    rwidth : float, optional (default=0.8)
        The relative width of the bars as a fraction of the bin width.

    snap : bool, optional (default=True)
        If True (the default) then the origin is an implicit lower bound of the
        histogram unless the histogram has both positive and negative bins.

    axes : matplotlib Axes instance, optional (default=None)
        The axes to plot on. If None then use the global current axes.

    kwargs : additional keyword arguments, optional
        All additional keyword arguments are passed to matplotlib's bar
        function.

    Returns
    -------

    The return value from matplotlib's bar function, or list of such return
    values if a stack or list of histograms was plotted.

    """
    if axes is None:
        axes = plt.gca()
    curr_xlim = axes.get_xlim()
    curr_ylim = axes.get_ylim()
    was_empty = not axes.has_data()
    logy = kwargs.pop('log', axes.get_yscale() == 'log')
    kwargs['log'] = logy
    returns = []
    if isinstance(hists, _Hist):
        # This is a single histogram.
        returns = _bar(hists, xerr=xerr, yerr=yerr,
                       axes=axes, **kwargs)
        _set_bounds(hists, axes=axes,
                    was_empty=was_empty,
                    prev_xlim=curr_xlim,
                    prev_ylim=curr_ylim,
                    xpadding=xpadding, ypadding=ypadding,
                    yerror_in_padding=yerror_in_padding,
                    snap=snap,
                    logy=logy)
    elif stacked == 'cluster':
        nhists = len(hists)
        hlist = _maybe_reversed(hists, reverse)
        for i, h in enumerate(hlist):
            width = rwidth / nhists
            offset = (1 - rwidth) / 2 + i * width
            returns.append(_bar(
                h, offset, width,
                xerr=xerr, yerr=yerr, axes=axes, **kwargs))
        _set_bounds(sum(hists), axes=axes,
                    was_empty=was_empty,
                    prev_xlim=curr_xlim,
                    prev_ylim=curr_ylim,
                    xpadding=xpadding, ypadding=ypadding,
                    yerror_in_padding=yerror_in_padding,
                    snap=snap,
                    logy=logy)
    elif stacked is True:
        nhists = len(hists)
        hlist = _maybe_reversed(hists, reverse)
        toterr = bottom = None
        if yerr == 'linear':
            toterr = [sum([h.GetBinError(i) for h in hists])
                      for i in range(1, hists[0].nbins(0) + 1)]
        elif yerr == 'quadratic':
            toterr = [sqrt(sum([h.GetBinError(i) ** 2 for h in hists]))
                      for i in range(1, hists[0].nbins(0) + 1)]
        for i, h in enumerate(hlist):
            err = None
            if yerr is True:
                err = True
            elif yerr and i == (nhists - 1):
                err = toterr
            returns.append(_bar(
                h,
                xerr=xerr, yerr=err,
                bottom=list(bottom.y()) if bottom else None,
                axes=axes, **kwargs))
            if bottom is None:
                bottom = h.Clone()
            else:
                bottom += h
        _set_bounds(bottom, axes=axes,
                    was_empty=was_empty,
                    prev_xlim=curr_xlim,
                    prev_ylim=curr_ylim,
                    xpadding=xpadding, ypadding=ypadding,
                    yerror_in_padding=yerror_in_padding,
                    snap=snap,
                    logy=logy)
    else:
        for h in hlist:
            returns.append(_bar(h, xerr=xerr, yerr=yerr,
                                axes=axes, **kwargs))
        _set_bounds(max(hists), axes=axes,
                    was_empty=was_empty,
                    prev_xlim=curr_xlim,
                    prev_ylim=curr_ylim,
                    xpadding=xpadding, ypadding=ypadding,
                    yerror_in_padding=yerror_in_padding,
                    snap=snap,
                    logy=logy)
    return returns


def _bar(h, roffset=0., rwidth=1., xerr=None, yerr=None, axes=None, **kwargs):
    if axes is None:
        axes = plt.gca()
    if xerr:
        xerr = np.array([list(h.xerrl()), list(h.xerrh())])
    if yerr:
        yerr = np.array([list(h.yerrl()), list(h.yerrh())])
    _set_defaults(h, kwargs, ['common', 'line', 'fill', 'errors'])
    width = [x * rwidth for x in h.xwidth()]
    left = [h.xedgesl(i) + h.xwidth(i) * roffset
            for i in xrange(1, h.nbins(0) + 1)]
    height = list(h.y())
    return axes.bar(left, height, width=width, xerr=xerr, yerr=yerr, **kwargs)


def errorbar(hists,
             xerr=True, yerr=True,
             xpadding=0, ypadding=.1,
             xerror_in_padding=True,
             yerror_in_padding=True,
             emptybins=True,
             snap=True,
             axes=None,
             **kwargs):
    """
    Make a matplotlib errorbar plot from a ROOT histogram or graph
    or list of histograms and graphs.

    Parameters
    ----------

    hists : Hist, Graph or list of Hist and Graph
        The histogram(s) and/or Graph(s) to be plotted

    xerr : bool, optional (default=True)
        If True, x error bars will be displayed.

    yerr : bool or string, optional (default=True)
        If False, no y errors are displayed.  If True, an individual y
        error will be displayed for each hist in the stack.  If 'linear' or
        'quadratic', a single error bar will be displayed with either the
        linear or quadratic sum of the individual errors.

    xpadding : float or 2-tuple of floats, optional (default=0)
        Padding to add on the left and right sides of the plot as a fraction of
        the axes width after the padding has been added. Specify unique left
        and right padding with a 2-tuple.

    ypadding : float or 2-tuple of floats, optional (default=.1)
        Padding to add on the top and bottom of the plot as a fraction of
        the axes height after the padding has been added. Specify unique top
        and bottom padding with a 2-tuple.

    xerror_in_padding : bool, optional (default=True)
        If True then make the padding inclusive of the x errors otherwise
        only pad around the x values.

    yerror_in_padding : bool, optional (default=True)
        If True then make the padding inclusive of the y errors otherwise
        only pad around the y values.

    emptybins : bool, optional (default=True)
        If True (the default) then plot bins with zero content otherwise only
        show bins with nonzero content.

    snap : bool, optional (default=True)
        If True (the default) then the origin is an implicit lower bound of the
        histogram unless the histogram has both positive and negative bins.

    axes : matplotlib Axes instance, optional (default=None)
        The axes to plot on. If None then use the global current axes.

    kwargs : additional keyword arguments, optional
        All additional keyword arguments are passed to matplotlib's errorbar
        function.

    Returns
    -------

    The return value from matplotlib's errorbar function, or list of such
    return values if a list of histograms and/or graphs was plotted.

    """
    if axes is None:
        axes = plt.gca()
    curr_xlim = axes.get_xlim()
    curr_ylim = axes.get_ylim()
    was_empty = not axes.has_data()
    if isinstance(hists, (_Hist, _Graph1DBase)):
        # This is a single plottable object.
        returns = _errorbar(
            hists, xerr, yerr,
            axes=axes, emptybins=emptybins, **kwargs)
        _set_bounds(hists, axes=axes,
                    was_empty=was_empty,
                    prev_ylim=curr_ylim,
                    xpadding=xpadding, ypadding=ypadding,
                    xerror_in_padding=xerror_in_padding,
                    yerror_in_padding=yerror_in_padding,
                    snap=snap)
    else:
        returns = []
        for h in hists:
            returns.append(errorbar(
                h, xerr=xerr, yerr=yerr, axes=axes,
                xpadding=xpadding, ypadding=ypadding,
                xerror_in_padding=xerror_in_padding,
                yerror_in_padding=yerror_in_padding,
                snap=snap,
                emptybins=emptybins,
                **kwargs))
    return returns


def _errorbar(h, xerr, yerr, axes=None, emptybins=True, zorder=None, **kwargs):
    if axes is None:
        axes = plt.gca()
    if zorder is None:
        zorder = _get_highest_zorder(axes) + 1
    _set_defaults(h, kwargs, ['common', 'errors', 'errorbar', 'marker'])
    if xerr:
        xerr = np.array([list(h.xerrl()), list(h.xerrh())])
    if yerr:
        yerr = np.array([list(h.yerrl()), list(h.yerrh())])
    x = np.array(list(h.x()))
    y = np.array(list(h.y()))
    if not emptybins:
        nonempty = y != 0
        x = x[nonempty]
        y = y[nonempty]
        if xerr is not False:
            xerr = xerr[:, nonempty]
        if yerr is not False:
            yerr = yerr[:, nonempty]
    return axes.errorbar(x, y, xerr=xerr, yerr=yerr, zorder=zorder, **kwargs)


def step(h, logy=None, axes=None, **kwargs):
    """
    Make a matplotlib step plot from a ROOT histogram.

    Parameters
    ----------

    h : Hist
        A rootpy Hist

    logy : bool, optional (default=None)
        If True then clip the y range between 1E-300 and 1E300.
        If None (the default) then automatically determine if the axes are
        log-scale and if this clipping should be performed.

    axes : matplotlib Axes instance, optional (default=None)
        The axes to plot on. If None then use the global current axes.

    kwargs : additional keyword arguments, optional
        Additional keyword arguments are passed directly to
        matplotlib's fill_between function.

    Returns
    -------

    Returns the value from matplotlib's fill_between function.

    """
    if axes is None:
        axes = plt.gca()
    if logy is None:
        logy = axes.get_yscale() == 'log'
    _set_defaults(h, kwargs, ['common', 'line'])
    if 'color' not in kwargs:
        kwargs['color'] = h.GetLineColor('mpl')
    y = np.array(list(h.y()) + [0.])
    if logy:
        np.clip(y, 1E-300, 1E300, out=y)
    return axes.step(list(h.xedges()), y, where='post', **kwargs)


def fill_between(a, b, logy=None, axes=None, **kwargs):
    """
    Fill the region between two histograms or graphs.

    Parameters
    ----------

    a : Hist
        A rootpy Hist

    b : Hist
        A rootpy Hist

    logy : bool, optional (default=None)
        If True then clip the region between 1E-300 and 1E300.
        If None (the default) then automatically determine if the axes are
        log-scale and if this clipping should be performed.

    axes : matplotlib Axes instance, optional (default=None)
        The axes to plot on. If None then use the global current axes.

    kwargs : additional keyword arguments, optional
        Additional keyword arguments are passed directly to
        matplotlib's fill_between function.

    Returns
    -------

    Returns the value from matplotlib's fill_between function.

    """
    if axes is None:
        axes = plt.gca()
    if logy is None:
        logy = axes.get_yscale() == 'log'
    if not isinstance(a, _Hist) or not isinstance(b, _Hist):
        raise TypeError(
            "fill_between only operates on 1D histograms")
    a.check_compatibility(b, check_edges=True)
    x = []
    top = []
    bottom = []
    for abin, bbin in izip(a.bins(overflow=False), b.bins(overflow=False)):
        up = max(abin.value, bbin.value)
        dn = min(abin.value, bbin.value)
        x.extend([abin.x.low, abin.x.high])
        top.extend([up, up])
        bottom.extend([dn, dn])
    x = np.array(x)
    top = np.array(top)
    bottom = np.array(bottom)
    if logy:
        np.clip(top, 1E-300, 1E300, out=top)
        np.clip(bottom, 1E-300, 1E300, out=bottom)
    return axes.fill_between(x, top, bottom, **kwargs)


def hist2d(h, axes=None, **kwargs):
    """
    Draw a 2D matplotlib histogram plot from a 2D ROOT histogram.

    Parameters
    ----------

    h : Hist2D
        A rootpy Hist2D

    axes : matplotlib Axes instance, optional (default=None)
        The axes to plot on. If None then use the global current axes.

    kwargs : additional keyword arguments, optional
        Additional keyword arguments are passed directly to
        matplotlib's hist2d function.

    Returns
    -------

    Returns the value from matplotlib's hist2d function.

    """
    if axes is None:
        axes = plt.gca()
    X, Y = np.meshgrid(list(h.x()), list(h.y()))
    x = X.ravel()
    y = Y.ravel()
    z = np.array(h.z()).T
    return axes.hist2d(x, y, weights=z.ravel(),
                       bins=(list(h.xedges()), list(h.yedges())),
                       **kwargs)


def imshow(h, axes=None, **kwargs):
    """
    Draw a matplotlib imshow plot from a 2D ROOT histogram.

    Parameters
    ----------

    h : Hist2D
        A rootpy Hist2D

    axes : matplotlib Axes instance, optional (default=None)
        The axes to plot on. If None then use the global current axes.

    kwargs : additional keyword arguments, optional
        Additional keyword arguments are passed directly to
        matplotlib's imshow function.

    Returns
    -------

    Returns the value from matplotlib's imshow function.

    """
    if axes is None:
        axes = plt.gca()
    z = np.array(h.z()).T
    return axes.imshow(
        z,
        extent=[
            h.xedges(1), h.xedges(h.nbins(0) + 1),
            h.yedges(1), h.yedges(h.nbins(1) + 1)],
        interpolation='nearest',
        aspect='auto',
        origin='lower',
        **kwargs)


def contour(h, axes=None, zoom=None, **kwargs):
    """
    Draw a matplotlib contour plot from a 2D ROOT histogram.

    Parameters
    ----------

    h : Hist2D
        A rootpy Hist2D

    axes : matplotlib Axes instance, optional (default=None)
        The axes to plot on. If None then use the global current axes.

    zoom : float or sequence, optional (default=None)
        The zoom factor along the axes. If a float, zoom is the same for each
        axis. If a sequence, zoom should contain one value for each axis.
        The histogram is zoomed using a cubic spline interpolation to create
        smooth contours.

    kwargs : additional keyword arguments, optional
        Additional keyword arguments are passed directly to
        matplotlib's contour function.

    Returns
    -------

    Returns the value from matplotlib's contour function.

    """
    if axes is None:
        axes = plt.gca()
    x = np.array(list(h.x()))
    y = np.array(list(h.y()))
    z = np.array(h.z()).T
    if zoom is not None:
        from scipy import ndimage
        if hasattr(zoom, '__iter__'):
            zoom = list(zoom)
            x = ndimage.zoom(x, zoom[0])
            y = ndimage.zoom(y, zoom[1])
        else:
            x = ndimage.zoom(x, zoom)
            y = ndimage.zoom(y, zoom)
        z = ndimage.zoom(z, zoom)
    return axes.contour(x, y, z, **kwargs)

########NEW FILE########
__FILENAME__ = shapes
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from .. import QROOT
from ..decorators import snake_case_methods
from .base import Plottable

__all__ = [
    'Line',
    'Ellipse',
    'Arrow',
]


@snake_case_methods
class Line(Plottable, QROOT.TLine):
    _ROOT = QROOT.TLine

    def __init__(self, *args, **kwargs):
        super(Line, self).__init__(*args)
        self._post_init(**kwargs)


@snake_case_methods
class Ellipse(Plottable, QROOT.TEllipse):
    _ROOT = QROOT.TEllipse

    def __init__(self, *args, **kwargs):
        super(Ellipse, self).__init__(*args)
        self._post_init(**kwargs)


@snake_case_methods
class Arrow(QROOT.TArrow):
    _ROOT = QROOT.TArrow

########NEW FILE########
__FILENAME__ = labels
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from ....context import preserve_current_canvas
from ....memory.keepalive import keepalive

__all__ = [
    'ATLAS_label',
]


def ATLAS_label(x, y, text="Preliminary 20XX", sqrts=8,
                pad=None,
                expfont=73, labelfont=43,
                textsize=20, sep=None):

    if pad is None:
        pad = ROOT.gPad.func()
    with preserve_current_canvas():
        pad.cd()
        l = ROOT.TLatex(x, y, "ATLAS")
        #l.SetTextAlign(12)
        #l.SetTextSize(tsize)
        l.SetNDC()
        l.SetTextFont(expfont)
        l.SetTextSize(textsize)
        l.SetTextColor(1)
        l.Draw()
        keepalive(pad, l)
        if sep is None:
            # guess
            sep = 0.115 * 696 * pad.GetWh() / (472 * pad.GetWw())
        if text is not None:
            if sqrts is not None:
                text = text + " #sqrt{{s}}={0:d}TeV".format(sqrts)
            p = ROOT.TLatex(x + sep, y, text)
            p.SetNDC()
            p.SetTextFont(labelfont)
            p.SetTextSize(textsize)
            p.SetTextColor(1)
            p.Draw()
            keepalive(pad, p)
        else:
            p = None
        pad.Modified()
        pad.Update()
    return l, p

########NEW FILE########
__FILENAME__ = style
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
ATLAS Style, based on a style file from BaBar
"""
from __future__ import absolute_import

from .. import Style

__all__ = [
    'style',
]

def style(name='ATLAS', shape='rect', orientation='landscape'):

    STYLE = Style(name, 'ATLAS Style')

    # turn off borders
    STYLE.SetCanvasBorderMode(0)
    STYLE.SetFrameBorderMode(0)
    STYLE.SetPadBorderMode(0)

    # default canvas size and position
    if shape == 'rect':
        if orientation == 'landscape':
            h = 600
            w = 800
            mtop = 0.05
            mright = 0.04
            mbottom = 0.16
            mleft = 0.16
            xoffset = 1.4
            yoffset = 1.5
        elif orientation == 'portrait':
            h = 800
            w = 600
            mtop = 0.04
            mright = 0.05
            mbottom = 0.12
            mleft = 0.21
            xoffset = 1.4
            yoffset = 2.6
        else:
            raise ValueError("orientation must be 'landscape' or 'portrait'")
    elif shape == 'square':
        h = 600
        w = 600
        mtop = 0.05
        mright = 0.05
        mbottom = 0.16
        mleft = 0.21
        xoffset = 1.4
        yoffset = 2.
    else:
        raise ValueError("shape must be 'square' or 'rect'")

    STYLE.SetCanvasDefH(h)
    STYLE.SetCanvasDefW(w)
    STYLE.SetCanvasDefX(0)
    STYLE.SetCanvasDefY(0)

    # set margin sizes
    STYLE.SetPadTopMargin(mtop)
    STYLE.SetPadRightMargin(mright)
    STYLE.SetPadBottomMargin(mbottom)
    STYLE.SetPadLeftMargin(mleft)

    # set title offsets (for axis label)
    STYLE.SetTitleXOffset(xoffset)
    STYLE.SetTitleYOffset(yoffset)

    # use plain black on white colors
    STYLE.SetFrameFillColor(0)
    STYLE.SetCanvasColor(0)
    STYLE.SetPadColor(0)
    STYLE.SetStatColor(0)

    # don't use white fill color for *all* objects
    #STYLE.SetFillColor(0)

    # NOTE: the following is missing from the official ATLAS style
    STYLE.SetLegendBorderSize(0)
    STYLE.SetLegendFillColor(0)

    # set the paper & margin sizes
    STYLE.SetPaperSize(20,26)

    # use large fonts
    #font = 72 # Helvetica italics
    # NOTE: the official ATLAS style uses 42 here but it is preferred to specify the
    # font size in pixels, independent of the canvas size
    font = 43 # Helvetica
    tsize = 30
    STYLE.SetTextFont(font)
    STYLE.SetLegendFont(font)

    STYLE.SetTextSize(tsize)
    STYLE.SetLabelFont(font, "x")
    STYLE.SetTitleFont(font, "x")
    STYLE.SetLabelFont(font, "y")
    STYLE.SetTitleFont(font, "y")
    STYLE.SetLabelFont(font, "z")
    STYLE.SetTitleFont(font, "z")

    STYLE.SetLabelSize(tsize, "x")
    STYLE.SetTitleSize(tsize, "x")
    STYLE.SetLabelSize(tsize, "y")
    STYLE.SetTitleSize(tsize, "y")
    STYLE.SetLabelSize(tsize, "z")
    STYLE.SetTitleSize(tsize, "z")

    # use bold lines and markers
    STYLE.SetMarkerStyle(20)
    STYLE.SetMarkerSize(1.2)
    STYLE.SetHistLineWidth(2)
    STYLE.SetLineStyleString(2, "[12 12]") # postscript dashes

    # get rid of X error bars
    #STYLE.SetErrorX(0.001)
    # get rid of error bar caps
    STYLE.SetEndErrorSize(0.)

    # do not display any of the standard histogram decorations
    STYLE.SetOptTitle(0)
    #STYLE.SetOptStat(1111)
    STYLE.SetOptStat(0)
    #STYLE.SetOptFit(1111)
    STYLE.SetOptFit(0)

    # put tick marks on top and RHS of plots
    STYLE.SetPadTickX(1)
    STYLE.SetPadTickY(1)

    STYLE.SetPalette(1)

    return STYLE

########NEW FILE########
__FILENAME__ = style_mpl
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
ATLAS-like style for matplotlib
"""
__all__ = [
    'style_mpl',
]

def style_mpl():

    STYLE = {}

    STYLE['lines.linewidth'] = 1

    # font
    STYLE['font.family'] = 'sans-serif'
    STYLE['mathtext.fontset'] = 'stixsans'
    STYLE['mathtext.default'] = 'rm'
    # helvetica usually not present on linux
    STYLE['font.sans-serif'] = 'helvetica, Helvetica, Nimbus Sans L, Mukti Narrow, FreeSans'

    # figure layout
    STYLE['figure.figsize'] = 8.75, 5.92
    #   atlasStyle->SetPaperSize(20,26); # in cm
    # STYLE['figure.figsize'] =  10.2362205, 7.874015 # in inc, not working
    STYLE['figure.facecolor'] = 'white'
    STYLE['figure.subplot.bottom'] = 0.16
    STYLE['figure.subplot.top'] = 0.95
    STYLE['figure.subplot.left'] = 0.16
    STYLE['figure.subplot.right'] = 0.95

    # axes
    STYLE['axes.labelsize'] = 20
    STYLE['xtick.labelsize'] = 19
    STYLE['xtick.major.size'] = 12
    STYLE['xtick.minor.size'] = 6
    STYLE['ytick.labelsize'] = 19
    STYLE['ytick.major.size'] = 14
    STYLE['ytick.minor.size'] = 7
    STYLE['lines.markersize'] = 8
    # STYLE['lines.markeredgewidth'] = 0. # not working, it changes other stuff

    # legend
    STYLE['legend.numpoints'] = 1
    STYLE['legend.fontsize'] = 19
    STYLE['legend.labelspacing'] = 0.3
    STYLE['legend.frameon'] = False

    # what cannot be set with rcParams:
    # * markeredgewidth
    # * axis-label alignment
    # * axis-label offset
    # * axis-ticks

    return STYLE

########NEW FILE########
__FILENAME__ = test
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
import ROOT
from rootpy.plotting import Canvas, Hist
from rootpy.plotting.style import get_style
from rootpy.plotting.style.atlas.labels import ATLAS_label
from rootpy.interactive import wait

INTERACTIVE = False


def test_atlas():

    style = get_style('ATLAS')
    with style:
        canvas = Canvas()
        hpx = Hist(100, -4, 4, name="hpx", title="This is the px distribution")
        ROOT.gRandom.SetSeed()
        for i in xrange(1000):
            hpx.Fill(ROOT.gRandom.Gaus())
        hpx.GetXaxis().SetTitle("random variable [unit]")
        hpx.GetYaxis().SetTitle("#frac{dN}{dr} [unit^{-1}]")
        hpx.SetMaximum(80.)
        hpx.Draw()
        ATLAS_label(.4, .8)
        if INTERACTIVE:
            wait()


if __name__ == "__main__":
    import nose
    INTERACTIVE = True
    nose.runmodule()

########NEW FILE########
__FILENAME__ = labels
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Add the "CMS Preliminary" and \sqrt{s} blurbs to CMS plots.
"""
from __future__ import absolute_import

import ROOT

from ....context import preserve_current_canvas
from ....memory.keepalive import keepalive

__all__ = [
    'CMS_label',
]


def CMS_label(text="Preliminary 2012", sqrts=8, pad=None):
    """ Add a 'CMS Preliminary' style label to the current Pad.

    The blurbs are drawn in the top margin.  The label "CMS " + text is drawn
    in the upper left.  If sqrts is None, it will be omitted.  Otherwise, it
    will be drawn in the upper right.
    """
    if pad is None:
        pad = ROOT.gPad.func()
    with preserve_current_canvas():
        pad.cd()
        left_margin = pad.GetLeftMargin()
        top_margin = pad.GetTopMargin()
        ypos = 1 - top_margin / 2.
        l = ROOT.TLatex(left_margin, ypos, "CMS " + text)
        l.SetTextAlign(12) # left-middle
        l.SetNDC()
        # The text is 90% as tall as the margin it lives in.
        l.SetTextSize(0.90 * top_margin)
        l.Draw()
        keepalive(pad, l)
        # Draw sqrt(s) label, if desired
        if sqrts:
            right_margin = pad.GetRightMargin()
            p = ROOT.TLatex(1 - right_margin, ypos,
                            "#sqrt{{s}}={0:d}TeV".format(sqrts))
            p.SetTextAlign(32) # right-middle
            p.SetNDC()
            p.SetTextSize(0.90 * top_margin)
            p.Draw()
            keepalive(pad, p)
        else:
            p = None
        pad.Modified()
        pad.Update()
    return l, p

########NEW FILE########
__FILENAME__ = style
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
CMS style from http://cmssw.cvs.cern.ch/cgi-bin/cmssw.cgi/UserCode/RootMacros/style-CMSTDR.C
"""
from __future__ import absolute_import

from .. import Style

__all__ = [
    'style',
]


def style(name='CMSTDR'):

    STYLE = Style(name, "Style for CMS P-TDR")

    # For the canvas:
    STYLE.SetCanvasBorderMode(0)
    STYLE.SetCanvasColor(0)
    STYLE.SetCanvasDefH(600) # Height of canvas
    STYLE.SetCanvasDefW(600) # Width of canvas
    STYLE.SetCanvasDefX(0)   # Position on screen
    STYLE.SetCanvasDefY(0)

    # For the Pad:
    STYLE.SetPadBorderMode(0)
    # STYLE.SetPadBorderSize(Width_t size = 1)
    STYLE.SetPadColor(0)
    STYLE.SetPadGridX(False)
    STYLE.SetPadGridY(False)
    STYLE.SetGridColor(0)
    STYLE.SetGridStyle(3)
    STYLE.SetGridWidth(1)

    # For the frame:
    STYLE.SetFrameBorderMode(0)
    STYLE.SetFrameBorderSize(1)
    STYLE.SetFrameFillColor(0)
    STYLE.SetFrameFillStyle(0)
    STYLE.SetFrameLineColor(1)
    STYLE.SetFrameLineStyle(1)
    STYLE.SetFrameLineWidth(1)

    # For the histo:
    # STYLE.SetHistFillColor(1)
    # STYLE.SetHistFillStyle(0)
    STYLE.SetHistLineColor(1)
    STYLE.SetHistLineStyle(0)
    STYLE.SetHistLineWidth(1)
    # STYLE.SetLegoInnerR(Float_t rad = 0.5)
    # STYLE.SetNumberContours(Int_t number = 20)

    STYLE.SetEndErrorSize(2)
    #STYLE.SetErrorMarker(20)  # Seems to give an error
    STYLE.SetErrorX(0.)

    STYLE.SetMarkerStyle(20)

    #For the fit/function:
    STYLE.SetOptFit(1)
    STYLE.SetFitFormat("5.4g")
    STYLE.SetFuncColor(2)
    STYLE.SetFuncStyle(1)
    STYLE.SetFuncWidth(1)

    #For the date:
    STYLE.SetOptDate(0)
    # STYLE.SetDateX(Float_t x = 0.01)
    # STYLE.SetDateY(Float_t y = 0.01)

    # For the statistics box:
    STYLE.SetOptFile(0)
    STYLE.SetOptStat(0) # To display the mean and RMS:   SetOptStat("mr")
    STYLE.SetStatColor(0)
    STYLE.SetStatFont(42)
    STYLE.SetStatFontSize(0.025)
    STYLE.SetStatTextColor(1)
    STYLE.SetStatFormat("6.4g")
    STYLE.SetStatBorderSize(1)
    STYLE.SetStatH(0.1)
    STYLE.SetStatW(0.15)
    # STYLE.SetStatStyle(Style_t style = 1001)
    # STYLE.SetStatX(Float_t x = 0)
    # STYLE.SetStatY(Float_t y = 0)

    # Margins:
    STYLE.SetPadTopMargin(0.05)
    STYLE.SetPadBottomMargin(0.13)
    STYLE.SetPadLeftMargin(0.16)
    STYLE.SetPadRightMargin(0.02)

    # For the Global title:
    STYLE.SetOptTitle(0)    # 0=No Title
    STYLE.SetTitleFont(42)
    STYLE.SetTitleColor(1)
    STYLE.SetTitleTextColor(1)
    STYLE.SetTitleFillColor(10)
    STYLE.SetTitleFontSize(0.05)
    # STYLE.SetTitleH(0) # Set the height of the title box
    # STYLE.SetTitleW(0) # Set the width of the title box
    # STYLE.SetTitleX(0) # Set the position of the title box
    # STYLE.SetTitleY(0.985) # Set the position of the title box
    # STYLE.SetTitleStyle(Style_t style = 1001)
    # STYLE.SetTitleBorderSize(2)

    # For the axis titles:
    STYLE.SetTitleColor(1, "XYZ")
    STYLE.SetTitleFont(42, "XYZ")
    STYLE.SetTitleSize(0.05, "XYZ")
    # STYLE.SetTitleXSize(Float_t size = 0.02) # Another way to set the size?
    # STYLE.SetTitleYSize(Float_t size = 0.02)
    STYLE.SetTitleXOffset(1.0)
    STYLE.SetTitleYOffset(1.35)
    # STYLE.SetTitleOffset(1.1, "Y") # Another way to set the Offset

    # For the axis labels:
    STYLE.SetLabelColor(1, "XYZ")
    STYLE.SetLabelFont(42, "XYZ")
    STYLE.SetLabelOffset(0.007, "XYZ")
    STYLE.SetLabelSize(0.04, "XYZ")

    # For the axis:
    STYLE.SetAxisColor(1, "XYZ")
    STYLE.SetStripDecimals(True)
    STYLE.SetTickLength(0.03, "XYZ")
    STYLE.SetNdivisions(510, "XYZ")
    STYLE.SetPadTickX(1)  # 0=Text labels (and tics) only on bottom, 1=Text labels on top and bottom
    STYLE.SetPadTickY(1)

    # Change for log plots:
    STYLE.SetOptLogx(0)
    STYLE.SetOptLogy(0)
    STYLE.SetOptLogz(0)

    # Postscript options:
    STYLE.SetPaperSize(20.,20.)
    # STYLE.SetLineScalePS(Float_t scale = 3)
    # STYLE.SetLineStyleString(Int_t i, const char* text)
    # STYLE.SetHeaderPS(const char* header)
    # STYLE.SetTitlePS(const char* pstitle)

    # STYLE.SetBarOffset(Float_t baroff = 0.5)
    # STYLE.SetBarWidth(Float_t barwidth = 0.5)
    # STYLE.SetPaintTextFormat(const char* format = "g")
    # STYLE.SetPalette(Int_t ncolors = 0, Int_t* colors = 0)
    # STYLE.SetTimeOffset(Double_t toffset)
    # STYLE.SetHistMinimumZero(True)

    STYLE.SetPalette(1)

    return STYLE

########NEW FILE########
__FILENAME__ = test
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
import ROOT
from rootpy.plotting import Canvas, Hist
from rootpy.plotting.style import get_style
from rootpy.plotting.style.cmstdr.labels import CMS_label
from rootpy.interactive import wait

INTERACTIVE = False


def test_cmstdr():

    style = get_style('CMSTDR')
    with style:
        canvas = Canvas()
        hpx = Hist(100, -4, 4, name="hpx", title="This is the px distribution")
        ROOT.gRandom.SetSeed()
        for i in xrange(1000):
            hpx.Fill(ROOT.gRandom.Gaus())
        hpx.GetXaxis().SetTitle("random variable [unit]")
        hpx.GetYaxis().SetTitle("#frac{dN}{dr} [unit^{-1}]")
        hpx.SetMaximum(100.)
        hpx.Draw()
        CMS_label("Testing 2050", sqrts=100)
        if INTERACTIVE:
            wait()


if __name__ == "__main__":
    import nose
    INTERACTIVE = True
    nose.runmodule()

########NEW FILE########
__FILENAME__ = style
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from .. import Style

__all__ = [
    'style',
]

def style(name='DEFAULT'):
    return Style("DEFAULT", "Default Style")

########NEW FILE########
__FILENAME__ = labels
# Copyright 2013 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Add an 'LHCb (Preliminary|Unofficial)' label to plots.
"""
from __future__ import absolute_import

import ROOT

from ....context import preserve_current_canvas
from ....memory.keepalive import keepalive

__all__ = [
    'LHCb_label',
]


def LHCb_label(side="L", status="final", text="", pad=None):
    """Add an 'LHCb (Preliminary|Unofficial)' label to the current pad."""

    if pad is None:
        pad = ROOT.gPad.func()

    with preserve_current_canvas():
        pad.cd()
        if side == "L":
            l = ROOT.TPaveText(pad.GetLeftMargin() + 0.05,
                               0.87 - pad.GetTopMargin(),
                               pad.GetLeftMargin() + 0.30,
                               0.95 - pad.GetTopMargin(),
                               "BRNDC")
        elif side == "R":
            l = ROOT.TPaveText(0.70 - pad.GetRightMargin(),
                               0.75 - pad.GetTopMargin(),
                               0.95 - pad.GetRightMargin(),
                               0.85 - pad.GetTopMargin(),
                               "BRNDC")
        else:
            raise TypeError("Unknown side '{0}'".format(side))

        if status == "final":
            l.AddText("LHCb")
        elif status == "preliminary":
            l.AddText("#splitline{LHCb}{#scale[1.0]{Preliminary}}")
        elif status == "unofficial":
            l.AddText("#splitline{LHCb}{#scale[1.0]{Unofficial}}")
        elif status == "custom":
            l.AddText(text)
        else:
            raise TypeError("Unknown status '{0}'".format(status))

        l.SetFillColor(0)
        l.SetTextAlign(12)
        l.SetBorderSize(0)
        l.Draw()

        keepalive(pad, l)

        pad.Modified()
        pad.Update()

    return l, None

########NEW FILE########
__FILENAME__ = style
# Copyright 2013 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
LHCb style from lhcbStyle.C
"""
from __future__ import absolute_import

from .. import Style

__all__ = [
    'style',
]


def style(name='LHCb'):

    STYLE = Style(name, 'LHCb Style')

    font = 132
    line_width = 2
    text_size = 0.06

    # Default canvas size and position.
    STYLE.SetCanvasDefH(600)
    STYLE.SetCanvasDefW(800)
    STYLE.SetCanvasDefX(0)
    STYLE.SetCanvasDefY(0)

    # Colours.
    STYLE.SetCanvasBorderMode(0)
    STYLE.SetCanvasColor(0)
    STYLE.SetFillColor(1)
    STYLE.SetFillStyle(1001)
    STYLE.SetFrameBorderMode(0)
    STYLE.SetFrameFillColor(0)
    STYLE.SetLegendBorderSize(0)
    STYLE.SetPadBorderMode(0)
    STYLE.SetPadColor(0)
    STYLE.SetPalette(1)
    STYLE.SetStatColor(0)

    # Paper and margin sizes.
    STYLE.SetPadBottomMargin(0.16)
    STYLE.SetPadLeftMargin(0.14)
    STYLE.SetPadRightMargin(0.05)
    STYLE.SetPadTopMargin(0.05)
    STYLE.SetPaperSize(20, 26)

    # Font.
    STYLE.SetLabelFont(font, "x")
    STYLE.SetLabelFont(font, "y")
    STYLE.SetLabelFont(font, "z")
    STYLE.SetLabelSize(text_size, "x")
    STYLE.SetLabelSize(text_size, "y")
    STYLE.SetLabelSize(text_size, "z")
    STYLE.SetTextFont(font)
    STYLE.SetTextSize(text_size)
    STYLE.SetTitleFont(font)
    STYLE.SetTitleFont(font, "x")
    STYLE.SetTitleFont(font, "y")
    STYLE.SetTitleFont(font, "z")
    STYLE.SetTitleSize(1.2*text_size, "x")
    STYLE.SetTitleSize(1.2*text_size, "y")
    STYLE.SetTitleSize(1.2*text_size, "z")

    # Lines and markers.
    STYLE.SetFrameLineWidth(line_width)
    STYLE.SetFuncWidth(line_width)
    STYLE.SetGridWidth(line_width)
    STYLE.SetHistLineWidth(line_width)
    STYLE.SetLineStyleString(2, "[12 12]")
    STYLE.SetLineWidth(line_width)
    STYLE.SetMarkerSize(1.0)
    STYLE.SetMarkerStyle(20)

    # Label offsets.
    STYLE.SetLabelOffset(0.010, "X")
    STYLE.SetLabelOffset(0.010, "Y")

    # Decorations.
    STYLE.SetOptFit(0)
    STYLE.SetOptStat(0)
    STYLE.SetOptTitle(0)
    STYLE.SetStatFormat("6.3g")

    # Titles.
    STYLE.SetTitleBorderSize(0)
    STYLE.SetTitleFillColor(0)
    STYLE.SetTitleFont(font, "title")
    STYLE.SetTitleH(0.05)
    STYLE.SetTitleOffset(0.95, "X")
    STYLE.SetTitleOffset(0.95, "Y")
    STYLE.SetTitleOffset(1.2, "Z")
    STYLE.SetTitleStyle(0)
    STYLE.SetTitleW(1.0)
    STYLE.SetTitleX(0.0)
    STYLE.SetTitleY(1.0)

    # Statistics box.
    STYLE.SetStatBorderSize(0)
    STYLE.SetStatFont(font)
    STYLE.SetStatFontSize(0.05)
    STYLE.SetStatH(0.15)
    STYLE.SetStatW(0.25)
    STYLE.SetStatX(0.9)
    STYLE.SetStatY(0.9)

    # Tick marks.
    STYLE.SetPadTickX(1)
    STYLE.SetPadTickY(1)

    # Divisions: only 5 in x to avoid label overlaps.
    STYLE.SetNdivisions(505, "x")
    STYLE.SetNdivisions(510, "y")

    return STYLE

########NEW FILE########
__FILENAME__ = test
# Copyright 2013 the rootpy developers
# distributed under the terms of the GNU General Public License
import ROOT
from rootpy.plotting import Canvas, Hist
from rootpy.plotting.style import get_style
from rootpy.plotting.style.lhcb.labels import LHCb_label
from rootpy.interactive import wait

INTERACTIVE = False


def test_lhcb():
    style = get_style('LHCb')

    with style:
        canvas = Canvas()
        hpx = Hist(100, -4, 4, name="hpx", title="This is the px distribution")
        ROOT.gRandom.SetSeed()
        for i in xrange(1000):
            hpx.Fill(ROOT.gRandom.Gaus())
        hpx.GetXaxis().SetTitle("random variable [unit]")
        hpx.GetYaxis().SetTitle("#frac{dN}{dr} [unit^{-1}]")
        hpx.SetMaximum(80.)
        hpx.Draw()
        LHCb_label("R", "preliminary")
        if INTERACTIVE:
            wait()


if __name__ == "__main__":
    import nose
    INTERACTIVE = True
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_style
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy.plotting.style import Style, get_style
from ROOT import TStyle


def test_get_style():

    mystyle = TStyle('mystyle', 'some style')
    assert(isinstance(get_style('mystyle'), Style))

if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_graph
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy.plotting import Graph, Graph2D, Hist
import tempfile
from random import random
from nose.tools import assert_equal


def test_init():

    g = Graph(10, name='test')
    assert_equal(len(g), 10)
    g2d = Graph2D(10, name='test2d')


def test_init_from_hist():

    h = Hist(100, -10, 10)
    h.FillRandom('gaus')
    g = Graph(h)


def test_init_from_file_1d():

    with tempfile.NamedTemporaryFile() as f:
        for i in xrange(100):
            f.write('{0:.3f},{1:.3f}\n'.format(
                random(), random()))
        f.flush()
        g = Graph.from_file(f.name, sep=',')
        assert_equal(len(g), 100)


def test_init_from_file_2d():

    with tempfile.NamedTemporaryFile() as f:
        for i in xrange(100):
            f.write('{0:.3f},{1:.3f},{2:.3f}\n'.format(
                random(), random(), random()))
        f.flush()
        g = Graph2D.from_file(f.name, sep=',')
        assert_equal(len(g), 100)


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_hist
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy.plotting import Hist, Hist2D, Hist3D, HistStack
from rootpy.plotting import F2, F3
from rootpy.utils.extras import LengthMismatch
from nose.tools import (raises, assert_equal, assert_almost_equal,
                        assert_raises, assert_true, assert_false)


def test_init():
    # constructor arguments are repetitions of #bins, left bound, right bound.
    h2d = Hist2D(10, 0, 1, 50, -40, 10, name='2d hist')
    h3d = Hist3D(3, -1, 4, 10, -1000, -200, 2, 0, 1, name='3d hist')

    # variable-width bins may be created by passing the bin edges directly:
    h1d_variable = Hist([1, 4, 10, 100])
    h2d_variable = Hist2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20])
    h3d_variable = Hist3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20])

    # variable-width and constant-width bins can be mixed:
    h2d_mixed = Hist2D([2, 10, 30], 10, 1, 5)

@raises(ValueError)
def test_init_edge_order():
    # bin edges must be in ascending order
    Hist2D([10, 2, 30], 10, 1, 5)

@raises(ValueError)
def test_init_edge_repeated():
    # bin edges must not be repeated
    Hist([10, 10, 30])

def test_edges():
    h = Hist([1, 2, 3, 4])
    assert_equal(list(h.xedges()), [1, 2, 3, 4])
    assert_equal(list(h.xedges(overflow=True)),
                 [float('-inf'), 1, 2, 3, 4, float('inf')])
    assert_equal(h.xedges(0), float('-inf'))
    assert_equal(h.xedges(-1), float('inf'))
    assert_equal(h.xedges(5), float('inf'))
    # wrap around
    assert_equal(h.xedges(6), float('-inf'))
    for i in xrange(1, h.nbins() + 1):
        assert_equal(h.xedges(i), i)

def test_edgesl():
    h = Hist([1, 2, 3, 4])
    assert_equal(list(h.xedgesl()), [1, 2, 3])
    assert_equal(list(h.xedgesl(overflow=True)),
                 [float('-inf'), 1, 2, 3, 4])
    assert_equal(h.xedgesl(0), float('-inf'))
    assert_equal(h.xedgesl(-1), 4)
    assert_equal(h.xedgesl(4), 4)
    # wrap around
    assert_equal(h.xedgesl(5), float('-inf'))
    for i in xrange(1, h.nbins()):
        assert_equal(h.xedgesl(i), i)

def test_edgesh():
    h = Hist([1, 2, 3, 4])
    assert_equal(list(h.xedgesh()), [2, 3, 4])
    assert_equal(list(h.xedgesh(overflow=True)),
                 [1, 2, 3, 4, float('inf')])
    assert_equal(h.xedgesh(0), 1)
    assert_equal(h.xedgesh(-1), float('inf'))
    assert_equal(h.xedgesh(4), float('inf'))
    # wrap around
    assert_equal(h.xedgesh(5), 1)
    for i in xrange(1, h.nbins()):
        assert_equal(h.xedgesh(i), i + 1)

def test_width():
    h = Hist([1, 2, 4, 8])
    assert_equal(list(h.xwidth()), [1, 2, 4])
    assert_equal(list(h.xwidth(overflow=True)),
                 [float('inf'), 1, 2, 4, float('inf')])

def test_bounds():
    h = Hist(10, 0, 1)
    assert_equal(h.bounds(), (0, 1))
    h = Hist2D(10, 0, 1, 10, 1, 2)
    assert_equal(h.bounds(axis=0), (0, 1))
    assert_equal(h.bounds(axis=1), (1, 2))
    h = Hist3D(10, 0, 1, 10, 1, 2, 10, 2, 3)
    assert_equal(h.bounds(axis=0), (0, 1))
    assert_equal(h.bounds(axis=1), (1, 2))
    assert_equal(h.bounds(axis=2), (2, 3))

def test_ravel():
    hist = Hist2D(3, 0, 1, 4, 0, 1)
    for i, bin in enumerate(hist.bins()):
        bin.value = i
        bin.error = i
    rhist = hist.ravel()
    assert_equal(list(rhist.y()), range(12))
    assert_equal(list(rhist.yerrh()), range(12))

def test_uniform():
    hist = Hist(10, 0, 1)
    assert_true(hist.uniform())
    hist = Hist2D(10, 0, 1, [1, 10, 100])
    assert_false(hist.uniform())
    assert_true(hist.uniform(axis=0))

def test_stack():
    stack = HistStack()
    stack.Add(Hist(10, 0, 1, fillstyle='solid', color='red'))
    stack.Add(Hist(10, 0, 1, fillstyle='solid', color='blue'))
    stack.Add(Hist(10, 0, 1, fillstyle='solid', color='green'))
    assert_equal(len(stack), 3)
    stack2 = stack.Clone()
    assert_equal(stack2[2].linecolor, 'green')

def test_indexing():
    hist = Hist(10, 0, 1)
    hist.Fill(0.5)
    assert_equal(hist[6].value, 1)
    assert_equal(hist[10].value, 0)
    assert_raises(IndexError, hist.__getitem__, -13)
    assert_raises(IndexError, hist.__getitem__, 12)

def test_slice_assign():
    hist = Hist(10, 0, 1)
    hist[:] = [i for i in xrange(len(hist))]
    assert all([a.value == b for a, b in zip(hist, xrange(len(hist)))])
    clone = hist.Clone()
    # reverse bins
    hist[:] = clone[::-1]
    assert all([a.value == b.value for a, b in zip(hist, clone[::-1])])

@raises(LengthMismatch)
def test_slice_assign_bad():
    hist = Hist(10, 0, 1)
    hist[:] = xrange(len(hist) + 1)

def test_overflow_underflow():
    h1d = Hist(10, 0, 1)
    h1d.Fill(-1)
    h1d.Fill(2)
    assert_equal(h1d.underflow(), 1)
    assert_equal(h1d.overflow(), 1)

    h2d = Hist2D(10, 0, 1, 10, 0, 1)
    h2d.Fill(-1, .5)
    h2d.Fill(2, .5)
    assert_equal(h2d.underflow()[h2d.axis(1).FindBin(.5)], 1)
    assert_equal(h2d.overflow()[h2d.axis(1).FindBin(.5)], 1)
    h2d.Fill(.5, -1)
    h2d.Fill(.5, 2)
    assert_equal(h2d.underflow(axis=1)[h2d.axis(0).FindBin(.5)], 1)
    assert_equal(h2d.overflow(axis=1)[h2d.axis(0).FindBin(.5)], 1)

    h3d = Hist3D(10, 0, 1, 10, 0, 1, 10, 0, 1)
    h3d.Fill(-1, .5, .5)
    h3d.Fill(2, .5, .5)
    assert_equal(h3d.underflow()[h3d.axis(1).FindBin(.5)][h3d.axis(2).FindBin(.5)], 1)
    assert_equal(h3d.overflow()[h3d.axis(1).FindBin(.5)][h3d.axis(2).FindBin(.5)], 1)
    h3d.Fill(.5, -1, .5)
    h3d.Fill(.5, 2, .5)
    assert_equal(h3d.underflow(axis=1)[h3d.axis(0).FindBin(.5)][h3d.axis(2).FindBin(.5)], 1)
    assert_equal(h3d.overflow(axis=1)[h3d.axis(0).FindBin(.5)][h3d.axis(2).FindBin(.5)], 1)
    h3d.Fill(.5, .5, -1)
    h3d.Fill(.5, .5, 2)
    assert_equal(h3d.underflow(axis=2)[h3d.axis(0).FindBin(.5)][h3d.axis(1).FindBin(.5)], 1)
    assert_equal(h3d.overflow(axis=2)[h3d.axis(0).FindBin(.5)][h3d.axis(1).FindBin(.5)], 1)

def test_merge_bins():
    h1d = Hist(10, 0, 1)
    h1d.FillRandom('gaus', 1000)
    h1d_merged = h1d.merge_bins([(0, -1)])
    assert_equal(h1d_merged.nbins(0), 1)

    h3d = Hist3D(10, 0, 1, 10, 0, 1, 10, 0, 1)
    h3d.FillRandom('gaus')
    h3d_merged = h3d.merge_bins([(1, 3), (-4, -2)], axis=1)
    assert_equal(h3d.GetEntries(), h3d_merged.GetEntries())
    assert_equal(h3d.GetSumOfWeights(), h3d_merged.GetSumOfWeights())
    assert_equal(h3d_merged.nbins(1), 6)

def test_rebinning():
    h1d = Hist(100, 0, 1)
    h1d.FillRandom('gaus')
    assert_equal(h1d.rebinned(2).nbins(0), 50)
    assert_equal(h1d.rebinned((2,)).nbins(0), 50)
    assert_equal(h1d.rebinned([0, .5, 1]).nbins(0), 2)

    h3d = Hist3D(10, 0, 1, 10, 0, 1, 10, 0, 1)
    h3d.FillRandom('gaus')
    assert_equal(h3d.rebinned(2).nbins(0), 5)
    new = h3d.rebinned((2, 5, 1))
    assert_equal(new.nbins(0), 5)
    assert_equal(new.nbins(1), 2)
    assert_equal(new.nbins(2), 10)
    new = h3d.rebinned([0, 5, 10], axis=1)
    assert_equal(new.nbins(1), 2)

def test_quantiles():
    h3d = Hist3D(10, 0, 1, 10, 0, 1, 10, 0, 1)
    h3d.FillRandom('gaus')
    h3d.quantiles(2)
    h3d.quantiles(2, axis=1)
    h3d.quantiles([0, .5, 1], axis=2)

    h2d = Hist2D(100, 0, 1, 100, 0, 1)
    h2d.FillRandom(F2('x+y'))
    h2d.quantiles(4, axis=0)
    h2d.quantiles(4, axis=1)

def test_compatibility():
    a = Hist(10, 0, 1)
    b = Hist(10, 0, 1)
    c = Hist(10, 1, 2)
    d = Hist2D(10, 0, 1, 10, 0, 1)

    assert_true(a.compatible(a))
    assert_true(a.compatible(b))
    assert_true(a.compatible(c))
    assert_false(a.compatible(c, check_edges=True))
    assert_false(a.compatible(d))

def test_power():
    h = Hist2D(10, 0, 1, 10, 0, 1)
    h.FillRandom(F2('x+y'))
    p = h.Clone()
    p /= h.Integral()
    pow(h, 2)
    h**2
    h**p
    assert_raises(ValueError, pow, h, Hist2D(20, 0, 1, 10, 0, 1))
    assert_raises(TypeError, pow, h, Hist(10, 0, 1))
    h**=2


def test_integral():
    h = Hist(10, 0, 1)
    h.FillRandom('gaus', 100)
    h[0].value = 2
    h[-1].value = 4
    assert_equal(h.integral(), 100)
    assert_equal(h.integral(overflow=True), 106)
    assert_equal(h.integral(xbin1=1, overflow=True), 104)
    assert_equal(h.integral(xbin2=-2, overflow=True), 102)


def test_integral_error():
    h = Hist(1, 0, 1)
    h.FillRandom('gaus')
    ref_integral, ref_error = h.integral(error=True)

    h1 = Hist(10, 0, 1)
    h1.FillRandom('gaus')
    integral, error = h1.integral(error=True)
    assert_almost_equal(integral, ref_integral)
    assert_almost_equal(error, ref_error)

    h2 = Hist2D(10, 0, 1, 10, 0, 1)
    h2.FillRandom(F2('x+y'))
    integral, error = h2.integral(error=True)
    assert_almost_equal(integral, ref_integral)
    assert_almost_equal(error, ref_error)

    h3 = Hist3D(10, 0, 1, 10, 0, 1, 10, 0, 1)
    h3.FillRandom(F3('x+y+z'))
    integral, error = h3.integral(error=True)
    assert_almost_equal(integral, ref_integral)
    assert_almost_equal(error, ref_error)

def test_poisson_errors():
    h = Hist(20, -3, 3)
    h.FillRandom('gaus')
    g = h.poisson_errors()


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_legend
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from ROOT import TH1D
from rootpy.plotting import Hist, Legend
from rootpy.context import invisible_canvas


def test_init():

    with invisible_canvas():
        l = Legend(2)
        h = Hist(10, 0, 1)
        l.AddEntry(h)
        hr = TH1D("test", "", 10, 0, 1)
        l.AddEntry(hr)


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_plottable
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy.plotting import Hist
from nose.tools import assert_equals


def test_plottable_clone():

    a = Hist(10, 0, 1, linecolor='blue', drawstyle='same')

    b = a.Clone(fillstyle='solid')
    assert_equals(b.fillstyle, 'solid')
    assert_equals(b.linecolor, 'blue')
    assert_equals(b.drawstyle, 'same')

    c = a.Clone(color='red')
    assert_equals(c.linecolor, 'red')
    assert_equals(c.fillcolor, 'red')
    assert_equals(c.markercolor, 'red')


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_profile
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy.plotting import Profile, Profile2D, Profile3D
from nose.tools import raises


def test_init():
    # constructor arguments are repetitions of #bins, left bound, right bound.
    p2d = Profile2D(10, 0, 1, 50, -40, 10, name='2d profile')
    p3d = Profile3D(3, -1, 4, 10, -1000, -200, 2, 0, 1, name='3d profile')

    # variable-width bins may be created by passing the bin edges directly:
    p1d_variable = Profile([1, 4, 10, 100])
    p2d_variable = Profile2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20])
    p3d_variable = Profile3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20])

    # variable-width and constant-width bins can be mixed:
    p2d_mixed = Profile2D([2, 10, 30], 10, 1, 5)

def test_init_profiled_edges():
    # specifying the profiled axis bounds is optional
    p1d_variable = Profile([1, 4, 10, 100], 0, 1)
    # ROOTBUG: missing constructor:
    #p2d_variable = Profile2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20], 0, 1)
    #p3d_variable = Profile3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20], 0, 1)

def test_init_option():
    # specifying profile options is optional
    p1d_variable = Profile([1, 4, 10, 100], option='s')
    p2d_variable = Profile2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20],
            option='s')
    p3d_variable = Profile3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20],
            option='s')
    p1d_variable = Profile([1, 4, 10, 100], 0, 1, option='s')
    # ROOTBUG: missing constructor:
    #p2d_variable = Profile2D([2, 4, 7, 100, 200], [-100, -50, 0, 10, 20], 0, 1,
    #        option='s')
    p3d_variable = Profile3D([1, 3, 10], [20, 50, 100], [-10, -5, 10, 20],
            option='s')

@raises(ValueError)
def test_init_edge_order():
    # bin edges must be in ascending order
    Profile2D([10, 2, 30], 10, 1, 5)

@raises(ValueError)
def test_init_edge_repeated():
    # bin edges must not be repeated
    Profile([10, 10, 30])

@raises(ValueError)
def test_init_profiled_edge_order():
    # profiled axis edges must be in ascending order
    Profile2D([10, 2, 30], 10, 1, 5, 3, 1)

@raises(ValueError)
def test_init_profiled_edge_repeated():
    # bin edges must not be repeated
    Profile([1, 10, 30], 1, 1)


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_root2matplotlib
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy.plotting import Hist, Hist2D, HistStack, Graph
from nose.plugins.skip import SkipTest
from nose.tools import with_setup


def setup_func():
    try:
        import matplotlib
    except ImportError:
        raise SkipTest("matplotlib is not importable")
    matplotlib.use('Agg')
    from matplotlib import pyplot
    pyplot.ioff()


@with_setup(setup_func)
def test_errorbar():
    from rootpy.plotting import root2matplotlib as rplt
    h = Hist(100, -5, 5)
    h.FillRandom('gaus')
    g = Graph(h)
    rplt.errorbar(g)
    rplt.errorbar(h)


@with_setup(setup_func)
def test_bar():
    from rootpy.plotting import root2matplotlib as rplt
    h = Hist(100, -5, 5)
    h.FillRandom('gaus')
    rplt.bar(h)

    # stack
    h1 = h.Clone()
    stack = HistStack([h, h1])
    rplt.bar(stack)
    rplt.bar([h, h1])


@with_setup(setup_func)
def test_hist():
    from rootpy.plotting import root2matplotlib as rplt
    h = Hist(100, -5, 5)
    h.FillRandom('gaus')
    rplt.hist(h)

    # stack
    h1 = h.Clone()
    stack = HistStack([h, h1])
    rplt.hist(stack)
    rplt.hist([h, h1])


@with_setup(setup_func)
def test_hist2d():
    from rootpy.plotting import root2matplotlib as rplt
    from matplotlib import pyplot
    import numpy as np
    if not hasattr(pyplot, 'hist2d'):
        raise SkipTest("matplotlib is too old")
    a = Hist2D(100, -3, 3, 100, 0, 6)
    a.fill_array(np.random.multivariate_normal(
        mean=(0, 3),
        cov=np.arange(4).reshape(2, 2),
        size=(1000,)))
    rplt.hist2d(a)


@with_setup(setup_func)
def test_imshow():
    from rootpy.plotting import root2matplotlib as rplt
    import numpy as np
    a = Hist2D(100, -3, 3, 100, 0, 6)
    a.fill_array(np.random.multivariate_normal(
        mean=(0, 3),
        cov=np.arange(4).reshape(2, 2),
        size=(1000,)))
    rplt.imshow(a)


@with_setup(setup_func)
def test_contour():
    from rootpy.plotting import root2matplotlib as rplt
    import numpy as np
    a = Hist2D(100, -3, 3, 100, 0, 6)
    a.fill_array(np.random.multivariate_normal(
        mean=(0, 3),
        cov=np.arange(4).reshape(2, 2),
        size=(1000,)))
    rplt.contour(a)


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_utils
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy.plotting.utils import _limits_helper
from nose.tools import assert_equal, assert_raises


def test_limits():
    assert_equal(_limits_helper(0, 1, 0, 0), (0, 1))
    assert_equal(_limits_helper(1, 1, 0, 0, snap=True), (0, 1))
    assert_equal(_limits_helper(-2, -1, 0, 0, snap=True), (-2, 0))
    assert_equal(_limits_helper(-1, 1, .1, .1, snap=True), (-1.25, 1.25))


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = text
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from .base import _StyleContainer

__all__ = [
    'Font',
]

fonts_root2text = {
    1: 'times-medium-i-normal',
    2: 'times-bold-r-normal',
    3: 'times-bold-i-normal',
    4: 'helvetica-medium-r-normal',
    5: 'helvetica-medium-o-normal',
    6: 'helvetica-bold-r-normal',
    7: 'helvetica-bold-o-normal',
    8: 'courier-medium-r-normal',
    9: 'courier-medium-o-normal',
    10: 'courier-bold-r-normal',
    11: 'courier-bold-o-normal',
    12: 'symbol-medium-r-normal',
    13: 'times-medium-r-normal',
    14: 'wingdings',
    15: 'symbol-italic',
    }

fonts_text2root = dict([
    (value, key) for key, value in fonts_root2text.items()])


class Font(_StyleContainer):

    def __init__(self, font, prec=3):
        self._input = font
        if isinstance(font, basestring):
            if font not in fonts_text2root:
                raise ValueError("font '{0}' is not understood".format(font))
            self._root = fonts_text2root[font]
        else:
            if font not in fonts_root2text:
                raise ValueError("font '{0}' is not understood".format(font))
            self._root = font
        self._root *= 10
        self._root += prec
        # conversion to mpl not implemented
        self._mpl = None


if __name__ == '__main__':
    # Example from http://root.cern.ch/root/html/TAttText.html#T5
    from rootpy.plotting import Canvas
    from rootpy.interactive import wait
    from ROOT import TLatex

    c = Canvas(500, 700, name="ROOT Fonts", title="ROOT Fonts")
    c.Range(0, 0, 1, 1)
    c.SetBorderSize(2)
    c.SetFrameFillColor(0)

    def get_text(x, y, f, s):
        t = TLatex(x, y, "#font[41]{{0:d} :} {1}".format(f(), s))
        t.SetTextFont(f('root'))
        t.SetTextAlign(12)
        t.SetTextSize(0.048)
        return t

    y = 0.95
    prec = 2
    for font in sorted(fonts_root2text.keys()):
        f = Font(font, prec)
        if font != 14:
            t = get_text(0.02, y, f, "ABCDEFGH abcdefgh 0123456789 @#$")
        else:
            t = get_text(0.02, y, f, "ABCD efgh 01234 @#$")
        t.Draw()
        y -= 0.065
    wait()

########NEW FILE########
__FILENAME__ = utils
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from math import log
import operator

import ROOT

from .canvas import _PadBase
from .hist import _Hist, Hist, HistStack
from .graph import _Graph1DBase, Graph
from ..context import preserve_current_canvas, do_nothing

__all__ = [
    'draw',
    'get_limits',
    'get_band',
    'canvases_with',
    'find_all_primitives',
    'tick_length_pixels',
]


def draw(plottables, pad=None, same=False,
         xaxis=None, yaxis=None,
         xtitle=None, ytitle=None,
         xlimits=None, ylimits=None,
         **kwargs):
    """
    Draw a list of histograms, stacks, and/or graphs.

    Parameters
    ----------
    plottables : Hist, Graph, HistStack, or list of such objects
        List of objects to draw.

    pad : Pad or Canvas, optional (default=None)
        The pad to draw onto. If None then use the current global pad.

    same : bool, optional (default=False)
        If True then use 'SAME' draw option for all objects instead of
        all but the first. Use this option if you are drawing onto a pad
        that already holds drawn objects.

    xaxis : TAxis, optional (default=None)
        Use this x-axis or use the x-axis of the first plottable if None.

    yaxis : TAxis, optional (default=None)
        Use this y-axis or use the y-axis of the first plottable if None.

    xtitle : str, optional (default=None)
        Set the x-axis title.

    ytitle : str, optional (default=None)
        Set the y-axis title.

    xlimits : tuple, optional (default=None)
        Set the x-axis limits with a 2-tuple of (min, max)

    ylimits : tuple, optional (default=None)
        Set the y-axis limits with a 2-tuple of (min, max)

    kwargs : dict
        All extra arguments are passed to get_limits when determining the axis
        limits.

    Returns
    -------
    (xaxis, yaxis), (xmin, xmax, ymin, ymax) : tuple
        The axes and axes bounds.

    See Also
    --------
    get_limits

    """
    context = preserve_current_canvas if pad else do_nothing
    if not isinstance(plottables, (tuple, list)):
        plottables = [plottables]
    elif not plottables:
        raise ValueError("plottables is empty")
    with context():
        if pad is not None:
            pad.cd()
        # get the axes limits
        xmin, xmax, ymin, ymax = get_limits(plottables, **kwargs)
        if xlimits is not None:
            xmin, xmax = xlimits
        if ylimits is not None:
            ymin, ymax = ylimits
        if not same:
            # draw and get the axes with a temporary histogram
            hist = Hist(1, 0, 1)
            hist.Draw('AXIS')
            # ignore axes from user if any
            xaxis = hist.xaxis
            yaxis = hist.yaxis
        # draw the plottables
        for i, obj in enumerate(plottables):
            if i == 0 and isinstance(obj, ROOT.THStack):
                # use SetMin/Max for y-axis
                obj.SetMinimum(ymin)
                obj.SetMaximum(ymax)
                # ROOT: please fix this...
            obj.Draw('SAME')
        # set the axes limits and titles
        if xaxis is not None:
            xaxis.SetLimits(xmin, xmax)
            xaxis.SetRangeUser(xmin, xmax)
            if xtitle is not None:
                xaxis.SetTitle(xtitle)
        if yaxis is not None:
            yaxis.SetLimits(ymin, ymax)
            yaxis.SetRangeUser(ymin, ymax)
            if ytitle is not None:
                yaxis.SetTitle(ytitle)
    return (xaxis, yaxis), (xmin, xmax, ymin, ymax)


multiadd = lambda a, b: map(operator.add, a, b)
multisub = lambda a, b: map(operator.sub, a, b)


def _limits_helper(x1, x2, a, b, snap=False):
    """
    Given x1, x2, a, b, where:

        x1 - x0         x3 - x2
    a = ------- ,   b = -------
        x3 - x0         x3 - x0

    determine the points x0 and x3:

    x0         x1                x2       x3
    |----------|-----------------|--------|

    """
    if x2 < x1:
        raise ValueError("x2 < x1")
    if a + b >= 1:
        raise ValueError("a + b >= 1")
    if a < 0:
        raise ValueError("a < 0")
    if b < 0:
        raise ValueError("b < 0")
    if snap:
        if x1 >= 0:
            x1 = 0
            a = 0
        elif x2 <= 0:
            x2 = 0
            b = 0
        if x1 == x2 == 0:
            # garbage in garbage out
            return 0., 1.
    elif x1 == x2:
        # garbage in garbage out
        return x1 - 1., x1 + 1.
    if a == 0 and b == 0:
        return x1, x2
    elif a == 0:
        return x1, (x2 - b * x1) / (1 - b)
    elif b == 0:
        return (x1 - a * x2) / (1 - a), x2
    x0 = ((b / a) * x1 + x2 - (x2 - x1) / (1 - a - b)) / (1 + b / a)
    x3 = (x2 - x1) / (1 - a - b) + x0
    return x0, x3


def get_limits(plottables,
               xpadding=0,
               ypadding=0.1,
               xerror_in_padding=True,
               yerror_in_padding=True,
               snap=True,
               logx=False,
               logy=False,
               logx_crop_value=1E-5,
               logy_crop_value=1E-5,
               logx_base=10,
               logy_base=10):
    """
    Get the axes limits that should be used for a 1D histogram, graph, or stack
    of histograms.

    Parameters
    ----------

    plottables : Hist, Graph, HistStack, or list of such objects
        The object(s) for which visually pleasing plot boundaries are
        requested.

    xpadding : float or 2-tuple, optional (default=0)
        The horizontal padding as a fraction of the final plot width.

    ypadding : float or 2-tuple, optional (default=0.1)
        The vertical padding as a fraction of the final plot height.

    xerror_in_padding : bool, optional (default=True)
        If False then exclude the x error bars from the calculation of the plot
        width.

    yerror_in_padding : bool, optional (default=True)
        If False then exclude the y error bars from the calculation of the plot
        height.

    snap : bool, optional (default=True)
        Make the minimum or maximum of the vertical range the x-axis depending
        on if the plot maximum and minimum are above or below the x-axis. If
        the plot maximum is above the x-axis while the minimum is below the
        x-axis, then this option will have no effect.

    logx : bool, optional (default=False)
        If True, then the x-axis is log scale.

    logy : bool, optional (default=False)
        If True, then the y-axis is log scale.

    logx_crop_value : float, optional (default=1E-5)
        If an x-axis is using a logarithmic scale then crop all non-positive
        values with this value.

    logy_crop_value : float, optional (default=1E-5)
        If the y-axis is using a logarithmic scale then crop all non-positive
        values with this value.

    logx_base : float, optional (default=10)
        The base used for the logarithmic scale of the x-axis.

    logy_base : float, optional (default=10)
        The base used for the logarithmic scale of the y-axis.

    Returns
    -------

    xmin, xmax, ymin, ymax : tuple of plot boundaries
        The computed x and y-axis ranges.

    """
    try:
        import numpy as np
        use_numpy = True
    except ImportError:
        use_numpy = False

    if not isinstance(plottables, (list, tuple)):
        plottables = [plottables]

    xmin = float('+inf')
    xmax = float('-inf')
    ymin = float('+inf')
    ymax = float('-inf')

    for h in plottables:

        if isinstance(h, HistStack):
            h = h.sum

        if not isinstance(h, (_Hist, _Graph1DBase)):
            raise TypeError(
                "unable to determine plot axes ranges "
                "from object of type `{0}`".format(
                    type(h)))

        if use_numpy:
            y_array_min = y_array_max = np.array(list(h.y()))
            if yerror_in_padding:
                y_array_min = y_array_min - np.array(list(h.yerrl()))
                y_array_max = y_array_max + np.array(list(h.yerrh()))
            _ymin = y_array_min.min()
            _ymax = y_array_max.max()
        else:
            y_array_min = y_array_max = list(h.y())
            if yerror_in_padding:
                y_array_min = multisub(y_array_min, list(h.yerrl()))
                y_array_max = multiadd(y_array_max, list(h.yerrh()))
            _ymin = min(y_array_min)
            _ymax = max(y_array_max)

        if isinstance(h, _Graph1DBase):
            if use_numpy:
                x_array_min = x_array_max = np.array(list(h.x()))
                if xerror_in_padding:
                    x_array_min = x_array_min - np.array(list(h.xerrl()))
                    x_array_max = x_array_max + np.array(list(h.xerrh()))
                _xmin = x_array_min.min()
                _xmax = x_array_max.max()
            else:
                x_array_min = x_array_max = list(h.x())
                if xerror_in_padding:
                    x_array_min = multisub(x_array_min, list(h.xerrl()))
                    x_array_max = multiadd(x_array_max, list(h.xerrh()))
                _xmin = min(x_array_min)
                _xmax = max(x_array_max)
        else:
            _xmin = h.xedgesl(1)
            _xmax = h.xedgesh(h.nbins(0))

        if logy:
            _ymin = max(logy_crop_value, _ymin)
            _ymax = max(logy_crop_value, _ymax)
        if logx:
            _xmin = max(logx_crop_value, _xmin)
            _xmax = max(logx_crop_value, _xmax)

        if _xmin < xmin:
            xmin = _xmin
        if _xmax > xmax:
            xmax = _xmax
        if _ymin < ymin:
            ymin = _ymin
        if _ymax > ymax:
            ymax = _ymax

    if isinstance(xpadding, (list, tuple)):
        if len(xpadding) != 2:
            raise ValueError("xpadding must be of length 2")
        xpadding_left = xpadding[0]
        xpadding_right = xpadding[1]
    else:
        xpadding_left = xpadding_right = xpadding

    if isinstance(ypadding, (list, tuple)):
        if len(ypadding) != 2:
            raise ValueError("ypadding must be of length 2")
        ypadding_top = ypadding[0]
        ypadding_bottom = ypadding[1]
    else:
        ypadding_top = ypadding_bottom = ypadding

    if logx:
        x0, x3 = _limits_helper(
            log(xmin, logx_base), log(xmax, logx_base),
            xpadding_left, xpadding_right)
        xmin = logx_base ** x0
        xmax = logx_base ** x3
    else:
        xmin, xmax = _limits_helper(
            xmin, xmax, xpadding_left, xpadding_right)

    if logy:
        y0, y3 = _limits_helper(
            log(ymin, logy_base), log(ymax, logy_base),
            ypadding_bottom, ypadding_top, snap=False)
        ymin = logy_base ** y0
        ymax = logy_base ** y3
    else:
        ymin, ymax = _limits_helper(
            ymin, ymax, ypadding_bottom, ypadding_top, snap=snap)

    return xmin, xmax, ymin, ymax


def get_band(low_hist, high_hist, middle_hist=None):
    """
    Convert the low and high histograms into a TGraphAsymmErrors centered at
    the middle histogram if not None otherwise the middle between the low and
    high points, to be used to draw a (possibly asymmetric) error band.
    """
    npoints = low_hist.nbins(0)
    band = Graph(npoints)
    for i in xrange(npoints):
        center = low_hist.x(i + 1)
        width = low_hist.xwidth(i + 1)
        low, high = low_hist.y(i + 1), high_hist.y(i + 1)
        if middle_hist is not None:
            middle = middle_hist.y(i + 1)
        else:
            middle = (low + high) / 2.
        yerrh = max(high - middle, low - middle, 0)
        yerrl = abs(min(high - middle, low - middle, 0))
        band.SetPoint(i, center, middle)
        band.SetPointError(i, width / 2., width / 2.,
                           yerrl, yerrh)
    return band


def canvases_with(drawable):
    """
    Return a list of all canvases where `drawable` has been painted.

    Note: This function is inefficient because it inspects all objects on all
          canvases, recursively. Avoid calling it if you have a large number of
          canvases and primitives.
    """
    return [c for c in ROOT.gROOT.GetListOfCanvases()
            if drawable in find_all_primitives(c)]


def find_all_primitives(pad):
    """
    Recursively find all primities on a pad, even those hiding behind a
    GetListOfFunctions() of a primitive
    """
    result = []
    for primitive in pad.GetListOfPrimitives():
        result.append(primitive)
        if hasattr(primitive, "GetListOfFunctions"):
            result.extend(primitive.GetListOfFunctions())
        if hasattr(primitive, "GetHistogram"):
            p = primitive.GetHistogram()
            if p:
                result.append(p)
        if isinstance(primitive, ROOT.TPad):
            result.extend(find_all_primitives(primitive))
    return result


def tick_length_pixels(pad, xaxis, yaxis, xlength, ylength=None):
    """
    Set the axes tick lengths in pixels
    """
    if ylength is None:
        ylength = xlength
    xaxis.SetTickLength(xlength / float(pad.height_pixels))
    yaxis.SetTickLength(ylength / float(pad.width_pixels))

########NEW FILE########
__FILENAME__ = views
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
'''

=====================
Folder "View" Classes
=====================

These classes wrap Directories and perform automatic actions
to Histograms retrieved from them.  The different views can be composited and
layered.

Summary of views:

- ScaleView: scale histogram normalization
- NormalizeView: normalize histograms
- SumView: sum histograms from different folders together
- StyleView: apply a style to histograms
- StackView: build THStacks using histograms from different folders
- TitleView: change the title of histograms
- FunctorView: apply a arbitrary transformation function to the histograms
- MultiFunctorView: apply a arbitrary transformation function to a collection
  of histograms
- SubdirectoryView: A view of a subdirectory, which maintains the same view as
  the base.

Example use case
================

One has a ROOT file with the following content::

    zjets/mutau_mass
    zz/mutau_mass
    wz/mutau_mass
    data_2010/mutau_mass
    data_2011/mutau_mass

and wants to do the following:

1. Merge the two data taking periods together
2. Scale the Z, WZ, and ZZ simulated results to the appropriate int. lumi.
3. Combine WZ and ZZ into a single diboson sample
4. Apply different colors to the MC samples
5. Make a Stack of the expected yields from different simulated processes

This example can be tested by running::

    python -m rootpy.plotting.views

>>> # Mock up the example test case
>>> import rootpy.io as io
>>> # We have to keep these, to make sure PyROOT doesn't garbage collect them
>>> keep = []
>>> zjets_dir = io.Directory('zjets', 'Zjets directory')
>>> zz_dir = io.Directory('zz', 'ZZ directory')
>>> wz_dir = io.Directory('wz', 'WZ directory')
>>> data2010_dir = io.Directory('data2010', 'data2010 directory')
>>> data2011_dir = io.Directory('data2011', 'data2011 directory')
>>> # Make the Zjets case
>>> _ = zjets_dir.cd()
>>> zjets_hist = ROOT.TH1F("mutau_mass", "Mu-Tau mass", 100, 0, 100)
>>> zjets_hist.FillRandom('gaus', 5000)
>>> keep.append(zjets_hist)
>>> # Make the ZZ case
>>> _ = zz_dir.cd()
>>> zz_hist = ROOT.TH1F("mutau_mass", "Mu-Tau mass", 100, 0, 100)
>>> zz_hist.FillRandom('gaus', 5000)
>>> keep.append(zz_hist)
>>> # Make the WZ case
>>> _ = wz_dir.cd()
>>> wz_hist = ROOT.TH1F("mutau_mass", "Mu-Tau mass", 100, 0, 100)
>>> wz_hist.FillRandom('gaus', 5000)
>>> keep.append(wz_hist)
>>> # Make the 2010 data case
>>> _ = data2010_dir.cd()
>>> data2010_hist = ROOT.TH1F("mutau_mass", "Mu-Tau mass", 100, 0, 100)
>>> data2010_hist.FillRandom('gaus', 30)
>>> keep.append(data2010_hist)
>>> # Make the 2011 data case
>>> _ = data2011_dir.cd()
>>> data2011_hist = ROOT.TH1F("mutau_mass", "Mu-Tau mass", 100, 0, 100)
>>> data2011_hist.FillRandom('gaus', 51)
>>> keep.append(data2011_hist)

SumView
-------

We can merge the two data periods into a single case using a SumView.

>>> data = SumView(data2010_dir, data2011_dir)
>>> data_hist = data.Get("mutau_mass")
>>> data_hist.Integral()
81.0
>>> data_hist.Integral() == data2010_hist.Integral() + data2011_hist.Integral()
True

ScaleView
---------

The simulated results (Z & diboson) can be scaled to the expected integrated
luminosity using ScaleViews.

>>> zjets = ScaleView(zjets_dir, 0.01)
>>> zjets_hist = zjets.Get("mutau_mass")
>>> abs(zjets_hist.Integral() - 50.0) < 1e-5
True
>>> # Scale the diboson contribution
>>> zz = ScaleView(zz_dir, 0.001)
>>> wz = ScaleView(wz_dir, 0.003)

Combining views
---------------

The dibosons individually are tiny, let's put them together using a SumView.
Note that this operation nests two ScaleViews into a SumView.

>>> dibosons = SumView(zz, wz)
>>> # We expect 5000*0.001 + 5000*0.003 = 20 events
>>> dibosons_hist = dibosons.Get("mutau_mass")
>>> abs(dibosons_hist.Integral() - 20) < 1e-4
True

StyleView
---------

A style view automatically applies a style to retrieved Plottable objects.
The style is specified using the same arguments as the Plottable.decorate.
Let's make the Z background red and the diboson background blue.

>>> zjets = StyleView(zjets, fillcolor=ROOT.EColor.kRed)
>>> dibosons = StyleView(dibosons, fillcolor=ROOT.EColor.kBlue)
>>> zjets_hist = zjets.Get("mutau_mass")
>>> zjets_hist.GetFillColor() == ROOT.EColor.kRed
True
>>> dibosons_hist = dibosons.Get("mutau_mass")
>>> dibosons_hist.GetFillColor() == ROOT.EColor.kBlue
True

StackView
---------

The StackView combines multiple items into a HistStack.  In our example
we stack the SM backgrounds to compare to the data.

>>> sm_bkg = StackView(zjets, dibosons)
>>> sm_bkg_stack = sm_bkg.Get("mutau_mass")
>>> '%0.0f' % sm_bkg_stack.Integral()
'70'

Looks like we have an excess of 11 events - must be the Higgs.


Other Examples
==============

NormalizeView
-------------

The normalization view renormalizes histograms to a given value (default 1.0).
Here is an example of using the NormalizeView to compare the Z and diboson
shapes.

>>> z_shape = NormalizeView(zjets)
>>> z_shape_hist = z_shape.Get("mutau_mass")
>>> abs(1 - z_shape_hist.Integral()) < 1e-5
True
>>> # Let's compare the shapes using a HistStack, using the "nostack" option.
>>> diboson_shape = NormalizeView(dibosons)
>>> shape_comparison = StackView(z_shape, diboson_shape)
>>> # To draw the comparison:
>>> # shape_comparison.Get("mutau_mass").Draw('nostack')

FunctorView
-----------

FunctorView allows you to apply an arbitrary transformation to the object.
Here we show how you can change the axis range for all histograms in a
directory.

>>> rebin = lambda x: x.Rebin(2)
>>> zjets_rebinned = FunctorView(zjets, rebin)
>>> zjets.Get("mutau_mass").GetNbinsX()
100
>>> zjets_rebinned.Get("mutau_mass").GetNbinsX()
50

The functor doesn't have to return a histogram.

>>> mean_getter = lambda x: x.GetMean()
>>> mean = zjets.Get("mutau_mass").GetMean()
>>> zjets_mean = FunctorView(zjets, mean_getter)
>>> zjets_mean.Get("mutau_mass") == mean
True


MultiFunctorView
----------------

MultiFunctorView is similar except that it operates on a group of histograms.
The functor should take one argument, a *generator* of the sub-objects.

Here's an example to get the integral of the biggest histogram in a set:

>>> biggest_histo = lambda objects: max(y.Integral() for y in objects)
>>> biggest = MultiFunctorView(biggest_histo, zjets, dibosons)
>>> biggest.Get("mutau_mass") == zjets.Get("mutau_mass").Integral()
True

SubdirectoryView
----------------

If you'd like to "cd" into a lower subdirectory, while still maintaining
the same view, use a SubdirectoryView.

>>> basedir = io.Directory('base', 'base directory')
>>> _ = basedir.cd()
>>> subdir1 = io.Directory('subdir1', 'subdir directory in 1')
>>> _ = subdir1.cd()
>>> hist = ROOT.TH1F("mutau_mass", "Mu-Tau mass", 100, 0, 100)
>>> hist.FillRandom('gaus', 2000)
>>> keep.append(hist)
>>> _ = basedir.cd()
>>> subdir2 = io.Directory('subdir2', 'subdir directory 2')
>>> _ = subdir2.cd()
>>> hist = ROOT.TH1F("mutau_mass", "Mu-Tau mass", 100, 0, 100)
>>> hist.FillRandom('gaus', 5000)
>>> keep.append(hist)

The directory structure is now::
    base/subdir1/hist
    base/subdir2/hist

Subdirectory views work on top of other views.

>>> baseview = ScaleView(basedir, 0.1)
>>> subdir1view = SubdirectoryView(baseview, 'subdir1')
>>> subdir2view = SubdirectoryView(baseview, 'subdir2')
>>> histo1 = subdir1view.Get('mutau_mass')
>>> histo2 = subdir2view.Get('mutau_mass')
>>> exp_histo1 = baseview.Get("subdir1/mutau_mass")
>>> exp_histo2 = baseview.Get("subdir2/mutau_mass")
>>> def equivalent(h1, h2):
...     return (abs(h1.GetMean() - h2.GetMean()) < 1e-4 and
...             abs(h1.GetRMS() - h2.GetRMS()) < 1e-4 and
...             abs(h1.Integral() - h2.Integral()) < 1e-4)
>>> equivalent(exp_histo1, histo1)
True
>>> equivalent(exp_histo2, histo2)
True
>>> equivalent(histo1, histo2)
False

'''
from __future__ import absolute_import

import os
import ROOT

from .base import Plottable
from .hist import HistStack
from ..io import Directory, DoesNotExist

__all__ = [
    'ScaleView',
    'NormalizeView',
    'StyleView',
    'TitleView',
    'SumView',
    'StackView',
    'FunctorView',
    'MultiFunctorView',
    'PathModifierView',
    'SubdirectoryView',
]


class _FolderView(object):
    '''
    Abstract view of an individual folder

    Provides one interface: Get(path) which returns a modified version
    of whatever exists at path.  Subclasses should define::

        apply_view(self, obj)

    which should return the modified [object] as necessary.

    The subclass can get access to the queried path via the self.getting
    variable.
    '''
    def __init__(self, directory):
        ''' Initialize with the directory to be wrapped '''
        self.dir = directory

    def path(self):
        ''' Get the path of the wrapped folder '''
        if isinstance(self.dir, Directory):
            return self.dir._path
        elif isinstance(self.dir, ROOT.TDirectory):
            return self.dir.GetPath()
        elif isinstance(self.dir, _FolderView):
            return self.dir.path()
        else:
            return str(self.dir)

    def __str__(self):
        return "{0}('{1}')".format(self.__class__.__name__, self.path())

    def Get(self, path):
        ''' Get the (modified) object from path '''
        self.getting = path
        try:
            obj = self.dir.Get(path)
            return self.apply_view(obj)
        except DoesNotExist as dne:
            #print dir(dne)
            raise DoesNotExist(
                str(dne) + "[{0}]".format(self.__class__.__name__))


class _MultiFolderView(object):
    '''
    Abstract view of a collection of folders

    Applies some type of "merge" operation to the result of the get from each
    folder.  Subclasses should define::

        merge_views(self, objects)

    which takes a *generator* of objects returns a merged object.

    The subclass can get access to the queried path via the self.getting
    variable.
    '''
    def __init__(self, *directories):
        self.dirs = directories

    def __str__(self):
        return "{0}({1})".format(
            self.__class__.__name__,
            ','.join(str(x) for x in self.dirs))

    def Get(self, path):
        ''' Merge the objects at path in all subdirectories '''
        return self.merge_views(x.Get(path) for x in self.dirs)


class ScaleView(_FolderView):
    ''' View of a folder which applies a scaling factor to histograms. '''
    def __init__(self, directory, scale_factor):
        super(ScaleView, self).__init__(directory)
        self.factor = scale_factor

    def apply_view(self, obj):
        if not hasattr(obj, 'Scale'):
            raise ValueError(
                "`ScaleView` can't determine how to handle"
                "an object of type `{0}`; "
                "it has no `Scale` method".format(type(obj)))
        clone = obj.Clone()
        clone.Scale(self.factor)
        return clone


class NormalizeView(ScaleView):
    ''' Normalize histograms to a constant value '''
    def __init__(self, directory, normalization=1.0):
        # Initialize the scale view with a dummy scale factor.
        # The scale factor is changed dynamically for each histogram.
        super(NormalizeView, self).__init__(directory, None)
        self.norm = normalization

    def apply_view(self, obj):
        current_norm = obj.Integral()
        # Update the scale factor (in the base)
        if current_norm > 0:
            self.factor = self.norm / current_norm
        else:
            self.factor = 0
        return super(NormalizeView, self).apply_view(obj)


class StyleView(_FolderView):
    '''
    View of a folder which applies a style to Plottable objects.

    The kwargs are passed to Plottable.decorate
    '''
    def __init__(self, directory, **kwargs):
        super(StyleView, self).__init__(directory)
        self.kwargs = kwargs

    def apply_view(self, obj):
        if not isinstance(obj, Plottable):
            raise TypeError(
                "`ScaleView` can't determine how to handle "
                "an object of type `{0}`; it is not a subclass of "
                "`Plottable`".format(type(obj)))
        clone = obj.Clone()
        clone.decorate(**self.kwargs)
        return clone


class TitleView(_FolderView):
    ''' Override the title of gotten histograms '''
    def __init__(self, directory, title):
        self.title = title
        super(TitleView, self).__init__(directory)

    def apply_view(self, obj):
        clone = obj.Clone()
        clone.SetTitle(self.title)
        return clone


class SumView(_MultiFolderView):
    ''' Add a collection of histograms together '''
    def __init__(self, *directories):
        super(SumView, self).__init__(*directories)

    def merge_views(self, objects):
        output = None
        for obj in objects:
            if output is None:
                output = obj.Clone()
            else:
                output += obj
        return output


class StackView(_MultiFolderView):
    '''
    Build a HistStack from the input histograms

    The default draw option that histograms will use is "hist".

    One can override this for all histograms by passing a string.
    Individual behavior can be controlled by passing a list of draw options,
    corresponding to the input directories. In this case the option for
    all histograms must be specified.

    The name and title of the HistStack is taken from the first histogram in
    the list.

    Normally the histograms will be added to the stack in the order
    of the constructor.  Optionally, one can add them in order of ascending
    integral by passing the kwarg sorted=True.
    '''
    def __init__(self, *directories, **kwargs):
        super(StackView, self).__init__(*directories)
        self.sort = kwargs.get(sorted, False)

    def merge_views(self, objects):
        output = None
        if self.sort:
            objects = sorted(objects, key=lambda x: x.Integral())
        for obj in objects:
            if output is None:
                output = HistStack(name=obj.GetName(),
                                   title=obj.GetTitle())
            output.Add(obj)
        return output


class FunctorView(_FolderView):
    '''
    Apply an arbitrary function to the output histogram.

    The histogram is always cloned before it is passed to the function.
    '''
    def __init__(self, directory, function):
        self.f = function
        super(FunctorView, self).__init__(directory)

    def apply_view(self, obj):
        clone = obj.Clone()
        return self.f(clone)


class MultiFunctorView(_MultiFolderView):
    '''
    Apply an arbitrary function to the output histograms.

    The function must take one argument, a generator of objects.
    '''
    def __init__(self, f, *directories):
        self.f = f
        super(MultiFunctorView, self).__init__(*directories)

    def merge_views(self, objects):
        return self.f(objects)


class PathModifierView(_FolderView):
    '''
    Does some magic to the path

    User should supply a functor which transforms the path argument
    passed to Get(...)
    '''
    def __init__(self, dir, path_modifier):
        self.path_modifier = path_modifier
        super(PathModifierView, self).__init__(dir)

    def Get(self, path):
        newpath = self.path_modifier(path)
        return super(PathModifierView, self).Get(newpath)

    def apply_view(self, obj):
        ''' Do nothing '''
        return obj


class SubdirectoryView(PathModifierView):
    '''
    Add some base directories to the path of Get()

    <subdir> is the directory you want to 'cd' too.
    '''
    def __init__(self, dir, subdirpath):
        functor = lambda path: os.path.join(subdirpath, path)
        super(SubdirectoryView, self).__init__(dir, functor)


if __name__ == "__main__":
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = roosh
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import os
import sys
import readline
import cmd
import subprocess
import re
from fnmatch import fnmatch
from glob import glob
import traceback
# Try and get the termcolor module - pip install termcolor
try:
    from termcolor import colored
except ImportError:
    # Make a dummy function which does not color the text
    def colored(text, *args, **kwargs):
        return text

from .extern.argparse import ArgumentParser

from . import ROOT
from . import log; log = log[__name__]
log.basic_config_colorized()
from . import __version__
from .io import root_open, DoesNotExist
from .io.file import _DirectoryBase
from .userdata import DATA_ROOT
from .plotting import Canvas
from .plotting.style import set_style
from .logger.utils import check_tty

__all__ = [
    'ROOSH',
]

EXEC_CMD = re.compile('(?P<name>\w+)\.(?P<call>\S+)')
ASSIGN_CMD = re.compile('\w+\s*((\+=)|(-=)|(=))\s*\w+')
GET_CMD = re.compile('^(?P<name>\S+)(:?\s+as\s+(?P<alias>\S+))?$')

_COLOR_MATCHER = [
    (re.compile('^TH[123][CSIDF]'), 'red'),
    (re.compile('^TTree'), 'green'),
    (re.compile('^TChain'), 'green'),
    (re.compile('^TDirectory'), 'blue'),
]


def color_key(tkey):
    """
    Function which returns a colorized TKey name given its type
    """
    name = tkey.GetName()
    classname = tkey.GetClassName()
    for class_regex, color in _COLOR_MATCHER:
        if class_regex.match(classname):
            return colored(name, color=color)
    return name


def prompt(vars, message):

    prompt_message = message
    try:
        from IPython.Shell import IPShellEmbed
        ipshell = IPShellEmbed(
            argv=[''],
            banner=prompt_message, exit_msg="Goodbye")
        return ipshell
    except ImportError:
        # this doesn't quite work right, in that it doesn't go to the right env
        # so we just fail.
        import code
        import rlcompleter
        readline.parse_and_bind("tab: complete")
        # calling this with globals ensures we can see the environment
        if prompt_message:
            print prompt_message
        shell = code.InteractiveConsole(vars)
        return shell.interact


def ioctl_GWINSZ(fd):

    try:
        import fcntl
        import termios
        import struct
        cr = struct.unpack('hh', fcntl.ioctl(fd, termios.TIOCGWINSZ, '1234'))
    except:
        return None
    return cr


def get_terminal_size():

    cr = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)
    if not cr:
        try:
            fd = os.open(os.ctermid(), os.O_RDONLY)
            cr = ioctl_GWINSZ(fd)
            os.close(fd)
        except:
            pass
    if not cr:
        try:
            cr = (env['LINES'], env['COLUMNS'])
        except:
            cr = (25, 80)
    return int(cr[1]), int(cr[0])


def make_identifier(name):

    # Replace invalid characters with '_'
    name = re.sub('[^0-9a-zA-Z_]', '_', name)

    # Remove leading characters until we find a letter or underscore
    return re.sub('^[^a-zA-Z_]+', '', name)


def is_valid_identifier(name):

    return name == make_identifier(name)


class shell_cmd(cmd.Cmd, object):

    def do_shell(self, s):

        subprocess.call(s, shell=True)

    def help_shell(self):

        print "execute commands in your $SHELL (i.e. bash)"


class empty_cmd(cmd.Cmd, object):

    def emptyline(self):
        pass


class exit_cmd(cmd.Cmd, object):

    def can_exit(self):

        return True

    def onecmd(self, line):

        r = super(exit_cmd, self).onecmd(line)
        if (r and (self.can_exit() or
                   raw_input('exit anyway ? (yes/no):') == 'yes')):
            return True
        return False

    def do_exit(self, s):

        return True

    def help_exit(self):

        print "Exit the interpreter."
        print "You can also use the Ctrl-D shortcut."

    def do_EOF(self, s):

        if not self.script:
            print
        return True

    help_EOF = help_exit


def root_glob(directory, pattern):

    matches = []
    for dirpath, dirnames, filenames in \
            directory.walk(maxdepth=pattern.count(os.path.sep)):
        for dirname in dirnames:
            dirname = os.path.join(dirpath, dirname)
            if fnmatch(dirname, pattern):
                matches.append(dirname)
        for filename in filenames:
            filename = os.path.join(dirpath, filename)
            if fnmatch(filename, pattern):
                matches.append(filename)
    return matches


def show_exception(e, debug=False, show_type=False):

    if debug:
        traceback.print_exception(*sys.exc_info())
    elif show_type:
        print "{0}: {1}".format(e.__class__.__name__, e)
    else:
        print e


class LazyNamespace(dict):

    def __init__(self, roosh):
        self.roosh = roosh
        super(LazyNamespace, self).__init__()

    def __getitem__(self, key):
        if key in self.roosh.pwd:
            value = self.roosh.pwd[key]
            self.__setitem__(key, value)
            return value
        try:
            return super(LazyNamespace, self).__getitem__(key)
        except KeyError as e:
            if key == 'P':
                pad = ROOT.gPad.func()
                if pad:
                    return pad
                raise
            elif key == 'C':
                pad = ROOT.gPad.func()
                if pad:
                    return pad.GetCanvas()
                raise
            elif key == 'D':
                return self.roosh.pwd
            if key in __builtins__:
                return __builtins__[key]
            try:
                return getattr(ROOT, key)
            except AttributeError:
                pass
            raise e


class ROOSH(exit_cmd, shell_cmd, empty_cmd):

    ls_parser = ArgumentParser()
    ls_parser.add_argument('-l', action='store_true',
                           dest='showtype', default=False)
    ls_parser.add_argument('files', nargs='*')

    mkdir_parser = ArgumentParser()
    mkdir_parser.add_argument('-p', action='store_true',
                              dest='recurse', default=False,
                              help="create parent directories as required")
    mkdir_parser.add_argument('paths', nargs='*')

    def __init__(self, filename, mode='READ',
                 stdin=None, stdout=None,
                 script=False,
                 debug=False):

        if stdin is None:
            stdin = sys.stdin
        if stdout is None:
            stdout = sys.stdout
        super(ROOSH, self).__init__(stdin=stdin, stdout=stdout)

        self.script = script
        self.debug = debug

        root_file = root_open(filename, mode)
        self.files = {}
        self.files[filename] = root_file
        self.pwd = root_file
        self.prev_pwd = root_file
        self.current_file = root_file

        self.namespace = LazyNamespace(self)
        if script:
            self.prompt = ''
        else:
            self.__update_prompt()

    def __update_prompt(self):

        if self.script:
            return
        dirname = os.path.basename(self.pwd._path)
        if len(dirname) > 20:
            dirname = (dirname[:10] + '..' + dirname[-10:])
        self.prompt = '{0} > '.format(dirname)

    def do_env(self, s):

        for name, value in self.namespace.items():
            if name == '__builtins__':
                continue
            print name, value

    def help_env(self):

        print "print all variable names and values in current environment"
        print "object (excluding directories) contained within the"
        print "current directory are automatically included by name"

    def do_get(self, name):

        try:
            match = re.match(GET_CMD, name)
            if match:
                name = match.group('name')
                alias = match.group('alias')
                if alias is None:
                    alias = make_identifier(os.path.basename(name))
                # check that alias is a valid identifier
                elif not is_valid_identifier(alias):
                    print "{0} is not a valid identifier".format(alias)
                    return
                self.namespace[alias] = self.pwd.Get(name)
            else:
                self.default(name)
        except DoesNotExist as e:
            show_exception(e, debug=self.debug)

    def complete_get(self, text, line, begidx, endidx):

        return self.completion_helper(text, line, begidx, endidx)

    def help_get(self):

        print (
            "load the specified object into the current namespace\n"
            "Use 'get foo as bar' to alias the object named foo as bar")

    def do_cd(self, path):

        prev_pwd = self.pwd
        if path == '.':
            return
            self.prev_pwd = self.pwd
        try:
            if not path:
                self.pwd = self.current_file
            elif path == '-':
                self.pwd = self.prev_pwd
                self.do_pwd()
            else:
                self.pwd = self.pwd.GetDirectory(path)
            self.pwd.cd()
            self.__update_prompt()
            self.prev_pwd = prev_pwd
        except DoesNotExist as e:
            show_exception(e, debug=self.debug)

    def complete_cd(self, text, line, begidx, endidx):

        return self.completion_helper(
            text, line, begidx, endidx, 'TDirectoryFile')

    def help_cd(self):

        print (
            "change the current directory\n"
            "'cd -' will change to the previous directory\n"
            "'cd' (with no path) will change to the root directory\n")

    def do_ls(self, args=None):

        if args is None:
            args = ''
        args = ROOSH.ls_parser.parse_args(args.split())
        if not args.files:
            args.files = ['']
        for i, path in enumerate(args.files):
            if '*' in path:
                paths = root_glob(self.pwd, path)
                if not paths:
                    paths = [path]
            else:
                paths = [path]
            for path in paths:
                _dir = self.pwd
                if path:
                    try:
                        _dir = self.pwd.Get(path)
                    except DoesNotExist as e:
                        show_exception(e, debug=self.debug)
                        continue
                if isinstance(_dir, _DirectoryBase):
                    if len(args.files) > 1:
                        if i > 0:
                            print
                        print "{0}:".format(_dir.GetName())
                    keys = _dir.keys(latest=True)
                    keys.sort(key=lambda key: key.GetName())
                    things = [color_key(key) for key in keys]
                    if things:
                        self.columnize(things)
                else:
                    print path

    def complete_ls(self, text, line, begidx, endidx):

        return self.completion_helper(text, line, begidx, endidx)

    def help_ls(self):

        print "list items contained in a directory"

    def do_mkdir(self, args=None):

        if args is None:
            args = ''
        args = ROOSH.mkdir_parser.parse_args(args.split())

        for path in args.paths:
            try:
                self.pwd.mkdir(path, recurse=args.recurse)
            except Exception as e:
                show_exception(e, debug=self.debug)

    def complete_mkdir(self, text, line, begidx, endidx):

        return self.completion_helper(text, line, begidx, endidx,
                                      typename='TDirectoryFile')

    def do_rm(self, path):

        try:
            self.pwd.rm(path)
        except Exception as e:
            show_exception(e, debug=self.debug)

    def complete_rm(self, text, line, begidx, endidx):

        return self.completion_helper(text, line, begidx, endidx)

    def do_cp(self, args):
        try:
            thing, dest = args.split()
            self.pwd.copytree(dest, src=thing)
        except Exception as e:
            show_exception(e, debug=self.debug)

    def complete_cp(self, text, line, begidx, endidx):

        return self.completion_helper(text, line, begidx, endidx)

    def completion_helper(self, text, line, begidx, endidx, typename=None):

        things = []
        directory = self.pwd
        head = ''
        if begidx != endidx:
            prefix = line[begidx: endidx]
            head, prefix = os.path.split(prefix)
            if head:
                try:
                    directory = directory.GetDirectory(head)
                except DoesNotExist:
                    return []
        else:
            prefix = ''
        for key in directory.GetListOfKeys():
            if typename is not None:
                if key.GetClassName() != typename:
                    continue
            name = key.GetName()
            if prefix and not name.startswith(prefix):
                continue
            if key.GetClassName() == 'TDirectoryFile':
                things.append(os.path.join(head, '{0}/'.format(name)))
            else:
                things.append(os.path.join(head, name))
        return things

    def do_pwd(self, s=None):

        print self.pwd._path

    def help_pwd(self):

        print "print the current directory"

    def help_help(self):

        print "'help CMD' will print help for a command"
        print "'help' will print all available commands"

    def do_python(self, s=None):

        prompt(self.namespace, '')()

    def help_python(self):

        print "drop into an interactive Python shell"
        print "anything loaded into your current namespace"
        print "will be handed over to Python"

    @property
    def current_pad(self):
        pad = ROOT.gPad.func()
        if pad:
            return pad
        return None

    @property
    def current_canvas(self):
        pad = self.current_pad
        if pad:
            return pad.GetCanvas()
        return None

    @property
    def canvases(self):
        return ROOT.gROOT.GetListOfCanvases()

    def do_canvas(self, name=None):

        current_pad = self.current_pad
        current_canvas = self.current_canvas
        canvases = self.canvases

        if not name:
            # print list of existing canvases
            if not current_pad:
                print ("no canvases exist, create a new one by "
                       "specifying name: canvas mycanvas")
                return
            for c in canvases:
                if c is current_canvas:
                    print "* {0}".format(c.GetName())
                else:
                    print "  {0}".format(c.GetName())
            return

        for c in canvases:
            if c.GetName() == name:
                c.cd()
                print "switching to previous canvas '{0}'".format(name)
                return

        print "switching to new canvas '{0}'".format(name)
        canvas = Canvas(name=name, title=name)
        canvas.cd()

    def help_canvas(self):

        print "switch to a new or previous canvas"

    def complete_canvas(self, text, line, begidx, endidx):

        names = []
        if begidx != endidx:
            prefix = line[begidx: endidx]
        else:
            prefix = ''
        for c in self.canvases:
            name = c.GetName()
            if prefix and not name.startswith(prefix):
                continue
            names.append(name)
        return names

    def do_clear(self, *args):

        canvas = self.current_canvas
        if canvas is not None:
            canvas.Clear()
            canvas.Update()

    def help_clear(self):

        print "clear the current canvas"

    @property
    def styles(self):
        return ROOT.gROOT.GetListOfStyles()

    @property
    def current_style(self):
        return ROOT.gStyle

    def do_style(self, name):

        current_style = self.current_style
        styles = self.styles
        if not name:
            # print list of existing styles
            for s in styles:
                if s.GetName() == current_style.GetName():
                    print "* {0}".format(s.GetName())
                else:
                    print "  {0}".format(s.GetName())
            return
        try:
            set_style(name)
        except ValueError as e:
            show_exception(e)
        else:
            canvas = self.current_canvas
            if canvas is not None:
                canvas.UseCurrentStyle()
                canvas.Modified()
                canvas.Update()
                canvas.Modified()
                canvas.Update()

    def complete_style(self, text, line, begidx, endidx):

        names = []
        if begidx != endidx:
            prefix = line[begidx: endidx]
        else:
            prefix = ''
        if not prefix:
            return names
        for s in self.styles:
            name = s.GetName()
            if name.startswith(prefix) or name.lower().startswith(prefix):
                names.append(name)
        return names

    def help_style(self):

        print "set the current style"

    def do_roosh(self, filename=None):

        if not filename:
            for name, rfile in self.files.items():
                if rfile is self.current_file:
                    print "* {0}".format(name)
                else:
                    print "  {0}".format(name)
            return
        if not os.path.isfile(filename):
            print "file '{0}' does not exist".format(filename)
            return
        prev_pwd = self.pwd
        if filename not in self.files:
            print "switching to new file {0}".format(filename)
            rfile = root_open(filename)
            self.files[filename] = rfile
        else:
            print "switching to previous file {0}".format(filename)
            rfile = self.files[filename]
        self.pwd = rfile
        self.current_file = rfile
        self.pwd.cd()
        self.__update_prompt()
        self.prev_pwd = prev_pwd

    def help_roosh(self):

        print "switch to a new or previous file"

    def complete_roosh(self, text, line, begidx, endidx):

        names = []
        if begidx != endidx:
            prefix = line[begidx: endidx]
        else:
            prefix = ''
        for name in glob(prefix + '*'):
            if os.path.isdir(name) or fnmatch(name, '*.root*'):
                names.append(name)
        if len(names) == 1 and os.path.isdir(names[0]):
            names[0] = os.path.normpath(names[0]) + os.path.sep
        return names

    def completenames(self, text, *ignored):

        dotext = 'do_' + text
        cmds = [a[3:] for a in self.get_names() if a.startswith(dotext)]
        objects = [
            key.name for key in self.pwd.keys() if key.name.startswith(text)]
        return cmds + objects

    def completedefault(self, text, line, begidx, endidx):

        return self.completion_helper(text, line, begidx, endidx)

    def default(self, line):

        if line.lstrip().startswith('#'):
            return
        try:
            if not re.match(ASSIGN_CMD, line):
                line = line.strip()
                if (not line.startswith('print') and
                        not line.startswith('from ') and
                        not line.startswith('import ') and
                        not line.startswith('with ') and
                        not line.startswith('if ')):
                    line = '__ = ' + line
            exec line in self.namespace
            if '__' in self.namespace:
                if self.namespace['__'] is not None:
                    print repr(self.namespace['__'])
                del self.namespace['__']
            return
        except Exception as e:
            show_exception(e, debug=self.debug, show_type=True)
            return
        return super(ROOSH, self).default(line)


def main():

    parser = ArgumentParser()
    parser.add_argument('--version', action='version',
                        version=__version__,
                        help="show the version number and exit")
    parser.add_argument('script', nargs='?', default=None,
                        help="read input from this file instead of stdin")
    parser.add_argument('-l', action='store_true',
                        dest='nointro', default=False,
                        help="don't print the intro message")
    parser.add_argument('-u', '--update', action='store_true', default=False,
                        help="open the file in UPDATE mode (default: READ)")
    parser.add_argument('-d', '--debug', action='store_true', default=False,
                        help="print stack traces")
    parser.add_argument('filename', help="a ROOT file")
    parser.add_argument('libs', nargs='*',
                        help="libraries required to read "
                            "contents of the ROOT file")
    args = parser.parse_args()

    if not os.path.isfile(args.filename) and not args.update:
        sys.exit("File {0} does not exist".format(args.filename))

    if args.libs:
        for lib in args.libs:
            log.info("loading {0}".format(lib))
            ROOT.gSystem.Load(lib)

    history_file = os.path.join(DATA_ROOT, 'roosh_history')
    if os.path.exists(history_file):
        readline.read_history_file(history_file)
    history_size = os.getenv('ROOSH_HISTORY_SIZE', 500)
    readline.set_history_length(history_size)

    try:
        if args.script is not None:
            scriptmode = True
            stdin = open(args.script, 'r')
        else:
            scriptmode = False
            stdin = sys.stdin

        terminal = ROOSH(
            args.filename,
            mode='UPDATE' if args.update else 'READ',
            stdin=stdin,
            script=scriptmode,
            debug=args.debug)

        if scriptmode:
            terminal.use_rawinput = False

        if args.nointro or scriptmode:
            terminal.cmdloop()
        else:
            terminal.cmdloop(
                "Welcome to the ROOSH terminal\ntype help for help")
        if not scriptmode:
            readline.write_history_file(history_file)
    except Exception as e:
        if not scriptmode:
            readline.write_history_file(history_file)
        show_exception(e, debug=args.debug)
        sys.exit(e)

########NEW FILE########
__FILENAME__ = ROOT
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
:py:mod:`rootpy.ROOT`
=====================

This module is intended to be a drop-in replacement for ordinary
PyROOT imports by mimicking PyROOT's interface. If you find a case where it is
not, please report an issue to the rootpy developers.

Both ROOT and rootpy classes can be accessed in a harmonized way through this
module. This means you can take advantage of rootpy classes automatically by
replacing ``import ROOT`` with ``import rootpy.ROOT as ROOT`` or
``from rootpy import ROOT`` in your code, while maintaining backward
compatibility with existing use of ROOT's classes.

ROOT classes are automatically "asrootpy'd" *after* the constructor in ROOT has
been called:

.. sourcecode:: python

   >>> import rootpy.ROOT as ROOT
   >>> h = ROOT.TH1F('name', 'title', 10, 0, 1)
   >>> h
   Hist('name')
   >>> h.TYPE
   'F'

Also access rootpy classes under this same module without needing to remember
where to import them from in rootpy:

.. sourcecode:: python

   >>> import rootpy.ROOT as ROOT
   >>> h = ROOT.Hist(10, 0, 1, name='name', type='F')
   >>> h
   Hist('name')
   >>> h.TYPE
   'F'

Plain old ROOT can still be accessed through the ``R`` property:

.. sourcecode:: python

   >>> from rootpy import ROOT
   >>> ROOT.R.TFile
   <class 'ROOT.TFile'>

"""
from __future__ import absolute_import

from copy import copy

import ROOT

from . import asrootpy, lookup_rootpy, ROOT_VERSION
from . import QROOT, stl
from .utils.module_facade import Facade

__all__ = []


def proxy_global(name, no_expand_macro=False):
    """
    Used to automatically asrootpy ROOT's thread local variables
    """
    if no_expand_macro:
        # handle older ROOT versions without _ExpandMacroFunction wrapping
        @property
        def gSomething_no_func(self):
            glob = self(getattr(ROOT, name))
            # create a fake func() that just returns self
            def func():
                return glob
            glob.func = func
            return glob
        return gSomething_no_func

    @property
    def gSomething(self):
        glob = getattr(ROOT, name)
        orig_func = glob.func

        def asrootpy_izing_func():
            return self(orig_func())

        new_glob = copy(glob)
        new_glob.func = asrootpy_izing_func
        # Memoize
        setattr(type(self), name, new_glob)
        return new_glob
    return gSomething


@Facade(__name__, expose_internal=False)
class Module(object):

    __version__ = ROOT_VERSION

    def __call__(self, arg, after_init=False):
        return asrootpy(arg, warn=False, after_init=after_init)

    def __getattr__(self, what):
        try:
            # check ROOT
            result = self(getattr(ROOT, what), after_init=True)
        except AttributeError:
            # check rootpy
            result = lookup_rootpy(what)
            if result is None:
                raise AttributeError(
                    'ROOT does not have the attribute `{0}` '
                    'and rootpy does not contain the class `{0}`'.format(what))
            return result

        # Memoize
        setattr(self, what, result)
        return result

    @property
    def R(self):
        return ROOT

    gPad = proxy_global("gPad")
    gVirtualX = proxy_global("gVirtualX")

    if ROOT_VERSION < (5, 32, 0):
        # handle versions of ROOT older than 5.32.00
        gDirectory = proxy_global("gDirectory", no_expand_macro=True)
        gFile = proxy_global("gFile", no_expand_macro=True)
        gInterpreter = proxy_global("gInterpreter", no_expand_macro=True)
    else:
        gDirectory = proxy_global("gDirectory")
        gFile = proxy_global("gFile")
        gInterpreter = proxy_global("gInterpreter")

    # use the smart template STL types from rootpy.stl instead
    for t in QROOT.std.stlclasses:
        locals()[t] = getattr(stl, t)
    del t

########NEW FILE########
__FILENAME__ = root2hdf5
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module handles conversion of ROOT's TFile and
contained TTrees into HDF5 format with PyTables
"""
from __future__ import absolute_import

import os
import sys
import warnings
import pkg_resources

import tables
TABLES_NEW_API = int(pkg_resources.parse_version(tables.__version__)[0]) >= 3
if TABLES_NEW_API:
    tables_open = tables.open_file
else:
    tables_open = tables.openFile

from root_numpy import tree2rec, RootNumpyUnconvertibleWarning
from numpy.lib import recfunctions

from .io import root_open, TemporaryFile
from . import log; log = log[__name__]
from .extern.progressbar import ProgressBar, Bar, ETA, Percentage
from .logger.utils import check_tty

__all__ = [
    'root2hdf5',
]


def _drop_object_col(rec, warn=True):
    # ignore columns of type `object` since PyTables does not support these
    if rec.dtype.hasobject:
        object_fields = []
        fields = rec.dtype.fields
        for name in rec.dtype.names:
            if fields[name][0].kind == 'O':
                object_fields.append(name)
                if warn:
                    log.warning(
                        "ignoring unsupported object branch '{0}'".format(
                            name))
        # NumPy 1.7.1: TypeError: Cannot change data-type for object array.
        #return rec[non_object_fields]
        if object_fields:
            rec = recfunctions.rec_drop_fields(rec, object_fields)
    return rec


def root2hdf5(rfile, hfile, rpath='',
              entries=-1, userfunc=None,
              selection=None,
              show_progress=False):
    """
    Convert all trees in a ROOT file into tables in an HDF5 file.

    Parameters
    ----------

    rfile : string or asrootpy'd ROOT File
        A ROOT File handle or string path to an existing ROOT file.

    hfile : string or PyTables HDF5 File
        A PyTables HDF5 File handle or string path to an existing HDF5 file.

    rpath : string, optional (default='')
        Top level path to begin traversal through the ROOT file. By default
        convert everything in and below the root directory.

    entries : int, optional (default=-1)
        The number of entries to read at once while converting a ROOT TTree
        into an HDF5 table. By default read the entire TTree into memory (this
        may not be desired if your TTrees are large).

    userfunc : callable, optional (default=None)
        A function that will be called on every tree and that must return a
        tree or list of trees that will be converted instead of the original
        tree.

    selection : string, optional (default=None)
        A ROOT selection expression to be applied on all trees before
        conversion.

    show_progress : bool, optional (default=False)
        If True, then display and update a progress bar on stdout as each tree
        is converted.

    """
    show_progress = show_progress and check_tty(sys.stdout)
    if show_progress:
        widgets = [Percentage(), ' ', Bar(), ' ', ETA()]

    own_rootfile = False
    if isinstance(rfile, basestring):
        rfile = root_open(rfile)
        own_rootfile = True

    own_h5file = False
    if isinstance(hfile, basestring):
        hfile = tables_open(filename=hfile, mode="w", title="Data")
        own_h5file = True

    for dirpath, dirnames, treenames in rfile.walk(
            rpath, class_pattern='TTree'):

        # skip root
        if not dirpath and not treenames:
            continue

        # skip directories w/o trees or subdirs
        if not dirnames and not treenames:
            continue

        where_group = '/' + os.path.dirname(dirpath)
        current_dir = os.path.basename(dirpath)

        if not current_dir:
            group = hfile.root
        else:
            group = hfile.createGroup(where_group, current_dir, "")

        ntrees = len(treenames)
        log.info(
            "Will convert {0:d} tree{1} in this directory".format(
                ntrees, 's' if ntrees != 1 else ''))

        for treename in treenames:

            input_tree = rfile.Get(os.path.join(dirpath, treename))

            if userfunc is not None:
                tmp_file = TemporaryFile()
                # call user-defined function on tree and get output trees
                log.info("Calling user function on tree '{0}'".format(
                    input_tree.GetName()))
                trees = userfunc(input_tree)

                if not isinstance(trees, list):
                    trees = [trees]

            else:
                trees = [input_tree]
                tmp_file = None

            for tree in trees:

                log.info("Converting tree '{0}' with {1:d} entries ...".format(
                    tree.GetName(),
                    tree.GetEntries()))

                if tree.GetName() in group:
                    log.warning(
                        "skipping tree '{0}' that already exists "
                        "in the output file".format(tree.GetName()))
                    continue

                total_entries = tree.GetEntries()
                pbar = None
                if show_progress and total_entries > 0:
                    pbar = ProgressBar(widgets=widgets, maxval=total_entries)

                if entries <= 0:
                    # read the entire tree
                    if pbar is not None:
                        pbar.start()
                    recarray = tree2rec(tree, selection=selection)
                    recarray = _drop_object_col(recarray)
                    if TABLES_NEW_API:
                        table = hfile.create_table(
                            group, tree.GetName(),
                            recarray, tree.GetTitle())
                    else:
                        table = hfile.createTable(
                            group, tree.GetName(),
                            recarray, tree.GetTitle())
                    # flush data in the table
                    table.flush()
                    # flush all pending data
                    hfile.flush()
                else:
                    # read the tree in chunks
                    start = 0
                    while start < total_entries or start == 0:
                        if start > 0:
                            with warnings.catch_warnings():
                                warnings.simplefilter(
                                    "ignore",
                                    RootNumpyUnconvertibleWarning)
                                warnings.simplefilter(
                                    "ignore",
                                    tables.NaturalNameWarning)
                                recarray = tree2rec(
                                    tree,
                                    selection=selection,
                                    start=start,
                                    stop=start + entries)
                            recarray = _drop_object_col(recarray, warn=False)
                            table.append(recarray)
                        else:
                            recarray = tree2rec(
                                tree,
                                selection=selection,
                                start=start,
                                stop=start + entries)
                            recarray = _drop_object_col(recarray)
                            if pbar is not None:
                                # start after any output from root_numpy
                                pbar.start()
                            if TABLES_NEW_API:
                                table = hfile.create_table(
                                    group, tree.GetName(),
                                    recarray, tree.GetTitle())
                            else:
                                table = hfile.createTable(
                                    group, tree.GetName(),
                                    recarray, tree.GetTitle())
                        start += entries
                        if start <= total_entries and pbar is not None:
                            pbar.update(start)
                        # flush data in the table
                        table.flush()
                        # flush all pending data
                        hfile.flush()

                if pbar is not None:
                    pbar.finish()

            input_tree.Delete()

            if userfunc is not None:
                for tree in trees:
                    tree.Delete()
                tmp_file.Close()

    if own_h5file:
        hfile.close()
    if own_rootfile:
        rfile.Close()


def main():

    import rootpy
    from rootpy.extern.argparse import (
        ArgumentParser,
        ArgumentDefaultsHelpFormatter, RawTextHelpFormatter)

    class formatter_class(ArgumentDefaultsHelpFormatter,
                          RawTextHelpFormatter):
        pass

    parser = ArgumentParser(formatter_class=formatter_class,
        description="Convert ROOT files containing TTrees into HDF5 files "
                    "containing HDF5 tables")
    parser.add_argument('--version', action='version',
                        version=rootpy.__version__,
                        help="show the version number and exit")
    parser.add_argument('-n', '--entries', type=int, default=100000,
                        help="number of entries to read at once")
    parser.add_argument('-f', '--force', action='store_true', default=False,
                        help="overwrite existing output files")
    parser.add_argument('-u', '--update', action='store_true', default=False,
                        help="update existing output files")
    parser.add_argument('--ext', default='h5',
                        help="output file extension")
    parser.add_argument('-c', '--complevel', type=int, default=5,
                        choices=range(0, 10),
                        help="compression level")
    parser.add_argument('-l', '--complib', default='zlib',
                        choices=('zlib', 'lzo', 'bzip2', 'blosc'),
                        help="compression algorithm")
    parser.add_argument('-s', '--selection', default=None,
                        help="apply a selection on each "
                             "tree with a cut expression")
    parser.add_argument(
        '--script', default=None,
        help="Python script containing a function with the same name \n"
             "that will be called on each tree and must return a tree or \n"
             "list of trees that will be converted instead of the \n"
             "original tree")
    parser.add_argument('-q', '--quiet', action='store_true', default=False,
                        help="suppress all warnings")
    parser.add_argument('--no-progress-bar', action='store_true', default=False,
                        help="do not show the progress bar")
    parser.add_argument('files', nargs='+')
    args = parser.parse_args()

    rootpy.log.basic_config_colorized()
    import logging
    if hasattr(logging, 'captureWarnings'):
        logging.captureWarnings(True)

    def formatwarning(message, category, filename, lineno, line=None):
        return "{0}: {1}".format(category.__name__, message)

    warnings.formatwarning = formatwarning
    args.ext = args.ext.strip('.')

    if args.quiet:
        warnings.simplefilter(
            "ignore",
            RootNumpyUnconvertibleWarning)
        warnings.simplefilter(
            "ignore",
            tables.NaturalNameWarning)

    userfunc = None
    if args.script is not None:
        # get user-defined function
        try:
            exec(compile(open(args.script).read(), args.script, 'exec'),
                 globals(), locals())
        except IOError:
            sys.exit('Could not open script {0}'.format(args.script))
        funcname = os.path.splitext(os.path.basename(args.script))[0]
        try:
            userfunc = locals()[funcname]
        except KeyError:
            sys.exit(
                "Could not find the function '{0}' in the script {1}".format(
                    funcname, args.script))

    for inputname in args.files:
        outputname = os.path.splitext(inputname)[0] + '.' + args.ext
        output_exists = os.path.exists(outputname)
        if output_exists and not (args.force or args.update):
            sys.exit(
                "Output {0} already exists. "
                "Use the --force option to overwrite it".format(outputname))
        try:
            rootfile = root_open(inputname)
        except IOError:
            sys.exit("Could not open {0}".format(inputname))
        try:
            if args.complevel > 0:
                filters = tables.Filters(complib=args.complib,
                                         complevel=args.complevel)
            else:
                filters = None
            hd5file = tables_open(filename=outputname,
                                  mode='a' if args.update else 'w',
                                  title='Data', filters=filters)
        except IOError:
            sys.exit("Could not create {0}".format(outputname))
        try:
            log.info("Converting {0} ...".format(inputname))
            root2hdf5(rootfile, hd5file,
                      entries=args.entries,
                      userfunc=userfunc,
                      selection=args.selection,
                      show_progress=not args.no_progress_bar)
            log.info("{0} {1}".format(
                "Updated" if output_exists and args.update else "Created",
                outputname))
        except KeyboardInterrupt:
            log.info("Caught Ctrl-c ... cleaning up")
            os.unlink(outputname)
            break
        finally:
            hd5file.close()
            rootfile.Close()

########NEW FILE########
__FILENAME__ = category
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from . import log; log = log[__name__]
from .. import QROOT, asrootpy
from ..base import NamedObject
from .value import AbsArg

__all__ = [
    'CatType',
    'Category',
]


class CatType(NamedObject, QROOT.RooCatType):
    _ROOT = QROOT.RooCatType

    @property
    def value(self):
        return self.getVal()

    @value.setter
    def value(self, val):
        self.setVal(val)


class Category(NamedObject, AbsArg, QROOT.RooCategory):
    _ROOT = QROOT.RooCategory

    @property
    def index(self):
        return self.getIndex()

    @index.setter
    def index(self, value):
        return self.setIndex(value)

    @property
    def label(self):
        return self.getLabel()

    @index.setter
    def label(self, value):
        return self.setLabel(value)

########NEW FILE########
__FILENAME__ = collection
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from . import log; log = log[__name__]
from ..base import Object
from .. import QROOT, asrootpy

__all__ = [
    'ArgSet',
    'ArgList',
]


class _CollectionBase(object):

    def __getitem__(self, name):
        thing = self.find(name)
        if thing == None:
            raise ValueError(
                "argument '{0}' is not contained "
                "in the RooArgSet '{1}'".format(name, self.GetName()))
        return asrootpy(thing, warn=False)

    def __contains__(self, value):
        if isinstance(value, basestring):
            try:
                thing = self[value]
            except ValueError:
                return False
            return True
        # RooAbsArg
        return self.contains(value)

    def __iter__(self):
        start = self.fwdIterator()
        for i in xrange(len(self)):
            yield asrootpy(start.next(), warn=False)

    def __len__(self):
        return self.getSize()

    def __eq__(self, other):
        return self.equals(other)

    def find(self, name):
        thing = super(_CollectionBase, self).find(name)
        if thing == None:
            return None
        return asrootpy(thing, warn=False)

    def first(self):
        thing = super(_CollectionBase, self).first()
        if thing == None:
            return None
        return asrootpy(thing, warn=False)


class ArgSet(_CollectionBase, Object, QROOT.RooArgSet):
    _ROOT = QROOT.RooArgSet


class ArgList(_CollectionBase, Object, QROOT.RooArgList):
    _ROOT = QROOT.RooArgList

########NEW FILE########
__FILENAME__ = correlated_values
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import uncertainties as U

from .. import asrootpy

__all__ = [
    'as_ufloat',
    'correlated_values',
]


def as_ufloat(roorealvar):
    """
    Cast a `RooRealVar` to an `uncertainties.ufloat`
    """
    if isinstance(roorealvar, (U.AffineScalarFunc, U.Variable)):
        return roorealvar
    return U.ufloat((roorealvar.getVal(), roorealvar.getError()))


def correlated_values(param_names, roofitresult):
    """
    Return symbolic values from a `RooFitResult` taking into account covariance

    This is useful for numerically computing the uncertainties for expressions
    using correlated values arising from a fit.

    Parameters
    ----------

    param_names: list of strings
        A list of parameters to extract from the result. The order of the names
        is the order of the return value.

    roofitresult : RooFitResult
        A RooFitResult from a fit.

    Returns
    -------

    list of correlated values from the uncertainties package.

    Examples
    --------

    .. sourcecode:: python

        # Fit a pdf to a histogram
        pdf = some_roofit_pdf_with_variables("f(x, a, b, c)")
        fitresult = pdf.fitTo(histogram, ROOT.RooFit.Save())
        a, b, c = correlated_values(["a", "b", "c"], fitresult)
        # Arbitrary math expression according to what the `uncertainties`
        # package supports, automatically computes correct error propagation
        sum_value = a + b + c
        value, error = sum_value.nominal_value, sum_value.std_dev()

    """
    pars = roofitresult.floatParsFinal()
    #pars.Print()
    pars = [pars[i] for i in range(pars.getSize())]
    parnames = [p.GetName() for p in pars]

    values = [(p.getVal(), p.getError()) for p in pars]
    #values = [as_ufloat(p) for p in pars]
    matrix = asrootpy(roofitresult.correlationMatrix()).to_numpy()

    uvalues = U.correlated_values_norm(values, matrix.tolist())
    uvalues = dict((n, v) for n, v in zip(parnames, uvalues))

    assert all(n in uvalues for n in parnames), (
        "name {0} isn't in parameter list {1}".format(n, parnames))

    # Return a tuple in the order it was asked for
    return tuple(uvalues[n] for n in param_names)

########NEW FILE########
__FILENAME__ = dataset
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from . import log; log = log[__name__]
from .. import QROOT, asrootpy
from ..base import NamedObject

__all__ = [
    'DataSet',
]


class DataSet(NamedObject, QROOT.RooDataSet):
    _ROOT = QROOT.RooDataSet

    def createHistogram(self, *args, **kwargs):
        if args and isinstance(args[0], basestring):
            return ROOT.RooAbsData.createHistogram(self, *args, **kwargs)
        return super(DataSet, self).createHistogram(*args, **kwargs)

    def reduce(self, *args, **kwargs):
        return asrootpy(super(DataSet, self).reduce(*args, **kwargs))

########NEW FILE########
__FILENAME__ = fit
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from . import log; log = log[__name__]
from .. import QROOT, asrootpy

__all__ = [
    'minimize',
    'Minimizer',
    'FitResult',
]


def minimize(func,
             minimizer_type=None,
             minimizer_algo=None,
             strategy=None,
             retry=0,
             scan=False,
             print_level=None):
    """
    Minimize a RooAbsReal function

    Parameters
    ----------

    func : RooAbsReal
        The function to minimize

    minimizer_type : string, optional (default=None)
        The minimizer type: "Minuit" or "Minuit2".
        If None (the default) then use the current global default value.

    minimizer_algo : string, optional (default=None)
        The minimizer algorithm: "Migrad", etc.
        If None (the default) then use the current global default value.

    strategy : int, optional (default=None)
        Set the MINUIT strategy. Accepted values
        are 0, 1, and 2 and represent MINUIT strategies for dealing
        most efficiently with fast FCNs (0), expensive FCNs (2)
        and 'intermediate' FCNs (1). If None (the default) then use
        the current global default value.

    retry : int, optional (default=0)
        Number of times to retry failed minimizations. The strategy is
        incremented to a maximum of 2 from its initial value and remains at 2
        for additional retries.

    scan : bool, optional (default=False)
        If True then run Minuit2's scan algorithm before running the main
        ``minimizer_algo`` ("Migrad").

    print_level : int, optional (default=None)
        The verbosity level for the minimizer algorithm.
        If None (the default) then use the global default print level.
        If negative then all non-fatal messages will be suppressed.

    Returns
    -------

    minimizer : RooMinimizer
        The minimizer. Get the RooFitResult with ``minimizer.save()``.

    """
    llog = log['minimize']

    min_opts = ROOT.Math.MinimizerOptions
    if minimizer_type is None:
        minimizer_type = min_opts.DefaultMinimizerType()
    if minimizer_algo is None:
        minimizer_algo = min_opts.DefaultMinimizerAlgo()
    if strategy is None:
        strategy = min_opts.DefaultStrategy()
    if print_level is None:
        print_level = min_opts.DefaultPrintLevel()

    if print_level < 0:
        msg_service = ROOT.RooMsgService.instance()
        msg_level = msg_service.globalKillBelow()
        msg_service.setGlobalKillBelow(ROOT.RooFit.FATAL)

    minim = Minimizer(func)
    minim.setPrintLevel(print_level)
    minim.setStrategy(strategy)

    if scan:
        llog.info("running scan algorithm ...")
        minim.minimize('Minuit2', 'Scan')

    llog.info("minimizing with {0} {1} using strategy {2}".format(
        minimizer_type, minimizer_algo, strategy))
    status = minim.minimize(minimizer_type, minimizer_algo)

    iretry = 0
    while iretry < retry and status not in (0, 1):
        if strategy < 2:
            strategy += 1
            minim.setStrategy(strategy)
        llog.warning("minimization failed with status {0:d}".format(status))
        llog.info("retrying minimization with strategy {0:d}".format(strategy))
        status = minim.minimize(minimizer_type, minimizer_algo)

    if status in (0, 1):
        llog.info("found minimum")
    else:
        llog.warning("minimization failed with status {0:d}".format(status))

    if print_level < 0:
        msg_service.setGlobalKillBelow(msg_level)

    return minim


class Minimizer(QROOT.RooMinimizer):
    _ROOT = QROOT.RooMinimizer

    def save(self, *args, **kwargs):
        return asrootpy(super(Minimizer, self).save(*args, **kwargs))


class FitResult(QROOT.RooFitResult):
    _ROOT = QROOT.RooFitResult

    @property
    def covariance(self):
        return asrootpy(super(FitResult, self).covarianceMatrix())

    @property
    def correlation(self):
        return asrootpy(super(FitResult, self).correlationMatrix())

    def reduced_covariance(self, params):
        return asrootpy(
            super(FitResult, self).reducedCovarianceMatrix(params))

    def conditional_covariance(self, params):
        return asrootpy(
            super(FitResult, self).conditionalCovarianceMatrix(params))

########NEW FILE########
__FILENAME__ = histfactory
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from math import sqrt

import ROOT

from . import log; log = log[__name__]
from . import MIN_ROOT_VERSION
from ...memory.keepalive import keepalive
from ...base import NamedObject
from ... import asrootpy, QROOT, ROOT_VERSION

if ROOT_VERSION < MIN_ROOT_VERSION:
    raise NotImplementedError(
        "histfactory requires ROOT {0} but you are using {1}".format(
            MIN_ROOT_VERSION, ROOT_VERSION))

__all__ = [
    'Data',
    'Sample',
    'HistoSys',
    'HistoFactor',
    'NormFactor',
    'OverallSys',
    'ShapeFactor',
    'ShapeSys',
    'Channel',
    'Measurement',
]


class _Named(object):

    @property
    def name(self):
        return self.GetName()

    @name.setter
    def name(self, n):
        self.SetName(n)

    def __str__(self):

        return self.__repr__()

    def __repr__(self):

        return "{0}('{1}')".format(
            self.__class__.__name__, self.GetName())


class _HistNamePathFile(object):

    @property
    def hist_name(self):
        return self.GetHistoName()

    @hist_name.setter
    def hist_name(self, name):
        self.SetHistoName(name)

    @property
    def hist_path(self):
        return self.GetHistoPath()

    @hist_path.setter
    def hist_path(self, path):
        self.SetHistoPath(path)

    @property
    def hist_file(self):
        return self.GetInputFile()

    @hist_file.setter
    def hist_file(self, infile):
        self.SetInputFile(infile)


class _SampleBase(_Named, _HistNamePathFile):

    def SetHisto(self, hist):
        super(_SampleBase, self).SetHisto(hist)
        self.SetHistoName(hist.name)
        keepalive(self, hist)

    def GetHisto(self):
        hist = super(_SampleBase, self).GetHisto()
        # NULL pointer check
        if hist == None:
            return None
        return asrootpy(hist)

    @property
    def hist(self):
        return self.GetHisto()

    @hist.setter
    def hist(self, h):
        self.SetHisto(h)

    def __add__(self, other):
        if self.name != other.name:
            raise ValueError("attempting to add samples with different names")
        hist1 = self.GetHisto()
        hist2 = other.GetHisto()
        sample = self.__class__(self.name)
        if hist1 is not None and hist2 is not None:
            hist3 = hist1 + hist2
            hist3.name = '{0}_plus_{1}'.format(hist1.name, hist2.name)
            sample.SetHisto(hist3)
        return sample


class Data(_SampleBase, QROOT.RooStats.HistFactory.Data):
    _ROOT = QROOT.RooStats.HistFactory.Data

    def __init__(self, name, hist=None):
        # require a name
        super(Data, self).__init__()
        self.name = name
        if hist is not None:
            self.SetHisto(hist)

    def total(self, xbin1=1, xbin2=-2):
        """
        Return the total yield and its associated statistical uncertainty.
        """
        return self.hist.integral(xbin1=xbin1, xbin2=xbin2, error=True)

    def Clone(self):
        clone = Data(self.name)
        hist = self.hist
        if hist is not None:
            clone.hist = hist.Clone(shallow=True)
        return clone


class Sample(_SampleBase, QROOT.RooStats.HistFactory.Sample):
    _ROOT = QROOT.RooStats.HistFactory.Sample

    def __init__(self, name, hist=None):
        # require a sample name
        super(Sample, self).__init__(name)
        if hist is not None:
            self.SetHisto(hist)

    def __add__(self, other):

        if self.GetHistoFactorList() or other.GetHistoFactorList():
            raise NotImplementedError(
                "Samples cannot be summed if "
                "they contain HistoFactors")

        if self.GetShapeFactorList() or other.GetShapeFactorList():
            raise NotImplementedError(
                "Samples cannot be summed if "
                "they contain ShapeFactors")

        if self.GetShapeSysList() or other.GetShapeSysList():
            raise NotImplementedError(
                "Samples cannot be summed if "
                "they contain ShapeSys")

        if self.GetNormalizeByTheory() != other.GetNormalizeByTheory():
            raise ValueError(
                "attempting to sum samples with "
                "inconsistent NormalizeByTheory")

        sample = super(Sample, self).__add__(other)
        sample.SetNormalizeByTheory(self.GetNormalizeByTheory())

        # sum the histosys
        syslist1 = self.GetHistoSysList()
        syslist2 = other.GetHistoSysList()
        if len(syslist1) != len(syslist2):
            raise ValueError(
                "attempting to sum Samples with HistoSys lists of "
                "differing lengths")
        for sys1, sys2 in zip(syslist1, syslist2):
            sample.AddHistoSys(sys1 + sys2)

        # include the overallsys
        overall1 = self.GetOverallSysList()
        overall2 = other.GetOverallSysList()
        if len(overall1) != len(overall2):
            raise ValueError(
                "attempting to sum Samples with OverallSys lists of "
                "differing lengths")
        for o1, o2 in zip(overall1, overall2):
            if o1.name != o2.name:
                raise ValueError(
                    "attempting to sum Samples containing OverallSys "
                    "with differing names: {0}, {1}".format(
                        o1.name, o2.name))
            # TODO check equality of value, low and high
            sample.AddOverallSys(o1)

        # include the normfactors
        norms1 = self.GetNormFactorList()
        norms2 = other.GetNormFactorList()
        if len(norms1) != len(norms2):
            raise ValueError(
                "attempting to sum Samples with NormFactor lists of "
                "differing lengths")
        for norm1, norm2 in zip(norms1, norms2):
            if norm1.name != norm2.name:
                raise ValueError(
                    "attempting to sum Samples containing NormFactors "
                    "with differing names: {0}, {1}".format(
                        norm1.name, norm2.name))
            # TODO check equality of value, low and high
            sample.AddNormFactor(norm1)
        return sample

    def __radd__(self, other):
        # support sum([list of Samples])
        if other == 0:
            return self
        raise TypeError(
            "unsupported operand type(s) for +: '{0}' and '{1}'".format(
                other.__class__.__name__, self.__class__.__name__))

    def __mul__(self, scale):
        clone = self.Clone()
        clone *= scale
        return clone

    def __imul__(self, scale):
        hist = self.hist
        if hist is not None:
            hist *= scale
        for hsys in self.histo_sys:
            low = hsys.low
            high = hsys.high
            if low is not None:
                low *= scale
            if high is not None:
                high *= scale
        return self

    def sys_names(self):
        """
        Return a list of unique systematic names from OverallSys and HistoSys
        """
        names = {}
        for osys in self.overall_sys:
            names[osys.name] = None
        for hsys in self.histo_sys:
            names[hsys.name] = None
        return names.keys()

    def iter_sys(self):
        """
        Iterate over sys_name, overall_sys, histo_sys.
        overall_sys or histo_sys may be None for any given sys_name.
        """
        names = self.sys_names()
        for name in names:
            osys = self.GetOverallSys(name)
            hsys = self.GetHistoSys(name)
            yield name, osys, hsys

    def sys_hist(self, name=None):
        """
        Return the effective low and high histogram for a given systematic.
        If this sample does not contain the named systematic then return
        the nominal histogram for both low and high variations.
        """
        if name is None:
            low = self.hist.Clone(shallow=True)
            high = self.hist.Clone(shallow=True)
            return low, high
        osys = self.GetOverallSys(name)
        hsys = self.GetHistoSys(name)
        if osys is None:
            osys_high, osys_low = 1., 1.
        else:
            osys_high, osys_low = osys.high, osys.low
        if hsys is None:
            hsys_high = self.hist.Clone(shallow=True)
            hsys_low = self.hist.Clone(shallow=True)
        else:
            hsys_high = hsys.high.Clone(shallow=True)
            hsys_low = hsys.low.Clone(shallow=True)
        return hsys_low * osys_low, hsys_high * osys_high

    def has_sys(self, name):
        return (self.GetOverallSys(name) is not None or
                self.GetHistoSys(name) is not None)

    def total(self, xbin1=1, xbin2=-2):
        """
        Return the total yield and its associated statistical and
        systematic uncertainties.
        """
        integral, stat_error = self.hist.integral(
            xbin1=xbin1, xbin2=xbin2, error=True)
        # sum systematics in quadrature
        ups = [0]
        dns = [0]
        for sys_name in self.sys_names():
            sys_low, sys_high = self.sys_hist(sys_name)
            up = sys_high.integral(xbin1=xbin1, xbin2=xbin2) - integral
            dn = sys_low.integral(xbin1=xbin1, xbin2=xbin2) - integral
            if up > 0:
                ups.append(up**2)
            else:
                dns.append(up**2)
            if dn > 0:
                ups.append(dn**2)
            else:
                dns.append(dn**2)
        syst_error = (sqrt(sum(ups)), sqrt(sum(dns)))
        return integral, stat_error, syst_error

    ###########################
    # HistoSys
    ###########################
    def AddHistoSys(self, *args):
        super(Sample, self).AddHistoSys(*args)
        if len(args) == 1:
            # args is a HistoSys
            keepalive(self, args[0])

    def RemoveHistoSys(self, name):
        histosys_vect = super(Sample, self).GetHistoSysList()
        ivect = histosys_vect.begin()
        for histosys in histosys_vect:
            if histosys.GetName() == name:
                histosys_vect.erase(ivect)
                break
            ivect.__preinc__()

    def GetHistoSys(self, name):
        histosys_vect = super(Sample, self).GetHistoSysList()
        for histosys in histosys_vect:
            if histosys.GetName() == name:
                return asrootpy(histosys)
        return None

    def GetHistoSysList(self):
        return [asrootpy(syst) for syst in
                super(Sample, self).GetHistoSysList()]

    @property
    def histo_sys(self):
        return self.GetHistoSysList()

    ###########################
    # HistoFactor
    ###########################
    def AddHistoFactor(self, *args):
        super(Sample, self).AddHistoFactor(*args)
        if len(args) == 1:
            # args is a HistoFactor
            keepalive(self, args[0])

    def RemoveHistoFactor(self, name):
        histofactor_vect = super(Sample, self).GetHistoFactorList()
        ivect = histosys_factor.begin()
        for histofactor in histofactor_vect:
            if histofactor.GetName() == name:
                histofactor_vect.erase(ivect)
                break
            ivect.__preinc__()

    def GetHistoFactor(self, name):
        histofactor_vect = super(Sample, self).GetHistoFactorList()
        for histofactor in histofactor_vect:
            if histofactor.GetName() == name:
                return asrootpy(histofactor)
        return None

    def GetHistoFactorList(self):
        return [asrootpy(syst) for syst in
                super(Sample, self).GetHistoFactorList()]

    @property
    def histo_factors(self):
        return self.GetHistoFactorList()

    ###########################
    # NormFactor
    ###########################
    def AddNormFactor(self, *args):
        super(Sample, self).AddNormFactor(*args)
        if len(args) == 1:
            # args is a NormFactor
            keepalive(self, args[0])

    def RemoveNormFactor(self, name):
        normfactor_vect = super(Sample, self).GetNormFactorList()
        ivect = normfactor_vect.begin()
        for normfactor in normfactor_vect:
            if normfactor.GetName() == name:
                normfactor_vect.erase(ivect)
                break
            ivect.__preinc__()

    def GetNormFactor(self, name):
        normfactor_vect = super(Sample, self).GetNormFactorList()
        for normfactor in normfactor_vect:
            if normfactor.GetName() == name:
                return asrootpy(normfactor)
        return None

    def GetNormFactorList(self):
        return [asrootpy(norm) for norm in
                super(Sample, self).GetNormFactorList()]

    @property
    def norm_factors(self):
        return self.GetNormFactorList()

    ###########################
    # OverallSys
    ###########################
    def AddOverallSys(self, *args):
        super(Sample, self).AddOverallSys(*args)
        if len(args) == 1:
            # args is a OverallSys
            keepalive(self, args[0])

    def RemoveOverallSys(self, name):
        overallsys_vect = super(Sample, self).GetOverallSysList()
        ivect = overallsys_vect.begin()
        for overallsys in overallsys_vect:
            if overallsys.GetName() == name:
                overallsys_vect.erase(ivect)
                break
            ivect.__preinc__()

    def GetOverallSys(self, name):
        overallsys_vect = super(Sample, self).GetOverallSysList()
        for overallsys in overallsys_vect:
            if overallsys.GetName() == name:
                return asrootpy(overallsys)
        return None

    def GetOverallSysList(self):
        return [asrootpy(syst) for syst in
                super(Sample, self).GetOverallSysList()]

    @property
    def overall_sys(self):
        return self.GetOverallSysList()

    ###########################
    # ShapeFactor
    ###########################
    def AddShapeFactor(self, shapefactor):
        super(Sample, self).AddShapeFactor(shapefactor)
        if isinstance(shapefactor, ROOT.RooStats.HistFactory.ShapeFactor):
            keepalive(self, shapefactor)

    def RemoveShapeFactor(self, name):
        shapefactor_vect = super(Sample, self).GetShapeFactorList()
        ivect = shapefactor_vect.begin()
        for shapefactor in shapefactor_vect:
            if shapefactor.GetName() == name:
                shapefactor_vect.erase(ivect)
                break
            ivect.__preinc__()

    def GetShapeFactor(self, name):
        shapefactor_vect = super(Sample, self).GetShapeFactorList()
        for shapefactor in shapefactor_vect:
            if shapefactor.GetName() == name:
                return asrootpy(shapefactor)
        return None

    def GetShapeFactorList(self):
        return [asrootpy(sf) for sf in
                super(Sample, self).GetShapeFactorList()]

    @property
    def shape_factors(self):
        return self.GetShapeFactorList()

    ###########################
    # ShapeSys
    ###########################
    def AddShapeSys(self, *args):
        super(Sample, self).AddShapeSys(*args)
        if len(args) == 1:
            # args is a ShapeSys
            keepalive(self, args[0])

    def RemoveShapeSys(self, name):
        shapesys_vect = super(Sample, self).GetShapeSysList()
        ivect = shapesys_vect.begin()
        for shapesys in shapesys_vect:
            if shapesys.GetName() == name:
                shapesys_vect.erase(ivect)
                break
            ivect.__preinc__()

    def GetShapeSys(self, name):
        shapesys_vect = super(Sample, self).GetShapeSysList()
        for shapesys in shapesys_vect:
            if shapesys.GetName() == name:
                return asrootpy(shapesys)
        return None

    def GetShapeSysList(self):
        return [asrootpy(ss) for ss in
                super(Sample, self).GetShapeSysList()]

    @property
    def shape_sys(self):
        return self.GetShapeSysList()

    def Clone(self):
        clone = self.__class__(self.name)
        hist = self.hist
        if hist is not None:
            clone.hist = hist.Clone(shallow=True)
        # HistoSys
        for hsys in self.histo_sys:
            clone.AddHistoSys(hsys.Clone())
        # HistoFactor
        for hfact in self.histo_factors:
            clone.AddHistoFactor(hfact.Clone())
        # NormFactor
        for norm in self.norm_factors:
            clone.AddNormFactor(norm.Clone())
        # OverallSys
        for osys in self.overall_sys:
            clone.AddOverallSys(osys.Clone())
        # ShapeFactor
        for sfact in self.shape_factors:
            clone.AddShapeFactor(sfact.Clone())
        # ShapeSys
        for ssys in self.shape_sys:
            clone.AddShapeSys(ssys.Clone())
        return clone


class _HistoSysBase(object):

    def SetHistoHigh(self, hist):
        super(_HistoSysBase, self).SetHistoHigh(hist)
        self.SetHistoNameHigh(hist.name)
        keepalive(self, hist)

    def SetHistoLow(self, hist):
        super(_HistoSysBase, self).SetHistoLow(hist)
        self.SetHistoNameLow(hist.name)
        keepalive(self, hist)

    def GetHistoHigh(self):
        hist = super(_HistoSysBase, self).GetHistoHigh()
        # NULL pointer check
        if hist == None:
            return None
        return asrootpy(hist)

    def GetHistoLow(self):
        hist = super(_HistoSysBase, self).GetHistoLow()
        # NULL pointer check
        if hist == None:
            return None
        return asrootpy(hist)

    @property
    def low(self):
        return self.GetHistoLow()

    @low.setter
    def low(self, h):
        self.SetHistoLow(h)

    @property
    def high(self):
        return self.GetHistoHigh()

    @high.setter
    def high(self, h):
        self.SetHistoHigh(h)

    @property
    def low_name(self):
        return self.GetHistoNameLow()

    @low_name.setter
    def low_name(self, name):
        self.SetHistoNameLow(name)

    @property
    def high_name(self):
        return self.GetHistoNameHigh()

    @high_name.setter
    def high_name(self, name):
        self.SetHistoNameHigh(name)

    @property
    def low_path(self):
        return self.GetHistoPathLow()

    @low_path.setter
    def low_path(self, path):
        self.SetHistoPathLow(path)

    @property
    def high_path(self):
        return self.GetHistoPathHigh()

    @high_path.setter
    def high_path(self, path):
        self.SetHistoPathHigh(path)

    @property
    def low_file(self):
        return self.GetInputFileLow()

    @low_file.setter
    def low_file(self, infile):
        self.SetInputFileLow(infile)

    @property
    def high_file(self):
        return self.GetInputFileHigh()

    @high_file.setter
    def high_file(self, infile):
        self.SetInputFileHigh(infile)

    def Clone(self):
        clone = self.__class__(self.name)
        low = self.low
        high = self.high
        if low is not None:
            clone.low = low.Clone(shallow=True)
        if high is not None:
            clone.high = high.Clone(shallow=True)
        clone.low_name = self.low_name
        clone.high_name = self.high_name
        clone.low_path = self.low_path
        clone.high_path = self.high_path
        clone.low_file = self.low_file
        clone.high_file = self.high_file
        return clone


class HistoSys(_Named, _HistoSysBase, QROOT.RooStats.HistFactory.HistoSys):
    _ROOT = QROOT.RooStats.HistFactory.HistoSys

    def __init__(self, name, low=None, high=None):
        # require a name
        super(HistoSys, self).__init__(name)
        if low is not None:
            self.low = low
        if high is not None:
            self.high = high

    def __add__(self, other):

        if self.name != other.name:
            raise ValueError("attempting to add HistoSys with different names")
        histosys = HistoSys(self.name)
        low = self.low + other.low
        low.name = '{0}_plus_{1}'.format(self.low.name, other.low.name)
        histosys.low = low
        high = self.high + other.high
        high.name = '{0}_plus_{1}'.format(self.high.name, other.high.name)
        histosys.high = high
        return histosys


class HistoFactor(_Named, _HistoSysBase,
                  QROOT.RooStats.HistFactory.HistoFactor):
    _ROOT = QROOT.RooStats.HistFactory.HistoFactor

    def __init__(self, name, low=None, high=None):
        # require a name
        super(HistoFactor, self).__init__(name)
        if low is not None:
            self.low = low
        if high is not None:
            self.high = high

    def __add__(self, other):

        raise NotImplementedError("HistoFactors cannot be summed")


class NormFactor(_Named, QROOT.RooStats.HistFactory.NormFactor):
    _ROOT = QROOT.RooStats.HistFactory.NormFactor

    def __init__(self, name, value=None, low=None, high=None, const=None):

        super(NormFactor, self).__init__()
        self.name = name
        if value is not None:
            self.value = value
        if low is not None:
            self.low = low
        if high is not None:
            self.high = high
        if const is not None:
            self.const = const

    @property
    def const(self):
        return self.GetConst()

    @const.setter
    def const(self, value):
        self.SetConst(value)

    @property
    def value(self):
        return self.GetVal()

    @value.setter
    def value(self, value):
        self.SetVal(value)

    @property
    def low(self):
        return self.GetLow()

    @low.setter
    def low(self, value):
        self.SetLow(value)

    @property
    def high(self):
        return self.GetHigh()

    @high.setter
    def high(self, value):
        self.SetHigh(value)

    def Clone(self):
        return NormFactor(self.name,
            value=self.value,
            low=self.low,
            high=self.high,
            const=self.const)


class OverallSys(_Named, QROOT.RooStats.HistFactory.OverallSys):
    _ROOT = QROOT.RooStats.HistFactory.OverallSys

    def __init__(self, name, low=None, high=None):
        # require a name
        super(OverallSys, self).__init__()
        self.name = name
        if low is not None:
            self.low = low
        if high is not None:
            self.high = high

    @property
    def low(self):
        return self.GetLow()

    @low.setter
    def low(self, value):
        self.SetLow(value)

    @property
    def high(self):
        return self.GetHigh()

    @high.setter
    def high(self, value):
        self.SetHigh(value)

    def Clone(self):
        return OverallSys(self.name, low=self.low, high=self.high)


class ShapeFactor(_Named, QROOT.RooStats.HistFactory.ShapeFactor):
    _ROOT = QROOT.RooStats.HistFactory.ShapeFactor

    def __init__(self, name):
        # require a name
        super(ShapeFactor, self).__init__()
        self.name = name

    def Clone(self):
        return ShapeFactor(self.name)


class ShapeSys(_Named, _HistNamePathFile, QROOT.RooStats.HistFactory.ShapeSys):
    _ROOT = QROOT.RooStats.HistFactory.ShapeSys

    def __init__(self, name):
        # require a name
        super(ShapeSys, self).__init__()
        self.name = name

    def GetErrorHist(self):
        hist = super(ShapeSys, self).GetErrorHist()
        # NULL pointer check
        if hist == None:
            return None
        return asrootpy(hist)

    def SetErrorHist(self, hist):
        super(ShapeSys, self).SetErrorHist(hist)
        self.SetHistoName(hist.name)
        keepalive(self, hist)

    @property
    def hist(self):
        self.GetErrorHist()

    @hist.setter
    def hist(self, h):
        self.SetErrorHist(h)

    def Clone(self):
        clone = ShapeSys(self.name)
        hist = self.hist
        if hist is not None:
            clone.hist = hist.Clone(shallow=True)
        return clone


class Channel(_Named, QROOT.RooStats.HistFactory.Channel):
    _ROOT = QROOT.RooStats.HistFactory.Channel

    def __init__(self, name, samples=None, data=None, inputfile=""):
        # require a name
        super(Channel, self).__init__(name, inputfile)
        if samples is not None:
            for sample in samples:
                self.AddSample(sample)
        if data is not None:
            self.SetData(data)

    def __add__(self, other):
        channel = Channel('{0}_plus_{1}'.format(self.name, other.name))
        channel.SetData(self.data + other.data)
        samples1 = self.samples
        samples2 = other.samples
        if len(samples1) != len(samples2):
            raise ValueError(
                "attempting to add Channels containing differing numbers of "
                "Samples")
        for s1, s2 in zip(samples1, samples2):
            # samples must be compatible
            channel.AddSample(s1 + s2)
        channel.SetStatErrorConfig(self.GetStatErrorConfig())
        return channel

    def __radd__(self, other):
        # support sum([list of Channels])
        if other == 0:
            return self
        raise TypeError(
            "unsupported operand type(s) for +: '{0}' and '{1}'".format(
                other.__class__.__name__, self.__class__.__name__))

    def sys_names(self):
        """
        Return a list of unique systematic names from OverallSys and HistoSys
        """
        names = {}
        for sample in self.samples:
            for osys in sample.overall_sys:
                names[osys.name] = None
            for hsys in sample.histo_sys:
                names[hsys.name] = None
        return names.keys()

    def sys_hist(self, name=None, where=None):
        """
        Return the effective total low and high histogram for a given
        systematic over samples in this channel.
        If a sample does not contain the named systematic then its nominal
        histogram is used for both low and high variations.

        Parameters
        ----------

        name : string, optional (default=None)
            The systematic name otherwise nominal if None

        where : callable, optional (default=None)
            A callable taking one argument: the sample, and returns True if
            this sample should be included in the total.

        Returns
        -------

        total_low, total_high : histograms
            The total low and high histograms for this systematic

        """
        total_low, total_high = None, None
        for sample in self.samples:
            if where is not None and not where(sample):
                continue
            low, high = sample.sys_hist(name)
            if total_low is None:
                total_low = low.Clone(shallow=True)
            else:
                total_low += low
            if total_high is None:
                total_high = high.Clone(shallow=True)
            else:
                total_high += high
        return total_low, total_high

    def has_sample(self, name):
        for sample in self.samples:
            if sample.name == name:
                return True
        return False

    def has_sample_where(self, func):
        for sample in self.samples:
            if func(sample):
                return True
        return False

    def total(self, where=None, xbin1=1, xbin2=-2):
        """
        Return the total yield and its associated statistical and
        systematic uncertainties.
        """
        nominal, _ = self.sys_hist(None, where=where)
        integral, stat_error = nominal.integral(
            xbin1=xbin1, xbin2=xbin2, error=True)
        ups = [0]
        dns = [0]
        for sys_name in self.sys_names():
            low, high = self.sys_hist(sys_name, where=where)
            up = high.integral(xbin1=xbin1, xbin2=xbin2) - integral
            dn = low.integral(xbin1=xbin1, xbin2=xbin2) - integral
            if up > 0:
                ups.append(up**2)
            else:
                dns.append(up**2)
            if dn > 0:
                ups.append(dn**2)
            else:
                dns.append(dn**2)
        syst_error = (sqrt(sum(ups)), sqrt(sum(dns)))
        return integral, stat_error, syst_error

    def SetData(self, data):
        super(Channel, self).SetData(data)
        if isinstance(data, ROOT.TH1):
            keepalive(self, data)

    def GetData(self):
        return asrootpy(super(Channel, self).GetData())

    @property
    def data(self):
        return self.GetData()

    @data.setter
    def data(self, d):
        self.SetData(d)

    def AddSample(self, sample):
        super(Channel, self).AddSample(sample)
        keepalive(self, sample)

    def GetSample(self, name):
        samples = super(Channel, self).GetSamples()
        for sample in samples:
            if sample.GetName() == name:
                return asrootpy(sample)
        return None

    def GetSamples(self):
        return [asrootpy(s) for s in super(Channel, self).GetSamples()]

    def AddAdditionalData(self, data):
        super(Channel, self).AddAdditionalData(data)
        keepalive(self, data)

    def GetAdditionalData(self):
        return [asrootpy(d) for d in super(Channel, self).GetAdditionalData()]

    @property
    def samples(self):
        return self.GetSamples()

    @property
    def additional_data(self):
        return self.GetAdditionalData()

    @property
    def hist_path(self):
        return self.GetHistoPath()

    @hist_path.setter
    def hist_path(self, path):
        self.SetHistoPath(path)

    @property
    def hist_file(self):
        return self.GetInputFile()

    @hist_file.setter
    def hist_file(self, infile):
        self.SetInputFile(infile)

    def apply_snapshot(self, argset):
        """
        Create a clone of this Channel where histograms are modified according
        to the values of the nuisance parameters in the snapshot. This is
        useful when creating post-fit distribution plots.

        Parameters
        ----------

        argset : RooArtSet
            A RooArgSet of RooRealVar nuisance parameters

        Returns
        -------

        channel : Channel
            The modified channel

        """
        clone = self.Clone()
        args = [var for var in argset if not (
            var.name.startswith('binWidth_obs_x_') or
            var.name.startswith('gamma_stat') or
            var.name.startswith('nom_'))]
        # handle NormFactors first
        nargs = []
        for var in args:
            is_norm = False
            name = var.name.replace('alpha_', '')
            for sample in clone.samples:
                if sample.GetNormFactor(name) is not None:
                    log.info("applying snapshot of {0} on sample {1}".format(
                        name, sample.name))
                    is_norm = True
                    # scale the entire sample
                    sample *= var.value
                    # add an OverallSys for the error
                    osys = OverallSys(name,
                        low=1. - var.error / var.value,
                        high=1. + var.error / var.value)
                    sample.AddOverallSys(osys)
                    # remove the NormFactor
                    sample.RemoveNormFactor(name)
            if not is_norm:
                nargs.append(var)
        # modify the nominal shape and systematics
        for sample in clone.samples:
            # check that hist is not NULL
            if sample.hist is None:
                raise RuntimeError(
                    "sample {0} does not have a "
                    "nominal histogram".format(sample.name))
            nominal = sample.hist.Clone(shallow=True)
            for var in nargs:
                name = var.name.replace('alpha_', '')
                if not sample.has_sys(name):
                    continue
                log.info("applying snapshot of {0} on sample {1}".format(
                    name, sample.name))
                low, high = sample.sys_hist(name)
                # modify nominal
                val = var.value
                if val > 0:
                    sample.hist += (high - nominal) * val
                elif val < 0:
                    sample.hist += (nominal - low) * val
                # TODO:
                # modify OverallSys
                # modify HistoSys
        return clone

    def Clone(self):
        clone = Channel(self.name)
        data = self.data
        if data:
            clone.data = data.Clone()
        for sample in self.samples:
            clone.AddSample(sample.Clone())
        clone.hist_path = self.hist_path
        clone.hist_file = self.hist_file
        return clone


class Measurement(NamedObject, QROOT.RooStats.HistFactory.Measurement):
    _ROOT = QROOT.RooStats.HistFactory.Measurement

    def __init__(self, name, title=""):
        # require a name
        super(Measurement, self).__init__(name=name, title=title)
        self.SetExportOnly(True)

    @property
    def lumi(self):
        return self.GetLumi()

    @lumi.setter
    def lumi(self, l):
        self.SetLumi(l)

    @property
    def lumi_rel_error(self):
        return self.GetLumiRelErr()

    @lumi_rel_error.setter
    def lumi_rel_error(self, err):
        self.SetLumiRelErr(err)

    @property
    def poi(self):
        return list(self.GetPOIList())

    @poi.setter
    def poi(self, p):
        # this also adds a new POI so calling this multiple times will add
        # multiple POIs
        self.SetPOI(p)

    def AddChannel(self, channel):
        super(Measurement, self).AddChannel(channel)
        keepalive(self, channel)

    def GetChannel(self, name):
        return asrootpy(super(Measurement, self).GetChannel(name))

    def GetChannels(self):
        return [asrootpy(c) for c in super(Measurement, self).GetChannels()]

    @property
    def channels(self):
        return self.GetChannels()

    def GetConstantParams(self):
        return list(super(Measurement, self).GetConstantParams())

    @property
    def const_params(self):
        return self.GetConstantParams()

    def Clone(self):
        clone = Measurement(self.name, self.title)
        clone.lumi = self.lumi
        clone.lumi_rel_error = self.lumi_rel_error
        for channel in self.channels:
            clone.AddChannel(channel.Clone())
        for poi in self.GetPOIList():
            clone.AddPOI(poi)
        for const_param in self.const_params:
            clone.AddConstantParam(const_param)
        return clone

########NEW FILE########
__FILENAME__ = test_histfactory
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from nose.plugins.skip import SkipTest

try:
    from rootpy.stats import mute_roostats; mute_roostats()
except ImportError:
    raise SkipTest("ROOT is not compiled with RooFit and RooStats enabled")

from rootpy.io import TemporaryFile
from rootpy.plotting import Hist
from rootpy.decorators import requires_ROOT
from rootpy.stats.histfactory import *
from rootpy.stats import histfactory

from nose.plugins.attrib import attr
from nose.tools import assert_raises, assert_equal


def get_random_hist():
    h = Hist(10, -5, 5)
    h.FillRandom('gaus')
    return h

@requires_ROOT(histfactory.MIN_ROOT_VERSION, exception=SkipTest)
def test_histfactory():

    # create some Samples
    data = Data('data')
    data.hist = get_random_hist()
    a = Sample('QCD')
    b = Sample('QCD')

    for sample in (a, b):
        sample.hist = get_random_hist()
        # include some histosysts
        for sysname in ('x', 'y', 'z'):
            histosys = HistoSys(sysname)
            histosys.high = get_random_hist()
            histosys.low = get_random_hist()
            sample.AddHistoSys(histosys)
        # include some normfactors
        for normname in ('x', 'y', 'z'):
            norm = NormFactor(normname)
            norm.value = 1
            norm.high = 2
            norm.low = 0
            norm.const = False
            sample.AddNormFactor(norm)

    # samples must be compatible here
    c = a + b
    c = sum([a, b])

    # create Channels
    channel_a = Channel('VBF')
    channel_a.data = data
    channel_a.AddSample(a)

    channel_b = Channel('VBF')
    channel_b.data = data
    channel_b.AddSample(b)

    combined_channel = channel_a + channel_b
    combined_channel = sum([channel_a, channel_b])

    # create a Measurement
    meas = Measurement('MyAnalysis')
    meas.AddChannel(channel_a)

    # create the workspace containing the model
    workspace = make_workspace(meas, silence=True)
    with TemporaryFile():
        workspace.Write()


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = utils
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import os
import re
import shutil
from glob import glob

import ROOT

from . import log; log = log[__name__]
from ...memory.keepalive import keepalive
from ...utils.silence import silence_sout_serr
from ...utils.path import mkdir_p
from ...context import (
    do_nothing, working_directory, preserve_current_directory)
from ...io import root_open
from ... import asrootpy
from . import Channel, Measurement, HistoSys, OverallSys

__all__ = [
    'make_channel',
    'make_measurement',
    'make_workspace',
    'measurements_from_xml',
    'write_measurement',
    'patch_xml',
    'split_norm_shape',
]


def make_channel(name, samples, data=None, verbose=False):
    """
    Create a Channel from a list of Samples
    """
    if verbose:
        llog = log['make_channel']
        llog.info("creating channel {0}".format(name))
    # avoid segfault if name begins with a digit by using "channel_" prefix
    chan = Channel('channel_{0}'.format(name))
    chan.SetStatErrorConfig(0.05, "Poisson")

    if data is not None:
        if verbose:
            llog.info("setting data")
        chan.SetData(data)

    for sample in samples:
        if verbose:
            llog.info("adding sample {0}".format(sample.GetName()))
        chan.AddSample(sample)

    return chan


def make_measurement(name,
                     channels,
                     lumi=1.0, lumi_rel_error=0.1,
                     output_prefix='./histfactory',
                     POI=None,
                     const_params=None,
                     verbose=False):
    """
    Create a Measurement from a list of Channels
    """
    if verbose:
        llog = log['make_measurement']
        llog.info("creating measurement {0}".format(name))

    if not isinstance(channels, (list, tuple)):
        channels = [channels]

    # Create the measurement
    meas = Measurement('measurement_{0}'.format(name), '')
    meas.SetOutputFilePrefix(output_prefix)
    if POI is not None:
        if isinstance(POI, basestring):
            if verbose:
                llog.info("setting POI {0}".format(POI))
            meas.SetPOI(POI)
        else:
            if verbose:
                llog.info("adding POIs {0}".format(', '.join(POI)))
            for p in POI:
                meas.AddPOI(p)

    if verbose:
        llog.info("setting lumi={0:f} +/- {1:f}".format(lumi, lumi_rel_error))
    meas.lumi = lumi
    meas.lumi_rel_error = lumi_rel_error

    for channel in channels:
        if verbose:
            llog.info("adding channel {0}".format(channel.GetName()))
        meas.AddChannel(channel)

    if const_params is not None:
        if verbose:
            llog.info("adding constant parameters {0}".format(
                ', '.join(const_params)))
        for param in const_params:
            meas.AddConstantParam(param)

    return meas


def make_workspace(measurement, channel=None, name=None, silence=False):
    """
    Create a workspace containing the model for a measurement

    If `channel` is None then include all channels in the model

    If `silence` is True, then silence HistFactory's output on
    stdout and stderr.
    """
    context = silence_sout_serr if silence else do_nothing
    with context():
        hist2workspace = ROOT.RooStats.HistFactory.HistoToWorkspaceFactoryFast(
            measurement)
        if channel is not None:
            workspace = hist2workspace.MakeSingleChannelModel(
                measurement, channel)
        else:
            workspace = hist2workspace.MakeCombinedModel(measurement)
    workspace = asrootpy(workspace)
    keepalive(workspace, measurement)
    if name is not None:
        workspace.SetName('workspace_{0}'.format(name))
    return workspace


def measurements_from_xml(filename,
                          collect_histograms=True,
                          cd_parent=False,
                          silence=False):
    """
    Read in a list of Measurements from XML
    """
    if not os.path.isfile(filename):
        raise OSError("the file {0} does not exist".format(filename))
    silence_context = silence_sout_serr if silence else do_nothing

    filename = os.path.abspath(os.path.normpath(filename))

    if cd_parent:
        xml_directory = os.path.dirname(filename)
        parent = os.path.abspath(os.path.join(xml_directory, os.pardir))
        cd_context = working_directory
    else:
        parent = None
        cd_context = do_nothing

    log.info("parsing XML in {0} ...".format(filename))
    with cd_context(parent):
        parser = ROOT.RooStats.HistFactory.ConfigParser()
        with silence_context():
            measurements_vect = parser.GetMeasurementsFromXML(filename)
        # prevent measurements_vect from being garbage collected
        ROOT.SetOwnership(measurements_vect, False)
        measurements = []
        for m in measurements_vect:
            if collect_histograms:
                with silence_context():
                    m.CollectHistograms()
            measurements.append(asrootpy(m))
    return measurements


def write_measurement(measurement,
                      root_file=None,
                      xml_path=None,
                      output_path=None,
                      output_suffix=None,
                      write_workspaces=False,
                      apply_xml_patches=True,
                      silence=False):
    """
    Write a measurement and RooWorkspaces for all contained channels
    into a ROOT file and write the XML files into a directory.

    Parameters
    ----------

    measurement : HistFactory::Measurement
        An asrootpy'd ``HistFactory::Measurement`` object

    root_file : ROOT TFile or string, optional (default=None)
        A ROOT file or string file name. The measurement and workspaces
        will be written to this file. If ``root_file is None`` then a
        new file will be created with the same name as the measurement and
        with the prefix ``ws_``.

    xml_path : string, optional (default=None)
        A directory path to write the XML into. If None, a new directory with
        the same name as the measurement and with the prefix ``xml_`` will be
        created.

    output_path : string, optional (default=None)
        If ``root_file is None``, create the ROOT file under this path.
        If ``xml_path is None``, create the XML directory under this path.

    output_suffix : string, optional (default=None)
        If ``root_file is None`` then a new file is created with the same name
        as the measurement and with the prefix ``ws_``. ``output_suffix`` will
        append a suffix to this file name (before the .root extension).
        If ``xml_path is None``, then a new directory is created with the
        same name as the measurement and with the prefix ``xml_``.
        ``output_suffix`` will append a suffix to this directory name.

    write_workspaces : bool, optional (default=False)
        If True then also write a RooWorkspace for each channel and for all
        channels combined.

    apply_xml_patches : bool, optional (default=True)
        Apply fixes on the output of ``Measurement::PrintXML()`` to avoid known
        HistFactory bugs. Some of the patches assume that the ROOT file
        containing the histograms will exist one directory level up from the
        XML and that hist2workspace, or any tool that later reads the XML will
        run from that same directory containing the ROOT file.

    silence : bool, optional (default=False)
        If True then capture and silence all stdout/stderr output from
        HistFactory.

    """
    context = silence_sout_serr if silence else do_nothing

    output_name = measurement.name
    if output_suffix is not None:
        output_name += '_{0}'.format(output_suffix)
    output_name = output_name.replace(' ', '_')

    if xml_path is None:
        xml_path = 'xml_{0}'.format(output_name)
        if output_path is not None:
            xml_path = os.path.join(output_path, xml_path)

    if not os.path.exists(xml_path):
        mkdir_p(xml_path)

    if root_file is None:
        root_file = 'ws_{0}.root'.format(output_name)
        if output_path is not None:
            root_file = os.path.join(output_path, root_file)

    own_file = False
    if isinstance(root_file, basestring):
        root_file = root_open(root_file, 'recreate')
        own_file = True

    with preserve_current_directory():
        root_file.cd()

        log.info("writing histograms and measurement in {0} ...".format(
            root_file.GetName()))
        with context():
            measurement.writeToFile(root_file)
        # get modified measurement
        out_m = root_file.Get(measurement.name)
        log.info("writing XML in {0} ...".format(xml_path))
        with context():
            out_m.PrintXML(xml_path)

        if write_workspaces:
            log.info("writing combined model in {0} ...".format(
                root_file.GetName()))
            workspace = make_workspace(measurement, silence=silence)
            workspace.Write()
            for channel in measurement.channels:
                log.info("writing model for channel `{0}` in {1} ...".format(
                    channel.name, root_file.GetName()))
                workspace = make_workspace(
                    measurement, channel=channel, silence=silence)
                workspace.Write()

    if apply_xml_patches:
        # patch the output XML to avoid HistFactory bugs
        patch_xml(glob(os.path.join(xml_path, '*.xml')),
                  root_file=os.path.basename(root_file.GetName()))

    if own_file:
        root_file.Close()


def patch_xml(files, root_file=None, float_precision=3):
    """
    Apply patches to HistFactory XML output from PrintXML
    """
    if float_precision < 0:
        raise ValueError("precision must be greater than 0")

    def fix_path(match):
        path = match.group(1)
        if path:
            head, tail = os.path.split(path)
            new_path = os.path.join(os.path.basename(head), tail)
        else:
            new_path = ''
        return '<Input>{0}</Input>'.format(new_path)

    for xmlfilename in files:
        xmlfilename = os.path.abspath(os.path.normpath(xmlfilename))
        patched_xmlfilename = '{0}.tmp'.format(xmlfilename)
        log.info("patching {0} ...".format(xmlfilename))
        fin = open(xmlfilename, 'r')
        fout = open(patched_xmlfilename, 'w')
        for line in fin:
            if root_file is not None:
                line = re.sub(
                    'InputFile="[^"]*"',
                    'InputFile="{0}"'.format(root_file), line)
            line = line.replace(
                '<StatError Activate="True"  InputFile=""  '
                'HistoName=""  HistoPath=""  />',
                '<StatError Activate="True" />')
            line = re.sub(
                '<Combination OutputFilePrefix="(\S*)" >',
                '<Combination OutputFilePrefix="hist2workspace" >', line)
            line = re.sub('\w+=""', '', line)
            line = re.sub('\s+/>', ' />', line)
            line = re.sub('(\S)\s+</', r'\1</', line)
            # HistFactory bug:
            line = re.sub('InputFileHigh="\S+"', '', line)
            line = re.sub('InputFileLow="\S+"', '', line)
            # HistFactory bug:
            line = line.replace(
                '<ParamSetting Const="True"></ParamSetting>', '')
            # chop off floats to desired precision
            line = re.sub(
                r'"(\d*\.\d{{{0:d},}})"'.format(float_precision + 1),
                lambda x: '"{0}"'.format(
                    str(round(float(x.group(1)), float_precision))),
                line)
            line = re.sub('"\s\s+(\S)', r'" \1', line)
            line = re.sub('<Input>(.*)</Input>', fix_path, line)
            fout.write(line)
        fin.close()
        fout.close()
        shutil.move(patched_xmlfilename, xmlfilename)
        if not os.path.isfile(os.path.join(
                              os.path.dirname(xmlfilename),
                              'HistFactorySchema.dtd')):
            rootsys = os.getenv('ROOTSYS', None)
            if rootsys is not None:
                dtdfile = os.path.join(rootsys, 'etc/HistFactorySchema.dtd')
                target = os.path.dirname(xmlfilename)
                if os.path.isfile(dtdfile):
                    log.info("copying {0} to {1} ...".format(dtdfile, target))
                    shutil.copy(dtdfile, target)
                else:
                    log.warning("{0} does not exist".format(dtdfile))
            else:
                log.warning(
                    "$ROOTSYS is not set so cannot find HistFactorySchema.dtd")


def split_norm_shape(histosys, nominal_hist):
    """
    Split a HistoSys into normalization (OverallSys) and shape (HistoSys)
    components.

    It is recommended to use OverallSys as much as possible, which tries to
    enforce continuity up to the second derivative during
    interpolation/extrapolation. So, if there is indeed a shape variation, then
    factorize it into shape and normalization components.
    """
    up = histosys.GetHistoHigh()
    dn = histosys.GetHistoLow()
    up = up.Clone(name=up.name + '_shape')
    dn = dn.Clone(name=dn.name + '_shape')
    n_nominal = nominal_hist.integral(overflow=True)
    n_up = up.integral(overflow=True)
    n_dn = dn.integral(overflow=True)
    if n_up != 0:
        up.Scale(n_nominal / n_up)
    if n_dn != 0:
        dn.Scale(n_nominal / n_dn)
    shape = HistoSys(histosys.GetName(), low=dn, high=up)
    norm = OverallSys(histosys.GetName(),
                      low=n_dn / n_nominal if n_nominal != 0 else 1.,
                      high=n_up / n_nominal if n_nominal != 0 else 1.)
    return norm, shape

########NEW FILE########
__FILENAME__ = modelconfig
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from . import log; log = log[__name__]
from .. import QROOT, asrootpy
from ..base import NamedObject

__all__ = [
    'ModelConfig',
]


class ModelConfig(NamedObject, QROOT.RooStats.ModelConfig):
    _ROOT = QROOT.RooStats.ModelConfig

    def GetPdf(self):
        return asrootpy(super(ModelConfig, self).GetPdf())

    @property
    def workspace(self):
        return asrootpy(self.GetWorkspace())

    @workspace.setter
    def workspace(self, value):
        self.SetWorkspace(value)

    @property
    def pdf(self):
        return self.GetPdf()

    @pdf.setter
    def pdf(self, value):
        self.SetPdf(value)

    @property
    def prior_pdf(self):
        return self.GetPriorPdf()

    @prior_pdf.setter
    def prior_pdf(self, value):
        self.SetPriorPdf(value)

    @property
    def proto_data(self):
        return self.GetProtoData()

    @proto_data.setter
    def proto_data(self, value):
        self.SetProtoData(value)

    @property
    def snapshot(self):
        return self.GetSnapshot()

    @snapshot.setter
    def snapshot(self, value):
        self.SetSnapshot(value)

    @property
    def conditional_observables(self):
        return asrootpy(self.GetConditionalObservables())

    @conditional_observables.setter
    def conditional_observables(self, value):
        self.SetConditionalObservables(value)

    @property
    def constraint_parameters(self):
        return asrootpy(self.GetConstraintParameters())

    @constraint_parameters.setter
    def constraint_parameters(self, value):
        self.SetConstraintParameters(value)

    @property
    def global_observables(self):
        return asrootpy(self.GetGlobalObservables())

    @global_observables.setter
    def global_observables(self, value):
        self.SetGlobalObservables(value)

    @property
    def nuisance_parameters(self):
        return asrootpy(self.GetNuisanceParameters())

    @nuisance_parameters.setter
    def nuisance_parameters(self, value):
        self.SetNuisanceParameters(value)

    @property
    def observables(self):
        return asrootpy(self.GetObservables())

    @observables.setter
    def observables(self, value):
        self.SetObservables(value)

    @property
    def poi(self):
        return asrootpy(self.GetParametersOfInterest())

    @poi.setter
    def poi(self, value):
        self.SetParametersOfInterest(value)

########NEW FILE########
__FILENAME__ = pdf
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from . import log; log = log[__name__]
from .. import QROOT, asrootpy
from ..base import NamedObject

from .value import AbsArg

__all__ = [
    'Simultaneous',
    'AddPdf',
    'ProdPdf',
]


class Simultaneous(NamedObject, AbsArg, QROOT.RooSimultaneous):
    _ROOT = QROOT.RooSimultaneous

    def __iter__(self):
        iterator = self.indexCat().typeIterator()
        category = iterator.Next()
        while category:
            yield asrootpy(category)
            category = iterator.Next()

    def getPdf(self, category):
        if isinstance(category, ROOT.RooCatType):
            category = category.GetName()
        return asrootpy(super(Simultaneous, self).getPdf(category))

    def pdf(self, category):
        return self.getPdf(category)

    def indexCat(self):
        return asrootpy(super(Simultaneous, self).indexCat())

    @property
    def index_category(self):
        return self.indexCat()


class AddPdf(NamedObject, AbsArg, QROOT.RooAddPdf):
    _ROOT = QROOT.RooAddPdf


class ProdPdf(NamedObject, AbsArg, QROOT.RooProdPdf):
    _ROOT = QROOT.RooProdPdf

########NEW FILE########
__FILENAME__ = test_correlated_values
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from nose.plugins.skip import SkipTest
from rootpy.utils.silence import silence_sout

try:
    with silence_sout():
        from ROOT import (RooFit, RooRealVar, RooGaussian, RooArgusBG,
                          RooAddPdf, RooArgList, RooArgSet)
    from rootpy.stats import mute_roostats; mute_roostats()
    from rootpy.stats import Workspace
except ImportError:
    raise SkipTest("ROOT is not compiled with RooFit and RooStats enabled")

from rootpy.io import TemporaryFile
from nose.tools import assert_false


def test_correlated_values():

    try:
        import uncertainties
    except ImportError:
        raise SkipTest("uncertainties package is not installed")
    from rootpy.stats.correlated_values import correlated_values

    # construct pdf and toy data following example at
    # http://root.cern.ch/drupal/content/roofit

    # --- Observable ---
    mes = RooRealVar("mes", "m_{ES} (GeV)", 5.20, 5.30)

    # --- Parameters ---
    sigmean = RooRealVar("sigmean", "B^{#pm} mass", 5.28, 5.20, 5.30)
    sigwidth = RooRealVar("sigwidth", "B^{#pm} width", 0.0027, 0.001, 1.)

    # --- Build Gaussian PDF ---
    signal = RooGaussian("signal", "signal PDF", mes, sigmean, sigwidth)

    # --- Build Argus background PDF ---
    argpar = RooRealVar("argpar", "argus shape parameter", -20.0, -100., -1.)
    background = RooArgusBG("background", "Argus PDF",
                            mes, RooFit.RooConst(5.291), argpar)

    # --- Construct signal+background PDF ---
    nsig = RooRealVar("nsig", "#signal events", 200, 0., 10000)
    nbkg = RooRealVar("nbkg", "#background events", 800, 0., 10000)
    model = RooAddPdf("model", "g+a",
                      RooArgList(signal,background),
                      RooArgList(nsig,nbkg))

    # --- Generate a toyMC sample from composite PDF ---
    data = model.generate(RooArgSet(mes), 2000)

    # --- Perform extended ML fit of composite PDF to toy data ---
    fitresult = model.fitTo(data, RooFit.Save(), RooFit.PrintLevel(-1))

    nsig, nbkg = correlated_values(["nsig", "nbkg"], fitresult)

    # Arbitrary math expression according to what the `uncertainties`
    # package supports, automatically computes correct error propagation
    sum_value = nsig + nbkg
    value, error = sum_value.nominal_value, sum_value.std_dev

    workspace = Workspace(name='workspace')
    # import the data
    assert_false(workspace(data))
    with TemporaryFile():
        workspace.Write()

########NEW FILE########
__FILENAME__ = value
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from . import log; log = log[__name__]
from ..base import NamedObject
from .. import QROOT, asrootpy

__all__ = [
    'RealVar',
]


class AbsArg(object):
    """
    Use with classes inheriting from RooAbsArg
    """
    def getComponents(self):
        return asrootpy(super(AbsArg, self).getComponents())

    def components(self):
        return self.getComponents()

    def getDependents(self, *args, **kwargs):
        return asrootpy(super(AbsArg, self).getDependents(*args, **kwargs))

    def dependents(self, *args, **kwargs):
        return self.getDependents(*args, **kwargs)

    def getObservables(self, *args, **kwargs):
        return asrootpy(super(AbsArg, self).getObservables(*args, **kwargs))

    def observables(self, *args, **kwargs):
        return self.getObservables(*args, **kwargs)

    def getParameters(self, *args, **kwargs):
        return asrootpy(super(AbsArg, self).getParameters(*args, **kwargs))

    def parameters(self, *args, **kwargs):
        return self.getParameters(*args, **kwargs)


class _ValueBase(object):

    @property
    def value(self):
        return self.getVal()

    @value.setter
    def value(self, newvalue):
        self.setVal(newvalue)

    @property
    def error(self):
        if self.hasAsymError():
            return self.getErrorHi(), self.getErrorLo()
        return self.getError()

    @error.setter
    def error(self, value):
        if self.hasAsymError():
            # high, low -> low, high
            self.setAsymError(value[1], value[0])
        else:
            self.setError(value)

    @property
    def max(self):
        return self.getMax()

    @max.setter
    def max(self, value):
        self.setMax(value)

    @property
    def min(self):
        return self.getMin()

    @min.setter
    def min(self, value):
        self.setMin(value)


class RealVar(_ValueBase, NamedObject, QROOT.RooRealVar):
    _ROOT = QROOT.RooRealVar

########NEW FILE########
__FILENAME__ = workspace
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import multiprocessing

import ROOT

from . import log; log = log[__name__]
from .. import QROOT, asrootpy
from ..base import NamedObject
from .fit import minimize

__all__ = [
    'Workspace',
]

NCPU = multiprocessing.cpu_count()


class Workspace(NamedObject, QROOT.RooWorkspace):
    _ROOT = QROOT.RooWorkspace

    def __call__(self, *args):
        """
        Need to provide an alternative to RooWorkspace::import since import is
        a reserved word in Python and would be a syntax error.
        """
        return getattr(super(Workspace, self), 'import')(*args)

    def __getitem__(self, name):
        thing = super(Workspace, self).obj(name)
        if thing == None:
            raise ValueError(
                "object named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        return asrootpy(thing, warn=False)

    def __contains__(self, name):
        thing = super(Workspace, self).obj(name)
        if thing:
            return True
        return False

    def obj(self, name, cls=None):
        thing = super(Workspace, self).obj(name)
        if thing == None:
            raise ValueError(
                "object named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        thing = asrootpy(thing, warn=False)
        if cls is not None and not isinstance(thing, cls):
            raise TypeError(
                "object named '{0}' is not of the correct type: "
                "{1} does not subclass {2}".format(name, thing.__class__, cls))
        return thing

    @property
    def category_functions(self):
        return asrootpy(self.allCatFunctions())

    @property
    def categories(self):
        return asrootpy(self.allCats())

    @property
    def datas():
        return self.allData()

    @property
    def functions(self):
        return asrootpy(self.allFunctions())

    @property
    def generic_objects(self):
        return self.allGenericObjects()

    @property
    def pdfs(self):
        return asrootpy(self.allPdfs())

    @property
    def resolution_models(self):
        return asrootpy(self.allResolutionModels())

    @property
    def vars(self):
        return asrootpy(self.allVars())

    def arg(self, name):
        thing = super(Workspace, self).arg(name)
        if thing == None:
            raise ValueError(
                "RooAbsArg named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        return asrootpy(thing)

    def argset(self, name):
        thing = super(Workspace, self).argSet(name)
        if thing == None:
            raise ValueError(
                "RooArgSet named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        return asrootpy(thing)

    def category(self, name):
        thing = super(Workspace, self).cat(name)
        if thing == None:
            raise ValueError(
                "RooCategory named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        return asrootpy(thing)

    def category_function(self, name):
        # Dear RooStats, use camelCase consistently...
        thing = super(Workspace, self).catfunc(name)
        if thing == None:
            raise ValueError(
                "RooAbsCategory named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        return thing

    def data(self, name):
        thing = super(Workspace, self).data(name)
        if thing == None:
            raise ValueError(
                "RooAbsData named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        return asrootpy(thing)

    def function(self, name):
        thing = super(Workspace, self).function(name)
        if thing == None:
            raise ValueError(
                "RooAbsReal named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        return thing

    def pdf(self, name):
        thing = super(Workspace, self).pdf(name)
        if thing == None:
            raise ValueError(
                "RooAbsPdf named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        return asrootpy(thing)

    def set(self, name):
        thing = super(Workspace, self).set(name)
        if thing == None:
            raise ValueError(
                "RooArgSet named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        return asrootpy(thing)

    def var(self, name):
        thing = super(Workspace, self).var(name)
        if thing == None:
            raise ValueError(
                "RooRealVar named '{0}' does not exist "
                "in the workspace '{1}'".format(name, self.name))
        return asrootpy(thing)

    def fit(self,
            data_name='obsData',
            model_config_name='ModelConfig',
            param_const=None,
            param_values=None,
            param_ranges=None,
            poi_const=False,
            poi_value=None,
            poi_range=None,
            extended=False,
            num_cpu=1,
            process_strategy=0,
            offset=False,
            print_level=None,
            return_nll=False,
            **kwargs):
        """
        Fit a pdf to data in a workspace

        Parameters
        ----------

        workspace : RooWorkspace
            The workspace

        data_name : str, optional (default='obsData')
            The name of the data

        model_config_name : str, optional (default='ModelConfig')
            The name of the ModelConfig in the workspace

        param_const : dict, optional (default=None)
            A dict mapping parameter names to booleans setting
            the const state of the parameter

        param_values : dict, optional (default=None)
            A dict mapping parameter names to values

        param_ranges : dict, optional (default=None)
            A dict mapping parameter names to 2-tuples defining the ranges

        poi_const : bool, optional (default=False)
            If True, then make the parameter of interest (POI) constant

        poi_value : float, optional (default=None)
            If not None, then set the POI to this value

        poi_range : tuple, optional (default=None)
            If not None, then set the range of the POI with this 2-tuple

        extended : bool, optional (default=False)
            If True, add extended likelihood term (False by default)

        num_cpu : int, optional (default=1)
            Parallelize NLL calculation on multiple CPU cores.
            If negative then use all CPU cores.
            By default use only one CPU core.

        process_strategy : int, optional (default=0)
            **Strategy 0:** Divide events into N equal chunks.

            **Strategy 1:** Process event i%N in process N. Recommended for
            binned data with a substantial number of zero-bins, which will be
            distributed across processes more equitably in this strategy.

            **Strategy 2:** Process each component likelihood of a
            RooSimultaneous fully in a single process and distribute components
            over processes. This approach can be benificial if normalization
            calculation time dominates the total computation time of a
            component (since the normalization calculation must be performed
            in each process in strategies 0 and 1. However beware that if the
            RooSimultaneous components do not share many parameters this
            strategy is inefficient: as most minuit-induced likelihood
            calculations involve changing a single parameter, only 1 of the N
            processes will be active most of the time if RooSimultaneous
            components do not share many parameters.

            **Strategy 3:** Follow strategy 0 for all RooSimultaneous
            components, except those with less than 30 dataset entries,
            for which strategy 2 is followed.

        offset : bool, optional (default=False)
            Offset likelihood by initial value (so that starting value of FCN
            in minuit is zero). This can improve numeric stability in
            simultaneously fits with components with large likelihood values.

        print_level : int, optional (default=None)
            The verbosity level for the minimizer algorithm.
            If None (the default) then use the global default print level.
            If negative then all non-fatal messages will be suppressed.

        return_nll : bool, optional (default=False)
            If True then also return the RooAbsReal NLL function that was
            minimized.

        kwargs : dict, optional
            Remaining keyword arguments are passed to the minimize function

        Returns
        -------

        result : RooFitResult
            The fit result.

        func : RooAbsReal
            If return_nll is True, the NLL function is also returned.

        See Also
        --------

        minimize

        """
        model_config = self.obj(
            model_config_name, cls=ROOT.RooStats.ModelConfig)
        data = self.data(data_name)
        pdf = model_config.GetPdf()

        pois = model_config.GetParametersOfInterest()
        if pois.getSize() > 0:
            poi = pois.first()
            poi.setConstant(poi_const)
            if poi_value is not None:
                poi.setVal(poi_value)
            if poi_range is not None:
                poi.setRange(*poi_range)

        if param_const is not None:
            for param_name, const in param_const.items():
                var = self.var(param_name)
                var.setConstant(const)
        if param_values is not None:
            for param_name, param_value in param_values.items():
                var = self.var(param_name)
                var.setVal(param_value)
        if param_ranges is not None:
            for param_name, param_range in param_ranges.items():
                var = self.var(param_name)
                var.setRange(*param_range)

        if print_level < 0:
            msg_service = ROOT.RooMsgService.instance()
            msg_level = msg_service.globalKillBelow()
            msg_service.setGlobalKillBelow(ROOT.RooFit.FATAL)

        args = [
            ROOT.RooFit.Constrain(model_config.GetNuisanceParameters()),
            ROOT.RooFit.GlobalObservables(model_config.GetGlobalObservables())]
        if extended:
            args.append(ROOT.RooFit.Extended(True))
        if offset:
            args.append(ROOT.RooFit.Offset(True))
        if num_cpu != 1:
            if num_cpu == 0:
                raise ValueError("num_cpu must be non-zero")
            if num_cpu < 0:
                num_cpu = NCPU
            args.append(ROOT.RooFit.NumCPU(num_cpu, process_strategy))

        func = pdf.createNLL(data, *args)

        if print_level < 0:
            msg_service.setGlobalKillBelow(msg_level)

        result = minimize(func, print_level=print_level, **kwargs)

        if return_nll:
            return result, func
        return result

########NEW FILE########
__FILENAME__ = stl
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module allows C++ template types to be generated on demand with ease,
automatically building dictionaries with ROOT's ACLiC as necessary.  Unlike
vanilla ACLiC, rootpy's stl module generates and compiles dictionaries without
creating a mess of temporary files in your current working directory.
Dictionaries are also cached in ``~/.cache/rootpy/`` and used by any future
request for the same dictionary instead of compiling from scratch again.
Templates can be arbitrarily nested, limited only by what ACLiC and CINT can
handle.

Examples
--------

.. sourcecode:: python

    import rootpy.stl as stl, ROOT

    # Create a vector type
    StrVector = stl.vector(stl.string)
    # Instantiate
    strvector = StrVector()
    strvector.push_back("Hello")

    MapStrRoot = stl.map(stl.string, ROOT.TH1D)
    MapStrRootPtr = stl.map(stl.string, "TH1D*")


Dictionary generation type inference is flexible and can be nested::

    >>> import rootpy.stl as stl
    >>> import ROOT
    >>> from rootpy.plotting import Hist
    >>> stl.vector('int')
    <class 'ROOT.vector<int,allocator<int> >'>
    >>> stl.vector(int)
    <class 'ROOT.vector<int,allocator<int> >'>
    >>> stl.vector(long)
    <class 'ROOT.vector<long,allocator<long> >'>
    >>> stl.vector('vector<int>')
    <class 'ROOT.vector<vector<int,allocator<int> >,allocator<vector<int,allocator<int> > > >'>
    >>> stl.vector(stl.vector('int'))
    <class 'ROOT.vector<vector<int,allocator<int> >,allocator<vector<int,allocator<int> > > >'>
    >>> stl.vector(stl.vector(stl.vector(int)))
    <class 'ROOT.vector<vector<vector<int,allocator<int> >,allocator<vector<int,allocator<int> > > > >'>
    >>> stl.map('string,int')
    <class 'ROOT.map<string,int,less<string>,allocator<pair<const string,int> > >'>
    >>> stl.map('string', 'int')
    <class 'ROOT.map<string,int,less<string>,allocator<pair<const string,int> > >'>
    >>> stl.map(stl.string, int)
    <class 'ROOT.map<string,int,less<string>,allocator<pair<const string,int> > >'>
    >>> stl.map(str, int)
    <class 'ROOT.map<string,int,less<string>,allocator<pair<const string,int> > >'>
    >>> stl.map(str, stl.map(int, stl.vector(float)))
    <class 'ROOT.map<string,map<int,vector<float,allocator<float> > > >'>
    >>> stl.map(str, Hist)
    <class 'ROOT.map<string,TH1,less<string>,allocator<pair<const string,TH1> > >'>
    >>> stl.map(str, ROOT.TH1)
    <class 'ROOT.map<string,TH1,less<string>,allocator<pair<const string,TH1> > >'>
    >>> stl.map(str, 'TH1*')
    <class 'ROOT.map<string,TH1*,less<string>,allocator<pair<const string,TH1*> > >'>

"""
from __future__ import absolute_import

import inspect
import hashlib
import os
import re
from os.path import join as pjoin, exists

import ROOT

from .extern.pyparsing import ParseException

from .base import Object
from .defaults import extra_initialization
from .utils.cpp import CPPGrammar
from .utils.path import mkdir_p
from .utils.lock import lock
from . import compiled
from . import userdata
from . import lookup_by_name, register, QROOT
from . import log; log = log[__name__]

__all__ = []

STL = QROOT.std.stlclasses

HAS_ITERATORS = [
    'map',
    'vector',
    'list'
]

KNOWN_TYPES = {
    # Specify class names and headers to use here. ROOT classes beginning "T"
    # and having a header called {class}.h are picked up automatically.
    # 'TLorentzVector': 'TLorentzVector.h',
    "pair": "<utility>",
    "string": "<string>",
}


# FIXME: _rootpy_dictionary_already_exists returns false positives
# if a third-party module provides "incomplete" dictionaries.
compiled.register_code("""
    #include <string>

    // PyROOT builtin
    namespace PyROOT { namespace Utility {
        const std::string ResolveTypedef( const std::string& name );
    } }

    // cint magic
    int G__defined_tagname(const char*, int);

    // Returns true if the given type does not require a dictionary
    bool _rootpy_dictionary_already_exists(const char* type) {
        const std::string full_typedef = PyROOT::Utility::ResolveTypedef(type);
        return G__defined_tagname(full_typedef.c_str(), 4) != -1;
    }
""", ["_rootpy_dictionary_already_exists"])

LINKDEF = '''\
%(includes)s
#ifdef __CINT__
#pragma link off all globals;
#pragma link off all classes;
#pragma link off all functions;
#pragma link C++ nestedclasses;
#pragma link C++ nestedtypedefs;
#pragma link C++ class %(declaration)s;
#pragma link C++ class %(declaration)s::*;
#ifdef HAS_ITERATOR
#pragma link C++ operators %(declaration)s::iterator;
#pragma link C++ operators %(declaration)s::const_iterator;
#pragma link C++ operators %(declaration)s::reverse_iterator;
#pragma link C++ operators %(declaration)s::const_reverse_iterator;
#endif
#endif
'''

NEW_DICTS = False
LOOKUP_TABLE_NAME = 'lookup'

# Initialized in initialize()
LOADED_DICTS = {}

DICTS_PATH = os.path.join(userdata.BINARY_PATH, 'dicts')
if not os.path.exists(DICTS_PATH):
    # avoid race condition by ignoring OSError if path exists by the time we
    # try to create it. See https://github.com/rootpy/rootpy/issues/328
    mkdir_p(DICTS_PATH)


@extra_initialization
def initialize():
    global DICTS_PATH
    # Used insetad of AddDynamicPath for ordering
    path = ":".join([DICTS_PATH, ROOT.gSystem.GetDynamicPath()])
    ROOT.gSystem.SetDynamicPath(path)
    ROOT.gSystem.AddLinkedLibs("-Wl,-rpath,{0}".format(DICTS_PATH))


class CPPType(CPPGrammar):
    """
    Grammar and representation of a C++ template type. Can handle arbitrary
    nesting and namespaces.
    """
    def __init__(self, parse_result):
        self.parse_result = parse_result
        self.prefix = parse_result.type_prefix
        self.name = ' '.join(parse_result.type_name)
        self.params = parse_result.template_params
        self.member = parse_result.template_member
        self.suffix = parse_result.type_suffix

    def __repr__(self):
        return self.parse_result.dump()

    @classmethod
    def make(cls, string, location, tokens):
        return cls(tokens)

    @property
    def is_template(self):
        """
        Is this a template type? (Does it have template parameters?)
        """
        return bool(self.params)

    def ensure_built(self, headers=None):
        """
        Make sure that a dictionary exists for this type.
        """
        if not self.params:
            return
        else:
            for child in self.params:
                child.ensure_built(headers=headers)
        if headers is None:
            headers = self.guess_headers
        generate(str(self), headers,
                 has_iterators=self.name in HAS_ITERATORS)

    @property
    def guess_headers(self):
        """
        Attempt to guess what headers may be required in order to use this
        type. Returns `guess_headers` of all children recursively.

        * If the typename is in the :const:`KNOWN_TYPES` dictionary, use the
            header specified there
        * If it's an STL type, include <{type}>
        * If it exists in the ROOT namespace and begins with T,
          include <{type}.h>
        """
        name = self.name.replace("*", "")
        headers = []
        if name in KNOWN_TYPES:
            headers.append(KNOWN_TYPES[name])
        elif name in STL:
            headers.append('<{0}>'.format(name))
        elif hasattr(ROOT, name) and name.startswith("T"):
            headers.append('<{0}.h>'.format(name))
        elif '::' in name:
            headers.append('<{0}.h>'.format(name.replace('::', '/')))
        elif name == 'allocator':
            headers.append('<memory>')
        else:
            try:
                # is this just a basic type?
                CPPGrammar.BASIC_TYPE.parseString(name, parseAll=True)
            except ParseException as e:
                # nope... I don't know what it is
                log.warning(
                    "unable to guess headers required for {0}".format(name))
        if self.params:
            for child in self.params:
                headers.extend(child.guess_headers)
        # remove duplicates
        return list(set(headers))

    @property
    def cls(self):
        """
        Return the class definition for this type
        """
        # TODO: register the resulting type?
        return SmartTemplate(self.name)(", ".join(map(str, self.params)))

    @classmethod
    def try_parse(cls, string):
        """
        Try to parse ``string`` as a C++ type, returning :const:`None` on
        failure.
        """
        try:
            with log.ignore("^Failed to parse.*$"):
                return cls.from_string(string)
        except ParseException:
            return None

    @classmethod
    def from_string(cls, string):
        """
        Parse ``string`` into a CPPType instance
        """
        cls.TYPE.setParseAction(cls.make)
        try:
            return cls.TYPE.parseString(string, parseAll=True)[0]
        except ParseException:
            log.error("Failed to parse '{0}'".format(string))
            raise

    def __str__(self):
        """
        Returns the C++ code representation of this type
        """
        prefix = ' '.join(self.prefix)
        if prefix:
            prefix += ' '
        name = self.name
        args = [str(p) for p in self.params] if self.params else []
        templatize = '<{0} >' if args and args[-1].endswith('>') else '<{0}>'
        args = '' if not self.params else templatize.format(', '.join(args))
        member = ('::' + self.member[0]) if self.member else ''
        suffix = ' '.join(self.suffix)
        return "{0}{1}{2}{3}{4}".format(prefix, name, args, member, suffix)


def make_string(obj):
    """
    If ``obj`` is a string, return that, otherwise attempt to figure out the
    name of a type.
    """
    if inspect.isclass(obj):
        if issubclass(obj, Object):
            return obj._ROOT.__name__
        if issubclass(obj, basestring):
            return 'string'
        return obj.__name__
    if not isinstance(obj, basestring):
        raise TypeError("expected string or class")
    return obj


def generate(declaration, headers=None, has_iterators=False):
    """Compile and load the reflection dictionary for a type.

    If the requested dictionary has already been cached, then load that instead.

    Parameters
    ----------
    declaration : str
        A type declaration (for example "vector<int>")
    headers : str or list of str
        A header file or list of header files required to compile the dictionary
        for this type.
    has_iterators : bool
        If True, then include iterators in the dictionary generation.
    """
    global NEW_DICTS
    # FIXME: _rootpy_dictionary_already_exists returns false positives
    # if a third-party module provides "incomplete" dictionaries.
    #if compiled._rootpy_dictionary_already_exists(declaration):
    #    log.debug("generate({0}) => already available".format(declaration))
    #    return
    log.debug("requesting dictionary for {0}".format(declaration))
    if headers:
        if isinstance(headers, basestring):
            headers = sorted(headers.split(';'))
        log.debug("using the headers {0}".format(', '.join(headers)))
        unique_name = ';'.join([declaration] + headers)
    else:
        unique_name = declaration
    unique_name = unique_name.replace(' ', '')

    # If the library is already loaded, do nothing
    if unique_name in LOADED_DICTS:
        log.debug("dictionary for {0} is already loaded".format(declaration))
        return

    libname = hashlib.sha512(unique_name).hexdigest()[:16]
    libnameso = libname + ".so"

    if ROOT.gROOT.GetVersionInt() < 53403:
        # check for this class in the global TClass list and remove it
        # fixes infinite recursion in ROOT < 5.34.03
        # (exact ROOT versions where this is required is unknown)
        cls = ROOT.gROOT.GetClass(declaration)
        if cls and not cls.IsLoaded():
            log.debug("removing {0} from gROOT.GetListOfClasses()".format(
                declaration))
            ROOT.gROOT.GetListOfClasses().Remove(cls)

    # If a .so already exists for this class, use it.
    if exists(pjoin(DICTS_PATH, libnameso)):
        log.debug("loading previously generated dictionary for {0}"
                    .format(declaration))
        if (ROOT.gInterpreter.Load(pjoin(DICTS_PATH, libnameso))
                not in (0, 1)):
            raise RuntimeError(
                "failed to load the library for '{0}' @ {1}".format(
                    declaration, libname))
        LOADED_DICTS[unique_name] = None
        return

    with lock(pjoin(DICTS_PATH, "lock"), poll_interval=5, max_age=60):
        # This dict was not previously generated so we must create it now
        log.info("generating dictionary for {0} ...".format(declaration))
        includes = ''
        if headers is not None:
            for header in headers:
                if re.match('^<.+>$', header):
                    includes += '#include {0}\n'.format(header)
                else:
                    includes += '#include "{0}"\n'.format(header)
        source = LINKDEF % locals()
        sourcepath = os.path.join(DICTS_PATH, '{0}.C'.format(libname))
        log.debug("source path: {0}".format(sourcepath))
        with open(sourcepath, 'w') as sourcefile:
            sourcefile.write(source)
        log.debug("include path: {0}".format(
            ROOT.gSystem.GetIncludePath()))
        if (ROOT.gSystem.CompileMacro(
                sourcepath, 'k-', libname, DICTS_PATH) != 1):
            raise RuntimeError(
                "failed to compile the library for '{0}'".format(
                    sourcepath))

    LOADED_DICTS[unique_name] = None
    NEW_DICTS = True


Template = QROOT.Template


class SmartTemplate(Template):
    """
    Behaves like ROOT's Template class, except it will build dictionaries on
    demand.
    """
    def __call__(self, *params, **kwargs):
        """
        Instantiate the template represented by ``self`` with the template
        arguments specified by ``params``.
        """
        headers = kwargs.pop('headers', None)
        params = ", ".join(make_string(p) for p in params)
        typ = self.__name__
        if params:
            typ = '{0}<{1}>'.format(typ, params)
        cpptype = CPPType.from_string(typ)
        str_name = str(cpptype)
        # check registry
        cls = lookup_by_name(str_name)
        if cls is None:
            cpptype.ensure_built(headers=headers)
            cls = Template.__call__(self, params)
            register(names=str_name, builtin=True)(cls)
        return cls


from .utils.module_facade import Facade


@Facade(__name__, expose_internal=False)
class STLWrapper(object):
    # Base types
    for t in STL:
        locals()[t] = SmartTemplate(t)
    del t
    string = QROOT.string
    CPPType = CPPType
    generate = staticmethod(generate)

########NEW FILE########
__FILENAME__ = test_base
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
import ROOT
from rootpy.base import Object
from rootpy.tests.utils import iter_rootpy_classes
from rootpy import asrootpy
from rootpy.io import MemFile
from nose.tools import assert_equal, assert_true


def test_object():

    with MemFile('test', 'recreate'):
        for cls in iter_rootpy_classes():
            # avoid RooStats bugs for now
            if getattr(cls, '_ROOT', object).__name__.startswith('Roo'):
                continue
            if hasattr(cls, 'dynamic_cls'):
                cls = cls.dynamic_cls()
            assert hasattr(cls, '_ROOT'), \
                "rootpy class {0} does not have a _ROOT attribute".format(
                    cls.__name__)
            if issubclass(cls, ROOT.TDirectory):
                continue
            obj = asrootpy(cls._ROOT())

            if isinstance(obj, Object):
                clone = obj.Clone()


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_compiled
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
import rootpy.compiled as C

C.register_file("test_compiled.cxx",
                ["AnswerToLtUaE", "RootpyTestCompiled"])

C.register_code("""

    #include <string>
    std::string _rootpy_test() { return "Hello, world"; }

""", "_rootpy_test".split())


def test_compiled():
    assert C.AnswerToLtUaE() == 42
    assert C.RootpyTestCompiled().blah() == 84
    assert C._rootpy_test() == "Hello, world"

########NEW FILE########
__FILENAME__ = test_decorators
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy import ROOT
from rootpy.base import Object
from rootpy.decorators import (method_file_check, method_file_cd,
                               snake_case_methods)
from rootpy.io import TemporaryFile
import rootpy
from nose.tools import assert_equal, assert_true, raises


def test_snake_case_methods():

    class A(object):
        def SomeMethod(self): pass
        def some_method(self): pass
        def OtherMethod(self): pass
        def Write(self): pass
        def Cd(self): pass
        def cd(self): pass
        def LongMethodName(self): pass

    @snake_case_methods
    class B(A):
        _ROOT = A
        def write(self): pass

    assert_true(hasattr(B, 'some_method'))
    assert_true(hasattr(B, 'cd'))
    assert_true(hasattr(B, 'long_method_name'))
    assert_true(hasattr(B, 'write'))
    assert_true(hasattr(B, 'other_method'))


def test_snake_case_methods_descriptor():

    def f(_): pass

    class A(object):
        Prop = property(f)
        Sm = staticmethod(f)
        Cm = classmethod(f)
        M = f

    class B(A):
        cm = A.__dict__["Cm"]
        m = A.__dict__["M"]
        prop = A.__dict__["Prop"]
        sm = A.__dict__["Sm"]

    @snake_case_methods
    class snakeB(A):
        _ROOT = A

    # Ensure that no accidental descriptor dereferences happened inside
    # `snake_case_methods`. This is checked by making sure that the types
    # are the same between B and snakeB.

    for member in dir(snakeB):
        if member.startswith("_"): continue
        assert_equal(type(getattr(B, member)), type(getattr(snakeB, member)))


class Foo(Object, ROOT.R.TH1D):

    @method_file_check
    def something(self, foo):
        self.file = ROOT.gDirectory.func()
        return foo

    @method_file_cd
    def write(self):
        assert_true(self.GetDirectory() == ROOT.gDirectory.func())


def test_method_file_check_good():

    foo = Foo()
    with TemporaryFile():
        foo.something(42)


@raises(RuntimeError)
def test_method_file_check_bad():

    foo = Foo()
    foo.something(42)


def test_method_file_cd():

    file1 = TemporaryFile()
    foo = Foo()
    foo.SetDirectory(file1)
    file2 = TemporaryFile()
    foo.write()


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_ROOT
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy import ROOT
from rootpy.plotting.hist import _Hist
from nose.tools import assert_equal, assert_true


def test_ROOT():

    a = ROOT.TH1F("a", "a", 10, 0, 1)
    assert_true(isinstance(a, _Hist))

    b = ROOT.Hist(10, 0, 1, type='F')
    assert_equal(a.TYPE, b.TYPE)


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_root2hdf5
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy.testdata import get_file

from nose.tools import assert_equal, with_setup
from nose.plugins.skip import SkipTest

from tempfile import mkdtemp
import os
import shutil


TEMPDIR = None


def setup_func():

    global TEMPDIR
    TEMPDIR = mkdtemp()


def teardown_func():

    shutil.rmtree(TEMPDIR)


@with_setup(setup_func, teardown_func)
def test_root2hdf5():

    try:
        import tables
    except ImportError:
        raise SkipTest

    from rootpy.root2hdf5 import root2hdf5

    rfile = get_file('test_tree.root')
    hfilename = os.path.join(TEMPDIR, 'out.h5')
    root2hdf5(rfile, hfilename)

    hfile = tables.openFile(hfilename)
    assert_equal(len(hfile.root.test), 1000)
    hfile.close()


@with_setup(setup_func, teardown_func)
def test_root2hdf5_chunked():

    try:
        import tables
    except ImportError:
        raise SkipTest

    from rootpy.root2hdf5 import root2hdf5

    rfile = get_file('test_tree.root')
    hfilename = os.path.join(TEMPDIR, 'out.h5')
    root2hdf5(rfile, hfilename, entries=10)

    hfile = tables.openFile(hfilename)
    assert_equal(len(hfile.root.test), 1000)
    hfile.close()


@with_setup(setup_func, teardown_func)
def test_root2hdf5_chunked_selected():

    try:
        import tables
    except ImportError:
        raise SkipTest

    from rootpy.root2hdf5 import root2hdf5

    rfile = get_file('test_tree.root')
    hfilename = os.path.join(TEMPDIR, 'out.h5')
    root2hdf5(rfile, hfilename, entries=90, selection='i % 2 == 0')

    hfile = tables.openFile(hfilename)
    assert_equal(len(hfile.root.test), 500)
    hfile.close()


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_stl
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
import ROOT
from rootpy import stl
from rootpy.stl import CPPType, generate
from rootpy.testdata import get_file
from rootpy.extern.pyparsing import ParseException

from nose.plugins.attrib import attr
from nose.tools import assert_raises, assert_equal

from multiprocessing import Pool


GOOD = [
    'std::pair<vector<const int*>, double>*',
    'pair<vector<int>, vector<double> >',
    'vector<vector<vector<double> > >::iterator*',
    'map<int, string>',
    'map<int, vector<double> >',
    'map<int, vector<vector<double> > >',
    'vector<unsigned int>',
    'vector<const int*>',
    'vector<unsigned int>',
]

BAD = [
    'pair<vector<int>,double>>',
    'pair<vector<int>,,vector<double> >',
    'vector<<vector<vector<double> > >',
    'int,string',
    'int,vector<double> >',
    'vector<double> >',
    'map<int,vector<vector<double> > >,',
]


def test_parse():
    for template in GOOD:
        assert_equal(template, str(CPPType.from_string(template)))
    for template in BAD:
        assert_raises(ParseException, CPPType.from_string, template)


@attr('slow')
def test_stl():
    generate('map<int,vector<float> >', '<vector>;<map>')
    generate('map<int,vector<int> >', '<vector>;<map>')
    generate('vector<TLorentzVector>', '<vector>;TLorentzVector.h')

    ROOT.std.map('int,vector<float>')
    ROOT.std.map('int,vector<int>')
    ROOT.std.vector('TLorentzVector')

    temp = CPPType.from_string('vector<vector<vector<int> > >')
    temp.ensure_built()

    stl.vector('vector<map<int, string> >')
    stl.vector(stl.string)()
    stl.vector('string')()
    stl.vector(int)

    stl.map("string", "string")
    stl.map(stl.string, stl.string)
    stl.map(int, stl.string)
    stl.map(stl.string, int)
    stl.map("string", ROOT.TLorentzVector)

    histmap = stl.map("string", ROOT.TH1D)()
    a = ROOT.TH1D("a", "a", 10, -1, 1)
    histmap["a"] = a

    StrHist = stl.pair(stl.string, "TH1*")

    generate('pair<map<string,TH1*>::iterator,bool>', '<map>;<TH1.h>')
    histptrmap = stl.map(stl.string, "TH1*")()
    histptrmap.insert(StrHist("test", a))

    assert histptrmap["test"] is a

"""
This test frequently fails on Travis due to os.fork() not being able to
allocate memory. Disabling it for now until a solution is found.

def load_tree(*args):
    with get_file('test_dicts.root') as f:
        t = f.data
        # this will trigger the generation of the required dicts
        t.create_buffer()


def test_dict_load():
    # test file locking
    po = Pool()
    po.map(load_tree, xrange(3))
"""

if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = utils
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from . import log; log = log[__name__]
from .. import _get_class, INIT_REGISTRY_ROOTPY

__all__ = [
    'iter_rootpy_classes',
]


def iter_rootpy_classes():
    for name, path in INIT_REGISTRY_ROOTPY.items():
        try:
            cls = _get_class(path, name)
        except:
            log.warning(
                "unable to get class {0} at {1}".format(name, path))
            continue
        else:
            yield cls

########NEW FILE########
__FILENAME__ = categories
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import re

from .cut import Cut

__all__ = [
    'Categories',
]


class Categories(object):
    """
    Implements a mechanism to ease the creation of cuts that describe
    non-overlapping categories.
    """
    #TODO: use pyparsing
    CUT_REGEX = '[-+]?[0-9]*\.?[0-9]+([eE][-+]?[0-9]+)?'
    NODE_PATTERN = re.compile(
        '^{(?P<variable>[^:|]+)(?::(?P<type>[IFif]))?\|'
        '(?P<leftchild>{.+})?(?P<cut>' + CUT_REGEX + ')'
        '(?P<rightchild>{.+})?}$')
    CATEGORY_PATTERN = re.compile(
        '^(?P<left>{.+})(?:x(?P<right>{.+}(?:x{.+})*))$')
    CATEGORY_NODE_PATTERN = re.compile(
        '^{(?P<variable>[^:|]+)(?::(?P<type>[IFif]))?\|'
        '(?P<cuts>[\*]?(?:' + CUT_REGEX + ')(?:,' + CUT_REGEX + ')*[\*]?)}$')

    @classmethod
    def from_string(cls, string, variables=None):
        node = None
        if variables is None:
            variables = []
        nodematch = re.match(Categories.NODE_PATTERN, string)
        categorymatch = re.match(Categories.CATEGORY_PATTERN, string)
        categorynodematch = re.match(Categories.CATEGORY_NODE_PATTERN, string)
        if categorymatch:
            node = cls.from_string(categorymatch.group('left'), variables)
            subtree = cls.from_string(categorymatch.group('right'), variables)
            incompletenodes = node.get_incomplete_children()
            for child in incompletenodes:
                if not child.leftchild and not child.forbidleft:
                    clone = subtree.clone()
                    child.set_left(clone)
                if not child.rightchild and not child.forbidright:
                    clone = subtree.clone()
                    child.set_right(clone)
        elif categorynodematch:
            var_type = 'F'
            if categorynodematch.group('type'):
                var_type = categorynodematch.group('type').upper()
            variable = (categorynodematch.group('variable'), var_type)
            if variable not in variables:
                variables.append(variable)
            cuts = categorynodematch.group('cuts').split(',')
            if len(cuts) != len(set(cuts)):
                raise SyntaxError(
                    "repeated cuts in '{0}'".format(
                        categorynodematch.group('cuts')))
            if sorted(cuts) != cuts:
                raise SyntaxError(
                    "cuts not in ascending order in '{0}'".format(
                        categorynodematch.group('cuts')))
            nodes = []
            for cut in cuts:
                actual_cut = cut.replace('*', '')
                node = Categories(
                    feature=variables.index(variable),
                    data=actual_cut,
                    variables=variables)
                if cut.startswith('*'):
                    node.forbidleft = True
                if cut.endswith('*'):
                    node.forbidright = True
                nodes.append(node)
            node = Categories.make_balanced_tree(nodes)
        elif nodematch:
            var_type = 'F'
            if nodematch.group('type'):
                var_type = nodematch.group('type').upper()
            variable = (nodematch.group('variable'), var_type)
            if variable not in variables:
                variables.append(variable)
            node = Categories(
                feature=variables.index(variable),
                data=nodematch.group('cut'),
                variables=variables)
            if nodematch.group('leftchild'):
                leftchild = cls.from_string(
                    nodematch.group('leftchild'), variables)
                node.set_left(leftchild)
            if nodematch.group('rightchild'):
                rightchild = cls.from_string(
                    nodematch.group('rightchild'), variables)
                node.set_right(rightchild)
        else:
            raise SyntaxError(
                "{0} is not valid category tree syntax".format(string))
        return node

    @classmethod
    def make_balanced_tree(cls, nodes):
        if len(nodes) == 0:
            return None
        if len(nodes) == 1:
            return nodes[0]
        center = len(nodes) / 2
        leftnodes = nodes[:center]
        rightnodes = nodes[center + 1:]
        node = nodes[center]
        leftchild = Categories.make_balanced_tree(leftnodes)
        rightchild = Categories.make_balanced_tree(rightnodes)
        node.set_left(leftchild)
        node.set_right(rightchild)
        return node

    def __init__(self,
                 feature,
                 data,
                 variables,
                 leftchild=None,
                 rightchild=None,
                 parent=None,
                 forbidleft=False,
                 forbidright=False):
        self.feature = feature
        self.data = data
        self.variables = variables
        self.leftchild = leftchild
        self.rightchild = rightchild
        self.parent = parent
        self.forbidleft = forbidleft
        self.forbidright = forbidright

    def clone(self):
        leftclone = None
        if self.leftchild is not None:
            leftclone = self.leftchild.clone()
        rightclone = None
        if self.rightchild is not None:
            rightclone = self.rightchild.clone()
        return Categories(
            self.feature,
            self.data,
            self.variables,
            leftclone,
            rightclone,
            self.parent,
            self.forbidleft,
            self.forbidright)

    def __str__(self):
        leftstr = ''
        rightstr = ''
        if self.forbidleft:
            leftstr = '*'
        elif self.leftchild is not None:
            leftstr = str(self.leftchild)
        if self.forbidright:
            rightstr = '*'
        elif self.rightchild is not None:
            rightstr = str(self.rightchild)
        if self.feature >= 0:
            return '{{0}:{1}|{2}{3}{4}}'.format(
                self.variables[self.feature],
                leftstr, str(self.data), rightstr)
        return '{<<leaf>>|{0}}'.format(str(self.data))

    def __repr__(self):
        return self.__str__()

    def set_left(self, child):
        if child is self:
            raise ValueError("attempted to set self as left child!")
        self.leftchild = child
        if child is not None:
            child.parent = self

    def set_right(self, child):
        if child is self:
            raise ValueError("attempted to set self as right child!")
        self.rightchild = child
        if child is not None:
            child.parent = self

    def is_leaf(self):
        return self.leftchild is None and self.rightchild is None

    def is_complete(self):
        return self.leftchild is not None and self.rightchild is not None

    def depth(self):
        leftdepth = 0
        if self.leftchild is not None:
            leftdepth = self.leftchild.depth() + 1
        rightdepth = 0
        if self.rightchild is not None:
            rightdepth = self.rightchild.depth() + 1
        return max(leftdepth, rightdepth)

    def balance(self):
        leftdepth = 0
        rightdepth = 0
        if self.leftchild is not None:
            leftdepth = self.leftchild.depth() + 1
        if self.rightchild is not None:
            rightdepth = self.rightchild.depth() + 1
        return rightdepth - leftdepth

    def get_leaves(self):
        if self.is_leaf():
            return [self]
        leftleaves = []
        if self.leftchild is not None:
            leftleaves = self.leftchild.get_leaves()
        rightleaves = []
        if self.rightchild is not None:
            rightleaves = self.rightchild.get_leaves()
        return leftleaves + rightleaves

    def get_incomplete_children(self):
        children = []
        if not self.is_complete():
            children.append(self)
        if self.leftchild is not None:
            children += self.leftchild.get_incomplete_children()
        if self.rightchild is not None:
            children += self.rightchild.get_incomplete_children()
        return children

    def __len__(self):
        """
        Number of categories beneath current node
        """
        if self.is_leaf():
            total = 0
            if not self.forbidleft:
                total += 1
            if not self.forbidright:
                total += 1
            return total
        total = 0
        if not self.forbidleft and self.leftchild is not None:
            total += len(self.leftchild)
        if not self.forbidright and self.rightchild is not None:
            total += len(self.rightchild)
        return total

    def walk(self, expression=None):
        if expression is None:
            expression = Cut()
        if self.feature < 0:
            if expression:
                yield expression
        if not self.forbidleft:
            leftcondition = expression & Cut(
                '{0}<={1}'.format(
                    self.variables[self.feature][0], self.data))
            if self.leftchild is not None:
                for condition in self.leftchild.walk(leftcondition):
                    yield condition
            else:
                yield leftcondition
        if not self.forbidright:
            rightcondition = expression & Cut(
                '{0}>{1}'.format(
                    self.variables[self.feature][0], self.data))
            if self.rightchild is not None:
                for condition in self.rightchild.walk(rightcondition):
                    yield condition
            else:
                yield rightcondition

    def __iter__(self):
        """
        Iterator over leaf conditions
        """
        for category in self.walk():
            yield category

########NEW FILE########
__FILENAME__ = chain
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import multiprocessing
import time

from .. import log; log = log[__name__]
from ..io import root_open, DoesNotExist
from ..utils.extras import humanize_bytes
from ..context import preserve_current_directory
from .filtering import EventFilterList

__all__ = [
    'TreeChain',
    'TreeQueue',
]


class BaseTreeChain(object):

    def __init__(self, name,
                 treebuffer=None,
                 branches=None,
                 ignore_branches=None,
                 events=-1,
                 onfilechange=None,
                 read_branches_on_demand=False,
                 cache=False,
                 # 30 MB cache by default
                 cache_size=30000000,
                 learn_entries=10,
                 always_read=None,
                 ignore_unsupported=False,
                 filters=None):
        self._name = name
        self._buffer = treebuffer
        self._branches = branches
        self._ignore_branches = ignore_branches
        self._tree = None
        self._file = None
        self._events = events
        self._total_events = 0
        self._ignore_unsupported = ignore_unsupported
        self._initialized = False
        if filters is None:
            self._filters = EventFilterList([])
        else:
            self._filters = filters
        if onfilechange is None:
            onfilechange = []
        self._filechange_hooks = onfilechange

        self._read_branches_on_demand = read_branches_on_demand
        self._use_cache = cache
        self._cache_size = cache_size
        self._learn_entries = learn_entries

        self.weight = 1.
        self.userdata = {}

        if not self._rollover():
            raise RuntimeError("unable to initialize TreeChain")

        if always_read is None:
            self._always_read = []
        elif isinstance(always_read, basestring):
            if '*' in always_read:
                always_read = self._tree.glob(always_read)
            else:
                always_read = [always_read]
            self.always_read(always_read)
        else:
            branches = []
            for branch in always_read:
                if '*' in branch:
                    branches += self._tree.glob(branch)
                else:
                    branches.append(branch)
            self.always_read(branches)

    def __nonzero__(self):
        return len(self) > 0

    def _next_file(self):
        """
        Override in subclasses
        """
        return None

    def always_read(self, branches):
        self._always_read = branches
        self._tree.always_read(branches)

    def reset(self):
        if self._tree is not None:
            self._tree = None
        if self._file is not None:
            self._file.Close()
            self._file = None

    def Draw(self, *args, **kwargs):
        """
        Loop over subfiles, draw each, and sum the output into a single
        histogram.
        """
        self.reset()
        output = None
        while self._rollover():
            if not output:
                # Make our own copy of the drawn histogram
                output = self._tree.Draw(*args, **kwargs)
                if output:
                    # Make it memory resident
                    output = output.Clone()
                    output.SetDirectory(0)
            else:
                newoutput = self._tree.Draw(*args, **kwargs)
                if newoutput:
                    output += newoutput
        return output

    def draw(self, *args, **kwargs):
        return self.Draw(*args, **kwargs)

    def __getattr__(self, attr):
        try:
            return getattr(self._tree, attr)
        except AttributeError:
            raise AttributeError("{0} instance has no attribute '{1}'".format(
                self.__class__.__name__, attr))

    def __getitem__(self, item):
        return self._tree.__getitem__(item)

    def __contains__(self, branch):
        return self._tree.__contains__(branch)

    def __iter__(self):
        passed_events = 0
        while True:
            entries = 0
            total_entries = float(self._tree.GetEntries())
            t1 = time.time()
            t2 = t1
            for entry in self._tree:
                entries += 1
                self.userdata = {}
                if self._filters(entry):
                    yield entry
                    passed_events += 1
                    if self._events == passed_events:
                        break
                if time.time() - t2 > 60:
                    entry_rate = int(entries / (time.time() - t1))
                    log.info(
                        "{0:d} entr{1} per second. "
                        "{2:.0f}% done current tree.".format(
                            entry_rate,
                            'ies' if entry_rate != 1 else 'y',
                            100 * entries / total_entries))
                    t2 = time.time()
            if self._events == passed_events:
                break
            log.info("{0:d} entries per second".format(
                int(entries / (time.time() - t1))))
            log.info("read {0:d} bytes in {1:d} transactions".format(
                self._file.GetBytesRead(),
                self._file.GetReadCalls()))
            self._total_events += entries
            if not self._rollover():
                break
        self._filters.finalize()

    def _rollover(self):
        BaseTreeChain.reset(self)
        filename = self._next_file()
        if filename is None:
            return False
        log.info("current file: {0}".format(filename))
        try:
            with preserve_current_directory():
                self._file = root_open(filename)
        except IOError:
            self._file = None
            log.warning("could not open file {0} (skipping)".format(filename))
            return self._rollover()
        try:
            self._tree = self._file.Get(self._name)
        except DoesNotExist:
            log.warning(
                "tree {0} does not exist in file {1} (skipping)".format(
                    self._name, filename))
            return self._rollover()
        if len(self._tree.GetListOfBranches()) == 0:
            log.warning("tree with no branches in file {0} (skipping)".format(
                filename))
            return self._rollover()
        if self._branches is not None:
            self._tree.activate(self._branches, exclusive=True)
        if self._ignore_branches is not None:
            self._tree.deactivate(self._ignore_branches, exclusive=False)
        if self._buffer is None:
            self._tree.create_buffer(self._ignore_unsupported)
            self._buffer = self._tree._buffer
        else:
            self._tree.set_buffer(
                self._buffer,
                ignore_missing=True,
                transfer_objects=True)
            self._buffer = self._tree._buffer
        if self._use_cache:
            # enable TTreeCache for this tree
            log.info(
                "enabling a {0} TTreeCache for the current tree "
                "({1:d} learning entries)".format(
                    humanize_bytes(self._cache_size), self._learn_entries))
            self._tree.SetCacheSize(self._cache_size)
            self._tree.SetCacheLearnEntries(self._learn_entries)
        self._tree.read_branches_on_demand = self._read_branches_on_demand
        self._tree.always_read(self._always_read)
        self.weight = self._tree.GetWeight()
        for target, args in self._filechange_hooks:
            # run any user-defined functions
            target(*args, name=self._name, file=self._file, tree=self._tree)
        return True


class TreeChain(BaseTreeChain):
    """
    A ROOT.TChain replacement
    """
    def __init__(self, name, files, **kwargs):
        if isinstance(files, tuple):
            files = list(files)
        elif not isinstance(files, list):
            files = [files]
        else:
            files = files[:]
        if not files:
            raise RuntimeError(
                "unable to initialize TreeChain: no files")
        self._files = files
        self.curr_file_idx = 0
        super(TreeChain, self).__init__(name, **kwargs)

    def reset(self):
        """
        Reset the chain to the first file
        Note: not valid when in queue mode
        """
        super(TreeChain, self).reset()
        self.curr_file_idx = 0

    def __len__(self):
        return len(self._files)

    def _next_file(self):
        if self.curr_file_idx >= len(self._files):
            return None
        filename = self._files[self.curr_file_idx]
        nfiles_remaining = len(self._files) - self.curr_file_idx
        log.info("{0:d} file{1} remaining".format(
            nfiles_remaining,
            's' if nfiles_remaining > 1 else ''))
        self.curr_file_idx += 1
        return filename


class TreeQueue(BaseTreeChain):

    SENTINEL = None

    def __init__(self, name, files, **kwargs):
        # multiprocessing.queues d.n.e. until one has been created
        multiprocessing.Queue()
        if not isinstance(files, multiprocessing.queues.Queue):
            raise TypeError("files must be a multiprocessing.Queue")
        self._files = files

        super(TreeQueue, self).__init__(name, **kwargs)

    def __len__(self):
        # not reliable
        return self._files.qsize()

    def __nonzero__(self):
        # not reliable
        return not self._files.empty()

    def _next_file(self):
        filename = self._files.get()
        if filename == self.SENTINEL:
            return None
        return filename

########NEW FILE########
__FILENAME__ = cut
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import re

import ROOT

from .. import log; log = log[__name__]
from .. import QROOT
from ..utils import path


__all__ = [
    'Cut',
]


def cutop(func):
    def foo(self, other):
        other = Cut.convert(other)
        if not self:
            return other
        if not other:
            return self
        return func(self, other)
    return foo


def icutop(func):
    def foo(self, other):
        other = Cut.convert(other)
        if not self:
            self.SetTitle(other.GetTitle())
            return self
        if not other:
            return self
        return func(self, other)
    return foo


def _expand_ternary(match):
    return '({0}{1})&&({1}{2})'.format(
        match.group('left'),
        match.group('name'),
        match.group('right'))


_TERNARY = re.compile(
    '(?P<left>[a-zA-Z0-9_\.]+[<>=]+)'
    '(?P<name>\w+)'
    '(?P<right>[<>=]+[a-zA-Z0-9_\.]+)')


class Cut(QROOT.TCut):
    """
    Inherits from ROOT.TCut and implements logical operators
    """
    _ROOT = QROOT.TCut

    def __init__(self, cut='', from_file=False):
        if cut != '':
            if cut is None:
                cut = ''
            elif type(cut) is file:
                cut = ''.join(line.strip() for line in cut.readlines())
            elif isinstance(cut, basestring) and from_file:
                ifile = open(path.expand(cut))
                cut = ''.join(line.strip() for line in ifile.readlines())
                ifile.close()
            elif isinstance(cut, Cut):
                cut = cut.GetTitle()
            # remove whitespace
            cut = cut.replace(' ', '')
            # expand ternary operations (i.e. 3<A<8)
            cut = re.sub(_TERNARY, _expand_ternary, cut)
        super(Cut, self).__init__(cut)

    @staticmethod
    def convert(thing):
        if isinstance(thing, Cut):
            return thing
        elif isinstance(thing, basestring):
            return Cut(thing)
        elif thing is None:
            return Cut()
        return Cut(str(thing))

    @property
    def str(self):
        return self.GetTitle()

    @str.setter
    def str(self, content):
        self.SetTitle(str(content))

    def __mod__(self, other):
        if isinstance(other, Cut):
            other = str(other)
        return Cut(str(self) % other)

    def __imod__(self, other):
        if isinstance(other, Cut):
            other = str(other)
        self.SetTitle(str(self) % other)
        return self

    @cutop
    def __and__(self, other):
        """
        Return a new cut which is the logical AND of this cut and another
        """
        return Cut('({0!s})&&({1!s})'.format(self, other))

    @cutop
    def __rand__(self, other):
        return self & other

    @cutop
    def __mul__(self, other):
        """
        Return a new cut which is the product of this cut and another
        """
        return Cut('({0!s})*({1!s})'.format(self, other))

    @cutop
    def __rmul__(self, other):
        return self * other

    @icutop
    def __imul__(self, other):
        """
        Multiply other cut with self and return self
        """
        self.SetTitle('({0!s})*({1!s})'.format(self, other))
        return self

    @cutop
    def __or__(self, other):
        """
        Return a new cut which is the logical OR of this cut and another
        """
        return Cut('({0!s})||({1!s})'.format(self, other))

    @cutop
    def __ror__(self, other):
        return self | other

    @cutop
    def __add__(self, other):
        """
        Return a new cut which is the sum of this cut and another
        """
        return Cut('({0!s})+({1!s})'.format(self, other))

    @cutop
    def __radd__(self, other):
        return self + other

    @icutop
    def __iadd__(self, other):
        """
        Add other cut to self and return self
        """
        self.SetTitle('({0!s})+({1!s})'.format(self, other))
        return self

    @cutop
    def __sub__(self, other):
        """
        Return a new cut which is the difference of this cut and another
        """
        return Cut('({0!s})-({1!s})'.format(self, other))

    @cutop
    def __rsub__(self, other):
        return self - other

    @icutop
    def __isub__(self, other):
        """
        Subtract other cut to self and return self
        """
        self.SetTitle('({0!s})-({1!s})'.format(self, other))
        return self

    def __neg__(self):
        """
        Return a new cut which is the negation of this cut
        """
        if not self:
            return Cut()
        return Cut('!({0!s})'.format(self))

    def __pos__(self):
        return Cut(self)

    def __str__(self):
        return self.GetTitle()

    def __repr__(self):
        return "'{0!s}'".format(self)

    def __nonzero__(self):
        """
        A cut evaluates to False if it is empty (null cut).
        This has no affect on its actual boolean value within the context of
        a ROOT.TTree selection.
        """
        return str(self) != ''

    def __contains__(self, other):
        return str(other) in str(self)

    def safe(self, parentheses=True):
        """
        Returns a string representation with special characters
        replaced by safer characters for use in file names.
        """
        if not self:
            return ""
        string = str(self)
        string = string.replace("==", "_eq_")
        string = string.replace("<=", "_leq_")
        string = string.replace(">=", "_geq_")
        string = string.replace("<", "_lt_")
        string = string.replace(">", "_gt_")
        string = string.replace("&&", "_and_")
        string = string.replace("||", "_or_")
        string = string.replace("!", "not_")
        if parentheses:
            string = string.replace("(", "L")
            string = string.replace(")", "R")
        else:
            string = string.replace("(", "")
            string = string.replace(")", "")
        string = string.replace(" ", "")
        return string

    def latex(self):
        """
        Returns a string representation for use in LaTeX
        """
        if not self:
            return ""
        s = str(self)
        s = s.replace("==", " = ")
        s = s.replace("<=", " \leq ")
        s = s.replace(">=", " \geq ")
        s = s.replace("&&", r" \text{ and } ")
        s = s.replace("||", r" \text{ or } ")
        return s

    def where(self):
        """
        Return string compatible with PyTable's Table.where syntax:
        http://pytables.github.com/usersguide/libref.html#tables.Table.where
        """
        return re.sub(
            '!(?!=)', '~',
            str(self).replace('&&', '&').replace('||', '|'))

    def replace(self, name, newname):
        """
        Replace all occurrences of name with newname
        """
        if not re.match("[a-zA-Z]\w*", name):
            return None
        if not re.match("[a-zA-Z]\w*", newname):
            return None

        def _replace(match):
            return match.group(0).replace(match.group('name'), newname)

        pattern = re.compile("(\W|^)(?P<name>" + name + ")(\W|$)")
        cut = re.sub(pattern, _replace, str(self))
        return Cut(cut)

########NEW FILE########
__FILENAME__ = cutflow
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from ..extern.tabulartext import TextTable

__all__ = [
    'Cutflow',
]


class Cutflow(object):

    def __init__(self, names=None):
        if names is not None:
            self.__names = names
        else:
            self.__names = []
        self.__dict = None
        self.reset()

    def __setitem__(self, name, passes):
        if name not in self.__names:
            self.__names.append(name)
        self.__dict[name] = str(int(bool(passes)))

    def passed(self, name):
        if name not in self.__names:
            self.__names.append(name)
        self.__dict[name] = '1'

    def stages(self):
        self.reset()
        yield self
        for name in self.__names:
            self.passes(name)
            yield self
        self.reset()

    def reset(self):
        self.__dict = dict((name, '0') for name in self.__names)

    def bitstring(self):
        return ''.join([self.__dict[item] for item in self.__names])

    def int(self):
        if not self.__dict:
            return 0
        return int(self.bitstring(), 2)


class CutflowTable(object):

    def __init__(self, lumi=1.):
        self.lumi = lumi
        self.samples = []
        self.cut_titles = []

    def add_sample(self, sample, name, weight=1.):
        titles = [cut[0] for cut in sample]
        if not self.samples:
            self.cut_titles = titles
        elif titles != self.cut_titles:
            raise ValueError("mismatching cut-flows: names don't match")
        self.samples.append((weight, name, [cut[1] for cut in sample]))

    def __str__(self):
        return self.__repr__()

    def __repr__(self):
        if not self.samples:
            return ''
        table = TextTable()
        table.set_deco(TextTable.HEADER)
        table.add_row([''] + [name for weight, name, cuts in self.samples])
        for title in self.cut_titles:
            table.add_row([title] +
                          [weight * cuts * self.lumi
                           for weight, name, cuts in self.samples])
        return table.draw()

########NEW FILE########
__FILENAME__ = filtering
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module defines a framework for filtering Trees.
The user must write a class which inherits from Filter and
"""
from __future__ import absolute_import

from ..extern.tabulartext import PrettyTable
from . import log; log = log[__name__]

__all__ = [
    'Filter',
    'FilterHook',
    'EventFilter',
    'ObjectFilter',
    'FilterList',
    'EventFilterList',
    'ObjectFilterList',
]


class Filter(object):
    """
    The base class from which all filter classes must inherit from.
    The derived class must override the passes method which returns True
    if ths event passes and returns False if not.
    The number of passing and failing events are recorded and may be used
    later to create a cut-flow.
    """
    def __init__(self,
                 hooks=None,
                 passthrough=False,
                 name=None,
                 count_funcs=None):
        self.total = 0
        self.passing = 0
        self.count_funcs_total = {}
        self.count_funcs_passing = {}

        if count_funcs is not None:
            self.count_funcs = count_funcs
        else:
            self.count_funcs = {}

        for func_name in self.count_funcs.iterkeys():
            self.count_funcs_total[func_name] = 0.
            self.count_funcs_passing[func_name] = 0.

        self.details = {}
        if name is None:
            self.name = self.__class__.__name__
        else:
            self.name = name

        self.hooks = hooks
        self.passthrough = passthrough
        self.was_passed = False
        if self.passthrough:
            log.info(
                "Filter {0} will run in pass-through mode".format(
                    self.__class__.__name__))
        else:
            log.info(
                "Filter {0} is activated".format(
                    self.__class__.__name__))

    def __str__(self):
        return self.__repr__()

    def __getstate__(self):
        return {
            "name": self.name,
            "total": self.total,
            "passing": self.passing,
            "details": self.details,
            "count_funcs": dict([
                (name, None) for name in self.count_funcs.keys()]),
            "count_funcs_total": self.count_funcs_total,
            "count_funcs_passing": self.count_funcs_passing}

    def __setstate__(self, state):
        self.name = state['name']
        self.total = state['total']
        self.passing = state['passing']
        self.details = state['details']
        self.count_funcs = state['count_funcs']
        self.count_funcs_total = state['count_funcs_total']
        self.count_funcs_passing = state['count_funcs_passing']

    def __repr__(self):
        return ("Filter {0}\n"
                "Total: {1:d}\n"
                "Pass:  {2:d}").format(
                    self.name,
                    self.total,
                    self.passing)

    @classmethod
    def add(cls, left, right):
        if left.name != right.name:
            raise ValueError("Attemping to add filters with different names")
        newfilter = Filter()
        newfilter.name = left.name
        newfilter.total = left.total + right.total
        newfilter.passing = left.passing + right.passing
        newfilter.details = dict([
            (detail, left.details[detail] + right.details[detail])
            for detail in left.details.keys()])
        # sum count_funcs
        for func_name in left.count_funcs.keys():
            if func_name not in right.count_funcs:
                raise ValueError(
                    "{0} count is not defined "
                    "for both filters".format(func_name))
            newfilter.count_funcs[func_name] = left.count_funcs[func_name]
            newfilter.count_funcs_total[func_name] = (
                left.count_funcs_total[func_name] +
                right.count_funcs_total[func_name])
            newfilter.count_funcs_passing[func_name] = (
                left.count_funcs_passing[func_name] +
                right.count_funcs_passing[func_name])
        return newfilter

    def __add__(self, other):
        return Filter.add(self, other)

    def passed(self, event):
        self.total += 1
        self.passing += 1
        for name, func in self.count_funcs.iteritems():
            count = func(event)
            self.count_funcs_total[name] += count
            self.count_funcs_passing[name] += count
        self.was_passed = True

    def failed(self, event):
        self.total += 1
        for name, func in self.count_funcs.iteritems():
            count = func(event)
            self.count_funcs_total[name] += count
        self.was_passed = False


class FilterHook(object):

    def __init__(self, target, args):
        self.target = target
        self.args = args

    def __call__(self):
        self.target(*self.args)


class EventFilter(Filter):

    def __call__(self, event):
        if self.passthrough:
            if self.hooks:
                for hook in self.hooks:
                    hook()
            self.passed(event)
            return True
        _passes = self.passes(event)
        if _passes is None:
            # event is not counted in total
            log.warning(
                "Filter {0} returned None so event will not "
                "contribute to cut-flow. Use True to accept event, "
                "otherwise False.".format(self.__class__.__name__))
            return False
        elif _passes:
            if self.hooks:
                for hook in self.hooks:
                    hook()
            self.passed(event)
            return True
        self.failed(event)
        return False

    def passes(self, event):
        """
        You should override this method in your derived class
        """
        return True

    def finalize(self):
        """
        You should override this method in your derived class
        """
        pass


class ObjectFilter(Filter):

    def __init__(self, count_events=False, **kwargs):
        self.count_events = count_events
        super(ObjectFilter, self).__init__(**kwargs)

    def __call__(self, event, collection):
        self.was_passed = False
        if self.count_events:
            self.total += 1
        else:
            self.total += len(collection)
        if not self.passthrough:
            collection = self.filtered(event, collection)
        if len(collection) > 0:
            self.was_passed = True
            if self.count_events:
                self.passing += 1
            else:
                self.passing += len(collection)
        return collection

    def filtered(self, event, collection):
        """
        You should override this method in your derived class
        """
        return collection


class FilterList(list):
    """
    Creates a list of Filters for convenient evaluation of a
    sequence of Filters.
    """
    @classmethod
    def merge(cls, list1, list2):
        if not isinstance(list1, list):
            raise TypeError("list1 must be a FilterList or list")
        if not isinstance(list2, list):
            raise TypeError("list2 must be a FilterList or list")
        filterlist = FilterList()
        for f1, f2 in zip(list1, list2):
            if type(f1) is dict:
                _f1 = Filter()
                _f1.__setstate__(f1)
                f1 = _f1
            if type(f2) is dict:
                _f2 = Filter()
                _f2.__setstate__(f2)
                f2 = _f2
            filterlist.append(f1 + f2)
        return filterlist

    @property
    def total(self):
        if len(self) > 0:
            return self[0].total
        return 0

    @property
    def passing(self):
        if len(self) > 0:
            return self[-1].passing
        return 0

    def basic(self):
        """
        Return all filters as simple dicts for pickling.
        Removes all dependence on this module.
        """
        return [filter.__getstate__() for filter in self]

    def __setitem__(self, filter):
        if not isinstance(filter, (Filter, dict)):
            raise TypeError(
                "FilterList can only hold objects "
                "inheriting from Filter or dict")
        super(FilterList, self).__setitem__(filter)

    def append(self, filter):
        if not isinstance(filter, (Filter, dict)):
            raise TypeError(
                "FilterList can only hold objects "
                "inheriting from Filter or dict")
        super(FilterList, self).append(filter)

    def __str__(self):
        return self.__repr__()

    def __repr__(self):
        if len(self) > 0:
            table = PrettyTable(["Filter", "Pass"])
            table.align["Filter"] = "l"
            table.align["Pass"] = "l"
            table.add_row(["Total", self[0].total])
            for filter in self:
                table.add_row([filter.name, filter.passing])
            _str = str(table)
            # print count_funcs
            # assume same count_funcs in all filters
            # TODO: support possibly different/missing/extra count_funcs
            for func_name in self[0].count_funcs.keys():
                _str += "\n{0} counts\n".format(func_name)
                table = PrettyTable(["Filter", "Pass"])
                table.align["Filter"] = "l"
                table.align["Pass"] = "l"
                table.add_row(["Total", self[0].count_funcs_total[func_name]])
                for filter in self:
                    table.add_row([
                        filter.name,
                        filter.count_funcs_passing[func_name]])
                _str += str(table)
            for filter in self:
                if filter.details:
                    _str += "\n{0} Details\n".format(filter.name)
                    details_table = PrettyTable(["Detail", "Value"])
                    for key, value in filter.details.items():
                        details_table.add_row([key, value])
                    _str += str(details_table)
            return _str
        return "Empty FilterList"


class EventFilterList(FilterList):

    def __call__(self, event):
        for filter in self:
            if not filter(event):
                return False
        return True

    def __setitem__(self, filter):
        if not isinstance(filter, EventFilter):
            raise TypeError(
                "EventFilterList can only hold objects "
                "inheriting from EventFilter")
        super(EventFilterList, self).__setitem__(filter)

    def append(self, filter):
        if not isinstance(filter, EventFilter):
            raise TypeError(
                "EventFilterList can only hold objects "
                "inheriting from EventFilter")
        super(EventFilterList, self).append(filter)

    def finalize(self):
        for filter in self:
            filter.finalize()


class ObjectFilterList(FilterList):

    def __call__(self, event, collection):
        passing_objects = collection
        for filter in self:
            passing_objects = filter(event, passing_objects)
            if not passing_objects:
                return []
        return passing_objects

    def __setitem__(self, filter):
        if not isinstance(filter, ObjectFilter):
            raise TypeError(
                "ObjectFilterList can only hold objects "
                "inheriting from ObjectFilter")
        super(ObjectFilterList, self).__setitem__(filter)

    def append(self, filter):
        if not isinstance(filter, ObjectFilter):
            raise TypeError(
                "ObjectFilterList can only hold objects "
                "inheriting from ObjectFilter")
        super(ObjectFilterList, self).append(filter)

########NEW FILE########
__FILENAME__ = model
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import inspect
from cStringIO import StringIO
import types

import ROOT

from .. import log; log = log[__name__]
from .treetypes import Column
from .treebuffer import TreeBuffer

__all__ = [
    'TreeModel',
]


class TreeModelMeta(type):
    """
    Metaclass for all TreeModels
    Addition/subtraction of TreeModels is handled
    as set union and difference of class attributes
    """
    def __new__(cls, name, bases, dct):
        for attr, value in dct.items():
            TreeModelMeta.checkattr(attr, value)
        return type.__new__(cls, name, bases, dct)

    def __add__(cls, other):
        return type('_'.join([cls.__name__, other.__name__]),
                    (cls, other), {})

    def __iadd__(cls, other):
        return cls.__add__(other)

    def __sub__(cls, other):
        attrs = dict(set(cls.get_attrs()).difference(set(other.get_attrs())))
        return type('_'.join([cls.__name__, other.__name__]),
                    (TreeModel,), attrs)

    def __isub__(cls, other):
        return cls.__sub__(other)

    def __setattr__(cls, attr, value):
        TreeModelMeta.checkattr(attr, value)
        type.__setattr__(cls, attr, value)

    @classmethod
    def checkattr(metacls, attr, value):
        """
        Only allow class attributes that are instances of
        rootpy.types.Column, ROOT.TObject, or ROOT.ObjectProxy
        """
        if not isinstance(value, (
                types.MethodType,
                types.FunctionType,
                classmethod,
                staticmethod,
                property)):
            if attr in dir(type('dummy', (object,), {})) + \
                    ['__metaclass__']:
                return
            if attr.startswith('_'):
                raise SyntaxError(
                    "TreeModel attribute `{0}` "
                    "must not start with `_`".format(attr))
            if not inspect.isclass(value):
                if not isinstance(value, Column):
                    raise TypeError(
                        "TreeModel attribute `{0}` "
                        "must be an instance of "
                        "`rootpy.tree.treetypes.Column`".format(attr))
                return
            if not issubclass(value, (ROOT.TObject, ROOT.ObjectProxy)):
                raise TypeError(
                    "TreeModel attribute `{0}` must inherit "
                    "from `ROOT.TObject` or `ROOT.ObjectProxy`".format(
                        attr))

    def prefix(cls, name):
        """
        Create a new TreeModel where class attribute
        names are prefixed with ``name``
        """
        attrs = dict([(name + attr, value) for attr, value in cls.get_attrs()])
        return TreeModelMeta(
            '_'.join([name, cls.__name__]),
            (TreeModel,), attrs)

    def suffix(cls, name):
        """
        Create a new TreeModel where class attribute
        names are suffixed with ``name``
        """
        attrs = dict([(attr + name, value) for attr, value in cls.get_attrs()])
        return TreeModelMeta(
            '_'.join([cls.__name__, name]),
            (TreeModel,), attrs)

    def get_attrs(cls):
        """
        Get all class attributes ordered by definition
        """
        ignore = dir(type('dummy', (object,), {})) + ['__metaclass__']
        attrs = [
            item for item in inspect.getmembers(cls) if item[0] not in ignore
            and not isinstance(
                item[1], (
                    types.FunctionType,
                    types.MethodType,
                    classmethod,
                    staticmethod,
                    property))]
        # sort by idx and use attribute name to break ties
        attrs.sort(key=lambda attr: (getattr(attr[1], 'idx', -1), attr[0]))
        return attrs

    def to_struct(cls, name=None):
        """
        Convert the TreeModel into a compiled C struct
        """
        if name is None:
            name = cls.__name__
        basic_attrs = dict([(attr_name, value)
                            for attr_name, value in cls.get_attrs()
                            if isinstance(value, Column)])
        if not basic_attrs:
            return None
        src = 'struct {0} {{'.format(name)
        for attr_name, value in basic_attrs.items():
            src += '{0} {1};'.format(value.type.typename, attr_name)
        src += '};'
        if ROOT.gROOT.ProcessLine(src) != 0:
            return None
        return getattr(ROOT, name, None)

    def __repr__(cls):
        out = StringIO()
        for name, value in cls.get_attrs():
            print >> out, '{0} -> {1}'.format(name, value)
        return out.getvalue()[:-1]

    def __str__(cls):
        return repr(cls)


class TreeModel(object):
    __metaclass__ = TreeModelMeta

    def __new__(cls):
        """
        Return a TreeBuffer for this TreeModel
        """
        treebuffer = TreeBuffer()
        for name, attr in cls.get_attrs():
            treebuffer[name] = attr()
        return treebuffer

########NEW FILE########
__FILENAME__ = test_categories
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy.tree.categories import Categories
from nose.tools import assert_raises

GOOD = [
    '{a|1,2,3}',
    '{var1|1,2,3}x{var2|-10,10.3,100*}x{var3|100}',
]

BAD = [
    '{1,2,3}',
    '{a|3,2,1}',
    '{var1|1,2*,3}',
]

def test_from_string():

    for s in GOOD:
        Categories.from_string(s)
    for s in BAD:
        assert_raises(SyntaxError, Categories.from_string, s)

def test_len():

    c = Categories.from_string('{a|1,2,3}')
    assert len(c) == 4
    assert len(c) == len(list(c))

    c = Categories.from_string('{a|1,2,3}x{b|4,5,6}')
    assert len(c) == 16

    c = Categories.from_string('{a|1,2,3}x{b|4,5,6*}')
    assert len(c) == 12

    c = Categories.from_string('{a|1,2,3}x{b|*4,5,6*}')
    assert len(c) == 8

    c = Categories.from_string('{a|1,2,3*}x{b|*4,5,6*}')
    assert len(c) == 6

    c = Categories.from_string('{a|*1,2,3*}x{b|*4,5,6*}')
    assert len(c) == 4


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_tree
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
import ROOT

from rootpy.vector import LorentzVector
from rootpy.tree import Tree, Ntuple, TreeModel, TreeChain
from rootpy.io import root_open, TemporaryFile
from rootpy.tree.treetypes import FloatCol, IntCol
from rootpy.plotting import Hist, Hist2D, Hist3D
from rootpy import testdata
from rootpy import stl

from random import gauss, randint, random
import re
import os

from nose.tools import (assert_raises, assert_almost_equal,
                        assert_equal, raises, with_setup)


FILES = []
FILE_PATHS = []


def create_model():

    class ObjectA(TreeModel):
        # A simple tree object
        x = FloatCol()
        y = FloatCol()
        z = FloatCol()
        vect = LorentzVector

    class ObjectB(TreeModel):
        # A tree object collection
        x = stl.vector('int')
        y = stl.vector('float')
        vect = stl.vector('TLorentzVector')
        # collection size
        n = IntCol()

    class Event(ObjectA.prefix('a_') + ObjectB.prefix('b_')):
        i = IntCol()

    return Event


def create_tree():

    f = TemporaryFile()
    tree = Tree("tree", model=create_model())
    # fill the tree
    for i in xrange(1000):
        assert_equal(tree.a_vect, LorentzVector(0, 0, 0, 0))
        random_vect = LorentzVector(
            gauss(.5, 1.),
            gauss(.5, 1.),
            gauss(.5, 1.),
            gauss(.5, 1.))
        tree.a_vect.copy_from(random_vect)
        assert_equal(tree.a_vect, random_vect)
        tree.a_x = gauss(.5, 1.)
        tree.a_y = gauss(.3, 2.)
        tree.a_z = gauss(13., 42.)
        tree.b_n = randint(1, 5)
        for j in xrange(tree.b_n):
            vect = LorentzVector(
                gauss(.5, 1.),
                gauss(.5, 1.),
                gauss(.5, 1.),
                gauss(.5, 1.))
            tree.b_vect.push_back(vect)
            tree.b_x.push_back(randint(1, 10))
            tree.b_y.push_back(gauss(.3, 2.))
        tree.i = i
        assert_equal(tree.b_n, tree.b_vect.size())
        assert_equal(tree.b_n, tree.b_x.size())
        assert_equal(tree.b_n, tree.b_y.size())
        tree.fill(reset=True)
    tree.write()
    # TFile.Close the file but keep the underlying
    # tempfile file descriptor open
    ROOT.TFile.Close(f)
    FILES.append(f)
    FILE_PATHS.append(f.GetName())


def create_chain():

    for i in range(3):
        create_tree()


def cleanup():

    global FILES
    global FILE_PATHS

    for f in FILES:
        f.close()

    FILES = []
    FILE_PATHS = []


@with_setup(create_tree, cleanup)
def test_attrs():

    with root_open(FILE_PATHS[0]) as f:
        tree = f.tree
        tree.read_branches_on_demand = True
        tree.define_object('a', 'a_')
        tree.define_collection('b', 'b_', 'b_n')
        for event in tree:
            # test a setattr before a getattr with caching
            new_a_y = random()
            event.a_y = new_a_y
            assert_almost_equal(event.a_y, new_a_y)

            assert_equal(event.a_x, event.a.x)
            assert_equal(len(event.b) > 0, True)


@with_setup(create_tree, cleanup)
def test_draw():

    with root_open(FILE_PATHS[0]) as f:
        tree = f.tree

        tree.draw('a_x')
        tree.draw('a_x:a_y')
        tree.draw('a_x:a_y:a_z')
        tree.draw('a_x:a_y:a_z:b_x')
        tree.draw('a_x:a_y:a_z:b_x:b_y', options='para')

        h1 = Hist(10, -1, 2, name='h1')
        h2 = Hist2D(10, -1, 2, 10, -1, 2)
        h3 = Hist3D(10, -1, 2, 10, -1, 2, 10, -1, 2)

        # dimensionality does not match
        assert_raises(TypeError, tree.draw, 'a_x:a_y', hist=h1)

        # name does not match
        assert_raises(ValueError, tree.draw, 'a_x>>+something', hist=h1)

        # hist is not a TH1
        assert_raises(TypeError, tree.draw, 'a_x:a_y', hist=ROOT.TGraph())

        # name does match and is fine (just redundant)
        tree.draw('a_x>>h1', hist=h1)
        assert_equal(h1.Integral() > 0, True)
        h1.Reset()
        tree.draw('a_x>>+h1', hist=h1)
        assert_equal(h1.Integral() > 0, True)
        h1.Reset()

        # both binning and hist are specified
        assert_raises(ValueError, tree.draw, 'a_x>>+h1(10, 0, 1)', hist=h1)

        tree.draw('a_x', hist=h1)
        assert_equal(h1.Integral() > 0, True)
        tree.draw('a_x:a_y', hist=h2)
        assert_equal(h2.Integral() > 0, True)
        tree.draw('a_x:a_y:a_z', hist=h3)
        assert_equal(h3.Integral() > 0, True)

        h3.Reset()
        tree.draw('a_x>0:a_y/2:a_z*2', hist=h3)
        assert_equal(h3.Integral() > 0, True)

        # create a histogram
        hist = tree.draw('a_x:a_y:a_z', create_hist=True)
        assert_equal(hist.Integral() > 0, True)

        hist = tree.draw('a_x:a_y:a_z>>new_hist_1')
        assert_equal(hist.Integral() > 0, True)
        assert_equal(hist.name, 'new_hist_1')

        # create_hist=True is redundant here
        hist = tree.draw('a_x:a_y:a_z>>new_hist_2', create_hist=True)
        assert_equal(hist.Integral() > 0, True)
        assert_equal(hist.name, 'new_hist_2')


@with_setup(create_chain, cleanup)
def test_chain_draw():

    chain = TreeChain('tree', FILE_PATHS)
    hist = Hist(100, 0, 1)
    chain.draw('a_x', hist=hist)
    assert_equal(hist.Integral() > 0, True)

    # check that Draw can be repeated
    hist2 = Hist(100, 0, 1)
    chain.draw('a_x', hist=hist2)
    assert_equal(hist.Integral(), hist2.Integral())


@with_setup(create_chain, cleanup)
def test_chain_draw_hist_init_first():

    hist = Hist(100, 0, 1)
    chain = TreeChain('tree', FILE_PATHS)
    chain.draw('a_x', hist=hist)
    assert_equal(hist.Integral() > 0, True)


@raises(RuntimeError)
def test_require_file_bad():

    t = Tree()


def test_require_file_good():

    with TemporaryFile():
        t = Tree()


@raises(RuntimeError)
def test_require_file_not_writable():

    with testdata.get_file():
        t = Tree()


def test_draw_regex():

    p = Tree.DRAW_PATTERN
    m = re.match
    assert_equal(m(p, 'a') is not None, True)
    assert_equal(m(p, 'somebranch') is not None, True)
    assert_equal(m(p, 'x:y') is not None, True)
    assert_equal(m(p, 'xbranch:y') is not None, True)
    assert_equal(m(p, 'x:y:z') is not None, True)

    expr = '(x%2)>0:sqrt(y)>4:z/3'
    assert_equal(m(p, expr) is not None, True)

    redirect = '>>+histname(10, 0, 1)'
    expr_redirect = expr + redirect
    match = m(p, expr_redirect)
    groupdict = match.groupdict()
    assert_equal(groupdict['branches'], expr)
    assert_equal(groupdict['redirect'], redirect)
    assert_equal(groupdict['name'], 'histname')


def test_file_assoc():

    with TemporaryFile() as f1:
        t = Tree()
        with TemporaryFile() as f2:
            pass
        #f1.cd() <== this should not be needed!
        # the tree should "remember" what file it was created in
        t.Write()


def test_csv():

    from cStringIO import StringIO
    f = testdata.get_file('test_csv.root')
    tree = f.ParTree_Postselect
    tree.create_buffer(ignore_unsupported=True)
    output = StringIO()
    tree.csv(stream=output)
    f.close()
    # compare with existing txt output
    true_output_filename = testdata.get_filepath('test_csv.txt')
    with open(true_output_filename, 'r') as true_output_file:
        true_output = true_output_file.read()
        assert_equal(output.getvalue(), true_output)


def test_ntuple():

    with TemporaryFile():
        ntuple = Ntuple(('a', 'b', 'c'), name='test')
        for i in range(100):
            ntuple.Fill(gauss(.3, 2.), gauss(0, 1.), gauss(-1., 5))
        ntuple.Write()


if __name__ == '__main__':
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_treetypes
from rootpy.tree.treetypes import convert
from nose.tools import assert_equal


def test_convert():

    assert_equal(convert('ROOTNAME', 'NUMPY', 'Bool_t'), 'b')


if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = tree
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import sys
import re
import fnmatch
import uuid

import ROOT

from .. import log; log = log[__name__]
from .. import asrootpy, QROOT
from ..extern.ordereddict import OrderedDict
from ..context import set_directory, thread_specific_tmprootdir, do_nothing
from ..base import NamedObject
from ..decorators import snake_case_methods, method_file_check, method_file_cd
from ..plotting.base import Plottable
from ..plotting import Hist, Canvas
from ..memory.keepalive import keepalive
from .cut import Cut
from .treebuffer import TreeBuffer
from .treetypes import Scalar, Array, BaseChar
from .model import TreeModel

__all__ = [
    'Tree',
    'Ntuple',
]


class UserData(object):
    pass


class BaseTree(NamedObject):

    DRAW_PATTERN = re.compile(
        '^(?P<branches>.+?)'
        '(?P<redirect>\>\>[\+]?'
        '(?P<name>[^\(]+)'
        '(?P<binning>.+)?)?$')

    def _post_init(self):
        """
        The standard rootpy _post_init method that is used to initialize both
        new Trees and Trees retrieved from a File.
        """
        if not hasattr(self, '_buffer'):
            # only set _buffer if model was not specified in the __init__
            self._buffer = TreeBuffer()
        self.read_branches_on_demand = False
        self._branch_cache = {}
        self._current_entry = 0
        self._always_read = []
        self.userdata = UserData()
        self._inited = True

    def always_read(self, branches):
        """
        Always read these branches, even when in caching mode. Maybe you have
        caching enabled and there are branches you want to be updated for each
        entry even though you never access them directly. This is useful if you
        are iterating over an input tree and writing to an output tree sharing
        the same TreeBuffer and you want a direct copy of certain branches. If
        you have caching enabled but these branches are not specified here and
        never accessed then they will never be read from disk, so the values of
        branches in memory will remain unchanged.

        Parameters
        ----------
        branches : list, tuple
            these branches will always be read from disk for every GetEntry
        """
        if type(branches) not in (list, tuple):
            raise TypeError("branches must be a list or tuple")
        self._always_read = branches

    @classmethod
    def branch_type(cls, branch):
        """
        Return the string representation for the type of a branch
        """
        typename = branch.GetClassName()
        if not typename:
            leaf = branch.GetListOfLeaves()[0]
            typename = leaf.GetTypeName()
            # check if leaf has multiple elements
            length = leaf.GetLen()
            if length > 1:
                typename = '{0}[{1:d}]'.format(typename, length)
        return typename

    @classmethod
    def branch_is_supported(cls, branch):
        """
        Currently the branch must only have one leaf but the leaf may have one
        or multiple elements
        """
        return branch.GetNleaves() == 1

    def create_buffer(self, ignore_unsupported=False):
        """
        Create this tree's TreeBuffer
        """
        bufferdict = OrderedDict()
        for branch in self.iterbranches():
            # only include activated branches
            if not self.GetBranchStatus(branch.GetName()):
                continue
            if not BaseTree.branch_is_supported(branch):
                log.warning(
                    "ignore unsupported branch `{0}`".format(branch.GetName()))
                continue
            bufferdict[branch.GetName()] = Tree.branch_type(branch)
        self.set_buffer(TreeBuffer(
            bufferdict,
            ignore_unsupported=ignore_unsupported))

    def create_branches(self, branches):
        """
        Create branches from a TreeBuffer or dict mapping names to type names

        Parameters
        ----------
        branches : TreeBuffer or dict
        """
        if not isinstance(branches, TreeBuffer):
            branches = TreeBuffer(branches)
        self.set_buffer(branches, create_branches=True)

    def update_buffer(self, treebuffer, transfer_objects=False):
        """
        Merge items from a TreeBuffer into this Tree's TreeBuffer

        Parameters
        ----------
        buffer : rootpy.tree.buffer.TreeBuffer
            The TreeBuffer to merge into this Tree's buffer

        transfer_objects : bool, optional (default=False)
            If True then all objects and collections on the input buffer will
            be transferred to this Tree's buffer.
        """
        self._buffer.update(treebuffer)
        if transfer_objects:
            self._buffer.set_objects(treebuffer)

    def set_buffer(self, treebuffer,
                   branches=None,
                   ignore_branches=None,
                   create_branches=False,
                   visible=True,
                   ignore_missing=False,
                   ignore_duplicates=False,
                   transfer_objects=False):
        """
        Set the Tree buffer

        Parameters
        ----------
        treebuffer : rootpy.tree.buffer.TreeBuffer
            a TreeBuffer

        branches : list, optional (default=None)
            only include these branches from the TreeBuffer

        ignore_branches : list, optional (default=None)
            ignore these branches from the TreeBuffer

        create_branches : bool, optional (default=False)
            If True then the branches in the TreeBuffer should be created.
            Use this option if initializing the Tree. A ValueError is raised
            if an attempt is made to create a branch with the same name as one
            that already exists in the Tree. If False the addresses of existing
            branches will be set to point at the addresses in this buffer.

        visible : bool, optional (default=True)
            If True then the branches will be added to the buffer and will be
            accessible as attributes of the Tree.

        ignore_missing : bool, optional (default=False)
            If True then any branches in this buffer that do not exist in the
            Tree will be ignored, otherwise a ValueError will be raised. This
            option is only valid when ``create_branches`` is False.

        ignore_duplicates : bool, optional (default=False)
            If False then raise a ValueError if the tree already has a branch
            with the same name as an entry in the buffer. If True then skip
            branches that already exist. This option is only valid when
            ``create_branches`` is True.

        transfer_objects : bool, optional (default=False)
            If True, all tree objects and collections will be transferred from
            the buffer into this Tree's buffer.
        """
        # determine branches to keep while preserving branch order
        if branches is None:
            branches = treebuffer.keys()
        if ignore_branches is not None:
            branches = [b for b in branches if b not in ignore_branches]

        if create_branches:
            for name in branches:
                value = treebuffer[name]
                if self.has_branch(name):
                    if ignore_duplicates:
                        log.warning(
                            "Skipping entry in buffer with the same name "
                            "as an existing branch: `{0}`".format(name))
                        continue
                    raise ValueError(
                        "Attempting to create two branches "
                        "with the same name: `{0}`".format(name))
                if isinstance(value, Scalar):
                    self.Branch(name, value,
                        '{0}/{1}'.format(
                            name, value.type))
                elif isinstance(value, Array):
                    self.Branch(name, value,
                        '{0}[{2:d}]/{1}'.format(
                            name, value.type, len(value)))
                else:
                    self.Branch(name, value)
        else:
            for name in branches:
                value = treebuffer[name]
                if self.has_branch(name):
                    self.SetBranchAddress(name, value)
                elif not ignore_missing:
                    raise ValueError(
                        "Attempting to set address for "
                        "branch `{0}` which does not exist".format(name))
                else:
                    log.warning(
                        "Skipping entry in buffer for which no "
                        "corresponding branch in the "
                        "tree exists: `{0}`".format(name))
        if visible:
            newbuffer = TreeBuffer()
            for branch in branches:
                if branch in treebuffer:
                    newbuffer[branch] = treebuffer[branch]
            newbuffer.set_objects(treebuffer)
            self.update_buffer(newbuffer, transfer_objects=transfer_objects)

    def activate(self, branches, exclusive=False):
        """
        Activate branches

        Parameters
        ----------
        branches : str or list
            branch or list of branches to activate

        exclusive : bool, optional (default=False)
            if True deactivate the remaining branches
        """
        if exclusive:
            self.SetBranchStatus('*', 0)
        if isinstance(branches, basestring):
            branches = [branches]
        for branch in branches:
            if '*' in branch:
                matched_branches = self.glob(branch)
                for b in matched_branches:
                    self.SetBranchStatus(b, 1)
            elif self.has_branch(branch):
                self.SetBranchStatus(branch, 1)

    def deactivate(self, branches, exclusive=False):
        """
        Deactivate branches

        Parameters
        ----------
        branches : str or list
            branch or list of branches to deactivate

        exclusive : bool, optional (default=False)
            if True activate the remaining branches
        """
        if exclusive:
            self.SetBranchStatus('*', 1)
        if isinstance(branches, basestring):
            branches = [branches]
        for branch in branches:
            if '*' in branch:
                matched_branches = self.glob(branch)
                for b in matched_branches:
                    self.SetBranchStatus(b, 0)
            elif self.has_branch(branch):
                self.SetBranchStatus(branch, 0)

    @property
    def branches(self):
        """
        List of the branches
        """
        return [branch for branch in self.GetListOfBranches()]

    def iterbranches(self):
        """
        Iterator over the branches
        """
        for branch in self.GetListOfBranches():
            yield branch

    @property
    def branchnames(self):
        """
        List of branch names
        """
        return [branch.GetName() for branch in self.GetListOfBranches()]

    def iterbranchnames(self):
        """
        Iterator over the branch names
        """
        for branch in self.iterbranches():
            yield branch.GetName()

    def glob(self, patterns, exclude=None):
        """
        Return a list of branch names that match ``pattern``.
        Exclude all matched branch names which also match a pattern in
        ``exclude``. ``exclude`` may be a string or list of strings.

        Parameters
        ----------
        patterns: str or list
            branches are matched against this pattern or list of patterns where
            globbing is performed with '*'.

        exclude : str or list, optional (default=None)
            branches matching this pattern or list of patterns are excluded
            even if they match a pattern in ``patterns``.

        Returns
        -------
        matches : list
            List of matching branch names
        """
        if isinstance(patterns, basestring):
            patterns = [patterns]
        if isinstance(exclude, basestring):
            exclude = [exclude]
        matches = []
        for pattern in patterns:
            matches += fnmatch.filter(self.iterbranchnames(), pattern)
            if exclude is not None:
                for exclude_pattern in exclude:
                    matches = [match for match in matches
                               if not fnmatch.fnmatch(match, exclude_pattern)]
        return matches

    def __getitem__(self, item):
        """
        Get an entry in the tree or a branch

        Parameters
        ----------
        item : str or int
            if item is a str then return the value of the branch with that name
            if item is an int then call GetEntry
        """
        if isinstance(item, basestring):
            return self._buffer[item]
        self.GetEntry(item)
        return self

    def GetEntry(self, entry):
        """
        Get an entry. Tree collections are reset
        (see ``rootpy.tree.treeobject``)

        Parameters
        ----------
        entry : int
            entry index

        Returns
        -------
        ROOT.TTree.GetEntry : int
            The number of bytes read
        """
        if not (0 <= entry < self.GetEntries()):
            raise IndexError("entry index out of range: {0:d}".format(entry))
        self._buffer.reset_collections()
        return super(BaseTree, self).GetEntry(entry)

    def __iter__(self):
        """
        Iterator over the entries in the Tree.
        """
        if not self._buffer:
            self.create_buffer()
        if self.read_branches_on_demand:
            self._buffer.set_tree(self)
            # drop all branches from the cache
            self.DropBranchFromCache('*')
            for attr in self._always_read:
                try:
                    branch = self._branch_cache[attr]
                except KeyError:  # one-time hit
                    branch = self.GetBranch(attr)
                    if not branch:
                        raise AttributeError(
                            "branch `{0}` specified in "
                            "`always_read` does not exist".format(attr))
                    self._branch_cache[attr] = branch
                # add branches that we should always read to cache
                self.AddBranchToCache(branch)

            for i in xrange(self.GetEntries()):
                # Only increment current entry.
                # getattr on a branch will then GetEntry on only that branch
                # see ``TreeBuffer.get_with_read_if_cached``.
                self._current_entry = i
                self.LoadTree(i)
                for attr in self._always_read:
                    # Always read branched in ``self._always_read`` since
                    # these branches may never be getattr'd but the TreeBuffer
                    # should always be updated to reflect their current values.
                    # This is useful if you are iterating over an input tree
                    # and writing to an output tree that shares the same
                    # TreeBuffer but you don't getattr on all branches of the
                    # input tree in the logic that determines which entries
                    # to keep.
                    self._branch_cache[attr].GetEntry(i)
                self._buffer._entry.set(i)
                yield self._buffer
                self._buffer.next_entry()
                self._buffer.reset_collections()
        else:
            for i in xrange(self.GetEntries()):
                # Read all activated branches (can be slow!).
                super(BaseTree, self).GetEntry(i)
                self._buffer._entry.set(i)
                yield self._buffer
                self._buffer.reset_collections()

    def __setattr__(self, attr, value):
        if '_inited' not in self.__dict__ or attr in self.__dict__:
            return super(BaseTree, self).__setattr__(attr, value)
        try:
            return self._buffer.__setattr__(attr, value)
        except AttributeError:
            raise AttributeError(
                "`{0}` instance has no attribute `{1}`".format(
                    self.__class__.__name__, attr))

    def __getattr__(self, attr):
        if '_inited' not in self.__dict__:
            raise AttributeError(
                "`{0}` instance has no attribute `{1}`".format(
                    self.__class__.__name__, attr))
        try:
            return getattr(self._buffer, attr)
        except AttributeError:
            raise AttributeError(
                "`{0}` instance has no attribute `{1}`".format(
                    self.__class__.__name__, attr))

    def __setitem__(self, item, value):
        self._buffer[item] = value

    def __len__(self):
        """
        Same as GetEntries
        """
        return self.GetEntries()

    def __contains__(self, branch):
        """
        Same as has_branch
        """
        return self.has_branch(branch)

    def has_branch(self, branch):
        """
        Determine if this Tree contains a branch with the name ``branch``

        Parameters
        ----------
        branch : str
            branch name

        Returns
        -------
        has_branch : bool
            True if this Tree contains a branch with the name ``branch`` or
            False otherwise.
        """
        return not not self.GetBranch(branch)

    def csv(self, sep=',', branches=None,
            include_labels=True, limit=None,
            stream=None):
        """
        Print csv representation of tree only including branches
        of basic types (no objects, vectors, etc..)

        Parameters
        ----------
        sep : str, optional (default=',')
            The delimiter used to separate columns

        branches : list, optional (default=None)
            Only include these branches in the CSV output. If None, then all
            basic types will be included.

        include_labels : bool, optional (default=True)
            Include a first row of branch names labelling each column.

        limit : int, optional (default=None)
            Only include up to a maximum of ``limit`` rows in the CSV.

        stream : file, (default=None)
            Stream to write the CSV output on. By default the CSV will be
            written to ``sys.stdout``.
        """
        if stream is None:
            stream = sys.stdout
        if not self._buffer:
            self.create_buffer(ignore_unsupported=True)
        if branches is None:
            branchdict = OrderedDict([
                (name, self._buffer[name])
                for name in self.iterbranchnames()
                if isinstance(self._buffer[name], (Scalar, Array))])
        else:
            branchdict = OrderedDict()
            for name in branches:
                if not isinstance(self._buffer[name], (Scalar, Array)):
                    raise TypeError(
                        "selected branch `{0}` "
                        "is not a scalar or array type".format(name))
                branchdict[name] = self._buffer[name]
        if not branchdict:
            raise RuntimeError(
                "no branches selected or no "
                "branches of scalar or array types exist")
        if include_labels:
            # expand array types to f[0],f[1],f[2],...
            print >> stream, sep.join(
                name if isinstance(value, (Scalar, BaseChar))
                    else sep.join('{0}[{1:d}]'.format(name, idx)
                                  for idx in xrange(len(value)))
                        for name, value in branchdict.items())
        # even though 'entry' is not used, enumerate or simply iterating over
        # self is required to update the buffer with the new branch values at
        # each tree entry.
        for i, entry in enumerate(self):
            print >> stream, sep.join(
                str(v.value) if isinstance(v, (Scalar, BaseChar))
                else sep.join(map(str, v))
                    for v in branchdict.values())
            if limit is not None and i + 1 == limit:
                break

    def Scale(self, value):
        """
        Scale the weight of the Tree by ``value``

        Parameters
        ----------
        value : int, float
            Scale the Tree weight by this value
        """
        self.SetWeight(self.GetWeight() * value)

    def GetEntries(self, cut=None, weighted_cut=None, weighted=False):
        """
        Get the number of (weighted) entries in the Tree

        Parameters
        ----------
        cut : str or rootpy.tree.cut.Cut, optional (default=None)
            Only entries passing this cut will be included in the count

        weighted_cut : str or rootpy.tree.cut.Cut, optional (default=None)
            Apply a weighted selection and determine the weighted number of
            entries.

        weighted : bool, optional (default=False)
            Multiply the number of (weighted) entries by the Tree weight.
        """
        if weighted_cut:
            hist = Hist(1, -1, 2)
            branch = self.GetListOfBranches()[0].GetName()
            weight = self.GetWeight()
            self.SetWeight(1)
            self.Draw('{0}=={1}>>{2}'.format(branch, branch, hist.GetName()),
                      weighted_cut * cut)
            self.SetWeight(weight)
            entries = hist.Integral()
        elif cut:
            entries = super(BaseTree, self).GetEntries(str(cut))
        else:
            entries = super(BaseTree, self).GetEntries()
        if weighted:
            entries *= self.GetWeight()
        return entries

    def GetMaximum(self, expression, cut=None):
        """
        TODO: we need a better way of determining the maximum value of an
        expression.
        """
        if cut:
            self.Draw(expression, cut, 'goff')
        else:
            self.Draw(expression, '', 'goff')
        vals = self.GetV1()
        n = self.GetSelectedRows()
        vals = [vals[i] for i in xrange(min(n, 10000))]
        return max(vals)

    def GetMinimum(self, expression, cut=None):
        """
        TODO: we need a better way of determining the minimum value of an
        expression.
        """
        if cut:
            self.Draw(expression, cut, "goff")
        else:
            self.Draw(expression, "", "goff")
        vals = self.GetV1()
        n = self.GetSelectedRows()
        vals = [vals[i] for i in xrange(min(n, 10000))]
        return min(vals)

    def CopyTree(self, selection, *args, **kwargs):
        """
        Copy the tree while supporting a rootpy.tree.cut.Cut selection in
        addition to a simple string.
        """
        return super(BaseTree, self).CopyTree(str(selection), *args, **kwargs)

    def reset_branch_values(self):
        """
        Reset all values in the buffer to their default values
        """
        self._buffer.reset()

    @method_file_cd
    def Write(self, *args, **kwargs):
        super(BaseTree, self).Write(*args, **kwargs)

    def Draw(self,
             expression,
             selection="",
             options="",
             hist=None,
             create_hist=False,
             **kwargs):
        """
        Draw a TTree with a selection as usual, but return the created
        histogram.

        Parameters
        ----------
        expression : str
            The expression to draw. Multidimensional expressions are separated
            by ":". rootpy reverses the expressions along each dimension so the
            order matches the order of the elements identifying a location in
            the resulting histogram. By default ROOT takes the expression "Y:X"
            to mean Y versus X but we argue that this is counterintuitive and
            that the order should be "X:Y" so that the expression along the
            first dimension identifies the location along the first axis, etc.

        selection : str or rootpy.tree.Cut, optional (default="")
            The cut expression. Only entries satisfying this selection are
            included in the filled histogram.

        options : str, optional (default="")
            Draw options passed to ROOT.TTree.Draw

        hist : ROOT.TH1, optional (default=None)
            The histogram to be filled. If not specified, rootpy will attempt
            to find what ROOT created and return that.

        create_hist : bool (default=False)
            If True and `hist`` is not specified and a histogram name is not
            specified in the draw expression, then override ROOT's
            default behaviour and fill a new histogram. ROOT will otherwise add
            points to a TGraph or TPolyMarker3D if not drawing in more than
            two dimensions.

        kwargs : dict, optional
            Remaining keword arguments are used to set the style attributes of
            the histogram.

        Returns
        -------
        If ``hist`` is specified, None is returned. If ``hist`` is left
        unspecified, an attempt is made to retrieve the generated histogram
        which is then returned.

        """
        # Check that we have a valid draw expression and pick out components
        exprmatch = re.match(BaseTree.DRAW_PATTERN, expression)
        if not exprmatch:
            raise ValueError(
                "not a valid draw expression: `{0}`".format(expression))

        # Reverse variable order to match order in hist constructor
        exprdict = exprmatch.groupdict()
        fields = exprdict['branches'].split(':')
        num_dimensions = len(fields)
        expression = ':'.join(fields[:3][::-1] + fields[3:])
        if exprdict['redirect'] is not None:
            expression += exprdict['redirect']

        if not isinstance(selection, Cut):
            # Let Cut handle any extra processing (i.e. ternary operators)
            selection = Cut(selection)

        graphics = 'goff' not in options

        if hist is not None:
            if not isinstance(hist, ROOT.TH1):
                raise TypeError("Cannot draw into a `{0}`".format(type(hist)))

            # Check that the dimensionality of the expression and object match
            if num_dimensions != hist.GetDimension():
                raise TypeError(
                    "The dimensionality of the expression `{0}` ({1:d}) "
                    "does not match the dimensionality of a `{2}`".format(
                        expression, num_dimensions, hist.__class__.__name__))
            # Handle graphics ourselves
            if graphics:
                if options:
                    options += ' '
                options += 'goff'
            if exprdict['name'] is None:
                # Draw into histogram supplied by user
                expression = '{0}>>+{1}'.format(expression, hist.GetName())
            else:
                if exprdict['name'] != hist.GetName():
                    # If the user specified a name to draw into then check that
                    # this is consistent with the specified object.
                    raise ValueError(
                        "The name specified in the draw "
                        "expression `{0}` does not match the "
                        "name of the specified object `{1}`".format(
                            exprdict['name'],
                            hist.GetName()))
                # Check that binning is not specified
                if exprdict['binning'] is not None:
                    raise ValueError(
                        "When specifying the object to draw into, do not "
                        "specify a binning in the draw expression")
        else:
            if create_hist and exprdict['name'] is None:
                if num_dimensions > 4:
                    raise ValueError(
                        "Cannot create a histogram for expressions with "
                        "more than 4 dimensions")
                newname = uuid.uuid4().hex
                expression += '>>{0}'.format(newname)
                exprdict['name'] = newname

            pad = ROOT.gPad.func()
            own_pad = False

            if graphics and not pad:
                # Create a new canvas if one doesn't exist yet
                own_pad = True
                pad = Canvas()

        #  Note: TTree.Draw() pollutes gDirectory, make a temporary one
        with thread_specific_tmprootdir():
            if hist is not None:
                # If a custom histogram is specified (i.e, it's not being
                # created root side), then temporarily put it into the
                # temporary thread-specific directory.
                context = set_directory(hist)
            else:
                context = do_nothing()
            with context:
                super(BaseTree, self).Draw(expression, selection, options)

        if hist is None:
            # Retrieve histogram made by TTree.Draw
            if num_dimensions == 1 or exprdict['name'] is not None:
                # a TH1
                hist = asrootpy(self.GetHistogram(), warn=False)
            elif num_dimensions == 2:
                # a TGraph
                hist = asrootpy(pad.GetPrimitive('Graph'), warn=False)
            else:
                # ROOT: For a three and four dimensional Draw the TPolyMarker3D
                # is unnamed, and cannot be retrieved. Why, ROOT?
                log.warning(
                    "Cannot retrieve the TPolyMarker3D for "
                    "3D and 4D expressions")
                if graphics and own_pad:
                    # Since we cannot access the TPolyMarker3D we use self to
                    # keep the canvas alive
                    keepalive(self, pad)
            if hist: # is not None
                if isinstance(hist, Plottable):
                    hist.decorate(**kwargs)
                # ROOT, don't try to delete this object! (See issue #277)
                hist.SetBit(ROOT.kCanDelete, False)
                if graphics:
                    if own_pad:
                        # The usual bug is that the histogram is garbage
                        # collected and we want the canvas to keep the
                        # histogram alive, but here the canvas has been
                        # created locally and we are returning the histogram,
                        # so we want the histogram to keep the canvas alive.
                        keepalive(hist, pad)
                    # Redraw the histogram since we may have specified style
                    # attributes in **kwargs
                    hist.Draw()
            if graphics:
                pad.Modified()
                pad.Update()
        return hist

    def to_array(self, *args, **kwargs):
        """
        Convert this tree into a NumPy structured array
        """
        from root_numpy import tree2array
        return tree2array(self, *args, **kwargs)


@snake_case_methods
class Tree(BaseTree, QROOT.TTree):
    """
    Inherits from TTree so all regular TTree methods are available
    but certain methods (i.e. Draw) have been overridden
    to improve usage in Python.

    Parameters
    ----------
    name : str, optional (default=None)
        The Tree name (a UUID if None)

    title : str, optional (default=None)
        The Tree title (empty string if None)

    model : TreeModel, optional (default=None)
        If specified then this TreeModel will be used to create the branches
    """
    _ROOT = QROOT.TTree

    @method_file_check
    def __init__(self, name=None, title=None, model=None):
        super(Tree, self).__init__(name=name, title=title)
        self._buffer = TreeBuffer()
        if model is not None:
            if not issubclass(model, TreeModel):
                raise TypeError("the model must subclass TreeModel")
            self.set_buffer(model(), create_branches=True)
        self._post_init()

    def Fill(self, reset=False):
        """
        Fill the Tree with the current values in the buffer

        Parameters
        ----------
        reset : bool, optional (default=False)
            Reset the values in the buffer to their default values after
            filling.
        """
        super(Tree, self).Fill()
        # reset all branches
        if reset:
            self._buffer.reset()


@snake_case_methods
class Ntuple(BaseTree, QROOT.TNtuple):
    """
    Inherits from TNtuple so all regular TNtuple/TTree methods are available
    but certain methods (i.e. Draw) have been overridden
    to improve usage in Python.

    Parameters
    ----------
    varlist : list of str
        A list of the field names

    name : str, optional (default=None)
        The Ntuple name (a UUID if None)

    title : str, optional (default=None)
        The Ntuple title (empty string if None)

    bufsize : int, optional (default=32000)
        Basket buffer size
    """
    _ROOT = QROOT.TNtuple

    @method_file_check
    def __init__(self, varlist, name=None, title=None, bufsize=32000):
        super(Ntuple, self).__init__(':'.join(varlist), bufsize,
                                     name=name,
                                     title=title)
        self._post_init()

########NEW FILE########
__FILENAME__ = treebuffer
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import re

import ROOT

from ..extern.ordereddict import OrderedDict
from . import log
from .. import lookup_by_name, create, stl
from ..base import Object
from .treetypes import Scalar, Array, Int, Char, UChar, BaseCharArray
from .treeobject import TreeCollection, TreeObject, mix_classes

__all__ = [
    'TreeBuffer',
]


class TreeBuffer(OrderedDict):
    """
    A dictionary mapping branch names to values
    """
    ARRAY_PATTERN = re.compile('^(?P<type>[^\[]+)\[(?P<length>\d+)\]$')

    def __init__(self,
                 branches=None,
                 tree=None,
                 ignore_unsupported=False):
        super(TreeBuffer, self).__init__()
        self._fixed_names = {}
        self._branch_cache = {}
        self._branch_cache_event = {}
        self._tree = tree
        self._ignore_unsupported = ignore_unsupported
        self._current_entry = 0
        self._collections = {}
        self._objects = []
        self._entry = Int(0)
        if branches is not None:
            self.__process(branches)
        self._inited = True

    @classmethod
    def __clean(cls, branchname):
        # Replace invalid characters with '_'
        branchname = re.sub('[^0-9a-zA-Z_]', '_', branchname)
        # Remove leading characters until we find a letter or underscore
        return re.sub('^[^a-zA-Z_]+', '', branchname)

    def __process(self, branches):
        if not branches:
            return
        if not isinstance(branches, dict):
            try:
                branches = dict(branches)
            except TypeError:
                raise TypeError(
                    "branches must be a dict or anything "
                    "the dict constructor accepts")
        processed = []
        for name, vtype in branches.items():
            if name in processed:
                raise ValueError(
                    "duplicate branch name `{0}`".format(name))
            processed.append(name)
            obj = None
            array_match = re.match(TreeBuffer.ARRAY_PATTERN, vtype)
            if array_match:
                vtype = array_match.group('type') + '[]'
                length = int(array_match.group('length'))
                # try to lookup type in registry
                cls = lookup_by_name(vtype)
                if cls is not None:
                    # special case for [U]Char and [U]CharArray with
                    # null-termination
                    if issubclass(cls, BaseCharArray):
                        if length == 2:
                            obj = cls.scalar()
                        elif length == 1:
                            raise ValueError(
                                "char branch `{0}` is not "
                                "null-terminated".format(name))
                        else:
                            # leave slot for null-termination
                            obj = cls(length)
                    else:
                        obj = cls(length)
            else:
                # try to lookup type in registry
                cls = lookup_by_name(vtype)
                if cls is not None:
                    obj = cls()
                else:
                    cpptype = stl.CPPType.try_parse(vtype)
                    if cpptype and cpptype.is_template:
                        obj = cpptype.cls()
                    else:
                        # last resort: try to create ROOT.'vtype'
                        obj = create(vtype)
            if obj is None:
                if not self._ignore_unsupported:
                    raise TypeError(
                        "branch `{0}` has unsupported "
                        "type `{1}`".format(name, vtype))
                else:
                    log.warning(
                        "ignoring branch `{0}` with "
                        "unsupported type `{1}`".format(name, vtype))
            else:
                self[name] = obj

    def reset(self):
        for value in self.itervalues():
            if isinstance(value, (Scalar, Array)):
                value.reset()
            elif isinstance(value, Object):
                value._ROOT.__init__(value)
            elif isinstance(value, (ROOT.TObject, ROOT.ObjectProxy)):
                value.__init__()
            else:
                # there should be no other types of objects in the buffer
                raise TypeError(
                    "cannot reset object of type `{0}`".format(type(value)))

    def update(self, branches=None):
        if branches is None:
            # don't break super update
            return
        if isinstance(branches, TreeBuffer):
            self._entry = branches._entry
            for name, value in branches.items():
                super(TreeBuffer, self).__setitem__(name, value)
            self._fixed_names.update(branches._fixed_names)
        else:
            self.__process(branches)

    def set_tree(self, tree=None):
        self._branch_cache = {}
        self._branch_cache_event = {}
        self._tree = tree
        self._current_entry = 0

    def next_entry(self):
        super(TreeBuffer, self).__setattr__('_branch_cache_event', {})
        self._current_entry += 1

    def get_with_read_if_cached(self, attr):
        if self._tree is not None:
            try:
                branch = self._branch_cache[attr]
            except KeyError:
                # branch is being accessed for the first time
                branch = self._tree.GetBranch(attr)
                if not branch:
                    raise AttributeError
                self._branch_cache[attr] = branch
                self._tree.AddBranchToCache(branch)
            if branch not in self._branch_cache_event:
                # branch is being accessed for the first time in this entry
                branch.GetEntry(self._current_entry)
                self._branch_cache_event[branch] = None
        return super(TreeBuffer, self).__getitem__(attr)

    def __setitem__(self, name, value):
        # for a key to be used as an attr it must be a valid Python identifier
        fixed_name = TreeBuffer.__clean(name)
        if fixed_name in dir(self) or fixed_name.startswith('_'):
            raise ValueError("illegal branch name: `{0}`".format(name))
        if fixed_name != name:
            self._fixed_names[fixed_name] = name
        super(TreeBuffer, self).__setitem__(name, value)

    def __getitem__(self, name):
        return self.get_with_read_if_cached(name)

    def __setattr__(self, attr, value):
        """
        Maps attributes to values.
        Only if we are initialized
        """
        # this test allows attributes to be set in the __init__ method
        # any normal attributes are handled normally
        if '_inited' not in self.__dict__ or attr in self.__dict__:
            return super(TreeBuffer, self).__setattr__(attr, value)
        elif attr in self:
            variable = self.get_with_read_if_cached(attr)
            if isinstance(variable, (Scalar, Array)):
                variable.set(value)
                return
            elif isinstance(variable, Object):
                variable.copy_from(value)
                return
            raise TypeError(
                "cannot set attribute `{0}` of `{1}` instance".format(
                    attr, self.__class__.__name__))
        raise AttributeError(
            "`{0}` instance has no attribute `{1}`".format(
                self.__class__.__name__, attr))

    def __getattr__(self, attr):
        if '_inited' not in self.__dict__:
            raise AttributeError(
                "`{0}` instance has no attribute `{1}`".format(
                    self.__class__.__name__, attr))
        if attr in self._fixed_names:
            attr = self._fixed_names[attr]
        try:
            variable = self.get_with_read_if_cached(attr)
            if isinstance(variable, Scalar):
                return variable.value
            return variable
        except (KeyError, AttributeError):
            raise AttributeError(
                "{0} instance has no attribute `{1}`".format(
                    self.__class__.__name__, attr))

    def reset_collections(self):
        for coll in self._collections.iterkeys():
            coll.reset()

    def define_collection(self, name, prefix, size, mix=None):
        coll = TreeCollection(self, name, prefix, size, mix=mix)
        object.__setattr__(self, name, coll)
        self._collections[coll] = (name, prefix, size, mix)
        return coll

    def define_object(self, name, prefix, mix=None):
        cls = TreeObject
        if mix is not None:
            cls = mix_classes(TreeObject, mix)
        obj = cls(self, name, prefix)
        object.__setattr__(self, name, obj)
        self._objects.append((name, prefix, mix))
        return obj

    def set_objects(self, other):
        for args in other._objects:
            self.define_object(*args)
        for args in other._collections.itervalues():
            self.define_collection(*args)

    def __str__(self):
        return self.__repr__()

    def __repr__(self):
        rep = ''
        for name, value in self.items():
            rep += '{0} -> {1}\n'.format(name, repr(value))
        return rep

########NEW FILE########
__FILENAME__ = treeobject
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from copy import deepcopy

__all__ = [
    'TreeObject',
    'TreeCollectionObject',
    'TreeCollection',
]

__MIXINS__ = {}


def mix_classes(cls, mixins):

    if not isinstance(mixins, tuple):
        mixins = (mixins,)

    classes = (cls,) + mixins
    cls_names = [cls.__name__] + [m.__name__ for m in mixins]
    mixed_name = '_'.join(cls_names)
    inheritance = ', '.join(cls_names)
    inits = '{cls.__name__}.__init__(self, *args, **kwargs)\n'.format(cls=cls)
    inits += '\n'.join(['        {0}.__init__(self)'.format(m.__name__)
                        for m in mixins])
    cls_def = '''class {mixed_name}({inheritance}):
    def __init__(self, *args, **kwargs):
        {inits}'''.format(
            mixed_name=mixed_name,
            inheritance=inheritance,
            inits=inits)
    namespace = dict([(c.__name__, c) for c in classes])
    exec cls_def in namespace
    return namespace[mixed_name]


class TreeObject(object):

    def __init__(self, tree, name, prefix):

        self.tree = tree
        self.name = name
        self.prefix = prefix
        self._inited = True

    def __eq__(self, other):

        return (isinstance(other, self.__class__) and
                self.name == other.name and
                self.prefix == other.prefix)

    def __hash__(self):

        return hash((
            self.__class__.__name__,
            self.name,
            self.prefix))

    def __getitem__(self, attr):

        return getattr(self, attr)

    def __setitem__(self, attr, value):

        setattr(self.tree, self.prefix + attr, value)

    def __getattr__(self, attr):

        return getattr(self.tree, self.prefix + attr)

    def __setattr__(self, attr, value):

        if '_inited' not in self.__dict__:
            return object.__setattr__(self, attr, value)
        try:
            setattr(self.tree, self.prefix + attr, value)
        except AttributeError:
            return object.__setattr__(self, attr, value)

    def define_object(self, name, prefix):

        obj = TreeObject(self, name, prefix)
        object.__setattr__(self, name, obj)
        return obj


class TreeCollectionObject(TreeObject):

    def __init__(self, tree, name, prefix, index):

        self.index = index
        super(TreeCollectionObject, self).__init__(tree, name, prefix)
        self._inited = True

    def __eq__(self, other):

        return TreeObject.__eq__(self, other) and self.index == other.index

    def __hash__(self):

        return hash((
            self.__class__.__name__,
            self.name,
            self.prefix,
            self.index))

    def __getattr__(self, attr):

        try:
            return getattr(self.tree, self.prefix + attr)[self.index]
        except IndexError:
            raise IndexError(
                "index {0:d} out of range for "
                "attribute `{1}` of collection `{2}` of size {3:d}".format(
                    self.index, attr, self.prefix,
                    len(getattr(self.tree, self.prefix + attr))))

    def __setattr__(self, attr, value):

        if '_inited' not in self.__dict__:
            return object.__setattr__(self, attr, value)
        try:
            getattr(self.tree, self.prefix + attr)[self.index] = value
        except IndexError:
            raise IndexError(
                "index {0:d} out of range for "
                "attribute `{1}` of collection `{2}` of size {3:d}".format(
                    self.index, attr, self.prefix,
                    len(getattr(self.tree, self.prefix + attr))))
        except AttributeError:
            return object.__setattr__(self, attr, value)


class TreeCollection(object):

    def __init__(self, tree, name, prefix, size, mix=None, cache=True):

        self.tree = tree
        self.name = name
        self.prefix = prefix
        self.size = size
        self.selection = None

        self.__cache_objects = cache
        self.__cache = {}

        self.tree_object_cls = TreeCollectionObject
        if mix is not None:
            if mix in __MIXINS__:
                self.tree_object_cls = __MIXINS__[mix]
            else:
                self.tree_object_cls = mix_classes(TreeCollectionObject, mix)
                __MIXINS__[mix] = self.tree_object_cls

    def __nonzero__(self):

        return len(self) > 0

    def reset(self):

        self.reset_selection()
        self.reset_cache()

    def reset_selection(self):

        self.selection = None

    def reset_cache(self):

        self.__cache = {}

    def remove(self, thing):

        if self.selection is None:
            self.selection = range(len(self))
        for i, other in enumerate(self):
            if thing == other:
                self.selection.pop(i)
                break

    def pop(self, index):

        if self.selection is None:
            self.selection = range(len(self))
        thing = self[index]
        self.selection.pop(index)
        return thing

    def select(self, func):

        if self.selection is None:
            self.selection = range(len(self))
        self.selection = [
            i for i, thing in zip(self.selection, self)
            if func(thing)]

    def select_indices(self, indices):

        if self.selection is None:
            self.selection = range(len(self))
        self.selection = [self.selection[i] for i in indices]

    def mask(self, func):

        if self.selection is None:
            self.selection = range(len(self))
        self.selection = [
            i for i, thing in zip(self.selection, self)
            if not func(thing)]

    def mask_indices(self, indices):

        if self.selection is None:
            self.selection = range(len(self))
        self.selection = [
            j for i, j in enumerate(self.selection)
            if i not in indices]

    def _wrap_sort_key(self, key):

        def wrapped_key(index):
            return key(self.getitem(index))
        return wrapped_key

    def sort(self, key, **kwargs):

        if self.selection is None:
            self.selection = range(len(self))
        self.selection.sort(key=self._wrap_sort_key(key), **kwargs)

    def slice(self, start=0, stop=None, step=1):

        if self.selection is None:
            self.selection = range(len(self))
        self.selection = self.selection[slice(start, stop, step)]

    def make_persistent(self):
        """
        Perform actual selection and sorting on underlying
        attribute vectors
        """
        pass

    def getitem(self, index):
        """
        direct access without going through self.selection
        """
        if index >= getattr(self.tree, self.size):
            raise IndexError(index)
        if self.__cache_objects and index in self.__cache:
            return self.__cache[index]
        obj = self.tree_object_cls(self.tree, self.name, self.prefix, index)
        if self.__cache_objects:
            self.__cache[index] = obj
        return obj

    def __getitem__(self, index):

        if type(index) is slice:
            return [self[i] for i in xrange(*index.indices(len(self)))]
        if index >= len(self):
            raise IndexError(index)
        if self.selection is not None:
            index = self.selection[index]
        if self.__cache_objects and index in self.__cache:
            return self.__cache[index]
        obj = self.tree_object_cls(self.tree, self.name, self.prefix, index)
        if self.__cache_objects:
            self.__cache[index] = obj
        return obj

    def len(self):
        """
        length of original collection
        """
        return getattr(self.tree, self.size)

    def __len__(self):

        if self.selection is not None:
            return len(self.selection)
        return getattr(self.tree, self.size)

    def __iter__(self):

        for index in xrange(len(self)):
            yield self.__getitem__(index)


def one_to_one_assoc(name, collection, index_branch):

    collection = deepcopy(collection)
    collection.reset()
    cls_def = \
    '''class OneToOne{name}(object):
    @property
    def {name}(self):
        return collection[self.{index_branch}]
    '''.format(name=name, index_branch=index_branch)
    namespace = {}
    exec cls_def in namespace
    return namespace['OneToOne{name}'.format(name=name)]


def one_to_many_assoc(name, collection, index_branch):

    collection = deepcopy(collection)
    collection.reset()
    cls_def = \
    '''class OneToMany{name}(object):
    def __init__(self):
        self.{name} = deepcopy(collection)
        self.{name}.reset()
        self.{name}.select_indices(self.{index_branch})
    '''.format(name=name, index_branch=index_branch)
    namespace = {}
    exec cls_def in namespace
    return namespace['OneToMany{name}'.format(name=name)]

########NEW FILE########
__FILENAME__ = treetypes
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Wrappers for basic types that are compatible with ROOT TTrees
"""
from __future__ import absolute_import

import itertools
from array import array

from .. import register

# only list Column subclasses here
__all__ = [
    'ObjectCol',
    'BoolCol',
    'BoolArrayCol',
    'CharCol',
    'CharArrayCol',
    'UCharCol',
    'UCharArrayCol',
    'ShortCol',
    'ShortArrayCol',
    'UShortCol',
    'UShortArrayCol',
    'IntCol',
    'IntArrayCol',
    'UIntCol',
    'UIntArrayCol',
    'LongCol',
    'LongArrayCol',
    'ULongCol',
    'ULongArrayCol',
    'FloatCol',
    'FloatArrayCol',
    'DoubleCol',
    'DoubleArrayCol',
]


class Column(object):
    _counter = itertools.count()

    def __init__(self, *args, **kwargs):
        self.idx = Column._counter.next()
        self.args = args
        self.kwargs = kwargs

    def __call__(self):
        return self.type(*self.args, **self.kwargs)

    def __repr__(self):
        arg_params = ', '.join([str(a) for a in self.args])
        kwd_params = ', '.join(['{0}={1}'.format(name, value)
                                for name, value in self.kwargs.items()])
        params = []
        if arg_params:
            params.append(arg_params)
        if kwd_params:
            params.append(kwd_params)
        return "{0}({1})".format(
            self.__class__.__name__, ', '.join(params))

    def __str__(self):
        return repr(self)


class ObjectCol(Column):

    def __init__(self, cls, *args, **kwargs):
        self.type = cls
        Column.__init__(self, *args, **kwargs)


class Scalar(object):

    def clear(self):
        """Supplied to match the interface of ROOT.vector"""
        self.reset()


class BaseScalar(Scalar, array):
    """This is the base class for all variables"""

    def __init__(self, resetable=True):
        array.__init__(self)
        self.resetable = resetable

    def reset(self):
        """Reset the value to the default"""
        if self.resetable:
            self[0] = self.default

    @property
    def value(self):
        """The current value"""
        return self[0]

    def set(self, value):
        """Set the value"""
        if isinstance(value, BaseScalar):
            self[0] = self.convert(value.value)
        else:
            self[0] = self.convert(value)

    def __str__(self):
        return self.__repr__()

    def __repr__(self):
        return "{0}({1}) at {2}".format(
            self.__class__.__name__, repr(self.value), id(self).__hex__())

    def __getitem__(self, i):
        return array.__getitem__(self, 0)

    def __setitem__(self, i, value):
        if isinstance(value, BaseScalar):
            array.__setitem__(self, 0, value.value)
        else:
            array.__setitem__(self, 0, value)

    def __lt__(self, value):
        if isinstance(value, BaseScalar):
            return self.value < value.value
        return self.value < value

    def __le__(self, value):
        if isinstance(value, BaseScalar):
            return self.value <= value.value
        return self.value <= value

    def __eq__(self, value):
        if isinstance(value, BaseScalar):
            return self.value == value.value
        return self.value == value

    def __ne__(self, value):
        if isinstance(value, BaseScalar):
            return self.value != value.value
        return self.value != value

    def __gt__(self, value):
        if isinstance(value, BaseScalar):
            return self.value > value.value
        return self.value > value

    def __ge__(self, value):
        if isinstance(value, BaseScalar):
            return self.value >= value.value
        return self.value >= value

    def __nonzero__(self):
        return self.value != 0

    def __add__(self, other):
        if isinstance(other, BaseScalar):
            return self.value + other.value
        return self.value + other

    def __radd__(self, other):
        return self + other

    def __sub__(self, other):
        if isinstance(other, BaseScalar):
            return self.value - other.value
        return self.value - other

    def __rsub__(self, other):
        return other - self.value

    def __mul__(self, other):
        if isinstance(other, BaseScalar):
            return self.value * other.value
        return self.value * other

    def __rmul__(self, other):
        return self * other

    def __div__(self, other):
        if isinstance(other, BaseScalar):
            return self.value / other.value
        return self.value / other

    def __rdiv__(self, other):
        return other / self.value


class Array(object):

    def clear(self):
        """Supplied to match the interface of ROOT.vector"""
        self.reset()


class BaseArray(Array, array):
    """This is the base class for all array variables"""

    def __init__(self, resetable=True):
        array.__init__(self)
        self.resetable = resetable

    def reset(self):
        """Reset the value to the default"""
        if self.resetable:
            for i in xrange(len(self)):
                self[i] = self.default

    def set(self, other):
        for i, thing in enumerate(other):
            self[i] = self.convert(thing)
        for i in xrange(i + 1, len(self)):
            self[i] = self.default

    def __str__(self):
        return self.__repr__()

    def __repr__(self):
        return "{0}[{1}] at {2}".format(
            self.__class__.__name__,
            ', '.join(map(str, self)),
            id(self).__hex__())


class BaseChar(object):

    @property
    def value(self):
        return str(self.rstrip(b'\0').decode('ascii'))

    def __str__(self):
        return self.value

    def __repr__(self):
        return "{0}[{1}] at {2}".format(
            self.__class__.__name__,
            repr(str(self)),
            id(self).__hex__())


class BaseCharScalar(BaseChar, Scalar, bytearray):
    """This is the base class for all char variables"""

    def __init__(self, resetable=True):
        bytearray.__init__(self, 2)
        self.resetable = resetable

    def reset(self):
        """Reset the value to the default"""
        if self.resetable:
            # reset to null bytes
            self[0] = 0

    def set(self, other):
        self[0] = other


class BaseCharArray(BaseChar, Array, bytearray):
    """This is the base class for all char array variables"""

    def __init__(self, length, resetable=True):
        if not isinstance(length, int):
            raise TypeError("char array length must be an int")
        if length < 2:
            raise ValueError(
                "char array length must be at least 2 "
                "to include null-termination")
        bytearray.__init__(self, length)
        self.resetable = resetable

    def reset(self):
        """Reset the value to the default"""
        if self.resetable:
            # reset to null bytes
            self[:] = bytearray(len(self))

    def set(self, other):
        # leave the null-termination untouched
        if len(other) >= len(self):
            raise ValueError(
                "string of length {0:d} is too long to "
                "fit in array of length {1:d} with null-termination".format(
                    len(other), len(self)))
        self[:len(other)] = other


@register(names=('B', 'Bool_t'), builtin=True)
class Bool(BaseScalar):
    """
    This is a variable containing a Boolean type
    """
    # The ROOT character representation of the Boolean type
    type = 'O'
    typename = 'Bool_t'

    def __new__(cls, default=False, **kwargs):
        return BaseScalar.__new__(cls, 'B', [Bool.convert(default)])

    def __init__(self, default=False, **kwargs):
        BaseScalar.__init__(self, **kwargs)
        self.default = Bool.convert(default)

    @classmethod
    def convert(cls, value):
        return int(bool(value))


class BoolCol(Column):
    type = Bool


@register(names=('B[]', 'Bool_t[]'), builtin=True)
class BoolArray(BaseArray):
    """
    This is an array of Booleans
    """
    # The ROOT character representation of the Boolean type
    type = 'O'
    typename = 'Bool_t'
    convert = Bool.convert

    def __new__(cls, length, default=False, **kwargs):
        return BaseArray.__new__(
            cls, 'B',
            [Bool.convert(default)] * length)

    def __init__(self, length, default=False, **kwargs):
        BaseArray.__init__(self, **kwargs)
        self.default = Bool.convert(default)


class BoolArrayCol(Column):
    type = BoolArray


@register(names=('C', 'Char_t'), builtin=True)
class Char(BaseCharScalar):
    """
    This is a variable containing a character type
    """
    # The ROOT character representation of the char type
    type = 'C'
    typename = 'Char_t'


class CharCol(Column):
    type = Char


@register(names=('C[]', 'Char_t[]'), builtin=True)
class CharArray(BaseCharArray):
    """
    This is an array of characters
    """
    # The ROOT character representation of the char type
    type = 'C'
    typename = 'Char_t'
    scalar = Char


class CharArrayCol(Column):
    type = CharArray


@register(names=('UC', 'UChar_t'), builtin=True)
class UChar(BaseCharScalar):
    """
    This is a variable containing an unsigned character type
    """
    # The ROOT character representation of the unsigned char type
    type = 'c'
    typename = 'UChar_t'


class UCharCol(Column):
    type = UChar


@register(names=('UC[]', 'UChar_t[]'), builtin=True)
class UCharArray(BaseCharArray):
    """
    This is an array of unsigned characters
    """
    # The ROOT character representation of the unsigned char type
    type = 'c'
    typename = 'UChar_t'
    scalar = UChar


class UCharArrayCol(Column):
    type = UCharArray


@register(names=('S', 'Short_t'), builtin=True)
class Short(BaseScalar):
    """
    This is a variable containing an integer
    """
    # The ROOT character representation of the short type
    type = 'S'
    typename = 'Short_t'

    def __new__(cls, default=0, **kwargs):
        return BaseScalar.__new__(cls, 'h', [Short.convert(default)])

    def __init__(self, default=0, **kwargs):
        BaseScalar.__init__(self, **kwargs)
        self.default = Short.convert(default)

    @classmethod
    def convert(cls, value):
        return int(value)


class ShortCol(Column):
    type = Short


@register(names=('S[]', 'Short_t[]'), builtin=True)
class ShortArray(BaseArray):
    """
    This is an array of integers
    """
    # The ROOT character representation of the short type
    type = 'S'
    typename = 'Short_t'
    convert = Short.convert

    def __new__(cls, length, default=0, **kwargs):
        return BaseArray.__new__(
            cls, 'h',
            [Short.convert(default)] * length)

    def __init__(self, length, default=0, **kwargs):
        BaseArray.__init__(self, **kwargs)
        self.default = Short.convert(default)


class ShortArrayCol(Column):
    type = ShortArray


@register(names=('US', 'UShort_t'), builtin=True)
class UShort(BaseScalar):
    """
    This is a variable containing a short
    """
    # The ROOT character representation of the unsigned short type
    type = 's'
    typename = 'UShort_t'

    def __new__(cls, default=0, **kwargs):
        return BaseScalar.__new__(cls, 'H', [UShort.convert(default)])

    def __init__(self, default=0, **kwargs):
        BaseScalar.__init__(self, **kwargs)
        self.default = UShort.convert(default)

    @classmethod
    def convert(cls, value):
        if value < 0:
            raise ValueError(
                "Assigning negative value ({0:d}) "
                "to unsigned type".format(value))
        return int(value)


class UShortCol(Column):
    type = UShort


@register(names=('US[]', 'UShort_t[]'), builtin=True)
class UShortArray(BaseArray):
    """
    This is an array of unsigned shorts
    """
    # The ROOT character representation of the unsigned short type
    type = 's'
    typename = 'UShort_t'
    convert = UShort.convert

    def __new__(cls, length, default=0, **kwargs):
        return BaseArray.__new__(
            cls, 'H',
            [UShort.convert(default)] * length)

    def __init__(self, length, default=0, **kwargs):
        BaseArray.__init__(self, **kwargs)
        self.default = UShort.convert(default)


class UShortArrayCol(Column):
    type = UShortArray


@register(names=('I', 'Int_t'), builtin=True)
class Int(BaseScalar):
    """
    This is a variable containing an integer
    """
    # The ROOT character representation of the integer type
    type = 'I'
    typename = 'Int_t'

    def __new__(cls, default=0, **kwargs):
        return BaseScalar.__new__(cls, 'i', [Int.convert(default)])

    def __init__(self, default=0, **kwargs):
        BaseScalar.__init__(self, **kwargs)
        self.default = Int.convert(default)

    @classmethod
    def convert(cls, value):
        return int(value)


class IntCol(Column):
    type = Int


@register(names=('I[]', 'Int_t[]'), builtin=True)
class IntArray(BaseArray):
    """
    This is an array of integers
    """
    # The ROOT character representation of the integer type
    type = 'I'
    typename = 'Int_t'
    convert = Int.convert

    def __new__(cls, length, default=0, **kwargs):
        return BaseArray.__new__(
            cls, 'i',
            [Int.convert(default)] * length)

    def __init__(self, length, default=0, **kwargs):
        BaseArray.__init__(self, **kwargs)
        self.default = Int.convert(default)


class IntArrayCol(Column):
    type = IntArray


@register(names=('UI', 'UInt_t'), builtin=True)
class UInt(BaseScalar):
    """
    This is a variable containing an unsigned integer
    """
    # The ROOT character representation of the unsigned integer type
    type = 'i'
    typename = 'UInt_t'

    def __new__(cls, default=0, **kwargs):
        return BaseScalar.__new__(cls, 'I', [UInt.convert(default)])

    def __init__(self, default=0, **kwargs):
        BaseScalar.__init__(self, **kwargs)
        self.default = UInt.convert(default)

    @classmethod
    def convert(cls, value):
        if value < 0:
            raise ValueError(
                "Assigning negative value ({0:d}) "
                "to unsigned type".format(value))
        return long(value)


class UIntCol(Column):
    type = UInt


@register(names=('UI[]', 'UInt_t[]'), builtin=True)
class UIntArray(BaseArray):
    """
    This is an array of unsigned integers
    """
    # The ROOT character representation of the unsigned integer type
    type = 'i'
    typename = 'UInt_t'
    convert = UInt.convert

    def __new__(cls, length, default=0, **kwargs):
        return BaseArray.__new__(
            cls, 'I',
            [UInt.convert(default)] * length)

    def __init__(self, length, default=0, **kwargs):
        BaseArray.__init__(self, **kwargs)
        self.default = UInt.convert(default)


class UIntArrayCol(Column):
    type = UIntArray


@register(names=('L', 'Long64_t'), builtin=True)
class Long(BaseScalar):
    """
    This is a variable containing a long
    """
    # The ROOT character representation of the long type
    type = 'L'
    typename = 'Long64_t'

    def __new__(cls, default=0, **kwargs):
        return BaseScalar.__new__(cls, 'l', [Long.convert(default)])

    def __init__(self, default=0, **kwargs):
        BaseScalar.__init__(self, **kwargs)
        self.default = Long.convert(default)

    @classmethod
    def convert(cls, value):
        return long(value)


class LongCol(Column):
    type = Long


@register(names=('L[]', 'Long64_t[]'), builtin=True)
class LongArray(BaseArray):
    """
    This is an array of longs
    """
    # The ROOT character representation of the long type
    type = 'L'
    typename = 'Long64_t'
    convert = Long.convert

    def __new__(cls, length, default=0, **kwargs):
        return BaseArray.__new__(
            cls, 'l',
            [Long.convert(default)] * length)

    def __init__(self, length, default=0, **kwargs):
        BaseArray.__init__(self, **kwargs)
        self.default = Long.convert(default)


class LongArrayCol(Column):
    type = LongArray


@register(names=('UL', 'ULong64_t'), builtin=True)
class ULong(BaseScalar):
    """
    This is a variable containing an unsigned long
    """
    # The ROOT character representation of the long type
    type = 'l'
    typename = 'ULong64_t'

    def __new__(cls, default=0, **kwargs):
        return BaseScalar.__new__(cls, 'L', [ULong.convert(default)])

    def __init__(self, default=0, **kwargs):
        BaseScalar.__init__(self, **kwargs)
        self.default = ULong.convert(default)

    @classmethod
    def convert(cls, value):
        if value < 0:
            raise ValueError(
                "Assigning negative value ({0:d}) "
                "to unsigned type".format(value))
        return long(value)


class ULongCol(Column):
    type = ULong


@register(names=('UL[]', 'ULong64_t[]'), builtin=True)
class ULongArray(BaseArray):
    """
    This is of unsigned longs
    """
    # The ROOT character representation of the long type
    type = 'l'
    typename = 'ULong64_t'
    convert = ULong.convert

    def __new__(cls, length, default=0, **kwargs):
        return BaseArray.__new__(
            cls, 'L',
            [ULong.convert(default)] * length)

    def __init__(self, length, default=0, **kwargs):
        BaseArray.__init__(self, **kwargs)
        self.default = ULong.convert(default)


class ULongArrayCol(Column):
    type = ULongArray


@register(names=('F', 'Float_t'), builtin=True)
class Float(BaseScalar):
    """
    This is a variable containing a float
    """
    # The ROOT character representation of the float type
    type = 'F'
    typename = 'Float_t'

    def __new__(cls, default=0., **kwargs):
        return BaseScalar.__new__(cls, 'f', [Float.convert(default)])

    def __init__(self, default=0., **kwargs):
        BaseScalar.__init__(self, **kwargs)
        self.default = Float.convert(default)

    @classmethod
    def convert(cls, value):
        return float(value)


class FloatCol(Column):
    type = Float


@register(names=('F[]', 'Float_t[]'), builtin=True)
class FloatArray(BaseArray):
    """
    This is an array of floats
    """
    # The ROOT character representation of the float type
    type = 'F'
    typename = 'Float_t'
    convert = Float.convert

    def __new__(cls, length, default=0., **kwargs):
        return BaseArray.__new__(
            cls, 'f',
            [Float.convert(default)] * length)

    def __init__(self, length, default=0., **kwargs):
        BaseArray.__init__(self, **kwargs)
        self.default = Float.convert(default)


class FloatArrayCol(Column):
    type = FloatArray


@register(names=('D', 'Double_t'), builtin=True)
class Double(BaseScalar):
    """
    This is a variable containing a double
    """
    # The ROOT character representation of the double type
    type = 'D'
    typename = 'Double_t'

    def __new__(cls, default=0., **kwargs):
        return BaseScalar.__new__(cls, 'd', [Double.convert(default)])

    def __init__(self, default=0., **kwargs):
        BaseScalar.__init__(self, **kwargs)
        self.default = Double.convert(default)

    @classmethod
    def convert(cls, value):
        return float(value)


class DoubleCol(Column):
    type = Double


@register(names=('D[]', 'Double_t[]'), builtin=True)
class DoubleArray(BaseArray):
    """
    This is an array of doubles
    """
    # The ROOT character representation of the double type
    type = 'D'
    typename = 'Double_t'
    convert = Double.convert

    def __new__(cls, length, default=0., **kwargs):
        return BaseArray.__new__(
            cls, 'd',
            [Double.convert(default)] * length)

    def __init__(self, length, default=0., **kwargs):
        BaseArray.__init__(self, **kwargs)
        self.default = Double.convert(default)


class DoubleArrayCol(Column):
    type = DoubleArray


# ROOT type codes:
root_type_codes = '''\
O       a boolean (Bool_t) (see note 1)
B       an 8 bit signed integer (Char_t)
b       an 8 bit unsigned integer (UChar_t)
S       a 16 bit signed integer (Short_t)
s       a 16 bit unsigned integer (UShort_t)
I       a 32 bit signed integer (Int_t)
i       a 32 bit unsigned integer (UInt_t)
L       a 64 bit signed integer (Long64_t)
l       a 64 bit unsigned integer (ULong64_t)
F       a 32 bit floating point (Float_t)
D       a 64 bit floating point (Double_t)\
'''

root_type_codes = [line.split()[0] for line in root_type_codes.split('\n')]

# ROOT type names:
root_type_names = '''\
Bool_t
Char_t
UChar_t
Short_t
UShort_t
Int_t
UInt_t
Long64_t
ULong64_t
Float_t
Double_t\
'''

root_type_names = [line.split()[0] for line in root_type_names.split('\n')]

# Python array:
python_codes = '''\
B       unsigned char   int                 1 (used as boolean)
b       signed char     int                 1
B       unsigned char   int                 1
h       signed short    int                 2
H       unsigned short  int                 2
i       signed int      int                 2
I       unsigned int    long                2
l       signed long     int                 4
L       unsigned long   long                4
f       float           float               4
d       double          float               8\
'''

python_codes = [line.split()[0] for line in python_codes.split('\n')]

# Python NumPy array:
numpy_codes = '''\
b       Boolean
i1      Char
u1      Unsigned Char
i2      Short Integer
u2      Unsigned Short integer
i4      Integer
u4      Unsigned integer
i8      Long Integer
u8      Unsigned Long integer
f4      Floating point
f8      Double Floating point\
'''

numpy_codes = [line.split()[0] for line in numpy_codes.split('\n')]


def convert(origin, target, type):
    """
    convert type from origin to target
    origin/target must be ROOTCODE, ROOTNAME, ARRAY, or NUMPY
    """
    _origin = origin.upper()
    if _origin == 'ROOTCODE':
        _origin = root_type_codes
    elif _origin == 'ROOTNAME':
        _origin = root_type_names
    elif _origin == 'ARRAY':
        _origin = python_codes
    elif _origin == 'NUMPY':
        _origin = numpy_codes
    else:
        raise ValueError("{0} is not a valid type".format(origin))

    _target = target.upper()
    if _target == 'ROOTCODE':
        _target = root_type_codes
    elif _target == 'ROOTNAME':
        _target = root_type_names
    elif _target == 'ARRAY':
        _target = python_codes
    elif _target == 'NUMPY':
        _target = numpy_codes
    else:
        raise ValueError("{0} is not a valid type".format(target))

    if type not in _origin:
        raise ValueError("{0} is not a valid {1} type".format(type, origin))

    return _target[_origin.index(type)]

########NEW FILE########
__FILENAME__ = userdata
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module handles creation of the user-data area
"""
from __future__ import absolute_import

import os
import tempfile
import atexit
from os.path import expanduser, expandvars, exists, isdir, join as pjoin
from platform import machine

from . import log; log = log[__name__]
from . import QROOT, IN_NOSETESTS
from .defaults import extra_initialization

__all__ = [
    'DATA_ROOT',
    'CONFIG_ROOT',
    'BINARY_PATH',
    'ARCH',
]

if "XDG_CONFIG_HOME" not in os.environ:
    os.environ["XDG_CONFIG_HOME"] = expanduser('~/.config')
if "XDG_CACHE_HOME" not in os.environ:
    os.environ["XDG_CACHE_HOME"] = expanduser('~/.cache')


def ensure_directory(variable, default):
    path = os.getenv(variable)
    if path is None:
        path = expandvars(default)
    else:
        path = expandvars(expanduser(path))

    # check if expanduser failed:
    if path.startswith('~'):
        path = None
    elif not exists(path):
        os.makedirs(path)
    elif not isdir(path):
        # A file at path already exists
        path = None
    return path


DATA_ROOT = CONFIG_ROOT = None
GRID_MODE = os.getenv('ROOTPY_GRIDMODE') in ('1', 'true')

if (os.getenv('DEBUG', None) or not (GRID_MODE or IN_NOSETESTS)):
    DATA_ROOT = ensure_directory(
        'ROOTPY_DATA', '${XDG_CACHE_HOME}/rootpy')
    CONFIG_ROOT = ensure_directory(
        'ROOTPY_CONFIG', '${XDG_CONFIG_HOME}/rootpy')

if DATA_ROOT is None:
    log.info("Placing user data in /tmp.")
    log.warning(
        "Make sure '~/.cache/rootpy' or $ROOTPY_DATA is a writable "
        "directory so that it isn't necessary to recreate all user "
        "data each time")

    DATA_ROOT = tempfile.mkdtemp()

    @atexit.register
    def __cleanup():
        import shutil
        shutil.rmtree(DATA_ROOT)

BINARY_PATH = None

ARCH = "{0}-{1}".format(machine(), QROOT.gROOT.GetVersionInt())
if BINARY_PATH is None:
    BINARY_PATH = pjoin(DATA_ROOT, ARCH)


@extra_initialization
def show_binary_path():
    log.debug("Using binary path: {0}".format(BINARY_PATH))

########NEW FILE########
__FILENAME__ = cinterface
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Functions useful for interfacing with C/C++ functions:

* ``callback`` => Allows you to pass ctypes CFUNCTYPE objects as parameters to
              PyROOT functions
* ``objectproxy_realaddress`` => Determine the real address of a ROOT objects
    (useful because multiple ObjectProxies can point to the same underlying object)
"""
from __future__ import absolute_import

import ctypes as C

from . import quickroot as QROOT

__all__ = [
    'callback',
    'objectproxy_realaddress',
]


def callback(cfunc):
    """
    Turn a ctypes CFUNCTYPE instance into a value which can be passed into PyROOT
    """
    # Note:
    # ROOT wants a c_voidp whose addressof() == the call site of the target
    # function. This hackery is necessary to achieve that.
    return C.c_voidp.from_address(C.cast(cfunc, C.c_voidp).value)


def objectproxy_realaddress(obj):
    """
    Obtain a real address as an integer from an objectproxy.
    """
    voidp = QROOT.TPython.ObjectProxy_AsVoidPtr(obj)
    return C.addressof(C.c_char.from_buffer(voidp))

########NEW FILE########
__FILENAME__ = cpp
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import re

from ..extern.pyparsing import (Optional, Keyword, Literal, Combine, Word,
        OneOrMore, QuotedString, delimitedList, ParseException,
        nums, alphas, alphanums, Group, Forward, Regex)
from .. import log; log = log[__name__]

__all__  = [
    'CPPGrammar',
]


class CPPGrammar(object):
    """
    A grammar for parsing C++ method/function signatures and types
    """
    ERROR_PATTERN = re.compile('\(line:\d+, col:(\d+)\)')

    QUOTED_STRING = (
        QuotedString('"', escChar='\\') | Literal('""') |
        QuotedString("'", escChar='\\') | Literal("''"))

    PTR = Combine(OneOrMore(Word("*") | Word("&")), adjacent=False)
    SIGN = Optional(Literal('+') | Literal('-'))
    CONST = Keyword("const")
    SIGNED = Optional(Keyword('signed') | Keyword('unsigned'))
    STATIC = Keyword('static')
    VOID = Combine(Literal('void') + Optional(PTR), adjacent=False)

    BASIC_TYPE = Group(
        Keyword('bool') |
        (SIGNED + Keyword('char')) |
        (SIGNED + Keyword('short')) |
        (SIGNED + Keyword('int')) |
        (SIGNED + Keyword('long') + Optional(Keyword('long'))) |
        Keyword('enum') |
        Keyword('float') |
        (Optional('long') + Keyword('double')))('type_name')

    IDENTIFIER = Word(alphas + "_", alphanums + "_").setName("identifier")

    hexnums = nums + "abcdefABCDEF" + "_?"
    base = Regex("'[bBoOdDhH]").setName("base")
    BASEDNUMBER = Combine(
        Optional(Word(nums + "_")) + base +
        Word(hexnums + "xXzZ"),
        joinString=" ", adjacent=False).setName("based number")
    NUMBER = (
        BASEDNUMBER |
        Regex(r"[-+]?([0-9]*\.[0-9]+|[0-9]+\.?)([Ee][-+]?[0-9]+)?")
        ).setName("numeric")

    ARITH_OPERATOR = Word("*/+-").setName('arith op')
    BIT_OPERATOR = Word('&|').setName('bit op')
    BIT_EXPRESSION = (IDENTIFIER +
        OneOrMore(BIT_OPERATOR + IDENTIFIER)).setName('bit_expression')
    EXPRESSION = OneOrMore(
        NUMBER | ARITH_OPERATOR | IDENTIFIER).setName('expression')
    FULL_EXPRESSION = OneOrMore(
        NUMBER | ARITH_OPERATOR |
        Literal('(') | Literal(')')).setName('full_expression')

    NAMESPACED_NAME = (Optional(Literal('::')).suppress() +
            delimitedList(IDENTIFIER, delim='::', combine=True))

    TYPE = Forward()

    TEMPLATE_PARAMS = (
        Literal("<").suppress() +
        Group(delimitedList(TYPE | FULL_EXPRESSION))("template_params") +
        Literal(">").suppress())

    CLASS_MEMBER = (
        Literal('::').suppress() +
        NAMESPACED_NAME)("template_member")

    COMPLEX_TYPE = (
        Group(NAMESPACED_NAME)('type_name') +
        Optional(TEMPLATE_PARAMS + Optional(CLASS_MEMBER)))

    TYPE << (
        Group(Optional(CONST))('type_prefix') +
        (BASIC_TYPE | COMPLEX_TYPE) +
        Group(Optional(PTR + Optional(CONST)))('type_suffix'))

    TYPE_EXPRESSION = (
        Optional(NUMBER + ARITH_OPERATOR) + TYPE)('type_expression')

    SIMPLE_ARG_DEFAULT = Forward()
    ARG_LIST = delimitedList(SIMPLE_ARG_DEFAULT)('arg_list')
    SIMPLE_ARG_DEFAULT << (
        QUOTED_STRING | BIT_EXPRESSION | (TYPE_EXPRESSION +
        Optional(
            Literal('(').suppress() +
            Optional(ARG_LIST) +
            Literal(')').suppress())) |
        EXPRESSION)

    FUNC_ARG_DEFAULT = (Literal('&') + TYPE_EXPRESSION +
        Optional(Literal('(').suppress() +
        Optional(ARG_LIST) +
        Literal(')').suppress()))

    METHOD_ARGS = Forward()

    SIMPLE_ARG = (Optional(Optional(IDENTIFIER('arg_name')) +
        Optional(Literal('=').suppress() +
            SIMPLE_ARG_DEFAULT('arg_default'))))

    FUNC_ARG = (Literal('(*)') +
        Literal("(").suppress() +
        Optional(METHOD_ARGS)('func_arg_signature') +
        Literal(")").suppress() +
        Optional(Optional(IDENTIFIER)('arg_name') +
            Optional(Literal('=').suppress() +
                FUNC_ARG_DEFAULT('arg_default'))))

    METHOD_ARG = Group((VOID('arg_type') | TYPE('arg_type')) +
        (FUNC_ARG | SIMPLE_ARG))('arg')

    METHOD_ARGS << (delimitedList(METHOD_ARG) | Literal('...'))

    METHOD_SIGNATURE = (
        Optional(STATIC) +
        ((VOID('return') + COMPLEX_TYPE('name')) |
         (TYPE('return') + COMPLEX_TYPE('name')) |
         COMPLEX_TYPE('name')) +
        Literal("(").suppress() +
        Optional(Group(METHOD_ARGS)('args')) +
        Literal(")").suppress())

    @classmethod
    def _parse(cls, grammar, string, raise_exception=False, silent=True):

        try:
            return grammar.parseString(string, parseAll=True)
        except ParseException as e:
            if not silent:
                log.warning(string)
                str_e = str(e)
                match = re.search(cls.ERROR_PATTERN, str_e)
                if match:
                    log.warning(" " * (int(match.group(1)) - 1) + '^')
            if raise_exception:
                raise
            if not silent:
                log.warning(e)
            return None

    @classmethod
    def parse_type(cls, string, raise_exception=False, silent=True):

        return cls._parse(cls.TYPE, string,
                raise_exception, silent)

    @classmethod
    def parse_method(cls, string, raise_exception=False, silent=True):

        return cls._parse(cls.METHOD_SIGNATURE,
                string, raise_exception, silent)

########NEW FILE########
__FILENAME__ = extras
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

from urllib2 import urlopen
import xml.dom.minidom as minidom
from itertools import chain, izip

from .. import log; log = log[__name__]
from . import quickroot as QROOT

__all__ = [
    'iter_ROOT_classes',
    'humanize_bytes',
    'print_table',
    'izip_exact',
    'LengthMismatch',
]


def iter_ROOT_classes():
    """
    Iterator over all available ROOT classes
    """
    class_index = "http://root.cern.ch/root/html/ClassIndex.html"
    for s in minidom.parse(urlopen(class_index)).getElementsByTagName("span"):
        if ("class", "typename") in s.attributes.items():
            class_name = s.childNodes[0].nodeValue
            try:
                yield getattr(QROOT, class_name)
            except AttributeError:
                pass


def humanize_bytes(bytes, precision=1):

    abbrevs = (
        (1<<50L, 'PB'),
        (1<<40L, 'TB'),
        (1<<30L, 'GB'),
        (1<<20L, 'MB'),
        (1<<10L, 'kB'),
        (1, 'bytes')
    )
    if bytes == 1:
        return '1 byte'
    for factor, suffix in abbrevs:
        if bytes >= factor:
            break
    return '%.*f %s' % (precision, bytes / factor, suffix)


def print_table(table, sep='  '):

    # Reorganize data by columns
    cols = zip(*table)
    # Compute column widths by taking maximum length of values per column
    col_widths = [ max(len(value) for value in col) for col in cols ]
    # Create a suitable format string
    format = sep.join(['%%-%ds' % width for width in col_widths ])
    # Print each row using the computed format
    for row in table:
        print format % tuple(row)



class LengthMismatch(Exception):
    pass


def _throw():
    raise LengthMismatch
    yield None # unreachable


def _check(rest):
    for i in rest:
        try:
            i.next()
        except LengthMismatch:
            pass
        else:
            raise LengthMismatch
    return
    yield None # unreachable


def izip_exact(*iterables):
    """
    A lazy izip() that ensures that all iterables have the same length.
    A LengthMismatch exception is raised if the iterables' lengths differ.

    Examples
    --------

        >>> list(zip_exc([]))
        []
        >>> list(zip_exc((), (), ()))
        []
        >>> list(zip_exc("abc", range(3)))
        [('a', 0), ('b', 1), ('c', 2)]
        >>> try:
        ...     list(zip_exc("", range(3)))
        ... except LengthMismatch:
        ...     print "mismatch"
        mismatch
        >>> try:
        ...     list(zip_exc(range(3), ()))
        ... except LengthMismatch:
        ...     print "mismatch"
        mismatch
        >>> try:
        ...     list(zip_exc(range(3), range(2), range(4)))
        ... except LengthMismatch:
        ...     print "mismatch"
        mismatch
        >>> items = zip_exc(range(3), range(2), range(4))
        >>> items.next()
        (0, 0, 0)
        >>> items.next()
        (1, 1, 1)
        >>> try: items.next()
        ... except LengthMismatch: print "mismatch"
        mismatch

    References
    ----------

    [1] http://code.activestate.com/recipes/497006-zip_exc-a-lazy-zip-that-ensures-that-all-iterables/

    """
    rest = [chain(i, _throw()) for i in iterables[1:]]
    first = chain(iterables[0], _check(rest))
    return izip(*[first] + rest)

########NEW FILE########
__FILENAME__ = hook
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import types
import sys

from .inject_closure import inject_closure_values
from . import log; log = log[__name__]

__all__ = [
    'super_overridden',
    'uses_super',
    'classhook',
    'appendclass',
]

# The below code is here for reference:
# How to hook anything you want..
# TODO(pwaller): Delete this if no-one needs it after a month or two.
"""
from .. import QROOT

HOOKED_CLASSES = {}

TObject_meta = type(QROOT.TObject)

orig_meta_getattribute = TObject_meta.__getattribute__
def new_meta_getattribute(cls, name):
    #print cls, name
    if cls in HOOKED_CLASSES:
        hook = HOOKED_METHODS.get((cls, name), None)
        if hook:
            hook(orig_getattribute)
    return orig_meta_getattribute(cls, name)
TObject_meta.__getattribute__ = new_meta_getattribute

orig_getattribute = QROOT.TObject.__getattribute__
def new_getattribute(cls, name):
    x = orig_getattribute(cls, name)
    return x
QROOT.TObject.__getattribute__ = new_getattribute
"""

INTERESTING = (
    types.FunctionType, types.MethodType,
    property, staticmethod, classmethod)


def super_overridden(cls):
    """
    This decorator just serves as a reminder that the super function behaves
    differently. It doesn't actually do anything, that happens inside
    ``classhook.hook_class``.
    """
    cls.__rootpy_have_super_overridden = True
    return cls


def uses_super(func):
    """
    Check if the function/property/classmethod/staticmethod uses the `super` builtin
    """
    if isinstance(func, property):
        return any(uses_super(f) for f in (func.fget, func.fset, func.fdel) if f)
    elif isinstance(func, (staticmethod, classmethod)):
        if sys.version_info >= (2, 7):
            func = func.__func__
        elif isinstance(func, staticmethod):
            func = func.__get__(True)
        else: # classmethod
            func = func.__get__(True).im_func
    return "super" in func.func_code.co_names


class classhook(object):
    """
    Interpose the `hook` classes' methods onto the target `classes`.

    Note, it is also necessary to decorate these classes with @super_overridden
    to indicate at the usage site that the super method may behave differently
    than you expect.

    The trick is that we want the hook function to call `super(ClassBeingHooked, self)`,
    but there are potentially multiple ClassesBeingHooked. Therefore, instead
    you must write `super(MyHookClass, self)` and the super method is replaced
    at hook-time through bytecode modification with another one which does the
    right thing.

    Example usage:

    @classhook(ROOT.TH1)
    @super_overridden
    class ChangeBehaviour(object):
        def Draw(self, *args):
            # Call the original draw function
            result = super(ChangeBehaviour, self).Draw(*args)
            # do something with the result here
            return result
    """
    def overridden_super(self, target, realclass):
        class rootpy_overridden_super(super):
            def __init__(self, cls, *args):
                if cls is target:
                    cls = realclass
                super(rootpy_overridden_super, self).__init__(cls, *args)
        return rootpy_overridden_super

    def __init__(self, *classes):
        self.classes = classes

    def hook_class(self, cls, hook):
        # Attach a new class type with the original methods on it so that
        # super() works as expected.
        hookname = "_rootpy_{0}_OrigMethods".format(cls.__name__)
        newcls = types.ClassType(hookname, (), {})
        cls.__bases__ = (newcls,) + cls.__bases__

        # For every function-like (or property), replace `cls`'s methods
        for key, value in hook.__dict__.iteritems():
            if not isinstance(value, INTERESTING):
                continue

            # Save the original methods onto the newcls which has been
            # injected onto our bases, so that the originals can be called with
            # super().
            orig_method = getattr(cls, key, None)
            if orig_method:
                newcls.__dict__[key] = orig_method

            newmeth = value
            if uses_super(newmeth):
                assert getattr(hook, "__rootpy_have_super_overridden", None), (
                    "Hook class {0} is not decorated with @super_overridden! "
                    "See the ``hook`` module to understand why this must be "
                    "the case for all classes overridden with @classhook"
                    .format(hook))
                # Make super behave as though the class hierarchy is what we'd
                # like.
                newsuper = self.overridden_super(hook, cls)
                newmeth = inject_closure_values(value, super=newsuper)
            setattr(cls, key, newmeth)

    def __call__(self, hook):
        """
        Hook the decorated class onto all `classes`.
        """
        for cls in self.classes:
            self.hook_class(cls, hook)
        return hook


class appendclass(object):
    """
    Append the methods/properties of `appender` onto `classes`. The methods
    being appended must not exist on any of the target classes.
    """
    def __init__(self, *classes):
        self.classes = classes

    def __call__(self, appender):
        for appendee in self.classes:
            for key, value in appender.__dict__.iteritems():
                if not isinstance(value, INTERESTING):
                    continue
                assert not hasattr(appendee, key), (
                    "Don't override existing methods with appendclass")
                assert not uses_super(value), ("Don't use the super class with "
                    "@appendclass, use @classhook instead")
                setattr(appendee, key, value)
                continue
        return appender

########NEW FILE########
__FILENAME__ = inject_closure
import types

from ..extern import byteplay


def new_closure(vals):
    """
    Build a new closure
    """
    args = ','.join('x%i' % i for i in range(len(vals)))
    f = eval("lambda %s:lambda:(%s)" % (args, args))
    return f(*vals).func_closure


def _inject_closure_values_fix_closures(c, injected, **kwargs):
    """
    Recursively fix closures

    Python bytecode for a closure looks like:

        LOAD_CLOSURE var1
        BUILD_TUPLE <n_of_vars_closed_over>
        LOAD_CONST <code_object_containing_closure>
        MAKE_CLOSURE

    This function finds closures and adds the injected closed variables in the
    right place.
    """
    code = c.code
    orig_len = len(code)
    for iback, (opcode, value) in enumerate(reversed(code)):
        i = orig_len - iback - 1

        if opcode != byteplay.MAKE_CLOSURE:
            continue

        codeobj = code[i-1]
        assert codeobj[0] == byteplay.LOAD_CONST

        build_tuple = code[i-2]
        assert build_tuple[0] == byteplay.BUILD_TUPLE
        n_closed = build_tuple[1]

        load_closures = code[i-2-n_closed:i-2]
        assert all(o == byteplay.LOAD_CLOSURE for o, _ in load_closures)

        newlcs = [(byteplay.LOAD_CLOSURE, inj) for inj in injected]

        code[i-2] = byteplay.BUILD_TUPLE, n_closed + len(injected)
        code[i-2:i-2] = newlcs

        _inject_closure_values_fix_code(codeobj[1], injected, **kwargs)


def _inject_closure_values_fix_code(c, injected, **kwargs):
    """
    Fix code objects, recursively fixing any closures
    """
    # Add more closure variables
    c.freevars += injected

    # Replace LOAD_GLOBAL with LOAD_DEREF (fetch from closure cells)
    # for named variables
    for i, (opcode, value) in enumerate(c.code):
        if opcode == byteplay.LOAD_GLOBAL and value in kwargs:
            c.code[i] = byteplay.LOAD_DEREF, value

    _inject_closure_values_fix_closures(c, injected, **kwargs)

    return c


def _inject_closure_values(func, **kwargs):
    for name in kwargs:
        assert not name in func.func_code.co_freevars, ("BUG! Tried to inject "
            "closure variable where there is already a closure variable of the "
            "same name: {0}".format(name))

    cellvalues = []
    if func.func_closure:
        cellvalues = [c.cell_contents for c in func.func_closure]

    injected = tuple(sorted(kwargs))
    # Insert the closure values into the new cells
    cellvalues.extend(kwargs[key] for key in injected)

    c = byteplay.Code.from_code(func.func_code)

    _inject_closure_values_fix_code(c, injected, **kwargs)

    code = c.to_code()
    closure = new_closure(cellvalues)

    args = code, func.func_globals, func.func_name, func.func_defaults, closure
    newfunc = types.FunctionType(*args)
    return newfunc


def inject_closure_values(func, **kwargs):
    """
    Returns a new function identical to the previous one except that it acts as
    though global variables named in `kwargs` have been closed over with the
    values specified in the `kwargs` dictionary.

    Works on properties, class/static methods and functions.

    This can be useful for mocking and other nefarious activities.
    """
    wrapped_by = None

    if isinstance(func, property):
        fget, fset, fdel = func.fget, func.fset, func.fdel
        if fget: fget = fix_func(fget, **kwargs)
        if fset: fset = fix_func(fset, **kwargs)
        if fdel: fdel = fix_func(fdel, **kwargs)
        wrapped_by = type(func)
        return wrapped_by(fget, fset, fdel)

    elif isinstance(func, (staticmethod, classmethod)):
        func = func.__func__
        wrapped_by = type(func)

    newfunc = _inject_closure_values(func, **kwargs)

    if wrapped_by:
        newfunc = wrapped_by(newfunc)
    return newfunc

########NEW FILE########
__FILENAME__ = lock
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import os
import stat
import time
import platform
from contextlib import contextmanager

from ..extern.lockfile import LockFile, LockTimeout
from . import log; log = log[__name__]

__all__ = [
    'lock',
]


@contextmanager
def lock(path, poll_interval=5, max_age=60):
    """
    Aquire a file lock in a thread-safe manner that also reaps stale locks
    possibly left behind by processes that crashed hard.
    """
    if max_age < 30:
        raise ValueError("`max_age` must be at least 30 seconds")
    if poll_interval < 1:
        raise ValueError("`poll_interval` must be at least 1 second")
    if poll_interval >= max_age:
        raise ValueError("`poll_interval` must be less than `max_age`")
    proc = '{0:d}@{1}'.format(os.getpid(), platform.node())
    lock = LockFile(path)
    log.debug("{0} attempting to lock {1}".format(proc, path))
    while not lock.i_am_locking():
        if lock.is_locked():
            # Protect against race condition
            try:
                # Check age of the lock file
                age = time.time() - os.stat(lock.lock_file)[stat.ST_MTIME]
                # Break the lock if too old (considered stale)
                if age > max_age:
                    lock.break_lock()
                    # What if lock was released and reacquired in the meantime?
                    # We don't want to break a fresh lock!
                    # If a lock is stale then we may have many threads
                    # attempting to break it here at the "same time".
                    # Avoid the possibility of some thread trying to break the
                    # lock after it has already been broken and after the first
                    # other thread attempting to acquire the lock by sleeping
                    # for 0.5 seconds below.
                    log.warning(
                        "{0} broke lock on {1} "
                        "that is {2:d} seconds old".format(
                            proc, path, int(age)))
            except OSError:
                # Lock was released just now
                # os.path.exists(lock.lock_file) is False
                # OSError may be raised by os.stat() or lock.break_lock() above
                pass
        time.sleep(0.5)
        try:
            log.debug(
                "{0} waiting for {1:d} seconds "
                "for lock on {2} to be released".format(
                    proc, poll_interval, path))
            # Use float() here since acquire sleeps for timeout/10
            lock.acquire(timeout=float(poll_interval))
        except LockTimeout:
            pass
    log.debug("{0} locked {1}".format(proc, path))
    yield lock
    lock.release()
    log.debug("{0} released lock on {1}".format(proc, path))

########NEW FILE########
__FILENAME__ = module_facade
import sys

from inspect import getfile
from types import ModuleType

from .. import log; log = log[__name__]

log.show_stack(limit=2)


class computed_once_classproperty(property):
    """
    A property whose value is computed exactly once, then saved onto the target
    class.
    """
    def __get__(self, object_, type_=None):
        result = super(computed_once_classproperty, self).__get__(object_, type_)
        propname = self.fget.__name__
        # Remove the property from the class itself
        setattr(type_, propname, result)
        return result


class ModuleFacade(object):
    def __repr__(self):
        orig = super(ModuleFacade, self).__repr__()
        return "{0}({1})".format(type(self).__name__, orig)


class Facade(object):

    def __init__(self, name, **kwargs):
        """
        Use kwargs to force user to write them out for explicitness.
        """
        self.name = name
        _, _, self.name_lastpart = name.rpartition(".")
        self.expose_internal = kwargs.pop("expose_internal", True)
        self.submodule = kwargs.pop("submodule", False)

    def __call__(self, cls):
        """
        Decorate `cls`
        """
        expose_internal = self.expose_internal

        if self.submodule:
            self.name += "." + cls.__name__

        if self.name not in sys.modules:
            orig = ModuleType(self.name)
            orig.__name__ = self.name
            orig.__file__ = getfile(cls)
        else:
            orig = sys.modules[self.name]

        if isinstance(orig, ModuleFacade):
            raise TypeError("Facade() used inside module which is already "
                              "wrapped - only once Facade() allowed per module."
                              " inside {0}".format(orig))

        class _wrapper_cls(cls, ModuleFacade, ModuleType, object):
            _facade_wrapped = orig
            _facade_cls = cls

            def __dir__(self):
                items = set()
                items.update(self.__dict__)
                items.update(self._facade_cls.__dict__)

                if hasattr(self._facade_cls, "__dir__"):
                    items.update(self._facade_cls.__dir__(self))

                if expose_internal:
                    items.update(orig.__dict__)

                return sorted(items)

            def __getattr__(self, key):
                if expose_internal and hasattr(orig, key):
                    return getattr(orig, key)
                sup = super(_wrapper_cls, self)
                if hasattr(sup, "__getattr__"):
                    result = sup.__getattr__(key)
                    if result is not None:
                        return result
                raise AttributeError("'{0}' object has no attribute '{1}'"
                    .format(self, key))

        _wrapper_cls.__name__ = "ModuleFacade({0})".format(cls.__name__)
        inst = _wrapper_cls(self.name)
        sys.modules[self.name] = inst

        for key in "__name__ __doc__ __file__ __path__".split():
            if hasattr(orig, key):
                setattr(inst, key, getattr(orig, key))

        return inst

########NEW FILE########
__FILENAME__ = path
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import glob
import os
import errno

__all__ = [
    'expand',
    'expand_and_glob',
    'expand_and_glob_all',
    'mkdir_p',
]


def expand(s):

    return os.path.expanduser(os.path.expandvars(s))


def expand_and_glob(s):

    return glob.glob(expand(s))


def expand_and_glob_all(s):

    files = []
    for name in s:
        files += expand_and_glob(name)
    return files


def mkdir_p(path):
    """
    mkdir -p functionality
    http://stackoverflow.com/questions/600268/mkdir-p-functionality-in-python

    In rootpy, this function should be used when creating directories in a
    multithreaded environment to avoid race conditions when checking if a
    directory exists before creating it.
    """
    try:
        os.makedirs(path)
    except OSError as exc:
        if exc.errno == errno.EEXIST and os.path.isdir(path):
            pass
        else:
            raise

########NEW FILE########
__FILENAME__ = quickroot
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
Quickly load ROOT symbols without causing slow finalSetup()

The main principle is that appropriate dictionaries need to be loaded.
"""
from __future__ import absolute_import

import ROOT

from .. import log; log = log[__name__]
from .module_facade import Facade

__all__ = []

# Quick's __name__ needs to be the ROOT module for this to be transparent.
# The below is one way of obtaining such a function
Quick = eval("lambda symbol: module._root.LookupRootEntity(symbol)",
             ROOT.__dict__)

_gSystem = Quick("gSystem")
Load = _gSystem.Load

# It is not vital to list _all_ symbols in here, just enough that a library
# will be loaded by the time it is needed.
SYMBOLS = dict(
    Hist="TH1 TGraph TGraphAsymmErrors",
    Tree="TCut TTree",
    Gui="TPad TCanvas",
    Graf="TLegend TLine TEllipse",
    Physics="TVector2 TVector3 TLorentzVector TRotation TLorentzRotation",
    Matrix="TMatrixT",
    RooStats="RooStats RooMsgService",
    RooFit="RooFit RooWorkspace",
)

# Mapping of symbols to libraries which need to be loaded
SYMBOLS_TO_LIB = dict(
    (sym, lib) for lib, syms in SYMBOLS.iteritems() for sym in syms.split())

# If you encounter problems with particular symbols, add them to this set.
SLOW = set("".split())

@Facade(__name__, expose_internal=False)
class QuickROOT(object):
    def __getattr__(self, symbol):
        if symbol in SLOW:
            log.warning(
                "Tried to quickly load {0} which is always slow".format(symbol))

        lib = SYMBOLS_TO_LIB.get(symbol, None)
        if lib:
            # Load() doesn't cost anything if the library is already loaded
            libname = "lib{0}".format(lib)
            if libname not in _gSystem.GetLibraries():
                regex = "^duplicate entry .* for level 0; ignored$"
                with log["/ROOT.TEnvRec.ChangeValue"].ignore(regex):
                    if Load(libname) == 0:
                        log.debug("Loaded {0} (required by {1})".format(
                            libname, symbol))
                    else:
                        raise RuntimeError(
                            "Unable to load {0} (required by {1})".format(
                                libname, symbol))

        return Quick(symbol)

########NEW FILE########
__FILENAME__ = silence
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
"""
This module provides context managers for silencing output from external
compiled libraries on stdout, stderr, or both. Probably the most common use
is to completely silence output on stdout and/or stderr with the
`silence_sout_serr` function.

.. warning::
    There is the possibility that normal output may not be restored to the
    output stream and content may be unintentionally silenced. Only use these
    functions if you absolutely need them and beware of using them in large
    frameworks where debugging may be difficult if problems do occur.

"""
from contextlib import contextmanager
import os
import sys
import threading
LOCK = threading.RLock()

__all__ = [
    'silence_sout',
    'silence_serr',
    'silence_sout_serr',
]


@contextmanager
def silence_sout():
    LOCK.acquire()
    sys.__stdout__.flush()
    origstdout = sys.__stdout__
    oldstdout_fno = os.dup(sys.__stdout__.fileno())
    devnull = os.open(os.devnull, os.O_WRONLY)
    newstdout = os.dup(1)
    os.dup2(devnull, 1)
    os.close(devnull)
    sys.__stdout__ = os.fdopen(newstdout, 'w')
    try:
        yield
    finally:
        sys.__stdout__ = origstdout
        sys.__stdout__.flush()
        os.dup2(oldstdout_fno, 1)
        LOCK.release()


@contextmanager
def silence_serr():
    LOCK.acquire()
    sys.__stderr__.flush()
    origstderr = sys.__stderr__
    oldstderr_fno = os.dup(sys.__stderr__.fileno())
    devnull = os.open(os.devnull, os.O_WRONLY)
    newstderr = os.dup(2)
    os.dup2(devnull, 2)
    os.close(devnull)
    sys.__stderr__ = os.fdopen(newstderr, 'w')
    try:
        yield
    finally:
        sys.__stderr__ = origstderr
        sys.__stderr__.flush()
        os.dup2(oldstderr_fno, 2)
        LOCK.release()


@contextmanager
def silence_sout_serr():
    with silence_sout():
        with silence_serr():
            yield

########NEW FILE########
__FILENAME__ = facade_example
from rootpy.utils.module_facade import Facade


def module_level_function(what):
    return what

module_level_constant = "MODULE_LEVEL_CONSTANT"


@Facade(__name__, expose_internal=False, submodule=True)
class internal(object):
    @property
    def hello(self):
        return "hello"


@Facade(__name__, expose_internal=True)
class ExampleModuleFacade(object):
    class_level = "class_level"

    @property
    def hello(self):
        return "hello"

    def __getattr__(self, key):
        if key == "something":
            return "something"

    def __getitem__(self, key):
        return key

    def __dir__(self):
        return ["something"]

    def attach_thing(self, param):
        return param

########NEW FILE########
__FILENAME__ = test_cpp
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import print_function
import sys
from ROOT import MethodProxy
import inspect
from rootpy.utils.cpp import CPPGrammar
from rootpy.utils.extras import iter_ROOT_classes
from nose.plugins.attrib import attr


@attr('slow')
def test_cpp():

    i = 0
    num_methods = 0

    for cls in iter_ROOT_classes():
        members = inspect.getmembers(cls)
        # filter out those starting with "_" or "operator "
        # and non-method members
        # also split overloaded methods
        methods = {}
        for name, func in members:
            if name.startswith('_') or name.startswith('operator'):
                continue
            if not isinstance(func, MethodProxy):
                continue
            methods[name] = (func, func.func_doc.split('\n'))

        for name, (func, sigs) in methods.items():
            for sig in sigs:
                num_methods += 1
                if CPPGrammar.parse_method(sig, silent=False):
                    i += 1
            print("{0} / {1}".format(i, num_methods), end='\r')
            sys.stdout.flush()
    print("{0} / {1}".format(i, num_methods))

if __name__ == "__main__":
    import nose
    nose.runmodule()

########NEW FILE########
__FILENAME__ = test_hook
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from rootpy import QROOT
from rootpy.utils.hook import classhook, appendclass, super_overridden
from rootpy.context import invisible_canvas

from .. import log; log = log[__name__]

import ROOT

import rootpy.utils.hook as H

VALUE = 1
ANOTHER = 42

def basicfunc():
    return VALUE, ANOTHER

def wrap():
    a = 1
    def outer(VALUE):
        y = a
        z = 2
        def inner(x):
            return a, x, y, z, VALUE, ANOTHER, nonexist
        return inner
    return outer

def test_inject():
    assert (VALUE, ANOTHER) == (1, 42)
    assert basicfunc() == (VALUE, ANOTHER)

    # Basic injection test
    NEWVALUE = 2
    injected = H.inject_closure_values(basicfunc, VALUE=NEWVALUE)
    assert injected() == (NEWVALUE, ANOTHER)

    # Check that
    try:
        wrap()(1)(2)
    except NameError as e:
        assert "nonexist" in e.args[0]
    else:
        assert False, "expected a NameError"

    global nonexist
    nonexist = 999
    # Test the unmodified version of the function
    correct = wrap()(1)(2)
    del nonexist

    # Test that we can really replace globals
    NEWANOTHER = 43
    newvalue = tuple(a if a != ANOTHER else NEWANOTHER for a in correct)

    hooked = H.inject_closure_values(wrap, ANOTHER=NEWANOTHER, nonexist=999)
    result = hooked()(1)(2)

    assert result == newvalue, ("Closure injection is not working properly")

@classhook(QROOT.TH1)
@super_overridden
class TH1(object):
    def SetTitle(self, *args):
        super(TH1, self).SetTitle(*args)
        return "SUCCESS"

    @classmethod
    def _rootpy_hook_test(cls):
        return "SUCCESS"

    def _rootpy_test_super_draw(self, *args, **kwargs):
        super(TH1, self).Draw(*args, **kwargs)
        return "SUCCESS"

@appendclass(QROOT.TAttLine)
class TAttLine(object):
    @property
    def _rootpy_hook_test_prop(self):
        return "SUCCESS"

    @staticmethod
    def _rootpy_hook_test_static():
        return "SUCCESS"

    @classmethod
    def _rootpy_hook_test_clsmeth(cls):
        return "SUCCESS"

    def _rootpy_hook_test_method(self):
        return "SUCCESS"

def test_hooks():
    h = ROOT.TH1D()

    newtitle = "Hello, world"
    assert h.SetTitle(newtitle) == "SUCCESS"
    assert h.GetTitle() == newtitle

    with invisible_canvas() as c:
        assert c.GetListOfPrimitives().GetSize() == 0
        assert h._rootpy_test_super_draw() == "SUCCESS"
        assert c.GetListOfPrimitives().GetSize() == 1

    assert h._rootpy_hook_test_prop == "SUCCESS"
    assert h._rootpy_hook_test_method() == "SUCCESS"
    assert h._rootpy_hook_test_static() == "SUCCESS"
    assert h._rootpy_hook_test_clsmeth() == "SUCCESS"

########NEW FILE########
__FILENAME__ = test_module_facade
import rootpy.utils.tests.facade_example as F

def test_module_facade():
    assert F.hello == "hello"
    assert F.something == "something"
    assert F.attach_thing("thing") == "thing"
    assert F.class_level == "class_level"
    assert "something" in dir(F)
    assert F["item"] == "item"
    assert F.module_level_constant == "MODULE_LEVEL_CONSTANT"
    assert "module_level_constant" in dir(F)
    assert F.module_level_function("a") == "a"
    assert "module_level_function" in dir(F)

def test_internal_facade():
    from rootpy.utils.tests.facade_example.internal import hello
    assert hello == "hello"
    assert F.internal.hello == "hello"
    assert dir(hello)


########NEW FILE########
__FILENAME__ = vector
# Copyright 2012 the rootpy developers
# distributed under the terms of the GNU General Public License
from __future__ import absolute_import

import ROOT

from copy import copy

from . import QROOT
from .base import isbasictype, Object
from .decorators import snake_case_methods

__all__ = [
    'Vector2',
    'Vector3',
    'LorentzVector',
    'Rotation',
    'LorentzRotation',
]


class _arithmetic_mixin:

    def __mul__(self, other):
        try:
            prod = self.__class__.__bases__[-1].__mul__(self, other)
            if isinstance(prod, self.__class__.__bases__[-1]):
                prod.__class__ = self.__class__
        except TypeError:
            raise TypeError(
                "unsupported operand type(s) for *: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        return prod

    def __imul__(self, other):
        if isinstance(other, self.__class__):
            raise TypeError("Attemping to set vector to scalar quantity")
        try:
            prod = self * other
        except TypeError:
            raise TypeError(
                "unsupported operand type(s) for *: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        self = prod
        return self

    def __rmul__(self, other):
        try:
            return self * other
        except TypeError:
            raise TypeError(
                "unsupported operand type(s) for *: '{0}' and '{1}'".format(
                    other.__class__.__name__, self.__class__.__name__))

    def __add__(self, other):
        if other == 0:
            return copy(self)
        try:
            clone = self.__class__.__bases__[-1].__add__(self, other)
            clone.__class__ = self.__class__
        except TypeError:
            raise TypeError(
                "unsupported operand type(s) for +: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        return clone

    def __radd__(self, other):
        if other == 0:
            return copy(self)
        raise TypeError(
            "unsupported operand type(s) for +: '{0}' and '{1}'".format(
                other.__class__.__name__, self.__class__.__name__))

    def __iadd__(self, other):
        try:
            _sum = self + other
        except TypeError:
            raise TypeError(
                "unsupported operand type(s) for +: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        self = _sum
        return self

    def __sub__(self, other):
        if other == 0:
            return copy(self)
        try:
            clone = self.__class__.__bases__[-1].__sub__(self, other)
            clone.__class__ = self.__class__
        except TypeError:
            raise TypeError(
                "unsupported operand type(s) for -: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        return clone

    def __rsub__(self, other):
        if other == 0:
            return copy(self)
        raise TypeError(
                "unsupported operand type(s) for -: '{0}' and '{1}'".format(
                    other.__class__.__name__, self.__class__.__name__))

    def __isub__(self, other):
        try:
            diff = self - other
        except TypeError:
            raise TypeError(
                "unsupported operand type(s) for -: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        self = diff
        return self

    def __copy__(self):
        _copy = self.__class__.__bases__[-1](self)
        _copy.__class__ = self.__class__
        return _copy


@snake_case_methods
class Vector2(_arithmetic_mixin, Object, QROOT.TVector2):
    """
    A subclass of `ROOT.TVector2 <http://root.cern.ch/root/html/TVector2.html>`_.

    Examples
    --------

    >>> from rootpy.vector import Vector2
    >>> vect = Vector2(2, 4)
    >>> vect
    Vector2(x=2.000000, y=4.000000)

    """
    _ROOT = QROOT.TVector2

    @property
    def x(self):
        return self.X()

    @property
    def y(self):
        return self.Y()

    def __getitem__(self, i):
        if i == 0:
            return self.X()
        elif i == 1:
            return self.Y()
        raise IndexError("index {0:d} out of bounds".format(i))

    def __repr__(self):
        return '{0}(x={1:f}, y={2:f})'.format(
            self.__class__.__name__, self.X(), self.Y())

    def __mul__(self, other):
        if isinstance(other, self.__class__):
            prod = self.X() * other.X() + \
                   self.Y() * other.Y()
        elif isbasictype(other):
            prod = Vector2(other * self.X(), other * self.Y())
        else:
            raise TypeError(
                "unsupported operand type(s) for *: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        return prod

    def __add__(self, other):
        if isinstance(other, ROOT.TVector2):
            _sum = Vector3(self.X() + other.X(),
                           self.Y() + other.Y())
        else:
            raise TypeError(
                "unsupported operand type(s) for *: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        return _sum


@snake_case_methods
class Vector3(_arithmetic_mixin, Object, QROOT.TVector3):
    """
    A subclass of `ROOT.TVector3 <http://root.cern.ch/root/html/TVector3.html>`_.

    Examples
    --------

    >>> from rootpy.vector import Vector3
    >>> vect = Vector3(1, 2, 3)
    >>> vect
    Vector3(x=1.000000, y=2.000000, z=3.000000)

    """
    _ROOT = QROOT.TVector3

    @property
    def x(self):
        return self.X()

    @property
    def y(self):
        return self.Y()

    @property
    def z(self):
        return self.Z()

    def __getitem__(self, i):
        if i == 0:
            return self.X()
        elif i == 1:
            return self.Y()
        elif i == 2:
            return self.Z()
        raise IndexError("index {0:d} out of bounds".format(i))

    def __repr__(self):
        return '{0}(x={1:f}, y={2:f}, z={3:f})'.format(
            self.__class__.__name__, self.X(), self.Y(), self.Z())

    def Angle(self, other):
        if isinstance(other, LorentzVector):
            return other.Angle(self)
        return ROOT.TVector3.Angle(self, other)

    def __mul__(self, other):
        if isinstance(other, ROOT.TVector3):
            prod = self.X() * other.X() + \
                   self.Y() * other.Y() + \
                   self.Z() * other.Z()
        elif isbasictype(other):
            prod = Vector3(other * self.X(), other * self.Y(), other * self.Z())
        else:
            raise TypeError(
                "unsupported operand type(s) for *: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        return prod

    def __add__(self, other):
        if isinstance(other, ROOT.TVector3):
            _sum = Vector3(self.X() + other.X(),
                           self.Y() + other.Y(),
                           self.Z() + other.Z())
        else:
            raise TypeError(
                "unsupported operand type(s) for +: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        return _sum

    def __sub__(self, other):
        if isinstance(other, ROOT.TVector3):
            _dif = Vector3(self.X() - other.X(),
                           self.Y() - other.Y(),
                           self.Z() - other.Z())
        else:
            raise TypeError(
                "unsupported operand type(s) for -: '{0}' and '{1}'".format(
                    self.__class__.__name__, other.__class__.__name__))
        return _dif


@snake_case_methods
class LorentzVector(_arithmetic_mixin, Object, QROOT.TLorentzVector):
    """
    A subclass of `ROOT.TLorentzVector <http://root.cern.ch/root/html/TLorentzVector.html>`_.

    Examples
    --------

    >>> from rootpy.vector import LorentzVector
    >>> vect = LorentzVector(1, 2, 3, 4)
    >>> vect
    LorentzVector(px=1.000000, py=2.000000, pz=3.000000, E=4.000000)

    """
    _ROOT = QROOT.TLorentzVector

    @property
    def px(self):
        return self.Px()

    @property
    def py(self):
        return self.Py()

    @property
    def pz(self):
        return self.Pz()

    @property
    def e(self):
        return self.E()

    def __getitem__(self, i):
        if i == 0:
            return self.Px()
        elif i == 1:
            return self.Py()
        elif i == 2:
            return self.Pz()
        elif i == 3:
            return self.E()
        raise IndexError("index {0:d} out of bounds".format(i))

    def __repr__(self):
        return "{0}(px={1:f}, py={2:f}, pz={3:f}, E={4:f})".format(
            self.__class__.__name__,
            self.Px(), self.Py(), self.Pz(), self.E())

    def Angle(self, other):
        if isinstance(other, ROOT.TLorentzVector):
            return ROOT.TLorentzVector.Angle(self, other.Vect())
        return ROOT.TLorentzVector.Angle(self, other)

    def BoostVector(self):
        vector = ROOT.TLorentzVector.BoostVector(self)
        vector.__class__ = Vector3
        return vector


@snake_case_methods
class Rotation(_arithmetic_mixin, Object, QROOT.TRotation):
    """
    A subclass of `ROOT.TRotation <http://root.cern.ch/root/html/TRotation.html>`_.
    """
    _ROOT = QROOT.TRotation

    def __repr__(self):
        return ("[[{0:f}, {1:f}, {2:f}],\n"
                " [{3:f}, {4:f}, {5:f}],\n"
                " [{6:f}, {7:f}, {8:f}]]").format(
                    self.XX(), self.XY(), self.XZ(),
                    self.YX(), self.YY(), self.YZ(),
                    self.ZX(), self.ZY(), self.ZZ())


@snake_case_methods
class LorentzRotation(_arithmetic_mixin, Object, QROOT.TLorentzRotation):
    """
    A subclass of `ROOT.TLorentzRotation <http://root.cern.ch/root/html/TLorentzRotation.html>`_.
    """
    _ROOT = QROOT.TLorentzRotation

    def __repr__(self):
        return ("[[{0:f},  {1:f},  {2:f},  {3:f}],\n"
                " [{4:f},  {5:f},  {6:f},  {7:f}],\n"
                " [{8:f},  {9:f},  {10:f},  {11:f}],\n"
                " [{12:f},  {13:f},  {14:f},  {15:f}]]").format(
                    self.XX(), self.XY(), self.XZ(), self.XT(),
                    self.YX(), self.YY(), self.YZ(), self.YT(),
                    self.ZX(), self.ZY(), self.ZZ(), self.ZT(),
                    self.TX(), self.TY(), self.TZ(), self.TT())

########NEW FILE########
