__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Radon documentation build configuration file, created by
# sphinx-quickstart on Thu Oct 11 16:08:21 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import os
import sys
import datetime
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),
                                                '..')))
import radon

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.coverage', 'sphinx.ext.mathjax', 'sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Radon'
copyright = u'{0}, Michele Lacchia'.format('-'.join(map(str,
                                                        range(2012,
                                                              datetime.datetime.now().year + 1))))

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = radon.__version__
# The full version, including alpha/beta/rc tags.
release = version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'solar'
RTD_NEW_THEME = True

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
html_theme_path = ['_themes']

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Radondoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Radon.tex', u'Radon Documentation',
   u'Michele Lacchia', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'radon', u'Radon Documentation',
     [u'Michele Lacchia'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Radon', u'Radon Documentation',
   u'Michele Lacchia', 'Radon', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'
mathjax_path = 'MathJax.js'

########NEW FILE########
__FILENAME__ = cli
from mando import Program
try:
    import colorama
    colorama.init()
    GREEN, YELLOW, RED = (colorama.Fore.GREEN, colorama.Fore.YELLOW,
                          colorama.Fore.RED)
    MAGENTA, CYAN, WHITE = (colorama.Fore.MAGENTA, colorama.Fore.CYAN,
                            colorama.Fore.WHITE)
    BRIGHT, RESET = colorama.Style.BRIGHT, colorama.Style.RESET_ALL
except ImportError:
    # No colorama, so let's fallback to no-color mode
    GREEN = YELLOW = RED = MAGENTA = CYAN = WHITE = BRIGHT = RESET = ''

import os
import sys
import json as json_mod
import collections
import radon.complexity as cc_mod
from radon.tools import iter_filenames, cc_to_dict, raw_to_dict
from radon.complexity import cc_visit, cc_rank, sorted_results
from radon.raw import analyze
from radon.metrics import mi_visit, mi_rank

if not sys.stdout.isatty():
    GREEN = YELLOW = RED = MAGENTA = CYAN = WHITE = BRIGHT = RESET = ''

__version__ = '0.5.1'


RANKS_COLORS = {'A': GREEN, 'B': GREEN,
                'C': YELLOW, 'D': YELLOW,
                'E': RED, 'F': RED}

LETTERS_COLORS = {'F': MAGENTA,
                  'C': CYAN,
                  'M': WHITE}

MI_RANKS = {'A': GREEN, 'B': YELLOW, 'C': RED}
TEMPLATE = '{0}{1} {reset}{2}:{3} {4} - {5}{6}{reset}'
program = Program(version=__version__)


def log(msg, *args, **kwargs):
    '''Log a message, passing `*args` to `.format()`.

    `indent`, if present as a keyword argument, specifies the indent level, so
    that `indent=0` will log normally, `indent=1` will indent the message by 4
    spaces, &c..
    `noformat`, if present and True, will cause the message not to be formatted
    in any way.'''
    indent = 4 * kwargs.get('indent', 0)
    m = msg if kwargs.get('noformat', False) else msg.format(*args)
    sys.stdout.write(' ' * indent + m + '\n')


def log_list(lst, **kwargs):
    '''Log an entire list, line by line.'''
    for line in lst:
        log(line, **kwargs)


def log_error(msg, *args, **kwargs):
    '''Log an error message. Arguments are the same as log().'''
    log('{0}{1}ERROR{2}: {3}'.format(BRIGHT, RED, RESET, msg), *args, **kwargs)


def _format_line(line, ranked, show_complexity=False):
    '''Format a single line. *ranked* is the rank given by the
    `~radon.complexity.rank` function. If *show_complexity* is True, then
    the complexity score is added.
    '''
    letter_colored = LETTERS_COLORS[line.letter] + line.letter
    rank_colored = RANKS_COLORS[ranked] + ranked
    compl = '' if not show_complexity else ' ({0}) '.format(line.complexity)
    return TEMPLATE.format(BRIGHT, letter_colored, line.lineno,
                           line.col_offset, line.fullname, rank_colored,
                           compl, reset=RESET)


def _print_cc_results(path, results, show_complexity, min, max, total_average):
    '''Print Cyclomatic Complexity results.

    :param path: the path of the module that has been analyzed
    :param show_complexity: if True, show the complexity score in addition to
        the complexity rank
    '''
    res = []
    counted = 0
    average_cc = .0
    for line in results:
        ranked = cc_rank(line.complexity)
        if min <= ranked <= max:
            average_cc += line.complexity
            counted += 1
            res.append(_format_line(line, ranked, show_complexity))
        elif total_average:
            average_cc += line.complexity
            counted += 1
    if res:
        log(path)
        log_list(res, indent=1)
    return average_cc, counted


def analyze_cc(paths, exclude, ignore, order_function, no_assert):
    '''Analyze the files located under `paths`.

    :param paths: A list of paths to analyze.
    :param exclude: A comma-separated string of fnmatch patterns.
    :param ignore: A comma-separated string of patterns to ignore.
    :param min: The minimum rank to output.
    :param max: The maximum rank to output.
    :param order_function: Can be `SCORE`, `LINES` or `ALPHA`, to sort the
        results respectively by CC score, line number or name.
    :param no_assert: If `True` assert statements will not be counted.'''
    for name in iter_filenames(paths, exclude, ignore):
        with open(name) as fobj:
            try:
                results = sorted_results(cc_visit(fobj.read(),
                                                  no_assert=no_assert),
                                         order_function)
                yield name, results
            except Exception as e:
                log(name)
                log_error(e, indent=1)
                continue


def analyze_raw(paths, exclude, ignore):
    '''Analyze the files located under `paths`.

    :param paths: A list of paths to analyze.
    :param exclude: A comma-separated string of fnmatch patterns.
    :param ignore: A comma-separated string of patterns to ignore.'''
    for name in iter_filenames(paths, exclude, ignore):
        with open(name) as fobj:
            try:
                yield name, analyze(fobj.read())
            except Exception as e:
                log(name)
                log_error(e, indent=1)
                continue


@program.command
def mi(multi=True, exclude=None, ignore=None, show=False, *paths):
    '''Analyze the given Python modules and compute the Maintainability Index.

    The maintainability index (MI) is a compound metric, with the primary aim
    being to determine how easy it will be to maintain a particular body of
    code.

    :param -e, --exclude <str>:  Comma separated list of patterns to exclude.
    :param -i, --ignore <str>: Comma separated list of patterns to ignore.
        Radon won't even descend into those directories.
    :param -m, --multi:  If given, multiline strings are counted as comments.
    :param -s, --show:  If given, the actual MI value is shown in results.
    :param paths: The modules or packages to analyze.
    '''
    for name in iter_filenames(paths, exclude, ignore):
        with open(name) as fobj:
            try:
                result = mi_visit(fobj.read(), multi)
            except Exception as e:
                log(name, indent=1)
                log_error(e, indent=1)
                continue
            except KeyboardInterrupt:
                log(name)
                return
            rank = mi_rank(result)
            color = MI_RANKS[rank]
            to_show = '' if not show else ' ({0:.2f})'.format(result)
            log('{0} - {1}{2}{3}{4}', name, color, rank, to_show, RESET)


@program.command
def cc(path, min='A', max='F', show_complexity=False, average=False,
       exclude=None, ignore=None, order='SCORE', json=False, no_assert=False,
       total_average=False, *more_paths):
    '''Analyze the given Python modules and compute Cyclomatic
    Complexity (CC).

    The output can be filtered using the *min* and *max* flags. In addition
    to that, by default complexity score is not displayed.

    :param path: The path where to find modules or packages to analyze.
    :param -n, --min <str>: The minimum complexity to display (default to A).
    :param -x, --max <str>: The maximum complexity to display (default to F).
    :param -e, --exclude <str>: Comma separated list of patterns to exclude.
        By default hidden directories (those starting with '.') are excluded.
    :param -i, --ignore <str>: Comma separated list of patterns to ignore.
        If they are directory names, radon won't even descend into them.
    :param -s, --show-complexity: Whether or not to show the actual complexity
        score together with the A-F rank. Default to False.
    :param -a, --average: If True, at the end of the analysis display the
        average complexity. Default to False.
    :param --total-average: Like `-a, --average`, but it is not influenced by
        `min` and `max`. Every analyzed block is counted, no matter whether it
        is displayed or not.
    :param -o, --order <str>: The ordering function. Can be SCORE, LINES or
        ALPHA.
    :param -j, --json: Format results in JSON.
    :param --no-assert: Do not count `assert` statements when computing
        complexity.
    :param more_paths: Additional paths to analyze.
    '''
    paths = [path] + list(more_paths)
    min = min.upper()
    max = max.upper()
    average_cc = .0
    analyzed = 0
    order_function = getattr(cc_mod, order.upper(), getattr(cc_mod, 'SCORE'))
    cc_data = analyze_cc(paths, exclude, ignore, order_function,
                         no_assert)
    if json:
        result = {}
        for key, data in cc_data:
            result[key] = list(map(cc_to_dict, data))
        log(json_mod.dumps(result), noformat=True)
    else:
        for name, results in cc_data:
            cc, blocks = _print_cc_results(name, results, show_complexity, min,
                                           max, total_average)
            average_cc += cc
            analyzed += blocks

    if (average or total_average) and analyzed:
        cc = average_cc / analyzed
        ranked_cc = cc_rank(cc)
        log('\n{0} blocks (classes, functions, methods) analyzed.', analyzed)
        log('Average complexity: {0}{1} ({2}){3}', RANKS_COLORS[ranked_cc],
            ranked_cc, cc, RESET)


@program.command
def raw(exclude=None, ignore=None, summary=False, json=False, *paths):
    '''Analyze the given Python modules and compute raw metrics.

    Raw metrics include:

        * LOC: The number of lines of code (total)
        * LLOC: The number of logical lines of code
        * SLOC: The number of source lines of code (not necessarily
            corresponding to the LLOC)
        * comments: The number of Python comment lines
        * multi: The number of lines which represent multi-line strings
        * blank: The number of blank lines (or whitespace-only ones)

    The equation:

        sloc + blanks = loc

    should always hold.

    :param -e, --exclude <str>: Comma separated list of patterns to exclude.
        By default hidden directories (those starting with '.') are excluded.
    :param -i, --ignore <str>: Comma separated list of patterns to ignore.
        Radon won't even descend into those directories.
    :param -s, --summary:  If given, at the end of the analysis display the
        summary of the gathered metrics. Default to False.
    :param -j, --json: Format results in JSON.
    :param paths: The modules or packages to analyze.
    '''
    headers = ['LOC', 'LLOC', 'SLOC', 'Comments', 'Multi', 'Blank']
    sum_metrics = collections.defaultdict(int, zip(headers, [0] * 6))

    raw_data = analyze_raw(paths, exclude, ignore)

    if json:
        result = {}
        for key, data in raw_data:
            result[key] = raw_to_dict(data)
        log(json_mod.dumps(result), noformat=True)
    else:
        for path, mod in raw_data:
            log(path)
            for header, value in zip(headers, mod):
                log('{0}: {1}', header, value, indent=1)
                sum_metrics[header] = sum_metrics[header] + value
            if not mod.loc:
                continue
            log('- Comment Stats', indent=1)
            comments = mod.comments
            log('(C % L): {0:.0%}', comments / (float(mod.loc) or 1), indent=2)
            log('(C % S): {0:.0%}', comments / (float(mod.sloc) or 1),
                indent=2)
            log('(C + M % L): {0:.0%}', (comments + mod.multi) / float(mod.loc),
                indent=2)

        if summary:
            log('** Total **')
            for header in sum_metrics:
                log('{0}: {1}', header, sum_metrics[header], indent=1)

########NEW FILE########
__FILENAME__ = complexity
import ast
import math
from radon.visitors import GET_COMPLEXITY, ComplexityVisitor


# sorted_block ordering functions
SCORE = lambda block: -GET_COMPLEXITY(block)
LINES = lambda block: block.lineno
ALPHA = lambda block: block.name


def cc_rank(cc):
    '''Rank the complexity score from A to F, where A stands for the simplest
    and best score and F the most complex and worst one:

    ============= =====================================================
        1 - 5        A (low risk - simple block)
        6 - 10       B (low risk - well structured and stable block)
        11 - 20      C (moderate risk - slightly complex block)
        21 - 30      D (more than moderate risk - more complex block)
        31 - 40      E (high risk - complex block, alarming)
        41+          F (very high risk - error-prone, unstable block)
    ============= =====================================================

    Here *block* is used in place of function, method or class.

    The formula used to convert the score into an index is the following:

    .. math::

        \\text{rank} = \left \lceil \dfrac{\\text{score}}{10} \\right \\rceil
        - H(5 - \\text{score})

    where ``H(s)`` stands for the Heaviside Step Function.
    The rank is then associated to a letter (0 = A, 5 = F).
    '''
    if cc < 0:
        raise ValueError('Complexity must be a non-negative value')
    return chr(min(int(math.ceil(cc / 10.) or 1) - (1, 0)[5 - cc < 0], 5) + 65)


def average_complexity(blocks):
    '''Compute the average Cyclomatic complexity from the given blocks.
    Blocks must be either :class:`~radon.visitors.Function` or
    :class:`~radon.visitors.Class`. If the block list is empty, then 0 is
    returned.
    '''
    size = len(blocks)
    if size == 0:
        return 0
    return sum((GET_COMPLEXITY(block) for block in blocks), .0) / len(blocks)


def sorted_results(blocks, order=SCORE):
    '''Given a ComplexityVisitor instance, returns a list of sorted blocks
    with respect to complexity. A block is a either
    :class:`~radon.visitors.Function` object or a
    :class:`~radon.visitors.Class` object.
    The blocks are sorted in descending order from the block with the highest
    complexity.

    The optional `order` parameter indicates how to sort the blocks. It can be:

        * `LINES`: sort by line numbering;
        * `ALPHA`: sort by name (from A to Z);
        * `SCORE`: sorty by score (descending).

    Default is `SCORE`.
    '''
    return sorted(blocks, key=order)


def cc_visit(code, **kwargs):
    '''Visit the given code with :class:`~radon.visitors.ComplexityVisitor` and
    then pass the result to the :func:`~radon.complexity.sorted_results`
    function.
    '''
    return cc_visit_ast(ast.parse(code), **kwargs)


def cc_visit_ast(ast_node, **kwargs):
    '''Visit the AST node with :class:`~radon.visitors.ComplexityVisitor` and
    pass the resulting blocks to :func:`~radon.complexity.sorted_results`.
    '''
    return sorted_results(ComplexityVisitor.from_ast(ast_node, **kwargs)
                          .blocks)

########NEW FILE########
__FILENAME__ = metrics
import ast
import math
import collections
from radon.visitors import HalsteadVisitor, ComplexityVisitor
from radon.raw import analyze


# Halstead metrics
Halstead = collections.namedtuple('Halstead', 'h1 h2 N1 N2 vocabulary length '
                                              'calculated_length volume '
                                              'difficulty effort time bugs')


def h_visit(code):
    '''Compile the code into an AST tree and then pass it to
    :func:`~radon.metrics.h_visit_ast`.
    '''
    return h_visit_ast(ast.parse(code))


def h_visit_ast(ast_node):
    '''Visit the AST node using the :class:`~radon.visitors.HalsteadVisitor`
    visitor. A namedtuple with the following fields is returned:

        * h1: the number of distinct operators
        * h2: the number of distinct operands
        * N1: the total number of operators
        * N2: the total number of operands
        * h: the vocabulary, i.e. h1 + h2
        * N: the length, i.e. N1 + N2
        * calculated_length: h1 * log2(h1) + h2 * log2(h2)
        * volume: V = N * log2(h)
        * difficulty: D = h1 / 2 * N2 / h2
        * effort: E = D * V
        * time: T = E / 18 seconds
        * bugs: B = V / 3000 - an estimate of the errors in the implementation
    '''
    visitor = HalsteadVisitor.from_ast(ast_node)
    h1, h2 = visitor.distinct_operators, visitor.distinct_operands
    N1, N2 = visitor.operators, visitor.operands
    h = h1 + h2
    N = N1 + N2
    if all((h1, h2)):
        length = h1 * math.log(h1, 2) + h2 * math.log(h2, 2)
    else:
        length = 0
    volume = N * math.log(h, 2) if h != 0 else 0
    difficulty = (h1 * N2) / float(2 * h2) if h2 != 0 else 0
    effort = difficulty * volume
    return Halstead(
        h1, h2, N1, N2, h, N, length, volume, difficulty, effort,
        effort / 18., volume / 3000.
    )


def mi_compute(halstead_volume, complexity, sloc, comments):
    '''Compute the Maintainability Index (MI) given the Halstead Volume, the
    Cyclomatic Complexity, the SLOC number and the number of comment lines.
    Usually it is not used directly but instead
    :func:`~radon.metrics.mi_visit` is preferred.
    '''
    if any(metric <= 0 for metric in (halstead_volume, sloc)):
        return 100.
    sloc_scale = math.log(sloc)
    volume_scale = math.log(halstead_volume)
    comments_scale = math.sqrt(2.46 * math.radians(comments))
    # Non-normalized MI
    nn_mi = (171 - 5.2 * volume_scale - .23 * complexity - 16.2 * sloc_scale +
             50 * math.sin(comments_scale))
    return min(max(0., nn_mi * 100 / 171.), 100.)


def mi_parameters(code, count_multi=True):
    '''Given a source code snippet, compute the necessary parameters to
    compute the Maintainability Index metric. These include:

        * the Halstead Volume
        * the Cyclomatic Complexity
        * the number of LLOC (Logical Lines of Code)
        * the percent of lines of comment

    :param multi: If True, then count multiline strings as comment lines as
        well. This is not always safe because Python multiline strings are not
        always docstrings.
    '''
    ast_node = ast.parse(code)
    raw = analyze(code)
    comments_lines = raw.comments + (raw.multi if count_multi else 0)
    comments = comments_lines / float(raw.sloc) * 100 if raw.sloc != 0 else 0
    return (h_visit_ast(ast_node).volume,
            ComplexityVisitor.from_ast(ast_node).total_complexity, raw.lloc,
            comments)


def mi_visit(code, multi):
    '''Visit the code and compute the Maintainability Index (MI) from it.
    '''
    return mi_compute(*mi_parameters(code, multi))


def mi_rank(score):
    '''Rank the score with a letter:

        * A if :math:`\\text{score} > 19`;
        * B if :math:`9 < \\text{score} \le 19`;
        * C if :math:`\\text{score} \le 9`.
    '''
    return chr(65 + (9 - score >= 0) + (19 - score >= 0))

########NEW FILE########
__FILENAME__ = filters
"""
pathfinder - making it easy to find paths
"""
import fnmatch
import os
import re

class Filter(object):

    def __and__(self, other):
        return AndFilter(self, other)

    def __or__(self, other):
        return OrFilter(self, other)

    def find(self, filepath):
        from radon.pathfinder import walk_and_filter
        return walk_and_filter(filepath, self)

class AlwaysAcceptFilter(Filter):
    """ Accept every path. """

    def accepts(self, _):
        """ Always returns True. """
        return True

class DirectoryFilter(Filter):
    """ Accept directory paths. """

    def accepts(self, filepath):
        """ Returns True if filepath represents a directory. """
        return os.path.isdir(filepath)

class FileFilter(Filter):
    """ Accept file paths. """

    def accepts(self, filepath):
        """ Returns True if filepath represents a file. """
        return os.path.isfile(filepath)

class RegexFilter(Filter):
    """ Accept paths if they match the specified regular expression. """

    def __init__(self, regex):
        """ Initialize the filter with the specified regular expression. """
        super(RegexFilter, self).__init__()
        self.regex = re.compile(regex)

    def accepts(self, filepath):
        """ Returns True if the regular expression matches the filepath. """
        return self.regex.match(filepath) is not None

class FnmatchFilter(Filter):
    """ Accept paths if they match the specifed fnmatch pattern. """

    def __init__(self, pattern):
        """ Initialize the filter with the specified fnmatch pattern. """
        super(FnmatchFilter, self).__init__()
        self.pattern = pattern

    def accepts(self, filepath):
        """ Returns True if the fnmatch pattern matches the filepath. """
        return fnmatch.fnmatch(filepath, self.pattern)

class AndFilter(Filter, list):
    """ Accept paths if all of it's filters accept the path. """

    def __init__(self, *args):
        """ Initialize the filter with the list of filters. """
        list.__init__(self, args)

    def accepts(self, filepath):
        """ Returns True if all of the filters in this filter return True. """
        return all(sub_filter.accepts(filepath) for sub_filter in self)

class OrFilter(Filter, list):
    """ Accept paths if any of it's filters accept the path. """

    def __init__(self, *args):
        """ Initialize the filter with the list of filters. """
        list.__init__(self, args)

    def accepts(self, filepath):
        """ Returns True if any of the filters in this filter return True. """
        return any(sub_filter.accepts(filepath) for sub_filter in self)

class NotFilter(Filter):
    """ Negate the accept of the specified filter. """

    def __init__(self, pathfilter):
        """ Initialize the filter with the filter it is to negate. """
        super(NotFilter, self).__init__()
        self.pathfilter = pathfilter

    def accepts(self, filepath):
        """ Returns True of the sub-filter returns False. """
        return not self.pathfilter.accepts(filepath)

class DotDirectoryFilter(AndFilter):
    """ Do not accept a path for a directory that begins with a period. """

    def __init__(self):
        """
        Initialise the filter to ignore directories beginning with
        a period.
        """
        super(DotDirectoryFilter, self).__init__(
                DirectoryFilter(),
                RegexFilter(r'.*%s*\..*$' % (os.sep)))

class SizeFilter(FileFilter):

    def __init__(self, max_bytes=None, min_bytes=None):
        self.file_filter = FileFilter()
        self.max_bytes = max_bytes
        self.min_bytes = min_bytes

    def accepts(self, filepath):
        if super(SizeFilter, self).accepts(filepath):
            stat = os.stat(filepath)
            if self.max_bytes is not None:
                if stat.st_size > self.max_bytes:
                    return False
            if self.min_bytes is not None:
                if stat.st_size < self.min_bytes:
                    return False
            return True
        return False

########NEW FILE########
__FILENAME__ = raw
import tokenize
import operator
import collections
try:
    import StringIO as io
except ImportError:  # pragma: no cover
    import io


__all__ = ['OP', 'COMMENT', 'TOKEN_NUMBER', 'NL', 'EM', 'Module', '_generate',
           '_less_tokens', '_find', '_logical', 'analyze']

COMMENT = tokenize.COMMENT
OP = tokenize.OP
NL = tokenize.NL
EM = tokenize.ENDMARKER

# Helper for map()
TOKEN_NUMBER = operator.itemgetter(0)

# A module object. It contains the following data:
#   loc = Lines of Code (total lines)
#   lloc = Logical Lines of Code
#   comments = Comments lines
#   blank = Blank lines (or whitespace-only lines)
Module = collections.namedtuple('Module', ['loc', 'lloc', 'sloc',
                                           'comments', 'multi', 'blank'])


def _generate(code):
    '''Pass the code into `tokenize.generate_tokens` and convert the result
    into a list.
    '''
    return list(tokenize.generate_tokens(io.StringIO(code).readline))


def _less_tokens(tokens, remove):
    '''Process the output of `tokenize.generate_tokens` removing
    the tokens specified in `remove`.
    '''
    for values in tokens:
        if values[0] in remove:
            continue
        yield values


def _find(tokens, token, value):
    '''Return the position of the last token with the same (token, value)
    pair supplied. The position is the one of the rightmost term.
    '''
    for index, token_values in enumerate(reversed(tokens)):
        if (token, value) == token_values[:2]:
            return len(tokens) - index - 1
    raise ValueError('(token, value) pair not found')


def _split_tokens(tokens, token, value):
    '''Split a list of tokens on the specified token pair (token, value),
    where *token* is the token type (i.e. its code) and *value* its actual
    value in the code.
    '''
    res = [[]]
    for token_values in tokens:
        if (token, value) == token_values[:2]:
            res.append([])
            continue
        res[-1].append(token_values)
    return res


def _get_all_tokens(line, lines):
    '''Starting from *line*, generate the necessary tokens which represent the
    shortest tokenization possible. This is done by catching
    :exc:`tokenize.TokenError` when a multi-line string or statement is
    encountered.
    '''
    sloc_increment = multi_increment = 0
    try:
        tokens = _generate(line)
    except tokenize.TokenError:
        # A multi-line string or statement has been encountered:
        # start adding lines and stop when tokenize stops complaining
        while True:
            sloc_increment += 1
            line = '\n'.join([line, next(lines)])
            try:
                tokens = _generate(line)
            except tokenize.TokenError:
                continue
            if tokens[0][0] == 3 and len(tokens) == 2:
                # Multi-line string detected
                multi_increment += line.count('\n') + 1
            break
    return tokens, sloc_increment, multi_increment


def _logical(tokens):
    '''Find how many logical lines are there in the current line.

    Normally 1 line of code is equivalent to 1 logical line of code,
    but there are cases when this is not true. For example::

        if cond: return 0

    this line actually corresponds to 2 logical lines, since it can be
    translated into::

        if cond:
            return 0

    Examples::

        if cond:  -> 1

        if cond: return 0  -> 2

        try: 1/0  -> 2

        try:  -> 1

        if cond:  # Only a comment  -> 1

        if cond: return 0  # Only a comment  -> 2
    '''
    def aux(sub_tokens):
        '''The actual function which does the job.'''
        # Get the tokens and, in the meantime, remove comments
        processed = list(_less_tokens(sub_tokens, [COMMENT]))
        try:
            # Verify whether a colon is present among the tokens and that
            # it is the last token.
            token_pos = _find(processed, OP, ':')
            return 2 - (token_pos == len(processed) - 2)
        except ValueError:
            # The colon is not present
            # If the line is only composed by comments, newlines and endmarker
            # then it does not count as a logical line.
            # Otherwise it count as 1.
            if not list(_less_tokens(processed, [NL, EM])):
                return 0
            return 1
    return sum(aux(sub) for sub in _split_tokens(tokens, OP, ';'))


def analyze(source):
    '''Analyze the source code and return a namedtuple with the following
    fields:

        * **loc**: The number of lines of code (total)
        * **lloc**: The number of logical lines of code
        * **sloc**: The number of source lines of code (not necessarily
            corresponding to the LLOC)
        * **comments**: The number of Python comment lines
        * **multi**: The number of lines which represent multi-line strings
        * **blank**: The number of blank lines (or whitespace-only ones)

    The equation :math:`sloc + blanks = loc` should always hold.
    Multiline strings are not counted as comments, since, to the Python
    interpreter, they are not comments but strings.
    '''
    loc = sloc = lloc = comments = multi = blank = 0
    lines = iter(source.splitlines())
    for lineno, line in enumerate(lines, 1):
        loc += 1
        line = line.strip()
        if not line:
            blank += 1
            continue
        # If this is not a blank line, then it counts as a
        # source line of code
        sloc += 1
        try:
            # Process a logical line that spans on multiple lines
            tokens, sloc_incr, multi_incr = _get_all_tokens(line, lines)
        except StopIteration:
            raise SyntaxError('SyntaxError at line: {0}'.format(lineno))
        # Update tracked metrics
        loc += sloc_incr  # LOC and SLOC increments are the same
        sloc += sloc_incr
        multi += multi_incr
        # Add the comments
        comments += list(map(TOKEN_NUMBER, tokens)).count(COMMENT)
        # Process a logical line
        # Split it on semicolons because they increase the number of logical
        # lines
        for sub_tokens in _split_tokens(tokens, OP, ';'):
            lloc += _logical(sub_tokens)
    return Module(loc, lloc, sloc, comments, multi, blank)

########NEW FILE########
__FILENAME__ = tools
import os
import operator
import itertools
from functools import reduce
from radon.pathfinder import (find_paths, FnmatchFilter, NotFilter, FileFilter,
                              DirectoryFilter, AlwaysAcceptFilter)
from radon.visitors import Function
from radon.complexity import cc_rank


def iter_filenames(paths, exclude=None, ignore=None):
    '''A generator that yields all sub-paths of the ones specified in `paths`.
    Optional exclude filters can be passed as a comma-separated string of
    fnmatch patterns.'''
    finder = lambda path: build_finder(path, build_filter(exclude),
                                       build_ignore(ignore))
    return itertools.chain(*map(finder, paths))


def build_finder(path, filter, ignore):
    '''Construct a path finder for the specified `path` and with the specified
    `filter`. Hidden directories are ignored by default.'''
    if os.path.isfile(path):
        return (path,)
    return find_paths(path, filter=filter, ignore=ignore)


def build_filter(exclude):
    '''Construct a filter from a comma-separated string of fnmatch patterns.'''
    return build_custom(exclude, FileFilter() & FnmatchFilter('*.py'),
                        NotFilter)


def build_ignore(ignore):
    '''Construct an ignore filter from a comma-separated string of fnmatch
    patterns.'''
    return build_custom(ignore, None, add=[FnmatchFilter('*/.*')])


def build_custom(pattern, start=None, final=lambda x: x, op=operator.or_,
                 add=[]):
    patt = [FnmatchFilter(p) for p in (pattern or '').split(',') if p] + add
    start = start or AlwaysAcceptFilter()
    if patt:
        start &= final(
            reduce(op, patt[1:], patt[0])
        )
    return start


def cc_to_dict(obj):
    '''Convert a list of results into a dictionary. This is meant for JSON
    dumping.'''
    def get_type(obj):
        if isinstance(obj, Function):
            return 'method' if obj.is_method else 'function'
        return 'class'

    result = {
        'type': get_type(obj),
        'rank': cc_rank(obj.complexity),
    }
    attrs = set(Function._fields) - set(('is_method', 'clojures'))
    for a in attrs:
        v = getattr(obj, a, None)
        if v is not None:
            result[a] = v
    for key in ('methods', 'clojures'):
        if hasattr(obj, key):
            result[key] = list(map(cc_to_dict, getattr(obj, key)))
    return result


def raw_to_dict(obj):
    '''Convert a list of results into a dictionary. This is meant for JSON
    dumping.'''
    result = {}
    for a in obj._fields:
        v = getattr(obj, a, None)
        if v is not None:
            result[a] = v
    return result

########NEW FILE########
__FILENAME__ = visitors
import ast
import operator
import collections


# Helper functions to use in combination with map()
GET_COMPLEXITY = operator.attrgetter('complexity')
GET_REAL_COMPLEXITY = operator.attrgetter('real_complexity')
NAMES_GETTER = operator.attrgetter('name', 'asname')
GET_ENDLINE = operator.attrgetter('endline')

BaseFunc = collections.namedtuple('Function', ['name', 'lineno', 'col_offset',
                                               'endline', 'is_method',
                                               'classname', 'clojures',
                                               'complexity'])
BaseClass = collections.namedtuple('Class', ['name', 'lineno', 'col_offset',
                                             'endline', 'methods',
                                             'real_complexity'])


class Function(BaseFunc):
    '''Base object represeting a function.
    '''

    @property
    def letter(self):
        '''The letter representing the function. It is `M` if the function is
        actually a method, `F` otherwise.
        '''
        return 'M' if self.is_method else 'F'

    @property
    def fullname(self):
        '''The full name of the function. If it is a method, then the full name
        is:
                {class name}.{method name}
        Otherwise it is just the function name.
        '''
        if self.classname is None:
            return self.name
        return '{0}.{1}'.format(self.classname, self.name)

    def __str__(self):
        return '{0} {1}:{2}->{3} {4} - {5}'.format(self.letter, self.lineno,
                                                   self.col_offset,
                                                   self.endline,
                                                   self.fullname,
                                                   self.complexity)


class Class(BaseClass):

    letter = 'C'

    @property
    def fullname(self):
        '''The full name of the class. It is just its name. This attribute
        exists for consistency (see :data:`Function.fullname`).
        '''
        return self.name

    @property
    def complexity(self):
        '''The average complexity of the class. It corresponds to the average
        complexity of its methods plus one.
        '''
        if not self.methods:
            return self.real_complexity
        return int(self.real_complexity / float(len(self.methods))) + 1

    def __str__(self):
        return '{0} {1}:{2}->{3} {4} - {5}'.format(self.letter, self.lineno,
                                                   self.col_offset,
                                                   self.endline, self.name,
                                                   self.complexity)


class CodeVisitor(ast.NodeVisitor):
    '''Base class for every NodeVisitors in `radon.visitors`. It implements a
    couple utility class methods and a static method.
    '''

    @staticmethod
    def get_name(obj):
        '''Shorthand for ``obj.__class__.__name__``.'''
        return obj.__class__.__name__

    @classmethod
    def from_code(cls, code, **kwargs):
        '''Instanciate the class from source code (string object). The
        `**kwargs` are directly passed to the `ast.NodeVisitor` constructor.
        '''
        return cls.from_ast(ast.parse(code), **kwargs)

    @classmethod
    def from_ast(cls, ast_node, **kwargs):
        '''Instanciate the class from an AST node. The `**kwargs` are
        directly passed to the `ast.NodeVisitor` constructor.
        '''
        visitor = cls(**kwargs)
        visitor.visit(ast_node)
        return visitor


class ComplexityVisitor(CodeVisitor):
    '''A visitor that keeps track of the cyclomatic complexity of
    the elements.

    :param to_method: If True, every function is treated as a method. In this
        case the *classname* parameter is used as class name.
    :param classname: Name of parent class.
    :param off: If True, the starting value for the complexity is set to 1,
        otherwise to 0.
    '''

    def __init__(self, to_method=False, classname=None, off=True,
                 no_assert=False):
        self.off = off
        self.complexity = 1 if off else 0
        self.functions = []
        self.classes = []
        self.to_method = to_method
        self.classname = classname
        self.no_assert = no_assert
        self._max_line = float('-inf')

    @property
    def functions_complexity(self):
        '''The total complexity from all functions (i.e. the total number of
        decision points + 1).
        '''
        return sum(map(GET_COMPLEXITY, self.functions)) - len(self.functions)

    @property
    def classes_complexity(self):
        '''The total complexity from all classes (i.e. the total number of
        decision points + 1).
        '''
        return sum(map(GET_REAL_COMPLEXITY, self.classes)) - len(self.classes)

    @property
    def total_complexity(self):
        '''The total complexity. Computed adding up the class complexity, the
        functions complexity, and the classes complexity.
        '''
        return (self.complexity + self.functions_complexity +
                self.classes_complexity + (not self.off))

    @property
    def blocks(self):
        '''All the blocks visited. These include: all the functions, the
        classes and their methods. The returned list is not sorted.
        '''
        blocks = self.functions
        for cls in self.classes:
            blocks.append(cls)
            blocks.extend(cls.methods)
        return blocks

    @property
    def max_line(self):
        return self._max_line

    @max_line.setter
    def max_line(self, value):
        if value > self._max_line:
            self._max_line = value

    def generic_visit(self, node):
        '''Main entry point for the visitor.'''
        # Get the name of the class
        name = self.get_name(node)
        # Check for a lineno attribute
        if hasattr(node, 'lineno'):
            self.max_line = node.lineno
        # The Try/Except block is counted as the number of handlers
        # plus the `else` block.
        # In Python 3.3 the TryExcept and TryFinally nodes have been merged
        # into a single node: Try
        if name in ('Try', 'TryExcept'):
            self.complexity += len(node.handlers) + len(node.orelse)
        elif name == 'BoolOp':
            self.complexity += len(node.values) - 1
        # Lambda functions, ifs, with and assert statements count all as 1.
        elif name in ('Lambda', 'With', 'If', 'IfExp'):
            self.complexity += 1
        # The For and While blocks count as 1 plus the `else` block.
        elif name in ('For', 'While'):
            self.complexity += bool(node.orelse) + 1
        # List, set, dict comprehensions and generator exps count as 1 plus
        # the `if` statement.
        elif name == 'comprehension':
            self.complexity += len(node.ifs) + 1

        super(ComplexityVisitor, self).generic_visit(node)

    def visit_Assert(self, node):
        self.complexity += not self.no_assert

    def visit_FunctionDef(self, node):
        # The complexity of a function is computed taking into account
        # the following factors: number of decorators, the complexity
        # the function's body and the number of clojures (which count
        # double).
        clojures = []
        body_complexity = 1
        for child in node.body:
            visitor = ComplexityVisitor(off=False, no_assert=self.no_assert)
            visitor.visit(child)
            clojures.extend(visitor.functions)
            # Add general complexity and clojures' complexity
            body_complexity += (visitor.complexity +
                                visitor.functions_complexity)

        func = Function(node.name, node.lineno, node.col_offset,
                        max(node.lineno, visitor.max_line), self.to_method,
                        self.classname, clojures, body_complexity)
        self.functions.append(func)

    def visit_ClassDef(self, node):
        # The complexity of a class is computed taking into account
        # the following factors: number of decorators and the complexity
        # of the class' body (which is the sum of all the complexities).
        methods = []
        # According to Cyclomatic Complexity definition it has to start off
        # from 1.
        body_complexity = 1
        classname = node.name
        visitors_max_lines = [node.lineno]
        for child in node.body:
            visitor = ComplexityVisitor(True, classname, off=False,
                                        no_assert=self.no_assert)
            visitor.visit(child)
            methods.extend(visitor.functions)
            body_complexity += (visitor.complexity +
                                visitor.functions_complexity)
            visitors_max_lines.append(visitor.max_line)

        cls = Class(classname, node.lineno, node.col_offset,
                    max(visitors_max_lines + list(map(GET_ENDLINE, methods))),
                    methods, body_complexity)
        self.classes.append(cls)


class HalsteadVisitor(CodeVisitor):
    '''Visitor that keeps track of operators and operands, in order to compute
    Halstead metrics (see :func:`radon.metrics.h_visit`).
    '''

    types = {ast.Num: 'n',
             ast.Name: 'id',
             ast.Attribute: 'attr'}

    def __init__(self, context=None):
        self.operators_seen = set()
        self.operands_seen = set()
        self.operators = 0
        self.operands = 0
        self.context = context

    @property
    def distinct_operators(self):
        '''The number of distinct operators.'''
        return len(self.operators_seen)

    @property
    def distinct_operands(self):
        '''The number of distinct operands.'''
        return len(self.operands_seen)

    def dispatch(meth):
        '''Does all the hard work needed for every node.

        The decorated method must return a tuple of 4 elements:

            * the number of operators
            * the number of operands
            * the operators seen (a sequence)
            * the operands seen (a sequence)
        '''
        def aux(self, node):
            results = meth(self, node)
            self.operators += results[0]
            self.operands += results[1]
            self.operators_seen.update(results[2])
            for operand in results[3]:
                new_operand = getattr(operand,
                                      self.types.get(type(operand), ''),
                                      operand)

                self.operands_seen.add((self.context, new_operand))
            # Now dispatch to children
            super(HalsteadVisitor, self).generic_visit(node)
        return aux

    @dispatch
    def visit_BinOp(self, node):
        '''A binary operator.'''
        return (1, 2, (self.get_name(node.op),), (node.left, node.right))

    @dispatch
    def visit_UnaryOp(self, node):
        '''A unary operator.'''
        return (1, 1, (self.get_name(node.op),), (node.operand,))

    @dispatch
    def visit_BoolOp(self, node):
        '''A boolean operator.'''
        return (1, len(node.values), (self.get_name(node.op),), node.values)

    @dispatch
    def visit_AugAssign(self, node):
        '''An augmented assign (contains an operator).'''
        return (1, 2, (self.get_name(node.op),), (node.target, node.value))

    @dispatch
    def visit_Compare(self, node):
        '''A comparison.'''
        return (len(node.ops), len(node.comparators) + 1,
                map(self.get_name, node.ops), node.comparators + [node.left])

    def visit_FunctionDef(self, node):
        for child in node.body:
            visitor = HalsteadVisitor.from_ast(child, context=node.name)
            self.operators += visitor.operators
            self.operands += visitor.operands
            self.operators_seen.update(visitor.operators_seen)
            self.operands_seen.update(visitor.operands_seen)

########NEW FILE########
__FILENAME__ = test
#
# Copyright 2009 keyes.ie
#
# License: http://jkeyes.mit-license.org/
#

import os
import unittest

from radon.pathfinder import find_paths
from radon.pathfinder import walk_and_filter
from radon.pathfinder.filters import *

BASEPATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "data")
pathfind = lambda *a, **kw: list(find_paths(*a, **kw))

class FindTest(unittest.TestCase):

    def test_just_dirs(self):
        """ Test just_dirs parameter."""
        # only find directories
        paths = pathfind(BASEPATH, just_dirs=True)
        self.assertEqual(5, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir1') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4') in paths)

        # use Filter.find
        paths_2 = DirectoryFilter().find(BASEPATH)
        self.assertEqual(paths, paths_2)

    def test_just_files(self):
        """ Test just_files parameter."""
        # only find files
        paths = pathfind(BASEPATH, just_files=True)
        self.assertEqual(17, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'file1.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file2.dat') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file3.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo.gif') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.gif') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.jpg') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'transparent_gs.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory', 'sub.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file4.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file5.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file6.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file7.html') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3', 'file8') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3', '.file9') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4', 'file10') in paths)

        # use Filter.find
        paths_2 = FileFilter().find(BASEPATH)
        self.assertEqual(paths, paths_2)

    def test_regex(self):
        """ Test regex parameter."""
        # find all files and directories
        paths = pathfind(BASEPATH, regex=".*")
        self.assertEqual(22, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir1') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file1.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file2.dat') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file3.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo.gif') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.gif') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.jpg') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'transparent_gs.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory', 'sub.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file4.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file5.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file6.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file7.html') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3', 'file8') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3', '.file9') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4', 'file10') in paths)

        # use Filter.find
        paths_2 = RegexFilter('.*').find(BASEPATH)
        self.assertEqual(paths, paths_2)

        # find only files and directories with a t in the extension
        paths = pathfind(BASEPATH, regex=".*\..*t.*$")
        self.assertEqual(6, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'file1.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file2.dat') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file3.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory', 'sub.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file4.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file7.html') in paths)

        # find only files and directories with 1 anywhere in the path
        paths = pathfind(BASEPATH, regex=".*1.*")
        self.assertTrue(7, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir1') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file1.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory', 'sub.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file4.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file5.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4', 'file10') in paths)

    def test_fnmatch(self):
        """ Test fnmatch parameter."""
        # find all files and directories
        paths = pathfind(BASEPATH, fnmatch="*")
        self.assertEqual(22, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir1') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file1.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file2.dat') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file3.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo.gif') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.gif') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.jpg') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'transparent_gs.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory', 'sub.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file4.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file5.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file6.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file7.html') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3', 'file8') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3', '.file9') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4', 'file10') in paths)

        # find only files or directories with a .txt extension
        paths = pathfind(BASEPATH, fnmatch="*.txt")
        self.assertEqual(4, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'file1.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file3.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory', 'sub.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file4.txt') in paths)

    def test_all(self):
        """ Test with no parameters. """
        # find all paths
        paths = pathfind(BASEPATH)
        self.assertEqual(22, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir1') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file1.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file2.dat') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file3.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo.gif') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.gif') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.jpg') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'transparent_gs.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory', 'sub.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file4.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file5.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file6.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file7.html') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3', 'file8') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3', '.file9') in paths)

    def test_and(self):
        """ Test AndFilter."""
        # find directories with a 2 anywhere in the path
        filt = AndFilter(DirectoryFilter(), RegexFilter('.*2.*'))
        paths = pathfind(BASEPATH, filter=filt)
        self.assertEqual(1, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir2') in paths)

        # test overridden __and__
        filt = DirectoryFilter() & RegexFilter('.*2.*')
        paths_2 = pathfind(BASEPATH, filter=filt)
        self.assertEqual(paths, paths_2)

        # use Filter.find
        paths_3 = AndFilter(DirectoryFilter(), RegexFilter('.*2.*')).find(BASEPATH)
        self.assertEqual(paths, paths_3)

    def test_or(self):
        """ Test OrFilter."""
        # find all directories and any files (or directories)
        # with 2 in the path
        filt = OrFilter(DirectoryFilter(), RegexFilter('.*2.*'))
        paths = pathfind(BASEPATH, filter=filt)
        self.assertEqual(8, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir1') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file2.dat') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file6.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file7.html') in paths)

        # test overridden __or__
        filt = DirectoryFilter() | RegexFilter('.*2.*')
        paths_2 = pathfind(BASEPATH, filter=filt)
        self.assertEqual(paths, paths_2)

        # use Filter.find
        paths_3 = OrFilter(DirectoryFilter(), RegexFilter('.*2.*')).find(BASEPATH)
        self.assertEqual(paths, paths_3)

    def test_not(self):
        """ Test NotFilter."""
        # find all files and directories with a .txt extension
        # except ones that end in 3.txt
        filt = AndFilter(NotFilter(FnmatchFilter('*3.txt')), FnmatchFilter('*.txt'))
        paths = pathfind(BASEPATH, filter=filt)
        self.assertEqual(3, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'file1.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory', 'sub.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file4.txt') in paths)

    def test_ignore(self):
        """ Test ignore parameter."""
        # find all directories and all files and directories
        # with a 2 in the path and no directories that begin
        # with a dot
        filt = OrFilter(DirectoryFilter(), RegexFilter('.*2.*'))
        ignore = DotDirectoryFilter()
        paths = pathfind(BASEPATH, filter=filt, ignore=ignore)
        self.assertEqual(7, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir1') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file2.dat') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file6.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file7.html') in paths)

        filt = FnmatchFilter("*.txt")
        ignore = FnmatchFilter("*4.txt")

        all_paths = pathfind(BASEPATH, filter=filt)
        self.assertEqual(4, len(all_paths))
        self.assertTrue("4.txt" in " ".join(all_paths))

        ignore_paths = pathfind(BASEPATH, filter=filt, ignore=ignore)
        self.assertEqual(3, len(ignore_paths))
        self.assertFalse("4.txt" in " ".join(ignore_paths))

    def test_abspath(self):
        """ Make sure all paths are absolute paths."""
        cwd = os.getcwd()
        paths = pathfind(BASEPATH, filter=DirectoryFilter(), abspath=True)
        self.assertEqual(5, len(paths))
        self.assertTrue(os.path.join(cwd, BASEPATH, 'dir1') in paths)
        self.assertTrue(os.path.join(cwd, BASEPATH, 'dir1', 'subdirectory') in paths)
        self.assertTrue(os.path.join(cwd, BASEPATH, 'dir2') in paths)
        self.assertTrue(os.path.join(cwd, BASEPATH, 'dir3') in paths)
        self.assertTrue(os.path.join(cwd, BASEPATH, '.dir4') in paths)

        paths = pathfind(BASEPATH, just_files=True, abspath=True)
        self.assertEqual(17, len(paths))
        self.assertTrue(os.path.join(cwd, BASEPATH, 'python_logo.png') in paths)

    def test_depth(self):
        """ Only descend a certain depth into a tree."""
        paths = pathfind(BASEPATH, filter=DirectoryFilter(), depth=1)
        self.assertEqual(4, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir1') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4') in paths)

        paths = pathfind(BASEPATH, filter=DirectoryFilter(), depth=2)
        self.assertEqual(5, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory') in paths)

    def test_find_filepath(self):
        """ Test when the root path to a find is a file and not a directory. """
        a_paths = pathfind(os.path.join(BASEPATH, 'python_logo.png'), just_files=True)
        b_paths = pathfind(BASEPATH, just_files=True)
        self.assertEqual(a_paths, b_paths)

    def test_generator(self):
        """ Test with no parameters. """
        # find all paths
        paths = []
        for path in find_paths(BASEPATH):
            paths.append(path)
        self.assertEqual(22, len(paths))
        self.assertTrue(os.path.join(BASEPATH, 'dir1') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3') in paths)
        self.assertTrue(os.path.join(BASEPATH, '.dir4') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file1.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file2.dat') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'file3.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo.gif') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.gif') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.jpg') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'python_logo_gs.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'transparent_gs.png') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'subdirectory', 'sub.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file4.txt') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir1', 'file5.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file6.log') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir2', 'file7.html') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3', 'file8') in paths)
        self.assertTrue(os.path.join(BASEPATH, 'dir3', '.file9') in paths)

########NEW FILE########
__FILENAME__ = run
if __name__ == '__main__':
    import nose
    nose.main()

########NEW FILE########
__FILENAME__ = main
# from plumbum

class AtomicFile(object):
    """
    Atomic file operations implemented using file-system advisory locks (``flock`` on POSIX,
    ``LockFile`` on Windows).

    .. note::
        On Linux, the manpage says ``flock`` might have issues with NFS mounts. You should
        take this into account.

    .. versionadded:: 1.3
    """

    CHUNK_SIZE = 32 * 1024

    def __init__(self, filename, ignore_deletion = False):
        self.path = local.path(filename)
        self._ignore_deletion = ignore_deletion
        self._thdlock = threading.Lock()
        self._owned_by = None
        self._fileobj = None
        self.reopen()

    def __repr__(self):
        return "<AtomicFile: %s>" % (self.path,) if self._fileobj else "<AtomicFile: closed>"

    def __del__(self):
        self.close()
    def __enter__(self):
        return self
    def __exit__(self, t, v, tb):
        self.close()

    def close(self):
        if self._fileobj is not None:
            self._fileobj.close()
            self._fileobj = None

    def reopen(self):
        """
        Close and reopen the file; useful when the file was deleted from the file system
        by a different process
        """
        self.close()
        self._fileobj = os.fdopen(os.open(str(self.path), os.O_CREAT | os.O_RDWR, 384), "r+b", 0)

    @contextmanager
    def locked(self, blocking = True):
        """
        A context manager that locks the file; this function is reentrant by the thread currently
        holding the lock.

        :param blocking: if ``True``, the call will block until we can grab the file system lock.
                         if ``False``, the call may fail immediately with the underlying exception
                         (``IOError`` or ``WindowsError``)
        """
        if self._owned_by == threading.get_ident():
            yield
            return
        with self._thdlock:
            with locked_file(self._fileobj.fileno(), blocking):
                if not self.path.exists() and not self._ignore_deletion:
                    raise ValueError("Atomic file removed from filesystem")
                self._owned_by = threading.get_ident()
                try:
                    yield
                finally:
                    self._owned_by = None

    def delete(self):
        """
        Atomically delete the file (holds the lock while doing it)
        """
        with self.locked():
            self.path.delete()

    def _read_all(self):
        self._fileobj.seek(0)
        data = []
        while True:
            buf = self._fileobj.read(self.CHUNK_SIZE)
            data.append(buf)
            if len(buf) < self.CHUNK_SIZE:
                break
        return six.b("").join(data)

    def read_atomic(self):
        """Atomically read the entire file"""
        with self.locked():
            return self._read_all()

    def read_shared(self):
        """Read the file **without** holding the lock"""
        return self._read_all()

    def write_atomic(self, data):
        """Writes the given data atomically to the file. Note that it overwrites the entire file;
        ``write_atomic("foo")`` followed by ``write_atomic("bar")`` will result in only ``"bar"``.
        """
        with self.locked():
            self._fileobj.seek(0)
            while data:
                chunk = data[:self.CHUNK_SIZE]
                self._fileobj.write(chunk)
                data = data[len(chunk):]
            self._fileobj.flush()
            self._fileobj.truncate()

########NEW FILE########
__FILENAME__ = secondary
# from circus
import errno
import logging
import os
from circus.fixed_threading import Thread, get_ident
import sys
from time import sleep
import select
import socket
from tornado import gen
import time

import zmq
from zmq.eventloop import ioloop

from circus.controller import Controller
from circus.exc import AlreadyExist
from circus import logger
from circus.watcher import Watcher
from circus.util import debuglog, _setproctitle, parse_env_dict
from circus.util import DictDiffer, synchronized, tornado_sleep
from circus.config import get_config
from circus.plugins import get_plugin_cmd
from circus.sockets import CircusSocket, CircusSockets


_ENV_EXCEPTIONS = ('__CF_USER_TEXT_ENCODING', 'PS1', 'COMP_WORDBREAKS',
                   'PROMPT_COMMAND')


class Arbiter(object):

    """Class used to control a list of watchers.

    Options:

    - **watchers** -- a list of Watcher objects
    - **endpoint** -- the controller ZMQ endpoint
    - **pubsub_endpoint** -- the pubsub endpoint
    - **statsd** -- If True, a circusd-stats process is run (default: False)
    - **stats_endpoint** -- the stats endpoint.
    - **statsd_close_outputs** -- if True sends the circusd-stats stdout/stderr
      to /dev/null (default: False)
    - **multicast_endpoint** -- the multicast endpoint for circusd cluster
      auto-discovery (default: udp://237.219.251.97:12027)
      Multicast addr should be between 224.0.0.0 to 239.255.255.255 and the
      same for the all cluster.
    - **check_delay** -- the delay between two controller points
      (default: 1 s)
    - **prereload_fn** -- callable that will be executed on each reload
      (default: None)
    - **context** -- if provided, the zmq context to reuse.
      (default: None)
    - **loop**: if provided, a :class:`zmq.eventloop.ioloop.IOLoop` instance
       to reuse. (default: None)
    - **plugins** -- a list of plugins. Each item is a mapping with:

        - **use** -- Fully qualified name that points to the plugin class
        - every other value is passed to the plugin in the **config** option
    - **sockets** -- a mapping of sockets. Each key is the socket name,
      and each value a :class:`CircusSocket` class. (default: None)
    - **warmup_delay** -- a delay in seconds between two watchers startup.
      (default: 0)
    - **httpd** -- If True, a circushttpd process is run (default: False)
    - **httpd_host** -- the circushttpd host (default: localhost)
    - **httpd_port** -- the circushttpd port (default: 8080)
    - **httpd_close_outputs** -- if True, sends circushttpd stdout/stderr
      to /dev/null. (default: False)
    - **debug** -- if True, adds a lot of debug info in the stdout (default:
      False)
    - **proc_name** -- the arbiter process name
    - **fqdn_prefix** -- a prefix for the unique identifier of the circus
                         instance on the cluster.
    """

    def __init__(self, watchers, endpoint, pubsub_endpoint, check_delay=1.0,
                 prereload_fn=None, context=None, loop=None, statsd=False,
                 stats_endpoint=None, statsd_close_outputs=False,
                 multicast_endpoint=None, plugins=None,
                 sockets=None, warmup_delay=0, httpd=False,
                 httpd_host='localhost', httpd_port=8080,
                 httpd_close_outputs=False, debug=False,
                 ssh_server=None, proc_name='circusd', pidfile=None,
                 loglevel=None, logoutput=None, fqdn_prefix=None, umask=None):

        self.watchers = watchers
        self.endpoint = endpoint
        self.check_delay = check_delay
        self.prereload_fn = prereload_fn
        self.pubsub_endpoint = pubsub_endpoint
        self.multicast_endpoint = multicast_endpoint
        self.proc_name = proc_name
        self.ssh_server = ssh_server
        self.evpub_socket = None
        self.pidfile = pidfile
        self.loglevel = loglevel
        self.logoutput = logoutput
        self.umask = umask

        try:
            # getfqdn appears to fail in Python3.3 in the unittest
            # framework so fall back to gethostname
            socket_fqdn = socket.getfqdn()
        except KeyError:
            socket_fqdn = socket.gethostname()
        if fqdn_prefix is None:
            fqdn = socket_fqdn
        else:
            fqdn = '{}@{}'.format(fqdn_prefix, socket_fqdn)
        self.fqdn = fqdn

        self.ctrl = self.loop = None
        self._provided_loop = False
        self.socket_event = False
        if loop is not None:
            self._provided_loop = True
            self.loop = loop

        # initialize zmq context
        self._init_context(context)
        self.pid = os.getpid()
        self._watchers_names = {}
        self._stopping = False
        self._restarting = False
        self.debug = debug
        self._exclusive_running_command = None
        if self.debug:
            self.stdout_stream = self.stderr_stream = {'class': 'StdoutStream'}
        else:
            self.stdout_stream = self.stderr_stream = None

        # initializing circusd-stats as a watcher when configured
        self.statsd = statsd
        self.stats_endpoint = stats_endpoint

        if self.statsd:
            cmd = "%s -c 'from circus import stats; stats.main()'" % \
                sys.executable
            cmd += ' --endpoint %s' % self.endpoint
            cmd += ' --pubsub %s' % self.pubsub_endpoint
            cmd += ' --statspoint %s' % self.stats_endpoint
            if ssh_server is not None:
                cmd += ' --ssh %s' % ssh_server
            if debug:
                cmd += ' --log-level DEBUG'
            stats_watcher = Watcher('circusd-stats', cmd, use_sockets=True,
                                    singleton=True,
                                    stdout_stream=self.stdout_stream,
                                    stderr_stream=self.stderr_stream,
                                    copy_env=True, copy_path=True,
                                    close_child_stderr=statsd_close_outputs,
                                    close_child_stdout=statsd_close_outputs)

            self.watchers.append(stats_watcher)

        # adding the httpd
        if httpd:
            # adding the socket
            httpd_socket = CircusSocket(name='circushttpd', host=httpd_host,
                                        port=httpd_port)
            if sockets is None:
                sockets = [httpd_socket]
            else:
                sockets.append(httpd_socket)

            cmd = ("%s -c 'from circusweb import circushttpd; "
                   "circushttpd.main()'") % sys.executable
            cmd += ' --endpoint %s' % self.endpoint
            cmd += ' --fd $(circus.sockets.circushttpd)'
            if ssh_server is not None:
                cmd += ' --ssh %s' % ssh_server

            # Adding the watcher
            httpd_watcher = Watcher('circushttpd', cmd, use_sockets=True,
                                    singleton=True,
                                    stdout_stream=self.stdout_stream,
                                    stderr_stream=self.stderr_stream,
                                    copy_env=True, copy_path=True,
                                    close_child_stderr=httpd_close_outputs,
                                    close_child_stdout=httpd_close_outputs)
            self.watchers.append(httpd_watcher)

        # adding each plugin as a watcher
        ch_stderr = self.stderr_stream is None
        ch_stdout = self.stdout_stream is None

        if plugins is not None:
            for plugin in plugins:
                fqn = plugin['use']
                cmd = get_plugin_cmd(plugin, self.endpoint,
                                     self.pubsub_endpoint, self.check_delay,
                                     ssh_server, debug=self.debug)
                plugin_cfg = dict(cmd=cmd, priority=1, singleton=True,
                                  stdout_stream=self.stdout_stream,
                                  stderr_stream=self.stderr_stream,
                                  copy_env=True, copy_path=True,
                                  close_child_stderr=ch_stderr,
                                  close_child_stdout=ch_stdout)
                plugin_cfg.update(plugin)
                if 'name' not in plugin_cfg:
                    plugin_cfg['name'] = fqn

                plugin_watcher = Watcher.load_from_config(plugin_cfg)
                self.watchers.append(plugin_watcher)

        self.sockets = CircusSockets(sockets)
        self.warmup_delay = warmup_delay

    def _init_context(self, context):
        self.context = context or zmq.Context.instance()
        if self.loop is None:
            ioloop.install()
            self.loop = ioloop.IOLoop.instance()
        self.ctrl = Controller(self.endpoint, self.multicast_endpoint,
                               self.context, self.loop, self, self.check_delay)

    def get_socket(self, name):
        return self.sockets.get(name, None)

    def get_socket_config(self, config, name):
        for i in config.get('sockets', []):
            if i['name'] == name:
                return i.copy()
        return None

    def get_watcher_config(self, config, name):
        for i in config.get('watchers', []):
            if i['name'] == name:
                return i.copy()
        return None

    def get_plugin_config(self, config, name):
        for i in config.get('plugins', []):
            if i['name'] == name:
                cfg = i.copy()
                cmd = get_plugin_cmd(cfg, self.endpoint,
                                     self.pubsub_endpoint, self.check_delay,
                                     self.ssh_server, debug=self.debug)

                cfg.update(dict(cmd=cmd, priority=1, singleton=True,
                                stdout_stream=self.stdout_stream,
                                stderr_stream=self.stderr_stream,
                                copy_env=True, copy_path=True))
                return cfg
        return None

    @classmethod
    def get_arbiter_config(cls, config):
        cfg = config.copy()
        del cfg['watchers']
        del cfg['plugins']
        del cfg['sockets']

        return cfg

    @synchronized("arbiter_reload_config")
    @gen.coroutine
    def reload_from_config(self, config_file=None, inside_circusd=False):
        new_cfg = get_config(config_file if config_file else self.config_file)
        # if arbiter is changed, reload everything
        if self.get_arbiter_config(new_cfg) != self._cfg:
            yield self._restart(inside_circusd=inside_circusd)
            return

        ignore_sn = set(['circushttpd'])
        ignore_wn = set(['circushttpd', 'circusd-stats'])

        # Gather socket names.
        current_sn = set([i.name for i in self.sockets.values()]) - ignore_sn
        new_sn = set([i['name'] for i in new_cfg.get('sockets', [])])
        added_sn = new_sn - current_sn
        deleted_sn = current_sn - new_sn
        maybechanged_sn = current_sn - deleted_sn
        changed_sn = set([])
        wn_with_changed_socket = set([])
        wn_with_deleted_socket = set([])

        # get changed sockets
        for n in maybechanged_sn:
            s = self.get_socket(n)
            if self.get_socket_config(new_cfg, n) != s._cfg:
                changed_sn.add(n)

                # just delete the socket and add it again
                deleted_sn.add(n)
                added_sn.add(n)

                # Get the watchers whichs use these, so they could be
                # deleted and added also
                for w in self.iter_watchers():
                    if 'circus.sockets.%s' % n.lower() in w.cmd:
                        wn_with_changed_socket.add(w.name)

        # get deleted sockets
        for n in deleted_sn:
            s = self.get_socket(n)
            s.close()
            # Get the watchers whichs use these, these should not be
            # active anymore
            for w in self.iter_watchers():
                if 'circus.sockets.%s' % n.lower() in w.cmd:
                    wn_with_deleted_socket.add(w.name)
            del self.sockets[s.name]

        # get added sockets
        for n in added_sn:
            socket_config = self.get_socket_config(new_cfg, n)
            s = CircusSocket.load_from_config(socket_config)
            s.bind_and_listen()
            self.sockets[s.name] = s

        if added_sn or deleted_sn:
            # make sure all existing watchers get the new sockets in
            # their attributes and get the old removed
            # XXX: is this necessary? self.sockets is an mutable
            # object
            for watcher in self.iter_watchers():
                # XXX: What happens as initalize is called on a
                # running watcher?
                watcher.initialize(self.evpub_socket, self.sockets, self)

        # Gather watcher names.
        current_wn = set([i.name for i in self.iter_watchers()]) - ignore_wn
        new_wn = set([i['name'] for i in new_cfg.get('watchers', [])])
        new_wn = new_wn | set([i['name'] for i in new_cfg.get('plugins', [])])
        added_wn = (new_wn - current_wn) | wn_with_changed_socket
        deleted_wn = current_wn - new_wn - wn_with_changed_socket
        maybechanged_wn = current_wn - deleted_wn
        changed_wn = set([])

        if wn_with_deleted_socket and wn_with_deleted_socket not in new_wn:
            raise ValueError('Watchers %s uses a socket which is deleted' %
                             wn_with_deleted_socket)

        # get changed watchers
        for n in maybechanged_wn:
            w = self.get_watcher(n)
            new_watcher_cfg = (self.get_watcher_config(new_cfg, n) or
                               self.get_plugin_config(new_cfg, n))
            old_watcher_cfg = w._cfg.copy()

            if 'env' in new_watcher_cfg:
                new_watcher_cfg['env'] = parse_env_dict(new_watcher_cfg['env'])

            # discarding env exceptions
            for key in _ENV_EXCEPTIONS:
                if 'env' in new_watcher_cfg and key in new_watcher_cfg['env']:
                    del new_watcher_cfg['env'][key]

                if 'env' in new_watcher_cfg and key in old_watcher_cfg['env']:
                    del old_watcher_cfg['env'][key]

            diff = DictDiffer(new_watcher_cfg, old_watcher_cfg).changed()

            if diff == set(['numprocesses']):
                # if nothing but the number of processes is
                # changed, just changes this
                w.set_numprocesses(int(new_watcher_cfg['numprocesses']))
                changed = False
            else:
                changed = len(diff) > 0

            if changed:
                # Others things are changed. Just delete and add the watcher.
                changed_wn.add(n)
                deleted_wn.add(n)
                added_wn.add(n)

        # delete watchers
        for n in deleted_wn:
            w = self.get_watcher(n)
            yield w._stop()
            del self._watchers_names[w.name.lower()]
            self.watchers.remove(w)

        # add watchers
        for n in added_wn:
            new_watcher_cfg = (self.get_plugin_config(new_cfg, n) or
                               self.get_watcher_config(new_cfg, n))

            w = Watcher.load_from_config(new_watcher_cfg)
            w.initialize(self.evpub_socket, self.sockets, self)
            yield self.start_watcher(w)
            self.watchers.append(w)
            self._watchers_names[w.name.lower()] = w

    @classmethod
    def load_from_config(cls, config_file, loop=None):
        cfg = get_config(config_file)
        watchers = []
        for watcher in cfg.get('watchers', []):
            watchers.append(Watcher.load_from_config(watcher))

        sockets = []
        for socket in cfg.get('sockets', []):
            sockets.append(CircusSocket.load_from_config(socket))

        httpd = cfg.get('httpd', False)
        if httpd:
            # controlling that we have what it takes to run the web UI
            # if something is missing this will tell the user
            try:
                import circusweb  # NOQA
            except ImportError:
                logger.error('You need to install circus-web')
                sys.exit(1)

        # creating arbiter
        arbiter = cls(watchers, cfg['endpoint'], cfg['pubsub_endpoint'],
                      check_delay=cfg.get('check_delay', 1.),
                      prereload_fn=cfg.get('prereload_fn'),
                      statsd=cfg.get('statsd', False),
                      stats_endpoint=cfg.get('stats_endpoint'),
                      multicast_endpoint=cfg.get('multicast_endpoint'),
                      plugins=cfg.get('plugins'), sockets=sockets,
                      warmup_delay=cfg.get('warmup_delay', 0),
                      httpd=httpd,
                      loop=loop,
                      httpd_host=cfg.get('httpd_host', 'localhost'),
                      httpd_port=cfg.get('httpd_port', 8080),
                      debug=cfg.get('debug', False),
                      ssh_server=cfg.get('ssh_server', None),
                      pidfile=cfg.get('pidfile', None),
                      loglevel=cfg.get('loglevel', None),
                      logoutput=cfg.get('logoutput', None),
                      fqdn_prefix=cfg.get('fqdn_prefix', None),
                      umask=cfg['umask'])

        # store the cfg which will be used, so it can be used later
        # for checking if the cfg has been changed
        arbiter._cfg = cls.get_arbiter_config(cfg)
        arbiter.config_file = config_file

        return arbiter

    def iter_watchers(self, reverse=True):
        return sorted(self.watchers, key=lambda a: a.priority, reverse=reverse)

    @debuglog
    def initialize(self):
        # set process title
        _setproctitle(self.proc_name)

        # set umask even though we may have already set it early in circusd.py
        if self.umask is not None:
            os.umask(self.umask)

        # event pub socket
        self.evpub_socket = self.context.socket(zmq.PUB)
        self.evpub_socket.bind(self.pubsub_endpoint)
        self.evpub_socket.linger = 0

        # initialize sockets
        if len(self.sockets) > 0:
            self.sockets.bind_and_listen_all()
            logger.info("sockets started")

        # initialize watchers
        for watcher in self.iter_watchers():
            self._watchers_names[watcher.name.lower()] = watcher
            watcher.initialize(self.evpub_socket, self.sockets, self)

    @gen.coroutine
    def start_watcher(self, watcher):
        """Aska a specific watcher to start and wait for the specified
        warmup delay."""
        if watcher.autostart:
            yield watcher._start()
            yield tornado_sleep(self.warmup_delay)

    @gen.coroutine
    @debuglog
    def start(self):
        """Starts all the watchers.

        If the ioloop has been provided during __init__() call,
        starts all watchers as a standard coroutine

        If the ioloop hasn't been provided during __init__() call (default),
        starts all watchers and the eventloop (and blocks here). In this mode
        the method MUST NOT yield anything because it's called as a standard
        method.
        """
        logger.info("Starting master on pid %s", self.pid)
        self.initialize()

        # start controller
        self.ctrl.start()
        self._restarting = False
        try:
            # initialize processes
            logger.debug('Initializing watchers')
            if self._provided_loop:
                yield self.start_watchers()
            else:
                # start_watchers will be called just after the start_io_loop()
                self.loop.add_future(self.start_watchers(), lambda x: None)
            logger.info('Arbiter now waiting for commands')
            if not self._provided_loop:
                # If an event loop is not provided, block at this line
                self.start_io_loop()
        finally:
            if not self._provided_loop:
                # If an event loop is not provided, do some cleaning
                self.stop_controller_and_close_sockets()
        raise gen.Return(self._restarting)

    def stop_controller_and_close_sockets(self):
        self.ctrl.stop()
        self.evpub_socket.close()
        if len(self.sockets) > 0:
            self.sockets.close_all()

    def start_io_loop(self):
        """Starts the ioloop and wait inside it
        """
        while True:
            try:
                self.loop.start()
            except zmq.ZMQError as e:
                if e.errno == errno.EINTR:
                    continue
                else:
                    raise
            else:
                break

    @synchronized("arbiter_stop")
    @gen.coroutine
    def stop(self):
        yield self._stop()

    @gen.coroutine
    def _emergency_stop(self):
        """Emergency and fast stop, to use only in circusd
        """
        for watcher in self.iter_watchers():
            watcher.graceful_timeout = 0
        yield self._stop_watchers()
        self.stop_controller_and_close_sockets()

    @gen.coroutine
    def _stop(self):
        logger.info('Arbiter exiting')
        self._stopping = True
        yield self._stop_watchers(close_output_streams=True)
        if self._provided_loop:
            cb = self.stop_controller_and_close_sockets
            self.loop.add_callback(cb)
        else:
            self.loop.add_timeout(time.time() + 1, self._stop_cb)

    def _stop_cb(self):
        self.loop.stop()
        # stop_controller_and_close_sockets will be
        # called in the end of start() method

    def reap_processes(self):
        # map watcher to pids
        watchers_pids = {}
        for watcher in self.iter_watchers():
            if not watcher.is_stopped():
                for process in watcher.processes.values():
                    watchers_pids[process.pid] = watcher

        # detect dead children
        while True:
            try:
                # wait for our child (so it's not a zombie)
                pid, status = os.waitpid(-1, os.WNOHANG)
                if not pid:
                    break

                if pid in watchers_pids:
                    watcher = watchers_pids[pid]
                    watcher.reap_process(pid, status)
            except OSError as e:
                if e.errno == errno.EAGAIN:
                    sleep(0)
                    continue
                elif e.errno == errno.ECHILD:
                    # process already reaped
                    return
                else:
                    raise

    @synchronized("manage_watchers")
    @gen.coroutine
    def manage_watchers(self):
        if self._stopping:
            return

        need_on_demand = False
        # manage and reap processes
        self.reap_processes()
        list_to_yield = []
        for watcher in self.iter_watchers():
            if watcher.on_demand and watcher.is_stopped():
                need_on_demand = True
            list_to_yield.append(watcher.manage_processes())
        if len(list_to_yield) > 0:
            yield list_to_yield

        if need_on_demand:
            sockets = [x.fileno() for x in self.sockets.values()]
            rlist, wlist, xlist = select.select(sockets, [], [], 0)
            if rlist:
                self.socket_event = True
                self._start_watchers()
                self.socket_event = False

    @synchronized("arbiter_reload")
    @gen.coroutine
    @debuglog
    def reload(self, graceful=True):
        """Reloads everything.

        Run the :func:`prereload_fn` callable if any, then gracefuly
        reload all watchers.
        """
        if self._stopping:
            return
        if self.prereload_fn is not None:
            self.prereload_fn(self)

        # reopen log files
        for handler in logger.handlers:
            if isinstance(handler, logging.FileHandler):
                handler.acquire()
                handler.stream.close()
                handler.stream = open(handler.baseFilename, handler.mode)
                handler.release()

        # gracefully reload watchers
        for watcher in self.iter_watchers():
            yield watcher._reload(graceful=graceful)
            tornado_sleep(self.warmup_delay)

    def numprocesses(self):
        """Return the number of processes running across all watchers."""
        return sum([len(watcher) for watcher in self.watchers])

    def numwatchers(self):
        """Return the number of watchers."""
        return len(self.watchers)

    def get_watcher(self, name):
        """Return the watcher *name*."""
        return self._watchers_names[name]

    def statuses(self):
        return dict([(watcher.name, watcher.status())
                     for watcher in self.watchers])

    @synchronized("arbiter_add_watcher")
    def add_watcher(self, name, cmd, **kw):
        """Adds a watcher.

        Options:

        - **name**: name of the watcher to add
        - **cmd**: command to run.
        - all other options defined in the Watcher constructor.
        """
        if name in self._watchers_names:
            raise AlreadyExist("%r already exist" % name)

        if not name:
            return ValueError("command name shouldn't be empty")

        watcher = Watcher(name, cmd, **kw)
        if self.evpub_socket is not None:
            watcher.initialize(self.evpub_socket, self.sockets, self)
        self.watchers.append(watcher)
        self._watchers_names[watcher.name.lower()] = watcher
        return watcher

    @synchronized("arbiter_rm_watcher")
    @gen.coroutine
    def rm_watcher(self, name):
        """Deletes a watcher.

        Options:

        - **name**: name of the watcher to delete
        """
        logger.debug('Deleting %r watcher', name)

        # remove the watcher from the list
        watcher = self._watchers_names.pop(name)
        del self.watchers[self.watchers.index(watcher)]

        # stop the watcher
        yield watcher._stop()

    @synchronized("arbiter_start_watchers")
    @gen.coroutine
    def start_watchers(self):
        yield self._start_watchers()

    @gen.coroutine
    def _start_watchers(self):
        for watcher in self.iter_watchers():
            if watcher.autostart:
                yield watcher._start()
                yield tornado_sleep(self.warmup_delay)

    @gen.coroutine
    @debuglog
    def _stop_watchers(self, close_output_streams=False):
        yield [w._stop(close_output_streams)
               for w in self.iter_watchers(reverse=False)]

    @synchronized("arbiter_stop_watchers")
    @gen.coroutine
    def stop_watchers(self):
        yield self._stop_watchers()

    @gen.coroutine
    def _restart(self, inside_circusd=False):
        if inside_circusd:
            self._restarting = True
            yield self._stop()
        else:
            yield self._stop_watchers()
            yield self._start_watchers()

    @synchronized("arbiter_restart")
    @gen.coroutine
    def restart(self, inside_circusd=False):
        yield self._restart(inside_circusd=inside_circusd)


class ThreadedArbiter(Thread, Arbiter):

    def __init__(self, *args, **kw):
        Thread.__init__(self)
        Arbiter.__init__(self, *args, **kw)

    def start(self):
        return Thread.start(self)

    def run(self):
        return Arbiter.start(self)

    def stop(self):
        Arbiter.stop(self)
        if get_ident() != self.ident and self.isAlive():
            self.join()

########NEW FILE########
__FILENAME__ = testall
def solve(f, *symbols, **flags):
    def _sympified_list(w):
        return list(map(sympify, w if iterable(w) else [w]))
    bare_f = not iterable(f)
    ordered_symbols = (symbols and
                       symbols[0] and
                       (isinstance(symbols[0], Symbol) or
                        is_sequence(symbols[0],
                        include=GeneratorType)
                       )
                      )
    f, symbols = (_sympified_list(w) for w in [f, symbols])

    implicit = flags.get('implicit', False)

    # preprocess equation(s)
    ###########################################################################
    for i, fi in enumerate(f):
        if isinstance(fi, Equality):
            f[i] = fi.lhs - fi.rhs
        elif isinstance(fi, Poly):
            f[i] = fi.as_expr()
        elif isinstance(fi, bool) or fi.is_Relational:
            return reduce_inequalities(f, assume=flags.get('assume'),
                                       symbols=symbols)

        # Any embedded piecewise functions need to be brought out to the
        # top level so that the appropriate strategy gets selected.
        # However, this is necessary only if one of the piecewise
        # functions depends on one of the symbols we are solving for.
        def _has_piecewise(e):
            if e.is_Piecewise:
                return e.has(*symbols)
            return any([_has_piecewise(a) for a in e.args])
        if _has_piecewise(f[i]):
            f[i] = piecewise_fold(f[i])

        # if we have a Matrix, we need to iterate over its elements again
        if f[i].is_Matrix:
            bare_f = False
            f.extend(list(f[i]))
            f[i] = S.Zero

        # if we can split it into real and imaginary parts then do so
        freei = f[i].free_symbols
        if freei and all(s.is_real or s.is_imaginary for s in freei):
            fr, fi = f[i].as_real_imag()
            if fr and fi and not any(i.has(re, im, arg) for i in (fr, fi)) \
                    and fr != fi:
                if bare_f:
                    bare_f = False
                f[i: i + 1] = [fr, fi]

    # preprocess symbol(s)
    ###########################################################################
    if not symbols:
        # get symbols from equations
        symbols = reduce(set.union, [fi.free_symbols
                                     for fi in f], set())
        if len(symbols) < len(f):
            for fi in f:
                pot = preorder_traversal(fi)
                for p in pot:
                    if not (p.is_number or p.is_Add or p.is_Mul) or \
                            isinstance(p, AppliedUndef):
                        flags['dict'] = True  # better show symbols
                        symbols.add(p)
                        pot.skip()  # don't go any deeper
        symbols = list(symbols)
        # supply dummy symbols so solve(3) behaves like solve(3, x)
        for i in range(len(f) - len(symbols)):
            symbols.append(Dummy())

        ordered_symbols = False
    elif len(symbols) == 1 and iterable(symbols[0]):
        symbols = symbols[0]

    # remove symbols the user is not interested in
    exclude = flags.pop('exclude', set())
    if exclude:
        if isinstance(exclude, Expr):
            exclude = [exclude]
        exclude = reduce(set.union, [e.free_symbols for e in sympify(exclude)])
    symbols = [s for s in symbols if s not in exclude]

    # real/imag handling
    for i, fi in enumerate(f):
        _abs = [a for a in fi.atoms(Abs) if a.has(*symbols)]
        fi = f[i] = fi.xreplace(dict(list(zip(_abs,
            [sqrt(a.args[0]**2) for a in _abs]))))
        if fi.has(*_abs):
            if any(s.assumptions0 for a in
                    _abs for s in a.free_symbols):
                raise NotImplementedError(filldedent('''
                All absolute
                values were not removed from %s. In order to solve
                this equation, try replacing your symbols with
                Dummy symbols (or other symbols without assumptions).
                ''' % fi))
            else:
                raise NotImplementedError(filldedent('''
                Removal of absolute values from %s failed.''' % fi))
        _arg = [a for a in fi.atoms(arg) if a.has(*symbols)]
        f[i] = fi.xreplace(dict(list(zip(_arg,
            [atan(im(a.args[0])/re(a.args[0])) for a in _arg]))))
    # see if re(s) or im(s) appear
    irf = []
    for s in symbols:
        # if s is real or complex then re(s) or im(s) will not appear in the equation;
        if s.is_real or s.is_complex:
            continue
        # if re(s) or im(s) appear, the auxiliary equation must be present
        irs = re(s), im(s)
        if any(_f.has(i) for _f in f for i in irs):
            symbols.extend(irs)
            irf.append((s, re(s) + S.ImaginaryUnit*im(s)))
    if irf:
        for s, rhs in irf:
            for i, fi in enumerate(f):
                f[i] = fi.xreplace({s: rhs})
        if bare_f:
            bare_f = False
        flags['dict'] = True
        f.extend(s - rhs for s, rhs in irf)
    # end of real/imag handling

    symbols = list(uniq(symbols))
    if not ordered_symbols:
        # we do this to make the results returned canonical in case f
        # contains a system of nonlinear equations; all other cases should
        # be unambiguous
        symbols = sorted(symbols, key=default_sort_key)

    # we can solve for non-symbol entities by replacing them with Dummy symbols
    symbols_new = []
    symbol_swapped = False
    for i, s in enumerate(symbols):
        if s.is_Symbol:
            s_new = s
        else:
            symbol_swapped = True
            s_new = Dummy('X%d' % i)
        symbols_new.append(s_new)

    if symbol_swapped:
        swap_sym = list(zip(symbols, symbols_new))
        f = [fi.subs(swap_sym) for fi in f]
        symbols = symbols_new
        swap_sym = dict([(v, k) for k, v in swap_sym])
    else:
        swap_sym = {}

    # this is needed in the next two events
    symset = set(symbols)

    # get rid of equations that have no symbols of interest; we don't
    # try to solve them because the user didn't ask and they might be
    # hard to solve; this means that solutions may be given in terms
    # of the eliminated equations e.g. solve((x-y, y-3), x) -> {x: y}
    newf = []
    for fi in f:
        # let the solver handle equations that..
        # - have no symbols but are expressions
        # - have symbols of interest
        # - have no symbols of interest but are constant
        # but when an expression is not constant and has no symbols of
        # interest, it can't change what we obtain for a solution from
        # the remaining equations so we don't include it; and if it's
        # zero it can be removed and if it's not zero, there is no
        # solution for the equation set as a whole
        #
        # The reason for doing this filtering is to allow an answer
        # to be obtained to queries like solve((x - y, y), x); without
        # this mod the return value is []
        ok = False
        if fi.has(*symset):
            ok = True
        else:
            free = fi.free_symbols
            if not free:
                if fi.is_Number:
                    if fi.is_zero:
                        continue
                    return []
                ok = True
            else:
                if fi.is_constant():
                    ok = True
        if ok:
            newf.append(fi)
    if not newf:
        return []
    f = newf
    del newf

    # mask off any Object that we aren't going to invert: Derivative,
    # Integral, etc... so that solving for anything that they contain will
    # give an implicit solution
    seen = set()
    non_inverts = set()
    for fi in f:
        pot = preorder_traversal(fi)
        for p in pot:
            if not isinstance(p, Expr) or isinstance(p, Piecewise):
                pass
            elif (isinstance(p, bool) or
                    not p.args or
                    p in symset or
                    p.is_Add or p.is_Mul or
                    p.is_Pow and not implicit or
                    p.is_Function and not implicit):
                continue
            elif not p in seen:
                seen.add(p)
                if p.free_symbols & symset:
                    non_inverts.add(p)
                else:
                    continue
            pot.skip()
    del seen
    non_inverts = dict(list(zip(non_inverts, [Dummy() for d in non_inverts])))
    f = [fi.subs(non_inverts) for fi in f]

    non_inverts = [(v, k.subs(swap_sym)) for k, v in non_inverts.items()]

    # rationalize Floats
    floats = False
    if flags.get('rational', True) is not False:
        for i, fi in enumerate(f):
            if fi.has(Float):
                floats = True
                f[i] = nsimplify(fi, rational=True)

    #
    # try to get a solution
    ###########################################################################
    if bare_f:
        solution = _solve(f[0], *symbols, **flags)
    else:
        solution = _solve_system(f, symbols, **flags)

    #
    # postprocessing
    ###########################################################################
    # Restore masked-off objects
    if non_inverts:

        def _do_dict(solution):
            return dict([(k, v.subs(non_inverts)) for k, v in
                         solution.items()])
        for i in range(1):
            if type(solution) is dict:
                solution = _do_dict(solution)
                break
            elif solution and type(solution) is list:
                if type(solution[0]) is dict:
                    solution = [_do_dict(s) for s in solution]
                    break
                elif type(solution[0]) is tuple:
                    solution = [tuple([v.subs(non_inverts) for v in s]) for s
                                in solution]
                    break
                else:
                    solution = [v.subs(non_inverts) for v in solution]
                    break
            elif not solution:
                break
        else:
            raise NotImplementedError(filldedent('''
                            no handling of %s was implemented''' % solution))

    # Restore original "symbols" if a dictionary is returned.
    # This is not necessary for
    #   - the single univariate equation case
    #     since the symbol will have been removed from the solution;
    #   - the nonlinear poly_system since that only supports zero-dimensional
    #     systems and those results come back as a list
    #
    # ** unless there were Derivatives with the symbols, but those were handled
    #    above.
    if symbol_swapped:
        symbols = [swap_sym[k] for k in symbols]
        if type(solution) is dict:
            solution = dict([(swap_sym[k], v.subs(swap_sym))
                             for k, v in solution.items()])
        elif solution and type(solution) is list and type(solution[0]) is dict:
            for i, sol in enumerate(solution):
                solution[i] = dict([(swap_sym[k], v.subs(swap_sym))
                              for k, v in sol.items()])

    # undo the dictionary solutions returned when the system was only partially
    # solved with poly-system if all symbols are present
    if (
            solution and
            ordered_symbols and
            type(solution) is not dict and
            type(solution[0]) is dict and
            all(s in solution[0] for s in symbols)
    ):
        solution = [tuple([r[s].subs(r) for s in symbols]) for r in solution]

    # Get assumptions about symbols, to filter solutions.
    # Note that if assumptions about a solution can't be verified, it is still
    # returned.
    check = flags.get('check', True)

    # restore floats
    if floats and solution and flags.get('rational', None) is None:
        solution = nfloat(solution, exponent=False)

    if check and solution:

        warning = flags.get('warn', False)
        got_None = []  # solutions for which one or more symbols gave None
        no_False = []  # solutions for which no symbols gave False
        if type(solution) is list:
            if type(solution[0]) is tuple:
                for sol in solution:
                    for symb, val in zip(symbols, sol):
                        test = check_assumptions(val, **symb.assumptions0)
                        if test is False:
                            break
                        if test is None:
                            got_None.append(sol)
                    else:
                        no_False.append(sol)
            elif type(solution[0]) is dict:
                for sol in solution:
                    a_None = False
                    for symb, val in sol.items():
                        test = check_assumptions(val, **symb.assumptions0)
                        if test:
                            continue
                        if test is False:
                            break
                        a_None = True
                    else:
                        no_False.append(sol)
                        if a_None:
                            got_None.append(sol)
            else:  # list of expressions
                for sol in solution:
                    test = check_assumptions(sol, **symbols[0].assumptions0)
                    if test is False:
                        continue
                    no_False.append(sol)
                    if test is None:
                        got_None.append(sol)

        elif type(solution) is dict:
            a_None = False
            for symb, val in solution.items():
                test = check_assumptions(val, **symb.assumptions0)
                if test:
                    continue
                if test is False:
                    no_False = None
                    break
                a_None = True
            else:
                no_False = solution
                if a_None:
                    got_None.append(solution)

        elif isinstance(solution, (Relational, And, Or)):
            assert len(symbols) == 1
            if warning and symbols[0].assumptions0:
                warnings.warn(filldedent("""
                    \tWarning: assumptions about variable '%s' are
                    not handled currently.""" % symbols[0]))
            # TODO: check also variable assumptions for inequalities

        else:
            raise TypeError('Unrecognized solution')  # improve the checker

        solution = no_False
        if warning and got_None:
            warnings.warn(filldedent("""
                \tWarning: assumptions concerning following solution(s)
                can't be checked:""" + '\n\t' +
                ', '.join(str(s) for s in got_None)))

    #
    # done
    ###########################################################################

    as_dict = flags.get('dict', False)
    as_set = flags.get('set', False)

    if not as_set and isinstance(solution, list):
        # Make sure that a list of solutions is ordered in a canonical way.
        solution.sort(key=default_sort_key)

    if not as_dict and not as_set:
        return solution or []

    # return a list of mappings or []
    if not solution:
        solution = []
    else:
        if isinstance(solution, dict):
            solution = [solution]
        elif iterable(solution[0]):
            solution = [dict(list(zip(symbols, s))) for s in solution]
        elif isinstance(solution[0], dict):
            pass
        else:
            assert len(symbols) == 1
            solution = [{symbols[0]: s} for s in solution]
    if as_dict:
        return solution
    assert as_set
    if not solution:
        return [], set()
    k = sorted(list(solution[0].keys()), key=lambda i: i.sort_key())
    return k, set([tuple([s[ki] for ki in k]) for s in solution])

########NEW FILE########
__FILENAME__ = test_cli
import sys
import shutil
import os.path
import tempfile
from radon.cli import cc, mi, raw
from radon.tools import iter_filenames
from paramunittest import *
try:
    import StringIO
except ImportError:
    import io as StringIO


RADON_DIR = os.path.dirname(os.path.dirname(__file__))
TEST_DIR = os.path.join(RADON_DIR, 'tests', 'testpkg')
REAL_STDOUT = sys.stdout


def patch_stdout():
    sys.stdout = StringIO.StringIO()


def restore_stdout():
    sys.stdout = REAL_STDOUT


@parametrized((cc,), (mi,), (raw,))
class TestGeneralCommands(ParametrizedTestCase):

    def setUp(self):
        patch_stdout()

    def tearDown(self):
        restore_stdout()

    def setParameters(self, command):
        self.command = command

    def testItWorks(self):
        self.assertTrue(self.command(RADON_DIR) is None)

    def testIterFilenames(self):
        tmpdir = tempfile.mkdtemp()
        try:
            os.makedirs(os.path.join(tmpdir, 'd1'))
            f1 = os.path.join(tmpdir, 'd1', 't1.py')
            open(f1, 'w').close()
            f2 = os.path.join(tmpdir, 'd1', 't2.py')
            open(f2, 'w').close()
            os.makedirs(os.path.join(tmpdir, 'd2'))
            f3 = os.path.join(tmpdir, 'd2', 't3.py')
            open(f3, 'w').close()
            f4 = os.path.join(tmpdir, 'd2', 't4.py')
            open(f4, 'w').close()

            dir1 = [os.path.join(tmpdir, 'd1')]
            dir12 = [os.path.join(tmpdir, 'd1'), os.path.join(tmpdir, 'd2')]
            dirall = [tmpdir]

            # Test without excludes
            exclude = ''
            names = iter_filenames(dirall, exclude)
            self.assertEqual(set(names), set([f1, f2, f3, f4]))
            names = iter_filenames(dir12, exclude)
            self.assertEqual(set(names), set([f1, f2, f3, f4]))
            names = iter_filenames(dir1, exclude)
            self.assertEqual(set(names), set([f1, f2]))

            # Test with one exclude
            exclude = '*/t2.py'
            names = iter_filenames(dirall, exclude)
            self.assertEqual(set(names), set([f1, f3, f4]))
            names = iter_filenames(dir12, exclude)
            self.assertEqual(set(names), set([f1, f3, f4]))
            names = iter_filenames(dir1, exclude)
            self.assertEqual(set(names), set([f1]))

            # Test with two excludes
            exclude = '*/t2.py,*/d2/*'
            names = iter_filenames(dirall, exclude)
            self.assertEqual(set(names), set([f1]))
            names = iter_filenames(dir12, exclude)
            self.assertEqual(set(names), set([f1]))
            names = iter_filenames(dir1, exclude)
            self.assertEqual(set(names), set([f1]))
        finally:
            shutil.rmtree(tmpdir)


args = []
for letter in 'ABCDEF':
    args.extend([dict(min=letter), dict(min=letter.lower()),
                 dict(max=letter), dict(max=letter.lower())])
for arg in args[:]:
    arg2 = arg.copy()
    arg2['show_complexity'] = True
    arg2['no_assert'] = True
    arg2['average'] = True
    arg3 = arg2.copy()
    arg3['json'] = True
    args.extend([arg2, arg3])

for pattern in ['*/tests', '.dir']:
    args.append(dict(ignore=pattern))
for pattern in ['*/tests/*', '*/secondary.py']:
    args.append(dict(exclude=pattern))


@parametrized(
    {},
    *args
)
class TestCCCommand(ParametrizedTestCase):

    def setUp(self):
        patch_stdout()

    def tearDown(self):
        restore_stdout()

    def setParameters(self, **params):
        self.params = params

    def testCall(self):
        cc(TEST_DIR, **self.params)

########NEW FILE########
__FILENAME__ = test_complexity_utils
import operator
from paramunittest import *
from radon.complexity import *
from radon.visitors import Class, Function
from .test_complexity_visitor import GENERAL_CASES, dedent


get_index = lambda seq: lambda index: seq[index]


def _compute_cc_rank(score):
    # This is really ugly
    # Luckily the rank function in radon.complexity is not like this!
    if score < 0:
        rank = ValueError
    elif 0 <= score <= 5:
        rank = 'A'
    elif 6 <= score <= 10:
        rank = 'B'
    elif 11 <= score <= 20:
        rank = 'C'
    elif 21 <= score <= 30:
        rank = 'D'
    elif 31 <= score <= 40:
        rank = 'E'
    else:
        rank = 'F'
    return rank


RANK_CASES = [(score, _compute_cc_rank(score)) for score in range(-1, 100)]


@parametrized(*RANK_CASES)
class TestRank(ParametrizedTestCase):

    def setParameters(self, score, expected_rank):
        self.score = score
        self.expected_rank = expected_rank

    def testRank(self):
        if (hasattr(self.expected_rank, '__call__') and
            isinstance(self.expected_rank(), Exception)):
            self.assertRaises(self.expected_rank, cc_rank, self.score)
        else:
            self.assertEqual(cc_rank(self.score), self.expected_rank)


fun = lambda complexity: Function('randomname', 1, 4, 23, False, None, [], complexity)
cls = lambda complexity: Class('randomname_', 3, 21, 18, [], complexity)

# This works with both the next two tests
SIMPLE_BLOCKS = [
    ([], [], 0.),
    ([fun(12), fun(14), fun(1)], [1, 0, 2], 9.),
    ([fun(4), cls(5), fun(2), cls(21)], [3, 1, 0, 2], 8.),
]


@parametrized(*SIMPLE_BLOCKS)
class TestSortedResults(ParametrizedTestCase):

    def setParameters(self, blocks, indices, _):
        self.blocks = blocks
        self.expected_result = list(map(get_index(blocks), indices))

    def testSortedResults(self):
        self.assertEqual(sorted_results(self.blocks), self.expected_result)


@parametrized(*SIMPLE_BLOCKS)
class TestAverageComplexity(ParametrizedTestCase):

    def setParameters(self, blocks, _, expected_average):
        self.blocks = blocks
        self.expected_average = expected_average

    def testAverageComplexity(self):
        self.assertEqual(average_complexity(self.blocks),
                         self.expected_average)


CC_VISIT_CASES = [
    (GENERAL_CASES[0][0], 1),
    (GENERAL_CASES[1][0], 3),
]


@parametrized(*CC_VISIT_CASES)
class TestCCVisit(ParametrizedTestCase):

    def setParameters(self, code, blocks):
        self.code = dedent(code)
        self.number_of_blocks = blocks

    def testCCVisit(self):
        results = cc_visit(self.code)
        self.assertTrue(isinstance(results, list))
        self.assertEqual(len(results), self.number_of_blocks)

########NEW FILE########
__FILENAME__ = test_complexity_visitor
import sys
import textwrap
try:
    import unittest2 as unittest
except ImportError:
    import unittest
from paramunittest import *
from radon.visitors import *


dedent = lambda code: textwrap.dedent(code).strip()


SIMPLE_BLOCKS = [
    ('''
     if a: pass
     ''', 2),

    ('''
     if a: pass
     else: pass
     ''', 2),

    ('''
     if a: pass
     elif b: pass
     ''', 3),

    ('''
     if a: pass
     elif b: pass
     else: pass
     ''', 3),

    ('''
    if a and b: pass
    ''', 3),

    ('''
    if a and b: pass
    else: pass
    ''', 3),

    ('''
     if a and b: pass
     elif c and d: pass
     else: pass
     ''', 5),

    ('''
     if a and b or c and d: pass
     else: pass
     ''', 5),

    ('''
     if a and b or c: pass
     else: pass
     ''', 4),

    ('''
     for x in range(10): print(x)
     ''', 2),

    ('''
     for x in xrange(10): print(x)
     else: pass
     ''', 3),

    ('''
     while a < 4: pass
     ''', 2),

    ('''
     while a < 4: pass
     else: pass
     ''', 3),

    ('''
     while a < 4 and b < 42: pass
     ''', 3),

    ('''
     while a and b or c < 10: pass
     else: pass
     ''', 5),

    ('''
     with open('raw.py') as fobj: print(fobj.read())
     ''', 2),

    ('''
     [i for i in range(4)]
     ''', 2),

    ('''
     [i for i in range(4) if i&1]
     ''', 3),

    ('''
     (i for i in range(4))
     ''', 2),

    ('''
     (i for i in range(4) if i&1)
     ''', 3),

    ('''
     [i for i in range(42) if sum(k ** 2 for k in divisors(i)) & 1]
     ''', 4),

    ('''
     try: raise TypeError
     except TypeError: pass
     ''', 2),

    ('''
     try: raise TypeError
     except TypeError: pass
     else: pass
     ''', 3),

    ('''
     try: raise TypeError
     finally: pass
     ''', 1),

    ('''
     try: raise TypeError
     except TypeError: pass
     finally: pass
     ''', 2),

    ('''
     try: raise TypeError
     except TypeError: pass
     else: pass
     finally: pass
     ''', 3),

    ('''
     k = lambda a, b: k(b, a)
     ''', 2),

    ('''
     v = a if b else c
     ''', 2),

    ('''
     v = a if sum(i for i in xrange(c)) < 10 else c
     ''', 3),

    ('''
     sum(i for i in range(12) for z in range(i ** 2) if i * z & 1)
     ''', 4),

    ('''
     sum(i for i in range(10) if i >= 2 and val and val2 or val3)
     ''', 6),

    ('''
     for i in range(10):
         print(i)
     else:
         print('wah')
         print('really not found')
         print(3)
     ''', 3),

    ('''
     while True:
         print(1)
     else:
         print(2)
         print(1)
         print(0)
         print(-1)
     ''', 3),

    ('''
     assert i < 0
     ''', 2),

    ('''
     assert i < 0, "Fail"
     ''', 2),

    ('''
     assert i < 0
     ''', 1, {'no_assert': True}),
]


# These run only if Python version is >= 2.7
ADDITIONAL_BLOCKS = [
    ('''
     {i for i in range(4)}
     ''', 2),

    ('''
     {i for i in range(4) if i&1}
     ''', 3),

    ('''
     {i:i**4 for i in range(4)}
     ''', 2),

    ('''
     {i:i**4 for i in range(4) if i&1}
     ''', 3),
]

BLOCKS = SIMPLE_BLOCKS[:]
if sys.version_info[:2] >= (2, 7):
    BLOCKS.extend(ADDITIONAL_BLOCKS)

@parametrized(*BLOCKS)
class TestBlocks(ParametrizedTestCase):
    '''Test blocks.'''

    def setParameters(self, code, expected_complexity, kwargs={}):
        self.code = dedent(code)
        self.expected_complexity = expected_complexity
        self.kwargs = kwargs

    def testComplexityVisitor(self):
        visitor = ComplexityVisitor.from_code(self.code, **self.kwargs)
        self.assertEqual(visitor.complexity, self.expected_complexity)



SINGLE_FUNCTIONS_CASES = [
    ('''
     def f(a, b, c):
        if a and b == 4:
            return c ** c
        elif a and not c:
            return sum(i for i in range(41) if i&1)
        return a + b
     ''', (1, 7)),

    ('''
     if a and not b: pass
     elif b or c: pass
     else: pass

     for i in range(4):
        print(i)

     def g(a, b):
        while a < b:
            b, a = a **2, b ** 2
        return b
     ''', (6, 2)),

    ('''
     def f(a, b):
        while a**b:
            a, b = b, a * (b - 1)
            if a and b:
                b = 0
            else:
                b = 1
        return sum(i for i in range(b))
     ''', (1, 5)),
]


@parametrized(*SINGLE_FUNCTIONS_CASES)
class TestSingleFunctions(ParametrizedTestCase):

    def setParameters(self, code, expected_complexity):
        self.code = dedent(code)
        self.expected_complexity = expected_complexity

    def testComplexityVisitor(self):
        visitor = ComplexityVisitor.from_code(self.code)
        self.assertEqual(len(visitor.functions), 1)
        self.assertEqual((visitor.complexity, visitor.functions[0].complexity),
                         self.expected_complexity)


FUNCTIONS_CASES = [
    ('''
     def f(a, b):
        return a if b else 2

     def g(a, b, c):
        if a and b:
            return a / b + b / a
        elif b and c:
            return b / c - c / b
        return a + b + c

     def h(a, b):
        return 2 * (a + b)
     ''', (2, 5, 1)),

    ('''
     def f(p, q):
        while p:
            p, q = q, p - q
        if q < 1:
            return 1 / q ** 2
        elif q > 100:
            return 1 / q ** .5
        return 42 if not q else p

     def g(a, b, c):
        if a and b or a - b:
            return a / b - c
        elif b or c:
            return 1
        else:
            k = 0
            with open('results.txt', 'w') as fobj:
                for i in range(b ** c):
                    k += sum(1 / j for j in range(i ** 2) if j > 2)
                fobj.write(str(k))
            return k - 1
     ''', (5, 10)),
]


@parametrized(*FUNCTIONS_CASES)
class TestFunctions(ParametrizedTestCase):

    def setParameters(self, code, expected_complexity):
        self.code = dedent(code)
        self.expected_complexity = expected_complexity

    def testComplexityVisitor(self):
        visitor = ComplexityVisitor.from_code(self.code)
        self.assertEqual(len(visitor.functions), len(self.expected_complexity))
        self.assertEqual(tuple(map(GET_COMPLEXITY, visitor.functions)),
                         self.expected_complexity)


CLASSES_CASES = [
    ('''
     class A(object):

         def m(self, a, b):
             if not a or b:
                 return b - 1
             try:
                 return a / b
             except ZeroDivisionError:
                 return a

         def n(self, k):
             while self.m(k) < k:
                 k -= self.m(k ** 2 - min(self.m(j) for j in range(k ** 4)))
             return k
     ''', (6, 4, 3)),

    ('''
     class B(object):

         ATTR = 9 if A().n(9) == 9 else 10
         import sys
         if sys.version_info >= (3, 3):
             import os
             AT = os.openat('/random/loc')

         def __iter__(self):
             return __import__('itertools').tee(B.__dict__)

         def test(self, func):
             a = func(self.ATTR, self.AT)
             if a < self.ATTR:
                 yield self
             elif a > self.ATTR ** 2:
                 yield self.__iter__()
             yield iter(a)
     ''', (5, 1, 3)),
]


@parametrized(*CLASSES_CASES)
class TestClasses(ParametrizedTestCase):

    def setParameters(self, code, expected_complexity):
        self.code = dedent(code)
        self.total_class_complexity = expected_complexity[0]
        self.methods_complexity = expected_complexity[1:]

    def testComplexityVisitor(self):
        visitor = ComplexityVisitor.from_code(self.code)
        self.assertEqual(len(visitor.classes), 1)
        self.assertEqual(len(visitor.functions), 0)
        cls = visitor.classes[0]
        self.assertEqual(cls.real_complexity, self.total_class_complexity)
        self.assertEqual(tuple(map(GET_COMPLEXITY, cls.methods)),
                         self.methods_complexity)


GENERAL_CASES = [
    ('''
     if a and b:
         print
     else:
         print
     a = sum(i for i in range(1000) if i % 3 == 0 and i % 5 == 0)

     def f(n):
         if n == 0:
             return 1
         elif n == 1:
             return n
         elif n < 5:
             return (n - 1) ** 2
         return n * pow(n, f(n - 1), n - 3)
     ''', (6, 3, 0, 9)),

    ('''
     try:
         1 / 0
     except ZeroDivisonError:
         print
     except TypeError:
         pass

     class J(object):

         def aux(self, w):
             if w == 0:
                 return 0
             return w - 1 + sum(self.aux(w - 3 - i) for i in range(2))

     def f(a, b):
         if a < b:
             b, a = a, b
         return a, b
     ''', (3, 1, 2, 6)),
]


@parametrized(*GENERAL_CASES)
class TestModules(ParametrizedTestCase):

    def setParameters(self, code, expected_complexity):
        self.code = dedent(code)
        self.module_complexity, self.functions_complexity, \
            self.classes_complexity, \
            self.total_complexity = expected_complexity

    def testModule(self):
        visitor = ComplexityVisitor.from_code(self.code)
        self.assertEqual(visitor.complexity, self.module_complexity)
        self.assertEqual(visitor.functions_complexity,
                         self.functions_complexity)
        self.assertEqual(visitor.classes_complexity, self.classes_complexity)
        self.assertEqual(visitor.total_complexity, self.total_complexity)


CLOJURES_CASES = [
    ('''
     def f(n):
         def g(l):
             return l ** 4
         def h(i):
             return i ** 5 + 1 if i & 1 else 2
         return sum(g(u + 4) / float(h(u)) for u in range(2, n))
     ''', ('g', 'h'), (1, 2, 3)),

    ('''
     # will it work? :D
     def memoize(func):
         cache = {}
         def aux(*args, **kwargs):
             key = (args, kwargs)
             if key in cache:
                 return cache[key]
             cache[key] = res = func(*args, **kwargs)
             return res
         return aux
     ''', ('aux',), (2, 2)),
]


@parametrized(*CLOJURES_CASES)
class TestClojures(ParametrizedTestCase):

    def setParameters(self, code, clojure_names, expected_cc):
        self.visitor = ComplexityVisitor.from_code(dedent(code))
        self.func = self.visitor.functions[0]
        self.clojure_names = clojure_names
        self.expected_cj_cc = expected_cc[:-1]
        self.expected_total_cc = expected_cc[-1]

    def testOneFunction(self):
        self.assertEqual(len(self.visitor.functions), 1)

    def testClojureNames(self):
        names = tuple(cj.name for cj in self.func.clojures)
        self.assertEqual(names, self.clojure_names)

    def testClojuresComplexity(self):
        cj_complexity = tuple(cj.complexity for cj in self.func.clojures)
        self.assertEqual(cj_complexity, self.expected_cj_cc)

    def testTotalComplexity(self):
        self.assertEqual(self.func.complexity, self.expected_total_cc)


CONTAINERS_CASES = [
    (('func', 12, 0, 18, False, None, [], 5),
     ('F', 'func', 'F 12:0->18 func - 5')),

    (('meth', 12, 0, 21, True, 'cls', [], 5),
     ('M', 'cls.meth', 'M 12:0->21 cls.meth - 5')),

    (('cls', 12, 0, 15, [], 5),
     ('C', 'cls', 'C 12:0->15 cls - 5')),

    (('cls', 12, 0, 19, [object, object, object, object], 30),
     ('C', 'cls', 'C 12:0->19 cls - 8')),
]


@parametrized(*CONTAINERS_CASES)
class TestContainers(ParametrizedTestCase):

    def setParameters(self, values, expected):
        self.values = values
        self.expected_letter = expected[0]
        self.expected_name = expected[1]
        self.expected_str = expected[2]

    def testContainers(self):
        cls = Function if len(self.values) == 8 else Class
        obj = cls(*self.values)
        self.assertEqual(obj.letter, self.expected_letter)
        self.assertEqual(obj.fullname, self.expected_name)
        self.assertEqual(str(obj), self.expected_str)


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = test_halstead
import textwrap
from paramunittest import *
from radon.visitors import HalsteadVisitor


dedent = lambda code: textwrap.dedent(code).strip()


SIMPLE_BLOCKS = [
    ('''
     if a and b: pass
     ''', (1, 2, 1, 2)),

    ('''
     if a and b: pass
     elif b or c: pass
     ''', (2, 4, 2, 3)),

    ('''
     if a and b: pass
     elif b and c: pass
     ''', (2, 4, 1, 3)),

    ('''
     a = b * c
     ''', (1, 2, 1, 2)),

    ('''
     b = -x
     ''', (1, 1, 1, 1)),

    ('''
     a = -x
     c = -x
     ''', (2, 2, 1, 1)),

    ('''
     a = -x
     b = +x
     ''', (2, 2, 2, 1)),

    ('''
     a += 3
     b += 4
     c *= 3
     ''', (3, 6, 2, 5)),

    ('''
     a = 2
     b = 3
     a *= b

     def f():
         b = 2
         b += 4
     ''', (2, 4, 2, 4)),

    ('''
     a = b < 4
     c = i <= 45 >= d
     k = 4 < 2
     ''', (4, 7, 3, 6)),
]


@parametrized(*SIMPLE_BLOCKS)
class TestHalsteadVisitor(ParametrizedTestCase):

    def setParameters(self, code, expected_result):
        self.code = dedent(code)
        self.expected_result = expected_result

    def testHalsteadVisitor(self):
        visitor = HalsteadVisitor.from_code(self.code)
        result = visitor.operators, visitor.operands, \
            visitor.distinct_operators, visitor.distinct_operands
        self.assertEqual(result, self.expected_result)


if __name__ == '__main__':
    import unittest
    unittest.main()

########NEW FILE########
__FILENAME__ = test_other_metrics
import textwrap
from paramunittest import *
from radon.metrics import *


dedent = lambda code: textwrap.dedent(code).strip()

def _compute_mi_rank(score):
    if 0 <= score < 10:
        res = 'C'
    elif 10 <= score < 20:
        res = 'B'
    elif 20 <= score <= 100:
        res = 'A'
    else:
        raise ValueError(score)
    return res


MI_COMPUTE_CASES = [
    ((0, 0, 0, 0), 100.),
    ((0, 1, 2, 0), 100.),
    ((10, 2, 5, .5), 81.75051711476864),
    ((200, 10, 78, 45), 70.0321877686122),
]


@parametrized(*MI_COMPUTE_CASES)
class TestComputeMI(ParametrizedTestCase):

    def setParameters(self, values, expected):
        self.values = values
        self.expected = expected

    def testComputeMI(self):
        self.assertAlmostEqual(mi_compute(*self.values), self.expected)


MI_RANK_CASES = [(score, _compute_mi_rank(score)) for score in range(0, 100)]


@parametrized(*MI_RANK_CASES)
class TestMIRank(ParametrizedTestCase):

    def setParameters(self, score, expected_rank):
        self.score = score
        self.expected_rank = expected_rank

    def testRank(self):
        self.assertEqual(mi_rank(self.score), self.expected_rank)


H_VISIT_CASES = [
    ('''
     ''', (0,) * 12),

    ('''
     a = b + c
     d = c - f

     def f(b):
         a = 2 - 4
         d = a + b
         return a ** d
     ''', (3, 8, 5, 10, 11, 15, 28.75488750216347, 51.89147427955947,
           1.875, 97.296514274174, 5.405361904120777, 0.01729715809318649)),
]


@parametrized(*H_VISIT_CASES)
class TestHVisit(ParametrizedTestCase):

    def setParameters(self, code, expected):
        self.code = dedent(code)
        self.expected = expected

    def testHVisit(self):
        self.assertEqual(h_visit(self.code), self.expected)


first_mi = '''
     def f(a, b, c):
         return (a ** b) % c

     k = f(1, 2, 3)
     print(k ** 2 - 1)
'''

second_mi = '''
     class A(object):

         def __init__(self, n):
             # this is awesome
             self.n = sum(i for i in range(n) if i&1)

         def m(self, j):
             """Just compute it.
             Example.
             """
             if j > 421:
                 return (self.n + 2) ** j
             return (self.n - 2) ** j

     a = A(4)
     a.m(42)  # i don't know why, but it works
'''

MI_VISIT_CASES = [
    ('''
     ''', 100., True),

    ('''
     ''', 100., False),

    # V = 41.51317942364757
    # CC = 1
    # LLOC = 4
    # CM % = 0
    (first_mi, 75.40162245189028, True),
    (first_mi, 75.40162245189028, False),

    # V = 66.60791492653966
    # CC = 4
    # LLOC = 10
    # CM % = 38.46153846153847
    (second_mi, 92.93379997479954, True),

    # CM % = 15.384615384615385
    (second_mi, 86.11274278663237, False),
]


@parametrized(*MI_VISIT_CASES)
class TestMIVisit(ParametrizedTestCase):

    def setParameters(self, code, expected, count_multi):
        self.code = dedent(code)
        self.expected = expected
        self.count_multi = count_multi

    def testMIParameters(self):
        self.assertEqual(mi_visit(self.code, self.count_multi), self.expected)


if __name__ == '__main__':
    import unittest
    unittest.main()

########NEW FILE########
__FILENAME__ = test_raw
import textwrap
from paramunittest import *
from radon.raw import *


dedent = lambda code: textwrap.dedent(code).strip()


FIND_CASES = [
    ('''
     return 0
     ''', None),

    ('''
     # most useless comment :
     ''', None),

    ('''
     if a: pass
     ''', 2),

    ('''
     # useless comment
     if a: pass
     ''', 4),

    ('''
     d[3:]
     ''', 3),
]


@parametrized(*FIND_CASES)
class TestFind(ParametrizedTestCase):

    def setParameters(self, code, result):
        self.code = _generate(dedent(code))
        self.result = result

    def testFind(self):
        if self.result is None:
            self.assertRaises(ValueError, _find, self.code, OP, ':')
        else:
            self.assertEqual(_find(self.code, OP, ':'), self.result)


LOGICAL_LINES_CASES = [
    ('''
     ''', 0),

    ('''
     # most useless comment
     ''', 0),

    ('''
     a * b + c
     ''', 1),

    ('''
     if a:
     ''', 1),

    ('''
     try:
     ''', 1),

    ('''
     if a:  # just a comment
     ''', 1),

    ('''
     try:  # just a comment
     ''', 1),

    ('''
     if a: pass
     ''', 2),

    ('''
     if a: continue
     ''', 2),

    ('''
     if a: break
     ''', 2),

    ('''
     if a: return
     ''', 2),

    ('''
     if a: pass  # just a comment
     ''', 2),

    ('''
     if a: continue  # just a comment
     ''', 2),

    ('''
     if a: break  # just a comment
     ''', 2),

    ('''
     if a: return  # just a comment
     ''', 2),

    ('''
     42 # a comment
     ''', 1),

    ('''
     """
     multiple
     """
     ''', 1),

    ('''
     # just a comment
     ''', 0),

    ('''
     a = 2; b = 43
     ''', 2),

    ('''
     a = 1; b = 2;
     ''', 2),
]


@parametrized(*LOGICAL_LINES_CASES)
class TestLogicalLines(ParametrizedTestCase):

    def setParameters(self, code, expected_number_of_lines):
        self.code = _generate(dedent(code))
        self.expected_number_of_lines = expected_number_of_lines

    def testLogical(self):
        self.assertEqual(_logical(self.code), self.expected_number_of_lines)


ANALYZE_CASES = [
    ('''
     ''', (0, 0, 0, 0, 0, 0)),

    ('''
     """
     doc?
     """
     ''', (3, 1, 3, 0, 3, 0)),

    ('''
     # just a comment
     if a and b:
         print('woah')
     else:
         # you'll never get here
         print('ven')
     ''', (6, 4, 6, 2, 0, 0)),

    ('''
     #
     #
     #
     ''', (3, 0, 3, 3, 0, 0)),

    ('''
     if a:
         print


     else:
         print
     ''', (6, 4, 4, 0, 0, 2)),

    # In this case the docstring is not counted as a multi-line string
    # because in fact it is on one line!
    ('''
     def f(n):
         """here"""
         return n * f(n - 1)
     ''', (3, 3, 3, 0, 0, 0)),

    ('''
     def hip(a, k):
         if k == 1: return a
         # getting high...
         return a ** hip(a, k - 1)

     def fib(n):
         """Compute the n-th Fibonacci number.

         Try it with n = 294942: it will take a fairly long time.
         """
         if n <= 1: return 1  # otherwise it will melt the cpu
         return fib(n - 2) + fib(n - 1)
     ''', (12, 9, 11, 2, 4, 1)),

    ('''
     a = [1, 2, 3,
     ''', SyntaxError),
]


@parametrized(*ANALYZE_CASES)
class TestAnalyze(ParametrizedTestCase):

    def setParameters(self, code, expected):
        self.code = dedent(code)
        self.expected = expected

    def testAnalyze(self):
        try:
            len(self.expected)
        except:
            self.assertRaises(self.expected, analyze, self.code)
        else:
            result = analyze(self.code)
            self.assertEqual(result, self.expected)
            # blank + sloc = loc
            self.assertTrue(result[0] == result[2] + result[5])


if __name__ == '__main__':
    import unittest
    unittest.main()

########NEW FILE########
