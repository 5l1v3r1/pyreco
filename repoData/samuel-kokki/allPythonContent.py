__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# kokki documentation build configuration file, created by
# sphinx-quickstart on Mon Jul 27 14:30:15 2009.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.append(os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.todo']
try:
    from github.tools import sphinx
except ImportError:
    pass
else:
    extensions.append('github.tools.sphinx')

# August 9, 2010 -- ss turn on Todo items in built doc
todo_include_todos = True

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'kokki'
copyright = u'2009, Samuel Stauffer'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
execfile(os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'kokki', 'version.py'))
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
#unused_docs = []

# List of directories, relative to source directory, that shouldn't be searched
# for source files.
exclude_trees = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  Major themes that come with
# Sphinx are currently 'default' and 'sphinxdoc'.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = [] # ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_use_modindex = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = ''

# Output file base name for HTML help builder.
htmlhelp_basename = 'kokkidoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'kokki.tex', u'Kokki Documentation',
   u'Samuel Stauffer', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_use_modindex = True

########NEW FILE########
__FILENAME__ = base
#!/usr/bin/env python

__all__ = ["Resource", "ResourceArgument", "ForcedListArgument", "BooleanArgument"]

import logging
from kokki.environment import Environment
from kokki.exceptions import Fail, InvalidArgument

class ResourceArgument(object):
    def __init__(self, default=None, required=False, allow_override=False):
        self.required = False # Prevents the initial validate from failing
        if hasattr(default, '__call__'):
            self.default = default
        else:
            self.default = self.validate(default)
        self.required = required
        self.allow_override = allow_override

    def validate(self, value):
        if self.required and value is None:
            raise InvalidArgument("Required argument %s missing" % self.name)
        return value

class ForcedListArgument(ResourceArgument):
    def validate(self, value):
        value = super(ForcedListArgument, self).validate(value)
        if not isinstance(value, (tuple, list)):
            value = [value]
        return value

class BooleanArgument(ResourceArgument):
    def validate(self, value):
        value = super(BooleanArgument, self).validate(value)
        if not value in (True, False):
            raise InvalidArgument("Expected a boolean for %s received %r" % (self.name, value))
        return value

class Accessor(object):
    def __init__(self, name):
        self.name = name

    def __get__(self, obj, cls):
        try:
            return obj.arguments[self.name]
        except KeyError:
            val = obj._arguments[self.name].default
            if hasattr(val, '__call__'):
                val = val(obj)
            return val

    def __set__(self, obj, value):
        obj.arguments[self.name] = obj._arguments[self.name].validate(value)

class ResourceMetaclass(type):
    # def __new__(cls, name, bases, attrs):
    #     super_new = super(ResourceMetaclass, cls).__new__
    #     return super_new(cls, name, bases, attrs)

    def __init__(mcs, _name, bases, attrs):
        mcs._arguments = getattr(bases[0], '_arguments', {}).copy()
        for key, value in list(attrs.items()):
            if isinstance(value, ResourceArgument):
                value.name = key
                mcs._arguments[key] = value
                setattr(mcs, key, Accessor(key))

class Resource(object):
    __metaclass__ = ResourceMetaclass

    is_updated = False

    action = ForcedListArgument(default="nothing")
    ignore_failures = BooleanArgument(default=False)
    notifies = ResourceArgument(default=[])
    subscribes = ResourceArgument(default=[])
    not_if = ResourceArgument()
    only_if = ResourceArgument()

    actions = ["nothing"]

    def __new__(cls, name, env=None, provider=None, **kwargs):
        env = env or Environment.get_instance()
        provider = provider or getattr(cls, 'provider', None)

        r_type = cls.__name__
        if r_type not in env.resources:
            env.resources[r_type] = {}
        if name not in env.resources[r_type]:
            obj = super(Resource, cls).__new__(cls)
            env.resources[r_type][name] = obj
            env.resource_list.append(obj)
            return obj

        obj = env.resources[r_type][name]
        if obj.provider != provider:
            raise Fail("Duplicate resource %r with a different provider %r != %r" % (obj, provider, obj.provider))

        obj.override(**kwargs)
        return obj

    def __init__(self, name, env=None, provider=None, **kwargs):
        if hasattr(self, 'name'):
            return

        self.name = name
        self.env = env or Environment.get_instance()
        self.provider = provider or getattr(self, 'provider', None)
        self.log = logging.getLogger("kokki.resource")

        self.arguments = {}
        for key, value in kwargs.items():
            try:
                arg = self._arguments[key]
            except KeyError:
                raise Fail("%s received unsupported argument %s" % (self, key))
            else:
                try:
                    self.arguments[key] = arg.validate(value)
                except InvalidArgument, exc:
                    raise InvalidArgument("%s %s" % (self, exc))

        self.log.debug("New resource %s: %s" % (self, self.arguments))
        self.subscriptions = {'immediate': set(), 'delayed': set()}

        for sub in self.subscribes:
            if len(sub) == 2:
                action, res = sub
                immediate = False
            else:
                action, res, immediate = sub

            res.subscribe(action, self, immediate)

        for sub in self.notifies:
            self.subscribe(*sub)

        self.validate()

    def validate(self):
        pass

    def subscribe(self, action, resource, immediate=False):
        imm = "immediate" if immediate else "delayed"
        sub = (action, resource)
        self.subscriptions[imm].add(sub)

    def updated(self):
        self.is_updated = True

    def override(self, **kwargs):
        for key, value in kwargs.items():
            try:
                arg = self._arguments[key]
            except KeyError:
                raise Fail("%s received unsupported argument %s" % (self, key))
            else:
                if value != self.arguments.get(key):
                    if not arg.allow_override:
                        raise Fail("%s doesn't allow overriding argument '%s'" % (self, key))

                    try:
                        self.arguments[key] = arg.validate(value)
                    except InvalidArgument, exc:
                        raise InvalidArgument("%s %s" % (self, exc))
        self.validate()

    def __repr__(self):
        return "%s['%s']" % (self.__class__.__name__, self.name)

    def __unicode__(self):
        return u"%s['%s']" % (self.__class__.__name__, self.name)

    def __getstate__(self):
        return dict(
            name = self.name,
            provider = self.provider,
            arguments = self.arguments,
            subscriptions = self.subscriptions,
            subscribes = self.subscribes,
            notifies = self.notifies,
            env = self.env,
        )

    def __setstate__(self, state):
        self.name = state['name']
        self.provider = state['provider']
        self.arguments = state['arguments']
        self.subscriptions = state['subscriptions']
        self.subscribes = state['subscribes']
        self.notifies = state['notifies']
        self.env = state['env']

        self.log = logging.getLogger("kokki.resource")

        self.validate()

########NEW FILE########
__FILENAME__ = command

import logging
import os
import sys
from optparse import OptionParser

from kokki.kitchen import Kitchen

def build_parser():
    parser = OptionParser(usage="Usage: %prog [options] <command> ...")
    parser.add_option("-f", "--file", dest="filename",
        help="Look for the command in FILE", metavar="FILE", default="kitchen.py")
    parser.add_option("-l", "--load", dest="config",
        help="Load dumped kitchen from FILE", metavar="FILE", default=None)
    parser.add_option("-d", "--dump", dest="dump",
        help = "Dump a serialized representation of what would be run"
               " to FILE (default to YAML, can specify <format>:<filename>"
               " e.g. pickle:kitchen.dump)", metavar="FILE", default=None)
    parser.add_option("-o", "--override", dest="overrides", help="Config overrides (key=value)", action="append", default=[])
    parser.add_option("-v", "--verbose", dest="verbose", default=False, action="store_true")
    return parser

def main():
    parser = build_parser()
    options, args = parser.parse_args()
    if not args and not options.config:
        parser.error("must specify at least one command")

    logging.basicConfig(level=logging.INFO)
    if options.verbose:
        logger = logging.getLogger('kokki')
        logger.setLevel(logging.DEBUG)

    if options.config:
        if ':' in options.config:
            fmt, filename = options.config.split(':', 1)
        else:
            fmt, filename = "yaml", options.config
        if fmt == "yaml":
            import yaml
            with open(options.config, "rb") as fp:
                kit = yaml.load(fp.read())
        elif fmt == "pickle":
            import cPickle as pickle
            with open(filename, "rb") as fp:
                kit = pickle.load(fp)
    else:
        path = os.path.abspath(options.filename)
        if not os.path.isdir(path):
            path = os.path.dirname(path)
        if path not in sys.path:
            sys.path.insert(0, path)

        if os.path.isdir(options.filename):
            files = [os.path.join(path, f) for f in sorted(os.listdir(path)) if f.endswith('.py')]
        else:
            files = [options.filename]

        globs = {}
        for fname in files:
            globs["__file__"] = os.path.abspath(fname)
            with open(fname, "rb") as fp:
                source = fp.read()
            exec compile(source, fname, 'exec') in globs
        del globs['__file__']

        kit = Kitchen()
        roles = []
        for c in args:
            try:
                roles.append(globs[c])
            except KeyError:
                sys.stderr.write("Function for role '%s' not found in config\n" % c)
                sys.exit(1)
        for r in roles:
            r(kit)
    
    for over in options.overrides:
        name, value = over.split('=', 1)
        try:
            value = int(value)
        except ValueError:
            pass
        kit.update_config({name: value})
    
    if options.dump:
        if ':' in options.dump:
            fmt, filename = options.dump.split(':', 1)
        else:
            fmt, filename = "yaml", options.dump
        if fmt == "yaml":
            import yaml
            if filename == "-":
                print yaml.dump(kit)
            else:
                with open(filename, "wb") as fp:
                    yaml.dump(kit, fp)
        elif fmt == "pickle":
            import cPickle as pickle
            if filename == "-":
                print pickle.dumps(kit)
            else:
                with open(filename, "wb") as fp:
                    pickle.dump(kit, fp, pickle.HIGHEST_PROTOCOL)
        sys.exit(0)

    kit.run()

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = conf

from kokki import Environment, File, Template

def config(name):
    env = Environment.get_instance()

    File("%s/mods-available/%s.conf" % (env.config.apache.dir, name),
        content = Template('apache2/mods/%s.conf.j2' % name),
        notifies = [("restart", env.resources["Service"]["apache2"])])

########NEW FILE########
__FILENAME__ = module

import os
from kokki import Environment, Execute

def module(name, enable=True, conf=False):
    env = Environment.get_instance()

    if conf:
        env.cookbooks.apache2.config(name)

    if enable:
        Execute("a2enmod %s" % name,
            command = "/usr/sbin/a2enmod %s" % name,
            notifies = [("restart", env.resources["Service"]["apache2"])],
            not_if = lambda:os.path.exists("%s/mods-enabled/%s.load" % (env.config.apache.dir, name)))
    else:
        Execute("a2dismod %s" % name,
            command = "/usr/sbin/a2dismod %s" % name,
            notifies = [("restart", env.resources["Service"]["apache2"])],
            only_if = lambda:os.path.exists("%s/mods-enabled/%s.load" % (env.config.apache.dir, name)))

########NEW FILE########
__FILENAME__ = site

import os
from kokki import Environment, Execute

def site(name, enable=True):
    env = Environment.get_instance()

    if enable:
        Execute("a2ensite %s" % name,
            command = "/usr/sbin/a2ensite %s" % name,
            notifies = [("restart", env.resources["Service"]["apache2"])],
            not_if = lambda:os.path.exists("%s/sites-enabled/%s" % (env.config.apache.dir, name)),
            only_if = lambda:os.path.exists("%s/sites-available/%s" % (env.config.apache.dir, name)))
    else:
        Execute("a2dissite %s" % name,
            command = "/usr/sbin/a2dissite %s" % name,
            notifies = [("restart", env.resources["Service"]["apache2"])],
            only_if = lambda:os.path.exists("%s/sites-enabled/%s" % (env.config.apache.dir, name)))

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Apache2 web server"
__config__ = {
    "apache.dir": {
        "description": "Location for Apache configuration",
        "default": None,
    },
    "apache.log_dir": {
        "description": "Location for Apache logs",
        "default": None,
    },
    "apache.pidfile": {
        "description": "Location of apache's pid file",
        "default":None
    },
    "apache.user": {
        "description": "User Apache runs as",
        "default": None,
    },
    "apache.binary": {
        "description": "Apache server daemon program",
        "default": None,
    },
    "apache.icondir": {
        "description": "Directory location for icons",
        "default": None,
    },
    "apache.listen_ports": {
        "description": "Ports that Apache should listen on",
        "default": [80, 443],
    },
    "apache.contact": {
        "description": "Email address of webmaster",
        "default": "ops@example.com",
    },
    "apache.timeout": {
        "description": "Connection timeout value",
        "default": 300,
    },
    "apache.keepalive": {
        "description": "HTTP persistent connections",
        "default": "On",
    },
    "apache.keepaliverequests": {
        "description": "Number of requests allowed on a persistent connection",
        "default": 100,
    },
    "apache.keepalivetimeout": {
        "description": "Time to wait for requests on persistent connection",
        "default": 5,
    },
    "apache.servertokens": {
        "display_name": "Apache Server Tokens",
        "description": "Server response header",
        "default": "Prod",
    },
    "apache.serversignature": {
        "display_name": "Apache Server Signature",
        "description": "Configure footer on server-generated documents",
        "default": "Off",
    },
    "apache.traceenable": {
        "display_name": "Apache Trace Enable",
        "description": "Determine behavior of TRACE requests",
        "default": "Off",
    },
    "apache.allowed_openids": {
        "display_name": "Apache Allowed OpenIDs",
        "description": "Array of OpenIDs allowed to authenticate",
        "default": None,
    },
    "apache.prefork.startservers": {
        "display_name": "Apache Prefork MPM StartServers",
        "description": "Number of MPM servers to start",
        "default": 16,
    },
    "apache.prefork.minspareservers": {
        "display_name": "Apache Prefork MPM MinSpareServers",
        "description": "Minimum number of spare server processes",
        "default": 16,
    },
    "apache.prefork.maxspareservers": {
        "display_name": "Apache Prefork MPM MaxSpareServers",
        "description": "Maximum number of spare server processes",
        "default": 32,
    },
    "apache.prefork.serverlimit": {
        "display_name": "Apache Prefork MPM ServerLimit",
        "description": "Upper limit on configurable server processes",
        "default": 400,
    },
    "apache.prefork.maxclients": {
        "display_name": "Apache Prefork MPM MaxClients",
        "description": "Maximum number of simultaneous connections",
        "default": 400,
    },
    "apache.prefork.maxrequestsperchild": {
        "display_name": "Apache Prefork MPM MaxRequestsPerChild",
        "description": "Maximum number of request a child process will handle",
        "default": 10000,
    },
    "apache.worker.startservers": {
        "display_name": "Apache Worker MPM StartServers",
        "description": "Initial number of server processes to start",
        "default": 4,
    },
    "apache.worker.maxclients": {
        "display_name": "Apache Worker MPM MaxClients",
        "description": "Maximum number of simultaneous connections",
        "default": 1024,
    },
    "apache.worker.minsparethreads": {
        "display_name": "Apache Worker MPM MinSpareThreads",
        "description": "Minimum number of spare worker threads",
        "default": 64,
    },
    "apache.worker.maxsparethreads": {
        "display_name": "Apache Worker MPM MaxSpareThreads",
        "description": "Maximum number of spare worker threads",
        "default": 192,
    },
    "apache.worker.threadsperchild": {
        "display_name": "Apache Worker MPM ThreadsPerChild",
        "description": "Constant number of worker threads in each server process",
        "default": 64,
    },
    "apache.worker.maxrequestsperchild": {
        "display_name": "Apache Worker MPM MaxRequestsPerChild",
        "description": "Maximum number of request a child process will handle",
        "default": 0,
    },
}
def __loader__(kit):
    # Where the various parts of apache are
    if kit.system.platform in ('redhat', 'centos', 'fedora', 'suse'):
        updates = {
            "dir":     "/etc/httpd",
            "log_dir": "/var/log/httpd",
            "user":    "apache",
            "binary":  "/usr/sbin/httpd",
            "icondir": "/var/www/icons/",
        }

        if kit.system.platform == "centos":
            updates['pidfile'] = '/var/run/httpd.pid'
        else:
            updates['pidfile'] = 'logs/httpd.pid'
    else: # env.system.platform in ("debian", "ubuntu"):
        updates = {
            "dir":     "/etc/apache2",
            "log_dir": "/var/log/apache2",
            "user":    "www-data",
            "binary":  "/usr/sbin/apache2",
            "icondir": "/usr/share/apache2/icons",
            "pidfile": "/var/run/apache2.pid"
        }
    for k, v in updates.items():
        if kit.config.apache[k] is None:
            kit.config.apache[k] = v
########NEW FILE########
__FILENAME__ = default

from kokki import Package, Directory, Service, File, StaticFile, Execute, Template

PLATFORM_CONFIGS = dict(
    centos = "httpd",
    redhat = "httpd",
    fedora = "httpd",
    suse = "httpd",
    debian = "apache2",
    ubuntu = "apache2",
)

Package("apache2",
    package_name = "httpd" if env.system.platform in ("centos", "redhat", "fedora", "suse") else "apache2")

Directory(env.config.apache.log_dir, mode = 0700, owner = env.config.apache.user, group = env.config.apache.user)

if env.system.platform in ("centos", "redhat", "fedora", "suse"):
    Service("apache2",
        service_name = "httpd",
        restart_command = "/sbin/service httpd restart && sleep 1",
        reload_command = "/sbin/service httpd reload && sleep 1",
        supports_restart = True,
        supports_reload = True,
        supports_status = True)

    File("/usr/local/bin/apache2_module_conf_generate.pl",
        mode = 0755,
        owner = "root",
        group = "root",
        content = StaticFile("apache2/files/apache2_module_conf_generate.pl"))

    for d in ('sites-available', 'sites-enabled', 'mods-available', 'mods-enabled'):
        Directory("%s/%s" % (env.config.apache.dir, d),
            mode = 0755,
            owner = "root",
            group = "root")

    libdir = "lib64" if env.system.architecture == "x86_64" else "lib"
    Execute("generate-module-list",
        command = "/usr/local/bin/apache2_module_conf_generate.pl /usr/%s/httpd/modules /etc/httpd/mods-available" % libdir)

    # %w{a2ensite a2dissite a2enmod a2dismod}.each do |modscript|
    # template "/usr/sbin/#{modscript}" do
    #   source "#{modscript}.erb"
    #   mode 0755
    #   owner "root"
    #   group "root"
    # end  
    # end
    # 
    # # installed by default on centos/rhel, remove in favour of mods-enabled
    # file "#{node[:apache][:dir]}/conf.d/proxy_ajp.conf" do
    # action :delete
    # backup false
    # end
    # file "#{node[:apache][:dir]}/conf.d/README" do
    # action :delete
    # backup false
    # end
    # 
    # # welcome page moved to the default-site.rb temlate
    # file "#{node[:apache][:dir]}/conf.d/welcome.conf" do
    # action :delete
    # backup false
    # end
else: # debian, ubuntu
    Service("apache2",
        supports_restart = True,
        supports_reload = True,
        supports_status = True)

Directory("%s/ssl" % env.config.apache.dir,
    mode = 0755,
    owner = "root",
    group = "root")

File("apache2.conf",
    path = ("%s/conf/httpd.conf" if env.system.platform in ("centos", "redhat", "fedora") else "%s/apache2.conf") % env.config.apache.dir,
    content = Template("apache2/apache2.conf.j2"),
    owner = "root",
    group = "root",
    mode = 0644,
    notifies = [("restart", env.resources["Service"]["apache2"])])

File("apache2-security",
    path = "%s/conf.d/security" % env.config.apache.dir,
    content = Template("apache2/security.j2"),
    owner = "root",
    group = "root",
    mode = 0644,
    notifies = [("restart", env.resources["Service"]["apache2"])])

File("apache2-charset",
    path = "%s/conf.d/charset" % env.config.apache.dir,
    content = Template("apache2/charset.j2"),
    owner = "root",
    group = "root",
    mode = 0644,
    notifies = [("restart", env.resources["Service"]["apache2"])])
 
File("apache2-ports.conf",
    path = "%s/ports.conf" % env.config.apache.dir,
    content = Template("apache2/ports.conf.j2"),
    owner = "root",
    group = "root",
    mode = 0644,
    notifies = [("restart", env.resources["Service"]["apache2"])])

# File("apache2-default",
#     path = "%s/sites-available/default" % env.config.apache.dir,
#     content = Template("apache2/default-site.j2"),
#     owner = "root",
#     group = "root",
#     mode = 0644,
#     noifies = [("restart", env.resources["Service"]["apache2"])])
 
File("apache2-default-000",
    path = "%s/sites-enabled/000-default" % env.config.apache.dir,
    action = "delete")

env.cookbooks.apache2.module("alias", conf=False)

# env.cookbooks.apache2.module("status", conf=True)
# include_recipe "apache2::mod_status"
# include_recipe "apache2::mod_alias"
# include_recipe "apache2::mod_auth_basic"
# include_recipe "apache2::mod_authn_file"
# include_recipe "apache2::mod_authz_default"
# include_recipe "apache2::mod_authz_groupfile"
# include_recipe "apache2::mod_authz_host"
# include_recipe "apache2::mod_authz_user"
# include_recipe "apache2::mod_autoindex"
# include_recipe "apache2::mod_dir"
# include_recipe "apache2::mod_env"
# include_recipe "apache2::mod_mime"
# include_recipe "apache2::mod_negotiation"
# include_recipe "apache2::mod_setenvif"
# include_recipe "apache2::mod_log_config" if platform?("centos", "redhat", "suse")

########NEW FILE########
__FILENAME__ = prefork

from kokki import Package

env.include_recipe("apache2")

Package("apache2-mpm-prefork")

########NEW FILE########
__FILENAME__ = worker

from kokki import Package

env.include_recipe("apache2")

Package("apache2-mpm-worker")

########NEW FILE########
__FILENAME__ = metadata

__description__ = """
This project is a repository of simple utilities written in various scripting
languages, which are designed to make slow tasks a bit faster. The name is
taken from the common garden snail. Many of these tools are developed by
consultants at Percona, where the author works.

http://code.google.com/p/aspersa/
"""
__config__ = {
    "aspersa.install_path": dict(
        description = "Path where to install the scripts",
        default = "/usr/local/bin",
    ),
    "aspersa.scripts": dict(
        description = "List of scripts to install",
        default = [
            "align", "collect", "diskstats", "iodump", "ioprofile", "mext",
            "mext2", "mysql-summary", "pmp", "rel", "sif", "slowlog",
            "snoop-to-tcpdump", "stalk", "summary", "usl",
        ],
    ),
}

########NEW FILE########
__FILENAME__ = default

import os
from kokki import Execute, File

base_url = "http://aspersa.googlecode.com/svn/trunk/{name}"

for name in env.config.aspersa.scripts:
    path = os.path.join(env.config.aspersa.install_path, name)
    url = base_url.format(name=name)
    Execute("wget -q -O {path} {url}".format(path=path, url=url),
        creates = path)
    File(path,
        owner = "root",
        group = "root",
        mode = 0755)

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Avatar server"
__config__ = {
    "avatartare.path": dict(
        description = "Path to avatartare installation",
        default = "/var/www/avatartare",
    ),
    "avatartare.aws_access_key_id": dict(
        description = "AWS key to use for S3",
        default = None,
    ),
    "avatartare.aws_secret_access_key": dict(
        description = "AWS secret key to use for S3",
        default = None,
    ),
    "avatartare.s3_bucket": dict(
        description = "S3 bucket where to store avatars",
        default = "avatartare",
    ),
    "avatartare.memcached_servers": dict(
        description = "List of memcached servers to use",
        default = ["localhost:11211"],
    ),
    "avatartare.process_count": dict(
        description = "Number of processes to run",
        default = 6,
    ),
}

########NEW FILE########
__FILENAME__ = default

import os
from kokki import Package, Directory, Execute, File, Template

env.include_recipe("mongodb")
env.include_recipe("supervisor")

env.cookbooks.supervisor.SupervisorService("avatartare")

Package("python-pycurl")
Package("python-imaging")

# Clone project
Directory(os.path.dirname(env.config.avatartare.path), mode=0755)
Execute("git clone git://github.com/samuel/avatartare.git %s" % env.config.avatartare.path,
    creates = env.config.avatartare.path,
)

# Bootstrap the environment
Execute("avatartare-bootstrap",
    command = "python bin/bootstrap.py env",
    cwd = env.config.avatartare.path,
    creates = "%s/env" % env.config.avatartare.path,
)

# Config
File("avatartare-local_settings.py",
    path = "%s/local_settings.py" % env.config.avatartare.path,
    content = Template("avatartare/local_settings.py.j2"),
    notifies = [("restart", env.resources["SupervisorService"]["avatartare"])])

# Setup Supervisor to start and monitor the processes
File("%s/avatartare.conf" % env.config.supervisor.custom_config_path,
    content = Template("avatartare/supervisor.j2"),
    notifies = [("restart", env.resources["SupervisorService"]["avatartare"])])

########NEW FILE########
__FILENAME__ = providers

import itertools
import os
import time
from kokki import Provider, Fail

class EBSVolumeProvider(Provider):
    def action_create(self):
        if self.resource.volume_id:
            raise Fail("Cannot create a volume with a specific id (EC2 chooses volume ids)")
        
        vol = self._find_volume(self.resource.volume_id, self.resource.name, self.resource.device)
        if vol:
            self.log.debug("Volume %s already exists", self.resource)
            # self.log.debug("There is already a volume attached at device %s" % self.resource.device)
            # # if not self._volume_compatible_with_resource_definition(attached_volume):
            # raise Fail("Volume %s attached at %s but does not conform to this resource's specifications" % (attached_volume['aws_id'], attached_volume['aws_device']))
            # # self.log.debug("The volume matches the resource's definition, so the volume is assumed to be already created")
        else:
            vol = self._create_volume(self.resource.snapshot_id, self.resource.size, self.resource.availability_zone, self.resource.name, self.resource.timeout)
            self.resource.updated()
    
    def action_attach(self):
        vol = self._determine_volume()
        
        if vol.status == "in-use":
            if vol.attach_data.instance_id != self.resource.env.config.aws.instance_id:
                raise Fail("Volume with id %s exists but is attached to instance %s" % (vol.id, vol.attach_data.instance_id))
            else:
                self.log.debug("Volume is already attached")
        else:
            self._attach_volume(vol, self.resource.env.config.aws.instance_id, self.resource.device, self.resource.timeout)
            self.resource.updated()
    
    def action_detach(self):
        vol = self._determine_volume()
        if not vol.attach_data or vol.attach_data.instance_id != self.resource.env.config.aws.instance_id:
            return
        
        self._detach_volume(vol, self.resource.timeout)
        self.resource.updated()
    
    def action_snapshot(self):
        vol = self._determine_volume()
        snapshot = self.ec2.create_snapshot(vol.id)
        self.resource.updated()
        self.log.info("Created snapshot of %s as %s" % (vol.id, snapshot.id))
    
    def _find_volume(self, volume_id=None, name=None, device=None):
        vol = None
        if volume_id:
            vol = self._volume_by_id(volume_id)
        else:
            all_volumes = [v for v in self.ec2.get_all_volumes() if v.status in ('in-use', 'available')]
            if device:
                for v in all_volumes:
                    if v.attach_data and v.attach_data.device == device and v.attach_data.instance_id == self.resource.env.config.aws.instance_id:
                        vol = v
                        break
            if not vol and name:
                if '{index}' in name:
                    allnames = dict((v.tags.get('Name'), v) for v in all_volumes)
                    for i in itertools.count(1):
                        vname = name.format(index=i)
                        try:
                            v = allnames[vname]
                            if v.status == "available":
                                vol = v
                                break
                        except KeyError:
                            self.resource.name = vname
                            break
                else:
                    for v in all_volumes:
                        if v.tags.get('Name') == name:
                            vol = v
                            break
        if vol and '{index}' in name:
            self.resource.name = vol.tags.get('Name')
        return vol

    def _determine_volume(self):
        """Pulls the volume id from the volume_id attribute or the node data and verifies that the volume actually exists"""
        vol = self._find_volume(self.resource.volume_id, self.resource.name, self.resource.device)

        if not vol:
            raise Fail("volume_id attribute not set or no volume with the given name or device found")

        return vol

    def _volume_by_id(self, volume_id):
        """Retrieves information for a volume"""
        volumes = self.ec2.get_all_volumes([volume_id])
        if volumes:
            return volumes[0]

    def _volume_compatible_with_resource_definition(self, volume):
        return (
            (not self.resource.size or self.resource.size == volume.size),
            (not self.resource.availability_zone or self.resource.availability_zone == volume.zone),
            (self.resource.snapshot_id == volume.snapshot_id)
        )
    
    def _find_snapshot(self, name):
        snapshots = self.ec2.get_all_snapshots(filters={"tag:Name": name})
        if snapshots:
            snapshots.sort(cmp=lambda x, y: cmp(y.start_time, x.start_time))
            return snapshots[0]
        return None
    
    def _create_volume(self, snapshot_id, size, availability_zone, name, timeout):
        """Creates a volume according to specifications and blocks until done (or times out)"""

        self.log.debug("Creating volume with attributes: snapshot_id=%s size=%s availability_zone=%s name=%s timeout=%s", snapshot_id, size, availability_zone, name, timeout)

        if snapshot_id and not snapshot_id.startswith('snap-'):
            sid = self._find_snapshot(snapshot_id)
            if not sid and self.resource.snapshot_required:
                raise Fail("Unable to find snapshot with name %s" % snapshot_id)
            snapshot_id = sid

        availability_zone = availability_zone or self.resource.env.config.aws.availability_zone
        vol = self.ec2.create_volume(size, availability_zone, snapshot_id)
        self.log.info("Created new volume %s %s%s", name, vol.id, " based on %s" % snapshot_id if snapshot_id else "")

        start_time = time.time()
        end_time = start_time + timeout if timeout else 0

        while (not timeout) or (time.time() < end_time):
            if vol.update() in ('in-use', 'available'):
                break
            time.sleep(1)

        if name:
            vol.add_tag('Name', name)

        try:
            del self.resource.env.config.aws.resources._volumes
        except AttributeError:
            pass

        return vol

    def _attach_volume(self, vol, instance_id, device, timeout):
        """Attaches the volume and blocks until done (or times out)"""
        self.log.info("Attaching %s as %s" % (vol.id, device))
        vol.attach(instance_id, device)

        start_time = time.time()
        end_time = start_time + timeout if timeout else 0
        attached = False

        # block until attached
        while (not timeout) or (time.time() < end_time):
            if vol.update() != "deleting":
                if vol.attachment_state() == "attached":
                    if vol.attach_data.instance_id == instance_id:
                        self.log.info("%s Volume is attached" % self)
                        attached = True
                        break
                    else:
                        raise Fail("Volume is attached to instance %s instead of %s" % (vol.attach_data.instance_id, instance_id))
                else:
                    self.log.debug("Volume is %s" % vol.status)
            else:
                raise Fail("%s Volume %s no longer exists" % (self, vol.id))
            time.sleep(3)

        # block until device is available
        if attached:
            while (not timeout) or (time.time() < end_time):
                if os.path.exists(self.resource.device):
                    return
                time.sleep(1)

        raise Fail("Timed out waiting for volume attachment after %s seconds" % (time.time() - start_time))

    # def detach_volume(self, vol, timeout):
    #     Chef::Log.debug("Detaching #{volume_id}")
    #     vol = volume_by_id(volume_id)
    #     orig_instance_id = vol[:aws_instance_id]
    #     vol.detach()
    #  
    #   # block until detached
    #   begin
    #     Timeout::timeout(timeout) do
    #       while true
    #         vol = volume_by_id(volume_id)
    #         if vol and vol[:aws_status] != "deleting"
    #           if vol[:aws_instance_id] != orig_instance_id
    #             Chef::Log.debug("Volume detached from #{orig_instance_id}")
    #             break
    #           else
    #             Chef::Log.debug("Volume: #{vol.inspect}")
    #           end
    #         else
    #           Chef::Log.debug("Volume #{volume_id} no longer exists")
    #           break
    #         end
    #         sleep 3
    #       end
    #     end
    #   rescue Timeout::Error
    #     raise "Timed out waiting for volume detachment after #{timeout} seconds"

    @property
    def ec2(self):
        return self.resource.env.config.aws.resources.ec2

########NEW FILE########
__FILENAME__ = resources

from kokki import Resource, ResourceArgument

class ElasticIP(Resource):
    actions = ["associate", "disassociate"]

    aws_access_key = ResourceArgument()
    aws_secret_access_key = ResourceArgument()
    ip = ResourceArgument()
    timeout = ResourceArgument(default=3*60) # None or 0 for no timeout

class EBSVolume(Resource):
    provider = "*aws.EBSVolumeProvider"

    actions = ["create", "attach", "detach", "snapshot"]

    volume_id = ResourceArgument()
    aws_access_key = ResourceArgument()
    aws_secret_access_key = ResourceArgument()
    size = ResourceArgument()
    snapshot_id = ResourceArgument()
    snapshot_required = ResourceArgument(default=False)
    availability_zone = ResourceArgument()
    device = ResourceArgument()
    linux_device = ResourceArgument()
    timeout = ResourceArgument(default=3*60) # None or 0 for no timeout

########NEW FILE########
__FILENAME__ = volume

from kokki import Environment, Mount, Execute, Package

def setup_ebs_volume(name=None, availability_zone=None, volume_id=None, device=None, linux_device=None, snapshot_id=None, size=None, fstype=None, mount_point=None, fsoptions=None):
    env = Environment.get_instance()

    if linux_device is None:
        linux_device = device

    env.cookbooks.aws.EBSVolume(name or volume_id,
        volume_id = volume_id,
        availability_zone = availability_zone or env.config.aws.availability_zone,
        device = device,
        linux_device = linux_device,
        snapshot_id = snapshot_id,
        size = size,
        action = "attach" if volume_id else ["create", "attach"])

    if fstype:
        if fstype == "xfs":
            Package("xfsprogs")
        Execute("mkfs.%(fstype)s -f %(device)s" % dict(fstype=fstype, device=linux_device),
            not_if = """if [ "`file -s %(device)s`" = "%(device)s: data" ]; then exit 1; fi""" % dict(device=linux_device))

    if mount_point:
        Mount(mount_point,
            device = linux_device,
            fstype = fstype,
            options = fsoptions if fsoptions is not None else ["noatime"],
            action = ["mount", "enable"])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Resources and providers to support Amazon's Web Services (EC2, S3, etc..)"
__config__ = {
    "aws.access_key_id": dict(
        description = "API Key for AWS",
        default = None,
    ),
    "aws.secret_access_key": dict(
        description = "Secret key for AWS",
        default = None,
    ),
    "aws.volumes": dict(
        description = "Volumes to attach and mount to the current instance (volume_id, device, fstype, fsoptions, mount_point)",
        default = [],
    ),
}

def lazyproperty(method):
    name = "_"+method.__name__
    @property
    def _lazyproperty(self):
        try:
            return getattr(self, name)
        except AttributeError:
            value = method(self)
            setattr(self, name, value)
            return value
    return _lazyproperty

class LazyAWS(object):
    def __init__(self, access_key_id, secret_access_key):
        self.access_key_id = access_key_id
        self.secret_access_key = secret_access_key
    
    @lazyproperty
    def ec2(self):
        from boto.ec2 import EC2Connection
        self._ec2 = EC2Connection(
            self.access_key_id,
            self.secret_access_key)
        return self._ec2
    
    @lazyproperty
    def volumes(self):
        ec2 = self.ec2
        
        all_volumes = ec2.get_all_volumes()
        volumes = []
        for v in all_volumes:
            if v.attach_data and v.attach_data.instance_id == self.instance_id:
                volumes.append(v)
        return volumes
    
    def get_ec2_metadata(self, key):
        import urllib2
        res = urllib2.urlopen("http://169.254.169.254/2009-04-04/meta-data/" + key)
        return res.read().strip()
    
    @lazyproperty
    def instance_id(self):
        return self.get_ec2_metadata('instance-id')
    
    @lazyproperty
    def instance_type(self):
        return self.get_ec2_metadata('instance-type')
    
    @lazyproperty
    def availability_zone(self):
        return self.get_ec2_metadata('placement/availability-zone')

    @lazyproperty
    def tags(self):
        res = self.ec2.get_all_instances([self.instance_id])
        if not res:
            return {}
        return res.instances[0].tags

def __loader__(kit):
    aws = LazyAWS(
        kit.config.aws.access_key_id,
        kit.config.aws.secret_access_key
    )

    kit.update_config({
        "aws.resources": aws, 
        "aws.instance_id": aws.instance_id,
        "aws.instance_type": aws.instance_type,
        "aws.availability_zone": aws.availability_zone,
    })

########NEW FILE########
__FILENAME__ = default

env.include_recipe("boto")

# Mount volumes and format is necessary

for vol in env.config.aws.volumes:
    env.cookbooks.aws.setup_ebs_volume(**vol)

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Amazon Web Services library for Python"
__config__ = {}

########NEW FILE########
__FILENAME__ = default

from kokki import Package

# Package("python-boto")

# Package("pip",
#     provider = "kokki.providers.package.easy_install.EasyInstallProvider")
# Execute("mv /usr/lib/pymodules/python2.6/boto /tmp/boto.orig",
#     only_if = lambda:os.path.exists("/usr/lib/pymodules/python2.6/boto"))
# Execute("pip install git+http://github.com/boto/boto.git#egg=boto",
#     not_if = 'python -c "import boto"')

Package("boto",
    action = "upgrade",
    provider = "kokki.providers.package.easy_install.EasyInstallProvider")

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Service monitoring"
__config__ = {
    "busket.path": dict(
        description = "Install path for busket",
        default = "/usr/local/busket",
    )
}

########NEW FILE########
__FILENAME__ = default

import os
from kokki import Package, File, Service, Script

Package("erlang")
# ubuntu's erlang is a bit messed up.. remove the man link
File("/usr/lib/erlang/man",
    action = "delete")

# Package("mercurial",
#     provider = "kokki.providers.package.easy_install.EasyInstallProvider")

command = os.path.join(env.config.busket.path, "bin", "busket")

Service("busket",
    start_command = "%s start" % command,
    stop_command = "%s stop" % command,
    restart_command = "{0} start || {0} restart".format(command),
    status_command = "%s ping" % command,
    action = "nothing")

Script("install-busket",
    not_if = lambda:os.path.exists(env.config.busket.path),
    cwd = "/usr/local/src",
    code = (
        "git clone git://github.com/samuel/busket.git busket\n"
        "cd busket\n"
        "mkdir /tmp/erlhome\n"
        "export HOME=/tmp/erlhome\n"
        "make release\n"
        "mv rel/busket {install_path}\n"
    ).format(install_path=env.config.busket.path),
    notifies = [("start", env.resources["Service"]["busket"])],
)

if "librato.silverline" in env.included_recipes:
    File("/etc/default/busket",
        owner = "root",
        group = "root",
        mode = 0644,
        content = (
            'RUNNER_ENV="SL_NAME=busket"\n'
        ),
        notifies = [("restart", env.resources["Service"]["busket"])])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Cassandra database"
__config__ = {
    "cassandra.cluster_name": dict(
        display_name = "Cassandra cluster name",
        description = "Name of the Cassandra cluster",
        default = "Test Cluster",
    ),
    "cassandra.auto_bootstrap": dict(
        display_name = "Auto bootstrap",
        description = "Turns on or off the auto-bootstrapping of the node",
        default = False,
    ),
    "cassandra.hinted_handoff_enabled": dict(
        display_name = "Hinted hand-off enabled",
        description = "Enable or disable hinted hand-off",
        default = True,
    ),
    "cassandra.partitioner": dict(
        display_name = "Partitioner",
        description = "Partitioner class path",
        default = "org.apache.cassandra.dht.RandomPartitioner",
    ),
    "cassandra.data_file_directories": dict(
        display_name = "Data file directories",
        description = "List of directories where Cassandra should store data on disk",
        default = ['/var/lib/cassandra/data'],
    ),
    "cassandra.seeds": dict(
        display_name = "Seed nodes",
        description = "List of addresses for seed nodes",
        default = ['127.0.0.1'],
    ),
    "cassandra.disk_access_mode": dict(
        display_name = "Disk access mode",
        description = "How Cassandra handles i/o (auto, mmap, mmap_index_only, or standard)",
        default = "auto",
    ),
    "cassandra.listen_address": dict(
        display_name = "Listen address",
        description = "Address to bind to and tell other nodes to connect to",
        default = "127.0.0.1",
    ),
    "cassandra.rpc_address": dict(
        display_name = "RPC Address",
        description = "Address to bind the Thrift RPC to",
        default = "127.0.0.1",
    ),
    "cassandra.commitlog_directory": dict(
        display_name = "Commit log directory",
        description = "Path where to store the commit log",
        default = "/var/lib/cassandra/commitlog",
    ),
    "cassandra.endpoint_snitch": dict(
        display_nane = "End-point snitch",
        description = "Class that will Cassandra discover topology of the network",
        default = "org.apache.cassandra.locator.SimpleSnitch",
    ),
}

########NEW FILE########
__FILENAME__ = default

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Cloudera Repositories"
__config__ = {}

########NEW FILE########
__FILENAME__ = default

from kokki import Execute, File

env.include_recipe("java.jre")

apt_list_path = '/etc/apt/sources.list.d/cloudera.list'
apt = (
    "deb http://archive.cloudera.com/debian {distro}-cdh3 contrib\n"
    "deb-src http://archive.cloudera.com/debian {distro}-cdh3 contrib\n"
).format(distro=env.system.lsb['codename'])

Execute("apt-update-clouders",
    command = "apt-get update",
    action = "nothing")

Execute("curl -s http://archive.cloudera.com/debian/archive.key | sudo apt-key add -",
    not_if = "(apt-key list | grep Cloudera > /dev/null)")

File(apt_list_path,
    owner = "root",
    group ="root",
    mode = 0644,
    content = apt,
    notifies = [("run", env.resources["Execute"]["apt-update-clouders"], True)])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "CloudKick server monitoring"
__config__ = {
    "cloudkick.oauth_key": dict(
        description = "OAuth Key",
        default = None,
    ),
    "cloudkick.oath_secret": dict(
        description = "OAuth Secret",
        default = None,
    ),
    "cloudkick.tags": dict(
        description = "Tags",
        default = [],
    ),
    "cloudkick.hostname": dict(
        description = "Hostname",
        default = None,
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Execute, Fail, File, Template, Package, Service

assert env.config.cloudkick.oauth_key and env.config.cloudkick.oauth_secret and env.config.cloudkick.hostname

apt_list_path = '/etc/apt/sources.list.d/cloudkick.list'
apt = None
if env.system.platform == "ubuntu":
    ver = env.system.lsb['release']
    if ver in ("10.10", "11.04", "11.10"):
        apt = "deb http://packages.cloudkick.com/ubuntu maverick main"
    elif ver == "10.04":
        apt = "deb http://packages.cloudkick.com/ubuntu lucid main"
    elif ver == "9.10":
        apt = "deb http://packages.cloudkick.com/ubuntu karmic main"
    elif ver == "9.04":
        apt = "deb http://packages.cloudkick.com/ubuntu jaunty main"
    elif ver == "8.10":
        apt = "deb http://packages.cloudkick.com/ubuntu intrepid main"
    elif ver == "8.04":
        apt = "deb http://packages.cloudkick.com/ubuntu hardy main"
    elif ver == "6.04":
        apt = "deb http://packages.cloudkick.com/ubuntu dapper main"
elif env.system.platform == "debian":
    ver = env.system.lsb['release']
    apt = "deb http://packages.cloudkick.com/ubuntu lucid main"
    # if ver == '5.0':
    #     apt = "deb http://apt.librato.com/debian/ lenny non-free"

if not apt:
    raise Fail("Can't find a cloudkick package for your platform/version")

Execute("apt-update-cloudkick",
    command = "apt-get update",
    action = "nothing")

Execute("curl http://packages.cloudkick.com/cloudkick.packages.key | apt-key add -",
    not_if = "(apt-key list | grep 'Cloudkick' > /dev/null)")

File(apt_list_path,
    owner = "root",
    group ="root",
    mode = 0644,
    content = apt+"\n",
    notifies = [("run", env.resources["Execute"]["apt-update-cloudkick"], True)])

File("/etc/cloudkick.conf",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("cloudkick/cloudkick.conf.j2"))

Package("cloudkick-agent",
    action = "upgrade")

Service("cloudkick-agent",
    supports_restart = True,
    subscribes = [("restart", env.resources["File"]["/etc/cloudkick.conf"])])

Package("libssl0.9.8") # This seems to not get installed for some reason

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Exim4 mail server"
__config__ = {
    "exim4.configtype": dict(
        description = "Type of config for mail sending (e.g. satellite)",
        default = "satellite",
    ),
    "exim4.other_hostnames": dict(
        description = "Other host names to receive mail for",
        default = "localhost",
    ),
    "exim4.local_interfaces": dict(
        description = "Local interfaces to bind to",
        default = "127.0.0.1",
    ),
    "exim4.readhost": dict(
        description = "Read host",
        default = "localhost",
    ),
    "exim4.smarthost": dict(
        description = "Host through which to forward mail",
        default = "",
    ),
    "exim4.auth": dict(
        description = "Credentials to use when authenticating to a remote server. List of dictionaries with keys 'domain', 'login', and 'password'.",
        default = [],
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Package, Service, File, Template

Package("exim4", action="upgrade")
Service("exim4",
    supports_restart=True)

File("/etc/exim4/update-exim4.conf.conf",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("exim4/update-exim4.conf.conf.j2"),
    notifies = [("restart", env.resources["Service"]["exim4"])])

File("/etc/exim4/exim4.conf.localmacros",
    owner = "root",
    group = "root",
    mode = 0644,
    content = "AUTH_CLIENT_ALLOW_NOTLS_PASSWORDS = 1\nMAIN_TLS_ENABLE = 1\n",
    notifies = [("restart", env.resources["Service"]["exim4"])])

File("/etc/exim4/passwd.client",
    mode = 0640,
    content = Template("exim4/passwd.client.j2"),
    notifies = [("restart", env.resources["Service"]["exim4"])])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Data flows"
__config__ = {
    "flume.master.servers": dict(
        description = "A comma-separated list of hostnames, one for each machine in the Flume Master.",
        default = None,
    ),
    "flume.plugin.classes": dict(
        description = "Comma separated list of plugin classes",
        default = None,
    ),
    "flume.collector.event.host": dict(
        description = "Host name of the default 'remote' collector",
        default = None,
    ),
    "flume.collector.post": dict(
        description = "Default tcp port that the collector listen to in order to receive events it is collecting",
        default = None,
    ),
    "flume.master.zk.logdir": dict(
        description = "Base directory in which the ZBCS stores data",
        default = "/tmp/flume-zk",
    ),
    "flume.master.zk.server.quorum.port": dict(
        description = "ZooKeeper quorum port",
        default = 3182,
    ),
    "flume.master.zk.server.election.port": dict(
        description = "ZooKeeper election port",
        default = 3183,
    ),
    "flume.master.zk.client.port": dict(
        description = "ZooKeeper client port",
        default = 3181,
    ),
    "flume.master.zk.use.external": dict(
        description = "Use an external ZooKeeper cluter",
        default = False,
    ),
    "flume.master.zk.servers": dict(
        description = "Comma-separated list of external ZooKeeper servers",
        default = None,
    ),
    "flume.agent.logdir": dict(
        description = "This is the directory that write-ahead logging data"
                      "or disk-failover data is collected from applicaitons"
                      "gets written to. The agent watches this directory.",
        default = "/tmp/flume/agent",
    ),
    "flume.collector.dfs.dir": dict(
        description = "This is a dfs directory that is the the final resting"
                      "place for logs to be stored in.  This defaults to a local dir in"
                      "/tmp but can be hadoop URI path that such as hdfs://namenode/path/",
        default = "file:///tmp/flume/collected",
    ),
    "flume.collector.dfs.compress.gzip": dict(
        description = "Writes compressed output in gzip format to dfs.",
        value = False,
    ),
    "flume.log_level": dict(
        description = "Log level (DEBUG, INFO, WARN, ERROR)",
        value = "INFO",
    ),
    "flume.aws_access_key_id": dict(
        description = "AWS access key id to use S3 for storage",
        value = None,
    ),
    "flume.aws_secret_access_key": dict(
        description = "AWS secret access key to use S3 for storage",
        value = None,
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Package, Directory, Link, File, Template

env.include_recipe("cloudera")

Package("flume")

Directory("/etc/flume/conf.kokki",
    owner = "root",
    group = "root",
    mode = 0755)

Link("/etc/flume/conf",
    to = "/etc/flume/conf.kokki")

File("flume-config",
    path = "/etc/flume/conf.kokki/flume-conf.xml",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("flume/flume-conf.xml.j2"))

File("flume-site-config",
    path = "/etc/flume/conf.kokki/flume-site.xml",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("flume/flume-site.xml.j2"))

File("flume-log-config",
    path = "/etc/flume/conf.kokki/log4j.properties",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("flume/log4j.properties.j2"))

File("flume-daemon-sh",
    path = "/usr/lib/flume/bin/flume-daemon.sh",
    owner = "root",
    group = "root",
    mode = 0755,
    content = Template("flume/flume-daemon.sh.j2"))

Directory(env.config.flume.agent.logdir,
    owner = "flume",
    group = "flume",
    recursive = True)

Directory(env.config.flume.master.zk.logdir,
    owner = "flume",
    group = "flume",
    recursive = True)

########NEW FILE########
__FILENAME__ = master

from kokki import Package, Service

env.include_recipe("flume")

Package("flume-master")

import os
def flume_master_status():
    pid_path = "/var/run/flume/flume-flume-master.pid"
    try:
        with open(pid_path, "rb") as fp:
            pid = int(fp.read().strip())
        os.getpgid(pid) # Throws OSError if processes doesn't exist
    except (IOError, OSError, ValueError):
        return False
    return True

Service("flume-master",
    supports_restart = True,
    supports_reload = False,
    status_command = flume_master_status,
    subscribes = [
        ("restart", env.resources["File"]["flume-config"]),
        ("restart", env.resources["File"]["flume-site-config"]),
        ("restart", env.resources["File"]["flume-log-config"]),
        ("restart", env.resources["File"]["flume-daemon-sh"]),
    ])

########NEW FILE########
__FILENAME__ = node

from kokki import Package, Service

env.include_recipe("flume")

Package("flume-node")

import os
def flume_node_status():
    pid_path = "/var/run/flume/flume-flume-node.pid"
    try:
        with open(pid_path, "rb") as fp:
            pid = int(fp.read().strip())
        os.getpgid(pid) # Throws OSError if processes doesn't exist
    except (IOError, OSError, ValueError):
        return False
    return True

Service("flume-node",
    supports_restart = True,
    supports_reload = False,
    status_command = flume_node_status,    
    subscribes = [
        ("restart", env.resources["File"]["flume-config"]),
        ("restart", env.resources["File"]["flume-site-config"]),
        ("restart", env.resources["File"]["flume-log-config"]),
        ("restart", env.resources["File"]["flume-daemon-sh"]),
    ])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Gearman RPC broker"
__config__ = {
    "gearmand.listen_address": dict(
        description = "IP address to bind to",
        default = "127.0.0.1",
    ),
    "gearmand.user": dict(
        display_name = "Gearmand user",
        description = "User to run the gearmand procses as",
        default = "nobody",
    ),
    "gearmand.pidfile": dict(
        display_name = "Gearmand pid file",
        description = "Path to the PID file for gearmand",
        default = "/var/run/gearmand/gearmand.pid",
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Package, Directory, Script, Template, Fail

env.include_recipe("monit")

def install_package(name, url, creates):
    import os
    filename = url.rsplit('/', 1)[-1]
    dirname = filename
    while dirname.rsplit('.', 1)[-1] in ('gz', 'tar', 'tgz', 'bz2'):
        dirname = dirname.rsplit('.', 1)[0]

    if not dirname:
        raise Fail("Unable to figure out directory name of project for URL %s" % url)

    Script("install-%s" % name,
        not_if = lambda:os.path.exists(creates),
        cwd = "/usr/local/src",
        code = (
            "wget %(url)s\n"
            "tar -zxvf %(filename)s\n"
            "cd %(dirname)s\n"
            "./configure && make install\n"
            "ldconfig\n") % dict(url=url, dirname=dirname, filename=filename)
    )

Package("uuid-dev")
Package("libevent-dev")
Package("g++")
install_package("gearmand",
    creates = "/usr/local/sbin/gearmand",
    url = "http://launchpad.net/gearmand/trunk/0.14/+download/gearmand-0.14.tar.gz")

Directory("/var/run/gearmand",
    owner = "nobody",
    mode = 0755)
env.cookbooks.monit.rc("gearmand",
    content = Template("gearmand/monit.conf.j2"))

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Sun Java 6"
__config__ = {}

########NEW FILE########
__FILENAME__ = default

import os
from kokki import Package, Execute, File, Script

Package("debconf-utils")

Execute("apt-update-java",
    command = "apt-get update",
    action = "nothing")

if env.system.lsb['codename'] == 'karmic':
    def enter_the_multiverse():
        with open("/etc/apt/sources.list", "r") as fp:
            source = fp.read().split(' ')[1]
        return (
            "deb {source} karmic multiverse\n"
            "deb-src {source} karmic multiverse\n"
            "deb {source} karmic-updates multiverse\n"
            "deb-src {source} karmic-updates multiverse\n"
            "deb http://security.ubuntu.com/ubuntu karmic-security multiverse\n"
        ).format(source=source)
    File("/etc/apt/sources.list.d/multiverse.list",
        owner = "root",
        group = "root",
        mode = 0644,
        not_if = lambda:os.path.exists("/etc/apt/sources.list.d/multiverse.list"),
        content = enter_the_multiverse,
        notifies = [("run", env.resources["Execute"]["apt-update-java"], True)])

ubuntu_sources = ("lucid", "maverick")

if env.system.lsb['codename'] in ubuntu_sources:
    Execute('add-apt-repository "deb http://archive.canonical.com/ %s partner" ; apt-get update' % env.system.lsb['codename'],
        not_if = "grep '%s partner' /etc/apt/sources.list > /dev/null" % env.system.lsb['codename'])

Script("accept-java-license",
    not_if = "debconf-show sun-java6-jre | grep accepted > /dev/null",
    cwd = "/usr/local/src",
    code = """#!/bin/sh
echo 'sun-java6-bin   shared/accepted-sun-dlj-v1-1    boolean true
sun-java6-jdk   shared/accepted-sun-dlj-v1-1    boolean true
sun-java6-jre   shared/accepted-sun-dlj-v1-1    boolean true
sun-java6-jre   sun-java6-jre/stopthread        boolean true
sun-java6-jre   sun-java6-jre/jcepolicy note
sun-java6-bin   shared/present-sun-dlj-v1-1     note
sun-java6-jdk   shared/present-sun-dlj-v1-1     note
sun-java6-jre   shared/present-sun-dlj-v1-1     note
'|debconf-set-selections""")

########NEW FILE########
__FILENAME__ = jre

from kokki import Package

env.include_recipe("java")

Package("sun-java6-jre")

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Jenkins CI"
__config__ = {
    "jenkins.http_port": dict(
        description = "HTTP port to listen on",
        default = 8080,
    )
}

########NEW FILE########
__FILENAME__ = default

from kokki import Execute, File, Package, Service, Template

if env.system.platform in ("ubuntu", "debian"):
    Execute("wget -q -O - http://pkg.jenkins-ci.org/debian/jenkins-ci.org.key | sudo apt-key add -",
        not_if = "(apt-key list | grep 'Kohsuke Kawaguchi' > /dev/null)")
    

    apt = "deb http://pkg.jenkins-ci.org/debian binary/"
    apt_list_path = '/etc/apt/sources.list.d/jenkins.list'

    Execute("apt-update-jenkins",
        command = "apt-get update",
        action = "nothing")

    File(apt_list_path,
        owner = "root",
        group ="root",
        mode = 0644,
        content = apt+"\n",
        notifies = [("run", env.resources["Execute"]["apt-update-jenkins"], True)])

Package("jenkins")

Service("jenkins")

File("/etc/default/jenkins",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("jenkins/default.j2"),
    notifies = [("restart", env.resources["Service"]["jenkins"])])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Librato Silverline process monitoring and management"
__config__ = {
    "librato.api_token": dict(
        description = "API token for account",
        default = "0",
    ),
    "librato.server_id_cmd": dict(
        description = "Command to run to generate server ID",
        default = None,
    ),
    "librato.template_id": dict(
        description = "Template ID for this server",
        default = None,
    ),
    "librato.email_address": dict(
        description = "Email address of account",
        default = None,
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Execute, File, Fail

apt_list_path = '/etc/apt/sources.list.d/librato.list'
apt = None
if env.system.platform == "ubuntu":
    ver = env.system.lsb['release']
    if ver == "10.04":
        apt = "deb http://apt.librato.com/ubuntu/ lucid non-free"
    elif ver in ("10.10", "11.04", "11.10"):
        apt = "deb http://apt.librato.com/ubuntu/ maverick non-free"
elif env.system.platform == "debian":
    ver = env.system.lsb['release']
    if ver == '5.0':
        apt = "deb http://apt.librato.com/debian/ lenny non-free"

if not apt:
    raise Fail("Can't find a librato package for your platform/version")

Execute("apt-update-librato",
    command = "apt-get update",
    action = "nothing")

Execute("curl http://apt.librato.com/packages.librato.key | apt-key add -",
    not_if = "(apt-key list | grep Librato > /dev/null)")

File(apt_list_path,
    owner = "root",
    group ="root",
    mode = 0644,
    content = apt+"\n",
    notifies = [("run", env.resources["Execute"]["apt-update-librato"], True)])

########NEW FILE########
__FILENAME__ = silverline

from kokki import Package, Service, Execute, File, Template

env.include_recipe("librato")

Package("librato-silverline")

Service("silverline", action="start")

Execute("reload-silverline",
    command = "killall lmd",
    action = "nothing")

File("/etc/load_manager/lmd.conf",
    owner = "root",
    group = "root",
    mode = 0600,
    content = Template("librato/lmd.conf.j2"),
    notifies = [("run", env.resources["Execute"]["reload-silverline"])])

File("/etc/load_manager/lmc.conf",
    owner = "root",
    group = "root",
    mode = 0600,
    content = Template("librato/lmc.conf.j2"))

########NEW FILE########
__FILENAME__ = limit

from kokki import Environment

def Limit(domain, type, item, value, action="include"):
    env = Environment().get_instance()

    for i, l in enumerate(env.config.limits):
        if l['domain'] == domain and l['type'] == type and l['item'] == item:
            del env.config.limits[i]
            break

    if action == "include":
        env.config.limits.append(dict(domain=domain, type=type, item=item, value=value))

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Security limits"
__config__ = {
    "limits": dict(
        description = "List of dictionaries with keys domain, type, item, and value.",
        default = [
            dict(domain="root", type="soft", item="nofile", value="30000"),
            dict(domain="root", type="hard", item="nofile", value="30000"),
        ],
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import File, Template

File("/etc/security/limits.conf",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("limits/limits.conf.j2"))

########NEW FILE########
__FILENAME__ = providers

import subprocess
from kokki import Provider

class ArrayProvider(Provider):
    def action_create(self):
        if not self.exists():
            subprocess.check_call(["/sbin/mdadm",
                    "--create", self.resource.name,
                    "-R",
                    "-c", str(self.resource.chunksize),
                    "--level", str(self.resource.level),
                    "--metadata", self.resource.metadata,
                    "--raid-devices", str(len(self.resource.devices)),
                ] + self.resource.devices)
            self.resource.updated()
    
    def action_stop(self):
        if self.exists():
            subprocess.check_call(["/sbin/mdadm",
                    "--stop", self.resource.name])
            self.resource.updated()

    def action_assemble(self):
        if not self.exists():
            subprocess.check_call(["/sbin/mdadm",
                    "--assemble", self.resource.name,
                ] + self.resource.devices)
            self.resource.updated()

    def exists(self):
        ret = subprocess.call(["/sbin/mdadm", "-Q", self.resource.name])
        return not ret

########NEW FILE########
__FILENAME__ = resources

from kokki import Resource, ForcedListArgument, ResourceArgument

class Array(Resource):
    provider = "*mdadm.ArrayProvider"

    actions = Resource.actions + ["create", "stop", "assemble"]

    action = ForcedListArgument(default="create")
    chunksize = ResourceArgument()
    level = ResourceArgument()
    metadata = ResourceArgument()
    devices = ForcedListArgument()

    def __init__(self, *args, **kwargs):
        super(Array, self).__init__(*args, **kwargs)
        self.subscribe("run", self.env.resources["Execute"]["mdadm-update-conf"], False)

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Software RAID for Linux"
__config__ = {
    "mdadm.arrays": dict(
        description = "List of dictionary with keys name, devices, level, chunksize, and metadata",
        default = [],
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Package, Execute, Mount

if env.config.mdadm.arrays:
    Package("mdadm")

Execute("mdadm-update-conf",
    action = "nothing",
    command = ("("
        "echo DEVICE partitions > /etc/mdadm/mdadm.conf"
        "; mdadm --detail --scan >> /etc/mdadm/mdadm.conf"
    ")"
    ))

for arr in env.config.mdadm.arrays:
    array = arr.copy()
    fstype = array.pop('fstype', None)
    fsoptions = array.pop('fsoptions', None)
    mount_point = array.pop('mount_point', None)

    env.cookbooks.mdadm.Array(**array)

    if fstype:
        if fstype == "xfs":
            Package("xfsprogs")
        Execute("mkfs.%(fstype)s -f %(device)s" % dict(fstype=fstype, device=array['name']),
            not_if = """if [ "`file -s %(device)s`" = "%(device)s: data" ]; then exit 1; fi""" % dict(device=array['name']))

    if mount_point:
        Mount(mount_point,
            device = array['name'],
            fstype = fstype,
            options = fsoptions if fsoptions is not None else ["noatime"],
            action = ["mount", "enable"])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Database by NorthScale"
__config__ = {

}

########NEW FILE########
__FILENAME__ = default

########NEW FILE########
__FILENAME__ = moxi

if env.system.platform in ("ubuntu", "debian"):
    if env.system.arch == "x86_64":
        deb_url = "http://c2493362.cdn.cloudfiles.rackspacecloud.com/moxi-server_x86_64_1.6.0.deb"
    elif env.system.arch == "x86_32":
        deb_url = "http://c2493362.cdn.cloudfiles.rackspacecloud.com/moxi-server_x86_1.6.0.deb"
    # TODO: Install deb
elif env.system.platform in ("fedora", "redhat"):
    if env.system.arch == "x86_64":
        rpm_url = "http://c2493362.cdn.cloudfiles.rackspacecloud.com/moxi-server_x86_64_1.6.0.rpm"
    elif env.system.arch == "x86_32":
        rpm_url = "http://c2493362.cdn.cloudfiles.rackspacecloud.com/moxi-server_x86_1.6.0.rpm"
    # TODO: Install rpm

########NEW FILE########
__FILENAME__ = server

if env.system.platform in ("ubuntu", "debian"):
    if env.system.arch == "x86_64":
        deb_url = "http://c2493362.cdn.cloudfiles.rackspacecloud.com/membase-server-community_x86_64_1.6.0.deb"
    elif env.system.arch == "x86_32":
        deb_url = "http://c2493362.cdn.cloudfiles.rackspacecloud.com/membase-server-community_x86_1.6.0.deb"
    # TODO: Install deb
elif env.system.platform in ("fedora", "redhat"):
    if env.system.arch == "x86_64":
        rpm_url = "http://c2493362.cdn.cloudfiles.rackspacecloud.com/membase-server-community_x86_64_1.6.0.rpm"
    elif env.system.arch == "x86_32":
        rpm_url = "http://c2493362.cdn.cloudfiles.rackspacecloud.com/membase-server-community_x86_1.6.0.rpm"
    # TODO: Install rpm

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Memcached shared memory cache daemon"
__config__ = {
    "memcached.memory": dict(
        description = "Memory allocated for memcached instance in megabytes",
        default = 64,
    ),
    "memcached.listen_address": dict(
        description = "IP address to bind to",
        default = "127.0.0.1",
    ),
    "memcached.port": dict(
        description = "Port to use for memcached instance",
        default = 11211,
    ),
    "memcached.user": dict(
        description = "User as which to run the memcached instance",
        default = "nobody",
    ),
    "memcached.threads": dict(
        description = "Number of threads to use to process incoming requests",
        default = 1,
    ),
    "memcached.verbose": dict(
        description = "Verbose logging output",
        default = False,
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Package, Service, File, Template, Link

Package("memcached", action="upgrade")
Package("libmemcache-dev", action="upgrade")
Service("memcached")

File("/etc/memcached.conf",
    content = Template("memcached/memcached.conf.j2"),
    owner = "root",
    group = "root",
    mode = 0644,
    notifies = [("restart", env.resources["Service"]["memcached"], True)])

if "librato.silverline" in env.included_recipes:
    File("/etc/default/memcached",
        owner = "root",
        group = "root",
        mode = 0644,
        content = (
            "ENABLE_MEMCACHED=yes\n"
            "export SL_NAME=memcached\n"
        ),
        notifies = [("restart", env.resources["Service"]["memcached"])])

if "munin.node" in env.included_recipes:
    for n in ('bytes', 'connections', 'curr_items', 'items', 'queries'):
        Link("/etc/munin/plugins/memcached_%s" % n,
            to = "/etc/munin/python-munin/plugins/memcached_%s" % n,
            notifies = [("restart", env.resources['Service']['munin-node'])])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Minecraft game server"
__config__ = {
    "minecraft.path": dict(
        description = "Path where to install Minecraft server",
        default = "/var/lib/minecraft",
    ),
    "minecraft.user": dict(
        description = "User to run Minecraft server as",
        default = "nobody",
    ),
    "minecraft.package_url": dict(
        description = "URL of the server jar file",
        default = "http://www.minecraft.net/download/minecraft_server.jar", #"?v=445",
    ),
    "minecraft.xms": dict(
        description = "Initial Java heap size",
        default = "1024M",
    ),
    "minecraft.xmx": dict(
        description = "Maximum Java heap size",
        default = "1024M",
    ),
}

########NEW FILE########
__FILENAME__ = server

import os
from kokki import Package, Directory, Script, File, Service

env.include_recipe("java.jre")

Package("screen")

Directory(env.config.minecraft.path,
    owner = env.config.minecraft.user)

Script("install-minecraft-server",
    not_if = lambda:os.path.exists(os.path.join(env.config.minecraft.path, "minecraft_server.jar")),
    code = (
        "cd {config.minecraft.path}\n"
        "wget {config.minecraft.package_url}\n"
    ).format(config=env.config)
)

File("%s/server.sh",
    mode = 0755,
    content = (
        "#!/bin/sh\n"
        "cd {0}\n"
        "java -Xmx1024M -Xms1024M -jar {0}/minecraft_server.jar nogui\n"
    ).format(env.config.minecraft.path),
)

Service("minecraft-server",
    start_command = "screen -dmS minecraft -- %s/server.sh" % env.config.minecraft.path,
    stop_command = 'screen -S minecraft -X stuff "stop\n"',
    status_command = "nc -z localhost 25565",
    action = "start",
)

########NEW FILE########
__FILENAME__ = server

import os
from kokki import Environment, Directory, File, Service, Template

def setup(name, **kwargs):
    env = Environment.get_instance()
    config = env.config.mongodb.copy()
    config.update(kwargs)

    config['configpath'] = "/etc/mongodb/%s.conf" % name
    if 'dbpath' not in kwargs:
        config['dbpath'] = os.path.join(config.dbpath, name)
    if 'logfilename' not in kwargs:
        config['logfilename'] = "%s.log" % name

    Directory("/etc/mongodb",
        owner = "root",
        group = "root",
        mode = 0755)

    Directory(config.dbpath,
        owner = "mongodb",
        group = "mongodb",
        mode = 0755,
        recursive = True)

    File(config.configpath,
        owner = "root",
        group = "root",
        mode = 0644,
        content = Template("mongodb/mongodb.conf.j2", variables=dict(mongodb=config)))
        # notifies = [("restart", env.resources["MonitService"]["mongodb-%s" % name])])

    controller = kwargs.get("controller")
    if controller == "monit":
        env.include_recipe("monit")
        env.cookbooks.monit.rc("mongodb-%s" % name,
            Template("mongodb/monit.conf.j2", variables=dict(name=name, mongodb=config)))
        env.cookbooks.monit.MonitService("mongodb-%s" % name,
            subscribes = [("restart", env.resources["File"][config.configpath])])
    elif controller == "supervisord":
        env.include_recipe("supervisor")
        env.cookbooks.supervisor.configuration("mongodb-%s" % name,
            Template("mongodb/supervisord.conf.j2", variables=dict(name=name, mongodb=config)))
        env.cookbooks.supervisor.SupervisorService("mongodb-%s" % name,
            subscribes = [("restart", env.resources["File"][config.configpath])])
    else:
        Service("mongodb-%s" % name,
             subscribes = [("restart", env.resources["File"][config.configpath])])
        File("/etc/init/mongodb-%s.conf" % name,
            owner = "root",
            group = "root",
            mode = 0644,
            content = Template("mongodb/upstart.conf.j2", variables=dict(mongodb=config)),
            notifies = [
                ("reload", env.resources["Service"]["mongodb-%s" % name], True),
            ])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "MongoDB database"
__config__ = {
    "mongodb.nodefault": dict(
        description = "Remove the default mongodb.conf and init script",
        default = False,
    ),
    "mongodb.configpath": dict(
        description = "Path to the MongoDB config file",
        default = "/etc/mongodb.conf",
    ),
    "mongodb.options": dict(
        description = "List of command line options (e.g. ['--configsvr'])",
        default = [],
    ),
    "mongodb.dbpath": dict(
        description = "Path where to store the MongoDB database",
        default = "/var/lib/mongodb",
    ),
    "mongodb.logpath": dict(
        description = "Path where to store the MongoDB log",
        default = "/var/log/mongodb",
    ),
    "mongodb.logfilename": dict(
        description = "Name of log file",
        default = "mongodb.log",
    ),
    "mongodb.port": dict(
        description = "Specifies the port number on which Mongo will listen for client connections.",
        default = None,
    ),
    "mongodb.verbose": dict(
        description = "Verbose logging output",
        default = False,
    ),
    "mongodb.rest": dict(
        description = "Allow extended operations at the HTTP Interface",
        default = False,
    ),
    "mongodb.oplog_size": dict(
        description = "Custom size for replication operation log.",
        default = None,
    ),
    "mongodb.op_id_mem": dict(
        description = "Size limit for in-memory storage of op ids.",
        default = None,
    ),
    "mongodb.replica_set": dict(
        description = "<setname>[/<seedlist>] Use replica sets with the specified logical set name.  Typically the optional seed host list need not be specified.",
        default = None,
    ),
    "mongodb.limit_nofile": dict(
        description = "Open file limit set in upstart config",
        default = 32000,
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import File, Template, Execute, Directory, Service, Fail, Package

apt_list_path = '/etc/apt/sources.list.d/mongodb.list'
apt = None
if env.system.platform == "ubuntu":
    ver = env.system.lsb['release']
    if ver in ('10.10', '10.04', '9.10', '9.04'):
        ver = ver.replace(".0", ".")
        apt = 'deb http://downloads.mongodb.org/distros/ubuntu %s 10gen' % ver
elif env.system.platform == "debian":
    ver = env.system.lsb['release']
    if ver == '5.0':
        apt = 'deb http://downloads.mongodb.org/distros/debian 5.0 10gen'

if not apt:
    raise Fail("Can't find a mongodb package for your platform/version")

Execute("apt-update-mongo",
    command = "apt-get update",
    action = "nothing")

Execute("apt-key adv --keyserver keyserver.ubuntu.com --recv 7F0CEB10",
    not_if = "(apt-key list | grep 10gen.com > /dev/null)")

File(apt_list_path,
    owner = "root",
    group ="root",
    mode = 0644,
    content = apt+"\n",
    notifies = [("run", env.resources["Execute"]["apt-update-mongo"], True)])

###

Package("mongodb-stable")

if env.config.mongodb.nodefault:
    Service("mongodb")
    File(env.config.mongodb.configpath,
        action = "delete",
        notifies = [("stop", env.resources["Service"]["mongodb"], True)])
    File("/etc/init/mongodb.conf", action="delete")
    File("/etc/init.d/mongodb", action="delete")
else:
    Directory(env.config.mongodb.dbpath,
        owner = "mongodb",
        group = "mongodb",
        mode = 0755,
        recursive = True)

    Service("mongodb")

    File("/etc/init/mongodb.conf",
        owner = "root",
        group = "root",
        mode = 0644,
        content = Template("mongodb/upstart.conf.j2", variables=dict(mongodb=env.config.mongodb)),
        notifies = [
            ("restart", env.resources["Service"]["mongodb"], True),
        ])

    File(env.config.mongodb.configpath,
        owner = "root",
        group = "root",
        mode = 0644,
        content = Template("mongodb/mongodb.conf.j2", variables=dict(mongodb=env.config.mongodb)),
        notifies = [("restart", env.resources["Service"]["mongodb"])])

########NEW FILE########
__FILENAME__ = providers

import subprocess
from kokki import Fail
from kokki.providers.service import ServiceProvider

class MonitServiceProvider(ServiceProvider):
    def action_restart(self):
        self._init_cmd("restart", 0)
        self.resource.updated()

    def status(self):
        p = subprocess.Popen(["/usr/sbin/monit", "summary"],
            stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        out = p.communicate()[0]
        for l in out.split('\n'):
            try:
                typ, name, status = l.strip().split(' ', 2)
            except ValueError:
                continue
            if typ.strip() == 'Process' and name.strip() == "'%s'" % self.resource.service_name:
                return status.strip() == "running"
        raise Fail("Service %s not managed by monit" % self.resource.service_name)

    def _init_cmd(self, command, expect=None):
        ret = subprocess.call(["/usr/sbin/monit", command, self.resource.service_name],
            stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        if expect is not None and expect != ret:
            raise Fail("%r command %s for service %s failed" % (self, command, self.resource.service_name))
        return ret

########NEW FILE########
__FILENAME__ = rc

from kokki import Environment, File

def rc(name, content):
    env = Environment.get_instance()
    return File("monitrc-%s" % name,
        content = content,
        owner = "root",
        group = "root",
        mode = 0644,
        path = "%s/monit.d/%s" % (env.config.monit.config_path, name),
        notifies = [("restart", env.resources["Service"]["monit"])])

########NEW FILE########
__FILENAME__ = resources

from kokki import Service, BooleanArgument

class MonitService(Service):
    provider = "*monit.MonitServiceProvider"

    supports_restart = BooleanArgument(default=True)
    supports_status = BooleanArgument(default=True)
    supports_reload = BooleanArgument(default=False)

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Process monitoring"
__config__ = {
    "monit.alert_emails": dict(
        display_name = "Alert emails",
        description = "Emails that should receive alerts about service changes.",
        default = [],
    ),
    "monit.password": dict(
        dispaly_name = "Password",
        description = "Password for accessing web interface",
        default = "m0n1t1tup",
    ),
    'monit.config_path': dict(
        description = "Path to config files",
        default = "/etc/monit",
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Package, File, Template, Directory, Service

Package("monit")

File("%s/monitrc" % env.config.monit.config_path,
    owner = "root",
    group = "root",
    mode = 0700,
    content = Template("monit/monitrc.j2"))

if env.system.platform == "ubuntu":
    File("/etc/default/monit",
        content = Template("monit/default.j2"))

Directory("%s/monit.d" % env.config.monit.config_path,
    owner = "root",
    group = "root",
    mode = 0700)

Directory("/var/monit",
    owner = "root",
    group = "root",
    mode = 0700)

Service("monit",
    supports_restart = True,
    supports_status = False,
    subscribes = [('restart', env.resources['File']["%s/monitrc" % env.config.monit.config_path])])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Munin and munin-node server monitoring"
__config__ = {
    "munin.bind": dict(
        description = "IP address munin-node should bind to",
        default = "127.0.0.1",
    ),
    "munin.port": dict(
        description = "Port number munin-node should listen on",
        default = 4949,
    ),
    "munin.allow": dict(
        description = "IP address ranges that are allowed to connect to munin-node",
        default = ["127.0.0.1/32"],
    ),
    "munin.contacts": dict(
        description = "Who to contact on alerts. List of dictionaries with keys name, email, and subject(optional).",
        default = [], # dict(name='', subject='optional', email='')
    ),
    "munin.contact_commands": dict(
        description = "Dictionary of commands to execute on alerts",
        default = {},
    ),
    "munin.hosts": dict(
        description = "List of hosts to monitor. List of dictionaries with keys name and ip.",
        default = [dict(name="localhost", ip="127.0.0.1")],
    ),
    "munin.dbdir": dict(
        description = "Path to directory where rrd files are kept",
        default = None, # Usually /var/lib/munin
    ),
}

########NEW FILE########
__FILENAME__ = master

from kokki import Package, Directory, File, Template

Package("munin")

Directory(env.config.munin.dbdir,
    owner = "munin",
    group = "munin",
    mode = 0755)

File("/etc/munin/munin.conf",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("munin/munin.conf.j2"))

########NEW FILE########
__FILENAME__ = node

from kokki import Package, File, Template, Service

if env.system.platform == "amazon":
    Package("perl-NetAddr-IP")

Package("munin-node")

File("munin-node.conf",
    path = "/etc/munin/munin-node.conf",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("munin/munin-node.conf.j2"))

Service("munin-node",
    subscribes = [("restart", env.resources["File"]["munin-node.conf"])])

File("/etc/munin/plugin-conf.d/python",
    owner = "root",
    group = "root",
    mode = 0644,
    content = (
        "[*]\n"
        "env.PYTHON_EGG_CACHE /tmp/munin-egg-cache\n"
    ),
    notifies = [("restart", env.resources["Service"]["munin-node"])])

if env.system.ec2:
    File("/etc/munin/plugins/if_err_eth0",
        action = "delete",
        notifies = [("restart", env.resources["Service"]["munin-node"])])

########NEW FILE########
__FILENAME__ = metadata

__config__ = {
    "mysql.server_root_password": dict(
        default = "changeme",
    ),
    "mysql.server_repl_password": dict(
        default = None,
    ),
    "mysql.server_debian_password": dict(
        default = "changeme",
    ),
    "mysql.grants": dict(
        default = [
            # dict(user, host, database, password, permissions)
        ],
    ),
    "mysql.datadir": dict(
        description = "Location of MySQL database",
        default = "/var/lib/mysql",
    ),
    "mysql.bind_address": dict(
        description = "Address that MySQLd should listen on",
        default = "127.0.0.1",
    ),
    "mysql.ft_min_word_len": dict(
        description = "Minimum word length for items in the full-text index",
        default = None,
    ),
    "mysql.tunable.key_buffer": dict(
        default = "250M",
    ),
    "mysql.tunable.max_connections": dict(
        default = 800,
    ),
    "mysql.tunable.wait_timeout": dict(
        default = 180,
    ),
    "mysql.tunable.net_read_timeout": dict(
        default = 30,
    ),
    "mysql.tunable.net_write_timeout": dict(
        default = 30,
    ),
    "mysql.tunable.back_log": dict(
        default = 128,
    ),
    "mysql.tunable.table_cache": dict(
        default = 128,
    ),
    "mysql.tunable.max_heap_table_size": dict(
        default = "32M",
    ),
    "mysql.tunable.thread_stack": dict(
        default = "128K"
    ),
    # Replication
    "mysql.server_id": dict(
        default = None,
    ),
    "mysql.log_bin": dict(
        default = None, # /var/log/mysql/mysql-bin.log
    ),
    "mysql.expire_logs_days": dict(
        default = 10,
    ),
    "mysql.max_binlog_size": dict(
        default = "100M",
    ),
}
########NEW FILE########
__FILENAME__ = client

from kokki import Package

Package("libmysqlclient-dev")
Package("mysql-client")

########NEW FILE########
__FILENAME__ = default

env.include_recipe("mysql.client")

########NEW FILE########
__FILENAME__ = php5

from kokki import Package

Package("php5-mysql")

########NEW FILE########
__FILENAME__ = python

from kokki import Package

Package("python-mysqldb")

########NEW FILE########
__FILENAME__ = server

from kokki import Directory, Execute, File, Template, Package, Service

env.include_recipe("mysql.client")

if env.system.platform in ("debian", "ubuntu"):
    Directory("/var/cache/local/preseeding",
        owner = "root",
        group = "root",
        mode = 0755,
        recursive = True)

    Execute("preseed mysql-server",
        command = "debconf-set-selections /var/cache/local/preseeding/mysql-server.seed",
        action = "nothing")

    File("/var/cache/local/preseeding/mysql-server.seed",
        owner = "root",
        group = "root",
        mode = 0600,
        content = Template("mysql/mysql-server.seed.j2"),
        notifies = [("run", env.resources["Execute"]["preseed mysql-server"], True)])

    File("/etc/mysql/debian.cnf",
        owner = "root",
        group = "root",
        mode = 0600,
        content = Template("mysql/debian.cnf.j2"))

Package("mysql-server")
Service("mysql",
    supports_status = True,
    supports_restart = True)

Execute("mysql_install_db --user=mysql --datadir=%s" % env.config.mysql.datadir,
    creates = env.config.mysql.datadir)

File("/etc/mysql/conf.d/kokki.cnf",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("mysql/kokki.cnf.j2"),
    notifies = [("restart", env.resources["Service"]["mysql"], True)])

File("/etc/mysql/grants.sql",
    owner = "root",
    group = "root",
    mode = 0600,
    content = Template("mysql/grants.sql.j2"))

Execute("/usr/bin/mysql -u root --password='%s' < /etc/mysql/grants.sql" % env.config.mysql.server_root_password,
    action = "nothing",
    subscribes = [("run", env.resources["File"]["/etc/mysql/grants.sql"], True)])

########NEW FILE########
__FILENAME__ = contact

from kokki import Environment

def Contact(name,
            alias,
            service_notification_commands = "notify-service-by-email",
            host_notification_commands = "notify-host-by-email",
            service_notification_period = "24x7",
            host_notification_period = "24x7",
            service_notification_options = "w,u,c,r",
            host_notification_options = "d,r",
            email = None,
            groups = [],
            **kwargs):
    env = Environment.get_instance()

    for k in ('service_notification_commands',
              'host_notification_commands',
              'service_notification_period',
              'host_notification_period',
              'service_notification_options',
              'host_notification_options'):
        kwargs[k] = locals()[k]

    env.config.nagios3.contacts[name] = kwargs
    for g in groups:
        env.config.nagios3.contactgroups[g].append(name)

########NEW FILE########
__FILENAME__ = host

from kokki import Environment

def Host(name,
         alias = None,
         address = None,
         use = "generic-host",
         groups = [],
         action = "create",
         **kwargs):
    env = Environment.get_instance()

    kwargs['name'] = name
    kwargs['alias'] = alias or name
    kwargs['address'] = address or name
    kwargs['use'] = use
    kwargs['services'] = {}
    kwargs['groups'] = groups

    if action == "delete":
        host = env.config.nagios3.hosts.pop(name, None)
        if host:
            for g in host.get('groups', []):
                env.config.nagios3.hostgroups[g]['members'].remove(name)
    else:
        env.config.nagios3.hosts[name] = kwargs
        for g in groups:
            env.config.nagios3.hostgroups[g]['members'].append(name)

########NEW FILE########
__FILENAME__ = service

from kokki import Environment, File, Template

def Service(service_description, host_name=None, hostgroup_name=None, check_command=None, use="generic-service", notification_interval=0, action="create"):
    env = Environment.get_instance()

    values = dict(
        host_name = host_name,
        hostgroup_name = hostgroup_name,
        service_description = service_description,
        check_command = check_command,
        use = use,
        notification_interval = notification_interval,
    )

    if host_name:
        env.config.nagios3.hosts[host_name]["services"][service_description] = values
        return

    File("/etc/nagios3/conf.d/service_%s.cfg" % service_description.lower(),
        content = Template("nagios3/service.cfg.j2", values),
        action = action,
        notifies = [("restart", env.resources["Service"]["nagios3"])])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Server monitoring"
__config__ = {
    "nagios3.contacts": dict(
        description = "Dictionary of contacts with name as key and value as a dictionary with additional options",
        default = {
            # "root": dict(
            #     alias = "Root",
            #     service_notification_period = "24x7",
            #     host_notification_period = "24x7",
            #     service_notification_options = "w,u,c,r",
            #     host_notification_options = "d,r",
            #     service_notification_commands = "notify-service-by-email",
            #     host_notification_commands = "notify-host-by-email",
            #     email = "root@localhost",
            # ),
        },
    ),
    "nagios3.hosts": dict(
        description = "Dictionary of hosts with name as key and value as dictionary with keys use, alias, and address",
        default = {},
    ),
    "nagios3.contactgroups": dict(
        description = "Dictionary of contact groups with name as key and value as a dictionary with alias and members:list",
        default = {
            "admins": dict(
                alias = "Nagios Administrators",
                members = [],
            ),
        },
    ),
    "nagios3.hostgroups": dict(
        description = "Dictionary of host groups with name as key and value as a dictionary with alias and members",
        default = {
            # A simple wildcard hostgroup
            "all": dict(
                alias = "All Servers",
                members = ["*"],
            ),
            # A list of your web servers
            "http-servers": dict(
                alias = "HTTP Servers",
                members = [],
            ),
            # A list of your ssh-accessible servers
            "ssh-servers": dict(
                alias = "SSH Servers",
                members = [],
            ),
            # nagios doesn't like monitoring hosts without services, so this is
            # a group for devices that have no other "services" monitorable
            # (like routers w/out snmp for example)
            "ping-servers": dict(
                alias = "Pingable Servers",
                members = [],
            ),
        },
    ),
    # cgi
    "nagios3.default_user_name": dict(
        description =
            "Setting this variable will define a default user name that can "
            "access pages without authentication.  This allows people within a "
            "secure domain (i.e., behind a firewall) to see the current status "
            "without authenticating.  You may want to use this to avoid basic "
            "authentication if you are not using a secure server since basic "
            "authentication transmits passwords in the clear.\n"
            "Important:  Do not define a default username unless you are "
            "running a secure web server and are sure that everyone who has "
            "access to the CGIs has been authenticated in some manner!  If you "
            "define this variable, anyone who has not authenticated to the web "
            "server will inherit all rights you assign to this user!",
        default = None,
    ),
    "nagios3.default_admin": dict(
        description = "Default username that has full access",
        default = "nagiosadmin",
    ),
    "nagios3.authorized_for_system_information": dict(
        description = 
            "SYSTEM/PROCESS INFORMATION ACCESS\n"
            "This option is a comma-delimited list of all usernames that "
            "have access to viewing the Nagios process information as "
            "provided by the Extended Information CGI (extinfo.cgi). By "
            "default, *no one* has access to this unless you choose to "
            "not use authorization.  You may use an asterisk (*) to "
            "authorize any user who has authenticated to the web server.",
        default = None,
    ),
    "nagios3.authorized_for_configuration_information": dict(
        description =
            "CONFIGURATION INFORMATION ACCESS\n"
            "This option is a comma-delimited list of all usernames that "
            "can view ALL configuration information (hosts, commands, etc). "
            "By default, users can only view configuration information "
            "for the hosts and services they are contacts for. You may use "
            "an asterisk (*) to authorize any user who has authenticated "
            "to the web server.",
        default = None,
    ),
    "nagios3.authorized_for_system_commands": dict(
        description =
            "SYSTEM/PROCESS COMMAND ACCESS\n"
            "This option is a comma-delimited list of all usernames that "
            "can issue shutdown and restart commands to Nagios via the "
            "command CGI (cmd.cgi).  Users in this list can also change "
            "the program mode to active or standby. By default, *no one* "
            "has access to this unless you choose to not use authorization. "
            "You may use an asterisk (*) to authorize any user who has "
            "authenticated to the web server.",
        default = None,
    ),
    "nagios3.authorized_for_all_services": dict(
        description =
            "GLOBAL HOST/SERVICE VIEW ACCESS\n"
            "These two options are comma-delimited lists of all usernames that "
            "can view information for all hosts and services that are being "
            "monitored.  By default, users can only view information "
            "for hosts or services that they are contacts for (unless you "
            "you choose to not use authorization). You may use an asterisk (*) "
            "to authorize any user who has authenticated to the web server.",
        default = None,
    ),
    "nagios3.authorized_for_all_hosts": dict(
        description = "See authorized_for_all_services",
        default = None,
    ),
    "nagios3.authorized_for_all_service_commands": dict(
        description =
            "GLOBAL HOST/SERVICE COMMAND ACCESS\n"
            "These two options are comma-delimited lists of all usernames that "
            "can issue host or service related commands via the command "
            "CGI (cmd.cgi) for all hosts and services that are being monitored. "
            "By default, users can only issue commands for hosts or services "
            "that they are contacts for (unless you you choose to not use "
            "authorization).  You may use an asterisk (*) to authorize any "
            "user who has authenticated to the web server.",
        default = None,
    ),
    "nagios3.authorized_for_all_host_commands": dict(
        description = "See authorized_for_all_service_commands",
        default = None,
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Package, Service, File, Template

env.include_recipe("apache2")

Package("nagios3")
Service("nagios3",
    supports_status = True,
    supports_restart = True,
    supports_reload = True)

# NRPE plugin

Package("nagios-nrpe-plugin")

##

File("/etc/nagios3/cgi.cfg",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("nagios3/cgi.cfg.j2"),
    notifies = [("restart", env.resources["Service"]["nagios3"])])

if env.system.ec2:
    File("/etc/nagios3/conf.d/host-gateway_nagios3.cfg",
        action = "delete",
        notifies = [("restart", env.resources["Service"]["nagios3"])])

File("/etc/nagios3/conf.d/extinfo_nagios2.cfg",
    action = "delete",
    notifies = [("restart", env.resources["Service"]["nagios3"])])

# nagios3 hostgroups

File("/etc/nagios3/conf.d/hostgroups_nagios2.cfg",
    action = "delete",
    notifies = [("restart", env.resources["Service"]["nagios3"])])

File("nagio3-hostgroups",
    path = "/etc/nagios3/conf.d/hostgroups.cfg",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("nagios3/hostgroups.cfg.j2"),
    notifies = [("restart", env.resources["Service"]["nagios3"])])


# nagios3 contacts

File("/etc/nagios3/conf.d/contacts_nagios2.cfg",
    action = "delete",
    notifies = [("restart", env.resources["Service"]["nagios3"])])

File("nagio3-contacts",
    path = "/etc/nagios3/conf.d/contacts.cfg",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("nagios3/contacts.cfg.j2"),
    notifies = [("restart", env.resources["Service"]["nagios3"])])

env.cookbooks.nagios3.Contact("root",
    alias = "Root",
    service_notification_period = "24x7",
    host_notification_period = "24x7",
    service_notification_options = "w,u,c,r",
    host_notification_options = "d,r",
    service_notification_commands = "notify-service-by-email",
    host_notification_commands = "notify-host-by-email",
    email = "root@localhost")

# nagios3 services

File("/etc/nagios3/conf.d/services_nagios2.cfg",
    action = "delete",
    notifies = [("restart", env.resources["Service"]["nagios3"])])

env.cookbooks.nagios3.Service("HTTP",
    hostgroup_name = "http-servers",
    check_command = "check_http",
    use = "generic-service",
    notification_interval = 0)

env.cookbooks.nagios3.Service("SSH",
    hostgroup_name = "ssh-servers",
    check_command = "check_ssh",
    use = "generic-service",
    notification_interval = 0)

env.cookbooks.nagios3.Service("PING",
    hostgroup_name = "ping-servers",
    check_command = "check_ping!100.0,20%!500.0,60%",
    use = "generic-service",
    notification_interval = 0)

# nagios3 hosts

File("/etc/nagios3/conf.d/localhost_nagios2.cfg",
    action = "delete",
    notifies = [("restart", env.resources["Service"]["nagios3"])])

File("nagios3-hosts",
    path = "/etc/nagios3/conf.d/hosts.cfg",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("nagios3/hosts.cfg.j2"),
    notifies = [("restart", env.resources["Service"]["nagios3"])])

env.cookbooks.nagios3.Host("localhost",
    address = "127.0.0.1",
    groups = ["ssh-servers"])

env.cookbooks.nagios3.Service("Disk Space",
    host_name = "localhost",
    check_command = "check_all_disks!20%!10%")

env.cookbooks.nagios3.Service("Total Processes",
    host_name = "localhost",
    check_command = "check_procs!250!400")

env.cookbooks.nagios3.Service("Current Load",
    host_name = "localhost",
    check_command = "check_load!5.0!4.0!3.0!10.0!6.0!4.0")

##

File("/etc/apache2/conf.d/nagios3.conf",
    action = "delete",
    notifies = [("restart", env.resources["Service"]["apache2"])])

File("/etc/apache2/sites-available/nagios3",
    owner = "www-data",
    group = "www-data",
    mode = 0644,
    content = Template("nagios3/apache2-site.j2"),
    notifies = [("restart", env.resources["Service"]["apache2"])])

env.cookbooks.apache2.site("nagios3")

########NEW FILE########
__FILENAME__ = nrpe

from kokki import Package

Package("nagios-nrpe-server")
Package("nagios-plugins")
# Package("nagios-plugins-basic")

########NEW FILE########
__FILENAME__ = sites

from os.path import exists
from kokki import Environment, Execute

def site(name, enable=True):
    env = Environment.get_instance()

    if enable:
        cmd = 'nxensite'
    else:
        cmd = 'nxdissite'

    def _not_if():
        e = exists("%s/sites-enabled/%s" % (env.config.nginx.dir, name))
        return e if enable else not e

    Execute("%s %s" % (cmd, name),
            command = "/usr/sbin/%s %s" % (cmd, name),
            notifies = [("reload", env.resources["Service"]["nginx"])],
            not_if = _not_if)

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Installs and configures Nginx"
__config__ = {
    "nginx.dir": dict(
        description = "Location of nginx configuration files",
        default = "/etc/nginx",
    ),
    "nginx.log_dir": dict(
        description = "Location for nginx logs",
        default = "/var/log/nginx",
    ),
    "nginx.log_format": dict(
        description = "Format string for the access log. If not set them the default for nginx is used.",
        default = None,
    ),
    "nginx.user": dict(
        description = "User nginx will run as",
        default = None,
    ),
    "nginx.binary": dict(
        description = "Location of the nginx server binary",
        default = "/usr/sbin/nginx",
    ),
    "nginx.event_model": dict(
        description = "Which event model nginx should use (e.g. epoll)",
        default = None,
    ),
    "nginx.sendfile": dict(
        description = "Whether sendfile should be used to serve files",
        default = True,
    ),
    "nginx.tcp_nopush": dict(
        description = "Whether to enable/disable tcp_nopush",
        default = True,
    ),
    "nginx.tcp_nodelay": dict(
        description = "Whether to enable/disable tcp_nodelay",
        default = False,
    ),
    "nginx.gzip": dict(
        description = "Whether gzip is enabled",
        default = True,
    ),
    "nginx.gzip_http_version": dict(
        description = "Version of HTTP Gzip",
        default = 1.0,
    ),
    "nginx.gzip_comp_level": dict(
        description = "Amount of compression to use",
        default = 2,
    ),
    "nginx.gzip_proxied": dict(
        description = "Whether gzip is proxied",
        default = "any",
    ),
    "nginx.gzip_vary": dict(
        description = "Whether the 'Content-Vary: Accept-Encoding' header should be included when gzipping",
        default = "on",
    ),
    "nginx.gzip_types": dict(
        description = "Supported MIME-types for gzip",
        default = [
            "text/plain",
            "text/css",
            "application/x-javascript",
            "text/xml",
            "application/xml",
            "application/xml+rss",
            "text/javascript",
        ],
    ),
    "nginx.keepalive": dict(
        description = "Whether to enable keepalive",
        default = True,
    ),
    "nginx.keepalive_timeout": dict(
        default = 65,
    ),
    "nginx.worker_processes": dict(
        description = "Number of worker processes",
        default = 1,
    ),
    "nginx.worker_connections": dict(
        description = "Number of connections per worker",
        default = 1024,
    ),
    "nginx.server_names_hash_max_size": dict(
        description = "The maximum size of the server name hash tables. (default 512)",
        default = None,
    ),
    "nginx.server_names_hash_bucket_size": dict(
        description = "Directive assigns the size of basket in the hash-tables of the names of servers. (default 32/64/128 depending on architecture)",
        default = None,
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Package, Directory, File, Template, Service

if not env.config.nginx.user:
    if env.system.platform == "amazon":
        env.config.nginx.user = "nginx"
    else:
        env.config.nginx.user = "www-data"

Package("nginx")

Directory(env.config.nginx.log_dir,
    mode = 0755,
    owner = env.config.nginx.user,
    action = 'create')

for nxscript in ('nxensite', 'nxdissite'):
    File("/usr/sbin/%s" % nxscript,
        content = Template("nginx/%s.j2" % nxscript),
        mode = 0755,
        owner = "root",
        group = "root")

File("nginx.conf",
    path = "%s/nginx.conf" % env.config.nginx.dir,
    content = Template("nginx/nginx.conf.j2"),
    owner = "root",
    group = "root",
    mode = 0644)

Directory("%s/sites-available" % env.config.nginx.dir,
    mode = 0755,
    owner = env.config.nginx.user,
    action = "create")

Directory("%s/sites-enabled" % env.config.nginx.dir,
    mode = 0755,
    owner = env.config.nginx.user,
    action = "create")

File("%s/sites-available/default" % env.config.nginx.dir,
    content = Template("nginx/default-site.j2"),
    owner = "root",
    group = "root",
    mode = 0644)

Service("nginx",
    supports_status = True,
    supports_restart = True,
    supports_reload = True,
    action = "start",
    subscribes = [("reload", env.resources["File"]["nginx.conf"])])

if "librato.silverline" in env.included_recipes:
    File("/etc/default/nginx",
        owner = "root",
        group = "root",
        mode = 0644,
        content = (
            "export SL_NAME=nginx\n"
        ),
        notifies = [("restart", env.resources["Service"]["nginx"])])

########NEW FILE########
__FILENAME__ = providers

__all__ = ["PipPackageProvider"]

import re
from subprocess import check_call, Popen, PIPE, STDOUT

from kokki import Fail
from kokki.providers.package import PackageProvider

version_re = re.compile(r'\S\S(.*)\/(.*)-(.*)-py(.*).egg\S')
best_match_re = re.compile(r'Best match: (.*) (.*)\n')

class PipPackageProvider(PackageProvider):
    def get_current_status(self):
        p = Popen("%s freeze | grep ^%s==" % (self.pip_binary_path, self.resource.package_name), stdout=PIPE, stderr=STDOUT, shell=True)
        out = p.communicate()[0]
        res = p.wait()
        if res != 0:
            self.current_version = None
        else:
            try:
                self.current_version = out.split("==", 1)[1].strip()
            except IndexError:
                raise Fail("pip could not determine installed package version.")

    @property
    def candidate_version(self):
        if not hasattr(self, '_candidate_version'):
            if not self.resource.version and re.match("^[A-Za-z0-9_.-]+$", self.resource.package_name):
                p = Popen([self.easy_install_binary_path, "-n", self.resource.package_name], stdout=PIPE, stderr=STDOUT)
                out = p.communicate()[0]
                res = p.wait()
                if res != 0:
                    self.log.warning("easy_install check returned a non-zero result (%d) %s" % (res, self.resource))

                m = best_match_re.search(out)
                if not m:
                    self._candidate_version = None
                else:
                    self._candidate_version = m.group(2)
            else:
                self._candidate_version = self.resource.version
        return self._candidate_version

    @property
    def pip_binary_path(self):
        return "pip"

    @property
    def easy_install_binary_path(self):
        return "easy_install"

    def install_package(self, name, version):
        if name == 'pip' or not version:
            check_call([self.pip_binary_path, "install", "--upgrade", name], stdout=PIPE, stderr=STDOUT)
        else:
            check_call([self.pip_binary_path, "install", '{0}=={1}'.format(name, version)], stdout=PIPE, stderr=STDOUT)

    def upgrade_package(self, name, version):
        self.install_package(name, version)

    def remove_package(self, name, version):
        check_call([self.pip_binary_path, "uninstall", name])

    def purge_package(self, name, version):
        self.remove_package(name, version)
########NEW FILE########
__FILENAME__ = resources

__all__ = ["PipPackage"]

from kokki import Resource, ForcedListArgument, ResourceArgument


class PipPackage(Resource):
    provider = "*pip.PipPackageProvider"

    action = ForcedListArgument(default="install")
    package_name = ResourceArgument(default=lambda obj:obj.name)
    location = ResourceArgument(default=lambda obj:obj.package_name)
    version = ResourceArgument(required = True)
    actions = ["install", "upgrade", "remove", "purge"]
########NEW FILE########
__FILENAME__ = metadata

__description__ = "Pip Packages"
__config__ = {}

########NEW FILE########
__FILENAME__ = default

from kokki import Package

Package("pip",
    provider = "kokki.providers.package.easy_install.EasyInstallProvider"
)
########NEW FILE########
__FILENAME__ = metadata

__description__ = "PostgreSQL server and clients"
__config__ = {
    "postgresql84.data_dir": dict(
        display_name = "PostgreSQL Data Directory",
        description = "Location of the PostgreSQL databases",
        default = "/var/lib/postgresql/8.4/main",
    ),
    "postgresql84.config_dir": dict(
        display_name = "PostgreSQL Config Directory",
        description = "Location of the PostgreSQL configuration files",
        default = "/etc/postgresql/8.4/main",
    ),
    "postgresql84.pidfile": dict(
        display_name = "PostgreSQL PID File",
        description = "Path to the PostgreSQL pid file",
        default = "/var/run/postgresql/8.4-main.pid",
    ),
    "postgresql84.listen_addresses": dict(
        display_name = "PostgreSQL listen addresses",
        description = "IP addresses PostgreSQL should listen on (* for all interfaces)",
        default = "[localhost]",
    ),
    "postgresql84.port": dict(
        display_name = "PostgreSQL port",
        description = "Port PostgreSQL should bind to",
        default = 5432,
    ),
    "postgresql84.max_connections": dict(
        display_name = "PostgreSQL max connections",
        description = "Maximum numbers of connections",
        default = 100,
    ),
    "postgresql84.auth": dict(
        display_name = "PostgreSQL authentication",
        description = "List of auth configs",
        default = [
            dict(
                type = "local",
                database = "all",
                user = "all",
                method = "ident",
            ),
            dict(
                type = "host",
                database = "all",
                user = "all",
                cidr = "127.0.0.1/32",
                method = "md5",
            ),
            dict(
                type = "host",
                database = "all",
                user = "all",
                cidr = "::1/128",
                method = "md5",
            ),
        ],
    ),
    "postgresql84.log_min_duration_statement": dict(
        display_name = "PostgreSQL Logging Minimum Statement Duration",
        description = "-1 is disabled, 0 logs all statements and their durations, > 0 logs only statements running at least this number of milliseconds",
        default = -1,
    ),
    "postgresql84.skytools.ticker.job_name": dict(
        display_name = "Skytools ticker job name",
        description = "Name used for logging and other such things",
        default = "Ticker1",
    ),
    "postgresql84.skytools.ticker.db": dict(
        display_name = "Skytools ticker database DSN",
        description = "PostgreSQL connection string (dbname, user, password, host, port)",
        default = "dbname=P",
    ),
    "postgresql84.skytools.ticker.logfile": dict(
        display_name = "Skytools ticker log file path",
        description = "Path to the log file. Can include %(job_name)s",
        default = "/var/log/%(job_name)s.log",
    ),
    "postgresql84.skytools.ticker.pidfile": dict(
        display_name = "Skytools ticker pid file path",
        description = "Path to the pid file. Can include %(job_name)s",
        default = "/var/run/%(job_name)s.pid",
    ),
    "postgresql84.skytools.londiste.job_name": dict(
        display_name = "Skytools londiste job name",
        description = "Name used for logging and other such things",
        default = "Londiste1",
    ),
    "postgresql84.skytools.londiste.provider_db": dict(
        display_name = "Skytools londiste provider database DSN",
        description = "PostgreSQL connection string (dbname, user, password, host, port)",
        default = "dbname=P host=127.0.0.1",
    ),
    "postgresql84.skytools.londiste.subscriber_db": dict(
        display_name = "Skytools londiste subscriber database DSN",
        description = "PostgreSQL connection string (dbname, user, password, host, port)",
        default = "dbname=S host=127.0.0.1",
    ),
    "postgresql84.skytools.londiste.pgq_queue_name": dict(
        display_name = "Skytools londiste PGQ queue name",
        description = "PQG queue name for londiste (it will be used as sql ident so no dots/spaces).",
        default = "londiste_replica",
    ),
    "postgresql84.skytools.londiste.logfile": dict(
        display_name = "Skytools londiste log file path",
        description = "Path to the log file. Can include %(job_name)s",
        default = "/var/log/%(job_name)s.log ",
    ),
    "postgresql84.skytools.londiste.pidfile": dict(
        display_name = "Skytools londiste pid file path",
        description = "Path to the pid file. Can include %(job_name)s",
        default = "/var/run/%(job_name)s.pid ",
    ),
    'postgresql84.locale': dict(
        description = "Locale",
        default = None,
    ),
}
def __loader__(kit):
    if kit.config.postgresql84.locale is None:
        postgresql_locale = kit.system.locales[0]
        for l in kit.system.locales:
            if 'utf8' in l.lower() or 'utf-8' in l.lower():
                postgresql_locale = l
                break
        kit.config.postgresql84.locale = postgresql_locale

########NEW FILE########
__FILENAME__ = client

from kokki import Package, Fail

if env.system.platform in ("ubuntu", "debian"):
    Package("postgresql-client")
elif env.system.platform in ("redhat", "centos", "fedora"):
    Package("postgresql-devel")
else:
    raise Fail("Unsupported platform %s for recipe postgresql.client" % env.system.platform)

########NEW FILE########
__FILENAME__ = server

import os
from kokki import Service, File, Package, Template

Service("postgresql",
    supports_restart = True,
    supports_reload = True,
    supports_status = True,
    action = "nothing")

Package("postgresql-8.4",
    notifies = [("stop", env.resources["Service"]["postgresql"], True)])

File("pg_hba.conf",
    owner = "postgres",
    group = "postgres",
    mode = 0600,
    path = os.path.join(env.config.postgresql84.config_dir, "pg_hba.conf"),
    content = Template("postgresql84/pg_hba.conf.j2"),
    notifies = [("reload", env.resources["Service"]["postgresql"])])

File("postgresql.conf",
    owner = "postgres",
    group = "postgres",
    mode = 0600,
    path = os.path.join(env.config.postgresql84.config_dir, "postgresql.conf"),
    content = Template("postgresql84/postgresql.conf.j2"),
    notifies = [("restart", env.resources["Service"]["postgresql"])])

########NEW FILE########
__FILENAME__ = skytools

from kokki import Package, Directory, Script, Fail

Package("postgresql-server-dev",
    package_name = "postgresql-server-dev-8.4")
Package("python-dev")
Package("python-psycopg2")

def install_package(name, url, creates):
    import os
    filename = url.rsplit('/', 1)[-1]
    dirname = filename
    while dirname.rsplit('.', 1)[-1] in ('gz', 'tar', 'tgz', 'bz2'):
        dirname = dirname.rsplit('.', 1)[0]

    if not dirname:
        raise Fail("Unable to figure out directory name of project for URL %s" % url)

    Script("install-%s" % name,
        not_if = lambda:os.path.exists(creates),
        cwd = "/usr/local/src",
        code = (
            "wget %(url)s\n"
            "tar -zxvf %(filename)s\n"
            "cd %(dirname)s\n"
            "./configure && make install\n"
            "ldconfig\n") % dict(url=url, dirname=dirname, filename=filename)
    )

install_package("skytools",
    creates = "/usr/local/bin/pgqadm.py",
    url = "http://pgfoundry.org/frs/download.php/2370/skytools-2.1.10.tar.gz")

Directory("/etc/skytools",
    owner = "root",
    mode = 0755)

########NEW FILE########
__FILENAME__ = skytools_londiste

from kokki import File, Template

env.include_recipe("postgresql84.skytools")

File("/etc/skytools/londiste.ini",
    owner = "root",
    content = Template("postgresql84/skytools-londiste.ini.j2"))

########NEW FILE########
__FILENAME__ = skytools_ticker

from kokki import File, Template

env.include_recipe("postgresql84.skytools")

File("/etc/skytools/ticker.ini",
    owner = "root",
    content = Template("postgresql84/skytools-ticker.ini.j2"))

########NEW FILE########
__FILENAME__ = metadata

__description__ = "PostgreSQL database 9"
__config__ = {
    "postgresql9.version": dict (
        description = "Version of PostgreSQL 9",
        default = "9.1",
    ),
    "postgresql9.data_dir": dict(
        description = "Location of the PostgreSQL databases",
        default = "/var/lib/postgresql/9.1/main",
    ),
    "postgresql9.config_dir": dict(
        description = "Location of the PostgreSQL configuration files",
        default = "/etc/postgresql/9.1/main",
    ),
    "postgresql9.pidfile": dict(
        description = "Path to the PostgreSQL pid file",
        default = "/var/run/postgresql/9.1-main.pid",
    ),
    "postgresql9.unix_socket_directory": dict(
        default = "/var/run/postgresql",
    ),
    "postgresql9.listen_addresses": dict(
        description = "IP addresses PostgreSQL should listen on (* for all interfaces)",
        default = ["localhost"],
    ),
    "postgresql9.port": dict(
        description = "Port PostgreSQL should bind to",
        default = 5432,
    ),
    "postgresql9.max_connections": dict(
        description = "Maximum numbers of connections",
        default = 100,
    ),
    "postgresql9.auth": dict(
        description = "List of auth configs",
        default = [
            dict(
                type = "local",
                database = "all",
                user = "all",
                method = "ident",
            ),
            dict(
                type = "host",
                database = "all",
                user = "all",
                cidr = "127.0.0.1/32",
                method = "md5",
            ),
            dict(
                type = "host",
                database = "all",
                user = "all",
                cidr = "::1/128",
                method = "md5",
            ),
        ],
    ),
    "postgresql9.ssl": dict(
        default = False,
    ),
    "postgresql9.shared_buffers": dict(
        default = "24MB",
    ),
    "postgresql9.log_min_duration_statement": dict(
        description = "-1 is disabled, 0 logs all statements and their durations, > 0 logs only statements running at least this number of milliseconds",
        default = -1,
    ),
    "postgresql9.locale": dict(
        default = "en_US.UTF-8",
    ),
    # Streaming replication
    "postgresql9.max_wal_senders": dict(
        description = "Maximum number of WAL sender processes",
        default = 0,
    ),
    "postgresql9.wal_sender_delay": dict(
        description = "walsender cycle time, 1-10000 milliseconds",
        default = "200ms",
    ),
    # Standby Servers
    "postgresql9.hot_standby": dict(
        description = "Allow queries during discovery",
        default = False,
    ),
}

for k, v in __config__.iteritems():
    if isinstance(v['default'], basestring):
        v["default"] = v["default"].format(config=__config__)

########NEW FILE########
__FILENAME__ = default
import os
from kokki import Execute, Package

# if not (env.system.platform == "ubuntu" and env.system.lsb['release'] in ["11.10"]):
#     apt_list_path = '/etc/apt/sources.list.d/pitti-postgresql-lucid.list'

#     Execute("apt-update-postgresql9",
#         command = "apt-get update",
#         action = "nothing")

#     apt = None
#     if env.system.platform == "ubuntu":
#         Package("python-software-properties")
#         Execute("add-apt-repository ppa:pitti/postgresql -y",
#             not_if = lambda:os.path.exists(apt_list_path),
#             notifies = [("run", env.resources["Execute"]["apt-update-postgresql9"], True)])

########NEW FILE########
__FILENAME__ = server

import os
from kokki import Package, File, Template, Service

env.include_recipe("postgresql9")

Service("postgresql",
    supports_restart = True,
    supports_reload = True,
    supports_status = True,
    action = "nothing")

Package("postgresql-" + env.config.postgresql9.version,
    notifies = [("stop", env.resources["Service"]["postgresql"], True)])

File("pg_hba.conf",
    owner = "postgres",
    group = "postgres",
    mode = 0600,
    path = os.path.join(env.config.postgresql9.config_dir, "pg_hba.conf"),
    content = Template("postgresql9/pg_hba.conf.j2"),
    notifies = [("reload", env.resources["Service"]["postgresql"])])

File("postgresql.conf",
    owner = "postgres",
    group = "postgres",
    mode = 0666,
    path = os.path.join(env.config.postgresql9.config_dir, "postgresql.conf"),
    content = Template("postgresql9/postgresql.conf.j2"),
    notifies = [("restart", env.resources["Service"]["postgresql"])])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "PowerDNS server and recursor"
__config__ = {
    "powerdns.backends": dict(
        description = "List of backend modules to install",
        default = ["pipe"],
    ),
    "powerdns.pipe_command": dict(
        description = "Pipe command",
        default = None,
    ),
    "powerdns.allow_recursion": dict(
        description = "List of addresses from which to allow recursion",
        default = "127.0.0.1",
    ),
    "powerdns.recursor": dict(
        description = "IP address of recursing nameserver if desired",
        default = None,
    ),
}

########NEW FILE########
__FILENAME__ = default

########NEW FILE########
__FILENAME__ = recursor

from kokki import Package

Package("pdns-recursor")

########NEW FILE########
__FILENAME__ = server

from kokki import Package, Service, File, Template

Package("pdns-server")
Service("pdns")

File("/etc/powerdns/pdns.conf",
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("powerdns/pdns.conf"),
    notifies = [("reload", env.resources["Service"]["pdns"])])

for be in env.config.powerdns.backends:
    Package("pdns-backend-%s" % be)

########NEW FILE########
__FILENAME__ = metadata

__description__ = "RabbitMQ Messaging Server"
__config__ = {
    "rabbitmq.path": dict(
        description = "Install path for rabbitmq",
        default = "/usr/local/rabbitmq",
    )
}

########NEW FILE########
__FILENAME__ = default

from kokki import Package, Execute, File, Fail

Package("erlang")

apt_list_path = '/etc/apt/sources.list.d/rabbitmq.list'
apt = None
if env.system.platform in ("ubuntu", "debian"):
    apt = "deb http://www.rabbitmq.com/debian/ testing main"

if not apt:
    raise Fail("Can't find a rabbitmq package for your platform/version")

Execute("apt-update-rabbitmq",
    command = "apt-get update",
    action = "nothing")

Execute("curl http://www.rabbitmq.com/rabbitmq-signing-key-public.asc | apt-key add -",
    not_if = "(apt-key list | grep rabbitmq > /dev/null)")

File(apt_list_path,
    owner = "root",
    group ="root",
    mode = 0644,
    content = apt+"\n",
    notifies = [("run", env.resources["Execute"]["apt-update-rabbitmq"], True)])

Package("rabbitmq-server")

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Redis in-memory database"
__config__ = {
    "redis.configfile": dict(
        description = "Path to the config file",
        default = "/etc/redis.conf",
    ),
    "redis.bind": dict(
        description = "Interface to listen on",
        default = "127.0.0.1",
    ),
    "redis.port": dict(
        description = "Accept connections on the specified port",
        default = 6379,
    ),
    "redis.timeout": dict(
        description = "Close the connection after a client is idle for N seconds (0 to disable)",
        default = 300,
    ),
    "redis.pidfile": dict(
        description = "The file which to write the pid to.",
        default = "/var/run/redis.pid",
    ),
    "redis.dbdir": dict(
        description = "For default save/load DB in/from the working directory",
        default = "/var/db/redis/",
    ),
    "redis.appendonly": dict(
        description = "Use the append only file for persistence",
        default = True,
    ),
    "redis.appendfsync": dict(
        description = "How often to fsync the AOF file (no, everysec, always)",
        default = "everysec",
    ),
    "redis.databases": dict(
        description = "Set the number of databases.",
        default = 16,
    ),
    "redis.logfile": dict(
        description = "File for Redis's log",
        default = "/var/log/redis.log",
    ),
    "redis.loglevel": dict(
        description = "How much Redis should log",
        default = "notice",
    ),
    "redis.master.ip": dict(
        description = "This instance of redis is a slave of a master at the given IP",
        default = None,
    ),
    "redis.master.port": dict(
        description = "Port number for the master server. If slaveof.ip is specified but thit is not then defalts to redis.port.",
        default = None,
    ),
    "redis.maxmemory": dict(
        description = "Don't use more memory than the specified amount of bytes.",
        default = None,
    ),
}

########NEW FILE########
__FILENAME__ = default

import os
from kokki import Script, Directory, File, Service, Package, Link, Template

# env.include_recipe("monit")

version = "2.2.0-rc2"
dirname = "redis-%s" % version
filename = "%s.tar.gz" % dirname
url = "http://redis.googlecode.com/files/%s" % filename

Script("install-redis",
    not_if = lambda:os.path.exists("/usr/local/bin/redis-server"),
    cwd = "/usr/local/src",
    code = (
        "wget %(url)s\n"
        "tar -zxvf %(filename)s\n"
        "cd %(dirname)s\n"
        "make install\n") % dict(url=url, dirname=dirname, filename=filename))

Directory(env.config.redis.dbdir,
    owner = "root",
    group = "root",
    mode = 0700,
    recursive = True)

File("redis.conf",
    path = env.config.redis.configfile,
    owner = "root",
    group = "root",
    mode = 0644,
    content = Template("redis/redis.conf.j2"))

# env.cookbooks.monit.rc("redis",
#     content = Template("redis/monit.conf.j2"))

File("/etc/init.d/redis",
    owner = "root",
    group = "root",
    mode = 0755,
    content = Template("redis/init.conf.j2",
        variables = dict(
            redis = dict(
                logpath = os.path.dirname(env.config.redis.logfile),
                dbdir = env.config.redis.dbdir,
                configfile = env.config.redis.configfile,
                pidfile = env.config.redis.pidfile,
                options = [],
            ))))
    # notifies = [
    #     ("reload", env.resources["Service"]["redis"], True),
    # ])

Service("redis",
    subscribes = [
        ("restart", env.resources["Script"]["install-redis"]),
    ])

if "munin.node" in env.included_recipes:
    Package("redis",
        provider = "kokki.providers.package.easy_install.EasyInstallProvider")
    for n in ('active_connections', 'commands', 'connects', 'used_memory'):
        Link("/etc/munin/plugins/redis_%s" % n,
            to = "/etc/munin/python-munin/plugins/redis_%s" % n,
            notifies = [("restart", env.resources['Service']['munin-node'])])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "ServerDensity server monitoring"
__config__ = {
    "serverdensity.agent_key": dict(
        description = "Agent key",
        default = "key",
    ),
    "serverdensity.sd_url": dict(
        description = "Service url",
        default = "http://name.serverdensity.com",
    ),
    "serverdensity.plugin_directory": dict(
        description = "Path to plugins",
        default = "/etc/sd-agent/plugins",
    ),
    "serverdensity.configs": dict(
        description = "Dictionary of additional config variables for sd-agent",
        default = {},
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import File, Execute, Package, Directory, Service, Template, Fail

apt_list_path = '/etc/apt/sources.list.d/serverdensity.list'
apt = None
if env.system.platform == "ubuntu":
    ver = env.system.lsb['release']
    apt = "deb http://www.serverdensity.com/downloads/linux/debian lenny main"
    # if ver == "10.04":
    #     apt = "deb http://apt.librato.com/ubuntu/ lucid non-free"
elif env.system.platform == "debian":
    ver = env.system.lsb['release']
    apt = "deb http://www.serverdensity.com/downloads/linux/debian lenny main"
    # if ver == '5.0':
    #     apt = "deb http://apt.librato.com/debian/ lenny non-free"

if not apt:
    raise Fail("Can't find a serverdensity package for your platform/version")

Execute("apt-update-serverdensity",
    command = "apt-get update",
    action = "nothing")

Execute("curl http://www.serverdensity.com/downloads/boxedice-public.key | apt-key add -",
    not_if = "(apt-key list | grep 'Server Density' > /dev/null)")

File(apt_list_path,
    owner = "root",
    group ="root",
    mode = 0644,
    content = apt+"\n",
    notifies = [("run", env.resources["Execute"]["apt-update-serverdensity"], True)])

Package("sd-agent")

Directory(env.config.serverdensity.plugin_directory,
    owner = "sd-agent",
    group = "sd-agent",
    mode = 0770,
    recursive = True)

Service("sd-agent",
    supports_restart = True)

File("/etc/sd-agent/config.cfg",
    owner = "sd-agent",
    group = "sd-agent",
    mode = 0660,
    content = Template("serverdensity/config.cfg.j2"),
    notifies = [("restart", env.resources["Service"]["sd-agent"])])

########NEW FILE########
__FILENAME__ = config

from kokki import File, Template

def SSHConfig(name, hosts, mode=0600, **kwargs):
    File(name,
        mode = mode,
        content = Template("ssh/config.j2", {'hosts': hosts}),
        **kwargs)

########NEW FILE########
__FILENAME__ = providers

__all__ = ["SSHKnownHostProvider", "SSHAuthorizedKeyProvider"]

from kokki import Provider

class SSHKnownHostProvider(Provider):
    def action_include(self):
        hosts = self.resource.env.cookbooks.ssh.SSHKnownHostsFile(self.resource.path)
        modified = False
        for host in self.resource.host.split(','):
            if hosts.add_host(host, self.resource.keytype, self.resource.key, hashed=self.resource.hashed):
                modified = True
                self.log.info("[%s] Added host %s to known_hosts file %s" % (self, host, self.resource.path))
            else:
                self.log.debug("[%s] Host %s already in known_hosts file %s" % (self, host, self.resource.path))
        if modified:
            hosts.save(self.resource.path)
            self.resource.updated()

    def action_exclude(self):
        hosts = self.resource.env.cookbooks.ssh.SSHKnownHostsFile(self.resource.path)
        modified = False
        for host in self.resource.host.split(','):
            if hosts.remove_host(host):
                modified = True
                self.log.info("[%s] Removed host %s from known_hosts file %s" % (self, host, self.resource.path))
            else:
                self.log.debug("[%s] Host %s not found in known_hosts file %s" % (self, host, self.resource.path))
        if modified:
            hosts.save(self.resource.path)
            self.resource.updated()

class SSHAuthorizedKeyProvider(Provider):
    def action_include(self):
        keys = self.resource.env.cookbooks.ssh.SSHAuthorizedKeysFile(self.resource.path)
        if keys.add_key(self.resource.keytype, self.resource.key, self.resource.name):
            self.log.info("[%s] Added key to authorized_keys file %s" % (self, self.resource.path))
            keys.save(self.resource.path)
            self.resource.updated()
        else:
            self.log.debug("[%s] Key already in authorized_keys file %s" % (self, self.resource.path))

    def action_exclude(self):
        keys = self.resource.env.cookbooks.ssh.SSHAuthorizedKeysFile(self.resource.path)
        if keys.remove_key(self.resource.keytype, self.resource.key):
            self.log.info("[%s] Removed key from authorized_keys file %s" % (self, self.resource.path))
            keys.save(self.resource.path)
            self.resource.updated()
        else:
            self.log.debug("[%s] Key not found in authorized_keys file %s" % (self, self.resource.path))

########NEW FILE########
__FILENAME__ = resources

__all__ = ["SSHKnownHost", "SSHAuthorizedKey"]

import os.path
from kokki import Resource, ForcedListArgument, ResourceArgument, BooleanArgument, Fail

class SSHKnownHost(Resource):
    provider = "*ssh.SSHKnownHostProvider"

    action = ForcedListArgument(default="include")
    host = ResourceArgument(default=lambda obj:obj.name)
    keytype = ResourceArgument()
    key = ResourceArgument()
    hashed = BooleanArgument(default=True)
    user = ResourceArgument()
    path = ResourceArgument()

    actions = Resource.actions + ["include", "exclude"]

    def validate(self):
        if not self.path:
            if not self.user:
                raise Fail("[%s] Either path or user is required" % self)
            self.path = os.path.join(self.env.cookbooks.ssh.ssh_path_for_user(self.user), "known_hosts")

class SSHAuthorizedKey(Resource):
    provider = "*ssh.SSHAuthorizedKeyProvider"

    action = ForcedListArgument(default="include")
    keytype = ResourceArgument()
    key = ResourceArgument()
    user = ResourceArgument()
    path = ResourceArgument()

    actions = Resource.actions + ["include", "exclude"]

    def validate(self):
        if not self.path:
            if not self.user:
                raise Fail("[%s] Either path or user is required" % self)
            self.path = os.path.join(self.env.cookbooks.ssh.ssh_path_for_user(self.user), "authorized_keys")

########NEW FILE########
__FILENAME__ = utils

import hashlib
import hmac
import os
from base64 import b64decode, b64encode
from kokki import Fail, Environment

class SSHKnownHostsFile(object):
    def __init__(self, path=None):
        self.hosts = []
        self.parse(path)

    def parse(self, path):
        self.hosts = []
        with open(path, "r") as fp:
            for line in fp:
                line = line.strip()
                if not line:
                    continue

                addr, keytype, key = line.split(' ')
                if addr.startswith('|1|'):
                    # Hashed host entry
                    salt, hosthash = addr.split('|')[2:]
                    self.hosts.append((1, b64decode(salt), b64decode(hosthash), keytype, key))
                else:
                    # Unhashed
                    for a in addr.split(','):
                        self.hosts.append((0, a, keytype, key))

    def save(self, path):
        with open(path, "w") as fp:
            fp.write(str(self))

    def includes(self, host):
        host = host.lower()
        for h in self.hosts:
            if h[0] == 0:
                if h[1] == host:
                    return True
            elif h[0] == 1:
                hosthash = self.hash(host, h[1])[0]
                if hosthash == h[2]:
                    return  True
        return False

    def hash(self, host, salt=None):
        if not salt:
            salt = self.generate_salt()
        return hmac.new(salt, host, digestmod=hashlib.sha1).digest(), salt

    def generate_salt(self):
        return os.urandom(20)

    def add_host(self, host, keytype, key, hashed=True, verify=True):
        host = host.lower()
        if verify and self.includes(host):
            return False

        if hashed:
            hosthash, salt = self.hash(host)
            self.hosts.append((1, salt, hosthash, keytype, key))
        else:
            self.hosts.append((0, host, keytype, key))

        return True

    def remove_host(self, host):
        host = host.lower()
        new_hosts = []
        for h in self.hosts:
            if h[0] == 0:
                if h[1] == host:
                    continue
            elif h[0] == 1:
                hosthash = self.hash(host, h[1])[0]
                if hosthash == h[2]:
                    continue
            new_hosts.append(h)

        found = len(new_hosts) != len(self.hosts)
        self.hosts = new_hosts
        return found

    def __str__(self):
        out = []
        unhashed = {} # Group unhashed hosts by the key
        for h in self.hosts:
            if h[0] == 0:
                k = (h[2], h[3])
                if k not in unhashed:
                    unhashed[k] = [h[1]]
                else:
                    unhashed[k].append(h[1])
            elif h[0] == 1:
                out.append("|1|%s|%s %s %s" % (b64encode(h[1]), b64encode(h[2]), h[3], h[4]))
        for k, host in unhashed.items():
            out.append("%s %s %s" % (",".join(host), k[0], k[1]))
        out.append("")
        return "\n".join(out)

class SSHAuthorizedKeysFile(object):
    def __init__(self, path=None):
        self.keys = {}
        if path:
            self.parse(path)

    def parse(self, path):
        self.keys = {}
        try:
            with open(path, "r") as fp:
                for line in fp:
                    line = line.strip()
                    if not line:
                        continue

                    if line.startswith("command="):
                        # TODO: This is a bit of a hack.. not sure what else could be here
                        # TODO: Do something with cmd? It'll get overwritten
                        line = line[line.find("ssh-"):]
                    l = line.split(' ')
                    cmd = None
                    if len(l) == 3:
                        keytype, key, name = l
                    else:
                        keytype, key = l
                        name = ""
                    self.keys[(keytype, key)] = name
        except IOError as exc:
            if exc.errno != 2: # No such file
                raise

    def save(self, path):
        with open(path, "w") as fp:
            fp.write(str(self))

    def includes(self, keytype, key):
        return (keytype, key) in self.keys

    def add_key(self, keytype, key, name, verify=True):
        if verify and self.includes(keytype, key):
            return False

        self.keys[(keytype, key)] = name
        return True

    def remove_key(self, keytype, key):
        try:
            self.keys.pop((keytype, key))
        except KeyError:
            return False
        return True

    def __str__(self):
        out = []
        for k, name in self.keys.items():
            keytype, key = k
            out.append(" ".join((keytype, key, name)))
        out.append("")
        return "\n".join(out)

def ssh_path_for_user(user):
    env = Environment.get_instance()
    if env.system.os == "linux":
        if user == "root":
            return "/root/.ssh/"
        return "/home/%s/.ssh/" % user
    elif env.system.platform == "mac_os_x":
        return "/Users/%s/.ssh/" % user
    raise Fail("Unable to determine ssh path for user %s on os %s platform %s" % (user, env.system.os, env.system.platform))

########NEW FILE########
__FILENAME__ = metadata

__description__ = "SSH Service"
__config__ = {
    "sshd.allow_password_login_for_users": dict(
        description = "Allows password logins for the given users.",
        default = [],
    ),
    "sshd.password_authentication": dict(
        description = "Allow password authentication",
        default = False,
    ),
    "sshd.service_name": dict(
    	description = "Name of the ssh service",
    	default = None,
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Service, Package, File, Template

if env.system.os == "linux":
    Package("openssh-server", action="upgrade")
    Package("openssh-client", action="upgrade")

    if not env.config.sshd.service_name:
        if env.system.platform in ("redhat", "fedora", "centos", "amazon"):
            env.config.sshd.service_name = "sshd"
        else:
            env.config.sshd.service_name = "ssh"

    Service("ssh",
        service_name = env.config.sshd.service_name)

    File("sshd_config",
        path = "/etc/ssh/sshd_config",
        content = Template("ssh/sshd_config.j2"),
        mode = 0644,
        owner = "root",
        group = "root",
        notifies = [("restart", env.resources["Service"]["ssh"], True)]
    )
########NEW FILE########
__FILENAME__ = metadata

__config__ = {
    "sudo.users": dict(
        description = "Users who are allowed sudo ALL",
        default = [],
    ),
    "sudo.groups": dict(
        description = "Groups who are allowed sudo ALL",
        default = [],
    ),
}

########NEW FILE########
__FILENAME__ = default

from kokki import Package, File, Template

Package("sudo", action="upgrade")
File("/etc/sudoers",
    owner = "root",
    group = "root",
    mode = 0440,
    content = Template("sudo/sudoers.j2"),
)

########NEW FILE########
__FILENAME__ = config

import os
from kokki import Environment, File

def configuration(name, content):
    env = Environment.get_instance()
    return File("supervisor-%s" % name,
        content = content,
        owner = "root",
        group = "root",
        mode = 0644,
        path = os.path.join(env.config.supervisor.custom_config_path, name) + ".conf",
        notifies = [("reload", env.resources["Service"]["supervisor"])])

########NEW FILE########
__FILENAME__ = providers

import os
import re
import subprocess
from kokki import Provider, Fail

whitespace_re = re.compile(r'\s+')

class SupervisorServiceProvider(Provider):
    def action_start(self):
        if not self.status():
            self._init_cmd("start", 0)
            self.resource.updated()

    def action_stop(self):
        if self.status():
            self._init_cmd("stop", 0)
            self.resource.updated()

    def action_restart(self):
        self._init_cmd("restart", 0)
        self.resource.updated()

    def action_reload(self):
        self._init_cmd("update", 0)
        self.resource.updated()

    def status(self):
        p = subprocess.Popen([self.supervisorctl_path, "status"],
            stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        out = p.communicate()[0]
        for l in out.split('\n'):
            try:
                svc, status, info = whitespace_re.split(l.strip(), 2)
                service, process_name = svc.split(':')
            except ValueError:
                continue
            if service == self.resource.service_name:
                return status.strip() == "RUNNING"
        raise Fail("Service %s not managed by supervisor" % self.resource.service_name)

    def _init_cmd(self, command, expect=None):
        ret = subprocess.call([self.supervisorctl_path, command, self.resource.service_name],
            stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        if expect is not None and expect != ret:
            raise Fail("%r command %s for service %s failed" % (self, command, self.resource.service_name))
        return ret

    @property
    def supervisorctl_path(self):
        return os.path.join(self.resource.env.config.supervisor.binary_path, "supervisorctl")

########NEW FILE########
__FILENAME__ = resources

from kokki import Service, BooleanArgument

class SupervisorService(Service):
    provider = "*supervisor.SupervisorServiceProvider"

    supports_restart = BooleanArgument(default=True)
    supports_status = BooleanArgument(default=True)
    supports_reload = BooleanArgument(default=True)

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Process monitoring"
__config__ = {
    "supervisor.config_path": dict(
        description = "Config file path for supervisor",
        default = "/etc/supervisor/supervisord.conf",
    ),
    "supervisor.socket_path": dict(
        description = "Unix socket path",
        default = "/var/run/supervisor.sock",
    ),
    "supervisor.custom_config_path": dict(
        description = "Path to custom supervisor config files",
        default = "/etc/supervisor/conf.d", 
    ),
    "supervisor.binary_path": dict(
        description = "Path to the supervisor binaries",
        default = "/usr/bin",
    ),
    "supervisor.pidfile": dict(
        description = "Path to the supervisor pid file",
        default = "/var/run/supervisord.pid",
    ),
    "supervisor.logfile": dict(
        description = "Path to the supervisor log file",
        default = "/var/log/supervisord.log",
    ),
    "supervisor.childlogdir": dict(
        description = "Path where to place child log files",
        default = "/var/log/supervisor",
    ),
}

# if env.system.platform == "ubuntu":
#     env.supervisor.binary_path = "/usr/local/bin"
# else:
#     env.supervisor.binary_path = "/usr/bin"

########NEW FILE########
__FILENAME__ = default

import os
from kokki import Package, File, Directory, Service, Template, Link

# env.include_recipe("monit")

if env.system.platform == "ubuntu":
	Package("supervisor")
else:
	Package("supervisor",
		provider = "kokki.providers.package.easy_install.EasyInstallProvider")
	Directory(os.path.dirname(env.config.supervisor.config_path),
		action = "create")
	Directory(env.config.supervisor.custom_config_path,
		action = "create")
	Directory(os.path.dirname(env.config.supervisor.pidfile),
		action = "create")
	Directory(os.path.dirname(env.config.supervisor.logfile),
		action = "create")
	Directory(env.config.supervisor.childlogdir,
		action = "create")
	if env.config.supervisor.config_path != "/etc/supervisord.conf":
		Link("/etc/supervisord.conf",
			to = env.config.supervisor.config_path)

File("supervisord.conf",
    path = env.config.supervisor.config_path,
    content = Template("supervisor/supervisord.conf.j2"))

Directory("supervisor.d",
    path = env.config.supervisor.custom_config_path)

supervisorctl = os.path.join(env.config.supervisor.binary_path, "supervisorctl")
Service("supervisor",
    restart_command = "%s reload" % supervisorctl,
    reload_command = "%s update" % supervisorctl,
    subscribes = [("reload", env.resources["File"]["supervisord.conf"])])

#env.cookbooks.monit.rc("supervisord",
#    content = Template("supervisor/monit.conf.j2"))

#env.cookbooks.monit.MonitService("supervisord",
#    subscribes = [("restart", env.resources["File"]["supervisord.conf"])])

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Manage user accounts and sysadmins"
__config__ = {
    "users": dict(
        description = "Disctionary of sysadmins with username as the key and value as a dictionary of (id,sshkey_id,sshkey_type,sshkey)",
        default = {},
    )
}

########NEW FILE########
__FILENAME__ = default

import os.path
from kokki import Group, User, Directory, File

env.include_recipe("ssh")

Group("sysadmin",
    gid = 2300)

for username, user in env.config.users.items():
    home = "/home/%s" % username

    User(username,
        uid = user['id'],
        home = home,
        groups = user.get('groups', []),
        password = user.get('password'))

    Directory(env.cookbooks.ssh.ssh_path_for_user(username),
        owner = username,
        group = username,
        mode = 0700)

    if user.get('sshkey'):
        env.cookbooks.ssh.SSHAuthorizedKey("%s-%s" % (username, user['sshkey_id']),
            user = username,
            keytype = user['sshkey_type'],
            key = user['sshkey'])
        File(os.path.join(env.cookbooks.ssh.ssh_path_for_user(username), "authorized_keys"),
            owner = username,
            group = username,
            mode = 0600)

########NEW FILE########
__FILENAME__ = metadata

__description__ = "Zookeeper"
__config__ = {}

########NEW FILE########
__FILENAME__ = default

from kokki import Package

env.include_recipe("cloudera")

Package("hadoop-zookeeper")

########NEW FILE########
__FILENAME__ = server

from kokki import Package

env.include_recipe("zookeeper")

Package("hadoop-zookeeper-server")

########NEW FILE########
__FILENAME__ = environment
#!/usr/bin/env python

__all__ = ["Environment"]

import logging
import os
import shutil
import subprocess
from datetime import datetime

from kokki.exceptions import Fail
from kokki.providers import find_provider
from kokki.utils import AttributeDictionary
from kokki.system import System
from kokki.version import long_version

class Environment(object):
    _instances = []

    def __init__(self):
        self.log = logging.getLogger("kokki")
        self.reset()

    def reset(self):
        self.system = System.get_instance()
        self.config = AttributeDictionary()
        self.resources = {}
        self.resource_list = []
        self.delayed_actions = set()
        self.update_config({
            'date': datetime.now(),
            'kokki.long_version': long_version(),
            'kokki.backup.path': '/tmp/kokki/backup',
            'kokki.backup.prefix': datetime.now().strftime("%Y%m%d%H%M%S"),
        })

    def backup_file(self, path):
        if self.config.kokki.backup:
            if not os.path.exists(self.config.kokki.backup.path):
                os.makedirs(self.config.kokki.backup.path, 0700)
            new_name = self.config.kokki.backup.prefix + path.replace('/', '-')
            backup_path = os.path.join(self.config.kokki.backup.path, new_name)
            self.log.info("backing up %s to %s" % (path, backup_path))
            shutil.copy(path, backup_path)

    def update_config(self, attributes, overwrite=True):
        for key, value in attributes.items():
            attr = self.config
            path = key.split('.')
            for pth in path[:-1]:
                if pth not in attr:
                    attr[pth] = AttributeDictionary()
                attr = attr[pth]
            if overwrite or path[-1] not in attr:
                attr[path[-1]] = value

    def run_action(self, resource, action):
        self.log.debug("Performing action %s on %s" % (action, resource))

        provider_class = find_provider(self, resource.__class__.__name__, resource.provider)
        provider = provider_class(resource)
        try:
            provider_action = getattr(provider, 'action_%s' % action)
        except AttributeError:
            raise Fail("%r does not implement action %s" % (provider, action))
        provider_action()

        if resource.is_updated:
            for action, res in resource.subscriptions['immediate']:
                self.log.info("%s sending %s action to %s (immediate)" % (resource, action, res))
                self.run_action(res, action)
            for action, res in resource.subscriptions['delayed']:
                self.log.info("%s sending %s action to %s (delayed)" % (resource, action, res))
            self.delayed_actions |= resource.subscriptions['delayed']

    def _check_condition(self, cond):
        if hasattr(cond, '__call__'):
            return cond()

        if isinstance(cond, basestring):
            ret = subprocess.call(cond, shell=True)
            return ret == 0

        raise Exception("Unknown condition type %r" % cond)

    def run(self):
        with self:
            # Run resource actions
            for resource in self.resource_list:
                self.log.debug("Running resource %r" % resource)

                if resource.not_if is not None and self._check_condition(resource.not_if):
                    self.log.debug("Skipping %s due to not_if" % resource)
                    continue
 
                if resource.only_if is not None and not self._check_condition(resource.only_if):
                    self.log.debug("Skipping %s due to only_if" % resource)
                    continue

                for action in resource.action:
                    self.run_action(resource, action)

            # Run delayed actions
            while self.delayed_actions:
                action, resource = self.delayed_actions.pop()
                self.run_action(resource, action)

    @classmethod
    def get_instance(cls):
        return cls._instances[-1]

    def __enter__(self):
        self.__class__._instances.append(self)
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.__class__._instances.pop()
        return False

    def __getstate__(self):
        return dict(
            config = self.config,
            resources = self.resources,
            resource_list = self.resource_list,
            delayed_actions = self.delayed_actions,
        )

    def __setstate__(self, state):
        self.__init__()
        self.config = state['config']
        self.resources = state['resources']
        self.resource_list = state['resource_list']
        self.delayed_actions = state['delayed_actions']

########NEW FILE########
__FILENAME__ = exceptions

class Fail(Exception):
    pass

class InvalidArgument(Fail):
    pass

########NEW FILE########
__FILENAME__ = kitchen

__all__ = ["Kitchen", "Cookbook"]

import os
from kokki.environment import Environment
from kokki.exceptions import Fail
from kokki.system import System
from kokki.utils import AttributeDictionary

class Cookbook(object):
    def __init__(self, name, path, config=None):
        self.name = name
        self.path = path
        self._meta = None
        self._library = None

    @property
    def config(self):
        return self.meta.get('__config__', {})

    @property
    def loader(self):
        return self.meta.get('__loader__', lambda kit:None)

    @property
    def meta(self):
        if self._meta is None:
            metapath = os.path.join(self.path, "metadata.py")
            with open(metapath, "rb") as fp:
                source = fp.read()
            meta = {'system': System.get_instance()}
            exec compile(source, metapath, "exec") in meta
            self._meta = meta
        return self._meta

    @property
    def library(self):
        if self._library is None:
            libpath = os.path.join(self.path, "libraries")
            globs = {}

            if os.path.exists(libpath):
                for f in sorted(os.listdir(libpath)):
                    if not f.endswith('.py'):
                        continue

                    path = os.path.join(libpath, f)
                    with open(path, "rb") as fp:
                        source = fp.read()
                        exec compile(source, libpath, "exec") in globs
    
            self._library = AttributeDictionary(globs)
        return self._library

    def get_recipe(self, name):
        path = os.path.join(self.path, "recipes", name + ".py")
        if not os.path.exists(path):
            raise Fail("Recipe %s in cookbook %s not found" % (name, self.name))

        with open(path, "rb") as fp:
            return fp.read()

    def __getattr__(self, name):
        return self.library[name]

    @classmethod
    def load_from_path(cls, name, path):
        return cls(name, path)

    def __repr__(self):
        return str(self)

    def __unicode__(self):
        return u"Cookbook['%s']" % self.name

class Kitchen(Environment):
    def __init__(self):
        super(Kitchen, self).__init__()
        self.included_recipes_order = [] 
        self.included_recipes = {}
        self.sourced_recipes = set()
        self.cookbooks = AttributeDictionary()
        self.cookbook_paths = []
        self.running = False

    def add_cookbook_path(self, *args):
        for path in args:
            # Check if it's a Python import path
            origpath = path
            if "." in path and not os.path.exists(path):
                pkg = __import__(path, {}, {}, path)
                path = os.path.dirname(os.path.abspath(pkg.__file__))
            self.cookbook_paths.append((origpath, os.path.abspath(path)))

    def register_cookbook(self, cb):
        self.update_config(dict((k, v.get('default')) for k, v in cb.config.items()), False)
        self.cookbooks[cb.name] = cb

    def load_cookbook(self, *args, **kwargs):
        for name in args:
            cb = None
            for origpath, path in reversed(self.cookbook_paths):
                fullpath = os.path.join(path, name)
                if not os.path.exists(fullpath):
                    continue
                cb = Cookbook.load_from_path(name, fullpath)

            if not cb:
                raise ImportError("Cookbook %s not found" % name)

            self.register_cookbook(cb)

    def include_recipe(self, *args):
        for name in args:
            if name in self.included_recipes:
                continue

            self.included_recipes_order.append(name)

            try:
                cookbook, recipe = name.split('.')
            except ValueError:
                cookbook, recipe = name, "default"
            
            try:
                cb = self.cookbooks[cookbook]
            except KeyError:
                self.load_cookbook(cookbook)
                cb = self.cookbooks[cookbook]
                # raise Fail("Trying to include a recipe from an unknown cookbook %s" % name)

            self.included_recipes[name] = (cb, recipe)

            if self.running:
                self.source_recipe(cb, recipe)

    def source_recipe(self, cookbook, recipe):
        name = "%s.%s" % (cookbook.name, recipe)
        if name in self.sourced_recipes:
            return

        self.sourced_recipes.add(name)
        cookbook.loader(self)

        rc = cookbook.get_recipe(recipe)
        globs = {'env': self}
        with self:
            exec compile(rc, name, 'exec') in globs

    def prerun(self):
        for name in self.included_recipes_order:
            cookbook, recipe = self.included_recipes[name]
            self.source_recipe(cookbook, recipe)

    def run(self):
        self.running = True
        self.prerun()
        super(Kitchen, self).run()
        self.running = False

    def __getstate__(self):
        state = super(Kitchen, self).__getstate__()
        state.update(
            cookbook_paths = [x[0] for x in self.cookbook_paths],
            included_recipes = self.included_recipes_order,
        )
        return state

    def __setstate__(self, state):
        super(Kitchen, self).__setstate__(state)
        for path in state['cookbook_paths']:
            self.add_cookbook_path(path)
        for recipe in state['included_recipes']:
            self.include_recipe(recipe)

########NEW FILE########
__FILENAME__ = accounts

from __future__ import with_statement

import grp
import pwd
import subprocess
from kokki.providers import Provider

class UserProvider(Provider):
    def action_create(self):
        if not self.user:
            command = ['useradd', "-m"]

            useradd_options = dict(
                comment = "-c",
                gid = "-g",
                uid = "-u",
                shell = "-s",
                password = "-p",
                home = "-d",
            )

            if self.resource.system:
                command.append("--system")

            if self.resource.groups:
                command += ["-G", ",".join(self.resource.groups)]

            for option_name, option_flag in useradd_options.items():
                option_value = getattr(self.resource, option_name)
                if option_flag and option_value:
                    command += [option_flag, str(option_value)]

            command.append(self.resource.username)

            subprocess.check_call(command)
            self.resource.updated()
            self.log.info("Added user %s" % self.resource)

    def action_remove(self):
        if self.user:
            command = ['userdel', self.resource.username]
            subprocess.check_call(command)
            self.resource.updated()
            self.log.info("Removed user %s" % self.resource)

    @property
    def user(self):
        try:
            return pwd.getpwnam(self.resource.username)
        except KeyError:
            return None

class GroupProvider(Provider):
    def action_create(self):
        group = self.group
        if not group:
            command = ['groupadd']

            groupadd_options = dict(
                gid = "-g",
                password = "-p",
            )

            for option_name, option_flag in groupadd_options.items():
                option_value = getattr(self.resource, option_name)
                if option_flag and option_value:
                    command += [option_flag, str(option_value)]
                    
            command.append(self.resource.group_name)

            subprocess.check_call(command)
            self.resource.updated()
            self.log.info("Added group %s" % self.resource)

            group = self.group

        # if self.resource.members is not None:
        #     current_members = set(group.gr_mem)
        #     members = set(self.resource.members)
        #     for u in current_members - members:
        #         pass

    def action_remove(self):
        if self.user:
            command = ['groupdel', self.resource.group_name]
            subprocess.check_call(command)
            self.resource.updated()
            self.log.info("Removed group %s" % self.resource)

    @property
    def group(self):
        try:
            return grp.getgrnam(self.resource.group_name)
        except KeyError:
            return None

########NEW FILE########
__FILENAME__ = mount
from __future__ import with_statement

import os
import re
from subprocess import Popen, PIPE, STDOUT, check_call
from kokki.base import Fail
from kokki.providers import Provider

class MountProvider(Provider):
    def action_mount(self):
        if not os.path.exists(self.resource.mount_point):
            os.makedirs(self.resource.mount_point)

        if self.is_mounted():
            self.log.debug("%s already mounted" % self)
        else:
            args = ["mount"]
            if self.resource.fstype:
                args += ["-t", self.resource.fstype]
            if self.resource.options:
                args += ["-o", ",".join(self.resource.options)]
            if self.resource.device:
                args.append(self.resource.device)
            args.append(self.resource.mount_point)

            check_call(args)

            self.log.info("%s mounted" % self)
            self.resource.updated()

    def action_umount(self):
        if self.is_mounted():
            check_call(["umount", self.resource.mount_point])

            self.log.info("%s unmounted" % self)
            self.resource.updated()
        else:
            self.log.debug("%s is not mounted" % self)

    def action_enable(self):
        if self.is_enabled():
            self.log.debug("%s already enabled" % self)
        else:
            if not self.resource.device:
                raise Fail("[%s] device not set but required for enable action" % self)
            if not self.resource.fstype:
                raise Fail("[%s] fstype not set but required for enable action" % self)

            with open("/etc/fstab", "a") as fp:
                fp.write("%s %s %s %s %d %d\n" % (
                        self.resource.device,
                        self.resource.mount_point,
                        self.resource.fstype,
                        ",".join(self.resource.options or ["defaults"]),
                        self.resource.dump,
                        self.resource.passno,
                    ))

            self.log.info("%s enabled" % self)
            self.resource.updated()

    def action_disable(self):
        pass # TODO

    def is_mounted(self):
        if not os.path.exists(self.resource.mount_point):
            return False

        if self.resource.device and not os.path.exists(self.resource.device):
            raise Fail("%s Device %s does not exist" % (self, self.resource.device))

        mounts = self.get_mounted()
        for m in mounts:
            if m['mount_point'] == self.resource.mount_point:
                return True

        return False

    def is_enabled(self):
        mounts = self.get_fstab()
        for m in mounts:
            if m['mount_point'] == self.resource.mount_point:
                return True

        return False

    def get_mounted(self):
        p = Popen("mount", stdout=PIPE, stderr=STDOUT, shell=True)
        out = p.communicate()[0]
        if p.wait() != 0:
            raise Fail("[%s] Getting list of mounts (calling mount) failed" % self)

        mounts = [x.split(' ') for x in out.strip().split('\n')]

        return [dict(
                device = m[0],
                mount_point = m[2],
                fstype = m[4],
                options = m[5][1:-1].split(','),
            ) for m in mounts if m[1] == "on" and m[3] == "type"]

    def get_fstab(self):
        mounts = []
        with open("/etc/fstab", "r") as fp:
            for line in fp:
                line = line.split('#', 1)[0].strip()
                mount = re.split('\s+', line)
                if len(mount) == 6:
                    mounts.append(dict(
                        device = mount[0],
                        mount_point = mount[1],
                        fstype = mount[2],
                        options = mount[3].split(","),
                        dump = int(mount[4]),
                        passno = int(mount[5]),
                    ))
        return mounts

########NEW FILE########
__FILENAME__ = apt

import glob
import os
import shutil
import tempfile
from subprocess import Popen, STDOUT, PIPE, check_call, CalledProcessError
from kokki.base import Fail
from kokki.providers.package import PackageProvider


class DebianAptProvider(PackageProvider):
    def get_current_status(self):
        self.current_version = None
        self.candidate_version = None

        proc = Popen("apt-cache policy %s" % self.resource.package_name, shell=True, stdout=PIPE)
        out = proc.communicate()[0]
        for line in out.split("\n"):
            line = line.strip().split(':', 1)
            if len(line) != 2:
                continue

            ver = line[1].strip()
            if line[0] == "Installed":
                self.current_version = None if ver == '(none)' else ver
                self.log.debug("Current version of package %s is %s" % (self.resource.package_name, self.current_version))
            elif line[0] == "Candidate":
                self.candidate_version = ver

        if self.candidate_version == "(none)":
            raise Fail("APT does not provide a version of package %s" % self.resource.package_name)

    def install_package(self, name, version):
        if self.resource.build_vars:
            self._install_package_source(name, version)
        else:
            self._install_package_default(name, version)

    def _install_package_default(self, name, version):
        return 0 == check_call("DEBIAN_FRONTEND=noninteractive apt-get -q -y install %s=%s" % (name, version),
            shell=True, stdout=PIPE, stderr=STDOUT)
    
    def _install_package_source(self, name, version):
        build_vars = " ".join(self.resource.build_vars)
        run_check_call = lambda s, **kw: check_call(s, shell = True, stdout=PIPE, stderr=STDOUT, **kw)
        pkgdir = tempfile.mkdtemp(suffix = name)

        try:
            run_check_call("DEBIAN_FRONTEND=noninteractive apt-get -q -y install fakeroot")
            run_check_call("DEBIAN_FRONTEND=noninteractive apt-get -q -y build-dep %s=%s" % (name, version))
            run_check_call("DEBIAN_FRONTEND=noninteractive apt-get -q -y source %s=%s" % (name, version), cwd = pkgdir)

            try:
                builddir = [p for p in glob.iglob("%s/%s*" % (pkgdir, name)) if os.path.isdir(p)][0]
            except IndexError:
                raise Fail("Couldn't install %s from source: apt-get source created an unfamiliar directory structure." % name)

            run_check_call("%s fakeroot debian/rules binary > /dev/null" % build_vars, cwd = builddir)

            # NOTE: I can't figure out why this call returns non-zero sometimes, though everything seems to work.
            # Just ignoring checking for now.
            try:
                run_check_call("dpkg -i *.deb > /dev/null", cwd = pkgdir)
            except CalledProcessError:
                pass
        finally:
            shutil.rmtree(pkgdir)

        return True

    def remove_package(self, name):
        return 0 == check_call("DEBIAN_FRONTEND=noninteractive apt-get -q -y remove %s" % name,
            shell=True, stdout=PIPE, stderr=STDOUT)

    def purge_package(self, name):
        return 0 == check_call("DEBIAN_FRONTEND=noninteractive apt-get -q -y purge %s" % name,
            shell=True, stdout=PIPE, stderr=STDOUT)

    def upgrade_package(self, name, version):
        return self.install_package(name, version)

########NEW FILE########
__FILENAME__ = easy_install

import re
from subprocess import check_call, Popen, PIPE, STDOUT
from kokki.providers.package import PackageProvider

VERSION_RE = re.compile(r'\S\S(.*)\/(.*)-(.*)-py(.*).egg\S')
BEST_MATCH_RE = re.compile(r'Best match: (.*) (.*)\n')

class EasyInstallProvider(PackageProvider):
    def get_current_status(self):
        proc = Popen(["python", "-c", "import %s; print %s.__path__" % (self.resource.package_name, self.resource.package_name)], stdout=PIPE, stderr=STDOUT)
        path = proc.communicate()[0]
        if proc.wait() != 0:
            self.current_version = None
        else:
            match = VERSION_RE.search(path)
            if match:
                self.current_version = match.group(3)
            else:
                self.current_version = "unknown"

    @property
    def candidate_version(self):
        if not hasattr(self, '_candidate_version'):
            proc = Popen([self.easy_install_binary_path, "-n", self.resource.package_name], stdout=PIPE, stderr=STDOUT)
            out = proc.communicate()[0]
            res = proc.wait()
            if res != 0:
                self.log.warning("easy_install check returned a non-zero result (%d) %s" % (res, self.resource))
            #     self._candidate_version = None
            # else:
            match = BEST_MATCH_RE.search(out)
            if not match:
                self._candidate_version = None
            else:
                self._candidate_version = match.group(2)
        return self._candidate_version

    @property
    def easy_install_binary_path(self):
        return "easy_install"

    def install_package(self, name, version):
        check_call([self.easy_install_binary_path, "-U", "%s==%s" % (name, version)], stdout=PIPE, stderr=STDOUT)

    def upgrade_package(self, name, version):
        self.install_package(name, version)

    def remove_package(self, name):
        check_call([self.easy_install_binary_path, "-m", name])

    def purge_package(self, name):
        self.remove_package(name)

########NEW FILE########
__FILENAME__ = emerge

from subprocess import Popen, STDOUT, PIPE, check_call
from kokki.base import Fail
from kokki.providers.package import PackageProvider

class GentooEmergeProvider(PackageProvider):
    def get_current_status(self):
        self.current_version = None
        self.candidate_version = None

        proc = Popen("qlist --installed --exact --verbose --nocolor %s"
                  % self.resource.package_name, shell=True, stdout=PIPE)
        out = proc.communicate()[0]
        for line in out.split("\n"):
            line = line.split('/', 1)
            if len(line) != 2:
                continue
            _category, nameversion = line
            _name, version = nameversion.split('-', 1)
            self.current_version = version
            self.log.debug("Current version of package %s is %s",
                           self.resource.package_name, self.current_version)

        proc = Popen("emerge --pretend --quiet --color n %s" % self.resource.package_name, shell=True, stdout=PIPE)
        out = proc.communicate()[0]
        for line in out.split("\n"):
            line = line.strip(' [').split(']', 1)
            if len(line) != 2:
                continue

            # kind, flag = line[0].split()
            _category, nameversion = line[1].split('/', 1)
            _name, version = nameversion.split('-', 1)
            self.candidate_version = version
            self.log.debug("Candidate version of package %s is %s",
                            self.resource.package_name, self.candidate_version)

        if self.candidate_version is None:
            raise Fail("emerge does not provide a version of package %s" % self.resource.package_name)

    def install_package(self, name, version):
        return 0 == check_call("emerge --color n =%s-%s" % (name, version),
            shell=True, stdout=PIPE, stderr=STDOUT)

    def upgrade_package(self, name, version):
        return self.install_package(name, version)

########NEW FILE########
__FILENAME__ = yumrpm

from kokki.providers.package import PackageProvider
import yum


class DummyCallback(object):
    def event(self, state, data=None):
        pass


class YumProvider(PackageProvider):
    def get_current_status(self):
        self.candidate_version = None
        self.current_version = None
        yb = yum.YumBase()
        yb.doConfigSetup()
        yb.doTsSetup()
        yb.doRpmDBSetup()
        for pkg in yb.rpmdb.returnPackages():
            if pkg.name == self.resource.package_name:
                self.current_version = pkg.version
                self.log.debug("Current version of %s is %s" % (self.resource.package_name, self.current_version))
        searchlist = ['name', 'version']
        args = [self.resource.package_name]
        matching = yb.searchPackages(searchlist, args)
        for po in matching:
            if po.name == self.resource.package_name:
                self.candidate_version = po.version
                self.log.debug("Candidate version of %s is %s" % (self.resource.package_name, self.current_version))
    
    def install_package(self, name, version):
        yb = yum.YumBase()
        yb.doGenericSetup()
        yb.doRepoSetup()
        #TODO: Handle locks not being available
        yb.doLock()
        yb.install(pattern=name)
        yb.buildTransaction()
        #yb.conf.setattr('assumeyes',True)
        yb.processTransaction(callback=DummyCallback())
        yb.closeRpmDB()
        yb.doUnlock()
    
    def upgrade_package(self, name, version):
        return self.install_package(name, version)

########NEW FILE########
__FILENAME__ = debian

__all__ = ["DebianServiceProvider"]

from kokki.providers.service import ServiceProvider

class DebianServiceProvider(ServiceProvider):
    def enable_runlevel(self, runlevel):
        pass

########NEW FILE########
__FILENAME__ = gentoo

__all__ = ["GentooServiceProvider"]

from kokki.providers.service import ServiceProvider

class GentooServiceProvider(ServiceProvider):
    def enable_runlevel(self, runlevel):
        pass

########NEW FILE########
__FILENAME__ = redhat

__all__ = ["RedhatServiceProvider"]

from kokki.providers.service import ServiceProvider

class RedhatServiceProvider(ServiceProvider):
    def enable_runlevel(self, runlevel):
        pass

########NEW FILE########
__FILENAME__ = system

from __future__ import with_statement

import grp
import os
import pwd
import subprocess
from kokki.base import Fail
from kokki.providers import Provider

def _coerce_uid(user):
    try:
        uid = int(user)
    except ValueError:
        uid = pwd.getpwnam(user).pw_uid
    return uid
    
def _coerce_gid(group):
    try:
        gid = int(group)
    except ValueError:
        gid = grp.getgrnam(group).gr_gid 
    return gid

def _ensure_metadata(path, user, group, mode = None, log = None):
    stat = os.stat(path)
    updated = False

    if mode:
        existing_mode = stat.st_mode & 07777
        if existing_mode != mode:
            log and log.info("Changing permission for %s from %o to %o" % (path, existing_mode, mode))
            os.chmod(path, mode)
            updated = True

    if user:
        uid = _coerce_uid(user)
        if stat.st_uid != uid:
            log and log.info("Changing owner for %s from %d to %s" % (path, stat.st_uid, user))
            os.chown(path, uid, -1)
            updated = True

    if group:
        gid = _coerce_gid(group)
        if stat.st_gid != gid:
            log and log.info("Changing group for %s from %d to %s" % (path, stat.st_gid, group))
            os.chown(path, -1, gid)
            updated = True

    return updated
    

class FileProvider(Provider):
    def action_create(self):
        path = self.resource.path
        write = False
        content = self._get_content()
        if not os.path.exists(path):
            write = True
            reason = "it doesn't exist"
        else:
            if content is not None:
                with open(path, "rb") as fp:
                    old_content = fp.read()
                if content != old_content:
                    write = True
                    reason = "contents don't match"
                    self.resource.env.backup_file(path)

        if write:
            self.log.info("Writing %s because %s" % (self.resource, reason))
            with open(path, "wb") as fp:
                if content:
                    fp.write(content)
            self.resource.updated()

        if _ensure_metadata(self.resource.path, self.resource.owner, self.resource.group, mode = self.resource.mode, log = self.log):
            self.resource.updated()

    def action_delete(self):
        path = self.resource.path
        if os.path.exists(path):
            self.log.info("Deleting %s" % self.resource)
            os.unlink(path)
            self.resource.updated()

    def action_touch(self):
        path = self.resource.path
        with open(path, "a"):
            pass

    def _get_content(self):
        content = self.resource.content
        if content is None:
            return None
        elif isinstance(content, basestring):
            return content
        elif hasattr(content, "__call__"):
            return content()
        raise Fail("Unknown source type for %s: %r" % (self, content))


class DirectoryProvider(Provider):
    def action_create(self):
        path = self.resource.path
        if not os.path.exists(path):
            self.log.info("Creating directory %s" % self.resource)
            if self.resource.recursive:
                os.makedirs(path, self.resource.mode or 0755)
            else:
                os.mkdir(path, self.resource.mode or 0755)
            self.resource.updated()

        if _ensure_metadata(path, self.resource.owner, self.resource.group, mode = self.resource.mode, log = self.log):
            self.resource.updated()

    def action_delete(self):
        path = self.resource.path
        if os.path.exists(path):
            self.log.info("Removing directory %s" % self.resource)
            os.rmdir(path)
            # TODO: recursive
            self.resource.updated()


class LinkProvider(Provider):
    def action_create(self):
        path = self.resource.path

        if os.path.lexists(path):
            oldpath = os.path.realpath(path)
            if oldpath == self.resource.to:
                return
            if not os.path.islink(path):
                raise Fail("%s trying to create a symlink with the same name as an existing file or directory" % self)
            self.log.info("%s replacing old symlink to %s" % (self, oldpath))
            os.unlink(path)

        if self.resource.hard:
            self.log.info("Creating hard %s" % self.resource)
            os.link(self.resource.to, path)
            self.resource.updated()
        else:
            self.log.info("Creating symbolic %s" % self.resource)
            os.symlink(self.resource.to, path)
            self.resource.updated()

    def action_delete(self):
        path = self.resource.path
        if os.path.exists(path):
            self.log.info("Deleting %s" % self.resource)
            os.unlink(path)
            self.resource.updated()


def _preexec_fn(resource):
    def preexec():
        if resource.group:
            gid = _coerce_gid(resource.group)
            os.setgid(gid)
            os.setegid(gid)
        if resource.user:
            uid = _coerce_uid(resource.user)
            os.setuid(uid)
            os.seteuid(uid)
    return preexec


class ExecuteProvider(Provider):
    def action_run(self):
        if self.resource.creates:
            if os.path.exists(self.resource.creates):
                return

        self.log.info("Executing %s" % self.resource)

        ret = subprocess.call(self.resource.command, shell=True, cwd=self.resource.cwd, env=self.resource.environment, preexec_fn=_preexec_fn(self.resource))

        if self.resource.returns and ret not in self.resource.returns:
            raise Fail("%s failed, returned %d instead of %s" % (self, ret, self.resource.returns))
        self.resource.updated()

class ScriptProvider(Provider):
    def action_run(self):
        from tempfile import NamedTemporaryFile
        self.log.info("Running script %s" % self.resource)
        with NamedTemporaryFile(prefix="kokki-script", bufsize=0) as tf:
            tf.write(self.resource.code)
            tf.flush()

            _ensure_metadata(tf.name, self.resource.user, self.resource.group)
            subprocess.call([self.resource.interpreter, tf.name], cwd=self.resource.cwd, env=self.resource.environment, preexec_fn=_preexec_fn(self.resource))
        self.resource.updated()

########NEW FILE########
__FILENAME__ = accounts

__all__ = ["Group", "User"]

from kokki.base import Resource, ForcedListArgument, ResourceArgument, BooleanArgument

class Group(Resource):
    action = ForcedListArgument(default="create")
    group_name = ResourceArgument(default=lambda obj:obj.name)
    gid = ResourceArgument()
    members = ForcedListArgument()
    password = ResourceArgument()
    # append = BooleanArgument(default=False) # NOT SUPPORTED

    actions = Resource.actions + ["create", "remove", "modify", "manage", "lock", "unlock"]

class User(Resource):
    action = ForcedListArgument(default="create")
    username = ResourceArgument(default=lambda obj:obj.name)
    comment = ResourceArgument()
    uid = ResourceArgument()
    gid = ResourceArgument()
    groups = ForcedListArgument() # supplementary groups
    home = ResourceArgument()
    shell = ResourceArgument(default="/bin/bash")
    password = ResourceArgument()
    system = BooleanArgument(default=False)

    actions = Resource.actions + ["create", "remove", "modify", "manage", "lock", "unlock"]

########NEW FILE########
__FILENAME__ = packaging

__all__ = ["Package"]

from kokki.base import Resource, ForcedListArgument, ResourceArgument

class Package(Resource):
    action = ForcedListArgument(default="install")
    package_name = ResourceArgument(default=lambda obj:obj.name)
    location = ResourceArgument(default=lambda obj:obj.package_name)
    version = ResourceArgument()
    actions = ["install", "upgrade", "remove", "purge"]
    build_vars = ForcedListArgument(default=[])

########NEW FILE########
__FILENAME__ = service

__all__ = ["Service"]

from kokki.base import Resource, ResourceArgument, BooleanArgument

class Service(Resource):
    service_name = ResourceArgument(default=lambda obj:obj.name)
    enabled = ResourceArgument()
    running = ResourceArgument()
    pattern = ResourceArgument()
    start_command = ResourceArgument()
    stop_command = ResourceArgument()
    restart_command = ResourceArgument()
    reload_command = ResourceArgument()
    status_command = ResourceArgument()
    supports_restart = BooleanArgument(default=lambda obj:bool(obj.restart_command))
    supports_reload = BooleanArgument(default=lambda obj:bool(obj.reload_command))
    supports_status = BooleanArgument(default=lambda obj:bool(obj.status_command))

    actions = ["nothing", "start", "stop", "restart", "reload"]

########NEW FILE########
__FILENAME__ = system

__all__ = ["File", "Directory", "Link", "Execute", "Script", "Mount"]

from kokki.base import Resource, ForcedListArgument, ResourceArgument, BooleanArgument

class File(Resource):
    action = ForcedListArgument(default="create")
    path = ResourceArgument(default=lambda obj:obj.name)
    backup = ResourceArgument()
    mode = ResourceArgument()
    owner = ResourceArgument()
    group = ResourceArgument()
    content = ResourceArgument()

    actions = Resource.actions + ["create", "delete", "touch"]

class Directory(Resource):
    action = ForcedListArgument(default="create")
    path = ResourceArgument(default=lambda obj:obj.name)
    mode = ResourceArgument()
    owner = ResourceArgument()
    group = ResourceArgument()
    recursive = BooleanArgument(default=False)

    actions = Resource.actions + ["create", "delete"]

class Link(Resource):
    action = ForcedListArgument(default="create")
    path = ResourceArgument(default=lambda obj:obj.name)
    to = ResourceArgument(required=True)
    hard = BooleanArgument(default=False)

    actions = Resource.actions + ["create", "delete"]

class Execute(Resource):
    action = ForcedListArgument(default="run")
    command = ResourceArgument(default=lambda obj:obj.name)
    creates = ResourceArgument()
    cwd = ResourceArgument()
    environment = ResourceArgument()
    user = ResourceArgument()
    group = ResourceArgument()
    returns = ForcedListArgument(default=0)
    timeout = ResourceArgument()

    actions = Resource.actions + ["run"]

class Script(Resource):
    action = ForcedListArgument(default="run")
    code = ResourceArgument(required=True)
    cwd = ResourceArgument()
    environment = ResourceArgument()
    interpreter = ResourceArgument(default="/bin/bash")
    user = ResourceArgument()
    group = ResourceArgument()

    actions = Resource.actions + ["run"]

class Mount(Resource):
    action = ForcedListArgument(default="mount")
    mount_point = ResourceArgument(default=lambda obj:obj.name) 
    device = ResourceArgument()
    fstype = ResourceArgument()
    options = ResourceArgument(default=["defaults"])
    dump = ResourceArgument(default=0)
    passno = ResourceArgument(default=2)

    actions = Resource.actions + ["mount", "umount", "remount", "enable", "disable"]

########NEW FILE########
__FILENAME__ = source

from __future__ import with_statement

__all__ = ["Source", "Template", "StaticFile", "DownloadSource"]

import hashlib
import os
import urllib2
import urlparse
from kokki import environment
from kokki.exceptions import Fail

class Source(object):
    def get_content(self):
        raise NotImplementedError()

    def get_checksum(self):
        return None

    def __call__(self):
        return self.get_content()

class StaticFile(Source):
    def __init__(self, name, env=None):
        self.name = name
        self.env = env or environment.Environment.get_instance()

    def get_content(self):
        try:
            cookbook, name = self.name.split('/', 1)
        except ValueError:
            raise Fail("[StaticFile(%s)] Path must include cookbook name (e.g. 'nginx/nginx.conf')" % self.name)
        cb = self.env.cookbooks[cookbook]
        path = os.path.join(cb.path, "files", name)
        with open(path, "rb") as fp:
            return fp.read()

try:
    from jinja2 import Environment, BaseLoader, TemplateNotFound
except ImportError:
    class Template(Source):
        def __init__(self, name, variables=None, env=None):
            raise Exception("Jinja2 required for Template")
else:
    class TemplateLoader(BaseLoader):
        def __init__(self, env=None):
            self.env = env or environment.Environment.get_instance()

        def get_source(self, environment, template):
            try:
                cookbook, name = template.split('/', 1)
            except ValueError:
                raise Fail("[Template(%s)] Path must include cookbook name (e.g. 'nginx/nginx.conf.j2')" % template)
            cb = self.env.cookbooks[cookbook]
            path = os.path.join(cb.path, "templates", name)
            if not os.path.exists(path):
                raise TemplateNotFound("%s at %s" % (template, path))
            mtime = os.path.getmtime(path)
            with open(path, "rb") as fp:
                source = fp.read().decode('utf-8')
            return source, path, lambda:mtime == os.path.getmtime(path)

    class Template(Source):
        def __init__(self, name, variables=None, env=None):
            self.name = name
            self.env = env or environment.Environment.get_instance()
            self.context = variables.copy() if variables else {}
            self.template_env = Environment(loader=TemplateLoader(self.env), autoescape=False)
            self.template = self.template_env.get_template(self.name)

        def get_content(self):
            self.context.update(
                env = self.env,
                repr = repr,
                str = str,
                bool = bool,
            )
            rendered = self.template.render(self.context)
            return rendered + "\n" if not rendered.endswith('\n') else rendered

class DownloadSource(Source):
    def __init__(self, url, cache=True, md5sum=None, env=None):
        self.env = env or environment.Environment.get_instance()
        self.url = url
        self.md5sum = md5sum
        self.cache = cache
        if not 'download_path' in env.config:
            env.config.download_path = '/var/tmp/downloads'
        if not os.path.exists(env.config.download_path):
            os.makedirs(self.env.config.download_path)

    def get_content(self):
        filepath = os.path.basename(urlparse.urlparse(self.url).path)
        content = None
        if not self.cache or not os.path.exists(os.path.join(self.env.config.download_path, filepath)):
            web_file = urllib2.urlopen(self.url)
            content = web_file.read()
        else:
            update = False
            with open(os.path.join(self.env.config.download_path, filepath)) as fp:
                content = fp.read()
            if self.md5sum:
                m = hashlib.md5(content)
                md5 = m.hexdigest()
                if md5 != self.md5sum:
                    web_file = urllib2.urlopen(self.url)
                    content = web_file.read()
                    update = True
            if self.cache and update:
                with open(os.path.join(self.env.config.download_path, filepath), 'w') as fp:
                    fp.write(content)
        return content

########NEW FILE########
__FILENAME__ = system

__all__ = ["System"]

import os
import sys
from functools import wraps
from subprocess import Popen, PIPE

def lazy_property(undecorated):
    name = '_' + undecorated.__name__
    @property
    @wraps(undecorated)
    def decorated(self):
        try:
            return getattr(self, name)
        except AttributeError:
            v = undecorated(self)
            setattr(self, name, v)
            return v
    return decorated

class System(object):
    @lazy_property
    def os(self):
        platform = sys.platform
        if platform.startswith('linux'):
            return "linux"
        elif platform == "darwin":
            return "darwin"
        else:
            return "unknown"

    def unquote(self, val):
        if val[0] == '"':
            val = val[1:-1]
        return val

    @lazy_property
    def arch(self):
        machine = self.machine
        if machine in ("i386", "i486", "i686"):
            return "x86_32"
        return machine

    @lazy_property
    def machine(self):
        p = Popen(["/bin/uname", "-m"], stdout=PIPE, stderr=PIPE)
        return p.communicate()[0].strip()

    @lazy_property
    def lsb(self):
        if os.path.exists("/etc/lsb-release"):
            with open("/etc/lsb-release", "rb") as fp:
                lsb = (x.split('=') for x in fp.read().strip().split('\n'))
            return dict((k.split('_', 1)[-1].lower(), self.unquote(v)) for k, v in lsb)
        elif os.path.exists("/usr/bin/lsb_release"):
            p = Popen(["/usr/bin/lsb_release","-a"], stdout=PIPE, stderr=PIPE)
            lsb = {}
            for l in p.communicate()[0].split('\n'):
                v = l.split(':', 1)
                if len(v) != 2:
                    continue
                lsb[v[0].strip().lower()] = self.unquote(v[1].strip().lower())
            lsb['id'] = lsb.pop('distributor id')
            return lsb

    @lazy_property
    def platform(self):
        operatingsystem = self.os
        if operatingsystem == "linux":
            lsb = self.lsb
            if not lsb:
                if os.path.exists("/etc/redhat-release"):
                    return "redhat"
                if os.path.exists("/etc/fedora-release"):
                    return "fedora"
                if os.path.exists("/etc/debian_version"):
                    return "debian"
                if os.path.exists("/etc/gentoo-release"):
                    return "gentoo"
                if os.path.exists("/etc/system-release"):
                    with open("/etc/system-release", "rb") as fp:
                        release = fp.read()
                    if "Amazon Linux" in release:
                        return "amazon"
                return "unknown"
            return lsb['id'].lower()
        elif operatingsystem == "darwin":
            out = Popen("/usr/bin/sw_vers", stdout=PIPE).communicate()[0]
            sw_vers = dict([y.strip() for y in x.split(':', 1)] for x in out.strip().split('\n'))
            # ProductName, ProductVersion, BuildVersion
            return sw_vers['ProductName'].lower().replace(' ', '_')
        else:
            return "unknown"

    @lazy_property
    def locales(self):
        p = Popen("locale -a", shell=True, stdout=PIPE)
        out = p.communicate()[0]
        return out.strip().split("\n")

    @lazy_property
    def ec2(self):
        if not os.path.exists("/proc/xen"):
            return False
        if os.path.exists("/etc/ec2_version"):
            return True
        return False

    @lazy_property
    def vm(self):
        if os.path.exists("/usr/bin/VBoxControl"):
            return "vbox"
        elif os.path.exists("/usr/bin/vmware-toolbox-cmd") or os.path.exists("/usr/sbin/vmware-toolbox-cmd"):
            return "vmware"
        elif os.path.exists("/proc/xen"):
            return "xen"
        return None

    @classmethod
    def get_instance(cls):
        try:
            return cls._instance
        except AttributeError:
            cls._instance = cls()
        return cls._instance

########NEW FILE########
__FILENAME__ = utils

class AttributeDictionary(object):
    def __init__(self, *args, **kwargs):
        d = kwargs
        if args:
            d = args[0]
        super(AttributeDictionary, self).__setattr__("_dict", d)

    def __setattr__(self, name, value):
        self[name] = value

    def __getattr__(self, name):
        if name in self.__dict__:
            return self.__dict__[name]
        try:
            return self[name]
        except KeyError:
            raise AttributeError("'%s' object has no attribute '%s'" % (self.__class__.__name__, name))

    def __setitem__(self, name, value):
        self._dict[name] = self._convert_value(value)

    def __getitem__(self, name):
        return self._convert_value(self._dict[name])

    def _convert_value(self, value):
        if isinstance(value, dict) and not isinstance(value, AttributeDictionary):
            return AttributeDictionary(value)
        return value

    def copy(self):
        return self.__class__(self._dict.copy())

    def update(self, *args, **kwargs):
        self._dict.update(*args, **kwargs)

    def items(self):
        return self._dict.items()

    def values(self):
        return self._dict.values()

    def keys(self):
        return self._dict.keys()

    def pop(self, *args, **kwargs):
        return self._dict.pop(*args, **kwargs)

    def get(self, *args, **kwargs):
        return self._dict.get(*args, **kwargs)

    def __repr__(self):
        return self._dict.__repr__()

    def __unicode__(self):
        return self._dict.__unicode__()

    def __str__(self):
        return self._dict.__str__()

    def __iter__(self):
        return self._dict.__iter__()

    def __getstate__(self):
        return self._dict

    def __setstate__(self, state):
        super(AttributeDictionary, self).__setattr__("_dict", state)

########NEW FILE########
__FILENAME__ = version
VERSION = "0.4.1"

# August 9, 2010 -- ss -- made a long version to use in generated files
# TODO: make a switch to control generation of "long banners" in generated
#       files.  I like to have this info when i go back to a system after a
#       while but don't want to have to hand-code globs of stuff into every
#       template.  The switch will control how much information is automatically
#       inserted at the top of every file.
LONG_VERSION = "Kokki version %s : http://github.com/samuel/kokki" % VERSION

def version():
    return VERSION

def long_version():
    return LONG_VERSION

########NEW FILE########
__FILENAME__ = blah

from kokki import *

def tester():
    print "FEWFEWFEW"

########NEW FILE########
__FILENAME__ = metadata

__config__ = {
    "test.config1": dict(
        default = "fu",
    ),
    "test.config2": dict(
        default = "manchu",
    ),
}
__description__ = "This is a test cookbooks"

########NEW FILE########
__FILENAME__ = default

from kokki import *

# File("/tmp/kokki-test",
#     content = StaticFile("test/static.txt"))
#     # content = Template("test/test.j2"))

env._test = env.config.test.config2

########NEW FILE########
