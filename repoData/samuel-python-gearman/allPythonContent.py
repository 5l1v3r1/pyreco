__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# python-gearman documentation build configuration file, created by
# sphinx-quickstart on Mon Jul 27 14:30:15 2009.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.append(os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.todo']
try:
    from github.tools import sphinx
except ImportError:
    pass
else:
    extensions.append('github.tools.sphinx')

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'python-gearman'
copyright = u'2009, Samuel Stauffer'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '1.3.2'
# The full version, including alpha/beta/rc tags.
release = '1.3.2'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
#unused_docs = []

# List of directories, relative to source directory, that shouldn't be searched
# for source files.
exclude_trees = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  Major themes that come with
# Sphinx are currently 'default' and 'sphinxdoc'.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = [] # ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_use_modindex = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = ''

# Output file base name for HTML help builder.
htmlhelp_basename = 'python-gearmandoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'python-gearman.tex', u'python-gearman Documentation',
   u'Samuel Stauffer', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_use_modindex = True

########NEW FILE########
__FILENAME__ = client
#!/usr/bin/env python

import time, select, errno

from gearman.compat import *
from gearman.connection import GearmanConnection
from gearman.task import Task, Taskset

class GearmanBaseClient(object):
    class ServerUnavailable(Exception):
        pass
    class CommandError(Exception):
        pass
    class InvalidResponse(Exception):
        pass

    def __init__(self, job_servers, prefix=None, pre_connect=False):
        """
        job_servers = ['host:post', 'host', ...]
        """
        self.prefix = prefix and "%s\t" % prefix or ""
        self.set_job_servers(job_servers, pre_connect)

    def set_job_servers(self, servers, pre_connect=False):
        # TODO: don't shut down dups. shut down old ones gracefully
        self.connections = []
        self.connections_by_hostport = {}
        for serv in servers:
            connection = GearmanConnection(serv,timeout=2)
            if pre_connect:
                try:
                    connection.connect()
                except connection.ConnectionError:
                    pass
            self.connections.append(connection)
            self.connections_by_hostport[connection.hostspec] = connection

class GearmanClient(GearmanBaseClient):
    class TaskFailed(Exception):
        pass

    def __call__(self, func, arg, uniq=None, **kwargs):
        return self.do_task(Task(func, arg, uniq, **kwargs))

    def do_task(self, task):
        """Return the result of the task or raise a TaskFailed exception on failure."""
        def _on_fail():
            raise self.TaskFailed("Task failed")
        task.on_fail.append(_on_fail)
        taskset = Taskset([task])
        if not self.do_taskset(taskset, timeout=task.timeout):
            raise self.TaskFailed("Task timeout")
        return task.result

    def dispatch_background_task(self, func, arg, uniq=None, high_priority=False):
        """Submit a background task and return its handle."""
        task = Task(func, arg, uniq, background=True, high_priority=high_priority)
        taskset = Taskset([task])
        self.do_taskset(taskset)
        return task.handle

    def get_server_from_hash(self, hsh):
        """Return a live connection for the given hash"""
        # TODO: instead of cycling through, should we shuffle the list if the first connection fails or is dead?
        first_idx = hsh % len(self.connections)
        all_dead = all(conn.is_dead for conn in self.connections)
        for idx in range(first_idx, len(self.connections)) + range(0, first_idx):
            conn = self.connections[idx]

            # if all of the connections are dead we should try reconnecting
            if conn.is_dead and not all_dead:
                continue

            try:
                conn.connect() # Make sure the connection is up (noop if already connected)
            except conn.ConnectionError:
                pass
            else:
                return conn

        raise self.ServerUnavailable("Unable to Locate Server")

    def _submit_task(self, task):
        server = self.get_server_from_hash(hash(task))
        if task.background:
            func = "submit_job_bg"
        elif task.high_priority:
            func = "submit_job_high"
        else:
            func = "submit_job"
        server.send_command(func,
            dict(func=self.prefix + task.func, arg=task.arg, uniq=task.uniq))
        server.waiting_for_handles.insert(0, task)
        return server

    def _command_handler(self, taskset, conn, cmd, args):
        # DEBUG and _D( "RECEIVED COMMAND:", cmd, args )

        handle = ('handle' in args) and ("%s//%s" % (conn.hostspec, args['handle'])) or None

        if cmd != 'job_created' and handle:
            task = taskset.get( taskset.handles.get(handle, None), None)
            if not task:
                return
            if task.is_finished:
                raise self.InvalidResponse("Task %s received %s" % (repr(task), cmd))

        if cmd == 'work_complete':
            task.complete(args['result'])
        elif cmd == 'work_fail':
            if task.retries_done < task.retry_count:
                task.retries_done += 1
                task.retrying()
                task.handle = None
                taskset.connections.add(self._submit_task(task))
            else:
                task.fail()
        elif cmd == 'work_status':
            task.status(int(args['numerator']), int(args['denominator']))
        elif cmd == 'job_created':
            task = conn.waiting_for_handles.pop()
            task.handle = handle
            taskset.handles[handle] = hash( task )
            if task.background:
                task.is_finished = True
        elif cmd == 'error':
            raise self.CommandError(str(args)) # TODO make better
        else:
            raise Exception("Unexpected command: %s" % cmd)

    def do_taskset(self, taskset, timeout=None):
        """Execute a Taskset and return True iff all tasks finished before timeout."""

        # set of connections to which jobs were submitted
        taskset.connections = set(self._submit_task(task) for task in taskset.itervalues())

        taskset.handles = {}

        start_time = time.time()
        end_time = timeout and start_time + timeout or 0
        while not taskset.cancelled and not all(t.is_finished for t in taskset.itervalues()):
            timeleft = timeout and end_time - time.time() or 0.5
            if timeleft <= 0:
                taskset.cancel()
                break

            rx_socks = [c for c in taskset.connections if c.readable()]
            tx_socks = [c for c in taskset.connections if c.writable()]
            try:
                rd_list, wr_list, ex_list = select.select(rx_socks, tx_socks, taskset.connections, timeleft)
            except select.error, exc:
                # Ignore interrupted system call, reraise anything else
                if exc[0] != errno.EINTR:
                    raise
                continue

            for conn in ex_list:
                pass # TODO

            for conn in rd_list:
                for cmd in conn.recv():
                    self._command_handler(taskset, conn, *cmd)

            for conn in wr_list:
                conn.send()

        # TODO: should we fail all tasks that didn't finish or leave that up to the caller?

        return all(t.is_finished for t in taskset.itervalues())

    def get_status(self, handle):
        hostport, shandle = handle.split("//")

        server = self.connections_by_hostport[hostport]
        server.connect() # Make sure the connection is up (noop if already connected)
        server.send_command("get_status", dict(handle=shandle))
        return server.recv_blocking()[1]

########NEW FILE########
__FILENAME__ = compat
"""Compatability with older Python releases"""

try:
    all # Python 2.5
except NameError:
    def all(values):
        for val in values:
            if not val:
                return False
        return True

########NEW FILE########
__FILENAME__ = connection
import socket, struct, select, errno, logging
from time import time

from gearman.protocol import DEFAULT_PORT, pack_command, parse_command

log = logging.getLogger("gearman")

class GearmanConnection(object):
    class ConnectionError(Exception):
        pass

    def __init__(self, host, port=DEFAULT_PORT, sock=None, timeout=None, reconnect_timeout=60*2):
        """
        A connection to a Gearman server.
        """
        if not sock:
            self.sock = None
            self.connected = False
        else:
            self.sock = sock
            self.connected = True

        if ':' in host:
            host, port = (host.split(':') + [0])[:2]
            port = int(port) or DEFAULT_PORT
            self.addr = (host, port)
        else:
            port = port or DEFAULT_PORT
            self.addr = (host, port)
        self.hostspec = "%s:%d" % (host, port)
        self.timeout  = timeout
        self.reconnect_timeout = reconnect_timeout

        self.is_dead = False
        self._reset_queues()

    def _reset_queues(self):
        self.in_buffer = ""
        self.out_buffer = ""
        self.waiting_for_handles = []

    def fileno(self):
        return self.sock.fileno()

    def writable(self):
        return self.connected and len(self.out_buffer) != 0

    def readable(self):
        return self.connected

    def connect(self):
        """Connect to the server. Raise ConnectionError if connection fails."""

        if self.connected:
            return

        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.settimeout(self.timeout)
        try:
            self.sock.connect(self.addr)
        except (socket.error, socket.timeout), exc:
            self.sock = None
            self.is_dead = True
            raise self.ConnectionError(str(exc))

        self._reset_queues()
        self.is_dead = False
        self.connected = True
        self.sock.setblocking(0)
        self.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, struct.pack("L", 1))

    def is_dead():
        def fget(self):
            if self._is_dead and time() >= self._retry_at:
                self._is_dead = False
                # try:
                #     self.connect()
                # except self.ConnectionError:
                #     pass
            return self._is_dead
        def fset(self, value):
            self._is_dead = value
            self._retry_at = value and time() + self.reconnect_timeout or None
        return locals()
    is_dead = property(**is_dead())

    def recv(self, size=4096):
        """
        Returns a list of commands: [(cmd_name, cmd_args), ...]
        Raises ConnectionError if the connection dies.
            or ProtocolError if parsing of a command fails.
        """

        assert self.connected

        data = ''
        try:
            data = self.sock.recv(size)
        except socket.error, exc:
            if exc.args[0] == errno.EWOULDBLOCK:
                return
            if exc.args[0] == errno.ECONNRESET:
                data = None
            else:
                raise

        if not data:
            self.mark_dead()
            raise self.ConnectionError("connection died")

        self.in_buffer += data

        commands = []
        while len(self.in_buffer) >= 12:
            func, args, cmd_len = parse_command(self.in_buffer)
            if not cmd_len:
                break

            commands.append((func, args))

            self.in_buffer = buffer(self.in_buffer, cmd_len)
        return commands

    def send(self):
        assert self.connected

        if len(self.out_buffer) == 0:
            return 0

        try:
            nsent = self.sock.send(self.out_buffer)
        except socket.error, exc:
            if exc.args[0] == errno.EWOULDBLOCK:
                return len(self.out_buffer)
            self.mark_dead()
            raise self.ConnectionError(str(exc))

        self.out_buffer = buffer(self.out_buffer, nsent)

        return len(self.out_buffer)

    def send_command(self, name, kwargs={}):
        pkt = pack_command(name, **kwargs)
        self.out_buffer += pkt
        self.send()

    def flush(self, timeout=None): # TODO: handle connection failures
        while self.writable():
            try:
                wr_list = select.select([], [self], [], timeout)[1] # TODO: exc list
            except select.error, exc:
                # Ignore interrupted system call, reraise anything else
                if exc[0] != 4:
                    raise
            if self in wr_list:
                self.send()

    def send_command_blocking(self, cmd_name, cmd_args={}, timeout=None):
        self.send_command(cmd_name, cmd_args)
        self.flush(timeout)

    def recv_blocking(self, timeout=None):
        if not hasattr(self, '_command_queue'):
            self._command_queue = []

        if timeout:
            end_time = time() + timeout

        while not self._command_queue:
            time_left = max(0, timeout and end_time - time() or 0.5)

            try:
                rd_list, wr_list, ex_list = select.select([self], self.writable() and [self] or [], [self], time_left)
            except select.error, exc:
                # Ignore interrupted system call, reraise anything else
                if exc[0] != 4:
                    raise
                rd_list = wr_list = ex_list = []

            if self in ex_list:
                self.mark_dead()
                raise self.ConnectionError("connection died")

            if self in rd_list:
                for cmd in self.recv():
                    self._command_queue.insert(0, cmd)

            if self in wr_list:
                self.send()

            if time_left <= 0:
                break

        if self._command_queue:
            return self._command_queue.pop()
        return None

    def close(self):
        self.connected = False
        try:
            self.sock.close()
        except:
            pass
        self.sock = None

    def mark_dead(self):
        self.close()
        self.is_dead = True

    def __repr__(self):
        return ("<GearmanConnection %s:%d connected=%s dead=%s>" %
            (self.addr[0], self.addr[1], self.connected, self.is_dead))

########NEW FILE########
__FILENAME__ = manager
#!/usr/bin/env python

import socket

from gearman.connection import DEFAULT_PORT, GearmanConnection

ConnectionError = GearmanConnection.ConnectionError

class GearmanManager(object):
    def __init__(self, server, timeout=5):
        if ':' in server:
            host, port = (server.split(':') + [0])[:2]
            port = int(port) or DEFAULT_PORT
            self.addr = (host, port)
        else:
            self.addr = (server, DEFAULT_PORT)

        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.sock.settimeout(timeout)
        try:
            self.sock.connect(self.addr)
        except (socket.error, socket.timeout), exc:
            raise ConnectionError(str(exc))

    def send_command(self, name, reslist=False):
        self.sock.sendall("%s\n" % name)
        buf = ""
        while True:
            buf += self.sock.recv(4096)
            if not reslist:
                if '\n' in buf:
                    return buf.split('\n')[0]
            elif '\n.\n' in buf:
                return buf.split('\n')[:-2]

    def maxqueue(self, func, max_size):
        return self.send_command("maxqueue %s %s" % (func, max_size)) == "OK"

    def status(self):
        status = (s.rsplit('\t', 3) for s in self.send_command("status", True))
        return dict(
            (s[0], {'queued':int(s[1]), 'running':int(s[2]), 'workers':int(s[3])})
            for s in status)

    def shutdown(self, graceful):
        return self.send_command(graceful and "shutdown graceful" or "shutdown") == "OK"

    def version(self):
        return self.send_command("version")

    def workers(self):
        workers = (w.split(' ') for w in self.send_command("workers", True))
        return [
            {
                'fd': int(w[0]),
                'ip': w[1],
                'id': w[2] != '-' and w[2] or None,
                'functions': [x for x in w[4:] if x]
            } for w in workers]

########NEW FILE########
__FILENAME__ = protocol
import re
import struct

DEFAULT_PORT = 4730

COMMANDS = {
     1: ("can_do", ["func"]),
    23: ("can_do_timeout", ["func", "timeout"]),
     2: ("cant_do", ["func"]),
     3: ("reset_abilities", []),
    22: ("set_client_id", ["client_id"]),
     4: ("pre_sleep", []),

     6: ("noop", []),
     7: ("submit_job", ["func", "uniq", "arg"]),
    21: ("submit_job_high", ["func", "uniq", "arg"]),
    18: ("submit_job_bg", ["func", "uniq", "arg"]),

     8: ("job_created", ["handle"]),
     9: ("grab_job", []),
    10: ("no_job", []),
    11: ("job_assign", ["handle", "func", "arg"]),

    12: ("work_status", ["handle", "numerator", "denominator"]),
    13: ("work_complete", ["handle", "result"]),
    14: ("work_fail", ["handle"]),

    15: ("get_status", ["handle"]),
    20: ("status_res", ["handle", "known", "running", "numerator", "denominator"]),

    16: ("echo_req", ["text"]),
    17: ("echo_res", ["text"]),

    19: ("error", ["err_code", "err_text"]),

    24: ("all_yours", []),
}
# Create a mapping of function name -> id, args
R_COMMANDS = dict((m[0], (mid, m[1])) for mid, m in COMMANDS.iteritems())

txt_command_re = re.compile("^[\w\n\r]+")

class ProtocolError(Exception):
    pass

def parse_command(data, response=True):
    """Parse data and return (function name, argument dict, command size)
    or (None, None, data) if there's not enough data for a complete command.
    """
    data_len = len(data)

    if data_len < 4:
        return None, None, 0

    if response:
        expected_magic = "\x00RES"
    else:
        expected_magic = "\x00REQ"

    magic = data[:4]
    if magic == expected_magic:
        if data_len >= 12:
            magic, typ, cmd_len = struct.unpack("!4sLL", data[0:12])
            if data_len < 12 + cmd_len:
                return None, None, 0
        else:
            return None, None, 0
    elif txt_command_re.match(data):
        if '\n' in data:
            cmd, data = data.split('\n', 1)
            return cmd.strip(), data, len(cmd)+1
        return None, None, 0
    else:
        raise ProtocolError("Malformed Magic")


    msg_spec = COMMANDS.get(typ, None)
    if not msg_spec:
        raise ProtocolError("Unknown message received: %d" % typ)

    nargs = len(msg_spec[1])
    data = (nargs > 0) and data[12:12 + cmd_len].split('\x00', nargs-1) or []
    if len(data) != nargs:
        raise ProtocolError("Received wrong number of arguments to %s" % msg_spec[0])

    kwargs = dict(
        ((msg_spec[1][i], data[i]) for i in range(nargs))
    )

    return msg_spec[0], kwargs, 12 + cmd_len

def pack_command(name, response=False, **kwargs):
    msg = R_COMMANDS[name]
    data = []
    for k in msg[1]:
        v = kwargs.get(k, "")
        if v is None:
            v = ""
        data.append(str(v))
    data = "\x00".join(data)
    if response:
        magic = "\x00RES"
    else:
        magic = "\x00REQ"
    return "%s%s" % (struct.pack("!4sII", magic, msg[0], len(data)), data)

########NEW FILE########
__FILENAME__ = server

import logging
import random
import time
import asyncore
import socket
from collections import deque
from gearman.protocol import DEFAULT_PORT, ProtocolError, parse_command, pack_command

class GearmanServerClient(asyncore.dispatcher):
    def __init__(self, sock, addr, server, manager):
        asyncore.dispatcher.__init__(self, sock)
        self.addr = addr
        self.server = server
        self.manager = manager
        self.in_buffer = ""
        self.out_buffer = ""
        manager.register_client(self)

    def writable(self):
        return len(self.out_buffer) != 0

    def handle_close(self):
        self.close()
        self.manager.deregister_client(self)

    def handle_read(self):
        data = self.recv(8192)
        if not data:
            self.close()
            return

        self.in_buffer += data

        commands = []
        while True:
            try:
                func, args, cmd_len = parse_command(self.in_buffer, response=False)
            except ProtocolError, exc:
                logging.error("[%s] ProtocolError: %s" % (self.addr, str(exc)))
                self.close()
                return

            if not func:
                break

            self.handle_command(func, args)

            self.in_buffer = buffer(self.in_buffer, cmd_len)

    def handle_command(self, func, args):
        if func == "echo_req":
            self.send_command("echo_res", args)
        elif func == "submit_job":
            handle = self.manager.add_job(self, **args)
            self.send_command("job_created", {'handle': handle})
        elif func == "submit_job_high":
            handle = self.manager.add_job(self, high=True, **args)
            self.send_command("job_created", {'handle': handle})
        elif func == "submit_job_bg":
            handle = self.manager.add_job(self, bg=True, **args)
            self.send_command("job_created", {'handle': handle})
        elif func in ("can_do", "can_do_timeout"):
            self.manager.can_do(self, **args)
        elif func == "cant_do":
            self.manager.cant_do(self, **args)
        elif func == "grab_job":
            job = self.manager.grab_job(self)
            if job:
                self.send_command("job_assign", {'handle':job.handle, 'func':job.func, 'arg':job.arg})
            else:
                self.send_command("no_job")
        elif func == "pre_sleep":
            if not self.manager.sleep(self):
                self.wakeup()
        elif func == "work_complete":
            self.manager.work_complete(self, **args)
        elif func == "work_fail":
            self.manager.work_fail(self, **args)
        # Text commands
        elif func == "status":
            status = self.manager.get_status(self)
            for s in status:
                self.send_buffered("%s\t%d\t%d\t%d\n" % (s['func'], s['num_jobs'], s['num_working'], s['num_workers']))
            self.send_buffered(".\n")
        elif func == "version":
            from gearman import __version__
            self.send_buffered("%s\n" % __version__)
        elif func == "workers":
            for client, state in self.manager.states.items():
                # if not state.abilities:
                #     continue
                self.send_buffered("%d %s %s : %s\n" % (client.socket.fileno(), client.addr[0], state.client_id, " ".join(state.abilities)))
            self.send_buffered(".\n")
        # elif func == "maxqueue":
        # 
        #     This sets the maximum queue size for a function. If no size is
        #     given, the default is used. If the size is negative, then the queue
        #     is set to be unlimited. This sends back a single line with "OK".
        # 
        #     Arguments:
        #     - Function name.
        #     - Optional maximum queue size.
        # 
        elif func == "shutdown":
            # TODO: optional "graceful" argument - close listening socket and let all existing connections complete
            self.server.stop()
        else:
            logging.error("Unhandled command %s: %s" % (func, args))

    def handle_write(self):
        if len(self.out_buffer) == 0:
            return 0

        try:
            nsent = self.send(self.out_buffer)
        except socket.error, e:
            self.close()
            return

        self.out_buffer = buffer(self.out_buffer, nsent)

    def send_buffered(self, data):
        self.out_buffer += data

    def send_command(self, name, kwargs={}):
        self.send_buffered(pack_command(name, response=True, **kwargs))

    def wakeup(self):
        self.send_command('noop')

    def work_complete(self, handle, result):
        self.send_command('work_complete', {'handle':handle, 'result':result})

    def work_fail(self, handle):
        self.send_command('work_fail', {'handle':handle})

class Job(object):
    def __init__(self, owner, handle, func, arg, bg=False, high=False, uniq=None):
        self.owner = owner
        self.handle = handle
        self.func = func
        self.arg = arg
        self.bg = bg
        self.high = high
        self.uniq = uniq
        self.worker = None
        self.timeout = None

class ClientState(object):
    def __init__(self, client):
        self.client = client
        self.sleeping = False
        self.client_id = "-"
        # Clients
        self.jobs = []
        # Workers
        self.abilities = {}
        self.working = []

class GearmanTaskManager(object):
    def __init__(self):
        self.max_id = 0
        self.states = {}     # {client: ClientState}
        self.jobqueue = {}   # {function, [job]}
        self.jobs = {}       # {handle: job}
        self.uniq_jobs = {}  # {function: {uniq: job}}
        self.workers = {}    # {function: [state]}
        self.working = set() # set([job])

    def add_job(self, client, func, arg, uniq=None, high=False, bg=False):
        state = self.states[client]
        job = Job(state, self.new_handle(), func=func, arg=arg, uniq=uniq, high=False, bg=False)
        state.jobs.append(job)
        if func not in self.jobqueue:
            self.jobqueue[func] = deque([job])
        else:
            self.jobqueue[func].append(job)
        self.jobs[job.handle] = job
        workers = self.workers.get(func, [])
        for w in workers:
            if w.sleeping:
                w.client.wakeup()
        return job.handle

    def can_do(self, client, func, timeout=None):
        state = self.states[client]
        state.abilities[func] = int(timeout) if timeout else None

        if func not in self.workers:
            self.workers[func] = set((state,))
        else:
            self.workers[func].add(state)

    def cant_do(self, client, func):
        state = self.states[client]
        state.abilities.pop(func, None)
        self.workers[func].pop(state, None)

    def grab_job(self, client, grab=True):
        state = self.states[client]
        abilities = state.abilities.keys()
        random.shuffle(abilities)
        for f in abilities:
            jobs = self.jobqueue.get(f)
            if jobs:
                if not grab:
                    return True

                job = jobs.popleft()
                job.worker = state
                timeout = state.abilities[f]
                job.timeout = time.time() + timeout if timeout else None
                self.working.add(job)
                state.working.append(job)
                return job
                
        return None

    def sleep(self, client):
        has_job = self.grab_job(client, False)
        if has_job:
            return False
        state = self.states[client]
        state.sleeping = True
        return True

    def work_complete(self, client, handle, result):
        job = self.jobs[handle]
        job.owner.client.work_complete(handle, result)
        self._remove_job(job)

    def work_fail(self, client, handle):
        job = self.jobs[handle]
        job.owner.client.work_fail(handle)
        self._remove_job(job)

    def _remove_job(self, job):
        job.owner.jobs.remove(job)
        job.worker.working.remove(job)
        self.working.discard(job)

    def get_status(self, client):
        funcs = set(self.workers.keys()) | set(self.jobqueue.keys())
        status = []
        for f in sorted(funcs):
            workers = self.workers.get(f, [])
            num_workers = len(workers)
            num_working = len(self.working)
            num_jobs = num_working + len(self.jobs.get(f, []))
            status.append(dict(
                func = f,
                num_jobs = num_jobs,
                num_working = num_working,
                num_workers = num_workers,
            ))
        return status

    def check_timeouts(self):
        now = time.time()
        to_fail = []
        for job in self.working:
            if job.timeout and job.timeout < now:
                to_fail.append(job.handle)
        for handle in to_fail:
            self.work_fail(None, handle)

    def register_client(self, client):
        self.states[client] = ClientState(client)

    def deregister_client(self, client):
        state = self.states[client]
        del self.states[client]

        for f in state.abilities:
            self.workers[f].remove(state)

        for j in state.jobs:
            del self.jobs[j.handle]
            self.jobqueue[j.func].remove(j)

    def new_handle(self):
        self.max_id += 1
        return str(self.max_id)

class GearmanServer(asyncore.dispatcher):
    def __init__(self, host="127.0.0.1", port=DEFAULT_PORT):
        asyncore.dispatcher.__init__(self)
        self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
        self.set_reuse_addr()
        self.bind((host, port))
        self.listen(5)
        self.manager = GearmanTaskManager()

    def handle_accept(self):
        sock, addr = self.accept()
        GearmanServerClient(sock, addr, self, self.manager)

    def start(self):
        self.running = True
        while self.running:
            asyncore.loop(timeout=1, use_poll=False, count=1)
            self.manager.check_timeouts()

    def stop(self):
        self.running = False

########NEW FILE########
__FILENAME__ = task
import random
import uuid

# Constant that indicates to gearmand the task should be interpeted as unique iff the arg matches.
UNIQ_DATA_CHAR = '-'

class Task(object):
    hooks = ('on_complete', 'on_fail', 'on_retry', 'on_status', 'on_post')

    def __init__(self, func, arg, uniq=None, background=False, high_priority=False,
                 timeout=None, retry_count=0, **kwargs):
        """Build a task
        
            Arguments
                func - (string) Name of the function this task should execute
                arg - (string) Arguments to the function
                uniq - How should this Task be collated together on the remote side ?
                        None - (default) all tasks are unique
                        True - Task should be treated as unique based on the data
                        False - All tasks of the same function should be collated together
                        <string> - All tasks of this name should be collated together
                      Really only applies to background tasks.
                background - (bool) Indicates the task should be executed in the background and the client should return right away.
                high_priority - (bool) Put into high priority queue (only useful if some tasks of this functiona are not)
                timeout - (integer, seconds) How long should we wait for the task to complete
                retry_count - (integer) How many times to retry the task after failing.
        """
        for hook in self.hooks:
            setattr(self, hook, hook in kwargs and [kwargs[hook]] or [])

        self.func          = func
        self.arg           = arg
        self.background    = background
        self.high_priority = high_priority
        self.timeout       = timeout
        self.retry_count   = retry_count

        if uniq is None:
            self.uniq = uuid.uuid1().hex
        elif uniq is True:
            self.uniq = UNIQ_DATA_CHAR
        elif uniq is False:
            self.uniq = None
        else:
            self.uniq = uniq

        self.retries_done = 0
        self.is_finished  = False
        self.handle       = None
        self.result       = None
        self._hash        = hash(self.func + ((self.uniq == UNIQ_DATA_CHAR and self.arg) or self.uniq or str(random.randint(0, 999999))))

    def __hash__(self):
        return self._hash

    def merge_hooks(self, task2):
        for hook in self.hooks:
            getattr(self, hook).extend(getattr(task2, hook))

    def complete(self, result):
        """Mark the job as completed and call on_complete hooks."""
        self.result = result
        for func in self.on_complete:
            func(result)
        self._finished()

    def fail(self):
        """Mark the job as failed and call on_fail hooks."""
        for func in self.on_fail:
            func()
        self._finished()

    def status(self, numerator, denominator):
        """Call on_status hooks"""
        for func in self.on_status:
            func(numerator, denominator)

    def retrying(self):
        """Call on_retry hooks"""
        for func in self.on_retry:
            func()

    def _finished(self):
        """Mark the job as finished and call on_post hooks."""
        self.is_finished = True
        for func in self.on_post:
            func()
        for hook in self.hooks:
            delattr(self, hook) # TODO: perhaps should just clear the lists?

    def __repr__(self):
        return "<Task func='%s'>" % self.func

class Taskset(dict):
    """
    A Taskset is a group of tasks that are to be run all at once. The
    benefit of using a Taskset is allowing multiple tasks to run
    in parallel.
    """

    def __init__(self, tasks=[]):
        super(Taskset, self).__init__((hash(t), t) for t in tasks)
        self.cancelled = False

    def add(self, task):
        self[hash(task)] = task

    def add_task(self, *args, **kwargs):
        self.add(Task(*args, **kwargs))

    def cancel(self):
        self.cancelled = True

    def __or__(self, taskset2):
        for task_hash, task in taskset2.iteritems():
            if task_hash in self:
                self[task_hash].merge_hooks(task)
            else:
                self[task_hash] = task # TODO: should clone the task rather than just making a reference
        return self

########NEW FILE########
__FILENAME__ = util
#!/usr/bin/env python

"""
Geraman Client Utils
"""

########NEW FILE########
__FILENAME__ = worker
import random, sys, select, logging
from time import time

from gearman.compat import *
from gearman.client import GearmanBaseClient

log = logging.getLogger("gearman")

class GearmanJob(object):
    def __init__(self, conn, func, arg, handle):
        self.func = func
        self.arg = arg
        self.handle = handle
        self.conn = conn

    def status(self, numerator, denominator):
        self.conn.send_command_blocking("work_status", dict(handle=self.handle, numerator=numerator, denominator=denominator))

    def complete(self, result):
        self.conn.send_command_blocking("work_complete", dict(handle=self.handle, result=result))

    def fail(self):
        self.conn.send_command_blocking("work_fail", dict(handle=self.handle))

    def __repr__(self):
        return "<GearmanJob func=%s arg=%s handle=%s conn=%s>" % (self.func, self.arg, self.handle, repr(self.conn))

class GearmanWorker(GearmanBaseClient):
    def __init__(self, *args, **kwargs):
        super(GearmanWorker, self).__init__(*args, **kwargs)
        self.abilities = {}

    def register_function(self, name, func, timeout=None):
        """Register a function with gearman with an optional default timeout.
        """
        name = self.prefix + name
        self.abilities[name] = (func, timeout)

    def register_class(self, clas, name=None, decorator=None):
        """Register all the methods of a class or instance object with
        with gearman.
        
        'name' is an optional prefix for function names (name.method_name)
        """
        obj = clas
        if not isinstance(clas, type):
            clas = clas.__class__
        name = name or getattr(obj, 'name', clas.__name__)
        for k in clas.__dict__:
            v = getattr(obj, k)
            if callable(v) and k[0] != '_':
                if decorator:
                    v = decorator(v)
                self.register_function("%s.%s" % (name, k), v)

    def _can_do(self, connection, name, timeout=None):
        cmd_name = (timeout is None) and "can_do" or "can_do_timeout"
        cmd_args = (timeout is None) and dict(func=name) or dict(func=name, timeout=timeout)
        connection.send_command(cmd_name, cmd_args)

    def _set_abilities(self, conn):
        for name, args in self.abilities.iteritems():
            self._can_do(conn, name, args[1])

    @property
    def alive_connections(self):
        """Return a shuffled list of connections that are alive,
        and try to reconnect to dead connections if necessary."""
        random.shuffle(self.connections)
        all_dead = all(conn.is_dead for conn in self.connections)
        alive = []
        for conn in self.connections:
            if not conn.connected and (not conn.is_dead or all_dead):
                try:
                    conn.connect()
                except conn.ConnectionError:
                    continue
                else:
                    conn.sleeping = False
                    self._set_abilities(conn)
            if conn.connected:
                alive.append(conn)
        return alive

    def stop(self):
        self.working = False

    def _work_connection(self, conn, hooks=None):
        conn.send_command("grab_job")
        cmd = ('noop',)
        while cmd and cmd[0] == 'noop':
            cmd = conn.recv_blocking(timeout=0.5)

        if not cmd or cmd[0] == 'no_job':
            return False

        if cmd[0] != "job_assign":
            if cmd[0] == "error":
                log.error("Error from server: %s: %s" % (cmd[1]['err_code'], cmd[1]['err_text']))
            else:
                log.error("Was expecting job_assigned or no_job, received %s" % cmd[0])
            conn.mark_dead()
            return False

        job = GearmanJob(conn, **cmd[1])
        try:
            func = self.abilities[cmd[1]['func']][0]
        except KeyError:
            log.error("Received work for unknown function %s" % cmd[1])
            return True

        if hooks:
            hooks.start(job)
        try:
            result = func(job)
        except Exception:
            if hooks:
                hooks.fail(job, sys.exc_info())
            job.fail()
        else:
            if hooks:
                hooks.complete(job, result)
            job.complete(result)

        return True

    def work(self, stop_if=None, hooks=None):
        """Loop indefinitely working tasks from all connections."""
        self.working = True
        stop_if = stop_if or (lambda *a, **kw:False)
        last_job_time = time()
        while self.working:
            need_sleep = True

            # Try to grab work from all alive connections
            for conn in self.alive_connections:
                if conn.sleeping:
                    continue

                try:
                    worked = self._work_connection(conn, hooks)
                except conn.ConnectionError, exc:
                    log.error("ConnectionError on %s: %s" % (conn, exc))
                else:
                    if worked:
                        last_job_time = time()
                        need_sleep = False

            # If no tasks were handled then sleep and wait for the server
            # to wake us with a 'noop'
            is_idle = False
            if need_sleep:
                is_idle = True
                alive = self.alive_connections
                for conn in alive:
                    if not conn.sleeping:
                        conn.send_command("pre_sleep")
                        conn.sleeping = True
                try:
                    rd, wr, ex = select.select([c for c in alive if c.readable()], [], alive, 10)
                except select.error, e:
                    # Ignore interrupted system call, reraise anything else
                    if e[0] != 4:
                        raise
                else:
                    is_idle = not bool(rd)

                    for c in ex:
                        log.error("Exception on connection %s" % c)
                        c.mark_dead()

                    for c in rd:
                        c.sleeping = False

            if stop_if(is_idle, last_job_time):
                self.working = False

########NEW FILE########
__FILENAME__ = _twisted
#!/usr/bin/env python

from __future__ import with_statement

import time, select, errno

from gearman.compat import *
from gearman.connection import GearmanConnection
from gearman.task import Task, Taskset
from gearman.client import GearmanClient

from twisted.internet import abstract, defer, reactor

class _ConnectionWrapper(abstract.FileDescriptor):
    def __init__(self, conn, onRead, *args, **kwargs):
        abstract.FileDescriptor.__init__(self, *args, **kwargs)
        self.conn = conn
        self.onRead = onRead
        self.reading = False
        self.writing = False

    def startReading(self):
        if not self.reading:
            reactor.addReader(self)
            self.reading = True

    def stopReading(self):
        if self.reading:
            reactor.removeReader(self)
            self.reading = False

    def startWriting(self):
        if not self.writing:
            reactor.addWriter(self)
            self.writing = True

    def stopWriting(self):
        if self.writing:
            reactor.removeWriter(self)
            self.writing = False

    def setState(self):
        if self.conn.readable():
            self.startReading()
        else:
            self.stopReading()
        if self.conn.writable():
            self.startWriting()
        else:
            self.stopWriting()    

    def __enter__(self):
        self.setState()

    def __exit__(self, type, value, traceback):
        self.stopReading()
        self.stopWriting()

    def doWrite(self):
        self.conn.send()
        self.setState()

    def doRead(self):
        for cmd in self.conn.recv():
            self.onRead(*cmd)
        self.setState()

    def fileno(self):
        return self.conn.fileno()

class Client(GearmanClient):
    @defer.inlineCallbacks
    def do_task(self, task):
        """Return the result of the task or raise a TaskFailed exception on failure."""

        rtn = defer.Deferred()

        def _on_fail():
            rtn.errback(self.TaskFailed("Task failed"))

        task.on_fail.append(_on_fail)
        task.on_complete.append(rtn.callback)

        taskset = Taskset([task])
        taskset.handles = {}
        
        c = self._submit_task(task)
        taskset.connections = set([c])

        def _do_cmd(*args):
            return self._command_handler(taskset, c, *args)

        with _ConnectionWrapper(c, _do_cmd):
            rtn = yield rtn

        defer.returnValue(rtn)

    def dispatch_background_task(self, func, arg, uniq=None, high_priority=False):
        assert False, 'Not Implemented, use do_task(...)'

    def do_taskset(self, taskset, timeout=None):
        assert False, 'Not Implemented, use do_task(...) and DeferredList()'

    def get_status(self, handle):
        assert False, 'Not Implemented'

########NEW FILE########
__FILENAME__ = tests
import os, sys, signal
import unittest, time, socket

from gearman import GearmanClient, GearmanWorker
from gearman.connection import GearmanConnection
from gearman.manager import GearmanManager
from gearman.server import GearmanServer
from gearman.task import Task

job_servers = ["127.0.0.1"]

class FailedError(Exception):
    pass

def echo(job):
    return job.arg

def fail(job):
    raise FailedError()

def sleep(job):
    time.sleep(float(job.arg))
    return job.arg

class ObjectWorker(object):
    def echo(self, job):
        return job.arg

class ClassWorker(object):
    @staticmethod
    def echo(job):
        return job.arg

class GearmanTestCase(unittest.TestCase):
    def start_server(self):
        self.server_pid = os.fork()
        if not self.server_pid:
            server = GearmanServer()
            server.start()
            sys.exit()
        connection = GearmanConnection(job_servers[0])
        for i in range(10):
            try:
                connection.connect()
            except GearmanConnection.ConnectionError:
                time.sleep(0.5)
            else:
                break
        connection.close()

    def stop_server(self):
        os.kill(self.server_pid, signal.SIGTERM)
        os.waitpid(self.server_pid, 0)

class TestConnection(GearmanTestCase):
    def setUp(self):
        self.start_server()
        self.connection = GearmanConnection(job_servers[0])
        self.connection.connect()

    def tearDown(self):
        self.stop_server()

    def testNoArgs(self):
        self.connection.send_command_blocking("echo_req")
        cmd = self.connection.recv_blocking()
        self.failUnlessEqual(cmd[0], "echo_res")

    def testWithArgs(self):
        self.connection.send_command_blocking("submit_job", dict(func="echo", uniq="", arg="tea"))
        cmd = self.connection.recv_blocking()
        self.failUnlessEqual(cmd[0], 'job_created')

class TestGearman(GearmanTestCase):
    def setUp(self):
        self.start_server()
        self.last_exception = (None, None)
        self.worker = GearmanWorker(job_servers)
        self.worker.register_function("echo", echo)
        self.worker.register_function("fail", fail)
        self.worker.register_function("sleep", sleep, timeout=1)
        self.worker.register_class(ObjectWorker())
        self.worker.register_class(ClassWorker())
        class Hooks(object):
            @staticmethod
            def start(job):
                pass
            @staticmethod
            def complete(job, res):
                pass
            @staticmethod
            def fail(job, exc):
                self.last_exception = (job.func, exc)

        import thread
        self.worker_thread = thread.start_new_thread(self.worker.work, tuple(), dict(hooks=Hooks)) # TODO: Shouldn't use threads.. but we do for now (also, the thread is never terminated)
        self.client = GearmanClient(job_servers)

    def tearDown(self):
        del self.worker
        del self.client
        self.stop_server()

    def testComplete(self):
        self.failUnlessEqual(self.client.do_task(Task("echo", "bar")), 'bar')

    def testFail(self):
        self.failUnlessRaises(self.client.TaskFailed, lambda:self.client.do_task(Task("fail", "bar")))
        # self.failUnlessEqual(self.last_exception[0], "fail")

    def testCompleteAfterFail(self):
        self.failUnlessRaises(self.client.TaskFailed, lambda:self.client.do_task(Task("fail", "bar")))
        self.failUnlessEqual(self.client.do_task(Task("echo", "bar")), 'bar')

    def testTimeout(self):
        self.failUnlessEqual(self.client.do_task(Task("sleep", "0.1")), '0.1')
        self.failUnlessRaises(self.client.TaskFailed, lambda:self.client.do_task(Task("sleep", "1.5")))

    def testCall(self):
        self.failUnlessEqual(self.client("echo", "bar"), 'bar')

    def testObjectWorker(self):
        self.failUnlessEqual(self.client("ObjectWorker.echo", "foo"), "foo")

    def testClassWorker(self):
        self.failUnlessEqual(self.client("ClassWorker.echo", "foo"), "foo")

class TestManager(GearmanTestCase):
    def setUp(self):
        self.start_server()
        self.manager = GearmanManager(job_servers[0])

    def tearDown(self):
        self.stop_server()

    def testStatus(self):
        status = self.manager.status()
        self.failUnless(isinstance(status, dict))

    def testVersion(self):
        version = self.manager.version()
        self.failUnless('.' in version)

    def testWorkers(self):
        workers = self.manager.workers()
        self.failUnless(isinstance(workers, list))

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
