__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# neo4django documentation build configuration file, created by
# sphinx-quickstart on Thu Mar  7 12:27:41 2013.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.viewcode']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'neo4django'
copyright = u'2013, Matt Luongo'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.1.8'
# The full version, including alpha/beta/rc tags.
release = '0.1.8-dev'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'neo4djangodoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'neo4django.tex', u'neo4django Documentation',
   u'Matt Luongo', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'neo4django', u'neo4django Documentation',
     [u'Matt Luongo'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'neo4django', u'neo4django Documentation',
   u'Matt Luongo', 'neo4django', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = models
from django.contrib.admin import models as admin_models
from django.utils.translation import ugettext_lazy as _
from django.utils.encoding import smart_text

from ..db import models
from ..db.models.manager import NodeModelManager
from ..graph_auth.models import User
from ..decorators import borrows_methods
from ..contenttypes.models import ContentType

ADDITION = admin_models.ADDITION
DELETION = admin_models.DELETION
CHANGE = admin_models.CHANGE


class LogEntryManager(NodeModelManager):
        def log_action(self, user_id, content_type_id, object_id, object_repr,
                       action_flag, change_message=''):
            content_type = ContentType.objects.get(id=content_type_id)
            user = User.objects.get(id=user_id)
            e = self.model.objects.create(user=user, content_type=content_type,
                    object_id=smart_text(object_id), action_flag=action_flag,
                    object_repr=object_repr[:200], change_message=change_message)


LOGENTRY_PASSTHROUGH_METHODS = ('__repr__', '__str__', 'is_addition',
                                'is_change', 'is_deletion', 'get_edited_object',
                                'get_admin_url')

@borrows_methods(admin_models.LogEntry, LOGENTRY_PASSTHROUGH_METHODS)
class LogEntry(models.NodeModel):
    action_flag = models.IntegerProperty() # _('action flag')
    action_time = models.DateTimeProperty(auto_now=True) # _('action time'), 
    # TODO django 1.5 support (user models, #143)
    user = models.Relationship(User, rel_type='completed_by',related_name='completed_by', single=True)
    content_type = models.Relationship(ContentType, single=True, rel_type='content_type')
    object_id = models.StringProperty() # _('object id')
    object_repr = models.StringProperty(max_length=200) # _('object repr'),
    change_message = models.StringProperty() # _('change message')

    objects = LogEntryManager()

    class Meta:
        app_label = 'neo_admin'
        verbose_name = _('log entry')
        verbose_name_plural = _('log entries')
        ordering = ('-action_time',)


########NEW FILE########
__FILENAME__ = log
from django import template

from django.contrib.admin.templatetags import log as admin_log_tags

from ...utils import copy_func
from ..models import LogEntry

register = template.Library()

# extend / patch AdminLogNode to use our LogEntry
render_func = copy_func(admin_log_tags.AdminLogNode.render)
render_func.func_globals['LogEntry'] = LogEntry

class AdminLogNode(admin_log_tags.AdminLogNode):
    render = render_func

# patch the get_admin_log tag to use the new AdminLogNode
get_admin_log = copy_func(admin_log_tags.get_admin_log)
get_admin_log.func_globals['AdminLogNode'] = AdminLogNode
register.tag(get_admin_log)


########NEW FILE########
__FILENAME__ = benchmarks
from inspect import isfunction
from time import time
from db import models

import requests


####################
# BENCHMARK MODELS #
####################

class SimpleModel(models.NodeModel):
    class Meta:
        app_label = 'benchmark'
    age = models.IntegerProperty()
    name = models.StringProperty()


class IndexedModel(models.NodeModel):
    class Meta:
        app_label = 'benchmark'
    age = models.IntegerProperty(indexed=True)
    name = models.StringProperty(indexed=True)


class Parent(models.NodeModel):
    class Meta:
        app_label = 'benchmark'
    name = models.StringProperty()


class Child(models.NodeModel):
    class Meta:
        app_label = 'benchmark'
    name = models.StringProperty()
    age = models.IntegerProperty()
    parents = models.Relationship(Parent, 'CHILD_OF')


class Employer(models.NodeModel):
    class Meta:
        app_label = 'benchmark'
    name = models.StringProperty()
    employees = models.Relationship(Parent, 'EMPLOYS')


##############
# BENCHMARKS #
##############

def simple_creation_benchmark():
    for i in xrange(100):
        SimpleModel.objects.create(name=str(i), age=i)
simple_creation_benchmark.priority = True


def indexed_creation_benchmark():
    for i in xrange(100):
        IndexedModel.objects.create(name=str(i), age=i)
indexed_creation_benchmark.priority = True


def related_creation_benchmark():
    for i in xrange(100):
        employer = Employer(name=str(i))
        employees = [Parent(name=str(x)) for x in xrange(5)]
        for employee in employees:
            employee.children = [Child(name=str(x)) for x in xrange(2)]
        employer.employees = employees
        employer.save()
related_creation_benchmark.priority = True


def get_names_benchmark():
    parents = Parent.objects.all()
    [p.name for p in parents]
get_names_benchmark.number = 10
get_names_benchmark.priority = False


def get_related_benchmark():
    employers = Employer.objects.all()
    for e in employers:
        for p in e.employees.all():
            p.name
get_related_benchmark.number = 10
get_related_benchmark.priority = False


def get_select_related_benchmark():
    employers = Employer.objects.all().select_related()
    for e in employers:
        for p in e.employees.all():
            p.name
get_select_related_benchmark.number = 10
get_select_related_benchmark.priority = False


################
# BENCHMARKING #
################

from django.conf import settings


def cleandb():
    host = settings.NEO4J_DATABASES['default']['HOST']
    port = settings.NEO4J_DATABASES['default']['PORT']
    key = getattr(settings, 'NEO4J_DELETE_KEY', None)
    if key:
        requests.delete('http://%s:%s/cleandb/%s' % (host, port, key))

cleandb()

benchmarks = sorted((f for f in locals().items()
                     if isfunction(f[1]) and
                     f[0].endswith('_benchmark')), key=lambda f: -f[1].priority)
for b in benchmarks:
    num_runs = getattr(b[1], 'number', 1)
    #yes, we're using time() for now, since it's io-bound it makes sense
    start = time()
    for i in xrange(num_runs):
        b[1]()
    end = time()

    print "'%s':%.3f" % (b[0][:-10], (end - start) / num_runs)

cleandb()

########NEW FILE########
__FILENAME__ = constants
VERSION = '0.1.8'

INTERNAL_ATTR = '_neo4django'

#gremlin-related constants
ERROR_ATTR = INTERNAL_ATTR + '_error'

#node-related constants
TYPE_ATTR = INTERNAL_ATTR + '_type'

#relationship-related constants
ORDER_ATTR = INTERNAL_ATTR + '_order'

########NEW FILE########
__FILENAME__ = models
from django.utils.translation import ugettext_lazy as _
from django.contrib.contenttypes import models as django_ct_models

from ..db import models
from ..db.models.manager import NodeModelManager
from ..decorators import borrows_methods

class ContentTypeManager(NodeModelManager, django_ct_models.ContentTypeManager):
    pass

CONTENTTYPE_PASSTHROUGH_METHODS = ('model_class', 'get_object_for_this_type',
                                   'get_all_objects_for_this_type', 'natural_key')

@borrows_methods(django_ct_models.ContentType, CONTENTTYPE_PASSTHROUGH_METHODS)
class ContentType(models.NodeModel):
    name = models.StringProperty(max_length=100)
    app_label = models.StringProperty(max_length=100)
    model = models.StringProperty(max_length=100) # _('python model class name')
    # XXX this is a workaround for not yet supporting unique_together
    app_and_model = models.StringProperty(unique=True, indexed=True)

    objects = ContentTypeManager()

    def save(self, *args, **kwargs):
        self.app_and_model = ':'.join((self.app_label, self.model))
        return super(ContentType, self).save(*args, **kwargs)

    class Meta:
        app_label = 'neo_contenttypes'
        verbose_name = _('content type')
        verbose_name_plural = _('content types')
        ordering = ('name',)
        # TODO this is unsupported, currently working around
        unique_together = (('app_label', 'model'),)


########NEW FILE########
__FILENAME__ = aggregates
class Aggregate(object):
    """
    Default Cypher Aggregate.
    """
    cypher_template = '%(function)s(%(field)s)'

    def __init__(self, prop_name, source=None, is_summary=False, **extra):
        """
        Instantiate a Cypher aggregate. Uses similar class attributes to
        django.db.models.sql.aggregates.Aggregate.
        """

        self.prop_name = prop_name
        self.source = source
        self.is_summary = is_summary
        self.extra = extra

        self.field = source

    def as_cypher(self):
        "Return the aggregate, rendered as SQL."

        field_name = self.prop_name

        params = {
            'function': self.cypher_function,
            'field': field_name
        }
        params.update(self.extra)

        return self.cypher_template % params


class Avg(Aggregate):
    cypher_function = 'AVG'


class Count(Aggregate):
    cypher_function = 'COUNT'
    cypher_template = '%(function)s(%(distinct)s%(field)s)'

    def __init__(self, col, distinct=False, **extra):
        super(Count, self).__init__(col, distinct=distinct and 'DISTINCT ' or '', **extra)


class Max(Aggregate):
    cypher_function = 'MAX'


class Min(Aggregate):
    cypher_function = 'MIN'


class Sum(Aggregate):
    cypher_function = 'SUM'

########NEW FILE########
__FILENAME__ = base
from django.db import models as dj_models
from django.db.models import signals
from django.conf import settings

import neo4jrestclient.client as neo_client
import neo4jrestclient.constants as neo_constants

from neo4django.db import connections, DEFAULT_DB_ALIAS
from neo4django.exceptions import NoSuchDatabaseError
from neo4django.decorators import (not_implemented,
                                   alters_data,
                                   transactional,
                                   not_supported,
                                   memoized)

from .manager import NodeModelManager

import inspect
import itertools
import re
from decorator import decorator


class IdProperty(object):
    def __init__(self, getter, setter):
        self.getter = getter
        self.setter = setter

    def __get__(self, inst, cls):
        if inst is None:
            return IdLookup(cls)
        else:
            return self.getter(inst)

    def __set__(self, inst, value):
        return self.setter(inst, value)


class IdLookup(object):
    indexed = True
    unique = True
    id = True
    name = 'id'
    attname = name

    def __init__(self, model):
        self.__model = model
    index = property(lambda self: self)

    def to_neo(self, value):
        if value is not None:
            return int(value)
        else:  # Allows lookups on Nulls
            return value

    def to_python(self, value):
        return self.to_neo(value)


class NeoModelBase(type(dj_models.Model)):
    """
    Model metaclass that adds creation counters to models, a hook for adding
    custom "class Meta" style options to NeoModels beyond those supported by
    Django, and method transactionality.
    """
    meta_additions = ['has_own_index']

    def __init__(cls, name, bases, dct):
        super(NeoModelBase, cls).__init__(name, bases, dct)
        cls._creation_counter = 0

    def __new__(cls, name, bases, attrs):
        super_new = super(NeoModelBase, cls).__new__
        #process the extra meta options
        attr_meta = attrs.get('Meta', None)
        extra_options = {}
        if attr_meta:
            for key in set(NeoModelBase.meta_additions + cls.meta_additions):
                if hasattr(attr_meta, key):
                    extra_options[key] = getattr(attr_meta, key)
                    delattr(attr_meta, key)
        #find all methods flagged transactional and decorate them
        flagged_methods = [i for i in attrs.items()
                           if getattr(i[1], 'transactional', False) and
                           inspect.isfunction(i[1])]

        @decorator
        def trans_method(func, *args, **kw):
            #the first arg should be 'self', since these functions are to be
            #converted to methods. if there's another transaction in progress,
            #do nothing
            #TODO prevents nested transactions, reconsider
            if len(args) > 0 and isinstance(args[0], NodeModel) and\
               len(connections[args[0].using]._transactions) < 1:
                #tx = connections[args[0].using].transaction()
                #TODO this is where generalized transaction support will go,
                #when it's ready in neo4jrestclient
                ret = func(*args, **kw)
                #tx.commit()
                return ret
            else:
                return func(*args, **kw)
        for i in flagged_methods:
            attrs[i[0]] = trans_method(i[1])
        #call the superclass method
        new_cls = super_new(cls, name, bases, attrs)
        # fix the pk field, which will be improperly set for concretely
        # inherited classes
        if not new_cls._meta.abstract:
            new_cls._meta.pk = new_cls.id
        #set the extra meta options
        for k in extra_options:
            setattr(new_cls._meta, k, extra_options[k])
        return new_cls


class NeoModel(dj_models.Model):
    __metaclass__ = NeoModelBase

    class Meta:
        abstract = True

    class creation_counter(object):
        def __get__(self, obj, cls):
            if getattr(cls, '_creation_counter', None) is None:
                cls._creation_counter = 1
            else:
                cls._creation_counter += 1
            return cls._creation_counter
    creation_counter = creation_counter()


class NodeModel(NeoModel):
    objects = NodeModelManager()
    _indexes = {}

    class Meta:
        abstract = True

    def __init__(self, *args, **kwargs):
        self.__using = kwargs.pop('using', DEFAULT_DB_ALIAS)
        super(NodeModel, self).__init__(*args, **kwargs)

    @classmethod
    def _neo4j_instance(cls, neo_node):
        #A factory method to create NodeModels from a neo4j node.
        instance = cls.__new__(cls)
        instance.__node = neo_node
        
        #take care of using by inferring from the neo4j node
        names = []
        for name in connections:
            connection_url = connections[name].url
            # Remove the authentication part
            connection_url = re.sub("http(s?)\:\/\/\w+:\w+\@", "", connection_url, flags=re.I)

            if connection_url in neo_node.url:
                names.append(name)

        if len(names) < 1:
            raise NoSuchDatabaseError(url=neo_node.url)

        instance.__using = names[0]

        #TODO: this violates DRY (BoundProperty._all_properties_for...)
        def get_props(cls):
            meta = cls._meta
            if hasattr(meta, '_properties'):
                properties = meta._properties
            else:
                meta._properties = properties = {}
            return properties

        all_properties = {}
        all_properties.update(get_props(cls))

        for parent in cls.mro():
            if hasattr(parent, '_meta'):
                all_properties.update(get_props(parent))

        #XXX assumes in-db name is the model attribute name, which will change after #30
        for key in all_properties:
            val = None
            if key in neo_node.properties:
                val = all_properties[key].to_python(neo_node.properties[key])
            else:
                val = all_properties[key].get_default()
            setattr(instance, key, val)

        return instance

    def _get_pk_val(self, meta=None):
        return self.__node.id if self.__node else None

    def _set_pk_val(self, value):
        if self.__node is None:
            if value is not None:
                self.__node = self.connection.nodes[value]
        else:
            raise TypeError("Cannot change the id of nodes.")

    pk = id = IdProperty(_get_pk_val, _set_pk_val)

    def __eq__(self, other):
        if type(self) != type(other):
            return False
        pk1 = self._get_pk_val()
        pk2 = other._get_pk_val()
        if pk1 is not None and pk2 is not None:
            return self._get_pk_val() == other._get_pk_val()
        elif pk1 is None and pk2 is None:
            return id(self) == id(other)
        return False

    @property
    def using(self):
        return self.__using

    @classmethod
    def from_model(cls, neo_model):
        """
        Factory method that essentially allows "casting" from a saved model
        instance to another saved model instance. These instances are both
        represented by the same node in the graph, but allow different views
        of the same properties and relationships.
        """
        if neo_model.pk:
            new_model = cls._neo4j_instance(neo_model.node)
            return new_model
        else:
            return cls.copy_model(neo_model)

    @classmethod
    def copy_model(cls, neo_model):
        onto_field_names = [f.attname for f in neo_model._meta.fields]
        new_model = cls()
        for field in neo_model._meta.fields:
            name = field.attname
            if name not in onto_field_names or name in ('pk', 'id'):
                continue
            val = getattr(neo_model, name)
            if isinstance(val, dj_models.Manager):
                for obj in val.all():
                    getattr(new_model, name).add(obj)
            else:
                setattr(new_model, name, val)
        return new_model

    @classmethod
    def index(cls, using=DEFAULT_DB_ALIAS):
        if cls in cls._indexes and using in cls._indexes[cls]:
            return cls._indexes[cls][using]

        index_name = cls.index_name(using)
        conn = connections[using]

        def get_index(name):
            #XXX this is a hack bc of bad equality tests for indexes in
            #neo4jrestclient
            def _hash_(self):
                return hash(self.url)
            try:
                index = conn.nodes.indexes.get(index_name)
            except:
                index = conn.nodes.indexes.create(index_name, type='fulltext')
            index.__hash__ = _hash_.__get__(index, neo_client.Index)
            return index
        cls._indexes[cls][using] = index = get_index(index_name)

        return index

    @classmethod
    def index_name(cls, using=DEFAULT_DB_ALIAS):
        if cls in cls._indexes:
            if using in cls._indexes:
                return cls._indexes[cls][using]
        else:
            cls._indexes[cls] = {}

        model_parents = [t for t in cls.mro() if issubclass(t, NodeModel) and t is not NodeModel]
        if len(model_parents) == 0:
            #because marking this method abstract with the django metaclasses
            #is tough
            raise NotImplementedError('Indexing a base NodeModel is not '
                                      'implemented.')
        elif len(model_parents) > 1:
            return model_parents[-1].index_name(using=using)

        return"{0}-{1}".format(cls._meta.app_label, cls.__name__,)

    @property
    def connection(self):
        return connections[self.using]

    @alters_data
    @transactional
    def delete(self):
        if self.__node is None:
            raise ValueError("Unsaved nodes can't be deleted.")
        for rel in self.__node.relationships.all():
            rel.delete()
        cls = self.__class__
        signals.pre_delete.send(sender=cls, instance=self, using=self.using)
        self.__node.delete()
        signals.post_delete.send(sender=cls, instance=self, using=self.using)
        self.__node = None

    @alters_data
    @not_implemented
    @transactional
    def _insert(self, values, **kwargs):  # XXX: what is this?
        pass

    __node = None

    @property
    def node(self):
        node = self.__node
        if node is None:
            raise ValueError("Unsaved models don't have underlying nodes.")
        else:
            return node

    def save(self, using=DEFAULT_DB_ALIAS, **kwargs):
        return super(NodeModel, self).save(using=using, **kwargs)

    @alters_data
    #@transactional
    def save_base(self, raw=False, cls=None, origin=None,
                  force_insert=False, force_update=False,
                  using=DEFAULT_DB_ALIAS, *args, **kwargs):
        assert not (force_insert and force_update)
        using = using or DEFAULT_DB_ALIAS
        self.__using = using

        if cls is None:
            cls = self.__class__
        signals.pre_save.send(sender=cls, instance=self, raw=raw, using=using)

        is_new = self.id is None
        self._save_neo4j_node(using)
        self._save_properties(self, self.__node, is_new)
        self._save_neo4j_relationships(self, self.__node)

        signals.post_save.send(sender=cls, instance=self, created=(not is_new),
                               raw=raw, using=using)

    @alters_data
    @transactional
    def _save_neo4j_node(self, using):
        #if the node hasn't been created, do that
        if self.id is None:
            #TODO #244, batch optimization
            #get all the type props, in case a new type node needs to be created
            type_hier_props = [{'app_label': t._meta.app_label,
                                'model_name': t.__name__} for t in self._concrete_type_chain()]
            type_hier_props = list(reversed(type_hier_props))
            #get all the names of all types, including abstract, for indexing
            type_names_to_index = [t._type_name() for t in type(self).mro()
                                   if (issubclass(t, NodeModel) and t is not NodeModel)]
            script = '''
            node = Neo4Django.createNodeWithTypes(types)
            Neo4Django.indexNodeAsTypes(node, indexName, typesToIndex)
            results = node
            '''
            conn = connections[using]
            self.__node = conn.gremlin_tx(script, types=type_hier_props,
                                          indexName=self.index_name(),
                                          typesToIndex=type_names_to_index)
        return self.__node

    @classmethod
    def _concrete_type_chain(cls):
        """
        Returns an iterable of this NodeModel's concrete model ancestors,
        including itself, from newest (this class) to oldest ancestor.
        """
        def model_parents(cls):
            cur_cls = cls
            while True:
                bases = filter(lambda c: issubclass(c, NodeModel), cur_cls.__bases__)
                if len(bases) > 1:
                    raise ValueError('Multiple inheritance of NodeModels is not currently supported.')
                elif len(bases) == 0:
                    return
                cur_cls = bases[0]
                if not cur_cls._meta.abstract:
                    yield cur_cls
        return itertools.chain([cls], model_parents(cls))

    #XXX: conditionally memoized classmethod
    def __type_node(cls, using):
        conn = connections[using]
        name = cls.__name__

        type_hier_props = [{'app_label': t._meta.app_label, 'model_name': t.__name__}
                           for t in cls._concrete_type_chain()]
        type_hier_props = list(reversed(type_hier_props))
        script = "results = Neo4Django.getTypeNode(types)"
        error_message = 'The type node for class %s could not be created in the database.' % name
        try:
            script_rv = conn.gremlin_tx(script, types=type_hier_props)
        except Exception, e:
            raise RuntimeError(error_message, e)
        if not hasattr(script_rv, 'properties'):
            raise RuntimeError(error_message + '\n\n%s' % script_rv)
        return script_rv

    __type_node_memoized = classmethod(memoized(__type_node))
    __type_node_classmethod = classmethod(__type_node)

    @classmethod
    def _type_node(cls, using):
        """
        Switch between memoized and classmethod when attribute is accessed
        """
        if not (settings.DEBUG or
                getattr(settings, 'RUNNING_NEO4J_TESTS', None)):
            return cls.__type_node_memoized(using)
        else:
            return cls.__type_node_classmethod(using)

    @classmethod
    def _type_name(cls):
        return '{0}:{1}'.format(cls._meta.app_label, cls.__name__)

    @classmethod
    def _root_type_node(cls, using):
        #TODO consider moving to inferring this from the python inheritance
        #tree, not from the graph structure
        type_node = cls._type_node(cls, using)
        traversal = type_node.traverse(
            types=[neo_client.Incoming.get('<<TYPE>>')],
            uniqueness=neo_constants.NODE_GLOBAL,
            stop=neo_constants.STOP_AT_END_OF_GRAPH)
        #since -1 should be the reference node...
        return traversal[-2]

    @not_implemented
    @transactional
    def _get_next_or_previous_by_FIELD(self, field, is_next, **kwargs):
        pass

    @not_implemented
    @transactional
    def _get_next_or_previous_in_order(self, is_next):
        pass

    @not_supported
    def _collect_sub_objects(self, seen_objs, parent=None, nullable=False):
        pass

########NEW FILE########
__FILENAME__ = cypher
import itertools
from collections import Iterable

from django.core import exceptions

from ...utils import not_none, uniqify


def cypher_primitive(val):
    if isinstance(val, basestring):
        return '"%s"' % val
    elif val is None:
        return 'null'
    elif isinstance(val, Iterable):
        return "[%s]" % ','.join(cypher_primitive(v) for v in val)
    return str(val)


def cypher_escape_identifier(i):
    return u'`%s`' % i


####################
# QUERY COMPONENTS #
####################

class Cypher(object):
    """
    A class representing a Cypher snippet. Subclasses should implement
    get_params() and have an attribute, 'cypher_template', which will be used
    as a %-style template with the dict returned from get_params().

    Alternatively, subclasses can override as_cypher(), returning a unicode
    query string, for more complicated situations.
    """

    def as_cypher(self):
        return self.cypher_template % self.get_params()

    def __unicode__(self):
        return self.as_cypher()

    @property
    def required_identifiers(self):
        """
        A list of str identifiers required by this Cypher snippet.
        """
        return []

    @property
    def passing_identifiers(self):
        """
        A list of identifiers yielded by this Cypher snippet.
        """
        return []


class NodeComponent(Cypher):
    """ A paren-delimited node identifier, for use in path expressions."""

    cypher_template = '%(id)s'

    def __init__(self, identifier=None):
        self.identifier = identifier

    def get_params(self):
        ident = self.identifier
        return {
            'id':cypher_escape_identifier(ident) if ident else ''
        }

    @property
    def passing_identifiers(self):
        return list(not_none([self.identifier]))


class RelationshipComponent(Cypher):
    """ A relationship component for use in path expressions."""

    cypher_template = '-[%(id)s%(optional)s%(types)s%(length_range)s]-'
    
    def __init__(self, identifier=None, types=[], optional=False,
                 length_or_range=1, direction='>'):
        """
        Arguments:
        identifier - the relationship identifier, if needed
        types - a list of string relationship types this component can match,
        if needed
        optional - whether or not the relationship is optional (defaults to False)
        length_or_range - an integer represention a length (defaults to 1) or a
        tuple pair of ranges for variable-length relationships. None at
        either end means an unbound range (eg, `(5, None)` with yield a `5..`
        range.
        direction - a '>' or '<' indicating which direction the relationship
        string should point
        """
        if isinstance(length_or_range, Iterable) and len(length_or_range) != 2:
            raise ValueError("length_or_range should be an integer or an "
                             "integer pair.")
        self.identifier = identifier
        self.types = types
        self.length_or_range = length_or_range
        self.direction = direction
        self.optional = optional

    def get_params(self):
        length = self.length_or_range
        length_range = unicode(length) if isinstance(length, int) else \
                u'%s..%s' % tuple('' if i is None else unicode(i) for i in length)
        return {
            'id':self.identifier or '',
            'types':u':' + u'|'.join(cypher_escape_identifier(t)
                                     for t in self.types) \
                    if len(self.types) > 0 else '',
            'length_range':u'*' +  length_range if length != 1 else '',
            'optional':'?' if self.optional else ''
        }

    def as_cypher(self):
        sup = super(RelationshipComponent, self).as_cypher()
        if self.direction == '<':
            return '<' + sup
        return sup + '>'

    @property
    def passing_identifiers(self):
        return list(not_none([self.identifier]))


class Path(Cypher):
    """ A path expression, like those used in MATCH and WHERE clauses."""

    cypher_template = '%(path_assignment)s%(path_expr)s'

    # TODO there should be a way to specify which ids are already bound, and
    # which aren't so we can get a proper 'required_identifiers' list
    def __init__(self, components, path_variable=None,
                 required_identifiers=tuple()):
        """
        Arguments:
        components - a list of alternating node and relationship components

        Keyword arguments:
        path_variable - a string path identifer. If included, the final Cypher
        output will be a named path (eg, "p=(`n`)-[:`friends_with`]->(`m`)").
        Note that path_variable shouldn't be included for paths meant to be used
        is a WHERE clause.
        required_identifiers - a list of identifiers this path requires to be
        connected, if any (eg, `['n']` for a path the expects the column 'n'
        to have been bound earlier in the query).
        """
        self.path_variable = path_variable
        if len(components) % 2 == 0:
            raise exceptions.ValidationError('Paths must have an odd number of '
                                             'components.')
        self.components = components
        self._required_identifiers = required_identifiers

    def get_params(self):
        components = self.components[:]
        components.append(None)  # make the list even-length
        #break components into pairs and fix the node identifiers
        pairs = [('(%s)' % unicode(p[0]) if p[0] else '()', p[1])
                 for p in zip(*[iter(components)] * 2)]
        components = list(itertools.chain.from_iterable(pairs))[:-1]
        
        return {
            'path_assignment': '%s =' % cypher_escape_identifier(self.path_variable)
                               if self.path_variable is not None else '',
            'path_expr': u''.join(unicode(c) for c in components)
        }

    @property
    def passing_identifiers(self):
        return uniqify(not_none([self.path_variable] + \
                list(itertools.chain.from_iterable(c.passing_identifiers
                                                   for c in self.components))))

    @property
    def required_identifiers(self):
        return self._required_identifiers


class ColumnExpression(Cypher):
    """
    A column expression to be used in WHERE comparisons or RETURN lists.
    """

    def __init__(self, column, prop=None, fail_on_missing=False):
        self.column = column
        self.prop = prop
        self.fail_on_missing = fail_on_missing

    def as_cypher(self):
        expr =  u'.'.join(cypher_escape_identifier(i)
                          for i in not_none((self.column, self.prop)))
        return expr + ('!' if self.fail_on_missing else '?')

    @property
    def required_identifiers(self):
        return not_none([self.column])


class OrderByTerm(Cypher):
    """ An expression used in an ORDER BY clause."""

    cypher_template = '%(expr)s %(desc)s'

    def __init__(self, expression, negate=False):
        self.expression = expression
        self.negate = negate

    def get_params(self):
        return {
            'expr': unicode(self.expression),
            'desc':'DESC' if self.negate else ''
        }
    
    @property
    def required_identifiers(self):
        return getattr(self.expression, 'required_identifiers', [])


###########
# CLAUSES #
###########

class Clause(Cypher):
    @property
    def passing_identifiers(self):
        return []


class Clauses(list):
    def as_cypher(self):
        return u' '.join(unicode(c) for c in self)

    @property
    def passing_identifiers(self):
        return self[-1].passing_identifiers if len(self) > 0 \
                and hasattr(self[-1], 'passing_identifiers') else []

    @property
    def required_identifiers(self):
        return self[0].required_identifiers if len(self) > 0 \
                and hasattr(self[0], 'required_identifiers') else []


class Start(Clause):
    cypher_template = 'START %(exprs)s'

    def __init__(self, start_assignments, cypher_params):
        """
        start_assignments - a dict of variable name keys and assignment
        expression values to make up a START clause. eg, `{'n':'node(5)'}`
        will lead to the expression `n=node(5)` in the output Cypher str
        cypher_params - a list of all Cypher parameters used in `start_exprs`.
        these won't affect the output, but are for later bookkeeping and
        manipulation
        """
        self.start_assignments = start_assignments
        self.cypher_params = cypher_params

    def get_params(self):
        return {
            'exprs': ','.join('%s=%s' % (k, v)
                              for k, v in self.start_assignments.iteritems())
        }

    @property
    def passing_identifiers(self):
        return self.start_assignments.keys()


class Match(Clause):
    cypher_template = 'MATCH %(exprs)s'

    def __init__(self, paths):
        """
        paths - a list of strs of objects with as_cypher() methods that return
        Cypher paths- eg, "n-[:FRIENDS_WITH]->friend" or "path=n-->out".
        """
        paths = list(paths)
        if len(paths) < 1:
            raise exceptions.ValidationError('MATCH clauses require at least '
                                             'one path.')
        self.paths = paths

    def get_params(self):
        return {
            'exprs': u','.join(unicode(p) for p in self.paths)
        }

    @property
    def passing_identifiers(self):
        return uniqify(itertools.chain.from_iterable(
            p.passing_identifiers if hasattr(p, 'passing_identifiers') else []
            for p in self.paths))
    

class With(Clause):
    cypher_template = 'WITH %(fields)s %(order_by)s %(limit)s %(match)s %(where)s'

    def __init__(self, field_dict, order_by=None, limit=None, where=None, match=None):
        self.field_dict = field_dict
        self.order_by = order_by
        self.limit = limit
        self.where = where
        self.match = match

    def get_params(self):
        return {
            'fields': ','.join('%s AS %s' % (alias, field)
                               for alias, field in self.field_dict.iteritems()),
            'order_by':unicode(self.order_by) if self.order_by else '',
            'limit': 'LIMIT %s' % str(self.limit)
                     if self.limit is not None else '',
            'match': ((self.match.as_cypher() if hasattr(self.match, 'as_cypher')
                       else unicode(self.match)) if self.match else ''),
            'where': ((self.where.as_cypher() if hasattr(self.where, 'as_cypher')
                       else unicode(self.where)) if self.where else ''),
        }
    
    @property
    def passing_identifiers(self):
        match_ids = self.match.passing_identifiers \
                if hasattr(self.match, 'passing_identifiers') else []
        return uniqify(self.field_dict.keys() + match_ids)


class OrderBy(Clause):
    cypher_template = 'ORDER BY %(fields)s'

    def __init__(self, terms):
        self.terms = terms
    
    def get_params(self):
        return {
            'fields':u','.join(unicode(t) for t in self.terms)
        }

    @property
    def required_identifiers(self):
        return uniqify(itertools.chain.from_iterable(
            getattr(t, 'required_identifiers', []) for t in self.terms))


class Return(Clause):
    cypher_template = 'RETURN %(fields)s %(order_by)s %(skip)s %(limit)s'

    def __init__(self, field_dict, limit=None, skip=None, order_by=None,
                 distinct_fields=None):
        self.field_dict = field_dict
        self.limit = limit
        self.skip = skip
        self.order_by = order_by
        self.distinct_fields = distinct_fields

    def get_params(self):
        distinct_fields = set(self.distinct_fields or [])
        field_alias_pairs = ((field if field not in distinct_fields
                              else 'DISTINCT ' + field, alias)
                             for alias, field in self.field_dict.iteritems())
        return {
            'fields': ','.join('%s AS %s' % pair for pair in field_alias_pairs),
            'limit': 'LIMIT %s' % str(self.limit)
                     if self.limit is not None else '',
            'skip': 'SKIP %d' % self.skip if self.skip else '',
            'order_by': '' if self.order_by is None else unicode(self.order_by)
        }

    @property
    def passing_identifiers(self):
        return self.field_dict.keys()

    @property
    def required_identifiers(self):
        # TODO ultimately we want to know what's required for the field dict as
        # well, but we need more structure for that
        return getattr(self.order_by, 'required_identifiers', []) \
                if self.order_by is not None else []


class Delete(Clause):
    cypher_template = 'DELETE %(fields)s'

    def __init__(self, fields):
        self.fields = fields

    def get_params(self):
        return {
            'fields': ','.join(cypher_escape_identifier(f) for f in self.fields)
        }

    @property
    def required_identifiers(self):
        # TODO ultimately we want to know what's required for the field dict as
        # well, but we need more structure for that
        return list(self.fields)


class DeleteNode(Delete):
    cypher_template = 'WITH %(fields)s MATCH %(field_matches)s DELETE %(fields_and_rels)s'

    def get_params(self):
        field_rels = ['%s_r' % f for f in self.fields]
        params = {
            'fields': ','.join(self.fields),
            'fields_and_rels': ','.join(self.fields + field_rels),
            'field_matches': ','.join('(%s)-[%s]-()' % (f, r)
                             for f, r in zip(self.fields, field_rels))
        }
        return params


class Set(Clause):
    cypher_template = 'SET %(fields)s'

    def __init__(self, fields_and_values):
        self.fields_and_values = fields_and_values

    def get_params(self):
        assignments = ('n.%s=%s' % (cypher_escape_identifier(field),
                                  cypher_primitive(value))
                       for field, value in self.fields_and_values.iteritems())
        params = {
            'fields':','.join(assignments),
        }
        return params

    # TODO
    #@property
    #def required_identifiers(self)

########NEW FILE########
__FILENAME__ = manager
from django.db import models
from django.db.models.query import EmptyQuerySet

from neo4django.decorators import not_implemented
from query import NodeQuerySet


class NodeModelManager(models.Manager):
    def __init__(self):
        super(NodeModelManager, self).__init__()
        self._using = None
        self.model = None
        self._inherited = False

    @not_implemented
    def _insert(self, values, **kwargs):
        pass

    @not_implemented
    def _update(self, values, **kwargs):
        pass

    def get_empty_query_set(self):
        return EmptyQuerySet()

    @not_implemented
    def exclude(self, *args, **kwargs):
        pass

    def get_query_set(self):
        return NodeQuerySet(self.model)

    def all(self):
        return self.get_query_set()

    def get(self, *args, **kwargs):
        return self.get_query_set().get(*args, **kwargs)

    def dates(self, *args, **kwargs):
        return self.get_query_set().dates(*args, **kwargs)

    def create(self, **kwargs):
        return self.get_query_set().create(**kwargs)

    def filter(self, *args, **kwargs):
        return self.get_query_set().filter(*args, **kwargs)

########NEW FILE########
__FILENAME__ = properties
import re
import datetime

from abc import ABCMeta

from django.utils.translation import ugettext_lazy as _
from django.db.models import fields
from django.db.models.fields import NOT_PROVIDED
from django.core import exceptions, validators
from django.utils.encoding import force_unicode
from django.utils import timezone, datetime_safe
from django.forms import fields as formfields
from django.conf import settings

from neo4django.decorators import transactional
from .base import NodeModel
from .relationships import Relationship
from .. import connections
from neo4django.validators import (validate_array,
                                   validate_str_array,
                                   validate_int_array,
                                   ElementValidator)
from neo4django.utils import AttrRouter, write_through
from neo4django.decorators import borrows_methods
from neo4django.constants import ERROR_ATTR

MIN_INT = -9223372036854775808
MAX_INT = 9223372036854775807

FIELD_PASSTHROUGH_METHODS = ('formfield','get_flatchoices','_get_flatchoices',
                             'set_attributes_from_name', )


@borrows_methods(fields.Field, FIELD_PASSTHROUGH_METHODS)
class Property(object):
    """Extend to create properties of specific types."""
    # This class borrows heavily from Django 1.3's django.db.models.field.Field

    __metaclass__ = ABCMeta

    default_validators = []  # Default set of validators
    default_error_messages = {
        'invalid_choice': _(u'Value %r is not a valid choice.'),
        'null': _(u'This property cannot be null.'),
        'blank': _(u'This property cannot be blank.'),
    }

    def __init__(self, verbose_name=None, name=None, help_text=None,
                 indexed=False, indexed_fulltext=False, indexed_range=False,
                 indexed_by_member=False, has_own_index=False, unique=False,
                 editable=True, null=True, blank=True, validators=[],
                 choices=None, error_messages=None, required=False,
                 serialize=True, auto=False, metadata={},
                 auto_default=NOT_PROVIDED, default=NOT_PROVIDED, **kwargs):
        if unique and not indexed:
            raise ValueError('A unique property must be indexed.')
        if auto and auto_default == NOT_PROVIDED:
            raise ValueError('Properties with auto=True should also set an '
                             'auto_default.')
        self.indexed = self.db_index = indexed
        self.indexed_fulltext = indexed_fulltext
        self.indexed_range = indexed_range
        self.indexed_by_member = indexed_by_member
        self.has_own_index = has_own_index
        self.unique = unique
        # we don't support this uniqueness granularity
        self.unique_for_date = False
        self.unique_for_month = False
        self.unique_for_year = False
        self.editable = editable
        self.blank = blank
        self.null = null
        self.serialize = serialize
        self.auto = auto
        self.auto_default = auto_default
        self.meta = metadata
        self._default = default

        self.name = self.__name = name
        self.attname = self.name
        self.verbose_name = verbose_name
        self.help_text = help_text

        self.choices = choices or []

        self.validators = self.default_validators + validators

        messages = {}
        for c in reversed(self.__class__.__mro__):
            messages.update(getattr(c, 'default_error_messages', {}))
        messages.update(error_messages or {})
        self.error_messages = messages

    def get_internal_type(self):
        return self._internal_type_

    @property
    def default(self):
        self.get_default()

    @property
    def flatchoices(self):
        return self._get_flatchoices()

    def get_attname_column(self):
        return (self.name, None)

    def has_default(self):
        "Returns a boolean of whether this field has a default value."
        return self._default is not NOT_PROVIDED

    def get_default(self):
        "Returns the default value for this field."
        if self.has_default():
            if callable(self._default):
                return self._default()
            return force_unicode(self._default, strings_only=True)
        return None

    def to_neo(self, value):
        return value

    def from_python(self, value):
        """
        A python-centric alias for to_neo()
        """
        return self.to_neo(value)

    def from_neo(self, value):
        return value

    def to_python(self, value):
        """
        A python-centric alias for from_neo()
        """
        return self.from_neo(value)

    def to_neo_index(self, value):
        """
        Convert a Python value to how it should be represented in a Neo4j
        index - often, a string. Subclasses that wish to provide indexing
        should override this method.

        If a property intends to support the `indexed_range` option, the values
        returned by this function need to be lexically ordered in the same way
        as how they should be returned by an ascending range query. Properties
        that don't support said option need not be concerned.
        """
        return self.to_neo(value)

    def get_internal_type(self):
        """
        Returns the "internal" type of an object which instructs API handlers
        like Tastypie how to represent the field etc.

        Since all those external libraries expect the Django names like
        "DateTimeField" and our classes are named "DateTimeProperty", we have to
        replace all "Property"s with "Field". Also, rename "StringField" to
        "CharField".
        """

        classname = self.__class__.__name__

        if classname == 'StringProperty':
            return 'CharField'

        return classname.replace("Property", "Field")

    def contribute_to_class(self, cls, name):
        """
        Set up properties when the owner class is loaded.
        """
        self.creation_counter = cls.creation_counter
        self.set_attributes_from_name(name)
        if issubclass(cls, NodeModel):
            prop = BoundProperty(self, cls, self.__name or name, name)
            cls._meta.add_field(prop)
        elif issubclass(cls, Relationship):
            if self.indexed:
                raise TypeError(
                    "Relationship properties may not be indexed.")
            prop = BoundProperty(self, cls, self.__name or name)
            cls.add_field(prop)
        else:
            raise TypeError("Properties may only be added to Nodes"
                            " or Relationships")
        setattr(cls, name, prop)

    def run_validators(self, value):
        if value in validators.EMPTY_VALUES:  # TODO ??? - ML
            return

        errors = []
        for v in self.validators:
            try:
                v(value)
            except exceptions.ValidationError, e:
                if hasattr(e, 'code') and e.code in self.error_messages:
                    message = self.error_messages[e.code]
                    if e.params:
                        message = message % e.params
                    errors.append(message)
                else:
                    errors.extend(e.messages)
        if errors:
            raise exceptions.ValidationError(errors)

    def validate(self, value, model_instance):
        """
        Validates value and throws ValidationError. Subclasses should override
        this to provide validation logic.
        """
        if not self.editable:
            # Skip validation for non-editable fields.
            return
        if self.choices and value:
            for option_key, option_value in self.choices:
                if isinstance(option_value, (list, tuple)):
                    # This is an optgroup, so look inside the group for options.
                    for optgroup_key, optgroup_value in option_value:
                        if value == optgroup_key:
                            return
                elif value == option_key:
                    return
            raise exceptions.ValidationError(self.error_messages['invalid_choice'] % value)

        if value is None and not self.null:
            raise exceptions.ValidationError(self.error_messages['null'])

        if not self.blank and value in validators.EMPTY_VALUES:
            raise exceptions.ValidationError(self.error_messages['blank'])

    def clean(self, value, model_instance):
        """
        Convert the value's type and run validation. Validation errors from to_python
        and validate are propagated. The correct value is returned if no error is
        raised.
        """
        self.validate(value, model_instance)
        self.run_validators(value)
        value = self.to_python(value)
        return value

    def pre_save(self, model_instance, add, attname):
        pass


@borrows_methods(fields.Field, ('save_form_data',))
class BoundProperty(AttrRouter):
    rel = None
    primary_key = False

    def __init__(self, prop, cls, propname, attname, *args, **kwargs):
        super(BoundProperty, self).__init__(*args, **kwargs)
        self._property = prop

        self._route(['creation_counter',
                     'choices',
                     'convert',
                     'indexed',
                     'db_index',
                     'indexed_fulltext',
                     'indexed_range',
                     'indexed_by_member',
                     'get_internal_type',
                     'unique',
                     'help_text',
                     'null',
                     'to_neo',
                     'to_neo_index',
                     'to_neo_index_gremlin',
                     'member_to_neo_index',
                     'from_python',
                     'from_neo',
                     'to_python',
                     'default',
                     'has_default',
                     'get_default',
                     'clean',
                     'validate',
                     'run_validators',
                     'pre_save',
                     'serialize',
                     'auto',
                     'auto_default',
                     'next_value',
                     'next_value_gremlin',
                     'meta',
                     'MAX',
                     'MIN',
                     'get_internal_type',
                     'help_text',
                     'null',
                     #form-related properties
                     'editable',
                     'blank',
                     'formfield',
                     'unique_for_date',
                     'unique_for_month',
                     'unique_for_year',
                     'verbose_name',
                     'flatchoices',
                     ], self._property)

        self.__class = cls
        self.__propname = propname
        self.__attname = attname

        # TODO - i don't know why, but this is the final straw. properties
        # and boundproperties need to be merged, the coupling is ridiculous
        self._property.name = propname
        self._property.attname = attname

        properties = self._properties_for(cls)
        properties[self.name] = self  # XXX: weakref

    attname = name = property(lambda self: self.__attname)
    target = property(lambda self: self.__class)

    def _property_type(self):
        return type(self._property)

    def __cmp__(self, other):
        return cmp(self.creation_counter, other.creation_counter)

    @staticmethod
    def _values_of(instance, create=True):
        try:
            values = instance._prop_values
        except:
            values = {}
            if create:
                instance._prop_values = values
        return values

    @staticmethod
    def _properties_for(obj_or_cls):
        meta = obj_or_cls._meta
        try:
            properties = meta._properties
        except:
            meta._properties = properties = {}
        return properties

    @staticmethod
    def _all_properties_for(obj_or_cls):
        new_property_dict = {}
        new_property_dict.update(BoundProperty._properties_for(obj_or_cls))

        cls = obj_or_cls if isinstance(obj_or_cls, type) else type(obj_or_cls)

        for parent in cls.__bases__:
            if hasattr(parent, '_meta'):
                new_property_dict.update(BoundProperty._all_properties_for(parent))

        return new_property_dict

    def index(self, using):
        if not (self.indexed or self.auto):
            raise TypeError("'%s' is not indexed" % (self.__propname,))
        else:
            return self.__class.index(using)

    def index_name(self, using):
        if not (self.indexed or self.auto):
            raise TypeError("'%s' is not indexed" % (self.__propname,))
        else:
            return self.__class.index_name(using)

    #update the state of the model instance based on a rest client element property dictionary
    def _update_values_from_dict(instance, new_val_dict, clear=False):
        values = BoundProperty._values_of(instance)
        properties = BoundProperty._all_properties_for(instance)

        values.clear()

        for k, v in new_val_dict.items():
            prop = properties.get(k, None)
            if prop:
                #XXX duplicates __get_value()...
                values[k] = prop.to_python(v)
        #XXX this relies on neo4jrestclient private implementation details
        if clear:
            instance.node._dic['data'].clear()
        instance.node._dic['data'].update(new_val_dict)

    #TODO this needs to be revised
    NodeModel._update_values_from_dict = staticmethod(_update_values_from_dict)
    del _update_values_from_dict

    def _save_(instance, node, node_is_new):
        values = BoundProperty._values_of(instance)
        properties = BoundProperty._all_properties_for(instance)

        gremlin_props = {}
        for key, prop in properties.items():
            prop_class = prop.__class
            prop_dict = gremlin_props[key] = {}
            if prop.auto and values.get(key, None) is None:
                prop_dict['auto_increment'] = True
                prop_dict['increment_func'] = prop.next_value_gremlin
                prop_dict['auto_default'] = prop.auto_default
                prop_dict['auto_abstract'] = prop_class._meta.abstract
                prop_dict['auto_app_label'] = prop_class._meta.app_label
                prop_dict['auto_model'] = prop_class.__name__
            if prop.indexed:
                prop_dict['index_name'] = prop.index_name(instance.using)
                if hasattr(prop, 'to_neo_index_gremlin'):
                    prop_dict['to_index_func'] = prop.to_neo_index_gremlin
            if key in values:
                value = values[key]
                prop.clean(value, instance)
                value = prop.pre_save(node, node_is_new, prop.name) or value
                if (not value in validators.EMPTY_VALUES or
                        getattr(prop._property, "use_string", False)):
                    #should already have errored if self.null==False
                    value = prop.to_neo(value)
                prop_dict['value'] = value
                if prop.indexed:
                    indexed_values = prop_dict['values_to_index'] = []
                    prop_dict['unique'] = bool(prop.unique)
                    if value is not None:
                        indexed_values.append(prop.to_neo_index(values[key]))
                        if prop.indexed_by_member:
                            for m in value:
                                indexed_values.append(prop.member_to_neo_index(m))
                values[key] = value
        script = '''
        node=g.v(nodeId);
        results = Neo4Django.updateNodeProperties(node, propMap);
        '''
        conn = connections[instance.using]
        script_rv = conn.gremlin_tx(script, nodeId=instance.id,
                                    propMap=gremlin_props, raw=True)

        if (isinstance(script_rv, dict) and ERROR_ATTR in script_rv and 'property' in script_rv):
            raise ValueError("Duplicate index entries for <%s>.%s" %
                             (instance.__class__.__name__, script_rv['property']))
        elif isinstance(script_rv, dict) and 'data' in script_rv:
            #returned a node (TODO #128 error passing generalization)
            NodeModel._update_values_from_dict(instance, script_rv['data'],
                                               clear=True)
        else:
            raise ValueError('Unexpected response from server: %s' %
                             str(script_rv))

    #TODO this needs to be revised. I hope there's a better way.
    NodeModel._save_properties = staticmethod(_save_)
    del _save_

    def __get__(self, instance, cls=None):
        if instance is None:
            return self
        values = self._values_of(instance, create=False)
        if self.__propname in values:
            return values[self.__propname]
        else:
            return self.__get_value(instance)

    def __set__(self, instance, value):
        if write_through(instance):
            self.___set_value(instance, value)
        else:
            values = self._values_of(instance)
            values[self.__propname] = value

    @transactional
    def __get_value(self, instance):
        try:
            underlying = getattr(instance, 'node', None) or getattr(instance, 'relationship', None)
        except:  # no node existed
            pass
        else:
            try:
                values = BoundProperty._values_of(instance)
                values[self.__propname] = val = self._property.to_python(underlying[self.__propname])
                return val
            except:  # no value set on node
                pass
        return self.get_default()  # fall through: default value

    def _get_val_from_obj(self, obj):
        return self.__get__(obj)

    def value_from_object(self, obj):
        return self._get_val_from_obj(obj)

    def value_to_string(self, obj):
        #TODO not sure if this method plays a bigger role in django
        return str(self.__get__(obj))

    @transactional
    def __set_value(self, instance, value):
        underlying = getattr(instance, 'node', None) or getattr(instance, 'relationship', None)
        if not underlying:
            raise TypeError('Property has no underlying node or relationship!')
        try:
            old = underlying[self.__propname]
        except:
            old = None
        self._property.clean(value, instance)
        #supports null properties
        if not value in validators.EMPTY_VALUES:
            #should already have errored if self.null==False
            value = self._property.to_neo(value)
            underlying[self.__propname] = value
        elif self.__propname in underlying:
            #remove the property from the node if the val is None
            del underlying[self.__propname]

        return (old, value)


class StringProperty(Property):
    #since strings don't have a natural max, this is an arbitrarily high utf-8
    #string. this is necessary for gt string queries, since Lucene range
    #queries (prior 4.0) don't support open-ended ranges
    _internal_type_ = 'StringProperty'
    MAX = u'\U0010FFFF' * 20
    MIN = u''

    formfield = formfields.CharField

    def __init__(self, max_length=None, min_length=None, **kwargs):
        if kwargs.get('indexed', False):
            kwargs.setdefault('indexed_fulltext', True)
            kwargs.setdefault('indexed_range', True)
        super(StringProperty, self).__init__(**kwargs)
        self.max_length = max_length
        self.min_length = min_length
        if max_length is not None:
            self.validators.append(validators.MaxLengthValidator(max_length))
        if min_length is not None:
            self.validators.append(validators.MinLengthValidator(min_length))

    def to_neo(cls, value):
        return unicode(value)

    def formfield(self, **kwargs):
        defaults = dict(kwargs)
        if self.max_length is not None:
            defaults['max_length'] = self.max_length
        return super(StringProperty, self).formfield(**defaults)


class EmailProperty(StringProperty):
    #TODO docstring
    _internal_type_ = 'EmailProperty'
    default_validators = [validators.validate_email]

    formfield = formfields.EmailField


class URLProperty(StringProperty):
    _internal_type_ = 'URLProperty'
    formfield = formfields.URLField

    #TODO docstring
    def __init__(self, verify_exists=False, **kwargs):
        kwargs['max_length'] = kwargs.get('max_length', 2083)
        super(URLProperty, self).__init__(**kwargs)
        self.validators.append(validators.URLValidator())

    def formfield(self, **kwargs):
        defaults = {'form_class': formfields.URLField}
        defaults.update(kwargs)
        return super(URLProperty, self).formfield(**defaults)


class IntegerProperty(Property):
    """
    A 64-bit integer, akin to Django's `BigIntegerField`.
    """
    _internal_type_ = 'IntegerProperty'
    default_validators = [validators.MinValueValidator(MIN_INT), validators.MaxValueValidator(MAX_INT)]

    MAX = MAX_INT
    MIN = MIN_INT

    formfield = formfields.IntegerField

    def __init__(self, **kwargs):
        if kwargs.get('indexed', False):
            kwargs.setdefault('indexed_fulltext', True)
            kwargs.setdefault('indexed_range', True)
        return super(IntegerProperty, self).__init__(**kwargs)

    def get_default(self):
        return 0

    def to_neo(self, value):
        return int(value)

    def to_neo_index(self, value):
        #for now, we'll just use a fixed-width binary decimal encoding with a
        #'-' for negative and '0' for positive or 0.
        s = str(abs(value))
        if len(s) > 20:
            raise ValueError('Values should be between {0} and {1}.'.format(MIN_INT, MAX_INT))
        return ('-' if value < 0 else '0') + s.zfill(19)

    @property
    def to_neo_index_gremlin(self):
        """
        Return a Gremlin/Groovy closure literal that can compute
        to_neo_index(value) server-side. The closure should take a single value
        as an argument (that value actually set on the node).
        """
        return """{ i -> (i < 0?'-':'0') + String.format('%019d',i)} """

    def formfield(self, **kwargs):
        defaults = {'form_class': formfields.IntegerField}
        defaults.update(kwargs)
        return super(IntegerProperty, self).formfield(**defaults)


class AutoProperty(IntegerProperty):
    _internal_type_ = 'AutoProperty'
    editable = False
    formfield = formfields.IntegerField

    def __init__(self, *args, **kwargs):
        kwargs['auto'] = True
        kwargs['auto_default'] = 1
        super(AutoProperty, self).__init__(*args, **kwargs)

    def get_default(self):
        return None

    def next_value(self, old_value):
        return old_value + 1

    @property
    def next_value_gremlin(self):
        """
        Return a Gremlin/Groovy closure literal that can compute next_value()
        server-side. The closure take a single value as an argument to
        increment.
        """
        return """{ i -> i + 1}"""

    def formfield(self, **kwargs):
        return None


@borrows_methods(fields.DateField, ('to_python',))
class DateProperty(Property):

    _internal_type_ = 'DateProperty'
    default_error_messages = {
        'invalid': _('Enter a valid date in YYYY-MM-DD format.'),
        'invalid_date': _('Invalid date: %s'),
    }

    MAX = datetime.date.max
    MIN = datetime.date.min

    def __init__(self, auto_now=False, auto_now_add=False, **kwargs):
        self.auto_now, self.auto_now_add = auto_now, auto_now_add
        #HACKs : auto_now_add/auto_now should be done as a default or a pre_save.
        if auto_now or auto_now_add:
            kwargs['editable'] = False
            kwargs['blank'] = True
        if kwargs.get('indexed', False):
            kwargs['indexed_range'] = True
        super(DateProperty, self).__init__(**kwargs)

    def to_neo(self, value):
        if value is None:
            return value
        elif isinstance(value, datetime.datetime):
            return value.date().isoformat()
        elif isinstance(value, datetime.date):
            return value.isoformat()
        else:
            return unicode(value)

    def pre_save(self, model_instance, add, attname):
        if self.auto_now or (self.auto_now_add and add):
            value = datetime.date.today()
            setattr(model_instance, attname, value)
            return value
        else:
            return super(DateProperty, self).pre_save(model_instance, add,
                                                      attname)


@borrows_methods(fields.DateTimeField, ('to_python',))
class DateTimeProperty(DateProperty):
    _internal_type_ = 'DateTimeProperty'
    default_error_messages = fields.DateTimeField.default_error_messages

    MAX = datetime.datetime.max
    MIN = datetime.datetime.min

    def to_neo(self, value):
        if value is None:
            return value
        elif isinstance(value, datetime.date):
            if not isinstance(value, datetime.datetime):
                value = datetime_safe.new_datetime(value)
            if settings.USE_TZ and timezone.is_naive(value):
                default_timezone = timezone.get_default_timezone()
                value = timezone.make_aware(value, default_timezone)
            return value.isoformat()
        else:
            # TODO raise error
            pass

    def to_neo_index(self, value):
        cleaned = self.to_neo(value)
        if cleaned is not None:
            return cleaned.replace(' ', '-')

    def pre_save(self, model_instance, add, attname):
        if self.auto_now or (self.auto_now_add and add):
            value = timezone.now()
            setattr(model_instance, attname, value)
            return value
        else:
            return super(DateProperty, self).pre_save(model_instance, add,
                                                      attname)


class ArrayProperty(Property):
    __metaclass__ = ABCMeta
    _internal_type_ = 'ArrayProperty'

    formfield = fields.CharField

    default_validators = [validate_array]

    member_to_neo_index = Property.to_neo_index.im_func

    def __init__(self, *args, **kwargs):
        """
        Keyword arguments:
        per_element_validators -- a list of validators to apply to each element
            of the sequence, or a tuple containing a list of validators and an
            error message, in that order.
        """
        if kwargs.get('indexed', False):
            if 'indexed_by_member' not in kwargs:
                kwargs['indexed_by_member'] = True
        super(ArrayProperty, self).__init__(*args, **kwargs)
        per_key = 'per_element_validators'
        if per_key in kwargs:
            vals_or_tuple = kwargs[per_key]
            if isinstance(vals_or_tuple, tuple):
                per_vals, message = vals_or_tuple
                el_val = ElementValidator(per_vals, message=message)
            else:
                el_val = ElementValidator(vals_or_tuple)
            self.validators.append(el_val)

        #Store array values as a token separated string. For use in the event
        #the user needs to access the neo4j data multiple ways.
        #For example using REST interface you cannot store an empty array
        self.use_string = kwargs.get("use_string", False)
        self.token = kwargs.get("token", ",")
        self.escape_token = kwargs.get("escape_token", "+")
        self.token_regex = "(?<!%s)%s" % (re.escape(self.escape_token), self.token)

    def get_default(self):
        if self.use_string:
            return ""
        else:
            return []

    def from_neo(self, value):
        if value and not isinstance(value, (tuple, list)) and self.use_string:
            array_values = re.split(self.token_regex, value)
            for i, v in enumerate(array_values):
                array_values[i] = v.replace(
                    "%s%s" % (self.escape_token, self.token), self.token)
            return tuple(array_values)
        if not value:
            return tuple([])
        else:
            return tuple(value)

    def to_neo(self, value):
        if self.use_string:
            escaped_values = []
            for v in value:
                escaped_values.append(
                    str(v).replace(self.token, "%s%s" % (self.escape_token,
                                                         self.token)))
            return self.token.join(escaped_values)
        return value


class StringArrayProperty(ArrayProperty):
    default_validators = [validate_str_array]
    _internal_type_ = 'StringArrayProperty'


class URLArrayProperty(StringArrayProperty):
    _internal_type_ = 'URLArrayProperty'
    def __init__(self, *args, **kwargs):
        per_key = 'per_element_validators'
        per_val = validators.URLValidator()
        if per_key in kwargs:
            kwargs[per_key].append(per_val)  # TODO make this consistent with super
        else:
            kwargs[per_key] = ([per_val], 'Enter a valid sequence of URLs')
        super(URLArrayProperty, self).__init__(*args, **kwargs)


class IntArrayProperty(ArrayProperty):
    _internal_type_ = 'IntArrayProperty'
    default_validators = [validate_int_array]

    member_to_neo_index = IntegerProperty.to_neo_index.im_func


class BooleanProperty(Property):
    _internal_type_ = 'BooleanProperty'
    formfield = formfields.BooleanField

    def to_neo(self, value):
        return bool(value)

    def from_neo(self, value):
        return bool(value)

########NEW FILE########
__FILENAME__ = query
from django.db.models import Q
from django.db.models.query import QuerySet
from django.db.models.sql import subqueries
from django.core import exceptions
from django.db.models.loading import get_model
from django.utils.datastructures import SortedDict

from lucenequerybuilder import Q as LQ

from collections import namedtuple, defaultdict
from operator import and_, or_
import itertools
import re

import neo4jrestclient.constants as neo_constants

from .. import DEFAULT_DB_ALIAS, connections
from ...utils import Enum, uniqify, not_none
from ...constants import ORDER_ATTR
from ...decorators import (transactional,
                           not_supported,
                           alters_data,
                           not_implemented,
                           borrows_methods)

from .cypher import (Clauses, Start, NodeComponent, RelationshipComponent, Path,
                     Match, With, Set, Return, ColumnExpression, OrderByTerm,
                     OrderBy, DeleteNode, cypher_primitive)

from . import script_utils
from .script_utils import id_from_url, LazyNode, _add_auth as add_auth
from . import aggregates

#python needs a bijective map... grumble... but a reg enum is fine I guess
#only including those operators currently being implemented
OPERATORS = Enum('EXACT', 'IEXACT', 'LT', 'LTE', 'GT', 'GTE', 'IN', 'RANGE', 'MEMBER',
                 'CONTAINS', 'ICONTAINS', 'STARTSWITH', 'ISTARTSWITH',
                 'ENDSWITH', 'IENDSWITH', 'REGEX', 'IREGEX', 'MEMBER_IN',
                 'YEAR', 'MONTH', 'DAY', 'ISNULL')

ConditionTuple = namedtuple('ConditionTuple', ['field', 'value', 'operator', 'path'])


class Condition(ConditionTuple):
    def __init__(self, *args, **kwargs):
        if 'value' in kwargs:
            if isinstance(kwargs['value'], list):
                kwargs['value'] = tuple(kwargs['value'])
        else:
            if len(args) > 1:
                if isinstance(args[1], list):
                    args = list(args)
                    args[1] = tuple(args[1])
        super(Condition, self).__init__(*args, **kwargs)


QUERY_CHUNK_SIZE = 100

#TODO these should be moved to constants
TYPE_REL = '<<TYPE>>'
INSTANCE_REL = '<<INSTANCE>>'
INTERNAL_RELATIONSHIPS = (TYPE_REL, INSTANCE_REL)


#########################
# QUERY CODE GENERATION #
#########################

def clone_q(q):
    children = [clone_q(child) if isinstance(child, Q) else child
                for child in q.children]
    new_q = Q(*children)
    new_q.negated = q.negated
    new_q.connector = q.connector
    return new_q


def condition_from_kw(nodetype, keyval):
    pattern = re.compile('__+')
    terms = pattern.split(keyval[0])
    explicit_op = False

    if not terms:
        pass  # TODO error out
    elif len(terms) > 1:
        try:
            #get the corresponding operator
            op = getattr(OPERATORS, terms[-1].upper())
        except AttributeError:
            op = OPERATORS.EXACT
        else:
            explicit_op = True
    else:
        op = OPERATORS.EXACT

    path = terms[:-1] if explicit_op else terms[:]

    attname = None

    cur_m = nodetype
    for level, step in enumerate(path):
        #TODO DRY violation, this needs to be refactored to share code with
        # the select_related machinery, and possibly reuse Django methods for
        # following these paths
        rels = getattr(cur_m._meta, '_relationships', {}).items()
        candidates_on_models = sorted((s for s in ((score_model_rel(step, r), r)
                                                   for _, r in rels)
                                       if s[0] > 0), reverse=True)
        if len(candidates_on_models) < 1:
            # if there's no candidate, it could be an error *OR* it could be
            # a property at the end of the path
            if level == len(path) - 1:
                attname = path[-1]
                path = path[:-1]
                break
            else:
                raise exceptions.ValidationError("Cannot find referenced field "
                                                 "`%s` from model %s." %
                                                 (keyval[0], nodetype.__name__))
        rel_choice = candidates_on_models[0][-1]
        cur_m = (rel_choice.target_model if not rel_choice.target_model is cur_m
                 else rel_choice.source_model)

    attname = attname or 'id'

    try:
        field = getattr(cur_m, attname)
    except AttributeError:
        raise exceptions.ValidationError("Cannot find referenced field `%s` from model %s." %
                                         (keyval[0], nodetype.__name__))

    if op in (OPERATORS.RANGE, OPERATORS.IN, OPERATORS.MEMBER_IN):
        return Condition(field, tuple([field.to_neo(v) for v in keyval[1]]),
                         op, path)
    else:
        return Condition(field, field.to_neo(keyval[1]), op, path)


def lucene_query_from_condition(condition):
    """
    Build a Lucene query from a kw pair like those making up Q objects, eg
    ('name__exact','Sarah').
    """
    lq = None
    field = condition.field
    attname = field.attname

    def escape_wilds(s):
        return str(s).replace('*', '\*').replace('?', '\?')
    if condition.operator is OPERATORS.EXACT:
        lq = LQ(attname, field.to_neo_index(condition.value))
    elif condition.operator is OPERATORS.STARTSWITH:
        lq = LQ(attname, '%s*' % escape_wilds(condition.value), wildcard=True)
    elif condition.operator is OPERATORS.CONTAINS:
        lq = LQ(attname, '*%s*' % escape_wilds(condition.value), wildcard=True)
    elif condition.operator is OPERATORS.MEMBER:
        lq = LQ(attname, field.member_to_neo_index(condition.value))
    elif condition.operator is OPERATORS.IN:
        lq = reduce(or_, (LQ(attname, field.to_neo_index(v))
                          for v in condition.value))
    elif condition.operator is OPERATORS.MEMBER_IN:
        lq = reduce(or_, (LQ(attname, field.member_to_neo_index(v))
                          for v in condition.value))
    #FIXME OBOE with field.MAX + exrange, not sure it's easy to fix though...
    elif condition.operator in (OPERATORS.GT, OPERATORS.GTE, OPERATORS.LT,
                                OPERATORS.LTE, OPERATORS.RANGE):
        if not field.indexed_range:
            raise exceptions.FieldError(
                'The {0} property is not configured for range '
                'indexing.'.format(field.attname))
        fieldtype = field._property_type()
        if condition.operator in (OPERATORS.GT, OPERATORS.GTE):
            if not hasattr(field, 'MAX'):
                raise exceptions.FieldError(
                    'The {0} property is not configured for gt/gte '
                    'queries.'.format(field.attname))
            if condition.operator is OPERATORS.GT:
                lq = LQ(attname, exrange=(field.to_neo_index(condition.value),
                                          field.to_neo_index(fieldtype.MAX)))
            else:
                lq = LQ(attname, inrange=(field.to_neo_index(condition.value),
                                          field.to_neo_index(fieldtype.MAX)))
        elif condition.operator in (OPERATORS.LT, OPERATORS.LTE):
            if not hasattr(fieldtype, 'MIN'):
                raise exceptions.FieldError(
                    'The {0} property is not configured for lt/lte '
                    'queries.'.format(field.attname))
            if condition.operator is OPERATORS.LT:
                lq = LQ(attname, exrange=(field.to_neo_index(fieldtype.MIN),
                                          field.to_neo_index(condition.value)))
            else:
                lq = LQ(attname, inrange=(field.to_neo_index(fieldtype.MIN),
                                          field.to_neo_index(condition.value)))
        elif condition.operator is OPERATORS.RANGE:
            if len(condition.value) != 2:
                raise exceptions.ValidationError('Range queries need upper and lower bounds.')
            lq = LQ(condition.field.attname,
                    inrange=[condition.field.to_neo_index(v)
                             for v in condition.value])
    else:
        return None
    return lq


def condition_tree_from_q(nodetype, q, predicate=lambda x:True):
    """
    Returns a new Q tree with kwargs pairs replaced by conditions. Any
    conditions that don't meet an optional predicate will be removed.
    """
    if not isinstance(q, Q):
        if isinstance(q, Condition):
            return q
        return condition_from_kw(nodetype, q)
    new_q = clone_q(q)
    children = [condition_tree_from_q(nodetype, child, predicate=predicate)
                for child in new_q.children]
    new_q.children = filter(predicate, children)
    new_q.children_filtered = len(new_q.children) != len(q.children)
    return new_q


def condition_tree_leaves(q):
    """
    A generator to iterate through all meaningful leaves in a Q tree.
    """
    if not isinstance(q, Q):
        yield q
    else:
        for child in q.children:
            for leaf in condition_tree_leaves(child):
                yield leaf


def lucene_query_from_condition_tree(cond_q):
    """
    Unpack a Q tree with Condition children, building a Lucene query tree as
    we go.
    """
    if not isinstance(cond_q, Q):
        return lucene_query_from_condition(cond_q)
    if len(cond_q.children) > 0:
        children = [lucene_query_from_condition_tree(c)
                    for c in cond_q.children]
        children = filter(lambda x: bool(x), children)
        if len(children) > 0:
            op = and_ if cond_q.connector == 'AND' else or_
            lucene_query = reduce(op, children)
            if cond_q.negated:
                lucene_query = ~lucene_query
            return lucene_query


def lucene_query_and_index_from_q(using, nodetype, q):
    """
    Return an index name / Lucene query pair based on a given database, node
    type, and Q filter tree- which can have a mix of kwargs or Condition leaves.
    """
    # crawl the Q tree and prune all non-indexed fields. collect all indexed
    # non-rel-spanning fields, but drop any that have been OR'd against

    # XXX hack to get around lack of real closure support
    prop_indexes = set([])

    def predicate(cond):
        if isinstance(cond, Q):
            # exclude OR'd fields that aren't *all* indexed, as they can't
            # use an index to help. we use the "children_filtered" bool set by
            # condition_tree_from_q
            return not(cond.connector == 'OR' and
                       getattr(cond, 'children_filtered', False))
        # make sure the field is indexed, isn't a rel-spanning field,
        # and isn't an id field
        if len(cond.path) < 1 and cond.field.indexed \
           and not getattr(cond.field, 'id', False):
            index = cond.field.index(using)
            prop_indexes.add(index)
            if len(prop_indexes) > 1:
                raise exceptions.ValidationError("Complex filters cannot refer "
                                                 "to two indexed properties "
                                                 "that don't share an index.")
            return True

    cond_q = condition_tree_from_q(nodetype, q, predicate=predicate)
    if len(prop_indexes) == 0 or not predicate(cond_q):
        return None
    index = next(iter(prop_indexes))
    return (index.name, lucene_query_from_condition_tree(cond_q))


def cypher_predicate_from_condition(element_name, condition):
    """
    Build a Cypher expression suitable for a WHERE clause from a condition.

    Arguments:
    element_name - a valid Cypher variable to filter against. This should be
    a column representing the field, eg "name", or another expression that will
    yield a value to filter against, like "node.name".
    condition - the condition for which we're generating a predicate
    """
    from .properties import (StringProperty, ArrayProperty, DateProperty,
                             DateTimeProperty)
    from .relationships import BoundRelationship

    cypher = None

    # the neo4django field object
    field = condition.field

    #the value we're filtering against
    value = condition.value

    # if the operator is a simple case-insensitive op, lower-case the value
    # and wrap the element_name in LOWER
    # NB - this won't work for complex cases, eg iregex
    if condition.operator in (OPERATORS.IEXACT, OPERATORS.ICONTAINS,
                              OPERATORS.ISTARTSWITH, OPERATORS.IENDSWITH):
        value = value.lower()
        element_name = 'LOWER(%s)' % element_name

    if condition.operator in (OPERATORS.EXACT, OPERATORS.IEXACT):
        cypher = ("%s = %s" %
                  (element_name, cypher_primitive(value)))
    elif condition.operator is OPERATORS.GT:
        cypher = ("%s > %s" %
                  (element_name, cypher_primitive(value)))
    elif condition.operator is OPERATORS.GTE:
        cypher = ("%s >= %s" %
                  (element_name, cypher_primitive(value)))
    elif condition.operator is OPERATORS.LT:
        cypher = ("%s < %s" %
                  (element_name, cypher_primitive(value)))
    elif condition.operator is OPERATORS.LTE:
        cypher = ("%s <= %s" %
                  (element_name, cypher_primitive(value)))
    elif condition.operator is OPERATORS.RANGE:
        if len(condition.value) != 2:
            raise exceptions.ValidationError('Range queries need upper and lower bounds.')
        cypher = ("(%s >= %s) AND (%s <= %s)" %
                  (element_name, cypher_primitive(value[0]), element_name,
                   cypher_primitive(value[1])))
    elif (condition.operator is OPERATORS.MEMBER or
          (condition.operator is OPERATORS.CONTAINS and
           isinstance(field._property, ArrayProperty))):
        cypher = ("%s IN %s" %
                  (cypher_primitive(value), element_name))
    elif condition.operator is OPERATORS.IN:
        cypher = ("%s IN %s" %
                  (element_name, cypher_primitive(value)))
    elif condition.operator is OPERATORS.MEMBER_IN:
        cypher = ('ANY(someVar IN %s WHERE someVar IN %s)' %
                  (element_name, cypher_primitive(value)))
    elif condition.operator in (OPERATORS.CONTAINS, OPERATORS.ICONTAINS):
        if isinstance(field._property, StringProperty):
            #TODO this is a poor man's excuse for Java regex escaping. we need
            # a better solution
            regex = ('.*%s.*' % re.sub('"\'`;:{}\(\)\|', '', value) )
            cypher = '%s =~ %s' % (element_name, cypher_primitive(regex))
        else:
            raise exceptions.ValidationError('The contains operator is only'
                                             ' valid against string and array '
                                             'properties.')
    elif condition.operator in (OPERATORS.STARTSWITH, OPERATORS.ISTARTSWITH):
        if not isinstance(field._property, StringProperty):
            raise exceptions.ValidationError(
                'The startswith operator is only valid against string '
                'properties.')
        cypher = ("LEFT(%s, %d) = %s" %
                  (element_name, len(value), cypher_primitive(value)))
    elif condition.operator in (OPERATORS.ENDSWITH, OPERATORS.IENDSWITH):
        if not isinstance(field._property, StringProperty):
            raise exceptions.ValidationError(
                'The endswith operator is only valid against string '
                'properties.')
        cypher = ("RIGHT(%s, %d) = %s" %
                  (element_name, len(value), cypher_primitive(value)))
    elif condition.operator in (OPERATORS.REGEX, OPERATORS.IREGEX):
        if not isinstance(field._property, StringProperty):
            raise exceptions.ValidationError(
                'The regex operator is only valid against string '
                'properties.')
        if condition.operator is OPERATORS.IREGEX:
            value = '(?i)' + value
        cypher = ("%s =~ %s" %
                  (element_name, cypher_primitive(value)))
    elif condition.operator is OPERATORS.YEAR:
        if not isinstance(field._property, (DateProperty, DateTimeProperty)):
            raise exceptions.ValidationError(
                'The year operator is only valid against date-based '
                'properties.')
        cypher = ("SUBSTRING(%s, 0, 4) = %s" %
                  (element_name, cypher_primitive(unicode(value).zfill(4))))
    elif condition.operator is OPERATORS.MONTH:
        if not isinstance(field._property, (DateProperty, DateTimeProperty)):
            raise exceptions.ValidationError(
                'The month operator is only valid against date-based '
                'properties.')
        cypher = ("SUBSTRING(%s, 5, 2) = %s" %
                  (element_name, cypher_primitive(unicode(value).zfill(2))))
    elif condition.operator is OPERATORS.DAY:
        if not isinstance(field._property, (DateProperty, DateTimeProperty)):
            raise exceptions.ValidationError(
                'The day operator is only valid against date-based '
                'properties.')
        cypher = ("SUBSTRING(%s, 8, 2) = %s" %
                  (element_name, cypher_primitive(unicode(value).zfill(2))))
    elif condition.operator is OPERATORS.ISNULL:
        if not isinstance(field._property, BoundRelationship):
            cypher = 'HAS(%s)' % re.sub(r'(\?|\!)$', '', element_name)
            if value:
                cypher = 'NOT(%s)' % cypher
    else:
        raise NotImplementedError('Other operators are not yet implemented.')

    return cypher


def cypher_predicates_from_q(q):
    if not isinstance(q, Q):
        identifier = '__'.join(['n'] + q.path)
        if getattr(q.field, 'id', False):
            value_exp = 'ID(%s)' % identifier
        else:
            value_exp = '%s.%s!' % (identifier, q.field.attname)

        # Add an 'HAS()' condition to case unsensitive lookup
        if q.operator in (OPERATORS.IEXACT, OPERATORS.ICONTAINS,
                        OPERATORS.ISTARTSWITH, OPERATORS.IENDSWITH):
            return 'HAS(%s) AND (%s)' % (
                # Remove "!" from value_exp
                value_exp[:-1], 
                cypher_predicate_from_condition(value_exp, q)
            )
        else:
            return '(%s)' % cypher_predicate_from_condition(value_exp, q)
    children = list(not_none(cypher_predicates_from_q(c) for c in q.children))
    if len(children) > 0:
        expr = (" %s " % q.connector).join(children)
        return "NOT (%s)" % expr if q.negated else expr
    return None


def cypher_where_from_q(nodetype, q):
    """
    Build a Cypher WHERE clause based on a str Cypher element identifier that
    should resolve to a node or rel column in the final query, and a Q tree of
    kwarg filters.
    """
    cond_q = condition_tree_from_q(nodetype, q)
    exps = cypher_predicates_from_q(cond_q)
    return "WHERE %s\n" % exps if exps else ''


def cypher_rel_str(rel_type, rel_dir, identifier=None, optional=False):
    dir_strings = ('<-%s-', '-%s->')
    out = neo_constants.RELATIONSHIPS_OUT
    id_str = '`%s`' % identifier if identifier is not None else ''
    return dir_strings[rel_dir == out] % ('[%s%s:`%s`]' %
                                          (id_str, '?' if optional else '', rel_type))


def cypher_from_fields(nodetype, fields):
    """
    Generates Cypher MATCH and RETURN expressions from `select_related()` style
    field strings.
    """
    #TODO this function is a great example of why there should be some greater
    # layer of abstraction between query code and script generation. a first
    # step would be to write some CypherPrimitive, CypherList, etc.
    matches, returns = [], []
    reqd_fields = (field for i, field in enumerate(fields)
                   if not any(other_field.startswith(field)
                              and field != other_field
                              for other_field in fields[i:]))

    for i, field in enumerate(reqd_fields):
        path_name = 'p%d' % i
        returns.append(path_name)

        rel_match_components = []
        cur_m = nodetype
        for step in field.split('__'):
            #try to properly match a model field to the provided field string
            rels = getattr(cur_m._meta, '_relationships', {}).items()
            candidates_on_models = sorted((s for s in ((score_model_rel(step, r), r)
                                          for _, r in rels) if s > 0), reverse=True)
            if len(candidates_on_models) < 1:
                # give up if we can't find a valid candidate
                break
            rel_choice = candidates_on_models[0][-1]
            rel_match_components.append(
                cypher_rel_str(rel_choice.rel_type, rel_choice.direction))
            cur_m = (rel_choice.target_model
                     if not rel_choice.target_model is cur_m
                     else rel_choice.source_model)

        node_match_components = []  # Cypher node identifiers
        type_matches = []  # full Cypher type matching paths for return types
        for ri in xrange(len(rel_match_components)):
            return_node_name = '%s_r%d' % (path_name, ri)
            return_node_type_name = '%s_t' % return_node_name

            returns.extend((return_node_name, '%s.name' % return_node_type_name))

            node_match_components.append(return_node_name)
            type_matches.append('%s-[:`%s`]->%s' %
                                (return_node_type_name, INSTANCE_REL, return_node_name))

        model_match = ''.join(
            itertools.ifilter(None, itertools.chain.from_iterable(
                itertools.izip_longest(rel_match_components,
                                       node_match_components))))

        matches.append('%s=(s%s)' % (path_name, model_match))
        matches.extend(type_matches)

    return 'MATCH %s RETURN %s' % (','.join(matches), ','.join(returns))


def cypher_column_name_from_cond(cond):
    return '__'.join(['n'] + cond.path)


def cypher_match_from_q(nodetype, q):
    # TODO TODO DRY VIOLATION refactor to share common code with
    # select_related and Condition
    paths = []
    conditions = condition_tree_leaves(q)
    for cond in conditions:
        if len(cond.path) > 0:
            path = [NodeComponent('n')]
            cur_m = nodetype
            for level, cond_step in enumerate(cond.path):
                rels = getattr(cur_m._meta, '_relationships', {}).items()
                candidates_on_model = sorted((s for s in (
                    (score_model_rel(cond_step, r), r) for _, r in rels
                ) if s[0] > 0), reverse=True)
                rel_choice = candidates_on_model[0][-1]

                direction = ('>'
                             if (rel_choice.direction == 'out') !=
                                (rel_choice.target_model is nodetype)
                             else '<')
                rel_type = rel_choice.rel_type

                path.append(RelationshipComponent(types=[rel_type],
                        direction=direction, optional=True))

                cur_m = (rel_choice.target_model
                         if not rel_choice.target_model is cur_m
                         else rel_choice.source_model)
                if level != len(cond.path) - 1:
                    path.append(NodeComponent())
            path.append(NodeComponent(cypher_column_name_from_cond(cond)))
            paths.append(path)
    
    return Match(Path(p) for p in paths)


###################
# QUERY EXECUTION #
###################

def score_model_rel(field_name, bound_rel):
    """
    Scores a model's bound relationship on how likely it is to be the referrent
    of a user's select_related field.
    """
    score = 0
    if bound_rel.attname == field_name:
        score += 1
    if bound_rel.rel_type == field_name:
        score += .5
    return score


#XXX this will have to change significantly when issue #1 is worked on
#TODO this can be broken into retrieval and rebuilding functions
def execute_select_related(models=None, query=None, index_name=None,
                           fields=None, max_depth=1, model_type=None,
                           using=DEFAULT_DB_ALIAS):
    """
    Retrieves select_related models and and adds them to model caches.
    """
    if models is not None:
        if len(models) == 0:
            return
        #infer the database we're using
        model_dbs = [m.using for m in models if m.node]
        if len(set(model_dbs)) > 1:
            raise ValueError("Models to select_related should all be from the "
                             "same database.")
        else:
            using = model_dbs[0] if len(model_dbs) > 0 else using
        #infer the model type
        if model_type is None:
            model_type = type(models[0])
        start_expr = u'node(%s)' % ','.join(str(m.id) for m in models)
        start_depth = 1
    elif index_name and query:
        if model_type is None:
            raise ValueError("Must provide a model_type if using select_related"
                             " with an index query.")
        models = []
        start_expr = 'node:`%s`("%s")' % (index_name, str(query).replace('"', '\\"'))
        start_depth = 0
    else:
        raise ValueError("Either a model set or an index name and query need to be provided.")

    conn = connections[using]

    if fields is None:
        if max_depth < 1:
            raise ValueError("If no fields are provided for select_related, max_depth must be > 0.")
        #the simple depth-only case
        cypher_query = 'START s = %s '\
                       'MATCH p0=(s-[g*%d..%d]-p0_r0), p0_r0_t-[:`%s`]->p0_r0 '\
                       'WHERE NONE(r in g WHERE type(r) = "<<INSTANCE>>")'\
                       'RETURN p0, p0_r0, p0_r0_t.name'
        cypher_query %= (start_expr, start_depth, max_depth, INSTANCE_REL)
    elif fields:
        #build a match pattern + type check for each field
        match_and_return_expr = cypher_from_fields(model_type, fields)
        cypher_query = 'START s=%s %s'
        cypher_query %= (start_expr, match_and_return_expr)
    else:
        raise ValueError("Either a field list or max_depth must be provided "
                         "for select_related.")

    results = conn.cypher(cypher_query)

    #TODO this is another example of needing a cypher generation abstraction.
    paths = sorted(not_none(
                   results.get_all_rows(lambda c: re.match('p\d+$', c) is not None)),
                   key=lambda p: p['length'])
    nodes, types = [], []
    for path_i in itertools.count():
        path_name = 'p%d' % path_i
        if path_name not in results.column_names:
            break
        for node_i in itertools.count():
            return_node_name = '%s_r%s' % (path_name, node_i)
            return_node_type = '%s_t.name' % return_node_name
            if not (return_node_name in results.column_names or
                    return_node_type in results.column_names):
                break
            nodes = itertools.chain(nodes,
                                    results.get_all_rows(return_node_name))
            types = itertools.chain(types,
                                    results.get_all_rows(return_node_type))

    nodes = not_none(nodes)
    types = not_none(types)

    #put nodes in an id-lookup dict
    nodes = [script_utils.LazyNode.from_dict(d) for d in nodes]
    nodes_by_id = dict((n.id, n) for n in nodes)
    #add any nodes we've got from the models list
    if models is not None:
        nodes_by_id.update(dict((m.id, script_utils.LazyNode.from_dict(m.node._dic)) for m in models))

    #batch all relationships from paths and put em in a dict
    rels_by_id = {}
    rel_ids = []
    for p in paths:
        for rel_url in p['relationships']:
            rel_ids.append(id_from_url(rel_url))
    rels = script_utils.batch_rels(rel_ids, using)
    for r in rels:
        r.set_custom_node_lookup(nodes_by_id)
        rels_by_id[r.id] = r

    #build all the models, ignoring types that django hasn't loaded
    rel_nodes_types = ((n, get_model(*t.split(':')))
                       for n, t in itertools.izip(nodes, types))

    rel_models = (t._neo4j_instance(n) for n, t in rel_nodes_types if
                  (t is not None) and (t._neo4j_instance(n) not in models))
    models_so_far = dict((m.id, m) for m in itertools.chain(models, rel_models))

    # TODO HACK set model rel caches to empty
    # in the future, we'd like to properly mark a cache as 'filled', 'empty',
    # or 'unknown', to deal with deferred relationships versus those that have
    # been serviced by select_related. That will require doing more bookkeeping-
    # eg, knowing which models are at what depth in the max_depth case, and
    # which correspond to which field in the field case.
    # This covers the easy case, max_depth=1, and ignores the hard case of
    # dealing with a fields list or a greater depth.
    if fields is None and max_depth == 1:
        for m in models:
            for field_name, field in m._meta._relationships.items():
                #if rel is many side
                rel_on_model = getattr(m, field_name, None)
                if rel_on_model is not None and hasattr(rel_on_model, '_cache'):
                    rel_on_model._get_or_create_cache()  # set the cache to loaded and empty
                else:
                    #otherwise single side
                    field._set_cached_relationship(m, None)

    #paths ordered by shortest to longest
    paths = sorted(paths, key=lambda v: v['length'])

    for path in paths:
        m = models_so_far[id_from_url(path['start'])]

        node_it = (id_from_url(url) for url in path['nodes'][1:])
        rel_it = (id_from_url(url) for url in path['relationships'])

        cur_m = m
        for rel_id, node_id in itertools.izip(rel_it, node_it):

            if node_id not in models_so_far:
                # we've loaded a node outside of neo4django, or of a type
                # not yet loaded by neo4django. skip it.
                continue

            #make choice ab where it goes
            rel = rels_by_id[rel_id]
            rel.direction = (neo_constants.RELATIONSHIPS_OUT if node_id == rel.end.id
                             else neo_constants.RELATIONSHIPS_IN)

            field_candidates = [(k, v) for k, v in cur_m._meta._relationships.items()
                                if str(v.rel_type) == str(rel.type) and v.direction == rel.direction]
            if len(field_candidates) < 1:
                # nowhere to put the node- it's either related outside
                # neo4django or something else is going on
                continue
            elif len(field_candidates) > 1:
                raise ValueError("Too many model field candidates for "
                                 "returned path - there's an error in the "
                                 "Cypher query or your model definition.")
            field_name, field = field_candidates[0]

            #grab the model that should fit in this part of the path
            new_model = models_so_far[node_id]

            #if rel is many side
            rel_on_model = getattr(cur_m, field_name, None)
            if rel_on_model and hasattr(rel_on_model, '_cache'):
                rel_on_model._add_to_cache((rel, new_model))
                if field.ordered:
                    rel_on_model._cache.sort(
                        key=lambda r: r[0].properties.get(ORDER_ATTR, None))
            else:
                #otherwise single side
                field._set_cached_relationship(cur_m, new_model)
            cur_m = new_model

# we want some methods of sql.Query but don't want the burder of inheriting
# everything. these methods are pulled off django.db.models.sql.query.Query
QUERY_PASSTHROUGH_METHODS = ('set_limits', 'clear_limits', 'can_filter',
                             'add_ordering', 'clear_ordering',
                             'add_distinct_fields', 'add_update_values',
                             'add_update_fields')

@borrows_methods(subqueries.UpdateQuery, QUERY_PASSTHROUGH_METHODS)
class Query(object):
    aggregates_module = aggregates
    query_terms = set([
        'exact', 'contains', 'icontains', 'gt', 'gte', 'lt', 'lte', 'in',
        'startswith', 'istartswith', 'endswith', 'iendswith', 'range', 'year',
        'month', 'day', 'week_day', 'isnull', 'search', 'regex', 'iregex',
        ])

    def __init__(self, model, filters=None, max_depth=None,
                 select_related_fields=[]):
        self.filters = filters or []
        self.model = model
        self.max_depth = max_depth
        self.select_related_fields = list(select_related_fields)
        self.select_related = bool(select_related_fields) or max_depth

        self.return_fields = {'n': 'n'}

        self.aggregates = {}
        self.distinct_fields = []

        self.start_clause = None
        self.start_clause_param_func = lambda: {}
        self.with_clauses = []
        self.end_clause = None

        self.limit_before_return = None

        self.distinct = False
        self.distinct_fields = None

        self.standard_ordering = True
        self.query_terms = None

        # XXX to handle overreaching django code like in the admin - not used
        # otherwise
        self.where = False

        self.clear_limits()
        self.clear_ordering()

        # for updates
        self.values = []
        self.related_updates = {}

    def add_q(self, q):
        cond_q = condition_tree_from_q(self.model, q)
        self.filters.append(cond_q)
        return self

    def add_select_related(self, fields):
        self.select_related = True
        self.select_related_fields.extend(fields)

    def add_aggregate(self, aggregate, model, alias, is_summary):
        opts = model._meta
        if '__' in aggregate.lookup:
            raise NotImplementedError('Only simple field aggregates are'
                                      ' currently supported.')
        field_alias = aggregate.lookup
        try:
            source = opts.get_field(field_alias)
        except:  # TODO fix bare except (FieldDoesNotExist)
            source = field_alias

        aggregate.add_to_query(self, alias, col=field_alias, source=source,
                               is_summary=is_summary)

    def add_related_update(self, model, field, value):
        raise FieldError('Cannot update model field %s - only non-relations are'
                         ' permitted.' % field)

    def add_with(self, field_dict, **kwargs):
        self.with_clauses.append(With(field_dict, **kwargs))

    def set_start_clause(self, clause, param_dict_or_func=None):
        """
        clause - anything whose `as_cypher()` method returns a valid beginning
        of a Cypher query as a str. Additional elements, like MATCH queries, can
        be included as well.
        """
        self.start_clause = clause
        if param_dict_or_func is None:
            param_dict_or_func = {}
        self.start_clause_param_func = (param_dict_or_func if
                                        callable(param_dict_or_func) else lambda: param_dict_or_func)

    def get_start_clause_and_param_dict(self):
        # TODO if a clause has been set, return that
        # otherwise, compute it from conditions
        # (requires a refactor from as_groovy())
        return self.start_clause, self.start_clause_param_func()

    def set_limit_before_return(self, i):
        self.limit_before_return = i

    def model_from_node(self, node):
        return self.model._neo4j_instance(node)

    def clone(self):
        clone = type(self)(self.model, self.filters, self.max_depth,
                           self.select_related_fields)
        clone_attrs = ('order_by', 'return_fields', 'aggregates', 'distinct',
                       'distinct_fields', 'high_mark', 'low_mark',
                       'start_clause', 'start_clause_param_func',
                       'with_clauses', 'end_clause', 'standard_ordering',
                       'limit_before_return', 'values', 'related_updates')
        for a in clone_attrs:
            setattr(clone, a, getattr(self, a))
        return clone

    def get_aggregation(self, using):
        query = self.clone()

        def make_aggregate_of_n(agg):
            from .properties import BoundProperty, Property
            #TODO HACK when we start adding more columns this will get messy
            #TODO HACK this should resolve the field, then use field.attname
            # or similar to get the actual db prop name
            #TODO HACK this is just to cover weird cases like '*'...
            agged_over = 'n.%s' % agg.prop_name \
                         if isinstance(agg.source, (BoundProperty, Property)) \
                         else agg.prop_name
            return type(agg)(agged_over, source=agg.source,
                             is_summary=agg.is_summary)
        query.return_fields = SortedDict(
            (alias, make_aggregate_of_n(agg).as_cypher())
            for alias, agg in query.aggregates.iteritems())
        groovy, params = query.as_groovy(using)
        result_set = connections[using].gremlin_tx(groovy, raw=True, **params)
        # TODO HACK this only works for one aggregate
        return {query.return_fields.keys()[0]: result_set[0]}

    def as_groovy(self, using):
        filters = uniqify(self.filters)

        id_conditions = []

        # check all top-level children for id conditions
        for q in filters:
            if q.connector == 'AND':
                id_conditions.extend(c for c in q.children
                                     if getattr(getattr(c, 'field', False),
                                                'id', False))

        grouped_id_conds = itertools.groupby(id_conditions, lambda c: c.operator)
        id_lookups = dict(((k, list(l)) for k, l in grouped_id_conds))

        exact_id_lookups = list(id_lookups.get(OPERATORS.EXACT, []))
        if len(exact_id_lookups) > 1:
            raise ValueError("Conflicting exact id lookups - a node can't have"
                             " two ids.")

        in_id_lookups = list(id_lookups.get(OPERATORS.IN, []))

        # build index queries from filters

        index_qs = not_none(lucene_query_and_index_from_q(using, self.model, q)
                            for q in filters)
        
        # combine any queries headed for the same index and replace lucene
        # queries with strings

        index_qs_dict = {}
        for key, val in index_qs:
            if key in index_qs_dict:
                if index_qs_dict[key]:
                    index_qs_dict[key] &= val
            else:
                index_qs_dict[key] = val

        index_qs = [(key, unicode(val)) for key, val in index_qs_dict.iteritems()
                    if val is not None]
        
        # use index lookups, ids, OR a type tree traversal as a cypher START,
        # then unindexed conditions as a WHERE

        start_clause, cypher_params = self.get_start_clause_and_param_dict()

        # add the typeNodeId param, either for type verification or initial
        # type tree traversal
        cypher_params['typeNodeId'] = self.model._type_node(using).id

        type_restriction_expr = """
        n<-[:`<<INSTANCE>>`]-()<-[:`<<TYPE>>`*0..]-typeNode
        """

        type_restriction_pattern = Path([
            NodeComponent('n'),
            RelationshipComponent(types=['<<INSTANCE>>'], direction='<'),
            NodeComponent(),
            RelationshipComponent(types=['<<TYPE>>'], direction='<',
                                  length_or_range=(0, None)),
            NodeComponent('typeNode'),
        ])

        # separate filters into those requiring a MATCH clause and those that
        # don't
        non_spanning_filters = []
        spanning_filters = []

        for q in filters:
            if all((len(cond.path) < 1) for cond in condition_tree_leaves(q)):
                non_spanning_filters.append(q)
            else:
                spanning_filters.append(q)

        where_clause = cypher_where_from_q(self.model,
                                           Q(*non_spanning_filters))

        with_clauses = self.with_clauses or []

        limit = self.high_mark - self.low_mark if self.high_mark is not None else None

        if self.end_clause is None and len(self.values) > 0:
            # for updating queries
            return_clause = Clauses([Set(dict((tup[0].name, tup[2])
                                              for tup in self.values)),
                                     Return(self.return_fields)])
        elif self.end_clause is None:
            return_clause = Return(self.return_fields, skip=self.low_mark,
                    limit=limit, distinct_fields=['n'] if self.distinct else [])
        else:
            return_clause = self.end_clause

        order_by = OrderBy([OrderByTerm(ColumnExpression('n', field.lstrip('-')),
                                        negate=(field.startswith('-') == self.standard_ordering))
                            for field in self.order_by]) if self.order_by else None

        if order_by is not None:
            # decide where to inject the ORDER BY expression - if the fields
            # ordered aren't being returned, it needs to go before the RETURN
        
            all_order_ids_returned = all(i in return_clause.passing_identifiers
                                         for i in order_by.required_identifiers)
            if isinstance(return_clause, Return) and all_order_ids_returned:
                return_clause.order_by = order_by
            else:
                # TODO if the clauses before this don't have all the proper
                # passing identifiers, raise an exception
                prior_clause = ([start_clause] + with_clauses)[-1]
                passing_ids = getattr(
                    prior_clause, 'passing_identifiers', ['n'])
                with_clauses.append(With(dict((i, i) for i in passing_ids),
                                        order_by=order_by))

        groovy_script = None
        params = {
            #TODO HACK need a generalization
            'returnColumn': self.return_fields.keys()[0]
        }

        # TODO none of these queries but the last properly take type into
        # account.
        if len(in_id_lookups) > 0 or len(exact_id_lookups) > 0:
            # collect id lookups by column
            in_id_lookups_by_column = defaultdict(list)
            exact_id_lookups_by_column = defaultdict(list)

            for lookup in in_id_lookups:
                in_id_lookups_by_column[cypher_column_name_from_cond(lookup)]\
                        .append(lookup)

            for lookup in exact_id_lookups:
                exact_id_lookups_by_column[cypher_column_name_from_cond(lookup)]\
                        .append(lookup)

            columns = uniqify(exact_id_lookups_by_column.keys() + 
                              in_id_lookups_by_column.keys())

            start_field_dict = {}
            start_param_dict = {}

            # for each column, check for conflicts between id lookups and build
            # out the start clause field dict
            for column in columns:
                exact_lookups = exact_id_lookups_by_column[column]
                in_lookups = in_id_lookups_by_column[column]
                id_set = reduce(and_, (set(c.value) for c in in_lookups)) if in_lookups else set([])
                if len(exact_lookups) > 0:
                    exact_ids = uniqify(e.value for e in exact_lookups)
                    if len(exact_ids) > 1:
                        raise ValueError("Conflicting id__exact lookups - a "
                                         "node can't have two ids.")
                    exact_id = exact_ids[0]
                    if id_set and exact_id not in id_set:
                        raise ValueError("Conflicting id__exact and id__in lookups"
                                         " - a node can't have two ids.")
                    else:
                        id_set = set([exact_id])

                if len(id_set) >= 1:
                    param = column + '_startParam'
                    start_field_dict[column] = 'node({%s})' % param
                    start_param_dict[param] = list(id_set)

            if len(start_field_dict) >= 1:
                start_clause = start_clause or Start(start_field_dict,
                                                     start_param_dict.keys())
                groovy_script = """
                    results = []
                    startParams = startParams.findResults{
                        if (it.value) {
                            [it.key, Neo4Django.getVerticesByIds(it.value).collect{v -> v.id}]
                        }
                    }.collectEntries()
                    cypherParams += startParams
                    table = Neo4Django.cypher(cypherQuery,cypherParams)
                    results = table.columnAs(returnColumn)
                    """
                params['startParams'] = start_param_dict
            else:
                # XXX None is returned, meaning an empty result set
                return (None, None)
        elif len(index_qs) > 0:
            start_clause = start_clause or Start({'n': 'node({startParam})'},
                                                 ['startParam'])
            groovy_script = """
                results = []
                startIds = Neo4Django.queryNodeIndices(startQueries)\
                            .collect{it.id}
                cypherParams['startParam'] = startIds
                table = Neo4Django.cypher(cypherQuery, cypherParams)
                results = table.columnAs(returnColumn)
                """
            params['startQueries'] = index_qs
        else:
            #TODO move this to being index-based - it won't work for abstract model queries
            if start_clause is None:
                start_clause = Clauses([Start({'typeNode': 'node({typeNodeId})'},
                                              ['typeNodeId']),
                                        Match([type_restriction_pattern])])
                # we don't need an additional type restriction since it's
                # handled in the start
                type_restriction_pattern = None
            groovy_script = """
                results = []
                table = Neo4Django.cypher(cypherQuery, cypherParams)
                results = table.columnAs(returnColumn)
                """

        # make sure the start clause includes the typeNode
        if isinstance(start_clause, Clauses):
            start_clause, extra_start_clauses = start_clause[0], start_clause[1:]
        else:
            extra_start_clauses = []
        if 'typeNode' not in start_clause.start_assignments:
            start_clause.start_assignments['typeNode'] = 'node({typeNodeId})'
            start_clause.cypher_params += ['typeNodeId']
        start_clause = Clauses([start_clause] + extra_start_clauses)

        # add groovy to re-index after an update
        if len(self.values) > 0:
            reindex_values = [((model or self.model).index_name(),
                               field.name,
                               field.to_neo_index(value))
                              for field, model, value in self.values if field.indexed]
            if len(reindex_values) > 0:
                groovy_script += """
                def nodeToIndex, rawIndex, index
                while( results.hasNext() ) {
                    nodeToIndex = results.next()
                    valuesToIndexPerNode.each{ indexName, field, value ->
                        (index, rawIndex) = Neo4Django.getOrCreateIndex(indexName)
                        rawIndex.add(nodeToIndex, field, value)
                    }
                }
                """
                params['valuesToIndexPerNode'] = reindex_values


        # take care of any relationship-spanning lookups
        if len(spanning_filters) > 0:
            combined_filter = reduce(and_, spanning_filters)
            # build match clause
            match = cypher_match_from_q(self.model, combined_filter)
            # build where clause
            where = cypher_where_from_q(self.model, combined_filter)
            # TODO DRY VIOLATION this prior_clause / WITH clause pattern is showing up a alot
            prior_clause = ([start_clause] + with_clauses)[-1]
            passing_ids = getattr(
                prior_clause, 'passing_identifiers', ['n'])
            with_clauses.append(With(dict((i, i) for i in passing_ids),
                                     match=match, where=where))

        # if the type restriction hasn't been removed and this isn't an
        # abstract model (which can't be type restricted as easily)
        if type_restriction_pattern and not getattr(self.model._meta,
                                                    'abstract', False):
            # TODO DRY violation
            prior_complex_clause = ([start_clause] + with_clauses)[-1]
            passing_ids = getattr(prior_complex_clause, 'passing_identifiers', ['n'])
            with_clauses.append(With(dict((i, i) for i in passing_ids),
                    where='WHERE ' + unicode(type_restriction_pattern)))

        if self.limit_before_return:
            # TODO DRY violation
            prior_clause = ([start_clause] + with_clauses)[-1]
            passing_ids = getattr(
                prior_clause, 'passing_identifiers', ['n'])
            with_clauses.append(With(dict((i, i) for i in passing_ids),
                                    limit=self.limit_before_return))



        str_clauses = [start_clause.as_cypher(), where_clause] + \
                      [c.as_cypher() for c in with_clauses] + \
                      [return_clause.as_cypher()]

        params['cypherQuery'] = ' '.join(str_clauses) + ';'
        params['cypherParams'] = cypher_params

        return groovy_script, params

    def execute(self, using):
        conn = connections[using]

        groovy, params = self.as_groovy(using)

        raw_result_set = conn.gremlin_tx(groovy, **params) if groovy is not None else []

        #make the result_set not insane (properly lazy)
        result_set = [add_auth(LazyNode.from_dict(d), conn)
                      for d in raw_result_set._list] if raw_result_set else []

        model_results = [self.model_from_node(n) for n in result_set]

        if self.select_related:
            sel_fields = self.select_related_fields
            if not sel_fields:
                sel_fields = None
            execute_select_related(models=model_results,
                                   fields=sel_fields,
                                   max_depth=self.max_depth)

        for r in model_results:
            yield r

    def delete(self, using):
        clone = self.clone()
        clone.end_clause = DeleteNode(['n'])
        for m in clone.execute(using):
            pass

    def update(self, using, updates):
        if 'id' in updates or 'pk' in updates:
            raise FieldError("Neo4j doesn't allow node ids to be updated.")
        clone = self.clone()
        clone.add_update_values(updates)
        for m in clone.execute(using):
            pass

    def get_count(self, using):
        from django.db.models import Count
        obj = self.clone()
        obj.add_aggregate(Count('*'), self.model, 'count', True)
        aggregation = obj.get_aggregation(using)
        return aggregation.get('count', None)

    def has_results(self, using):
        obj = self.clone()
        obj.clear_ordering(True)
        obj.set_limit_before_return(1)
        return obj.get_count(using) > 0


#############
# QUERYSETS #
#############

class NodeQuerySet(QuerySet):
    """
    Represents a lazy database lookup for a set of node models.
    """
    def __init__(self, model, using=DEFAULT_DB_ALIAS, query=None):
        super(NodeQuerySet, self).__init__(model=model, using=using, query=query or Query(model))
        #TODO is this actually necessary?
        self._app_label = model._meta.app_label

    ########################
    # PYTHON MAGIC METHODS #
    ########################

    @not_implemented
    def __deepcopy__(self, memo):
        pass

    @not_implemented
    def __getstate__(self):
        pass

    ####################################
    # METHODS THAT DO DATABASE QUERIES #
    ####################################

    def __getitem__(self, k):
        """"
        If k is a slice or there's a ._result_cache, use super __getitem__.
        Otherwise, iterate over the queryset, loading items into the cache
        one by one, and return last element of the cache.
        """
        if not isinstance(k, (int, long)) or (k < 0) or \
           self._result_cache is not None:
            return super(NodeQuerySet, self).__getitem__(k)
        try:
            # ._fill_cache would be handy, but doesn't work when ._iter is None
            self._result_cache = []
            self._iter = self._iter or self.iterator()
            for _ in range(k + 1):
                self._result_cache.append(next(self._iter))
            return self._result_cache[-1]

        except self.model.DoesNotExist, e:
            raise IndexError(e.args)

    def __contains__(self, value):
        if self._result_cache is None:
            while True:
                i = 0
                try:
                    if self[i] == value:
                        return True
                    i += 1
                except (IndexError, StopIteration):
                    return False
        return super(NodeQuerySet, self).__contains__(value)

    def iterator(self):
        using = self.db
        if not self.query.can_filter():
            for model in self.query.execute(using):
                yield model
        else:
            start = 0
            stop = QUERY_CHUNK_SIZE
            while True:
                clone = self.query.clone()
                clone.set_limits(start, stop)
                piece = list(clone.execute(using))
                for model in piece:
                    yield model
                if len(piece) < QUERY_CHUNK_SIZE:
                    break
                start = stop
                stop += QUERY_CHUNK_SIZE

    #TODO leaving this todo for later transaction work
    @transactional
    def create(self, **kwargs):
        if 'id' in kwargs or 'pk' in kwargs:
            raise FieldError("Neo4j doesn't allow node ids to be assigned.")
        return super(NodeQuerySet, self).create(**kwargs)

    #TODO would be awesome if this were transactional
    def get_or_create(self, **kwargs):
        defaults = kwargs.pop('defaults', {})
        try:
            obj = self.get(**kwargs)
            created = False
        except:
            values = dict(defaults)
            values.update(kwargs)
            obj = self.create(**values)
            created = True
        return (obj, created)

    @transactional
    def in_bulk(self, id_list):
        return dict((o.id, o) for o in self.model.objects.filter(id__in=id_list))

    @alters_data
    def delete(self):
        self.query.delete(self.db)

    @alters_data
    def update(self, **kwargs):
        self.query.update(self.db, kwargs)

    ##################################################
    # PUBLIC METHODS THAT RETURN A QUERYSET SUBCLASS #
    ##################################################

    @not_implemented
    def values(self, *fields):
        pass

    @not_implemented
    def values_list(self, *fields, **kwargs):
        pass

    @not_implemented
    def dates(self, field_name, kind, order='ASC'):
        """
        Returns a list of datetime objects representing all available dates for
        the given field_name, scoped to 'kind'.
        """
        assert kind in ("month", "year", "day"), \
            "'kind' must be one of 'year', 'month' or 'day'."
        assert order in ('ASC', 'DESC'), \
            "'order' must be either 'ASC' or 'DESC'."
        return self._clone(klass=NodeDateQuerySet, setup=True,
                           _field_name=field_name, _kind=kind, _order=order)

    ##################################################################
    # PUBLIC METHODS THAT ALTER ATTRIBUTES AND RETURN A NEW QUERYSET #
    ##################################################################

    @not_implemented
    def complex_filter(self, filter_obj):
        pass

    def select_related(self, *fields, **kwargs):
        """
        Used the same way as in Django's ORM- select_related will load models
        from the graph up-front to minimize hitting the database.

        Some differences:
            - because we're dealing with a graph database, data will typically
            be highly connected. For this reason, depth defaults to 1.
            - we can't offer the same single-query transactional promises that
            Django's select_related offers, which means related objects might
            not be consistent. As usual, doing our best with what we have.
        """
        if 'depth' not in kwargs and not fields:
            kwargs['depth'] = 1
        return super(NodeQuerySet, self).select_related(*fields, **kwargs)

    def prefetch_related(self, *args, **kwargs):
        """
        Because of how Neo4j queries are built, this is just an alias for
        select_related.
        """
        return self.select_related(*args, **kwargs)

    @not_implemented
    def dup_select_related(self, other):
        pass

    @not_implemented
    def annotate(self, *args, **kwargs):
        pass

    def distinct(self, *field_names):
        if len(field_names) > 0:
            raise NotImplementedError("Only querying against distinct nodes is "
                                      "implemented. Distinct fields cannot be "
                                      "queried against.")
        return super(NodeQuerySet, self).distinct(*field_names)

    @not_supported
    def extra(self, *args, **kwargs):
        pass

    @not_implemented
    def defer(self, *fields):
        pass

    @not_implemented
    def only(self, *fields):
        pass

    ###################################
    # PUBLIC INTROSPECTION ATTRIBUTES #
    ###################################

    @property
    def db(self):
        "Return the database that will be used if this query is executed now"
        return self._db

    ###################
    # PRIVATE METHODS #
    ###################
    @not_supported
    def _as_sql(self, connection):
        pass


class NodeDateQuerySet(NodeQuerySet):

    def _setup_query(self):
        """
        Sets up any special features of the query attribute.

        Called by the _clone() method after initializing the rest of the
        instance.
        """
        self.query.clear_deferred_loading()
        self.query = self.query.clone(klass=sql.DateQuery, setup=True)
        self.query.select = []
        self.query.add_date_select(self._field_name, self._kind, self._order)

    def _clone(self, klass=None, setup=False, **kwargs):
        c = super(NodeDateQuerySet, self)._clone(klass, False, **kwargs)
        c._field_name = self._field_name
        c._kind = self._kind
        if setup and hasattr(c, '_setup_query'):
            c._setup_query()
        return c

########NEW FILE########
__FILENAME__ = relationships
from django.db import models
from django.db.models.fields.related import add_lazy_relation
from django.db.models.query_utils import DeferredAttribute
from django.db.models.query import EmptyQuerySet
from django.db.models.signals import post_delete
from django.forms import ModelChoiceField, ModelMultipleChoiceField
from django.utils.text import capfirst
from django.dispatch import receiver

from neo4django import Incoming, Outgoing
from neo4django.db import DEFAULT_DB_ALIAS
from neo4django.decorators import not_implemented, transactional
from neo4django.utils import AssignableList, AttrRouter
from neo4django.constants import INTERNAL_ATTR, ORDER_ATTR
from .base import NodeModel
from .query import (NodeQuerySet, Query, cypher_rel_str)
from .cypher import  (Clauses, Start, With, Match, Path, NodeComponent,
        RelationshipComponent, OrderBy, OrderByTerm, ColumnExpression)

from neo4jrestclient.constants import RELATIONSHIPS_IN, RELATIONSHIPS_OUT

from collections import defaultdict
from functools import partial


class RelationshipModel(object):
    """
    Model backing all relationships. Intended for a single instance to
    correspond to an edge in the graph.
    """
    __relationship = None

    def __init__(self):
        pass

    @property
    def relationship(self):
        rel = self.__relationship
        if rel is None:
            # XXX: better exception
            raise ValueError("Unsaved objects have no relationship.")
        return rel
    _neo4j_underlying = relationship

    @classmethod
    def new(RelationshipModel, module, name, bases):
        return type(name, bases + (RelationshipModel,),
                    {'__module__': module})

    @not_implemented
    @classmethod
    def add_field(self, prop):
        raise NotImplementedError("<RelationshipModel>.add_field()")


class Relationship(object):

    def __init__(self, target, rel_type=None, direction=None, optional=True,
                 single=False, related_single=False, related_name=None,
                 editable=True, verbose_name=None, help_text=None,
                 preserve_ordering=False, null = True, metadata={},
                 rel_metadata={}):
        if direction is Outgoing:
            direction = RELATIONSHIPS_OUT
        elif direction is Incoming:
            direction = RELATIONSHIPS_IN
        elif direction is None:
            if not isinstance(rel_type, basestring):
                direction = rel_type.direction
            else:
                direction = RELATIONSHIPS_OUT
        if not isinstance(rel_type, basestring):
            if rel_type.direction != direction:
                raise ValueError("Incompatible direction!")
            rel_type = rel_type.type

        self._reverse_relationship_type = Relationship

        self.__target = target
        self.name = rel_type
        self.__single = single
        self.direction = direction
        self.__related_single = related_single
        self._related_name = related_name
        self.__ordered = preserve_ordering
        self.__meta = metadata
        self.__related_meta = rel_metadata
        self.editable = editable
        self.optional = optional
        self.verbose_name = verbose_name
        self.help_text = help_text
        self.null = null

    target_model = property(lambda self: self.__target)
    ordered = property(lambda self: self.__ordered)
    meta = property(lambda self: self.__meta)
    single = property(lambda self: self.__single)

    __is_reversed = False

    def reverse(self, target, name):
        if self.direction is RELATIONSHIPS_IN:
            direction = RELATIONSHIPS_OUT
        elif self.direction is RELATIONSHIPS_OUT:
            direction = RELATIONSHIPS_IN
        else:
            direction = RELATIONSHIPS_OUT
        Type = self._reverse_relationship_type
        relationship = Type(
            target, rel_type=self.name, direction=direction,
            single=self.__related_single, related_name=name,
            metadata=self.__related_meta, preserve_ordering=self.__ordered)
        relationship.__is_reversed = True
        return relationship

    def reversed_name(self, target=None):
        if self._related_name:
            return self._related_name
        else:
            return self.get_name(target, self.__single)

    @staticmethod
    def get_name(target, single=False):
        suffix = '%s' if single else '%s_set'
        if isinstance(target, basestring):
            name = target.rsplit('.', 1)[-1]
        else:
            name = target.__name__
        return suffix % name.lower()

    def get_internal_type(self):
        return "Neo4jRelationship"

    def has_default(self):
        return False

    def _get_bound_relationship_type(self):
        # TODO this will change with relationship models (#1)
        if self.__single:
            return SingleNode
        else:
            return MultipleNodes

    def _get_new_bound_relationship(self, source, name):
        return self._get_bound_relationship_type()(self, source, self.name or name, name)

    def contribute_to_class(self, source, name):
        if not issubclass(source, NodeModel):
            raise TypeError("Relationships may only extend from Nodes.")
        self.creation_counter = source.creation_counter

        # XXX this is to cover strange situations like accidental overriding 
        # of abstract models' reverse relationships like issue #190 
        if hasattr(source, name): 
            return 

        # make sure this relationship doesn't overlap with another of the same
        # type and direction
        if hasattr(source._meta, '_relationships'):
            for r in source._meta._relationships.values():
                if r.rel_type == self.name and r.direction == self.direction:
                    import warnings
                    warnings.warn('`%s` and `%s` share a relationship type and '
                                  'direction. Is this what you meant to do?'
                                  % (r.name, name))
        bound = self._get_new_bound_relationship(source, name)
        source._meta.add_field(bound)
        if not hasattr(source._meta, '_relationships'):
            source._meta._relationships = {}
        source._meta._relationships[name] = bound
        setattr(source, name, bound)
        if isinstance(self.__target, basestring):
            def setup(field, target, source):
                if not issubclass(target, NodeModel):
                    raise TypeError("Relationships may only extend from Nodes.")
                # replace the string target with the real target
                self.__target = target
                bound._setup_reversed(target)
            add_lazy_relation(source, self, self.__target, setup)
        target = self.__target
        if not self.__is_reversed:
            bound._setup_reversed(target)

    def formfield(self, **kwargs):
        defaults = {
            'required': not self.optional,
            'label': capfirst(self.verbose_name),
            'help_text': self.help_text,
            'queryset': self.target_model.objects
        }
        if self.single:
            defaults['form_class'] = ModelChoiceField
        else:
            defaults['form_class'] = ModelMultipleChoiceField
        defaults.update(kwargs)

        form_class = defaults['form_class']
        del defaults['form_class']
        return form_class(**defaults)

    ###################
    # SPECIAL METHODS #
    ###################

    def __getinitargs__(self):
        return (self.__target, self.name, self.direction, True, self.__single,
                self.__related_single, self.reversed_name, self.__ordered,
                self.__meta, self.__related_meta)


#subclasses DeferredAttribute to avoid being set to None in
#django.db.models.Model.__init__().
class BoundRelationship(AttrRouter, DeferredAttribute):
    indexed = False
    rel = None
    primary_key = False
    choices = None
    db_index = None

    blank = True
    unique = False
    unique_for_date = False
    unique_for_year = False
    unique_for_month = False

    def __init__(self, rel, source, relname, attname, serialize=True):
        self.__rel = rel
        self.__source = source
        self._type = relname
        self.__attname = attname
        self.serialize = serialize
        relationships = self._relationships_for(source)
        relationships[self.__attname] = self  # XXX weakref
        self._route(['reversed_name',
                     'direction',
                     'target_model',
                     'ordered',
                     'help_text',
                     'meta',
                     'get_internal_type',
                     'help_text',
                     'null',
                     'has_default',
                     # form handling
                     'editable',
                     'formfield',
                     ], self.__rel)
        self.null = False

    def clean(self, value, instance):
        return value

    def has_default(self):
        return None

    def get_internal_type(self):
        return self.__rel.__class__.__name__

    def _setup_reversed(self, target):
        self.__target = target
        if not isinstance(target, basestring):
            self.__rel.reverse(self.__source,
                               self.__attname).contribute_to_class(
                                   target, self.reversed_name(self.__source))

    attname = name = property(lambda self: self.__attname)

    @property
    def rel_type(self):
        return self._type

    @property
    def relationship(self):
        return self.__rel

    @property
    def target_model(self):
        return self.__target

    @property
    def source_model(self):
        return self.__source

    def get_default(self):
        return None

    def contribute_to_class(self, source, name):
        return self.__rel.contribute_to_class(source, name)

    def _get_val_from_obj(self, obj):
        return self.__get__(obj)

    def value_to_string(self, obj):
        return str(self.__get__(self))

    @staticmethod
    def _state_for(instance, create=True):
        try:
            state = instance.__state
        except:
            state = {}
            if create:
                instance.__state = state
        return state

    @staticmethod
    def _relationships_for(obj_or_cls):
        meta = obj_or_cls._meta
        try:
            relationships = meta._relationships
        except:
            meta._relationships = relationships = {}
        return relationships

    @staticmethod
    def _all_relationships_for(obj_or_cls):
        new_rel_dict = {}
        new_rel_dict.update(BoundRelationship._relationships_for(obj_or_cls))

        cls = obj_or_cls if isinstance(obj_or_cls, type) else type(obj_or_cls)

        for parent in cls.__bases__:
            if hasattr(parent, '_meta'):
                new_rel_dict.update(BoundRelationship._all_relationships_for(parent))

        return new_rel_dict

    def _save_(instance, node):
        state = BoundRelationship._state_for(instance, create=False)
        if state:
            rels = BoundRelationship._all_relationships_for(instance)
            for key in state.keys():
                rels[key]._save_relationship(instance, node, state[key])
                if isinstance(state[key], tuple):  # HACK, rearchitect
                    state[key] = (False, state[key][1])

    #TODO this... well, consider revising
    NodeModel._save_neo4j_relationships = staticmethod(_save_)

    @not_implemented
    def _save_relationship(self, instance, node, state):
        pass

    def _load_relationships(self, node):
        #Returns all neo4j relationships attached to the provided neo4j node.
        #TODO TODO we can probably trash this function with the new backend, refs 174
        if self.direction is RELATIONSHIPS_OUT:
            rel_func = node.relationships.outgoing
        else:
            rel_func = node.relationships.incoming
        rels = rel_func([self._type])
        if not hasattr(self, '_relationships'):
            attrs = {}
        else:
            attrs = self._relationships.get_new_attrs()

        self._relationships = AssignableList(rels)
        for k in attrs.keys():
            setattr(self._relationships, k, attrs[k])
        return self._relationships

    creation_counter = property(lambda self: self.__rel.creation_counter)

    def _set_relationship(self, obj, state, value):
        if value is None:  # assume initialization - ignore
            return  # TODO: verify that obj is unsaved!
        raise TypeError("<%s>.%s is not assignable" %
                        (obj.__class__.__name__, self.name))

    def _del_relationship(self, obj, state):
        raise TypeError("Cannot delete <%s>.%s" %
                        (obj.__class__.__name__, self.name))

    def _create_neo_relationship(self, node, obj, **kwargs):
        neo_rel_attrs = kwargs.get('attrs', {})
        neo_rel_attrs[INTERNAL_ATTR] = True
        if obj.pk is None:
            obj.save(using=obj.using)
        other = obj.node
        # TODO: verify that it's ok in the reverse direction?
        if self.direction != 'out':
            node, other = other, node

        node.relationships.create(self._type, other, **neo_rel_attrs)

    @classmethod
    def to_python(cls, value):
        """
        A python-centric alias for from_neo()
        """
        return cls.from_neo(value)

    @classmethod
    def from_python(cls, value):
        """
        A python-centric alias for to_neo()
        """
        return cls.to_neo(value)

    @classmethod
    def to_neo(cls, value):
        return value

    @classmethod
    def from_neo(cls, value):
        return value

    ###################
    # SPECIAL METHODS #
    ###################

    def __getinitargs__(self):
        return (self.__rel, self.__source, self.__type, self.__attname, self.serialize)

    def __cmp__(self, other):
        return cmp(self.creation_counter, other.creation_counter)

    ######################
    # DESCRIPTOR METHODS #
    ######################

    def __get__(self, obj, cls=None):
        if obj is None:
            return self
        return self._get_relationship(obj, self._state_for(obj))

    def __set__(self, obj, value):
        self._set_relationship(obj, self._state_for(obj), value)

    def __delete__(self, obj):
        self._del_relationship(obj, self._state_for(obj))


class SingleNode(BoundRelationship):
    #BoundRelationship subclass for a single node relationship without an
    #associated relationship model.
    def _get_relationship(self, obj, state):
        if self.name in state:
            changed, result = state[self.name]
            return result

        if hasattr(obj, 'node'):
            this = obj.node
        else:
            return None

        result = self._load_related(this)
        state[self.name] = False, result
        return result

    def value_from_object(self, obj):
        return self.__get__(obj)

    @transactional
    def _load_related(self, node):
        relationships = self._load_relationships(node)
        #TODO seriously consider removing this restriction- I'm not sure I see
        # any benefit, and it makes creating neo4django-compliant graphs that
        # much more difficult.
        django_relationships = filter(lambda rel: rel[INTERNAL_ATTR], relationships)
        if len(django_relationships) < 1:
            return None
        elif len(django_relationships) > 1:
            raise ValueError("There's an ambiguous relationship set in the "
                             "database from node %d - there should only be one"
                             " relationship flagged as '_neo4django' for a "
                             "single=True Relationship." % node.id)
        return self._neo4j_instance(node, django_relationships[0])

    def _neo4j_instance(self, this, relationship):
        if this.id == relationship.end.id:
            that = relationship.start
        else:
            that = relationship.end  # get the other node

        return self.target_model._neo4j_instance(that)

    def _del_relationship(self, obj, state):
        self._set_relationship(obj, state, None)

    def _set_relationship(self, obj, state, other):
        state[self.name] = True, other

    def _save_relationship(self, instance, node, state):
        changed, other = state
        if not changed:
            return
        rels = self._load_relationships(node)

        #delete old relationship
        #create new relationship

        if other is None:
            #delete old relationship if it exists
            if hasattr(rels, 'single') and rels.single:
                rels.single.delete()  # TODO this deletion should be transactional w creation
            rels.single = None
        else:
            rels.single = self._create_neo_relationship(node, other)
            #other._save_neo4j_node(DEFAULT_DB_ALIAS)

    def save_form_data(self, instance, data):
        # TODO we need a function like _get_relationship that only takes a
        # model instance...
        state = self._state_for(instance)
        self._set_relationship(instance, state, data)

    def _set_cached_relationship(self, obj, other):
        state = BoundRelationship._state_for(obj)
        if self.name in state and state[self.name]:
            raise ValueError("Can't set the cache on an already initialized relationship!")
        state[self.name] = False, other


class BoundRelationshipModel(BoundRelationship):
    def __init__(self, rel, cls, relname, attname, Model):
        super(BoundRelationship, self).__init__(
            rel, cls, relname, attname)
        self.Model = Model
        raise NotImplementedError("Support for extended relationship "
                                  "models is not yet implemented.")


class SingleRelationship(BoundRelationshipModel):  # WAIT!

    @not_implemented
    def _get_relationship(self, obj, state):
        pass

    @not_implemented
    def _set_relationship(self, obj, state, other):
        pass


class MultipleNodes(BoundRelationship):
    #BoundRelationship subclass for a multi-node relationship without an
    #associated relationship model.

    def value_from_object(self, obj):
        return self.__get__(obj).all()

    def value_to_string(self, obj):
        return str([item.pk for item in list(self.__get__(obj).all())])

    def save_form_data(self, instance, data):
        # TODO we need a function like _get_relationship that only takes a
        # model instance...
        states = self._state_for(instance)
        self._set_relationship(instance, states, list(data))

    def clean(self, value, instance):
        # XXX HACK since we don't use a proxy object like
        # ForeignRelatedObjectsDescriptor (and actually return a
        # RelationshipInstance on getattr(model, field.attname)) so we have to
        # unpack a RelationshipInstance
        return list(value._added)

    def _get_state(self, obj, states):
        state = states.get(self.name)
        if state is None:
            states[self.name] = state = RelationshipInstance(self, obj)
        return state

    def _get_relationship(self, obj, states):
        return self._get_state(obj, states)

    def _set_relationship(self, obj, states, value):
        if value is not None:
            state = self._get_state(obj, states)
            items = list(state.all())
            notsaved = state._added
            if items and len(notsaved) < len(items):
                state.remove(*items)
                #TODO: make it so it only removes authors not in value
                #      and remove authors already there from value
                #XXX: only works when removing from saved nodes
            if notsaved:
                notsaved[:] = []  # TODO give rel instance a method for this?
            if hasattr(value, '__iter__'):
                state.add(*value)
            else:
                state.add(value)

    def _neo4j_instance(self, this, relationship):
        if this.id == relationship.start.id:
            that = relationship.end
        else:
            that = relationship.start
        return self.target_model._neo4j_instance(that)

    def accept(self, obj):
        pass  # TODO: implement verification

    def _save_relationship(self, instance, node, state):
        state.__save__(node)

    def _load_relationships(self, node, ordered=False, **kwargs):
        sup = super(MultipleNodes, self)._load_relationships(node, **kwargs)
        if ordered:
            return sorted(sup, key=lambda rel: rel[ORDER_ATTR])
        return sup

    def _create_neo_relationship(self, node, *args, **kwargs):
        if self.ordered:
            rels = self._load_relationships(node, ordered=True, **kwargs)
            new_index = rels[-1][ORDER_ATTR] + 1 if len(rels) > 0 else 0
            if 'attrs' in kwargs:
                kwargs['attrs'][ORDER_ATTR] = new_index
            else:
                kwargs['attrs'] = {ORDER_ATTR: new_index}
        return super(MultipleNodes, self)._create_neo_relationship(node, *args, **kwargs)


class MultipleRelationships(BoundRelationshipModel):  # WAIT!

    @not_implemented
    def _get_relationship(self, obj, state):
        pass

    @not_implemented
    def add(self, obj, other):
        pass


# TODO this needs to be supplanted by using somthing like django.db.models
# .fields.related.ForeignRelatedObjectsDescriptor
class RelationshipInstance(models.Manager):
    """
    A manager that keeps state for the many side (`MultipleNodes`) of
    relationships.
    """
    def __init__(self, rel, obj):
        self._rel = rel
        self._obj = obj
        self._added = []  # contains domain objects
        self._removed = []  # contains relationships
        #holds cached domain objects (that have been added or loaded by query)
        self._cache = None
        self._cache_unique = set([])

        # sender should be the associated model (not any associated LazyModel)
        sender = (self._rel.target_model._model
                  if hasattr(self._rel.target_model, '_model')
                  else self._rel.target_model)

        @receiver(post_delete, sender=sender, weak=False)
        def delete_handler(sender, **kwargs):
            deleted_obj = kwargs.pop('instance', None)
            if deleted_obj:
                self._remove_from_cache(deleted_obj)
                if deleted_obj in self._added:
                    self._added.remove(deleted_obj)

    ordered = property(lambda self: self._rel.ordered)

    def _add_to_cache(self, *relationship_neo4j_pairs):
        for pair in relationship_neo4j_pairs:
            if pair not in self._cache_unique:
                self._get_or_create_cache().append(pair)
                self._cache_unique.add(pair)

    def _remove_from_cache(self, obj):
        if self._cache is not None:
            for r, cached_obj in self._cache[:]:
                if cached_obj == obj:
                    pair = (r, cached_obj)
                    self._cache.remove(pair)
                    self._cache_unique.remove(pair)
                    break

    def _has_cache(self):
        return self._cache is not None

    def _get_or_create_cache(self):
        if self._cache is None:
            self._cache = []
        return self._cache

    def __save__(self, node):
        #Deletes all relationships removed since last save and adds any new
        #relatonships to the database.

        #TODO this should be batched
        for relationship in self._removed:
            relationship.delete()
        for obj in self._added:
            new_rel = self._rel._create_neo_relationship(node, obj)
            self._add_to_cache((new_rel, obj))
        self._removed[:] = []
        self._added[:] = []

    def _neo4j_relationships_and_models(self, node):
        """
        "Returns generator of relationship, neo4j instance tuples associated
        with node.
        """
        if self._cache is None:
            self._add_to_cache(*[(r, self._rel._neo4j_instance(node, r)) for r in
                               self._rel._load_relationships(node, ordered=self.ordered)])
        for tup in self._get_or_create_cache():
            if tup[0] not in self._removed:
                yield tup

    @property
    def _new(self):
        for item in self._added:
            yield item

    @property
    def _old(self):
        for item in self._removed:
            yield item

    def add(self, *objs):
        """
        Adds object(s) to the relationship. If ordered is True for
        the relationship, these objects will all be put at the end of the line.
        """
        for obj in objs:
            self._rel.accept(obj)
        self._added.extend(objs)

    def remove(self, *objs):
        """
        Remove objects from the relationship. If ordered is True,
        remove the first relationship to this object- otherwise, remove one
        of the relationships indiscriminately.
        """
        rel = self._rel
        if hasattr(self._obj, 'node'):
            neo_rels = list(rel._load_relationships(self._obj.node,
                                                    ordered=self.ordered))
            rels_by_node = defaultdict(list)
            for neo_rel in neo_rels:
                other_end = neo_rel.start if neo_rel.end == self._obj.node else neo_rel.end
                rels_by_node[other_end.url].append(neo_rel)

            for obj in objs:
                candidate_rels = rels_by_node[obj.node.url] if hasattr(obj, 'node') else []
                if candidate_rels:
                    if candidate_rels[0] not in self._removed:
                        self._removed.append(candidate_rels.pop(0))
                else:
                    try:
                        self._added.remove(obj)
                    except ValueError:
                        raise rel.target_model.DoesNotExist(
                            "%r is not related to %r." % (obj, self._obj))
                self._remove_from_cache(obj)
        else:
            for obj in objs:
                try:
                    if obj in self._added:
                        self._added.remove(obj)
                    elif obj in self._cache:
                        self._remove_from_cache(obj)
                except ValueError:
                    raise rel.target_model.DoesNotExist(
                        "%r is not related to %r." % (obj, self._obj))

    def clear(self):
        all_objs = list(self.all())
        self.remove(*all_objs)

    def clone(self):
        # Should cache be updated as well?
        cloned = RelationshipInstance(self._rel, self._obj)
        cloned.add(*self._new)
        return cloned

    def create(self, **kwargs):
        kwargs[self._rel.relationship._related_name] = self._obj
        new_model = self._rel.relationship.target_model(**kwargs)
        # TODO: saving twice, should only need
        # to save self._obj after #89 fix
        new_model.save()
        self._obj.save()

    @not_implemented
    def get_or_create(self, *args, **kwargs):
        pass

    def get_query_set(self):
        return RelationshipQuerySet(self, self._rel, self._obj)

    def get_empty_query_set(self):
        return EmptyQuerySet()


class RelationshipQuerySet(NodeQuerySet):

    def __init__(self, rel_instance, rel, model_instance, model=None,
                 query=None, using=DEFAULT_DB_ALIAS):
        # TODO will cause issues with #138 - multi-typed relationships
        target_model = model or rel.relationship.target_model
        super(RelationshipQuerySet, self).__init__(
            model=target_model, query=query or Query(target_model),
            using=using)
        self._rel_instance = rel_instance
        self._rel = rel
        self._model_instance = model_instance

        self.query.set_start_clause(self._get_start_clause(), lambda: {
            'startParam': self._model_instance.id
        })

    def _get_start_clause(self):
        """
        Return a Cypher START fragment - either a str, or an object with an
        as_cypher() method -  that will be used as the first half of the query
        built executing the query set. The query should expect a parameter named
        "startParam" containing this side of the relationship's node id, and
        should define a column "n" containing nodes to later be filtered
        against.
        """
        order_clause = """
            ORDER BY r.`%s`
        """ % ORDER_ATTR if self._rel_instance.ordered else ''

        start = Start({'m': 'node({startParam})'}, ['startParam'])

        direction = '>' if self._rel.direction == RELATIONSHIPS_OUT else '<'

        match = Match([
            Path([NodeComponent('m'),
                  RelationshipComponent(identifier='r',
                                        types=[self._rel.rel_type],
                                        direction=direction),
                  NodeComponent('n')])])

        order_by = OrderBy([OrderByTerm(ColumnExpression('r', ORDER_ATTR))]) \
                if self._rel_instance.ordered else None

        return Clauses([
            start,
            match,
            With({'n': 'n', 'r': 'r', 'typeNode': 'typeNode'}, order_by=order_by)
        ])

    def iterator(self):
        added = list(self._rel_instance._new)
        if self._model_instance.id is not None:
            for m in super(RelationshipQuerySet, self).iterator():
                yield m
        for item in added:
            yield item

    def _clone(self, klass=None, setup=False, **kwargs):
        klass = klass or self.__class__
        klass = partial(klass, self._rel_instance, self._rel,
                        self._model_instance)
        return super(RelationshipQuerySet, self)._clone(klass=klass,
                                                        setup=setup, **kwargs)

    def count(self):
        removed = list(self._rel_instance._old)
        added = list(self._rel_instance._new)
        diff_len = max(len(added) - len(removed), 0)
        if self._model_instance.id is not None:
            return super(RelationshipQuerySet, self).count() + diff_len
        else:
            return diff_len

########NEW FILE########
__FILENAME__ = script_utils
import neo4jrestclient.client as neo4j
from .. import connections
from ...rest_utils import id_from_url


class LazyBase(object):
    """
    A mixin to make elements of the REST client lazy.
    """
    def __init__(self, url, dic):
        self._dont_update = True
        super(LazyBase, self).__init__(url, create=False)
        self._dic = dic.copy()
        self._dont_update = False

    def update(self, *args, **kwargs):
        if not self._dont_update:
            super(LazyBase, self).update(*args, **kwargs)

    @classmethod
    def from_dict(cls, dic):
        return cls(dic['self'], dic)


class LazyNode(LazyBase, neo4j.Node):
    id_url_template = 'node/%d'


class LazyRelationship(LazyBase, neo4j.Relationship):
    id_url_template = 'relationship/%d'

    def __init__(self, *args, **kwargs):
        self._custom_lookup = None
        super(LazyRelationship, self).__init__(*args, **kwargs)

    def set_custom_node_lookup(self, lookup):
        """
        Specify a dict-like lookup object from which nodes can be pulled. Keys
        should be node urls.
        """
        #HACK solution for a lazy sub-graph
        self._custom_lookup = lookup

    @property
    def start(self):
        key = self._dic['start']
        if self._custom_lookup is not None and key:
            try:
                return self._custom_lookup[id_from_url(key)]
            except KeyError:
                pass
        return super(LazyRelationship, self).start

    @property
    def end(self):
        key = self._dic['end']
        if self._custom_lookup is not None and key:
            try:
                return self._custom_lookup[id_from_url(key)]
            except KeyError:
                pass
        return super(LazyRelationship, self).end


class SkeletonBase(object):
    """
    A mixin to allow REST element construction from an id and property dict.

    Expects a LazyNode or LazyRelationship in the class hierarchy.
    """
    def __init__(self, db_url, element_id, prop_dict):
        url = db_url + (self.id_url_template % element_id)
        element_dict = {}
        for k, v in self.DICT_TEMPLATE.items():
            element_dict[k] = v.replace('{db_url}', db_url).replace('{id}', str(element_id)) \
                if not hasattr(v, 'keys') else v
        element_dict['data'] = prop_dict
        super(SkeletonBase, self).__init__(url, element_dict)


class SkeletonNode(SkeletonBase, LazyNode):
    DICT_TEMPLATE = {
        "outgoing_relationships": "{db_url}node/{id}/relationships/out",
        "data": {},
        "traverse": "{db_url}node/{id}/traverse/{returnType}",
        "all_typed_relationships": "{db_url}node/{id}/relationships/all/{-list|&|types}",
        "property": "{db_url}node/{id}/properties/{key}",
        "self": "{db_url}node/{id}",
        "outgoing_typed_relationships": "{db_url}node/{id}/relationships/out/{-list|&|types}",
        "properties": "{db_url}node/{id}/properties",
        "incoming_relationships": "{db_url}node//relationships/in",
        "extensions": {},
        "create_relationship": "{db_url}node/{id}/relationships",
        "paged_traverse": "{db_url}node/{id}/paged/traverse/{returnType}{?pageSize,leaseTime}",
        "all_relationships": "{db_url}node/{id}/relationships/all",
        "incoming_typed_relationships": "{db_url}node/{id}/relationships/in/{-list|&|types}"
    }


def batch_base(ids, cls, using):
    """
    A function to replace the REST client's non-lazy batching.
    """
    #HACK to get around REST client limitations
    gremlin_func = 'e' if issubclass(cls, neo4j.Relationship) else 'v'
    script = """
    t = new Table()
    for (def id : ids) {
        g.%s(id).as('elements').table(t,['elements']).iterate()
    }
    results = t
    """
    script %= gremlin_func
    result_table = connections[using].gremlin(script, ids=ids)
    return [_add_auth(cls.from_dict(v[0]), connections[using]) for v in result_table['data']]


def batch_rels(ids, using):
    return batch_base(ids, LazyRelationship, using)


def batch_nodes(ids, using):
    return batch_base(ids, LazyNode, using)


def batch_paths(paths, using):
    """
    A function to replace the REST client's non-lazy batching of paths.
    """
    #TODO untested
    batched = []

    tx = connections[using].transaction(using_globals=False)
    for p in paths:
        for n_url in p['nodes']:
            tx.subscribe('GET', n_url)
        for r_url in p['relationships']:
            tx.subscribe('GET', r_url)
    result_dict = tx._batch()
    rel_by_url = {}
    node_by_url = {}
    for v in result_dict.values():
        d = v['body']
        if "start" in d:
            rel_by_url[d['self']] = _add_auth(LazyRelationship.from_dict(d), connections[using])
        else:
            node_by_url[d['self']] = _add_auth(LazyNode.from_dict(d), connections[using])
    for p in paths:
        node_it = (node_by_url[n_url] for n_url in iter(p['nodes']))
        rel_it = (rel_by_url[r_url] for r_url in iter(p['relationships']))
        p_list = []
        while True:
            try:
                p_list.append(node_it.next())
                p_list.append(rel_it.next())
            except StopIteration:
                break
        batched.append(tuple(p_list))
    return batched


def _add_auth(n, conn):
    n._auth = conn._auth
    return n


class GremlinSnippet(object):
    def __init__(self, name, script, in_args=['results'], out_args=['results']):
        self.script = script
        self.in_args = in_args
        self.out_args = out_args

########NEW FILE########
__FILENAME__ = decorators
from decorator import decorator


def transactional(func):
    """
    A decorator that currently does, well, nothing. Regardless, flag functions
    that should be transactional so that they can be dealt with in the future,
    when the Neo4j REST interface supports transactions.
    """
    func.transactional = True
    return func


@decorator
def not_supported(func, *args, **kw):
    raise TypeError("%s is not supported." % func.__name__)


def not_implemented(arg):
    """
    A decorator that throws a NotImplementedError instead of calling the supplied
    function.

    Intended use -

    @not_implemented
    def hard_work_for_the_future():
        ...

    @not_implemented('Not implemented until version 2!')
    def hard_work_for_the_future():
        ...

    The first use will raise the error with a message of "hard_work_for_the_future",
    and the second with "Not implemented until version 2!".

    Alternative, if you'd rather use this as a function

    def hard_work_for_the_future():
        ...
    hard_work_for_the_future = not_implemented(hard_work_for_the_future)

    def hard_work_for_the_future():
        ...
    hard_work_for_the_future = not_implemented("Not implemented until version 2!")(hard_work_for_the_future)

    respectively.
    """
    @decorator
    def not_implemented_dec(func, *args, **kwargs):
        if isinstance(arg, str):
            raise NotImplementedError(arg)
        else:
            raise NotImplementedError(func.__name__)
    if type(arg) == type(not_implemented_dec):
        return not_implemented_dec(arg)
    return not_implemented_dec


def alters_data(func):
    func.alters_data = True
    return func


@decorator
def memoized(func, *args, **kwargs):
    from operator import itemgetter
    if not hasattr(func, 'cache'):
        func.cache = {}
    key = args + tuple(sorted(kwargs.items(), key=itemgetter(0)))
    if key in func.cache:
        return func.cache[key]
    else:
        new_val = func(*args, **kwargs)
        try:
            func.cache[key] = new_val
        except TypeError:
            #uncacheable
            pass
        return new_val


def borrows_methods(target_cls, method_names):
    """
    Copy methods from a target class onto this one.

    Expected to be used as a decorator- eg

        @borrows_methods(SomeClass, ('__str__','__hash__'))
        class MyClass(object):
            pass

    Use this in situations where you'd like to use a class as a mixin, but it
    find it has a bit too much baggage.
    """
    def wrapped(cls):
        for method_name in set(method_names):
            target_method = getattr(target_cls, method_name)
            setattr(cls, method_name, target_method.im_func)
        return cls
    return wrapped

########NEW FILE########
__FILENAME__ = exceptions
class Error(Exception):
    """Base class for neo4django exceptions."""
    pass


class GremlinLibraryCouldNotBeLoaded(Error):
    """
    Error for when the Gremlin library could not be loaded within the number of
    acceptable retries. This could happen if the database's GremlinScriptEngine
    is being reset more than usual.
    """
    pass


class NoSuchDatabaseError(Error):
    def __init__(self, url=None, name=None):
        """
        Error for when a neo4j node without a configured database is provided,
        or a database name that doesn't exist in settings is provided.
        """
        if url is None and name is None:
            raise ValueError('A url or name identifying the problem database '
                             'must be provided.')
        self.url = url
        self.name = name

    def __str__(self):
        return 'No such database exists: %s'.format(str(self.url or self.name))

########NEW FILE########
__FILENAME__ = backends
try:
    from django.contrib.auth import get_user_model
    UserModel = get_user_model()
except ImportError:
    from .models import User as UserModel

class NodeModelBackend(object):
    """
    A Neo4j auth backend.
    """
    supports_object_permissions = False
    supports_anonymous_user = False
    supports_inactive_user = False

    def authenticate(self, username=None, password=None):
        try:
            user = UserModel.objects.get(username=username)
            if user is not None and user.check_password(password):
                return user
        except UserModel.DoesNotExist:
            pass

    def get_user(self, user_id):
        try:
            return UserModel.objects.get(id=user_id)
        except UserModel.DoesNotExist:
            return None

########NEW FILE########
__FILENAME__ = models
from django.utils import timezone
from django.conf import settings

from django.contrib.auth import models as django_auth_models

from ..db import models
from ..db.models.manager import NodeModelManager
from ..decorators import borrows_methods

class UserManager(NodeModelManager, django_auth_models.UserManager):
    pass

# all non-overriden methods of DjangoUser are called this way instead.
# inheritance would be preferred, but isn't an option because of conflicting
# metaclasses and weird class side-effects
USER_PASSTHROUGH_METHODS = (
    "__unicode__", "natural_key", "get_absolute_url",
    "is_anonymous", "is_authenticated", "get_full_name", "set_password",
    "check_password", "set_unusable_password", "has_usable_password",
    "get_group_permissions", "get_all_permissions", "has_perm", "has_perms",
    "has_module_perms", "email_user", 'get_profile','get_username')

@borrows_methods(django_auth_models.User, USER_PASSTHROUGH_METHODS)
class User(models.NodeModel):
    objects = UserManager()

    username = models.StringProperty(indexed=True, unique=True)
    first_name = models.StringProperty()
    last_name = models.StringProperty()

    email = models.EmailProperty(indexed=True)
    password = models.StringProperty()

    is_staff = models.BooleanProperty(default=False)
    is_active = models.BooleanProperty(default=False)
    is_superuser = models.BooleanProperty(default=False)

    last_login = models.DateTimeProperty(default=timezone.now())
    date_joined = models.DateTimeProperty(default=timezone.now())

    USERNAME_FIELD = 'username'
    REQUIRED_FIELDS=['email']


########NEW FILE########
__FILENAME__ = neo4jclient
from urlparse import urlparse
from neo4jrestclient.client import GraphDatabase, RAW as RETURNS_RAW
from neo4jrestclient.request import Request
from django.conf import settings as _settings
from django.core import exceptions

from pkg_resources import resource_stream as _pkg_resource_stream
from collections import namedtuple
import re as _re
import warnings

from .exceptions import GremlinLibraryCouldNotBeLoaded as LibraryCouldNotLoad
from .rest_utils import Neo4jTable

#TODO move this somewhere sane (settings?)
LIBRARY_LOADING_RETRIES = 1

#TODO DRY considerations
LIBRARY_NAME = 'Neo4Django'
#TODO issue #128 - better gremlin error passing
LIBRARY_LOADING_ERROR = 'neo4django: "%s" library not loaded!'
LIBRARY_ERROR_REGEX = _re.compile(LIBRARY_LOADING_ERROR % '.*?')

other_libraries = {}


class EnhancedGraphDatabase(GraphDatabase):
    def __init__(self, *args, **kwargs):
        cleandb_uri = kwargs.pop('CLEANDB_URI', None)
        super(EnhancedGraphDatabase, self).__init__(*args, **kwargs)
        if cleandb_uri:
            parsed_url = urlparse(self.url)
            cleandb_uri = "%s://%s%s" % (parsed_url.scheme,
                                         parsed_url.netloc, cleandb_uri)

            self._cleandb_uri = cleandb_uri

    def new_request(self):
        # Newer versions of neo4jrestclient support auth more robustly
        # the older versions do not support at all, so we have to check here
        try:
            auth = self._auth
        except AttributeError:
            auth = {}
        return Request(**auth)

    def cleandb(self):
        request = self.new_request()
        response, content = request.delete(self._cleandb_uri)
        if response.status != 200:
            warnings.warn('The CLEANDB_URI you specified is invalid: %s'
                          % self._cleandb_uri)
            # then try to do it with gremlin
            script = """
            try
            {
                indexManager = g.getRawGraph().index()
                indexManager.nodeIndexNames().each{g.dropIndex(it)}
                indexManager.relationshipIndexNames().each{g.dropIndex(it)}
                g.V.filter{it.id!=0}.sideEffect{g.removeVertex(it)}.iterate();
                results = true
            }
            catch(Exception e){results = false}
            """
            gremlin_ret = self.gremlin(script, raw=True)
            if gremlin_ret != 'true':
                error_msg = "\nDatabase couldn't be cleared - have you installed the cleandb extension at https://github.com/jexp/neo4j-clean-remote-db-addon?"
                raise exceptions.ImproperlyConfigured(error_msg)

    def gremlin(self, script, tx=False, raw=False, **params):
        """
        Execute a Gremlin script server-side and return the results.
        Transactions will be automatically managed, unless otherwise requested
        in the script, or the tx argument is set to True- in which case the
        whole script will be wrapped in a transaction.
        """
        #import statements have to be at the top, so this global try won't
        #do without pulling them up- luckily imports aren't super complicated
        #in the Groovy grammar. that said...
        #XXX this would be an easy place for a bug, and an actual parser
        #would be better...
        import_regex = _re.compile('\w*import [^{}]*?\w*(;|$)', _re.MULTILINE)
        import_statements = [m.group() for m in import_regex.finditer(script)]
        importless_script = import_regex.sub('', script)

        lib_script = '''
        import groovy.json.JsonBuilder;
        %(imports)s
        %(tx_begin)s
        try{
        %(main_code)s
        } catch (MissingPropertyException mpe) {
            %(tx_fail)s
            if (mpe.property in %(library_names)s) {
                results =String.format('%(load_error)s', mpe.property)
            }
            else { throw mpe }
        }
        catch (Exception otherE) {
            %(tx_fail)s
            throw otherE
        }
        %(tx_end)s
        if (results instanceof Map) {
            results = new JsonBuilder(results).toString()
        }
        results
        '''
        library_names = ("'%s'" % str(c) for c in
                         (['Neo4Django'] + other_libraries.keys()))
        library_list = '[' + ','.join(library_names) + ']'
        repl_dict = {'imports': ('\n'.join(s.strip(';') for s in import_statements)),
                     'tx_begin': '',
                     'main_code': importless_script,
                     'tx_fail': '',
                     'library_names': library_list,
                     'load_error': LIBRARY_LOADING_ERROR,
                     'tx_end': ''
                     }
        if tx:
            repl_dict['tx_begin'] = 'g.setMaxBufferSize(0); rootTx = g.getRawGraph().beginTx()'
            repl_dict['tx_end'] = 'rootTx.success(); rootTx.finish();' \
                                  'g.setMaxBufferSize(1)'
            repl_dict['tx_fail'] = 'rootTx.failure(); rootTx.finish();' \
                                   'g.setMaxBufferSize(1)'
        lib_script %= repl_dict
        ext = self.extensions.GremlinPlugin

        def include_main_library(s):
            #get the library source
            lib_source = _pkg_resource_stream(__package__.split('.', 1)[0],
                                              'gremlin/library.groovy').read()
            return lib_source + '\n' + s

        def include_unloaded_libraries(s):
            for name in other_libraries.keys():
                if not other_libraries[name].loaded:
                    source = other_libraries[name].source
                    s = source + '\n' + s
            return s

        def include_all_libraries(s):
            for name in other_libraries.keys():
                source = other_libraries[name].source
                other_libraries[name] = Library(source, True)
                s = source + '\n' + s
            return include_main_library(s)

        def send_script(s, params):
            execute_kwargs = {}
            if raw:
                execute_kwargs['returns'] = RETURNS_RAW
            script_rv = ext.execute_script(s, params=params, **execute_kwargs)
            if isinstance(script_rv, basestring):
                if LIBRARY_ERROR_REGEX.match(script_rv):
                    raise LibraryCouldNotLoad
                elif script_rv.startswith('{'):
                    import json
                    return json.loads(script_rv)
            return script_rv

        if getattr(_settings, 'NEO4DJANGO_DEBUG_GREMLIN', False):
            all_libs = include_all_libraries(lib_script)
            return send_script(all_libs, params)
        for i in xrange(LIBRARY_LOADING_RETRIES + 1):
            try:
                return send_script(include_unloaded_libraries(lib_script),
                                   params)
            except LibraryCouldNotLoad:
                if i == 0:
                    lib_script = include_all_libraries(lib_script)
        raise LibraryCouldNotLoad

    def gremlin_tx(self, script, **params):
        """
        Execute a Gremlin script server-side and return the results. The script
        will be wrapped in a transaction.
        """
        return self.gremlin(script, tx=True, **params)

    def cypher(self, query, **params):
        ext = self.extensions.CypherPlugin
        return Neo4jTable(ext.execute_query(query=query, params=params))

Library = namedtuple('Library', ['source', 'loaded'])


def load_library(library_class, library_source):
    if not isinstance(library_class, basestring):
        raise TypeError('Expected a string class name, not %s.'
                        % str(library_class))
    if library_class == LIBRARY_NAME:
        raise ValueError('%s is a reserved library name.' % LIBRARY_NAME)
    other_libraries[library_class] = Library(library_source, False)


def remove_library(library_class):
    other_libraries.pop(library_class, None)

########NEW FILE########
__FILENAME__ = rest_utils
from operator import itemgetter, add
from itertools import izip_longest, chain, ifilter


def id_from_url(url):
    from urlparse import urlsplit
    from posixpath import dirname, basename
    path = urlsplit(url).path
    b = basename(path)
    return int(b if b else dirname(path))


#if only there were a real itemdropper
def itemdropper(*ind):
    """
    A complement to itemgetter. Accepts ints representing indexes. Returns a
    function that will exclude all elements with those indexes from a provided
    seq.

    Note that, unlike itemgetter, itemdropper doesn't support slices or non-int
    keys, due to complexity.
    """
    def func(seq):
        return reduce(add, (seq[i:i + 1] for i in xrange(len(seq)) if i not in ind))
    return func


class Neo4jTable(object):
    def __init__(self, d):
        self.data = d['data']
        self.column_names = d['columns']

    def get_column_indexes(self, column_name_pred):
        if column_name_pred is None:
            column_name_pred = lambda s: s
        elif not callable(column_name_pred):
            if isinstance(column_name_pred, basestring):
                column_name = column_name_pred
                column_name_pred = lambda s: s == column_name
            else:
                column_names = column_name_pred
                column_name_pred = lambda s: s in column_names
        return [i for i, c in
                enumerate(self.column_names) if column_name_pred(c)]

    def get_all_rows(self, column_name_pred):
        """
        Return all table columns that match the provided predicate.

        If the argument is a string, test for equality instead- if it's another
        seq, test for membership. If the argument is None, the identity function
        is assumed.
        """
        columns = self.get_column_indexes(column_name_pred)
        col_getter = itemgetter(*columns)
        return chain.from_iterable(rc if isinstance(rc, tuple) else (rc,)
                                   for rc in (col_getter(r) for r in self.data))

    def drop_columns(self, column_name_pred):
        columns = self.get_column_indexes(column_name_pred)
        col_dropper = itemdropper(*columns)
        self.column_names = col_dropper(self.column_names)
        self.data = [col_dropper(r) for r in self.data]

    def append_column(self, column_name, column_rows):
        if len(column_rows) != len(self):
            raise ValueError('New columns are expected to have the same length'
                             ' as existing columns.')
        self.column_names = self.column_names + [column_name]
        self.data = [list(r) + [new_element] for r, new_element in
                     izip_longest(self.data, column_rows)]

    def to_dicts(self):
        def to_dict(row):
            return dict(izip_longest(self.column_names, row))
        return [to_dict(r) for r in self.data]

    def __len__(self):
        return len(self.data)


def prettify_path(path_dict):
    nodes = ['(%d)' % id_from_url(url) for url in path_dict['nodes']]
    rels = ['[%d]' % id_from_url(url) for url in path_dict['relationships']]
    return '->'.join(ifilter(None, chain.from_iterable(izip_longest(nodes, rels))))

########NEW FILE########
__FILENAME__ = testcases
from urlparse import urlparse

from django import test as django_test
from django.conf import settings as _settings

from .db import Neo4djangoRequest, connections, DEFAULT_DB_ALIAS
from .utils import ConnectionHandler


class NumRequestsProfiler(object):
    def __init__(self, connection, assertion):
        self.connection = connection
        self.assertion = assertion
        self.num = 0

    def __enter__(self):
        def counter(req, method, url, *args):
            if urlparse(url).netloc == urlparse(self.connection.url).netloc:
                # TODO this is not the best way to test which connection is
                # being counted- it would be nice if requests knew their
                # parent connections
                self.num += 1
        self._callback = counter
        Neo4djangoRequest.register_pre_request_callback(self._callback)
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        Neo4djangoRequest.unregister_pre_request_callback(self._callback)
        if exc_type is not None:
            return
        if self.assertion is not None:
            self.assertion(self.num)


class NodeModelTestCase(django_test.TestCase):
    """Cleans  up the graph database in between each run"""
    def __init__(self, *args, **kwargs):
        ## TODO: This really belongs in ``setup_environment`` on a custom
        ##       runner, but we don't want to ask our users to use a custom
        ##       TestCase and a custom runner?
        super(NodeModelTestCase, self).__init__(*args, **kwargs)
        _settings.NEO4J_DATABASES = _settings.NEO4J_TEST_DATABASES
        _settings.RUNNING_NEO4J_TESTS = True
        new_connections = ConnectionHandler(_settings.NEO4J_TEST_DATABASES)
        for alias in new_connections:
            connections[alias] = new_connections[alias]

    def _pre_setup(self, *args, **kwargs):
        for alias in connections:
            connections[alias].cleandb()
        return super(NodeModelTestCase, self)._pre_setup(*args, **kwargs)

    def _post_teardown(self, *args, **kwargs):
        for alias in connections:
            connections[alias].cleandb()
        return super(NodeModelTestCase, self)._post_teardown(*args, **kwargs)

    def assertNumRequests(self, num, func=None, *args, **kwargs):
        """
        Similar to Django's built-in `assertNumQueries`, but for Neo4j REST
        client requests.
        """
        using = kwargs.pop("using", DEFAULT_DB_ALIAS)
        conn = connections[using]

        def assert_num_requests(actual_num):
            self.assertEqual(num, actual_num)

        context = NumRequestsProfiler(conn, assert_num_requests)
        if func is None:
            return context

        with context:
            func(*args, **kwargs)

########NEW FILE########
__FILENAME__ = django_tests
from nose.tools import with_setup, eq_

from django.conf import settings
TEST_SQL_DB_NAME = settings.DATABASES.get('default',{}).get('NAME','')

import os

def setup():
    global Person, gdb, models

    from neo4django.tests import Person, gdb
    from neo4django.db import models

def teardown():
    gdb.cleandb()

def test_json_serialize():
    from django.core import serializers
    dave = Person(name='dave')
    dave.save()
    json_serializer = serializers.get_serializer('json')()
    assert json_serializer.serialize(Person.objects.all())
    dave = Person(name='dave', age=12)
    dave.save()
    assert json_serializer.serialize(Person.objects.all())
    dave = Person()
    dave.save()
    assert json_serializer.serialize(Person.objects.all())

def touch_test_db():
    db_dir = os.path.dirname(TEST_SQL_DB_NAME)
    if not os.path.exists(db_dir):
        os.makedirs(db_dir)
    open(TEST_SQL_DB_NAME,'w').close()

def rm_test_db():
    os.remove(TEST_SQL_DB_NAME)

@with_setup(touch_test_db, rm_test_db)
def test_syncdb():
    from django.core.management import call_command
    call_command('syncdb', interactive=False)

@with_setup(None, teardown)
def test_auth():
    from neo4django.graph_auth.models import User
    user = User.objects.create_user('john', 'lennon@thebeatles.com', 'johnpassword')

    from django.contrib.auth import authenticate
    eq_(authenticate(username='john', password='johnpassword'), user)

@with_setup(None, teardown)
def test_auth_backend():
    from neo4django.graph_auth.models import User
    user = User.objects.create_user('paul', 'mccartney@thebeatles.com', 'paulpassword')

    from neo4django.graph_auth.backends import NodeModelBackend
    backend = NodeModelBackend()
    eq_(backend.authenticate(username='paul', password='paulpassword'), user)
    eq_(backend.get_user(user.id), user)

@with_setup(None, teardown)
def test_modelform():
    from django.forms import ModelForm

    class PersonForm(ModelForm):
        class Meta:
            model = Person

    person_form = PersonForm()
    as_p = person_form.as_p()
    assert 'id_age' in as_p
    assert 'id_name' in as_p

    rick = Person.objects.create(name='Rick', age=20)
    new_rick_data = {'name':'Rick','age':21}

    bound_person_form = PersonForm(new_rick_data, instance=rick)
    assert bound_person_form.is_valid()

    bound_person_form.save()

    new_rick = Person.objects.get(id__exact=rick.id)
    eq_(new_rick.age, new_rick_data['age'])

@with_setup(None, teardown)
def test_related_modelform():
    from django.forms import ModelForm

    class FriendlyPerson(Person):
        friends = models.Relationship('self', rel_type='friends_with')

    class FriendlyPersonForm(ModelForm):
        class Meta:
            model = FriendlyPerson

    friendly_person_form = FriendlyPersonForm()
    as_p = friendly_person_form.as_p()
    assert 'id_friends' in as_p
    assert 'id_friendlyperson_set' in as_p

    pete = FriendlyPerson.objects.create(name='Pete', age=20)
    tom = FriendlyPerson.objects.create(name='Tom', age=30)
    tom.friends.add(pete)
    tom.save()

    bound_friendly_form = FriendlyPersonForm(instance=tom)
    as_p = bound_friendly_form.as_p()

    friendly_person_id_strs = [str(pete.id), str(tom.id)]

    from lxml import etree

    parsed = etree.fromstring('<root>%s</root>' % as_p)

    eq_(parsed.xpath("//select[@name='friendlyperson_set']/option/@value"),
        friendly_person_id_strs)
    eq_(parsed.xpath("//select[@name='friends']/option/@value"),
        friendly_person_id_strs)
    eq_(parsed.xpath("//select[@name='friends']/option[@selected]/@value"),
        [str(pete.id)])

    tom.friends.remove(pete)
    tom.save()

    new_data = {'friends':[pete.id]}

    bound_friendly_form = FriendlyPersonForm(new_data, instance=tom)

    assert bound_friendly_form.is_valid()
    bound_friendly_form.save()

    assert pete in tom.friends.all()

########NEW FILE########
__FILENAME__ = index_tests
from nose.tools import with_setup, eq_

def setup():
    global Person, neo4django, settings, gdb, models

    from neo4django.tests import Person, neo4django, gdb
    from neo4django.db import models

def teardown():
    gdb.cleandb()

def test_unique():
    """
    Tests unique property behavior.
    """

    class UniqueName(models.NodeModel):
        a_prop = models.StringProperty()
        name = models.StringProperty(indexed=True, unique=True)
        z_prop = models.StringProperty()
        prop_1 = models.StringProperty()
        prop = models.StringProperty()

    m = UniqueName(name='Matt')
    m.save()

    # confirms #150 - nodes with unique properties can't be saved
    m.save()

    c = UniqueName(name='Corbin')
    c.save()

    m2 = UniqueName(name='Matt')
    try:
        m2.save()
    except ValueError as verr:
        #confirms #62- uniqueness error should display correct property name.
        mess = str(verr)
        assert '<UniqueName>.name' in mess
    else:
        raise AssertionError('A saving second node with the same name should'
                             ' raise an error.')

def test_default_parents_index():
    """
    Tests whether indexed nodes, by default, share a parent index.
    """
    class RootIndexedNode(models.NodeModel):
        name = models.StringProperty(indexed=True)

    class ChildIndexedNode(RootIndexedNode):
        name1 = models.StringProperty(indexed=True)

    class GrandChildIndexedNode(ChildIndexedNode):
        name2 = models.StringProperty(indexed=True)

    root = RootIndexedNode(name='dave')
    root.save()

    child = ChildIndexedNode(name1='deandra')
    child.save()

    grandchild = GrandChildIndexedNode(name2='donald')
    grandchild.save()

    assert RootIndexedNode.index()['name']['dave'][0].id == root.pk,\
            "The root node wasn't indexed properly."
    assert RootIndexedNode.index()['name1']['deandra'][0].id == child.pk,\
            "The child node wasn't indexed properly."
    assert RootIndexedNode.index()['name2']['donald'][0].id == grandchild.pk,\
            "The grandchild node wasn't indexed properly."

def test_indexed_types():
    from neo4django.constants import TYPE_ATTR
    from neo4jrestclient.client import NotFoundError

    def get_indexed_type_ids(cls):
        try:
            return [i.id for i in cls.index()[TYPE_ATTR][cls._type_name()]]
        except NotFoundError:
            return []

    class SomeType(models.NodeModel):
        pass

    s = SomeType()
    s.save()

    assert s.pk in get_indexed_type_ids(SomeType), "Initial type was not indexed."

    class SomeOtherType(SomeType):
        pass

    s2 = SomeOtherType()
    s2.save()

    assert s2.pk in get_indexed_type_ids(SomeType), "Subtype not indexed with parent type."
    assert s2.pk in get_indexed_type_ids(SomeOtherType), "Subtype not indexed."

    old_pk = s2.pk
    s2.delete()

    assert old_pk not in get_indexed_type_ids(SomeType), "Subtype not removed from parent index."
    assert old_pk not in get_indexed_type_ids(SomeOtherType), "Subtype not removed from parent index.."

@with_setup(None, teardown)
def test_auto_property_indexing():
    class IndexedAutoNode(models.NodeModel):
        some_id = models.AutoProperty(indexed=True)

    nodes = [IndexedAutoNode.objects.create() for i in xrange(5)]
    for i in xrange(5):
        lookup = IndexedAutoNode.index()['some_id'][IndexedAutoNode.some_id.to_neo_index(nodes[i].some_id)]
        eq_(len(lookup), 1)
        eq_(next(lookup).id, nodes[i].id)


########NEW FILE########
__FILENAME__ = models
from neo4django.db import models

class IndexedMouse(models.NodeModel):
    name = models.StringProperty(indexed=True)
    age = models.IntegerProperty(indexed=True)

class RelatedCat(models.NodeModel):
    name = models.StringProperty()
    chases = models.Relationship(IndexedMouse, rel_type='chases')

class RelatedDog(models.NodeModel):
    name = models.StringProperty()
    chases = models.Relationship(RelatedCat, rel_type='chases')

class LazyCat(models.NodeModel):
    name = models.StringProperty()
    chases = models.Relationship('IndexedMouse', rel_type='chases_lazily')


########NEW FILE########
__FILENAME__ = model_tests
"""
The neo4django test suite. Currently, these are rough development-oriented tests,
and need to be expanded to be more robust.
"""

from nose.tools import eq_

def setup():
    global Person, neo4django, gdb, neo4jrestclient, neo_constants, settings, models

    from neo4django.tests import Person, neo4django, gdb, neo4jrestclient, \
            neo_constants, settings
    from neo4django.db import models

def teardown():
    gdb.cleandb()

def test_custom_manager():

    class MyCustomManager(neo4django.db.models.manager.NodeModelManager):
        def my_custom_manager_method(self):
            pass


    class CustomPerson(Person):
        objects = MyCustomManager()

    assert CustomPerson.objects.model is CustomPerson
    assert hasattr(CustomPerson.objects, 'my_custom_manager_method')

def test_save_delete():
    """Basic sanity check for NodeModel save and delete.  """
    from neo4jrestclient.client import NotFoundError

    pete = Person(name='Pete')
    pete.save()
    node_id = pete.id
    pete.delete()
    try:
        gdb.nodes.get(node_id)
    except NotFoundError:
        pass
    else:
        assert False, 'Pete was not properly deleted.'

def test_type_nodes():
    """Tests for type node existence and uniqueness."""
    class TestType(models.NodeModel):
        class Meta:
            app_label = 'type_node_test'

    n1 = TestType()
    n1.save()

    class TestType(models.NodeModel):
        class Meta:
            app_label = 'type_node_test'

    n2 = TestType()
    n2.save()

    class SecondTestType(TestType):
        class Meta:
            app_label = 'type_node_test2'

    n3 = SecondTestType()
    n3.save()

    class SecondTestType(TestType):
        class Meta:
            app_label = 'type_node_test2'

    n4 = SecondTestType()
    n4.save()

    test_type_nodes = filter(
        lambda n: (n['app_label'], n['model_name']) == ('type_node_test','TestType'),
        gdb.traverse(gdb.reference_node,
                     types=[neo4jrestclient.Outgoing.get('<<TYPE>>')],
                     stop=neo_constants.STOP_AT_END_OF_GRAPH))
    assert len(test_type_nodes) != 0, 'TestType type node does not exist.'
    assert len(test_type_nodes) <= 1, 'There are multiple TestType type nodes.'

    test_type_nodes = filter(
        lambda n: (n['app_label'], n['model_name']) == ('type_node_test2','SecondTestType'),
        gdb.traverse(gdb.reference_node,
                     types=[neo4jrestclient.Outgoing.get('<<TYPE>>')],
                     stop=neo_constants.STOP_AT_END_OF_GRAPH))

    assert len(test_type_nodes) != 0, 'SecondTestType type node does not exist.'
    assert len(test_type_nodes) <= 1, 'There are multiple SecondTestType type nodes.'

def test_model_inheritance():
    #TODO docstring
    class TypeOPerson(Person):
        class Meta:
            app_label = 'newapp'
        hobby = models.Property()

    jake = TypeOPerson(name='Jake', hobby='kayaking')
    jake.save()
    assert jake.hobby == 'kayaking'
   
def test_nodemodel_independence():
    """Tests that NodeModel subclasses can be created and deleted independently."""

    class TestSubclass(models.NodeModel):
        age = models.IntegerProperty()
    
    n1 = TestSubclass(age = 5)
    n1.save()

    class TestSubclass(models.NodeModel):
        pass
    
    n2 = TestSubclass()

    assert not hasattr(n2, 'age'), "Age should not be defined, as the new class didn't define it."

    n2.save()

    assert not hasattr(n2, 'age'),  "Age should not be defined, as the new class didn't define it."

def test_model_casting():
    """Tests functional saved model to model "casting"."""
    #create a model similar to person, but with relationships
    class Doppelganger(models.NodeModel):
        name = models.StringProperty()
        original = models.Relationship(Person,
                                           rel_type=neo4django.Outgoing.MIMICS,
                                           single=True)
    #create a person
    abe = Person.objects.create(name='Abraham Lincoln', age=202)
    #cast it to the new model
    imposter = Doppelganger.from_model(abe)
    imposter.original = abe
    imposter.save()
    #ensure the values are the same
    eq_(abe.name, imposter.name)

def test_model_casting_validation():
    raise NotImplementedError('Write this test!')

def test_model_copy():
    class NameOwner(models.NodeModel):
        name = models.StringProperty()
        confidantes = models.Relationship(Person, neo4django.Outgoing.KNOWS)

    pete = Person(name='Pete')
    pete2 = NameOwner.copy_model(pete)
    eq_(pete.name, pete2.name)

    pete2.confidantes.add(pete)
    pete3 = NameOwner.copy_model(pete2)
    assert pete in list(pete3.confidantes.all()),\
            "Copying isn't commuting relationships!"

def test_model_pickling():
    """
    Covers issue #46, pickling `NodeModel`s.
    """

    def pickle_and_restore(m):
        import pickle
        return pickle.loads(pickle.dumps(m))

    def pickle_eq(m1, m2):
        eq_(m1.name, m2.name)
        eq_(m2.using, m2.using)
        eq_(m2.id, m2.id)

    # try a simple model
    pete = Person(name="Pete")
    restored_pete = pickle_and_restore(pete)

    pickle_eq(pete, restored_pete)

    # try a saved model

    pete.save()
    restored_saved_pete = pickle_and_restore(pete)

    pickle_eq(pete, restored_saved_pete)

    # try related models

    from .models import IndexedMouse, RelatedCat, LazyCat
    jerry = IndexedMouse.objects.create(name='Jerry')
    tom = RelatedCat(name='Jerry')

    tom.chases = jerry
    tom.save()
    
    restored_tom = pickle_and_restore(tom)

    pickle_eq(tom, restored_tom)
    pickle_eq(jerry, list(restored_tom.chases.all())[0])

    # try a model with a lazy relation
    
    garfield = LazyCat(name='Garfield')
    garfield.chases.add(jerry)

    restored_garfield = pickle_and_restore(garfield)

    pickle_eq(garfield, restored_garfield)
    pickle_eq(jerry, list(restored_garfield.chases.all())[0])

    # and finally a saved model with a lazy relation

    garfield.save()

    restored_saved_garfield = pickle_and_restore(garfield)

    pickle_eq(garfield, restored_saved_garfield)
    pickle_eq(jerry, list(restored_saved_garfield.chases.all())[0])

########NEW FILE########
__FILENAME__ = neo4jclient_tests
from nose.tools import with_setup, eq_
import random, string
from django.conf import settings as _settings
from ..db import connections
from ..neo4jclient import EnhancedGraphDatabase

class MyGraphDatabase(EnhancedGraphDatabase):
    def do_something(self):
        return "did something"

def setup():
    global neo4django, gdb, neo4jclient, connection

    from neo4django.tests import neo4django, gdb
    from neo4django import neo4jclient
    from neo4django.db import connection

def teardown():
    gdb.cleandb()

def test_cleandb():
    def assert_deletion(ids):
        eq_(connection.gremlin('results=nodeIds.collect{(boolean)g.v(it)}.any()', nodeIds = ids, raw=True), 'false')

    node_id = connection.gremlin('results=g.addVertex().id')
    connection.cleandb()
    assert_deletion([node_id])

    #try it with more nodes
    node_ids = connection.gremlin('results=(0..50).collect{g.addVertex().id}', raw=True)
    connection.cleandb()
    assert_deletion(node_ids)

    #try it with related nodes
    linked_script = '''results = []
                       lastNode=g.v(0);(0..50).each{
                           thisNode=g.addVertex()
                           results << thisNode.id
                           g.addEdge(lastNode, thisNode, "knows",[:]);
                           lastNode = thisNode
                       }'''
    node_ids = connection.gremlin(linked_script, raw=True)
    connection.cleandb()
    assert_deletion(node_ids)

def test_other_library():
    random_lib = """
    class %(class_name)s {
        static public binding;
        static getRoot() {
            return binding.g.v(0)
        }
    }
    %(class_name)s.binding = binding;
    """
    class_name = ''.join(random.choice(string.letters) for i in xrange(6))
    random_lib %= {'class_name':class_name}
    neo4jclient.load_library(class_name, random_lib)

    node = connection.gremlin('results = %s.getRoot()' % class_name)
    eq_(node.id, 0)

def test_custom_clients_same_database():
    """Testing to make sure our custom """
    assert connections['custom'].do_something() == "did something"

    try:
        connections['default'].do_something()
    except AttributeError:
        pass
    else:
        raise AssertionError('Default database should not have access to do_something()')

########NEW FILE########
__FILENAME__ = nodequeryset_tests
from nose.tools import with_setup, eq_, raises

from django.core import exceptions
from django.db.models import Q

from time import time
import itertools
import sys, datetime
stdout = sys.stdout

def setup():
    global Person, neo4django, gdb, Query, OPERATORS, IndexedMouse, \
           DEFAULT_DB_ALIAS, Condition, models, RelatedCat, RelatedDog 

    from neo4django.tests import Person, neo4django, gdb
    from neo4django.db import DEFAULT_DB_ALIAS, models
    from neo4django.db.models.query import Query, OPERATORS, \
            Condition

    from django.db.models import get_model

    RelatedCat = get_model('tests','RelatedCat')
    RelatedDog = get_model('tests','RelatedDog')
    IndexedMouse = get_model('tests','IndexedMouse')

def teardown():
    gdb.cleandb()

@with_setup(None, teardown)
def test_create():
    """Confirm 'create()' works for NodeQuerySet."""
    pete = Person.objects.create(name='Pete')
    try:
        gdb.nodes.get(pete.pk)
    except:
        raise AssertionError('Pete was not created or was not given a primary '
                             'key.')
 
@with_setup(None, teardown)
def test_delete():
    """Confirm 'delete()' works for NodeQuerySet."""
    jack = Person(name='jack')
    jack.save()
    jacks_pk = jack.pk
    Person.objects.filter(name='jack').delete()
    try:
        gdb.nodes.get(jacks_pk)
    except:
        pass
    else:
        raise AssertionError("Jack's pk is still in the graph- he wasn't "
                             "deleted.")

@with_setup(None, teardown)
def test_iter():
    """Confirm 'all()' is iterable."""
    for p in Person.objects.all():
        pass

@with_setup(None, teardown)
def test_dates():
    """Testing dates() with simple time right now""" 
    
    class DatedPaper(models.NodeModel):
        name = models.StringProperty()
        date = models.DateProperty()
        datetime = models.DateTimeProperty()
        
    day0 = datetime.date.today()
    time0 = datetime.datetime.now()
    paper = DatedPaper(name='Papes', date = day0, datetime = time0)
    paper.save()
    day1 = datetime.date.today()
    time1 = datetime.datetime.now()
    other = DatedPaper(name='other', date = day1, datetime = time1)
    other.save()
    results = DatedPaper.objects.dates('day', 'year').iterator()
    paper = results.next()
    other = results.next()
    assert paper.name == 'Papes'
    assert other.name == 'other'
    assert paper.datetime < other.datetime

def test_none():
    eq_(len(Person.objects.none()), 0)

def make_mice(names, ages):
    for name, age in zip(names, ages):
        IndexedMouse.objects.create(name=name,age=age)

mouse_names = ['jerry','Brain', 'Pinky']
mouse_ages = [2,3,2]
def setup_mice():
    make_mice(mouse_names, mouse_ages)

def make_people(names, ages):
    pairs = zip(names, ages)
    for p in pairs:
        Person.objects.create(name=p[0], age=p[1])

people_names = ['Jack','Jill','Peter Pan','Tinker Bell','Candleja-']

def setup_people():
    make_people(people_names, [5,10,15,15,30])

setup_people.num_people=5

def setup_mice_and_people():
    setup_mice()
    setup_people()

@with_setup(setup_people, teardown)
def test_all():
    """
    Tests that all() returns all saved models of a type, and that calling it
    twice returns two distinct Querysets.
    """
    results = list(Person.objects.all())
    eq_(len(results), setup_people.num_people)

    names = set(p.name for p in results)
    for name in people_names:
        assert name in names, '%s is not in %s' % (name, repr(name))

    clone1 = Person.objects.all()
    clone2 = Person.objects.all()
    assert clone1 is not clone2

    for i in xrange(50):
        Person.objects.create()
    eq_(len(Person.objects.all()), setup_people.num_people + 50)

def test_queryset_str():
    q = Person.objects.all()
    str(q)

@with_setup(setup_mice, teardown)
def test_basic_indexed_query():
    """
    Tests a basic query over a single type. Only indexed fields are tested.
    """
    age_query = Query(IndexedMouse).add_q(Q(age=2))
    results = list(age_query.execute(DEFAULT_DB_ALIAS))
    eq_(len(results), 2)
    assert len([m for m in results if m.name == 'Brain']) == 0, "The query"\
            " returned Brain - even though he's too old."

    results = list(age_query.add_q(Q(name='jerry'))\
                   .execute(DEFAULT_DB_ALIAS))
    eq_(len(results), 1)
    assert len([m for m in results if m.name == 'jerry']) > 0, "The query"\
            " didn't return jerry - wrong mouse."

@with_setup(setup_mice, teardown)
def test_negated_query():
    """
    Tests a negated query over a single type. Only indexed fields are tested.
    """
    query = Query(IndexedMouse).add_q(Q(age=2))\
            .add_q(~Q(name='jerry'))
    results = list(query.execute(DEFAULT_DB_ALIAS))
    eq_(len(results), 1)
    assert len([m for m in results if m.name == 'jerry']) == 0, "The query"\
            " returned jerry, even though he was excluded."

@with_setup(setup_people, teardown)
def test_unindexed_query():
    """
    Tests a query over a single type. Only non-indexed fields are tested.
    """
    query = Query(Person).add_q(Q(name='Peter Pan'))
    results = list(query.execute(DEFAULT_DB_ALIAS))

    eq_(len(results), 1)
    eq_(results[0].name, 'Peter Pan')

@with_setup(setup_people, teardown)
def test_complex_query():
    """
    Tests a single-type query with both indexed and non-indexed fields.
    """
    query = Query(Person).add_q(~Q(name='Peter Pan')).add_q(Q(age=15))
    results = list(query.execute(DEFAULT_DB_ALIAS))

    eq_(len(results), 1)
    eq_(results[0].name, 'Tinker Bell')

@with_setup(None, teardown)
def test_type_query():
    """
    Tests that Query properly excludes results of different types.
    """
    #TODO
    raise NotImplementedError('Write this test!')

@with_setup(setup_people, teardown)
def test_get():
    """
    Tests Queryset.get() with and without filter parameters.
    """
    name = "The world's most interesting man"
    age = 150
    Person.objects.create(name=name, age=age)
    p = Person.objects.all().get(name=name, age=age)
    eq_(p.name, name)
    eq_(p.age, age)

@with_setup(setup_people, teardown)
def test_get_by_id():
    """
    Tests Queryset.get() using id as a filter parameter.
    """
    name = "The world's most interesting man"
    age = 150
    interesting_man = Person.objects.create(name=name, age=age)
    p1 = Person.objects.get(id=interesting_man.id)
    eq_(p1.name, name)
    eq_(p1.age, age)

    try:
        p2 = Person.objects.get(name="Less interesting man", id=interesting_man.id)
    except exceptions.ObjectDoesNotExist:
        pass
    else:
        raise AssertionError('Interesting man was returned, though he has the '
                             'wrong name.')

@with_setup(None, teardown)
def test_filter_exact():
    #TODO docstring
    make_people(['tom', 'jerry', 'jErry'], [1,2,2])
    try:
        tom = Person.objects.filter(age=1).get()
        assert tom.name == 'tom', "Returned Person from filtered queryset "\
                                  "doesn't have the correct name."
    except ValueError:
        assert False, 'More than one object exists in the queryset - it was '
        'improperly filtered.'
    #test multiple conditions
    try:
        jerry = Person.objects.filter(age=2).filter(name='jErry').get()
        assert jerry.name == 'jErry', "Returned Person from filtered queryset "\
                                  "doesn't have the correct name."
    except ValueError:
        assert False, 'More than one object exists in the multi-condition '\
                      'queryset - it was improperly filtered.'

@with_setup(None, teardown)
def test_filter_iexact():
    make_people(['tom', 'jerry', 'jErry'], [1,2,2])
    jerrys = Person.objects.filter(name__iexact='jerry')
    eq_(len(list(jerrys)), 2)

#test in

@with_setup(setup_people, teardown)
def test_in_id():
    """
    Tests Queryset.filter() with an id__in field lookup.
    """
    name = "The world's most interesting man"
    age = 150
    interesting_man = Person.objects.create(name=name, age=age)

    boring_name = 'uninteresting man'
    boring_age = age - 1
    uninteresting_man = Person.objects.create(name=boring_name, age=boring_age)

    Person.objects.create(age=boring_age)
    
    people = list(Person.objects.filter(id__in=(interesting_man.id, uninteresting_man.id)))
    eq_(len(people), 2)
    eq_([boring_age, age], sorted(p.age for p in people))

    people = list(Person.objects.filter(age=boring_age)
                  .filter(id__in=(interesting_man.id, uninteresting_man.id)))
    eq_(len(people), 1)
    eq_(people[0].id, uninteresting_man.id)

    single_person = list(Person.objects.filter(id__in=(interesting_man.id,)))
    eq_(len(single_person), 1)

    no_people = list(Person.objects.filter(id__in=(1000,)))
    eq_(len(no_people), 0)

    # Test chaining
    only_interesting = Person.objects.filter(
        id__in=(interesting_man.id,)
        ).filter(id__in=(interesting_man.id, uninteresting_man.id))
    eq_(len(only_interesting), 1)

    only_interesting = Person.objects.filter(
        id__in=(interesting_man.id,)
        ).filter(id__in=(uninteresting_man.id,))
    eq_(len(only_interesting), 0)
    
    # Passing in an empty qs -- replicate django
    eq_(len(Person.objects.filter(id__in=[])), 0)

    # Passing in qs with None -- replicate django
    eq_(len(Person.objects.filter(id__in=[uninteresting_man.id, None])), 1)

def setup_teens():
    setup_people()
    make_people(['Tina', 'Rob', 'Tiny Tim'], [13, 15, 12])

setup_teens.num_people = setup_people.num_people + 3

@with_setup(setup_teens, teardown)
def test_filter_gt():
    teens_and_up = Person.objects.filter(age__gt=13)
    assert all(p.age > 13 for p in teens_and_up), 'Not all teenage or older!'
    assert len(teens_and_up) > 0, 'No one returned!'
    assert not any(p.name == 'Tiny Tim' for p in teens_and_up),\
            "Tiny Tim was included, but he's too young!"
    # now check an unindexed property
    all_named_after_t = Person.objects.filter(name__gt='T')
    eq_(len(all_named_after_t), 3)

@with_setup(setup_teens, teardown)
def test_filter_gte():
    teens_and_up = Person.objects.filter(age__gte=12)
    assert all(12 <= p.age for p in teens_and_up), 'Not all teenage or older!'
    assert len(teens_and_up) > 0, 'No one returned!'
    assert any(p.name == 'Tiny Tim' for p in teens_and_up),\
            "Tiny Tim was excluded! That sucks, he's 12!"
    # now check an unindexed property
    all_named_after_tiny_tim = Person.objects.filter(name__gte='Tiny Tim')
    eq_(len(all_named_after_tiny_tim), 1)

@with_setup(setup_teens, teardown)
def test_filter_lt():
    kids_only = Person.objects.filter(age__lt=13)
    assert all(p.age < 13 for p in kids_only), 'Not all under 13!'
    assert len(kids_only) > 0, 'No one returned!'
    assert any(p.name == 'Tiny Tim' for p in kids_only),\
            "Tiny Tim was excluded! That sucks, he's 12!"
    # now check an unindexed property
    all_named_before_d = Person.objects.filter(name__lt='D')
    eq_(len(all_named_before_d), 1)

@with_setup(setup_teens, teardown)
def test_filter_lte():
    kids_only = Person.objects.filter(age__lte=12)
    assert all(p.age <= 12 for p in kids_only), 'Not all under 12!'
    assert len(kids_only) > 0, 'No one returned!'
    assert any(p.name == 'Tiny Tim' for p in kids_only),\
            "Tiny Tim was excluded! That sucks, he's 12!"
    # now check an unindexed property
    all_named_before_candle = Person.objects.filter(name__lte='Candleja-')
    eq_(len(all_named_before_candle), 1)

alphabet = [chr(i + 97) for i in range(26)]
def test_filter_range():
    import random
    ages_and_names = zip(*[(''.join(random.sample(alphabet, 6)), i + 70) for i in xrange(20)])
    make_people(*ages_and_names)
    octogenarians = Person.objects.filter(age__range=(80, 89))
    assert all(80 <= p.age <= 89 for p in octogenarians), "These guys aren't all in their 80's!"

    # now check an unindexed property
    make_people(['Tom'], [25])
    all_between_s_u = Person.objects.filter(name__range=('S','U'))
    assert len(all_between_s_u) >= 1, "There's at least one 'T' name!"

@with_setup(None, teardown)
def test_filter_date_range():
    class Lifetime(models.NodeModel):
        dob = models.DateProperty(indexed=True)
        mid_life_crisis = models.DateTimeProperty(indexed=True)
        tod = models.DateTimeProperty(indexed=False)
    date = datetime.date
    time = datetime.datetime
    bdays = [date(1952, 3, 5), date(1975, 8, 11), date(1988, 7, 27)]
    crises = [time(1992, 3, 6, 2, 15, 30), time(2007, 8, 13, 16, 10, 10),
              time(2020, 8, 1, 8, 7, 59, 99)]
    tods = [time(2022, 3, 6, 2, 15, 30), time(2047, 10, 30, 22, 47, 1),
              time(2060, 8, 15, 8, 7, 59)]
    for t in zip(bdays, crises, tods):
        Lifetime.objects.create(dob=t[0], mid_life_crisis=t[1], tod=t[2])

    low, high = date(1975, 9, 11), time.now()
    query = Lifetime.objects.filter(dob__range=(low, high))
    assert all(low < l.dob < high.date() for l in query)

    nowish = date(2011, 8, 10)
    query = Lifetime.objects.filter(mid_life_crisis__lt=nowish)
    eq_(len(query), 2)

    the_singularity = date(2032, 12, 12)
    query = Lifetime.objects.filter(tod__gt=the_singularity)
    eq_(len(query), 2)

@with_setup(None, teardown)
def test_filter_array_member():
    """
    Tests the new `field__member` array membership field lookup.
    """
    class TooManyAccounts(Person):
        names = models.StringArrayProperty()
        emails = models.StringArrayProperty(indexed=True)

    names = ['Test1','Rob','Bill']
    emails = ['test1@example.com','test2@example.com','test3@example.com']
    p1 = TooManyAccounts.objects.create(names=names[:2], emails=emails[:2])
    p2 = TooManyAccounts.objects.create(names=names[1:], emails=emails[1:])

    q_1only = TooManyAccounts.objects.filter(emails__member=emails[0])
    q_both = TooManyAccounts.objects.filter(emails__member=emails[1])

    eq_(len(q_1only), 1)
    eq_(list(q_1only)[0].id, p1.id)

    eq_(set(p.id for p in q_both), set((p1.id, p2.id)))

    # now check an unindexed property
    q_both = TooManyAccounts.objects.filter(names__member=names[1])
    eq_(len(q_both), 2)
    eq_(set(p.id for p in q_both), set((p1.id, p2.id)))

    q_1only = TooManyAccounts.objects.filter(names__member=names[0])
    eq_(len(q_1only), 1)
    eq_(list(q_1only)[0].id, p1.id)

@with_setup(setup_teens, teardown)
def test_filter_in():
    q = Person.objects.filter(age__in=[15, 12])
    
    eq_(len(q), 4)
    assert all(p.age in [15,12] for p in q)

    # now check an unindexed property
    tim_and_rob = Person.objects.filter(name__in=['Tiny Tim','Rob'])
    eq_(len(tim_and_rob), 2)

@with_setup(None, teardown)
def test_filter_array_member_in():
    """
    Tests the `field__member_in` array membership field lookup.
    """
    class TooManyAccounts(Person):
        names = models.StringArrayProperty()
        emails = models.StringArrayProperty(indexed=True)

    names = ['Test1','Rob','Bill']
    emails = ['test1@example.com','test2@example.com','test3@example.com']
    p1 = TooManyAccounts.objects.create(names=names[:2], emails=emails[:2])
    p2 = TooManyAccounts.objects.create(names=names[1:], emails=emails[1:])

    q_1only = TooManyAccounts.objects.filter(emails__member_in=[emails[0]])
    q_both = TooManyAccounts.objects.filter(emails__member_in=emails)

    eq_(len(q_1only), 1)
    eq_(list(q_1only)[0].id, p1.id)

    eq_(set(p.id for p in q_both), set((p1.id, p2.id)))

    # now check an unindexed property
    q_both = TooManyAccounts.objects.filter(names__member_in=names)
    eq_(len(q_both), 2)
    eq_(set(p.id for p in q_both), set((p1.id, p2.id)))

    q_1only = TooManyAccounts.objects.filter(names__member_in=[names[0]])
    eq_(len(q_1only), 1)
    eq_(list(q_1only)[0].id, p1.id)

@with_setup(setup_mice_and_people, teardown)
def test_filter_contains():
    q1 = Person.objects.filter(name__contains='a')

    eq_(len(q1), 3)
    assert all('a' in p.name for p in q1)

    q2 = IndexedMouse.objects.filter(name__contains='y')
    eq_(len(q2), 2)

@with_setup(setup_mice_and_people, teardown)
def test_filter_icontains():
    q1 = Person.objects.filter(name__icontains='j')

    eq_(len(q1), 3)
    assert all('j' in p.name.lower() for p in q1)

    q2 = IndexedMouse.objects.filter(name__icontains='b')
    eq_(len(q2), 1)

@with_setup(setup_mice_and_people, teardown)
def test_filter_startswith():
    q1 = Person.objects.filter(name__startswith='J')

    eq_(len(q1), 2)
    assert all(p.name.startswith('J') for p in q1)

    q2 = IndexedMouse.objects.filter(name__startswith='P')
    eq_(len(q2), 1)

@with_setup(None, teardown)
def test_filter_istartswith():
    make_people(['Pete', 'John', 'peter'],[32,25,30])
    
    q1 = Person.objects.filter(name__istartswith='Pete')
    eq_(len(q1), 2)
    assert all(p.name.lower().startswith('pete') for p in q1)

@with_setup(setup_mice_and_people, teardown)
def test_filter_endswith():
    q1 = Person.objects.filter(name__endswith='ll')

    eq_(len(q1), 2)
    assert all(p.name.endswith('ll') for p in q1)

    q2 = IndexedMouse.objects.filter(name__endswith='ky')
    eq_(len(q2), 1)

@with_setup(setup_mice_and_people, teardown)
def test_filter_iendswith():
    make_people(['BelL'],[18])
    q1 = Person.objects.filter(name__iendswith='ll')

    eq_(len(q1), 3)
    assert all(p.name.lower().endswith('ll') for p in q1)

    make_mice(['pinkY'],[15])
    q2 = IndexedMouse.objects.filter(name__iendswith='ky')
    eq_(len(q2), 2)

@with_setup(setup_mice_and_people, teardown)
def test_filter_regex():
    q1 = Person.objects.filter(name__regex='.*ll')
    eq_(len(q1), 2)

    q2 = IndexedMouse.objects.filter(name__regex='P.*ky')
    eq_(len(q2), 1)

@with_setup(setup_mice_and_people, teardown)
def test_filter_iregex():
    make_people(['Pete', 'John', 'peter'],[32,25,30])
    q1 = Person.objects.filter(name__iregex='Pete.*')
    eq_(len(q1), 3)

    q2 = IndexedMouse.objects.filter(name__iregex='p.*ky')
    eq_(len(q2), 1)

@with_setup(None, teardown)
def test_filter_year():
    class DatedEvent(models.NodeModel):
        date = models.DateProperty()

    event_1 = DatedEvent.objects.create(date=datetime.date.today())
    event_2 = DatedEvent.objects.create(date=datetime.date(2003, 3, 4))

    q = DatedEvent.objects.filter(date__year = 2003)
    eq_(len(q), 1)
    eq_(q[0], event_2)

@with_setup(None, teardown)
def test_filter_month():
    class DatedEvent(models.NodeModel):
        date = models.DateProperty()

    event_1 = DatedEvent.objects.create(date=datetime.date(2013, 1, 1))
    event_2 = DatedEvent.objects.create(date=datetime.date(2003, 3, 4))

    q = DatedEvent.objects.filter(date__month = 3)
    eq_(len(q), 1)
    eq_(q[0], event_2)

@with_setup(None, teardown)
def test_filter_day():
    class DatedEvent(models.NodeModel):
        date = models.DateProperty()

    event_1 = DatedEvent.objects.create(date=datetime.date(2013, 1, 1))
    event_2 = DatedEvent.objects.create(date=datetime.date(2003, 3, 4))

    q = DatedEvent.objects.filter(date__day = 1)
    eq_(len(q), 1)
    eq_(q[0], event_1)

@with_setup(None, teardown)
def test_filter_isnull():
    nameless_person = Person.objects.create(age=50)
    ageless_person = Person.objects.create(name='Pete', age=None)

    q1 = Person.objects.filter(age__isnull=True)
    eq_(len(q1), 1)
    eq_(q1[0], ageless_person)

    q2 = Person.objects.filter(name__isnull=True)
    eq_(len(q2), 1)
    eq_(q2[0], nameless_person)

    q3 = Person.objects.filter(age__isnull=False)
    eq_(len(q3), 1)
    eq_(q3[0], nameless_person)

@with_setup(None, teardown)
def test_exclude_exact():
    pass

@with_setup(setup_people, teardown)
def test_in_bulk():
    """
    Tests Queryset.in_bulk().
    """
    name = "The world's most interesting man"
    age = 150
    interesting_man = Person.objects.create(name=name, age=age)

    boring_name = 'uninteresting man'
    boring_age = age - 1
    uninteresting_man = Person.objects.create(name=boring_name, age=boring_age)

    Person.objects.create(age=boring_age)

    people = Person.objects.in_bulk((interesting_man.id, uninteresting_man.id))
    eq_(len(people), 2)
    eq_(people[interesting_man.id].name, name)
    eq_([boring_age, age], sorted(p.age for p in people.values()))

@with_setup(setup_people, teardown)
def test_in_bulk_not_found():
    """
    Tests QuerySet.in_bulk() with items not found.
    """
    people = Person.objects.in_bulk([999999])
    eq_(people, {})

cat_names = ['Tom', 'Mr. Pussy-Wussy', 'Mr. Bigglesworth']
dog_names = ['Spike','Lassie','Clifford']
def setup_chase():
    cats = [RelatedCat.objects.create(name=n) for n in cat_names]
    dogs = [RelatedDog.objects.create(name=n) for n in dog_names]
    mice = [IndexedMouse.objects.create(name=n) for n in mouse_names]

    for m, c, d in zip(mice, cats, dogs):
        c.chases = m
        d.chases = c
        c.save()
        d.save()

@with_setup(setup_chase, teardown)
def test_select_related():
    def check_dog_hier_from_q(queryset):
        dogs = []
        cats = []
        mice = []
        for d in queryset:
            dogs.append(d)
            for c in d.chases.all():
                cats.append(c)
                for m in c.chases.all():
                    mice.append(m)
                    m.name
        
        #check correctness, leave performance for benchmarking
        spike = filter(lambda d: d.name == 'Spike', dogs)[0]
        tom = filter(lambda c: c.name == 'Tom', cats)[0]
        jerry = filter(lambda m: m.name == 'jerry', mice)[0]
        eq_(list(spike.chases.all())[0], tom)
        eq_(list(tom.chases.all())[0], jerry)
    
    check_dog_hier_from_q(RelatedDog.objects.all().select_related(depth=2))

    #test reverse relation with an index-based query
    jerry = IndexedMouse.objects.all().select_related().get(name='jerry')
    jerry_chasers = list(jerry.relatedcat_set.all())
    eq_(len(jerry_chasers), 1)
    eq_(jerry_chasers[0].name, 'Tom')
    
    #try the hierarchy with a field-based select_related
    check_dog_hier_from_q(RelatedDog.objects.all().select_related('chases','chases__chases'))

@with_setup(setup_chase, teardown)
def test_spanning_lookup():
    #test the regular relation
    tom = RelatedCat.objects.get(chases__name='jerry')
    eq_(tom.name, 'Tom')

    spike = RelatedDog.objects.get(chases__chases__name='jerry')
    eq_(spike.name, 'Spike')

    #then test the reverse
    tom = RelatedCat.objects.all().get(relateddog_set__name='Spike')
    eq_(tom.name, 'Tom')

    jerry = IndexedMouse.objects.all().get(relatedcat_set__relateddog_set__name='Spike')
    eq_(jerry.name, 'jerry')

    # then test by id lookup
    tom = RelatedCat.objects.get(chases__id=jerry.id)
    eq_(tom.name, 'Tom')

@with_setup(setup_chase, teardown)
def test_pk_shortcut():
    """
    Tests whether 'pk' works in in lieu of id for local and spanning lookups.
    """
    jerry = IndexedMouse.objects.get(name='jerry')
    other_jerry = IndexedMouse.objects.get(pk=jerry.id)
    eq_(jerry, other_jerry)
    
    tom = RelatedCat.objects.get(chases__pk=jerry.id)
    eq_(tom.name, 'Tom')

@with_setup(None, teardown)
def test_large_query():
    ages = range(1, 151)
    names = ['a mouse'] * len(ages)
    make_mice(names, ages)

    mice =  list(IndexedMouse.objects.filter(age__in=ages))
    eq_(len(mice), len(ages))

@with_setup(None, teardown)
def test_zerovalued_lookup():
    ages = range(2)
    make_mice(['a','a'], ages)

    mice =  list(IndexedMouse.objects.filter(age__in=ages))
    eq_(len(mice), len(ages))

@with_setup(None, teardown)
def test_get_or_create():
    name = "Kristian"
    (obj1, created) = Person.objects.get_or_create(name=name)
    assert created == True, "Person should have been created but wasn't"
    (obj2, created) = Person.objects.get_or_create(name=name)
    assert created == False, "Person should not have been created, one should already exist"
    assert obj1 == obj2, "Second get_or_create() should have returned Person created by first get_or_create()"

@with_setup(None, teardown)
def test_object_index():
    class PollIdx(models.NodeModel):
            question = models.StringProperty()
            def __unicode__(self):
                return self.question
    p1 = PollIdx(question="Who's the best")
    p2 = PollIdx(question="How's the weather?")
    p3 = PollIdx(question="What's up?")
    p1.save()
    p2.save()
    p3.save()

    eq_(len(PollIdx.objects.all()), 3)
    p0 = PollIdx.objects.all()[0]
    p1 = PollIdx.objects.all()[1]
    p2 = PollIdx.objects.all()[2]
    eq_(len(set([p0, p1, p2, p0])), 3, "There should be 3 different polls")

    qsall = PollIdx.objects.all()
    # Should fill up cache one by one
    eq_(qsall._result_cache, None)
    p0 = qsall[0]
    eq_(len(qsall._result_cache), 1)
    p1 = qsall[1]
    eq_(len(qsall._result_cache), 2)
    p2 = qsall[2]
    eq_(len(qsall._result_cache), 3)
    eq_(len(set([p0, p1, p2, p0, p1])), 3, "There should be 3 different polls")

    qsall = PollIdx.objects.all()
    # Filling up the cache first
    len(qsall)
    eq_(len(qsall._result_cache), 3)
    p0 = qsall[0]
    p1 = qsall[1]
    p2 = qsall[2]
    eq_(len(set([p0, p1, p2, p0, p1, p2])), 3, "There should still be 3 different polls")

@with_setup(setup_people, teardown)
def test_order_by():
    people = Person.objects.all().order_by('age')
    eq_(len(people), 5)
    eq_(list(people), sorted(list(people), key=lambda p:p.age))
    
    # check the reverse order
    people = Person.objects.all().order_by('-age')
    eq_(list(people), sorted(list(people), key=lambda p:p.age, reverse=True))

@with_setup(setup_people, teardown)
def test_order_by_and_count():
    num_people = Person.objects.all().order_by('age').count()
    eq_(num_people, 5)

@with_setup(setup_people, teardown)
def test_reverse():
    people = Person.objects.all().order_by('age').reverse()
    eq_(len(people), 5)
    eq_(list(people), sorted(list(people), key=lambda p:p.age, reverse=True))

@with_setup(setup_people, teardown)
def test_exists():
    eq_(Person.objects.all().exists(), True)
    eq_(Person.objects.all().filter(name='Candleja-').exists(), True)
    eq_(Person.objects.all().filter(age__gt=80).exists(), False)
    eq_(Person.objects.all().filter(age__lt=80).exists(), True)

@with_setup(setup_people, teardown)
def test_count():
    eq_(Person.objects.all().count(), 5)
    eq_(Person.objects.all().filter(name='Candleja-').count(), 1)
    eq_(Person.objects.all().filter(age__gt=10).count(), 3)

@with_setup(setup_people, teardown)
def test_aggregate_count():
    from django.db.models import Count

    eq_(Person.objects.all().aggregate(Count('age')).get('age__count', None), 5)
    eq_(Person.objects.all().filter(name='Candleja-').aggregate(Count('age')).get('age__count', None), 1)
    eq_(Person.objects.filter(age__gt=10).aggregate(Count('name')).get('name__count', None), 3)

@with_setup(setup_people, teardown)
def test_aggregate_max_min():
    from django.db.models import Max, Min

    eq_(Person.objects.all().aggregate(Min('age')).get('age__min', None), 5)
    eq_(Person.objects.all().aggregate(Max('age')).get('age__max', None), 30)
    eq_(Person.objects.all().filter(name='Candleja-').aggregate(Min('age')).get('age__min', None), 30)

@with_setup(setup_people, teardown)
def test_aggregate_sum():
    from django.db.models import Sum

    eq_(Person.objects.all().aggregate(Sum('age')).get('age__sum', None), 75)
    eq_(Person.objects.all().filter(name='Candleja-').aggregate(Sum('age')).get('age__sum', None), 30)

@with_setup(setup_people, teardown)
def test_aggregate_avg():
    from django.db.models import Avg

    eq_(Person.objects.all().aggregate(Avg('age')).get('age__avg', None), 15)
    eq_(Person.objects.all().filter(name='Candleja-').aggregate(Avg('age')).get('age__avg', None), 30)

@with_setup(None, teardown)
def test_latest():
    class BornPerson(models.NodeModel):
        class Meta:
            get_latest_by = 'born'
        born = models.DateProperty()

    person = BornPerson.objects.create(born=datetime.date.today())
    older_person = BornPerson.objects.create(
        born=datetime.date.today() - datetime.timedelta(1))

    eq_(person, BornPerson.objects.latest('born'))
    eq_(person, BornPerson.objects.latest())

@with_setup(None, teardown)
def test_query_type():
    """
    Confirms #151 - ensures sibling types are not returned on query, even if the
    the related index is at the parent level.
    """
    class IndexedParent(models.NodeModel):
        name = models.StringProperty(indexed=True)

    class Sibling1(IndexedParent):
        pass

    class Sibling2(IndexedParent):
        pass

    s1 = Sibling1.objects.create(name='Amanda')
    s2 = Sibling2.objects.create(name='Other Amanda')

    eq_(len(Sibling1.objects.filter(name__contains='Amanda')), 1)
    eq_(len(Sibling2.objects.filter(name__contains='Amanda')), 1)

    eq_(len(IndexedParent.objects.filter(name__contains='Amanda')), 2)

@with_setup(setup_people, teardown)
def test_complex_filters():
    eq_(len(Person.objects.filter(Q(age=5))), 1)
    eq_(len(Person.objects.filter(Q(age=5) & Q(name='Jack'))), 1)
    eq_(len(Person.objects.filter(Q(age=5) | Q(name='Jill'))), 2)

@with_setup(None, teardown)
def test_inherited_indexed_filter():
    class SpecializedPerson(Person):
        position = models.StringProperty(indexed=True)

    pete = SpecializedPerson.objects.create(name='Pete',
                                            position='Assistant Manager')

    pete_2 = Person.objects.create(name='Pete')

    eq_(SpecializedPerson.objects.filter(name='Pete')\
                         .get(position__contains='Manager'),
        pete)

@with_setup(None, teardown)
@raises(Exception)
def test_create_with_id():
    """
    Confirm 'create()' errors out when given an id. Confirms #201.
    """
    pete = Person.objects.create()
    bad_obj = Person.objects.create(id=pete.id)

@with_setup(setup_people, teardown)
def test_update():
    """
    Confirm basic use of `update()`.
    """
    # update an indexed field
    teens = set(Person.objects.filter(age=15))
    Person.objects.filter(age=15).update(age=20)
    twenties = set(Person.objects.filter(age=20))
    eq_(teens, twenties)

    # and an unindexed field
    Person.objects.filter(age=20).update(name='Twenty')
    eq_(twenties, set(Person.objects.filter(age=20)))

########NEW FILE########
__FILENAME__ = property_tests
from nose.tools import eq_, with_setup
from django.core.exceptions import ValidationError

import datetime
import itertools

def setup():
    global Person, neo4django, gdb, neo4jrestclient, neo_constants, settings,\
           models, tzoffset, tzutc

    from neo4django.tests import Person, neo4django, gdb, neo4jrestclient, \
            neo_constants, settings
    from neo4django.db import models

    try:
        from dateutil.tz import tzutc, tzoffset
    except ImportError:
        from models.properties import tzutc, tzoffset

def teardown():
    gdb.cleandb()

#TODO refactor this for use by the rest of the suite
def assert_gremlin(script, params):
    """
    Assert the provided Gremlin script results evaluates to `true`.
    """
    eq_(gdb.gremlin_tx(script, **params), 'true')

def test_prop():
    pete = Person(name='Pete')
    assert pete.name == 'Pete'
    pete.save()
    assert pete.name == 'Pete'
    pete.name = 'Peter'
    assert pete.name == 'Peter'
    pete.save()
    assert pete.name == 'Peter'

def test_none_prop():
    """Confirm that `None` and null verification work properly."""
    #first show that unsert properties are None
    pete = Person()
    pete.save()
    assert pete.name is None
    
    #then that `null=False` works properly
    class NotNullPerson(models.NodeModel):
        class Meta:
            app_label = 'test'
        name = models.StringProperty(null=False)
    try:
        andy = NotNullPerson(name = None)
        andy.save()
    except:
        pass
    else:
        raise AssertionError('Non-nullable field accepted `None` as a value.')

    #and finally, that setting a property to None deletes it in the db
    pete.name = 'Pete'
    pete.save()
    pete.name = None
    pete.save()

    assert_gremlin('results=!g.v(node_id).any{it.hasProperty("name")}',
                   {'node_id':pete.id})

def test_integer():
    def try_int(integer):
        node = Person(name="SandraInt", age=integer)
        node.save()
        assert node.age == integer
        node.delete()

    for i in [0,1,-1,28,neo4django.db.models.properties.MAX_INT,neo4django.db.models.properties.MIN_INT]:
        try_int(i)
    
def test_date_constructor():
    class DateNode(models.NodeModel):
        date = models.DateProperty()

    today = datetime.date.today()
    d = DateNode(date=today)
    assert d.date == today
    d.save()
    assert d.date == today

def test_date_prop():
    #TODO
    pass

def disable_tz():
    settings.USE_TZ = False

def enable_tz():
    settings.USE_TZ = True

# test without TZ support, since another test covers that
@with_setup(disable_tz, enable_tz)
def test_datetime_constructor():
    """Confirm `DateTimeProperty`s work from a NodeModel constructor."""
    #TODO cover each part of a datetime
    class DateTimeNode(models.NodeModel):
        datetime = models.DateTimeProperty()

    time = datetime.datetime.now()
    d = DateTimeNode(datetime = time)
    assert d.datetime == time
    d.save()
    assert d.datetime == time

def test_datetime_auto_now():
    from time import sleep
    class BlogNode(models.NodeModel):
        title = models.Property()
        date_modified = models.DateTimeProperty(auto_now = True)
    timediff = .6 #can be this far apart
    ##Confirm the date auto sets on creation
    b = BlogNode(title = 'Snake House')
    b.save()
    time1 = datetime.datetime.now()
    test1, test2 = get_times(time1, b.date_modified)
    assert abs(test1-test2) <= timediff
    ##Confirm the date auto sets when saved and something changes
    sleep(timediff)
    b.title = 'BEEEEEEEES!'
    b.save()
    time2 = datetime.datetime.now()
    test1, test2 = get_times(time2, b.date_modified)
    assert abs(test1-test2) <= timediff
    ##Confirm the date auto sets when saved and nothing changes
    sleep(timediff)
    b.save()
    time3 = datetime.datetime.now()
    test1, test2 = get_times(time3, b.date_modified)
    assert abs(test1-test2) <= timediff

def get_times(t1, t2):
    rv = [t1.second*1.0 + (t1.microsecond/10.0**6), t2.second*1.0 + (t2.microsecond/10.0**6)]
    if t1.minute - t2.minute == 1:
        rv[0] += 60
    elif t2.minute - t1.minute == 1:
        rv[1] += 60
    return rv

def test_datetime_auto_now_add():
    class BloggNode(models.NodeModel):
        title = models.Property()
        date_created = models.DateTimeProperty(auto_now_add = True)
    timediff = .6
    ##Confrim date auto sets upon creation
    time1 = datetime.datetime.now()
    b = BloggNode(title = 'Angry birds attack buildings!')
    b.save()
    test1, test2 = get_times(time1, b.date_created)
    assert abs(test1-test2) <= .6
    time = b.date_created
    ##Confrim the date doesn't change when saved and something changes
    b.title = 'Ape uprising! NYC destroyed!'
    b.save()
    assert b.date_created == time
    ##Confirm the date doesn't change when saved and nothing changes
    b.save()
    assert b.date_created == time

def test_date_auto_now():
    class BlagNode(models.NodeModel):
        title = models.Property()
        date_changed = models.DateProperty(auto_now = True)
    ##Confirm the date auto sets on creation
    b = BlagNode(title = 'Snookie House')
    b.save()
    date1 = datetime.date.today()
    assert b.date_changed == date1
    ##Confirm the date auto sets when saved and something changes
    b.title = 'BEEAAAARRSSSS!'
    b.save()
    date2 = datetime.date.today()
    assert b.date_changed == date2
    ##Confirm the date auto sets when saved and nothing changes
    b.save()
    date3 = datetime.date.today()
    assert b.date_changed == date3

def test_date_auto_now_add():
    class BlegNode(models.NodeModel):
        title = models.Property()
        date_made = models.DateProperty(auto_now_add = True)
    ##Confirm the date auto sets on creation
    b = BlegNode(title = "d")
    b.save()
    date1 = datetime.date.today()
    assert b.date_made == date1
    ##Confirm the date doesn't change when another property changes
    b.title = 'Whoreticulture'
    b.save()
    assert b.date_made == date1
    ##Confrim the date doesn't change when no other property changes
    b.save()
    assert b.date_made == date1

def test_datetime_prop():
    # TODO
    pass

def test_datetime_auto_now():
    from time import sleep
    class BlogNode(models.NodeModel):
        title = models.Property()
        date_modified = models.DateTimeProperty(auto_now = True)
    timediff = .6 #can be this far apart
    ##Confirm the date auto sets on creation

def test_datetimetz_constructor():
    class DateTimeTZNode(models.NodeModel):
        datetime = models.DateTimeProperty()

    time = datetime.datetime.now(tzoffset('LOCAL', 3600))
    d = DateTimeTZNode(datetime=time)
    assert d.datetime == time
    d.save()
    eq_(d.datetime, time)
    eq_(d.datetime.astimezone(tz=tzutc()), time.astimezone(tz=tzutc()))

def test_datetimetz_prop():
    class DateTimeTZNode(models.NodeModel):
        datetime = models.DateTimeProperty()

    time = datetime.datetime.now(tzoffset('DST', 3600))
    d = DateTimeTZNode(datetime=time)
    assert d.datetime == time
    d.save()
    # Test roundtrip
    new_d = DateTimeTZNode.objects.get(id=d.id)
    eq_(new_d.datetime, time)

def test_array_property_validator():
    """Tests that ArrayProperty validates properly."""
    class ArrayNode(models.NodeModel):
        vals = models.ArrayProperty()

    n1 = ArrayNode(vals = (1, 2, 3))
    n1.save()
    n2 = ArrayNode(vals = [1, 2, 3])
    n2.save()
    try:
        n3 = ArrayNode(vals = 55555)
        n3.save()
    except ValidationError:
        pass
    else:
        raise AssertionError('ints should not work')

def test_empty_array():
    """Tests that an empty array is saved and retrieved properly."""
    class EmptyArrayNode(models.NodeModel):
        vals = models.ArrayProperty()

    n1 = EmptyArrayNode()
    n1.vals = []
    n1.save()

    eq_(n1.vals, tuple())

def test_int_array_property():
    """Tests that IntArrayProperty validates, saves and returns properly."""
    class IntArrayNode(models.NodeModel):
        vals = models.IntArrayProperty()
    
    n1 = IntArrayNode(vals = (1,2,3))
    eq_(n1.vals, (1,2,3))
    n1.save()
    eq_(n1.vals, (1,2,3))

    try:
        n2 = IntArrayNode(vals = ('1','2','3'))
        n2.save()
    except ValidationError:
        pass
    else:
        raise AssertionError('tuples of strs should not validate')

def test_str_array_property_validator():
    """Tests that StringArrayProperty validates properly."""
    class StrArrayNode(models.NodeModel):
        vals = models.StringArrayProperty()

    try:
        n2 = StrArrayNode(vals = (1,2,3,))
        n2.save()
    except:
        pass
    else:
        raise AssertionError('tuples of ints should not work')

def test_url_array_property_validator():
    """Tests that StringArrayProperty validates properly."""
    class URLArrayNode(models.NodeModel):
        vals = models.URLArrayProperty()

    n1 = URLArrayNode(vals = ('http://google.com',
                              'https://afsgdfvdfgdf.eu/123/asd',
                              'file://onetwothree.org/qwerty/123456'))
    n1.save()
    try:
        n2 = URLArrayNode(vals = (1,2,3,))
        n2.save()
    except:
        pass
    else:
        raise AssertionError('tuples of ints should not work')

def get_raw_property_by_rest(node, property_name):
    import requests, json
    data = json.loads(
        requests.get(node.connection.url + "node/%i/properties" % node.pk))
    return data[property_name]

def test_array_use_strings():
    """
    Tests that array are stored as token separated strings if use_string flag
    is True.
    """

    class MyNode(models.NodeModel):
        arr = models.ArrayProperty(use_string=True)

    node = MyNode(arr=["a","b","c"])
    node.save()

    assert MyNode.arr._property.token.join(node.arr) == \
        get_raw_property_by_rest(node, "arr")

def test_array_use_strings_value_escaping():
    """
    Test intra-value escaping is working.
    """

    class MyNode(models.NodeModel):
        arr = models.ArrayProperty(use_string=True)

    node = MyNode(arr=["a%sb" % MyNode.arr._property.token,"b","c"])
    node.save()
    node2 = MyNode.objects.get(pk=node.pk)

    assert node.arr == node2.arr

def test_prop_metadata():
    class NodeWithMetadata(models.NodeModel):
        name = models.StringProperty(metadata={'test':123})
    meta_fields = filter(lambda f: hasattr(f, 'meta'), NodeWithMetadata._meta.fields)
    eq_(len(meta_fields), 1)
    assert 'test' in meta_fields[0].meta
    eq_(meta_fields[0].meta['test'], 123)

@with_setup(None, teardown)
def test_auto_property():
    class AutoNode(models.NodeModel):
        some_id = models.AutoProperty()
    nodes = [AutoNode.objects.create() for i in xrange(5)]
    eq_([n.some_id for n in nodes], range(1, 6))

    #test with an abstract parent
    class AbstractAutoNode(models.NodeModel):
        class Meta:
            abstract = True
        some_id = models.AutoProperty()

    class ConcreteAutoNode1(AbstractAutoNode):
        pass

    class ConcreteAutoNode2(AbstractAutoNode):
        pass

    nodes = [ConcreteAutoNode1.objects.create() for i in xrange(5)]
    eq_([n.some_id for n in nodes], range(1, 6))

    #make sure the two child classes share an id 'collision domain'
    nodes = [ConcreteAutoNode2.objects.create() for i in xrange(6, 11)]
    eq_([n.some_id for n in nodes], range(6, 11))

########NEW FILE########
__FILENAME__ = relationship_tests
from nose.tools import eq_, with_setup, raises
from django.core.exceptions import FieldError, ObjectDoesNotExist

def setup():
    global Person, neo4django, settings, gdb, models

    from neo4django.tests import Person, neo4django, gdb
    from neo4django.db import models

def teardown():
    gdb.cleandb()

def test_basic_relationship():
    """
    Tests both sides of a simple many-to-many relationship (without relationship
    properties).
    """
    class RelatedPaper(models.NodeModel):
        authors = models.Relationship(Person,
                rel_type = neo4django.Outgoing.OWNED_BY,
                related_name = 'papers'
            )
    
    sandra = Person(name="Sandra")
    sandra.save()
    lifesWork = RelatedPaper()
    lifesWork.save()
    lifesWork.authors.add(sandra)
    
    lifesWork.save()
    work = list(sandra.papers.all())
    assert lifesWork in work, "Paper not found in %s" % repr(work)
    authors = list(lifesWork.authors.all())
    assert sandra in authors, "Author not found in %s" % repr(work)
    #find all shared neo4j relationships
    sandras = sandra.node.relationships.all(['OWNED_BY'])[:]
    eq_(len(sandras), 1)
    #test proper direction
    eq_(sandras[0].end, sandra.node)
    eq_(sandras[0].start, lifesWork.node)

def test_basic_relationship_manager():
    class SomeOtherPaper(models.NodeModel):
        authors = models.Relationship(Person,
                rel_type = neo4django.Outgoing.OTHER_OWNED_BY,
                related_name = 'papers'
            )
    pete = Person.objects.create(name="PETE!")
    boring_paper = SomeOtherPaper()
    boring_paper.authors.add(pete)
    eq_(list(boring_paper.authors.all()), [pete])
    
    boring_paper.authors.remove(pete)
    eq_(list(boring_paper.authors.all()), [])
    
    other_paper = SomeOtherPaper.objects.create()
    other_paper.authors.add(pete)
    other_paper.authors.clear()
    eq_(list(other_paper.authors.all()), [])

    ## Test to make sure we don't end up with duplicates
    ## When we do two saves in a row after clearing
    other_paper.save()
    other_paper.authors.add(pete)
    other_paper.save()
    eq_(len(list(other_paper.authors.all())), 1)

def test_one_to_many():
    class Origin1(models.NodeModel):
        name = models.StringProperty()

    class Reference1(models.NodeModel):
        origin = models.Relationship(Origin1,
                                         rel_type=neo4django.Outgoing.REFERS_TO,
                                         related_name='references',
                                         single=True)

    origin = Origin1(name='CNN')
    origin.save()
    ref = Reference1()
    ref.origin = origin
    ref.save()
    assert ref.origin.name == origin.name, "The single side doesn't work!"
    assert len(list(origin.references.all())) == 1, \
            "Adding to the single side doesn't update the many side."

def test_many_to_one():
    class Origin2(models.NodeModel):
        name = models.StringProperty()

    class Reference2(models.NodeModel):
        origin = models.Relationship(Origin2,
                                         rel_type=neo4django.Outgoing.REFERS_TO,
                                         #TODO explore edge direction here, this is wrong
                                         related_name='references',
                                         single=True)
    origin = Origin2(name='CNN')
    origin.save()
    ref = Reference2()
    ref.save()
    origin.references.add(ref)
    origin.save()
    assert ref.origin and (ref.origin.name == origin.name), \
           "Adding to the many side doesn't update the single side."
    assert len(list(origin.references.all())) == 1, "The many side doesn't work!"

def test_related_one_to_many():
    class AnotherReference(models.NodeModel):
        pass

    class AnotherOrigin(models.NodeModel):
        name = models.StringProperty()
        references = models.Relationship(AnotherReference,
                                         rel_type=neo4django.Outgoing.REFERS_TO,
                                         related_name='origin',
                                         related_single=True)

    origin = AnotherOrigin(name='CNN')
    origin.save()
    ref = AnotherReference()
    ref.origin = origin
    ref.save()
    assert ref.origin.name == origin.name, "The single side doesn't work!"
    assert len(list(origin.references.all())) == 1, \
            "Adding to the single side doesn't update the many side."

def test_related_many_to_one():
    class AnotherReference1(models.NodeModel):
        pass

    class AnotherOrigin1(models.NodeModel):
        name = models.StringProperty()
        references = models.Relationship(AnotherReference1,
                                         rel_type=neo4django.Outgoing.REFERS_TO,
                                         related_name='origin',
                                         related_single=True)
    origin = AnotherOrigin1(name='CNN')
    ref = AnotherReference1()
    ref.save()
    ref2 = AnotherReference1()
    ref2.save()
    origin.references.add(ref)
    origin.references.add(ref2)
    origin.save()
    assert ref.origin and (ref.origin.name == origin.name), \
           "Adding to the many side doesn't update the single side."
    assert len(list(origin.references.all())) == 2, "The many side doesn't work!"

def test_one_to_one():
    class Stalker(models.NodeModel):
        name = models.StringProperty()
        person = models.Relationship(Person,
                                            rel_type=neo4django.Outgoing.POINTS_TO,
                                            single=True,
                                            related_single=True
                                        )
    p = Person.objects.create(name='Stalked')
    s = Stalker(name='Creeper')
    s.person = p
    s.save()

    #test the other side of the relationship
    eq_(p.stalker, s)

    #test that the one-to-one is correct after a retrieval
    new_s = list(Stalker.objects.all())[0]
    eq_(new_s.person, p)

def test_ordering():
    class Actor(models.NodeModel):
        name = models.StringProperty()
        def __str__(self):
            return self.name

    class MovieCredits(models.NodeModel):
        actors = models.Relationship(Actor,
                                         rel_type=neo4django.Incoming.ACTS_IN,
                                         related_name='movies',
                                         preserve_ordering=True,
                                        )

    actors = [Actor(name=n) for n in ['Johnny','Angelina','Jennifer','Tobey']]
    for a in actors: a.save()
    
    superhero_flick = MovieCredits()
    superhero_flick.save()
    for a in actors: superhero_flick.actors.add(a)
    superhero_flick.save()

    node = superhero_flick.node
    del superhero_flick
    same_flick = MovieCredits._neo4j_instance(node)
    assert actors == list(same_flick.actors.all())

    same_flick.actors.remove(actors[1])
    same_flick.save()
    del same_flick

    same_flick = MovieCredits._neo4j_instance(node)
    flick_actors = list(same_flick.actors.all())
    should_be = [actors[0]] + actors[2:]
    assert should_be == flick_actors, "%s should be %s" % (str(flick_actors), str(should_be))

def test_relationship_model():
    """Tests both sides of a many-to-many relationship with attached properties & model."""
    class Authorship(models.Relationship):
        when = models.DateProperty()
    class ComplexRelatedPaper(models.NodeModel):
        pass
    raise NotImplementedError("Write this test!")

def test_multinode_setting():
    """Tests setting a multi-node relationship directly instead of adding."""
    class Classroom(models.NodeModel):
        students = models.Relationship('Student',
                                rel_type=neo4django.Outgoing.COMES_TO,
                                related_name="school"
                                )
    class Student(models.NodeModel):
        name = models.StringProperty()
        def __str__(self):
            return self.name

    students = [Student(name=name) for name in ['Violet', 'Grigori', 'Kaden', 'Gluz']]
    classroom = Classroom()
    classroom.students = students[:2]
    assert len(list(classroom.students.all())) == 2
    classroom.students.add(students[2])
    assert len(list(classroom.students.all())) == 3
    classroom.students = students[3:]
    classroom.save()
    assert len(list(classroom.students.all())) == 1

def test_rel_metadata():
    class NodeWithRelMetadata(models.NodeModel):
        contacts = models.Relationship(Person,
                                           rel_type=neo4django.Outgoing.KNOWS_1,
                                           metadata={'test':123})
    meta_fields = filter(lambda f: hasattr(f, 'meta'), NodeWithRelMetadata._meta.fields)
    eq_(len(meta_fields), 1)
    assert 'test' in meta_fields[0].meta
    eq_(meta_fields[0].meta['test'], 123)

def test_rel_self():
    class MetaNode(models.NodeModel):
        myself = models.Relationship('self', 'IS', single=True, related_name = 'myselves')

    meta = MetaNode()
    meta.myself = meta
    meta.save()

    eq_(meta.myself, meta)
    assert meta in meta.myselves.all()

def test_rel_string_target():
    class Child(models.NodeModel):
        parents = models.Relationship('neo4django.Person',
                                      neo4django.Outgoing.CHILD_OF)

    assert 'child_set' in (f.name for f in Person._meta.fields)

    child = Child()
    child.parents.add(Person.objects.create(name='Han'))
    child.parents.add(Person.objects.create(name='Leia'))
    child.save()

    eq_(('Han','Leia'), tuple(sorted(p.name for p in child.parents.all())))

def test_rel_string_type():
    class Child1(models.NodeModel):
        parents = models.Relationship(Person, 'CHILD1_OF')

    child = Child1()
    child.parents.add(Person.objects.create(name='Han'))
    child.parents.add(Person.objects.create(name='Leia'))
    child.save()

    eq_(('Han','Leia'), tuple(sorted(p.name for p in child.parents.all())))

    childs = child.node.relationships.all(['CHILD1_OF'])[:]
    eq_(len(childs), 2)
    #test proper direction
    for r in childs:
        eq_(r.start, child.node)

@with_setup(None, teardown)
def test_relationship_none():
    class Poll(models.NodeModel):
        question = models.StringProperty()

    class Choice(models.NodeModel):
        poll = models.Relationship(Poll,
                                    rel_type=neo4django.Incoming.OWNS,
                                    single=True,
                                    related_name='choices')
        choice = models.StringProperty()
    
    pbest = Poll(question="Who's the best?")
    c = Choice(poll=pbest, choice='Chris')
    eq_(len(pbest.choices.none()), 0)

    pbest.save()
    c.save()

    p = list(Poll.objects.all())[0]
    eq_(len(p.choices.none()), 0)

@with_setup(None, teardown)
def test_relationship_count():
    class CountingPoll(models.NodeModel):
        question = models.StringProperty()

    class CountingChoice(models.NodeModel):
        poll = models.Relationship(CountingPoll,
                                    rel_type=neo4django.Incoming.OWNS,
                                    single=True,
                                    related_name='choices')
        choice = models.StringProperty()


    pbest = CountingPoll(question="Who's the best?")
    eq_(pbest.choices.count(), 0)

    c1 = CountingChoice(poll=pbest, choice='Chris')
    c2 = CountingChoice(poll=pbest, choice='Matt')
    pbest.save()
    c1.save()
    c2.save()
    eq_(pbest.choices.count(), 2)

@with_setup(None, teardown)
def test_relationship_filter():
    class PollF(models.NodeModel):
        question = models.StringProperty()

    class ChoiceF(models.NodeModel):
        poll = models.Relationship(PollF,
                                    rel_type=neo4django.Incoming.OWNS,
                                    single=True,
                                    related_name='choices')
        choice = models.StringProperty()
        votes = models.IntegerProperty()

    p = PollF(question="Who's the best?")
    names = ['Matt', 'Corbin', 'Bob', 'Billy', 'Chris', 'Gus Chiggens']
    choices = [ChoiceF(poll=p, choice=name, votes=n) for n, name in enumerate(names)]
    for c in choices:
        c.save()
    p.save()

    p = list(PollF.objects.all())[0]
    choices = p.choices.all()
    eq_(len(PollF.objects.all()), 1)
    eq_(len(choices), 6)

    eq_(choices.filter(votes__lt=3).__class__.__name__, 'RelationshipQuerySet')
    eq_(set(choices.filter(votes__lt=3)), set([c for c in choices if c.votes < 3]))
    eq_(set(['Matt', 'Corbin']), set(c.choice for c in choices.filter(votes__lt=2)))

    eq_(len(choices.filter(choice='Gus Chiggens')), 1)
    eq_(len(choices.filter(choice__contains='C')), 3)
    eq_(len(choices.filter(choice__contains='c')), 0)
    eq_(len(choices.filter(votes__gte=3)), 3)
    eq_(len(choices.filter(votes__gte=3, choice='Matt')), 0)
    eq_(len(choices.filter(votes__gte=3).filter(choice='Matt')), 0)
    eq_(len(p.choices.filter(votes__gte=3).filter(choice='Matt')), 0)

@with_setup(None, teardown)
def test_relationship_filter_many_to_many():
    """
    Confirm filter works in a many to many relationship with string search.
    """
    class MyGuy(models.NodeModel):
        name = models.StringProperty(indexed=True)
        friends = models.Relationship('MyGuy',
                                      rel_type='FRIEND',
                                      related_name='friendsFrom')
        
    tom = MyGuy.objects.create(name='tom')
    bill = MyGuy.objects.create(name='bill')
    bruce = MyGuy.objects.create(name='bruce')
    robert = MyGuy.objects.create(name='robert')

    tom.friends.add(bruce)
    tom.friends.add(bill)
    tom.friends.add(robert)
    tom.save()
    eq_(len(tom.friends.all()), 3)
    # Not a typo, wanted to check filter with no args
    eq_(len(tom.friends.filter()), 3) 
    eq_(len(tom.friends.filter(name="bruce")), 1)
    eq_(len(tom.friends.filter(name__startswith="b")), 2) # bill & bruce
    eq_(len(tom.friends.filter(name__istartswith="B")), 2)
    eq_(len(tom.friends.filter(name__contains="b")), 3) # bill, bruce and robert
    eq_(len(tom.friends.filter(name__icontains="B")), 3)
    
@with_setup(None, teardown)
@raises(ObjectDoesNotExist)
def test_relationship_get_by_id():
    """
    Confirm `get(id=<related_id>)` returns the proper related object, and that
    `get(id=<unrelated_id>)` raises an ObjectDoesNotExist exception.

    Attempting (unsucessfully) to replicate #202.
    """
    class PollG(models.NodeModel):
        question = models.StringProperty()

    class ChoiceG(models.NodeModel):
        poll = models.Relationship(PollG,
                                    rel_type=neo4django.Incoming.OWNS,
                                    single=True,
                                    related_name='choices')
        choice = models.StringProperty()
        votes = models.IntegerProperty()

    p = PollG(question="Who's the best?")
    names = ['Matt', 'Corbin', 'Bob', 'Billy', 'Chris', 'Gus Chiggens']
    choices = [ChoiceG(poll=p, choice=name, votes=n) for n, name in enumerate(names)]
    for c in choices:
        c.save()
    p.save()

    eq_(p.choices.get(id=choices[1].id), choices[1])

    another_choice = ChoiceG.objects.create(choice='Unrelated Choice')
    p.choices.get(id=another_choice.id)

@with_setup(None, teardown)
def test_relationship_create():
    class PollCreate(models.NodeModel):
        question = models.StringProperty()

    class ChoiceCreate(models.NodeModel):
        poll = models.Relationship(PollCreate,
                                    rel_type=neo4django.Incoming.OWNS,
                                    single=True,
                                    related_name='choices')
        choice = models.StringProperty()
        votes = models.IntegerProperty()

    p = PollCreate(question="Who's the best?")
    eq_(len(p.choices.all()), 0)
    p.choices.create(choice='Superman', votes=2)
    p.choices.create(choice='Batman', votes=20)
    eq_(len(p.choices.all()), 2)
    eq_(len(ChoiceCreate.objects.all()), 2)

@with_setup(None, teardown)
def test_relationship_delete():
    class PollDelete(models.NodeModel):
        question = models.StringProperty()

    class ChoiceDelete(models.NodeModel):
        poll = models.Relationship(PollDelete,
                                    rel_type=neo4django.Incoming.OWNS,
                                    single=True,
                                    related_name='choices')
        choice = models.StringProperty()
        votes = models.IntegerProperty()

    p = PollDelete(question="Who's the best?")
    names = ['Matt', 'Corbin', 'Bob', 'Billy', 'Chris', 'Gus Chiggens']
    choices = [ChoiceDelete(poll=p, choice=name, votes=n) for n, name in enumerate(names)]
    for c in choices:
        c.save()
    p.save()
    eq_(len(p.choices.all()), 6)

    qs = p.choices.filter(votes=5) # only Gus
    qs.delete()

    p = list(PollDelete.objects.all())[0]  # have to re-select poll after each delete
    eq_(len(ChoiceDelete.objects.all()), 5)
    eq_(len(p.choices.all()), 5)

    qs = p.choices.filter(votes__gte=1) # all but Matt
    qs.delete()
    
    p = list(PollDelete.objects.all())[0]
    eq_(len(ChoiceDelete.objects.all()), 1)
    eq_(len(p.choices.all()), 1)

    qs = p.choices.filter(votes__gte=0) #all the rest
    qs.delete()

    eq_(len(p.choices.all()), 0)

    p = list(PollDelete.objects.all())[0] #re-pull it from the database
    eq_(len(p.choices.all()), 0)
    eq_(len(ChoiceDelete.objects.all()), 0)

@with_setup(None, teardown)
def test_relationship_distinct():
    class Job(models.NodeModel):
        pass

    class EmployedPerson(models.NodeModel):
        jobs = models.Relationship(Job, rel_type='emplyed_by')

    pete = EmployedPerson.objects.create()
    job = Job.objects.create()

    pete.jobs.add(job, job)
    pete.save()

    eq_(len(pete.jobs.all()), 2)
    eq_(len(pete.jobs.all().distinct()), 1)

@with_setup(None, teardown)
def test_abstract_rel_inheritance():
    """
    Test that inheriting abstract relationships doesn't throw an error. Stems
    from GitHub issue #37.
    """
    class ZenNode(models.NodeModel):
        class Meta:
            abstract = True
        rel = models.Relationship('self',rel_type='knows')

    class Pupil(ZenNode):
        pass

    p = Pupil.objects.create()
    p.rel.add(p)
    p.save()

@with_setup(None, teardown)
def test_rel_query_direction():
    """
    Confirm GitHub issue #42, querying doesn't respect rel direction.
    """
    class LetterL(models.NodeModel):
        name = models.StringProperty()

    class LetterM(models.NodeModel):
        name = models.StringProperty()
        follows = models.Relationship(LetterL, rel_type='follows')

    class LetterN(models.NodeModel):
        name = models.StringProperty()
        follows = models.Relationship(LetterM, rel_type='follows')

    el = LetterL.objects.create(name='LLL')

    m = LetterM.objects.create(name='MMM')
    m.follows.add(el)
    m.save()

    n = LetterN.objects.create(name='NNN')
    n.follows.add(m)
    n.save()

    eq_(len(list(m.follows.all())), 1)
    eq_(len(list(m.lettern_set.all())), 1)

@with_setup(None, teardown)
def test_rel_slicing():
    class Topic(models.NodeModel):
        value = models.StringProperty()

    class TOC(models.NodeModel):
        contains = models.Relationship(Topic, rel_type='follows', preserve_ordering=True)

    toc = TOC()
    for i in xrange(5):
        toc.contains.add(Topic(value=str(i)))
    toc.save()

    for i in xrange(5):
        eq_(toc.contains.all()[i].value, str(i))

    eq_([n.value for n in toc.contains.all()[0:2]], ['0','1'])

@with_setup(None, teardown)
def test_rel_cache():
    """
    Test confirming issue #67 (rel queryset cache problems) as reported by
    @baconz.
    """
    class Knight(models.NodeModel):
        number_of_limbs = models.IntegerProperty(indexed=True)

    class Spam(models.NodeModel):
        VERY_DELICIOUS, NOT_DELICIOUS = 'v', 'n'
        DELICIOUSNESS_CHOICES = (
            ('n', 'not'),
            ('v', 'very'),
        )

        deliciousness = models.StringProperty(max_length=1,
                                          choices=DELICIOUSNESS_CHOICES)
        on_top_of = models.Relationship('Knight', related_name="spams", rel_type=neo4django.Outgoing.GOES_WITH)

    k = Knight.objects.create(number_of_limbs=1)
    s = Spam.objects.create(deliciousness=Spam.VERY_DELICIOUS)
    s.on_top_of.add(k)
    s.save()
    len(list(s.on_top_of.all()))
    k.delete()
    eq_(len(list(s.on_top_of.all())), 0)

def test_conflicting_rel_types():
    """
    Tests that multiple `Relationship`s cannot be declared of the same type.

    Confirms #41.
    """
    import warnings
    with warnings.catch_warnings(record=True) as w:
        warnings.simplefilter("always")

        class ConflictedModel(models.NodeModel):
            first_rel = models.Relationship('self', rel_type=neo4django.Outgoing.CONFLICTS_WITH)
            second_rel = models.Relationship('self', rel_type=neo4django.Outgoing.CONFLICTS_WITH)

        assert len(w) > 0

########NEW FILE########
__FILENAME__ = signal_tests
"""
Tests for built-in signals (e.g. 'post_delete', 'pre_save'), some of which
are sent by methods that neo4django overrides.

"""
from nose.tools import with_setup

from django.db.models import signals

def setup():
    global Person, gdb

    from neo4django.tests import Person, gdb

def teardown():
    gdb.cleandb()

def test_pre_init():
    pete = None
    result = {'sent': False}

    def handler(*args, **kwargs):
        result['sent'] = True
        if pete:
            assert False, "'pre_init' signal sent at the wrong time"

    signals.pre_init.connect(handler, sender=Person)

    pete = Person(name='Pete')

    if not result['sent']:
        assert False, "'pre_init' signal was not sent to handler"

    signals.pre_init.disconnect(handler, sender=Person)

def test_post_init():
    pete = None
    result = {'sent': False}

    def handler(instance=None, *args, **kwargs):
        result['sent'] = True
        if not (instance and isinstance(instance, Person)
                and instance.name == 'Pete'):
            assert False, "'post_init' signal sent at the wrong time"

    signals.post_init.connect(handler, sender=Person)

    pete = Person(name='Pete')

    if not result['sent']:
        assert False, "'post_init' signal was not sent to handler"

    signals.post_init.disconnect(handler, sender=Person)

@with_setup(None, teardown)
def test_pre_save():
    result = {'sent': False}

    def handler(instance=None, *args, **kwargs):
        result['sent'] = True
        # should be initialized but not yet committed to db
        if not (instance.name == 'Pete' and not instance.pk):
            assert False, "'pre_save' signal sent at the wrong time"

    signals.pre_save.connect(handler, sender=Person)

    pete = Person.objects.create(name='Pete')

    if not result['sent']:
        assert False, "'pre_save' signal was not sent to handler"

    signals.pre_save.disconnect(handler, sender=Person)

@with_setup(None, teardown)
def test_post_save():
    result = {'sent': False}

    def handler(instance=None, *args, **kwargs):
        result['sent'] = True
        try:
            # should have already been committed to db by now
            if not (instance.pk and Person.objects.get(pk=instance.pk)):
                assert False, "'post_save' signal sent at the wrong time"
        except Person.DoesNotExist:
            pass

    signals.post_save.connect(handler, sender=Person)

    pete = Person.objects.create(name='Pete')

    if not result['sent']:
        assert False, "'post_save' signal was not sent to handler"

    signals.post_save.disconnect(handler, sender=Person)

@with_setup(None, teardown)
def test_pre_delete():
    result = {'sent': False}

    def handler(instance=None, *args, **kwargs):
        result['sent'] = True
        try:
            # should still be in db
            if not (instance.pk and Person.objects.get(pk=instance.pk)):
                assert False, "'pre_delete' signal sent at the wrong time"
        except Person.DoesNotExist:
            pass

    signals.pre_delete.connect(handler, sender=Person)

    pete = Person.objects.create(name='Pete')
    pete.delete()

    if not result['sent']:
        assert False, "'pre_delete' signal was not sent to handler"

    signals.pre_delete.disconnect(handler, sender=Person)

@with_setup(None, teardown)
def test_post_delete():
    result = {'sent': False}

    def handler(instance=None, *args, **kwargs):
        result['sent'] = True
        try:
            Person.objects.get(pk=instance.pk)
            # we got here so person still exists
            assert False, "'post_delete' signal sent at the wrong time"
        except Person.DoesNotExist:
            # this is correct; should not be in db
            pass

    signals.post_delete.connect(handler, sender=Person)

    pete = Person.objects.create(name='Pete')
    pete.delete()

    if not result['sent']:
        assert False, "'post_delete' signal was not sent to handler"

    signals.post_delete.disconnect(handler, sender=Person)


########NEW FILE########
__FILENAME__ = synchronicity_tests
from nose.tools import eq_, with_setup

from threading import Thread
from Queue import Queue
from time import sleep

def setup():
    global Person, neo4django, gdb, neo4jrestclient, neo_constants, settings, models

    from neo4django.tests import Person, neo4django, gdb, neo4jrestclient, \
            neo_constants, settings
    from neo4django.db import models

def teardown():
    gdb.cleandb()

@with_setup(None, teardown)
def test_typenode_transactionality():
    class RaceModel(models.NodeModel):
        pass

    exc_queue = Queue()

    def race():
        r = RaceModel()
        try:
            r.save()
        except Exception, e:
            exc_queue.put(str(e))
        else:
            exc_queue.put(True)

    num_threads = 5
    for i in xrange(num_threads):
        thread = Thread(target=race)
        thread.start()

    for i in xrange(num_threads):
        val = exc_queue.get()
        if val is not True:
            raise AssertionError('There was an error saving one of the '
                                     'RaceModels (#%d) - "%s"' % (i, val))
    #check the number of typenodes
    typenode_script = "g.v(0).outE('<<TYPE>>').inV.filter{it.model_name=='%s'}"
    typenode_script %= RaceModel.__name__
    typenodes = gdb.extensions.GremlinPlugin.execute_script(typenode_script)
    eq_(len(typenodes), 1)

def race(func, num_threads):
    """
    Run a multi-threaded race on func. Func should accept a single argument-
    a Queue. If func succeeds, it should `q.put(True)`- if it fails, it should
    `q.put('error message')`.
    """

    exc_queue = Queue()

    for i in xrange(num_threads):
        thread = Thread(target=func, args=(exc_queue,))
        thread.start()

    for i in xrange(num_threads):
        val = exc_queue.get()
        if val is not True:
            raise AssertionError('There was an error running race (#%d) - "%s"'
                                 % (i, val))

@with_setup(None, teardown)
def test_autoproperty_transactionality():
    class AutoRaceModel(models.NodeModel):
        some_id = models.AutoProperty()

    def autorace(queue):
        r = AutoRaceModel()
        try:
            r.save()
        except Exception, e:
            queue.put(str(e))
        else:
            queue.put(True)
    
    race(autorace, 3)
    eq_(len(set(m.some_id for m in AutoRaceModel.objects.all())), 3)

########NEW FILE########
__FILENAME__ = test_settings
import os
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

AUTHENTICATION_BACKENDS = ('neo4django.graph_auth.backends.NodeModelBackend',)

AUTH_USER_MODEL = 'graph_auth.User'

NEO4J_DATABASES = {
    'default' : {
        'HOST':'localhost',
        'PORT':7474,
        'ENDPOINT':'/db/data',
        'OPTIONS':{
            'CLEANDB_URI': '/cleandb/supersecretdebugkey!',
        },
    },
    'custom': {
        'HOST':'localhost',
        'PORT':7474,
        'ENDPOINT':'/db/data',
        'CLIENT': 'neo4django.tests.neo4jclient_tests.MyGraphDatabase',
        'OPTIONS':{
            'CLEANDB_URI': '/cleandb/supersecretdebugkey!',
        },
    },
}

NEO4J_TEST_DATABASES = {
    'default' : {
        'HOST':'localhost',
        'PORT':7474,
        'ENDPOINT':'/db/data',
        'OPTIONS':{
            'CLEANDB_URI': '/cleandb/supersecretdebugkey!',
        }
    }
}

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': os.path.join(BASE_DIR, 'db', 'test_database.sqlite3')
    }
}

DATABASE_ROUTERS = ['neo4django.utils.Neo4djangoIntegrationRouter']

USE_TZ = True

INSTALLED_APPS = (
    'neo4django.tests',
    'neo4django.graph_auth', 
)

SECRET_KEY="shutupdjangowe'retryingtotesthere"

DEBUG = True

NEO4DJANGO_PROFILE_REQUESTS = False
NEO4DJANGO_DEBUG_GREMLIN = False

########NEW FILE########
__FILENAME__ = test_utils
from mock import Mock, patch
from nose.tools import with_setup, raises
from pretend import stub

from django.core.exceptions import ImproperlyConfigured
from django.db.models import Model as DjangoModel

from neo4django import utils
from neo4django.neo4jclient import EnhancedGraphDatabase
from neo4django.db.models import NodeModel


# Nose does a weird copying from unittest asserts, meaning
# assertListEqual didn't move from unittest2 to unittest until
# Python 2.7. The yuck below is for 2.6 compatibility
try:
    from nose.tools import assert_list_equal
except ImportError:
    from itertools import starmap, izip
    from operator import eq as equals

    def assert_list_equal(a, b):
        """
        A simple (but hack) for compatibility with `nose.tools` on python
        2.6. This just asserts that both lists have the same length and that
        the values at the same indexes are equal
        """
        assert len(a) == len(b)
        assert all(starmap(equals, izip(a, b)))


def test_subborn_dict_restricts_keys():
    stubborn = utils.StubbornDict(('foo',), {'bar': 'baz'})

    # Setting a stubborn key will not do anything
    stubborn['foo'] = 'qux'
    assert 'foo' not in stubborn


def test_subborn_dict_allows_keys():
    stubborn = utils.StubbornDict(('foo',), {'bar': 'baz'})

    # We should be able to set a non-stubborn key
    stubborn['qux'] = 'foo'
    assert 'qux' in stubborn


def test_uniqify():
    values = [1, 1, 'foo', 2, 'foo', 'bar', 'baz']
    expected = [1, 'foo', 2, 'bar', 'baz']

    unique_values = utils.uniqify(values)

    assert_list_equal(expected, unique_values)


def test_all_your_base():
    # Establish base classes
    class A(object):
        pass

    class B(A):
        pass

    class C(B):
        pass

    class D(object):
        pass

    class E(C, D):
        pass

    c_bases = [cls for cls in utils.all_your_base(C, A)]
    e_bases = [cls for cls in utils.all_your_base(E, B)]

    assert_list_equal(c_bases, [C, B, A])
    assert_list_equal(e_bases, [E, C, B])


def test_write_through():
    obj = Mock()
    obj._meta.write_through = 'foo'

    assert utils.write_through(obj) == 'foo'


def test_write_through_default():
    obj = object()

    assert utils.write_through(obj) is False


def setup_attrrouter():
    global router, member
    router = utils.AttrRouter()
    member = stub(foo='bar')
    router.member = member


@with_setup(setup_attrrouter, None)
def test_attrrouter_router_default():
    router = utils.AttrRouter()
    assert router._router == {}


@with_setup(setup_attrrouter, None)
def test_attrrouter_with_routed_attrs():
    router.__dict__[router._key] = 'foo'
    assert router._router == 'foo'


@with_setup(setup_attrrouter, None)
def test_attrrouter_gets_obj_attr():
    router.foo = 'bar'
    assert getattr(router, 'foo') == 'bar'


@with_setup(setup_attrrouter, None)
def test_attrrouter_gets_routed():
    # Manually map the routing to ensure we test only what we intend to
    router._router['get'] = {'foo': member}
    assert router.foo == 'bar'


@with_setup(setup_attrrouter, None)
def test_attrrouter_sets_obj_attr():
    router.foo = 'bar'
    assert router.foo == 'bar'


@with_setup(setup_attrrouter, None)
def test_attrrouter_sets_routed():
    # Manually map the routing to ensure we test only what we intend to
    router._router['set'] = {'foo': member}
    router._router['get'] = {'foo': member}

    # Change the value
    router.foo = 'baz'

    # It should update both places
    assert router.foo == 'baz'
    assert member.foo == 'baz'


@with_setup(setup_attrrouter, None)
def test_attrrouter_dels_obj_attr():
    router.foo = 'bar'

    del router.foo

    assert not hasattr(router, 'foo')


@with_setup(setup_attrrouter, None)
def test_attrrouter_dels_routed():
    # Manually map the routing to ensure we test only what we intend to
    router._router['del'] = {'foo': member}
    router._router['get'] = {'foo': member}

    del router.foo

    # It should delete both places
    assert not hasattr(router, 'foo')
    assert not hasattr(member, 'foo')


@with_setup(setup_attrrouter, None)
def test_attrrouter_route_get():
    router._route(('foo',), member, get=True)
    assert router.foo == 'bar'


@with_setup(setup_attrrouter, None)
def test_attrrouter_route_set():
    router._route(('foo',), member, set=True)
    router.foo = 'baz'

    assert router.foo == 'baz'
    assert member.foo == 'baz'


@with_setup(setup_attrrouter, None)
def test_attrrouter_route_delete():
    router._route(('foo',), member, delete=True)
    del router.foo

    # It should delete both places
    assert not hasattr(router, 'foo')
    assert not hasattr(member, 'foo')


@raises(AttributeError)
@with_setup(setup_attrrouter, None)
def test_attrrouter_unroute_get():
    router._route(('foo',), member, get=True)
    router._unroute(('foo',), get=True)
    router.foo


@with_setup(setup_attrrouter, None)
def test_attrrouter_unroute_set():
    # Check routed
    router._route(('foo',), member, set=True)
    router._unroute(('foo',), set=True)
    router.foo = 'baz'

    # Should be different
    assert router.foo == 'baz'
    assert member.foo == 'bar'


@raises(AttributeError)
@with_setup(setup_attrrouter, None)
def test_attrrouter_unroute_delete():
    # Check routed
    router._route(('foo',), member, delete=True)
    router._unroute(('foo',), delete=True)
    del router.foo


class MyDjangoModel(DjangoModel):
    """
    A simple/empty subclass of django.db.models.Model for testing
    """


def test_integration_router_is_node_model():
    router = utils.Neo4djangoIntegrationRouter()
    model = NodeModel()

    assert router._is_node_model(NodeModel)
    assert router._is_node_model(model)


def test_integration_router_allow_relation_mismatch():
    router = utils.Neo4djangoIntegrationRouter()
    node_model = NodeModel()
    django_model = MyDjangoModel()

    assert router.allow_relation(node_model, django_model) is False


def test_integration_router_allow_relation_between_node_models():
    router = utils.Neo4djangoIntegrationRouter()
    node_model1 = NodeModel()
    node_model2 = NodeModel()

    assert router.allow_relation(node_model1, node_model2) is None


def test_integration_router_allow_relation_between_django_models():
    router = utils.Neo4djangoIntegrationRouter()
    django_model1 = MyDjangoModel()
    django_model2 = MyDjangoModel()

    assert router.allow_relation(django_model1, django_model2) is None


@raises(ImproperlyConfigured)
@patch('neo4django.utils.import_module')
def test_load_client_fail_module_import(import_module):
    import_module.side_effect = ImportError

    try:
        utils.load_client('foo.bar.baz')
    except ImproperlyConfigured as e:
        assert 'Could not import' in e.message
        raise e


@raises(ImproperlyConfigured)
@patch('neo4django.utils.import_module')
def test_load_client_module_class_missing(import_module):
    import_module.return_value = stub(foo='bar')

    try:
        utils.load_client('foo.bar.baz')
    except ImproperlyConfigured as e:
        assert 'Neo4j client module' in e.message
        raise e


@raises(ImproperlyConfigured)
@patch('neo4django.utils.import_module')
def test_load_client_not_correct_subclass(import_module):
    MyClass = type('MyClass', (object,), {})
    import_module.return_value = stub(baz=MyClass)

    try:
        utils.load_client('foo.bar.baz')
    except ImproperlyConfigured as e:
        assert 'is not a subclass of EnhancedGraphDatabase' in e.message
        raise e


@patch('neo4django.utils.import_module')
def test_load_client(import_module):
    MyClass = type('MyClass', (EnhancedGraphDatabase,), {})
    import_module.return_value = stub(baz=MyClass)

    assert utils.load_client('foo.bar.baz') == MyClass


def test_sliding_pair():
    ret = utils.sliding_pair(('foo', 'bar', 'baz'))
    expected = [('foo', 'bar'),
                ('bar', 'baz'),
                ('baz', None)]

    assert_list_equal(expected, list(ret))


def test_assignable_list():
    list_obj = utils.AssignableList()
    list_obj.foo = 'bar'

    # Check that we can get the attribute
    assert list_obj.foo == 'bar'

    # We should have added object to _new_attrs
    assert 'foo' in list_obj.get_new_attrs()

    # hasattr() should return True
    assert hasattr(list_obj, 'foo')


def test_enum_numerical_items():
    e = utils.Enum('foo', 'bar', 'baz')
    assert e.FOO == 0
    assert e.BAR == 1
    assert e.BAZ == 2


def test_enum_explict_items():
    e = utils.Enum(foo='bar', baz='qux')
    assert e.FOO == 'bar'
    assert e.BAZ == 'qux'


def test_countdown():
    fn = utils.countdown(5)

    # Should return True 5 times, then false
    assert all([fn() for x in xrange(5)])
    assert not any([fn() for x in xrange(100)])  # Excessive, but proves it


def test_apply_to_buffer():
    fn = Mock(return_value='a')
    ret = utils.apply_to_buffer(fn, xrange(100), size=5)

    assert fn.call_count == 5
    assert_list_equal(ret, ['a', 'a', 'a', 'a', 'a'])


@raises(StopIteration)
def test_apply_to_buffer_raises_stop_iteration():
    fn = Mock(return_value='a')
    utils.apply_to_buffer(fn, xrange(100), size=0)


def test_buffer_iterator():
    expected = [0, 1, 4, 9, 16]
    ret = [x for x in utils.buffer_iterator(lambda x: x**2, xrange(5), size=2)]
    assert_list_equal(ret, expected)

########NEW FILE########
__FILENAME__ = utils
import itertools

from abc import ABCMeta
from collections import defaultdict
from threading import local

from django.core.exceptions import ImproperlyConfigured
from django.utils.importlib import import_module

from neo4django.decorators import transactional
from neo4django.neo4jclient import EnhancedGraphDatabase


class StubbornDict(dict):
    """
    A subclass of dict that enforces a strict set of keys. If an attempt
    is made to set an item with a key that belongs to a set of blacklisted
    or "stubborn" keys, no action is taken
    """

    def __init__(self, stubborn_keys, d):
        self._stubborn_keys = stubborn_keys
        super(StubbornDict, self).__init__(d)

    def __setitem__(self, key, value):
        if key in self._stubborn_keys:
            return
        return super(StubbornDict, self).__setitem__(key, value)

def copy_func(func):
    """
    Return a copy of a function with a shallow copy of the original's
    func_globals.
    """
    import types
    return types.FunctionType(func.func_code, dict(func.func_globals),
                              name=func.func_name, argdefs=func.func_defaults,
                              closure=func.func_closure)

def sliding_pair(seq):
    """
    Return a sliding window of size 2 over the given sequence. The last pair
    will include None, so that special action can be taken at the end of the
    sequence.
    """
    s1, s2 = itertools.tee(seq)
    s2.next()  # This ensures we get a None sentinel for the end of the iterator
    return itertools.izip_longest(s1, s2)


def uniqify(seq):
    """
    Returns a list of only unique items in `seq` iterable. This has the effect
    of preserving the original order of `seq` while removing ignoring duplicates.
    """
    seen = set()
    return [x for x in seq if x not in seen and not seen.add(x)]


def not_none(it):
    return itertools.ifilter(None, it)


def Enum(*enums, **other_enums):
    """
    Creates an enum-like type that sets attributes with corresponding 0-indexed integer
    values coming from positional arguments that are converted to uppercase. For example::

        >>> e = Enum('foo', 'bar')
        >>> e.FOO
        0
        >>> e.BAR
        1

    If keyword arguments are passed, the effect is the same, however the keyword value
    will represent the value of the enum attribute, rather than a 0-indexed integer.
    For example::

        >>> e = Enum(foo='bar', baz='qux')
        >>> e.FOO
        'bar'
        >>> e.BAZ
        'qux'
    """
    # Handle args that should be numeric. Swap enumerate idx and value for dict comprehension later
    numerical_items = itertools.starmap(lambda i, v: (str(v).upper(), i), enumerate(enums))

    # Handle keyword arguments
    keyword_items = itertools.starmap(lambda k, v: (str(k).upper(), v), other_enums.iteritems())

    # Chain all items
    all_items = itertools.chain(numerical_items, keyword_items)

    return type('Enum', (), dict(x for x in all_items))


def all_your_base(cls, base):
    """
    Generator for returning all the common base classes of `cls` that are subclasses
    of `base`. This will yield common bases of `cls` as well as any common bases
    of all of the ancestors of `cls`. For example, given the classes::

        >>> class A(object): pass
        >>> class B(A): pass
        >>> class C(B): pass
        >>> class D(object): pass
        >>> class E(C, D): pass

    Would yield::

        >>> [cls for cls in all_your_base(C, A)]
        [C, B, A]

        >>> [cls for cls in all_your_base(E, B)]
        [E, C, B]
    """
    if issubclass(cls, base):
        yield cls
        for parent in cls.__bases__:
            for cls in all_your_base(parent, base):
                yield cls


def write_through(obj):
    """
    Returns the value of `obj._meta.write_through`. Defaults to False
    """
    return getattr(getattr(obj, '_meta', None), 'write_through', False)


def buffer_iterator(constructor, items, size=1):
    """
    Generator that yields the result of calling `constructor` with each
    value of `items` as an argument. However, this is done in chunks
    of at most `size` items
    For example::

        >>> list(buffer_iterator(lambda x: x**2, range(5), size=2))
        [0, 1, 4, 9, 16]]
    """
    iteritems = iter(items)

    while True:
        for item in apply_to_buffer(constructor, iteritems, size):
            yield item


@transactional
def apply_to_buffer(constructor, items, size=1):
    """
    Calls `constructor` with at the first `size` values from an
    iterator `items`. Returns a list of return values from these
    calls, raising StopIteration if no calls were made.
    """
    result = [constructor(x) for x in itertools.islice(items, size)]

    if not result:
        raise StopIteration

    return result


def countdown(number):
    """
    A method that returns a new method that will return True `number` amount
    of times and return False from then on.
    """
    counter = itertools.count()

    def done(*junk):
        for count in counter:
            return count < number
    return done


class AssignableList(list):
    """
    A special subclass of list the allow setting of arbitrary object
    attributes. The python builtin list prevents this behavior by raising
    an AttributeError::

        >>> x = []
        >>> x.foo = 'bar'
        Traceback (most recent call last):
        ...
        AttributeError: 'list' object has not attribute 'foo'

    Alternatively::

        >>> x = AssignableList()
        >>> x.foo = 'bar'
        >>> x.foo
        'bar'
    """

    def __init__(self, *args, **kwargs):
        super(AssignableList, self).__init__(*args, **kwargs)
        self._new_attrs = {}

    def __setattr__(self, name, value):
        if name != '_new_attrs':
            self._new_attrs[name] = value
        super(AssignableList, self).__setattr__(name, value)

    def get_new_attrs(self):
        """
        Returns a copy of all attributes that have been assigned to this object
        """
        return self._new_attrs.copy()


class AttrRouter(object):
    """
    Black magic ;). This abstract class exists to prevent one of my least
    favorite code repetition scenarios, namely

    class CoolOwner(object):
        def __init__(self):
            self.member = ImportantMember()

        def a(self):
            return self.member.a()

        def b(self, *args, **kwargs):
            return self.member.b(*args, **kwargs)

        @property
        def c(self):
            return self.member.c()
        ...

    Ad infinitum. Instead, try this

    class CoolOwner(SomeParent, AttrRouter):
        def __init__(self):
            self.member = ImportantMember()
            self._route_all(['a','b'], self.member)
            self._route(['c'],self.member)

    And we're done. All attribute calls for 'a' and 'b'  will be routed to
    self.member- gets, sets, and deletes. Only gets for 'c' will be routed to
    self.member.

    "But what if you want to add a bit of functionality?" you might whine. It's
    alright, I did too.

    class CoolOwner(SomeParent, AttrRouter):
        def __init__(self):
            self.member = ImportantMember()
            self._route_all(['a','b'], self.member)
            self._route(['c'],self.member)

        def b(self, *args, **kwargs):
            if 'DEBUG' in kwargs:
                print 'DEBUG STATEMENT!'
                del kwargs['DEBUG']
            super(CoolOwner, self).b(*args, **kwargs)

    And you're set.

    This approach won't work for special methods, like __len__- I haven't tested
    which cause problems. If there's another attribute with the same name in the
    inheritance heirarchy as a routed attribute, and comes up before AttrRouter
    in the MRO, it will be used, instead- this was an intentional decision.

    Obviously (or maybe not), if you set self.member to another object, calls
    will still be routed to the original. Unroute, or route to a new object,
    before doing that. In the future, I'll try to support that use case.

    I came up with this to solve a pain point, but I might be missing something.
    Forgive me if there's a more natural solution, and let me know!
    - Matt Luongo, mhluongo 'at' g mail.com
    """
    #TODO use weakrefs in the router dictionary
    #TODO allow specifying a base object and then a string attribute to support
    #the case where routing to self.member, where member changes frequently-
    #eg self._route(['method1'], self, member_chain = ['member'])
    __metaclass__ = ABCMeta
    __router_dict_key = '_AttrRouter__attr_route_dict'

    @property
    def _key(self):
        """
        Returns the key used to locate get/set/del routings from the object __dict__
        """
        return AttrRouter.__router_dict_key

    @property
    def _router(self):
        """
        Returns the attr router stored in the object __dict__ with key
        `self._key`. If the key does not exist, it is initialized with
        a defaultdict
        """
        return self.__dict__.setdefault(self._key, defaultdict(dict))

    def __getattr__(self, name):
        """
        Gets the routed attribute named `name`. If not routed, the default
        attribute of the class is returned
        """
        target = self._router['get'].get(name, super(AttrRouter, self))
        return getattr(target, name)

    def __setattr__(self, name, value):
        """
        Sets the routed attribute named `name` to `value`. If not routed, the
        class defers to super's __setattr__
        """
        #remember, getattr and setattr don't work the same way
        if name in self._router['set']:
            return setattr(self._router['set'][name], name, value)
        return super(AttrRouter, self).__setattr__(name, value)

    def __delattr__(self, name):
        """
        Deletes the routed attribute named `name` to `value`. If not routed, the
        class defers to super's __delattr__
        """
        router = self._router['del']

        if name in router:
            return delattr(router[name], name)
        return super(AttrRouter, self).__delattr__(name)

    def _build_dict_list(self, get=True, set=False, delete=False):
        """
        Constructs a list of all routed attribute dicts for get/set/del
        indicated by keyword arguments `get`, `set`, `delete`
        """
        dicts = []

        if set:
            dicts.append(self._router['set'])

        if get:
            dicts.append(self._router['get'])

        if delete:
            dicts.append(self._router['del'])

        return dicts

    def _route(self, attrs, obj, get=True, set=False, delete=False):
        """
        Routes `attrs` to `obj` for get/set/del operations indicated by
        keyword boolean args `get`, `set`, and `delete`.
        """
        for d in self._build_dict_list(get=get, set=set, delete=delete):
            for attr in attrs:
                d[attr] = obj

    def _unroute(self, attrs, get=True, set=False, delete=False):
        """
        Removes `attrs` routed to `obj` from  routing lists get/set/del
        indicated by keyword boolean args `get`, `set`, and `delete`.
        """
        for d in self._build_dict_list(get=get, set=set, delete=delete):
            for attr in itertools.ifilter(lambda x: x in d, attrs):
                del d[attr]

    def _route_all(self, attrs, obj):
        """
        Routes `attrs` to `obj` for get/set/del operations
        """
        self._route(attrs, obj, get=True, set=True, delete=True)

    def _unroute_all(self, attrs, obj):
        """
        Removes `attrs` routed to `obj` from  routing lists get/set/del
        """
        self._unroute(attrs, obj, get=True, set=True, delete=True)


class Neo4djangoIntegrationRouter(object):
    """
    A django database router that will allow integration of both Neo4j and other
    RDBMS backends. This will make sure that django apps that rely on the traditional
    ORM will play nicely with Neo4j models
    """

    def _is_node_model(self, obj):
        """
        Checks if `obj` is a subclass of NodeModel. If `obj` is not a class
        type, a check if it is an instance of NodeModel is done instead.
        """
        # Imported here for circular imports
        from neo4django.db.models import NodeModel

        try:
            return issubclass(obj, NodeModel)
        except TypeError:
            return isinstance(obj, NodeModel)

    def allow_relation(self, obj1, obj2, **hints):
        """
        Checks if a relation between `obj1` and `obj2` should be allowed. This
        is done by checking that both objects are either NodeModels or regular
        django models
        """
        if self._is_node_model(obj1) != self._is_node_model(obj2):
            return False
        return None

    def allow_syncdb(self, db, model):
        """
        Checks if `model` class should be synced to `db`. This is always False
        for NodeModels
        """
        if self._is_node_model(model):
            return False
        return None


## TODO: I think this connection stuff  might belong elsewhere?
class ConnectionDoesNotExist(Exception):
    pass


def load_client(client_path):
    """
    Imports a custom subclass of `neo4django.neo4jclient.EnhancedGraphDatabase`. The
    only param `client_path` should be an importable python path string in the form
    `foo.bar.baz`. This method will raise an `ImproperlyConfigured` if a) the module/class
    cannot be import or the imported class is not a subclass of `EnhancedGraphDatabase`.
    """

    client_modname, client_classname = client_path.rsplit('.', 1)

    try:
        client_mod = import_module(client_modname)
    except ImportError:
        raise ImproperlyConfigured("Could not import %s as a client" % client_path)

    try:
        client = getattr(client_mod, client_classname)
    except AttributeError:
        raise ImproperlyConfigured("Neo4j client module %s has no class %s" %
                                   (client_mod, client_classname))

    if not issubclass(client, EnhancedGraphDatabase):
        raise ImproperlyConfigured("%s is not a subclass of EnhancedGraphDatabase" % client_path)

    return client


class ConnectionHandler(object):
    """
    This is copied straight from django.db.utils. It uses threadlocality
    to handle the case where the user wants to change the connection
    info in middleware -- by keeping the connections thread-local, changes
    on a per-view basis in middleware will not be applied globally.

    The only difference is whereas the django ConnectionHandler operates on various
    expected values of the DATABASES setting, this class operates with expected
    configurations for Neo4j connections
    """

    def __init__(self, databases):
        self.databases = databases
        self._connections = local()

    def ensure_defaults(self, alias):
        """
        Puts the defaults into the settings dictionary for a given connection
        where no settings is provided.
        """
        try:
            conn = self.databases[alias]
        except KeyError:
            raise ConnectionDoesNotExist("The connection %s doesn't exist" % alias)

        conn.setdefault('CLIENT', 'neo4django.neo4jclient.EnhancedGraphDatabase')
        if conn['CLIENT'] == 'django.db.backends.' or not conn['CLIENT']:
            conn['CLIENT'] = 'neo4django.neo4jclient.EnhancedGraphDatabase'
        conn.setdefault('OPTIONS', {})
        if 'HOST' not in conn or 'PORT' not in conn:
            raise ImproperlyConfigured('Each Neo4j database configured needs a configured host and port.')

        for setting in ['HOST', 'PORT']:
            conn.setdefault(setting, '')

        # TODO: We can add these back in if we upgrade to supporting 1.6
        # for setting in ['USER', 'PASSWORD']:
        #     conn.setdefault(setting, None)

    def __getitem__(self, alias):
        if hasattr(self._connections, alias):
            return getattr(self._connections, alias)

        self.ensure_defaults(alias)
        db = self.databases[alias]
        Client = load_client(db['CLIENT'])
        conn = Client('http://%s:%d%s' % (db['HOST'], db['PORT'], db['ENDPOINT']), **db['OPTIONS'])
        setattr(self._connections, alias, conn)

        return conn

    def __setitem__(self, key, value):
        setattr(self._connections, key, value)

    def __iter__(self):
        return iter(self.databases)

    def __repr__(self):
        return "<ConnectionHandler(%s)>" % str(self.databases)

    def all(self):
        return [self[alias] for alias in self]

########NEW FILE########
__FILENAME__ = validators
from django.core import exceptions


class ArrayValidator(object):
    def __call__(self, values):
        sup = super(ArrayValidator, self)
        if hasattr(sup, '__call__'):
            sup.__call__(values)
        if not getattr(values, '__iter__', False):
            raise exceptions.ValidationError('Enter a non-string sequence.')

validate_array = ArrayValidator()


def validate_str(value):
    try:
        str(value)
    except:
        raise exceptions.ValidationError('Enter a valid str.')


def validate_basestring(value):
    if not isinstance(value, basestring):
        raise exceptions.ValidationError('Enter a valid str.')


def validate_int(value):
    if not isinstance(value, int):
        raise exceptions.ValidationError('Enter a valid int.')


class ElementValidator(object):
    """Validates a sequence element by element with a list of validators."""
    def __init__(self, validators, message='Invalid sequence of elements.',
                 *args, **kwargs):
        """
        Arguments:
        validators -- a sequence of callable validators

        Keyword arguments:
        message -- the error message to raise if the sequence is invalid
        """
        super(ElementValidator, self).__init__(*args, **kwargs)
        self.validators = validators
        self.message = message

    def __call__(self, values):
        sup = super(ElementValidator, self)
        if hasattr(sup, '__call__'):
            sup.__call__(values)
        try:
            for value in values:
                for validator in self.validators:
                    validator(value)
        except exceptions.ValidationError:
            raise exceptions.ValidationError(self.message)


class IntArrayValidator(ArrayValidator, ElementValidator):
    def __init__(self, *args, **kwargs):
        kwargs.setdefault('message', 'Enter a sequence of valid ints.')
        super(IntArrayValidator, self).__init__([validate_int],
                                                *args, **kwargs)


class StringArrayValidator(ArrayValidator, ElementValidator):
    def __init__(self, *args, **kwargs):
        kwargs.setdefault('message', 'Enter a sequence of valid strs.')
        super(StringArrayValidator, self).__init__([validate_basestring],
                                                   *args, **kwargs)

validate_str_array = StringArrayValidator()
validate_int_array = IntArrayValidator()

########NEW FILE########
__FILENAME__ = reg_settings
options={
	}
tests=[
	'test_get_or_create',
	'test_json_serialize',
	'test_unique',
	'test_default_parents_index',
	'test_indexed_types',
	'test_create',
	'test_delete',
	'test_iter',
	'test_dates',
	'test_all',
	'test_get',
	'test_filter_exact',
	'test_filter_iexact',
	'test_filter_range',
	'test_exclude_exact',
	'test_basic_relationship',
	'test_one_to_many',
	'test_many_to_one',
	'test_related_one_to_many',
	'test_related_many_to_one',
	'test_one_to_one',
	'test_ordering',
	'test_relationship_model',
	'test_multinode_setting',
	'test_save_delete',
	'test_custom_clients_same_database',
	'test_prop',
	'test_none_prop',
	'test_integer',
	'test_date_constructor',
	'test_date_prop',
	'test_datetime_constructor',
	'test_datetime_auto_now',
	'test_datetime_auto_now_add',
	'test_date_auto_now',
	'test_date_auto_now_add',
	'test_type_nodes',
	'test_model_inheritance',
	'test_nodemodel_independence',
	'test_array_property_validator',
	'test_int_array_property',
	'test_str_array_property_validator',
	'test_url_array_property_validator',
	'test_basic_indexed_query',
	'test_negated_query',
	'test_unindexed_query',
	'test_complex_query',
	'test_type_query',
	'test_filter_gt',
	'test_filter_gte',
	'test_filter_lt',
	'test_filter_lte',
	'test_filter_date_range',
	'test_model_casting',
	'test_model_casting_validation',
	'test_model_copy',
	'test_basic_relationship_manager',
	'test_one_to_one',
	'test_rel_metadata',
	'test_prop_metadata',
	'test_rel_self',
	'test_rel_string_target',
	'test_auto_property',
	'test_rel_string_type',
	'test_get_by_id',
	'test_in_id',
	'test_empty_array',
	'test_typenode_transactionality',
	'test_queryset_str',
	'test_in_bulk',
	'test_auto_property_indexing',
	'test_filter_array_member',
	'test_autoproperty_transactionality',
	'test_abstract_rel_inheritance',
	'test_filter_in',
	'test_filter_contains',
	'test_filter_startswith',
	'test_datetime_auto_now_add',
	'test_select_related',
	'test_rel_query_direction',
	'test_filter_array_member_in',
	'test_large_query',
	'test_zerovalued_lookup',
	'test_datetimetz_constructor',
	'test_datetimetz_prop',
	'test_datetime_prop',
	'test_custom_manager',
	'test_other_library',
	'test_rel_slicing',
	'test_pre_init',
	'test_post_init',
	'test_pre_save',
	'test_post_save',
	'test_pre_delete',
	'test_post_delete',
	'test_in_bulk_not_found',
	'test_none',
	'test_relationship_none',
	'test_relationship_count',
	'test_relationship_filter',
	'test_cleandb',
	'test_object_index',
	'test_array_use_strings',
	'test_array_use_strings_value_escaping',
	'test_relationship_create',
	'test_relationship_delete',
	'test_rel_cache',
	'test_conflicting_rel_types',
	'test_syncdb',
	'test_model_pickling',
	'touch_test_db',
	'rm_test_db',
	'test_spanning_lookup',
	'test_order_by',
	'test_count',
	'test_aggregate_count',
	'test_exists',
	'test_aggregate_avg',
	'test_aggregate_sum',
	'test_aggregate_max_min',
	'test_auth',
	'test_auth_backend',
	'test_modelform',
	'test_query_type',
	'test_complex_filters',
	'test_inherited_indexed_filter',
	'test_spanning_lookup',
	'test_related_modelform',
	'test_relationship_models',
	'test_relationship_distinct',
	'test_reverse',
	'test_latest',
	'test_filter_icontains',
	'test_filter_istartswith',
	'test_filter_iregex',
	'test_filter_regex',
	'test_filter_iendswith',
	'test_filter_endswith',
	'test_filter_year',
	'test_filter_month',
	'test_filter_day',
	'test_filter_isnull',
	'test_subborn_dict_restricts_keys',
	'test_subborn_dict_allows_keys',
	'test_uniqify',
	'test_all_your_base',
	'test_write_through',
	'test_write_through_default',
	'test_attrrouter_router_default',
	'test_attrrouter_with_routed_attrs',
	'test_attrrouter_gets_obj_attr',
	'test_attrrouter_gets_routed',
	'test_attrrouter_sets_obj_attr',
	'test_attrrouter_sets_routed',
	'test_attrrouter_dels_obj_attr',
	'test_attrrouter_dels_routed',
	'test_attrrouter_route_get',
	'test_attrrouter_route_set',
	'test_attrrouter_route_delete',
	'test_attrrouter_unroute_get',
	'test_attrrouter_unroute_set',
	'test_attrrouter_unroute_delete',
	'test_integration_router_is_node_model',
	'test_integration_router_allow_relation_mismatch',
	'test_integration_router_allow_relation_between_node_models',
	'test_integration_router_allow_relation_between_django_models',
	'test_load_client_fail_module_import',
	'test_load_client_module_class_missing',
	'test_load_client_not_correct_subclass',
	'test_load_client',
	'test_sliding_pair',
	'test_assignable_list',
	'test_enum_numerical_items',
	'test_enum_explict_items',
	'test_countdown',
	'test_apply_to_buffer',
	'test_apply_to_buffer_raises_stop_iteration',
	'test_buffer_iterator',
	'test_order_by_and_count',
	'test_pk_shortcut',
	'test_create_with_id',
	'test_relationship_get_by_id',
	'test_update',
	'test_relationship_filter_many_to_many']
should_fail=[
	'test_dates',
	'test_relationship_model',
	'test_nodemodel_independence',
	'test_url_array_property_validator',
	'test_type_query',
	'test_model_casting_validation',
	'test_array_use_strings',
	'test_relationship_models',
	'test_typenode_transactionality',
	'test_autoproperty_transactionality',
	'test_relationship_filter_many_to_many']

########NEW FILE########
