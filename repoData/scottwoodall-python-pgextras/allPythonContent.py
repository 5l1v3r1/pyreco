__FILENAME__ = conf
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# complexity documentation build configuration file, created by
# sphinx-quickstart on Tue Jul  9 22:26:36 2013.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys
import os

# If extensions (or modules to document with autodoc) are in another
# directory, add these directories to sys.path here. If the directory is
# relative to the documentation root, use os.path.abspath to make it
# absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# Get the project root dir, which is the parent dir of this
cwd = os.getcwd()
project_root = os.path.dirname(cwd)

# Insert the project root dir as the first element in the PYTHONPATH.
# This lets us ensure that the source package is imported, and that its
# version is used.
sys.path.insert(0, project_root)

import pgextras

# -- General configuration ---------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.viewcode']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'python-pgextras'
copyright = u'2014, Scott Woodall'

# The version info for the project you're documenting, acts as replacement
# for |version| and |release|, also used in various other places throughout
# the built documents.
#
# The short X.Y version.
version = pgextras.__version__
# The full version, including alpha/beta/rc tags.
release = pgextras.__version__

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to
# some non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all
# documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built
# documents.
#keep_warnings = False


# -- Options for HTML output -------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a
# theme further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as
# html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the
# top of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon
# of the docs.  This file should be a Windows icon file (.ico) being
# 16x16 or 32x32 pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets)
# here, relative to this directory. They are copied after the builtin
# static files, so a file named "default.css" will overwrite the builtin
# "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page
# bottom, using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names
# to template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer.
# Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer.
# Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages
# will contain a <link> tag referring to it.  The value of this option
# must be the base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'pgextrasdoc'


# -- Options for LaTeX output ------------------------------------------

latex_elements = {
    # The paper size ('letterpaper' or 'a4paper').
    #'papersize': 'letterpaper',

    # The font size ('10pt', '11pt' or '12pt').
    #'pointsize': '10pt',

    # Additional stuff for the LaTeX preamble.
    #'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass
# [howto/manual]).
latex_documents = [
    ('index', 'pgextras.tex',
     u'python-pgextras Documentation',
     u'Scott Woodall', 'manual'),
]

# The name of an image file (relative to this directory) to place at
# the top of the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings
# are parts, not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output ------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'pgextras',
     u'python-pgextras Documentation',
     [u'Scott Woodall'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ----------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
    ('index', 'pgextras',
     u'python-pgextras Documentation',
     u'Scott Woodall',
     'pgextras',
     'One line description of project.',
     'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False
########NEW FILE########
__FILENAME__ = sql_constants
# -*- coding: utf-8 -*-

"""
SQL statements are kept here as to not clutter up main file.
"""


VACUUM_STATS = """
    WITH table_opts AS (
        SELECT
            pg_class.oid,
            relname,
            nspname,
            array_to_string(reloptions, '') AS relopts
        FROM pg_class
            INNER JOIN pg_namespace ns ON relnamespace = ns.oid
    ), vacuum_settings AS (
        SELECT
            oid,
            relname,
            nspname,
            CASE
                WHEN relopts LIKE '%autovacuum_vacuum_threshold%'
                THEN regexp_replace(
                    relopts,
                    '.*autovacuum_vacuum_threshold=([0-9.]+).*',
                    E'\\\\\\1'
                )::integer
                ELSE current_setting('autovacuum_vacuum_threshold')::integer
            END AS autovacuum_vacuum_threshold,
            CASE
                WHEN relopts LIKE '%autovacuum_vacuum_scale_factor%'
                THEN regexp_replace(
                    relopts,
                    '.*autovacuum_vacuum_scale_factor=([0-9.]+).*',
                    E'\\\\\\1'
                )::real
                ELSE current_setting('autovacuum_vacuum_scale_factor')::real
            END AS autovacuum_vacuum_scale_factor
        FROM table_opts
    )
    SELECT
        vacuum_settings.nspname AS schema,
        vacuum_settings.relname AS table,
        to_char(psut.last_vacuum, 'YYYY-MM-DD HH24:MI') AS last_vacuum,
        to_char(psut.last_autovacuum, 'YYYY-MM-DD HH24:MI') AS last_autovacuum,
        pg_class.reltuples AS rowcount,
        psut.n_dead_tup AS dead_rowcount,
        autovacuum_vacuum_threshold + (
            autovacuum_vacuum_scale_factor::numeric * pg_class.reltuples)
        AS autovacuum_threshold,
        CASE
            WHEN autovacuum_vacuum_threshold + (
                autovacuum_vacuum_scale_factor::numeric * pg_class.reltuples
            ) < psut.n_dead_tup
            THEN 'yes'
        END AS expect_autovacuum
    FROM pg_stat_user_tables psut
        INNER JOIN pg_class ON psut.relid = pg_class.oid
        INNER JOIN vacuum_settings ON pg_class.oid = vacuum_settings.oid
    ORDER BY 1
"""

OUTLIERS = """
    SELECT {query} AS qry,
        interval '1 millisecond' * total_time AS exec_time,
        to_char((total_time/sum(total_time) OVER()) * 100,
            'FM90D0') || '%' AS
        prop_exec_time,
        calls AS ncalls,
        interval '1 millisecond' * (blk_read_time + blk_write_time)
            AS sync_io_time
    FROM pg_stat_statements
    WHERE userid = (
        SELECT usesysid
        FROM pg_user
        WHERE usename = current_user
        LIMIT 1
    )
    ORDER BY total_time DESC
    LIMIT 10
"""

BLOCKING = """
    SELECT
        bl.pid AS blocked_pid,
        ka.{query_column} AS blocking_statement,
        now() - ka.query_start AS blocking_duration,
        kl.pid AS blocking_pid,
        a.{query_column} AS blocked_statement,
        now() - a.query_start AS blocked_duration
    FROM
        pg_catalog.pg_locks bl
        JOIN pg_catalog.pg_stat_activity a ON bl.pid = a.{pid_column}
        JOIN pg_catalog.pg_locks kl
        JOIN pg_catalog.pg_stat_activity ka ON kl.pid = ka.{pid_column}
            ON bl.transactionid = kl.transactionid AND bl.pid != kl.pid
    WHERE NOT bl.granted
"""

INDEX_USAGE = """
    SELECT
        relname,
        CASE idx_scan
            WHEN 0 THEN 'Insufficient data'
            ELSE (100 * idx_scan / (seq_scan + idx_scan))::text
        END percent_of_times_index_used,
        n_live_tup rows_in_table
    FROM pg_stat_user_tables
    ORDER BY n_live_tup DESC
"""

CALLS = """
    {select} interval '1 millisecond' * total_time AS exec_time,
        to_char((total_time/sum(total_time) OVER()) * 100, 'FM90D0') || '%'
            AS prop_exec_time,
        calls AS ncalls,
        interval '1 millisecond' * (blk_read_time + blk_write_time)
            AS sync_io_time
    FROM pg_stat_statements
    WHERE userid = (
        SELECT usesysid
        FROM pg_user
        WHERE usename = current_user LIMIT 1
    )
    ORDER BY calls DESC
    LIMIT 10
"""

LOCKS = """
    SELECT
        pg_stat_activity.{pid_column},
        pg_class.relname,
        pg_locks.transactionid,
        pg_locks.granted,
        substr(pg_stat_activity.{query_column},1,30) AS query_snippet,
        age(now(),pg_stat_activity.query_start) AS "age"
    FROM
        pg_stat_activity,
        pg_locks LEFT OUTER JOIN pg_class ON (pg_locks.relation = pg_class.oid)
    WHERE
        pg_stat_activity.{query_column} <> '<insufficient privilege>'
            AND pg_locks.pid = pg_stat_activity.{pid_column}
            AND pg_locks.mode = 'ExclusiveLock'
            AND pg_stat_activity.{pid_column} <> pg_backend_pid()
    ORDER BY query_start
"""

PG_STAT_STATEMENT = """
    SELECT exists(
        SELECT 1
        FROM pg_extension
        WHERE extname = 'pg_stat_statements'
    ) AS available
"""

BLOAT = """
    WITH constants AS (
        SELECT
            current_setting('block_size')::numeric AS bs,
            23 AS hdr,
            4 AS ma
    ), bloat_info AS (
        SELECT
            ma,
            bs,
            schemaname,
            tablename,
            (datawidth+(
                hdr+ma-(
                    CASE
                        WHEN hdr%ma=0
                        THEN ma
                        ELSE hdr%ma
                    END
                )
            ))::numeric AS datahdr,
            (maxfracsum*(
                nullhdr+ma-(
                    CASE
                        WHEN nullhdr%ma=0
                        THEN ma
                        ELSE nullhdr%ma
                    END
                )
            )) AS nullhdr2
        FROM (
            SELECT
                schemaname,
                tablename,
                hdr,
                ma,
                bs,
                SUM((1-null_frac)*avg_width) AS datawidth,
                MAX(null_frac) AS maxfracsum,
                hdr+(
                    SELECT 1+count(*)/8
                    FROM pg_stats s2
                    WHERE
                        null_frac<>0
                        AND s2.schemaname = s.schemaname
                        AND s2.tablename = s.tablename
                ) AS nullhdr
            FROM
                pg_stats s,
                constants
            GROUP BY 1,2,3,4,5
        ) AS foo
    ), table_bloat AS (
        SELECT
            schemaname,
            tablename,
            cc.relpages,
            bs,
            CEIL(
                (cc.reltuples*(
                    (datahdr+ma-(
                        CASE
                            WHEN datahdr%ma=0
                            THEN ma
                            ELSE datahdr%ma
                        END
                    ))+nullhdr2+4
                ))/(bs-20::float)
            ) AS otta
        FROM bloat_info
            JOIN pg_class cc ON cc.relname = bloat_info.tablename
            JOIN pg_namespace nn ON cc.relnamespace = nn.oid
                AND nn.nspname = bloat_info.schemaname
                AND nn.nspname <> 'information_schema'
    ), index_bloat AS (
        SELECT
            schemaname,
            tablename,
            bs,
            COALESCE(c2.relname,'?') AS iname,
            COALESCE(c2.reltuples,0) AS ituples,
            COALESCE(c2.relpages,0) AS ipages,
            COALESCE(
                CEIL((c2.reltuples*(datahdr-12))/(bs-20::float)),0
            ) AS iotta
        FROM bloat_info
            JOIN pg_class cc ON cc.relname = bloat_info.tablename
            JOIN pg_namespace nn ON cc.relnamespace = nn.oid
                AND nn.nspname = bloat_info.schemaname
                AND nn.nspname <> 'information_schema'
            JOIN pg_index i ON indrelid = cc.oid
            JOIN pg_class c2 ON c2.oid = i.indexrelid
     )
     SELECT
        type,
        schemaname,
        object_name,
        bloat,
        pg_size_pretty(raw_waste) AS waste
     FROM (
        SELECT
            'table' AS type,
            schemaname,
            tablename AS object_name,
            ROUND(
                CASE
                    WHEN otta=0
                    THEN 0.0
                    ELSE table_bloat.relpages/otta::numeric
                END,
            1) AS bloat,
            CASE
                WHEN relpages < otta
                THEN '0'
                ELSE (bs*(
                    table_bloat.relpages-otta)::bigint)::bigint
            END AS raw_waste
        FROM table_bloat
        UNION
        SELECT
            'index' AS type,
            schemaname,
            tablename || '::' || iname AS object_name,
            ROUND(
                CASE
                    WHEN iotta=0 OR ipages=0
                    THEN 0.0
                    ELSE ipages/iotta::numeric
                END,
            1) AS bloat,
            CASE
                WHEN ipages < iotta
                THEN '0'
                ELSE (bs*(ipages-iotta))::bigint
            END AS raw_waste
        FROM index_bloat
    ) bloat_summary
    ORDER BY
        raw_waste DESC,
        bloat DESC
"""

LONG_RUNNING_QUERIES = """
     SELECT
        {pid_column},
        now() - pg_stat_activity.query_start AS duration,
        {query_column} AS query
    FROM pg_stat_activity
    WHERE
        pg_stat_activity.{query_column} <> ''::text
        {idle}
        AND now() - pg_stat_activity.query_start > interval '5 minutes'
    ORDER BY now() - pg_stat_activity.query_start DESC
"""

SEQ_SCANS = """
     SELECT
        relname AS name,
        seq_scan AS count
     FROM pg_stat_user_tables
     ORDER BY seq_scan DESC
"""

UNUSED_INDEXES = """
    SELECT
        schemaname || '.' || relname AS table,
        indexrelname AS index,
        pg_size_pretty(pg_relation_size(i.indexrelid)) AS index_size,
        idx_scan AS index_scans
    FROM pg_stat_user_indexes ui
        JOIN pg_index i ON ui.indexrelid = i.indexrelid
    WHERE
        NOT indisunique AND idx_scan < 50
        AND pg_relation_size(relid) > 5 * 8192
    ORDER BY
        pg_relation_size(i.indexrelid) / nullif(idx_scan, 0) DESC
        NULLS FIRST,
        pg_relation_size(i.indexrelid) DESC
"""

TOTAL_TABLE_SIZE = """
    SELECT
        c.relname AS name,
        pg_size_pretty(pg_total_relation_size(c.oid)) AS size
    FROM pg_class c
        LEFT JOIN pg_namespace n ON (n.oid = c.relnamespace)
    WHERE
        n.nspname NOT IN ('pg_catalog', 'information_schema')
        AND n.nspname !~ '^pg_toast'
        AND c.relkind='r'
    ORDER BY pg_total_relation_size(c.oid) DESC
"""

TOTAL_INDEXES_SIZE = """
    SELECT
        c.relname AS table,
        pg_size_pretty(pg_indexes_size(c.oid)) AS index_size
    FROM pg_class c
        LEFT JOIN pg_namespace n ON (n.oid = c.relnamespace)
    WHERE
        n.nspname NOT IN ('pg_catalog', 'information_schema')
        AND n.nspname !~ '^pg_toast'
        AND c.relkind='r'
    ORDER BY pg_indexes_size(c.oid) DESC;
"""

TABLE_SIZE = """
     SELECT
        c.relname AS name,
        pg_size_pretty(pg_table_size(c.oid)) AS size
     FROM pg_class c
        LEFT JOIN pg_namespace n ON (n.oid = c.relnamespace)
     WHERE
        n.nspname NOT IN ('pg_catalog', 'information_schema')
        AND n.nspname !~ '^pg_toast'
        AND c.relkind='r'
     ORDER BY pg_table_size(c.oid) DESC
"""

INDEX_SIZE = """
    SELECT
        c.relname AS name,
        pg_size_pretty(sum(c.relpages::bigint*8192)::bigint) AS size
    FROM pg_class c
        LEFT JOIN pg_namespace n ON (n.oid = c.relnamespace)
    WHERE
        n.nspname NOT IN ('pg_catalog', 'information_schema')
        AND n.nspname !~ '^pg_toast'
        AND c.relkind='i'
    GROUP BY c.relname
    ORDER BY sum(c.relpages) DESC
"""

TOTAL_INDEX_SIZE = """
    SELECT pg_size_pretty(sum(c.relpages::bigint*8192)::bigint) AS size
    FROM pg_class c
        LEFT JOIN pg_namespace n ON (n.oid = c.relnamespace)
    WHERE
        n.nspname NOT IN ('pg_catalog', 'information_schema')
        AND n.nspname !~ '^pg_toast'
        AND c.relkind='i';
"""

CACHE_HIT = """
    SELECT
        'index hit rate' AS name,
        (sum(idx_blks_hit)) / sum(idx_blks_hit + idx_blks_read) AS ratio
    FROM pg_statio_user_indexes
    UNION ALL
    SELECT
        'table hit rate' AS name,
        sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read))
            AS ratio
    FROM pg_statio_user_tables
"""

TABLE_INDEXES_SIZE = """
    SELECT
        c.relname AS table,
        pg_size_pretty(pg_indexes_size(c.oid)) AS index_size
    FROM pg_class c
        LEFT JOIN pg_namespace n ON (n.oid = c.relnamespace)
    WHERE n.nspname NOT IN ('pg_catalog', 'information_schema')
        AND n.nspname !~ '^pg_toast'
        AND c.relkind='r'
    ORDER BY pg_indexes_size(c.oid) DESC;
"""

PS = """
    SELECT
        {pid_column},
        application_name AS source,
        age(now(),query_start) AS running_for,
        waiting,
        {query_column} AS query
    FROM pg_stat_activity
    WHERE {query_column} <> '<insufficient privilege>'
        AND {pid_column} <> pg_backend_pid()
        {idle}
    ORDER BY query_start DESC
"""

VERSION = """
    SELECT version()
"""

########NEW FILE########
__FILENAME__ = test_pgextras
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import unittest

from mock import patch
import psycopg2
import psycopg2.extras

from pgextras import PgExtras, sql_constants as sql


class TestPgextras(unittest.TestCase):
    def setUp(self):
        self.dbname = 'python_pgextras_unittest'
        self.dsn = 'dbname={dbname}'.format(dbname=self.dbname)
        self.conn = psycopg2.connect(
            self.dsn,
            cursor_factory=psycopg2.extras.NamedTupleCursor
        )
        self.cursor = self.conn.cursor()

    def drop_pg_stat_statement(self):
        if self.is_pg_stat_statement_installed():
            statement = "DROP EXTENSION pg_stat_statements"
            self.cursor.execute(statement)
            self.conn.commit()

    def create_pg_stat_statement(self):
        if not self.is_pg_stat_statement_installed():
            statement = "CREATE EXTENSION pg_stat_statements"
            self.cursor.execute(statement)
            self.conn.commit()

    def is_pg_stat_statement_installed(self):
        self.cursor.execute(sql.PG_STAT_STATEMENT)
        results = self.cursor.fetchall()

        return results[0].available

    def test_that_pg_stat_statement_is_installed(self):
        self.create_pg_stat_statement()

        with PgExtras(dsn=self.dsn) as pg:
            self.assertTrue(pg.pg_stat_statement())

    def test_that_pg_stat_statement_is_not_installed(self):
        self.drop_pg_stat_statement()

        with PgExtras(dsn=self.dsn) as pg:
            self.assertFalse(pg.pg_stat_statement())

    def test_methods_have_one_result(self):
        method_names = ['version', 'total_index_size']

        with PgExtras(dsn=self.dsn) as pg:
            for method_name in method_names:
                func = getattr(pg, method_name)
                results = func()

                self.assertTrue(len(results), 1)

    def test_methods_have_two_results(self):
        method_names = ['cache_hit']

        with PgExtras(dsn=self.dsn) as pg:
            for method_name in method_names:
                func = getattr(pg, method_name)
                results = func()

                self.assertTrue(len(results), 2)

    def test_methods_have_three_results(self):
        method_names = ['index_size']

        with PgExtras(dsn=self.dsn) as pg:
            for method_name in method_names:
                func = getattr(pg, method_name)
                results = func()

                self.assertEqual(len(results), 3)

    def test_methods_have_four_results(self):
        method_names = [
            'table_indexes_size', 'index_usage', 'seq_scans',
            'total_table_size', 'table_size', 'total_indexes_size'
        ]

        with PgExtras(dsn=self.dsn) as pg:
            for method_name in method_names:
                func = getattr(pg, method_name)
                results = func()

                self.assertTrue(len(results), 4)

    def test_calls(self):
        with PgExtras(dsn=self.dsn) as pg:
            if pg.is_pg_at_least_nine_two():
                self.create_pg_stat_statement()
                results = pg.calls()
                self.assertTrue(len(results), 10)
            else:
                results = pg.calls()
                self.assertIsNotNone(results[0].error)

    def test_blocking(self):
        statement = """
            UPDATE pgbench_branches
            SET bbalance = bbalance + 10
            WHERE bid = 1
        """

        blocking_conn = psycopg2.connect(
            database=self.dbname,
            cursor_factory=psycopg2.extras.NamedTupleCursor
        )

        blocking_cursor = blocking_conn.cursor()
        blocking_cursor.execute(statement)

        async_conn = psycopg2.connect(
            database=self.dbname,
            cursor_factory=psycopg2.extras.NamedTupleCursor,
            async=1
        )

        psycopg2.extras.wait_select(async_conn)
        async_cursor = async_conn.cursor()
        async_cursor.execute(statement)

        with PgExtras(dsn=self.dsn) as pg:
            results = pg.blocking()

        self.assertEqual(len(results), 1)

    def test_ps(self):
        """
        If the test suite is ran back to back within one second of each other
        there is a race condition and this test has the potential to fail.
        There will be more than one result because the previous test suites run
        of pg_sleep(2) is still in the pg_stat_activity table. There's also a
        race condition that pg.ps() does not return within 2 seconds and the
        sleep is already gone from the pg_stat_activity.
        """

        statement = """
            SELECT pg_sleep(2);
        """

        async_conn = psycopg2.connect(
            database=self.dbname,
            cursor_factory=psycopg2.extras.NamedTupleCursor,
            async=1
        )

        psycopg2.extras.wait_select(async_conn)
        async_cursor = async_conn.cursor()
        async_cursor.execute(statement)

        with PgExtras(dsn=self.dsn) as pg:
            results = pg.ps()

        self.assertEqual(len(results), 1)

    @patch.object(PgExtras, 'is_pg_at_least_nine_two')
    def test_that_pid_column_returns_correct_column_name(self, mockery):
        mockery.return_value = False

        with PgExtras(dsn=self.dsn) as pg:
            self.assertEqual(pg.pid_column,  'procpid')
            mockery.return_value = True
            self.assertEqual(pg.pid_column,  'pid')

    @patch.object(PgExtras, 'is_pg_at_least_nine_two')
    def test_that_query_column_returns_correct_column_name(self, mockery):
        mockery.return_value = False

        with PgExtras(dsn=self.dsn) as pg:
            self.assertEqual(pg.query_column,  'current_query')
            mockery.return_value = True
            self.assertEqual(pg.query_column,  'query')

    @patch.object(PgExtras, 'version')
    def test_parsing_postgres_version_number(self, mockery):
        Record = type('Record', (object, ), {
            'version': 'PostgreSQL 9.3.3 on x86_64-apple-darwin13.0.0'
        })
        mockery.return_value = [Record]

        with PgExtras(dsn=self.dsn) as pg:
            self.assertTrue(pg.is_pg_at_least_nine_two())
            Record.version = 'PostgreSQL 9.1.1 on x86_64-apple-darwin13.0.0'
            pg._is_pg_at_least_nine_two = None
            self.assertFalse(pg.is_pg_at_least_nine_two())

    def test_error_property_exists_for_missing_pg_stat_statement(self):
        with PgExtras(dsn=self.dsn) as pg:
            results = pg.get_missing_pg_stat_statement_error()

            self.assertIsNotNone(results.error)

    def tearDown(self):
        self.cursor.close()
        self.conn.close()

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
