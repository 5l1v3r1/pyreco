__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# simpleai documentation build configuration file, created by
# sphinx-quickstart on Sat Sep 22 18:54:36 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os
sys.path.insert(0, os.path.abspath('..'))

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.viewcode', 'sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'simpleai'
copyright = u'2012, Juan Pedro Fisanotti'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.7'
# The full version, including alpha/beta/rc tags.
release = '0.7.9'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'simpleaidoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'simpleai.tex', u'simpleai Documentation',
   u'Juan Pedro Fisanotti', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'simpleai', u'simpleai Documentation',
     [u'Juan Pedro Fisanotti'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'simpleai', u'simpleai Documentation',
   u'Juan Pedro Fisanotti', 'simpleai', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = iris
#!/usr/bin/env python
# coding: utf-8

"""
Iris dataset classification example.

The iris dataset can be downloaded
from here: http://archive.ics.uci.edu/ml/datasets/Iris
It has to be placed in the corpus folder.
"""

import os
import math
import random
from simpleai.machine_learning import precision
from simpleai.machine_learning import NaiveBayes
from simpleai.machine_learning import KNearestNeighbors
from simpleai.machine_learning import DecisionTreeLearner_Queued
from simpleai.machine_learning import VectorDataClassificationProblem

BASE_PATH = os.path.dirname(os.path.abspath(__file__))
IRIS_PATH = os.path.join(BASE_PATH, "corpus", "iris.data")


def euclidean_vector_distance(x, y):
    return math.sqrt(sum([(a - b) ** 2 for a, b in zip(x, y)]))


class IrisDataset(list):
    target_index = 4

    def __init__(self, filepath, accept_criteria):
        i = 0
        for line in open(filepath):
            i += 1

            if not accept_criteria(i):
                continue

            line = line[:-1]
            if not line:
                continue
            attrs = line.split(",")
            target = attrs[self.target_index]
            attrs = [float(x) for x in attrs[:self.target_index]]
            self.append(attrs + [target])

        random.shuffle(self)


def main():
    # line count
    N = 0
    for _ in open(IRIS_PATH):
        N += 1
    testindexes = set(random.sample(xrange(N), N / 10))

    dataset = IrisDataset(IRIS_PATH, lambda i: i not in testindexes)
    testset = IrisDataset(IRIS_PATH, lambda i: i in testindexes)
    problem = VectorDataClassificationProblem(dataset, dataset.target_index)
    # Distance without target
    problem.distance = lambda x, y: euclidean_vector_distance(x[:-1], y[:-1])

    classifiers = {
        "K-Nearest Neighbours": KNearestNeighbors,
        "Naive Bayes": NaiveBayes,
        "Decision Tree": DecisionTreeLearner_Queued,
    }

    print "Precision:\n"
    for name, method in classifiers.iteritems():
        classifier = method(dataset, problem)
        p = precision(classifier, testset)
        print "{:>20} = {:.2}".format(name, p)


if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = language_classification
# -*- coding: utf-8 -*-

"""
Example for language classification from text using the es-en europarl
corpus[0].
This script should be able to tell if some text is english or spanish based
solely in counting the letters that appear.

It's *highly* recomended to make shorter versions of the corpus to experiment,
like this:
    head -n 100000 europarl-v7.es-en.en > short.en
    head -n 100000 europarl-v7.es-en.es > short.es

and then change the input files variable to point them... it'll be faster.


[0] Download link: http://www.statmt.org/europarl/v7/es-en.tgz
    See http://www.statmt.org/europarl/ for more information.
"""


# CHANGE INPUT FILES HERE:
input_files = [("english", "europarl-v7.es-en.en"),
               ("spanish", "europarl-v7.es-en.es")]


import random
from simpleai.machine_learning import DecisionTreeLearner_LargeData, \
                                      ClassificationProblem, Attribute, \
                                      precision, NaiveBayes
from simpleai.machine_learning.classifiers import tree_to_str


class Sentence(object):
    def __init__(self, language, text):
        self.language = language
        self.text = text


class LetterCount(Attribute):
    def __init__(self, letter):
        self.letter = letter
        self.name = "Counts for letter {!r}".format(letter)

    def __call__(self, sentence):
        return sentence.text.count(self.letter)


class LanguageClassificationProblem(ClassificationProblem):

    def __init__(self):
        super(LanguageClassificationProblem, self).__init__()
        for letter in "abcdefghijklmnopqrstuvwxyz":
            attribute = LetterCount(letter)
            self.attributes.append(attribute)

    def target(self, sentence):
        return sentence.language


class OnlineCorpusReader(object):
    def __init__(self, input_files, accept_criteria):
        self.input_files = input_files
        self.accept_criteria = accept_criteria

    def __iter__(self):
        print "Iterating corpus from the start..."
        i = 0
        for language, filename in self.input_files:
            for text in open(filename):
                if self.accept_criteria(i):
                    yield Sentence(language, text.lower())
                i += 1
                if i % 10000 == 0:
                    print "\tReaded {} examples".format(i)


print "Counting examples"
# line count
N = 0
for _, filename in input_files:
    for _ in open(filename):
        N += 1
print "Corpus has {} examples".format(N)

# Choose test set, either 10% or 10000 examples, whatever is less
M = min(N / 10, 10000)
testindexes = set(random.sample(xrange(N), M))
print "Keeping {} examples for testing".format(M)

problem = LanguageClassificationProblem()
train = OnlineCorpusReader(input_files, lambda i: i not in testindexes)
test = OnlineCorpusReader(input_files, lambda i: i in testindexes)


print "Training Naive Bayes..."
classifier = NaiveBayes(train, problem)
print "Testing..."
p = precision(classifier, test)
print "Precision Naive Bayes = {}".format(p)


print "Training Decision Tree (large data)..."
classifier = DecisionTreeLearner_LargeData(train, problem, minsample=500)
print "Final tree:"
print tree_to_str(classifier.root)
print "Testing..."
p = precision(classifier, test)
print "Precision Decision Tree = {}".format(p)

########NEW FILE########
__FILENAME__ = opinion
#!/usr/bin/env python
# coding: utf-8

"""
Opinion Mining example.
More about opinion mining here: http://en.wikipedia.org/wiki/Sentiment_analysis

Dataset extracted from: http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html
precisely http://www.cs.uic.edu/~liub/FBS/pros-cons.rar
It should be placed in a folder called corpus in the same location of this file.
"""

import os
import re
import codecs
import random

from simpleai.machine_learning import precision
from simpleai.machine_learning import Attribute
from simpleai.machine_learning import NaiveBayes
from simpleai.machine_learning import ClassificationProblem

BASE_PATH = os.path.dirname(os.path.abspath(__file__))
PRO_CORPUS_PATH = os.path.join(BASE_PATH, "corpus", "IntegratedPros.txt")
CON_CORPUS_PATH = os.path.join(BASE_PATH, "corpus", "IntegratedCons.txt")
STOPWORDS_PATH = os.path.join(BASE_PATH, "corpus", "stopwordsEN.txt")
STOPWORDS = {s.strip() for s in codecs.open(STOPWORDS_PATH, encoding="utf-8")}


class Opinion(object):
    def __init__(self, text, category=None):
        self.text = text
        self.category = category


class WordIsPresent(Attribute):
    def __init__(self, word):
        super(WordIsPresent, self).__init__(name="{} is present".format(word))
        self.word = word

    def __call__(self, opinion):
        words = opinion.text.split()
        return self.word in words


class ProConsCorpus(object):
    def __init__(self, input_files, accept_criteria):
        self.input_files = input_files
        self.accept_criteria = accept_criteria

    def _clean_line(self, line):
        line = re.sub("\<[\/]*Pros\>", "", line)
        line = re.sub("\<[\/]*Cons\>", "", line)
        line = re.sub("[;\":!\.,()]", "", line)
        line = line.strip()
        line = line.lower()
        return line

    def __iter__(self):
        i = 0
        for category, filename in self.input_files.items():
            for line in open(filename):
                line = self._clean_line(line)
                if self.accept_criteria(i):
                    yield Opinion(line, category)
                i += 1
                if i % 1000 == 0:
                    print "\tReaded {} examples".format(i)


class OpinionProblem(ClassificationProblem):
    def __init__(self, corpus):
        super(OpinionProblem, self).__init__()

        words = set()
        for opinion in corpus:
            for word in opinion.text.split():
                if word not in STOPWORDS:
                    words.add(word)

        for word in words:
            self.attributes.append(WordIsPresent(word))

    def target(self, opinion):
        return opinion.category


def main():
    input_files = {
        "pro": PRO_CORPUS_PATH,
        "con": CON_CORPUS_PATH,
    }

    # line count
    N = 0
    for _, filename in input_files.items():
        for _ in open(filename):
            N += 1
    print "Corpus has {} examples".format(N)

    # Choose test set, either 10% or 10000 examples, whatever is less
    M = min(N / 10, 1000)
    testindexes = set(random.sample(xrange(N), M))

    corpus = ProConsCorpus(input_files, lambda i: i not in testindexes)
    test = ProConsCorpus(input_files, lambda i: i in testindexes)
    print "Corpuses created"

    problem = OpinionProblem(corpus)
    classifier = NaiveBayes(corpus, problem)
    print "Classifier created"

    p = precision(classifier, test)
    print "Precision = {}".format(p)

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = tic_tac_toe
# -*- coding: utf-8 -*-
from simpleai.machine_learning.reinforcement_learning import TDQLearner, RLProblem, \
                                                             make_exponential_temperature, \
                                                             PerformanceCounter
import random
from simpleai.environments import RLEnvironment


class TicTacToeProblem(RLProblem):

    def actions(self, state):
        'actions are index where we can make a move'
        actions = []
        for index, char in enumerate(state):
            if char == '_':
                actions.append(index)
        return actions

    def update_state(self, percept, agent):
        state = percept.replace(agent.play_with, '1')
        state = state.replace(agent.other_play_with, '2')
        return state.replace('\n', '')


class TicTacToePlayer(TDQLearner):

    def __init__(self, play_with):
        super(TicTacToePlayer, self).__init__(TicTacToeProblem(),
                                              temperature_function=make_exponential_temperature(1000000, 0.01),
                                              discount_factor=0.4)
        self.play_with = play_with
        self.other_play_with = 'X' if play_with == 'O' else 'O'


class HumanPlayer(TicTacToePlayer):

    def set_reward(self, reward, terminal=False):
        print ('reward:', reward)

    def program(self, perception):
        print ('Current board:')
        rows = perception.split()
        s = ['+-+-+-+-+', '| |0|1|2|', '+-+-+-+-+']
        for i, row in enumerate(rows):
            row = row.replace('_', ' ')
            s.append('|%d|' % i + '|'.join(list(row)) + '|')
            s.append('+-+-+-+-+')
        print (('\n'.join(s)))
        a = input('Make your move (r, c):')
        r, c = a
        return r * 3 + c


class RandomPlayer(TicTacToePlayer):

    def program(self, perception):
        try:
            return random.choice(self.problem.actions(self.problem.update_state(perception, self)))
        except:
            return None


class TicTacToeGame(RLEnvironment):

    def __init__(self, agents):
        super(TicTacToeGame, self).__init__(agents, '___\n___\n___')

    def do_action(self, state, action, agent):
        if action is not None:
            s = state.replace('\n', '')
            s = s[:action] + agent.play_with + s[action + 1:]
            return '\n'.join([s[0:3], s[3:6], s[6:9]])
        return state

    def is_completed(self, state):
        return not ('_' in state and all([self.reward(state, x) == 0 for x in self.agents]))

    def reward(self, state, agent):
        rows = state.split()
        columns = [''.join(x) for x in zip(*rows)]
        diagonals = [rows[0][0] + rows[1][1] + rows[2][2], rows[0][2] + rows[1][1] + rows[2][0]]
        to_check = rows + columns + diagonals
        for x in to_check:
            if all([c == x[0] for c in x]) and x[0] != '_':
                if x[0] == agent.play_with:
                    return 1
                else:
                    return -1
        return 0


if __name__ == '__main__':
    a = TicTacToePlayer('X')
    b = RandomPlayer('O')
    c = HumanPlayer('O')
    game = TicTacToeGame([a, b])
    print ('Training with a random player, please wait...')
    game.agents = [a, b]
    for i in range(3000):
        game.run()

    a.dump('qlearner_agent')

    d = TicTacToePlayer.load('qlearner_agent')
    d.play_with = 'O'

    game.agents = [a, d]
    per = PerformanceCounter(game.agents, ['QLearnerA', 'QLearnerD'])
    for i in range(3000):
        game.run()
    per.show_statistics()

    game.agents = [a, c]
    print ('Do you like to play?')
    game.run()
    print game.state

########NEW FILE########
__FILENAME__ = wumpus
# -*- coding: utf-8 -*-
from simpleai.machine_learning.reinforcement_learning import TDQLearner, \
                                                             make_exponential_temperature, \
                                                             PerformanceCounter, \
                                                             RLProblem
from simpleai.environments import RLEnvironment
from Tkinter import *
import threading


class PerpetualTimer(threading._Timer):

    def __init__(self, interval, function, name=None, daemon=False,
                    args=(), kwargs={}):
        super(PerpetualTimer, self).__init__(interval, function, args, kwargs)
        self.setName(name)
        self.setDaemon(daemon)

    def run(self):
        while True:
            self.finished.wait(self.interval)
            if self.finished.isSet():
                return
            self.function(*self.args, **self.kwargs)

    def stop(self, timeout=None):
        self.cancel()
        self.join(timeout)

    def callback(egg):
        egg.cook()


class WumpusViewer(object):

    def __init__(self, environment):
        self.environment = environment
        root = Tk()
        w = Canvas(root, width=400, height=400)
        self.w = w
        w.pack()

        w.create_polygon(0, 0, 0, 400, 400, 400, 400, 0, fill='white')
        for x in range(4):
            w.create_line(100 * x, 0, 100 * x, 400)
            w.create_line(0, 100 * x, 400, 100 * x)

        #make holes
        for x, y in environment.holes:
            w.create_oval(*self._coord(x, y), fill='red')

        #make wumpus
        x, y = environment.wumpus
        w.create_oval(*self._coord(x, y), fill='blue')

        #make agent
        x, y, have_gold = environment.state
        self.agent = w.create_oval(*self._coord(x, y), fill='green')

        #make gold
        x, y = environment.gold
        self.gold = w.create_oval(*self._coord(x, y), fill='yellow')

        frame = Frame(root)
        frame.pack()

        self.start = Button(frame, text="Start", command=self.start)
        self.start.pack(side=LEFT)
        self.stop = Button(frame, text="Stop", command=self.stop)
        self.stop.pack(side=LEFT)

        root.mainloop()

    def _coord(self, x, y):
        y = 5 - y
        cx = 100 * (x - 1) + 50
        cy = 100 * (y - 1) + 50
        r = 30
        return (cx - r, cy - r, cx + r, cy + r)

    def step(self):
        if self.environment.is_completed(self.environment.state):
            self.timer.cancel()
        else:
            self.environment.step(viewer=self)

    def start(self):
        self.timer = PerpetualTimer(0.5, self.step)
        self.timer.start()
        self.environment.state = self.environment.initial_state

    def stop(self):
        self.timer.cancel()

    def event(self, state1, action, state2, agent):
        print 'action: %s state: %s' % (action, str(state2))
        x, y, have_gold = state2
        if have_gold and self.gold:
            self.w.delete(self.gold)
            self.w.itemconfig(self.agent, outline="yellow", width=6.0)
        self.w.coords(self.agent, self._coord(x, y))


class WumpusEnvironment(RLEnvironment):

    def __init__(self, agent):
        super(RLEnvironment, self).__init__([agent], (1, 1, False))
        self.action_dict = {'up': (0, 1), 'down': (0, -1), 'left': (-1, 0), 'rigth': (1, 0)}
        self.wumpus = (1, 3)
        self.holes = [(3, 1), (3, 3), (4, 4)]
        self.gold = (3, 4)
        self.threats = [self.wumpus] + self.holes

        self.rewards = {(1, 1, True): 10}
        for c, r in self.threats:
            self.rewards[(c, r, True)] = -10
            self.rewards[(c, r, False)] = -10

    def do_action(self, state, action, agent):
        c1, r1, have_gold = state
        c2, r2 = self.action_dict[action]
        rn = r1 + r2
        cn = c1 + c2
        if not have_gold and (cn, rn) == self.gold:
            have_gold = True
        _next = (cn, rn, have_gold)
        if (1 <= rn <= 4) and (1 <= cn <= 4):
            return _next
        return state

    def is_completed(self, state):
        return state in self.rewards.keys()

    def reward(self, state, agent):
        return self.rewards.get(state, -0.08)


class WumpusProblem(RLProblem):

    def actions(self, state):
        actions = ['up', 'down', 'left', 'rigth']
        return actions


if __name__ == '__main__':
    agent = TDQLearner(WumpusProblem(),
                       temperature_function=make_exponential_temperature(1000, 0.01),
                       discount_factor=0.8)
    game = WumpusEnvironment(agent)

    p = PerformanceCounter([agent], ['Q-learner Agent'])

    print 'Training...'
    for i in range(10000):
        game.run()

    p.show_statistics()
    game.run(viewer=WumpusViewer(game))



########NEW FILE########
__FILENAME__ = australia
from simpleai.search import CspProblem, backtrack, min_conflicts, MOST_CONSTRAINED_VARIABLE, HIGHEST_DEGREE_VARIABLE, LEAST_CONSTRAINING_VALUE

variables = ('WA', 'NT', 'SA', 'Q', 'NSW', 'V', 'T')

domains = dict((v, ['red', 'green', 'blue']) for v in variables)

def const_different(variables, values):
    return values[0] != values[1]  # expect the value of the neighbors to be different

constraints = [
    (('WA', 'NT'), const_different),
    (('WA', 'SA'), const_different),
    (('SA', 'NT'), const_different),
    (('SA', 'Q'), const_different),
    (('NT', 'Q'), const_different),
    (('SA', 'NSW'), const_different),
    (('Q', 'NSW'), const_different),
    (('SA', 'V'), const_different),
    (('NSW', 'V'), const_different),
]

my_problem = CspProblem(variables, domains, constraints)

print backtrack(my_problem)
print backtrack(my_problem, variable_heuristic=MOST_CONSTRAINED_VARIABLE)
print backtrack(my_problem, variable_heuristic=HIGHEST_DEGREE_VARIABLE)
print backtrack(my_problem, value_heuristic=LEAST_CONSTRAINING_VALUE)
print backtrack(my_problem, variable_heuristic=MOST_CONSTRAINED_VARIABLE, value_heuristic=LEAST_CONSTRAINING_VALUE)
print backtrack(my_problem, variable_heuristic=HIGHEST_DEGREE_VARIABLE, value_heuristic=LEAST_CONSTRAINING_VALUE)
print min_conflicts(my_problem)

########NEW FILE########
__FILENAME__ = cryptarithmetic
from time import time

from copy import deepcopy

from simpleai.search import (
    backtrack, MOST_CONSTRAINED_VARIABLE, LEAST_CONSTRAINING_VALUE,
    convert_to_binary, CspProblem)

variables = ('F', 'T', 'U', 'W', 'R', 'O', 'C_10', 'C_100', 'C_1000')

domains = dict((v, range(1, 10)) for v in variables)


def const_different(variables, values):
    return len(values) == len(set(values))  # remove repeated values and count

constraints = [
    (('F', 'T', 'U', 'W', 'R', 'O'), const_different),
    (('O', 'R', 'C_10'), lambda vars_, values: values[0] + values[0] == values[1] + 10 * values[2]),
    (('C_10', 'W', 'U', 'C_100'), lambda vars_, values: values[0] + values[1] + values[1] == values[2] + 10 * values[3]),
    (('C_100', 'T', 'O', 'C_1000'), lambda vars_, values: values[0] + values[1] + values[1] == values[2] + 10 * values[3]),
    (('C_1000', 'F'), lambda vars_, values: values[0] == values[1])
]

original_constraints = deepcopy(constraints)
original_domains = deepcopy(domains)

start = time()
problem = CspProblem(variables, original_domains, original_constraints)
result = backtrack(problem, variable_heuristic=MOST_CONSTRAINED_VARIABLE, value_heuristic=LEAST_CONSTRAINING_VALUE)
elapsed = time() - start
print result
print "Took %d seconds to finish using n-ary constraints" % elapsed


start = time()
variables, domains, constraints = convert_to_binary(variables, domains, constraints)
problem = CspProblem(variables, domains, constraints)
result = backtrack(problem, value_heuristic=LEAST_CONSTRAINING_VALUE)
elapsed = time() - start
print result
print "Took %d seconds to finish using binary constraints" % elapsed

########NEW FILE########
__FILENAME__ = dotsearch
from pygraphviz import AGraph
import base64
import tempfile
from simpleai.search import SearchProblem


class BadInputGraph(Exception):
    pass


class DotGraphSearchProblem(SearchProblem):
    """
    Playground for stuff in the library... eats a .dot graph and allows you
    to try it with the search methods.
    """
    def __init__(self, filename):
        self.G = AGraph(filename)
        xs = [(nodo, nodo.attr.get("initial", None))
              for nodo in self.G.iternodes()]
        xs = [x for x in xs if x[1]]
        if len(xs) == 0:
            raise BadInputGraph("Missing 'initial' node")
        elif len(xs) > 1:
            raise BadInputGraph("Cannot have two initial nodes")
        if not any(nodo.attr.get("goal", None) for nodo in self.G.iternodes()):
            raise BadInputGraph("Missing a goal state '[goal=\"1\"]'")
        super(DotGraphSearchProblem, self).__init__(xs[0][0])
        self.initial_state.attr["shape"] = "doublecircle"
        for node in self.G.iternodes():
            if self.is_goal(node):
                node.attr["shape"] = "hexagon"
                node.attr["color"] = "blue"
        self.seen = set()
        self.visit(self.initial_state)
        for edge in self.G.iteredges():
            edge.attr["style"] = "dotted"
            x = edge.attr.get("weight", None)
            if x:
                x = int(x)
            else:
                x = 1
            edge.attr["weight"] = x
            edge.attr["label"] = x

    def actions(self, state):
        assert state in self.G
        if self.G.is_directed():
            return self.G.itersucc(state)
        else:
            assert self.G.is_undirected()
            return self.G.iterneighbors(state)

    def result(self, state, action):
        assert state in self.G and action in self.G
        self.visit(state)
        return action

    def cost(self, state1, action, state2):
        assert state1 in self.G and action in self.G and action == state2
        x = self.G.get_edge(state1, state2).attr["weight"]
        if float(x) == int(x):
            return int(x)
        else:
            return float(x)

    def visit(self, state):
        if state in self.seen:
            return
        self.seen.add(state)
        attr = self.G.get_node(state).attr
        attr["color"] = "firebrick"

    def is_goal(self, state):
        return bool(state.attr.get("goal", False))

    def value(self, state):
        assert state in self.G
        value = self.G.get_node(state).attr.get("value", None)
        if not value:
            return 0
        return float(value)


def run_algorithm(algorithm, filename):
    problem = DotGraphSearchProblem(filename)
    goal = algorithm(problem)
    if goal:
        problem.visit(goal.state)
        prev = None
        for _, state in goal.path():
            if prev:
                edge = problem.G.get_edge(prev, state)
                edge.attr["style"] = "solid"
            prev = state
        return problem.G, goal.state, goal.cost, problem.value(goal.state), \
               len(problem.seen)
    return problem.G, None, None, None, len(problem.seen)


HTML_TEMPLATE = """
<html><body>
<table style="border:0" align="center">
    <tr><td colspan="2"><h2 style="text-align: center">{graph}</h2></td></tr>
    <tr><td colspan="2"><hr /></td></tr>
    {rows}
</table>
</body></html>
"""

RUN_TEMPLATE = """
<tr>
    <td>
      <b style="text-align: center"> {algorithm} </b> <br /> <br />
      Nodes expanded(or 'visited') = {visited}
      <br /> Path cost = {cost}
      <br /> Final node value = {value} </td>
    {image_column}
</tr>
<tr>
    <td colspan="2"><hr /></td>
</tr>
"""

IMAGE_TEMPLATE = """<td style="padding-left: 50px">
<img src="data:image/png;base64,{image}" /> </td>"""

#
#  Credits to Gonzalo Garcia Berrotaran (j0hn) for the clever way of putting
#  this into HTML.
#


def report(infile=None, algorithms=None, outfile="report.html",
           with_images=True):
    assert infile and algorithms
    rows = []
    for algorithm in algorithms:
        G, goal, cost, value, visited = run_algorithm(algorithm, infile)
        image = ""
        if with_images:
            out = tempfile.NamedTemporaryFile(delete=False)
            G.draw(out, format="png", prog="dot")
            out.seek(0)
            image = base64.b64encode(out.read())
            out.close()
            image = IMAGE_TEMPLATE.format(image=image)
        s = RUN_TEMPLATE.format(algorithm=algorithm.__name__,
                                visited=visited, cost=cost, value=value,
                                image_column=image, )
        rows.append(s)
    s = HTML_TEMPLATE.format(graph=infile, rows="".join(rows))
    open(outfile, "w").write(s)

########NEW FILE########
__FILENAME__ = eight_puzzle
'''
8 puzzle problem, a smaller version of the fifteen puzzle:
http://en.wikipedia.org/wiki/Fifteen_puzzle
States are defined as string representations of the pieces on the puzzle.
Actions denote what piece will be moved to the empty space.

States must allways be inmutable. We will use strings, but internally most of
the time we will convert those strings to lists, which are easier to handle.
For example, the state (string):

'1-2-3
 4-5-6
 7-8-e'

will become (in lists):

[['1', '2', '3'],
 ['4', '5', '6'],
 ['7', '8', 'e']]

'''

from simpleai.search import astar, SearchProblem
from simpleai.search.viewers import WebViewer


GOAL = '''1-2-3
4-5-6
7-8-e'''

INITIAL = '''4-1-2
7-e-3
8-5-6'''


def list_to_string(list_):
    return '\n'.join(['-'.join(row) for row in list_])


def string_to_list(string_):
    return [row.split('-') for row in string_.split('\n')]


def find_location(rows, element_to_find):
    '''Find the location of a piece in the puzzle.
       Returns a tuple: row, column'''
    for ir, row in enumerate(rows):
        for ic, element in enumerate(row):
            if element == element_to_find:
                return ir, ic


# we create a cache for the goal position of each piece, so we don't have to
# recalculate them every time
goal_positions = {}
rows_goal = string_to_list(GOAL)
for number in '12345678e':
    goal_positions[number] = find_location(rows_goal, number)


class EigthPuzzleProblem(SearchProblem):
    def actions(self, state):
        '''Returns a list of the pieces we can move to the empty space.'''
        rows = string_to_list(state)
        row_e, col_e = find_location(rows, 'e')

        actions = []
        if row_e > 0:
            actions.append(rows[row_e - 1][col_e])
        if row_e < 2:
            actions.append(rows[row_e + 1][col_e])
        if col_e > 0:
            actions.append(rows[row_e][col_e - 1])
        if col_e < 2:
            actions.append(rows[row_e][col_e + 1])

        return actions

    def result(self, state, action):
        '''Return the resulting state after moving a piece to the empty space.
           (the "action" parameter contains the piece to move)
        '''
        rows = string_to_list(state)
        row_e, col_e = find_location(rows, 'e')
        row_n, col_n = find_location(rows, action)

        rows[row_e][col_e], rows[row_n][col_n] = rows[row_n][col_n], rows[row_e][col_e]

        return list_to_string(rows)

    def is_goal(self, state):
        '''Returns true if a state is the goal state.'''
        return state == GOAL

    def cost(self, state1, action, state2):
        '''Returns the cost of performing an action. No useful on this problem, i
           but needed.
        '''
        return 1

    def heuristic(self, state):
        '''Returns an *estimation* of the distance from a state to the goal.
           We are using the manhattan distance.
        '''
        rows = string_to_list(state)

        distance = 0

        for number in '12345678e':
            row_n, col_n = find_location(rows, number)
            row_n_goal, col_n_goal = goal_positions[number]

            distance += abs(row_n - row_n_goal) + abs(col_n - col_n_goal)

        return distance


result = astar(EigthPuzzleProblem(INITIAL))
# if you want to use the visual debugger, use this instead:
# result = astar(EigthPuzzleProblem(INITIAL), viewer=WebViewer())

for action, state in result.path():
    print 'Move number', action
    print state


########NEW FILE########
__FILENAME__ = game_walk
#!/usr/bin/env python
# coding: utf-8

import math
from simpleai.search import SearchProblem, astar

MAP = """
##############################
#         #              #   #
# ####    ########       #   #
#  o #    #              #   #
#    ###     ####   ######   #
#         ####      #        #
#            #  #   #   #### #
#     ######    #       # x  #
#        #      #            #
##############################
"""
MAP = [list(x) for x in MAP.split("\n") if x]

COSTS = {
    "up": 1.0,
    "down": 1.0,
    "left": 1.0,
    "right": 1.0,
    "up left": 1.4,
    "up right": 1.4,
    "down left": 1.4,
    "down right": 1.4,
}


class GameWalkPuzzle(SearchProblem):

    def __init__(self, board):
        self.board = board
        self.goal = (0, 0)
        for y in xrange(len(self.board)):
            for x in xrange(len(self.board[y])):
                if self.board[y][x].lower() == "o":
                    self.initial = (x, y)
                elif self.board[y][x].lower() == "x":
                    self.goal = (x, y)

        super(GameWalkPuzzle, self).__init__(initial_state=self.initial)

    def actions(self, state):
        actions = []
        for action in COSTS.keys():
            newx, newy = self.result(state, action)
            if self.board[newy][newx] != "#":
                actions.append(action)
        return actions

    def result(self, state, action):
        x, y = state

        if action.count("up"):
            y -= 1
        if action.count("down"):
            y += 1
        if action.count("left"):
            x -= 1
        if action.count("right"):
            x += 1

        new_state = (x, y)
        return new_state

    def is_goal(self, state):
        return state == self.goal

    def cost(self, state, action, state2):
        return COSTS[action]

    def heuristic(self, state):
        x, y = state
        gx, gy = self.goal
        return math.sqrt((x - gx) ** 2 + (y - gy) ** 2)


def main():
    problem = GameWalkPuzzle(MAP)
    result = astar(problem, graph_search=True)
    path = [x[1] for x in result.path()]

    for y in xrange(len(MAP)):
        for x in xrange(len(MAP[y])):
            if (x, y) == problem.initial:
                print "o",
            elif (x, y) == problem.goal:
                print "x",
            elif (x, y) in path:
                print "·",
            else:
                print MAP[y][x],
        print


if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = hello_world
# coding=utf-8
from simpleai.search import SearchProblem, astar

GOAL = 'HELLO WORLD'


class HelloProblem(SearchProblem):
    def actions(self, state):
        if len(state) < len(GOAL):
            return list(' ABCDEFGHIJKLMNOPQRSTUVWXYZ')
        else:
            return []

    def result(self, state, action):
        return state + action

    def is_goal(self, state):
        return state == GOAL

    def heuristic(self, state):
        # how far are we from the goal?
        wrong = sum([1 if state[i] != GOAL[i] else 0
                    for i in range(len(state))])
        missing = len(GOAL) - len(state)
        return wrong + missing

problem = HelloProblem(initial_state='')
result = astar(problem)

print result.state
print result.path()

########NEW FILE########
__FILENAME__ = make_report
assert __name__ == "__main__"
from dotsearch import report
import argparse
parser = argparse.ArgumentParser(description="Runs graph search "
"algorithms over a .dot graph file.")
parser.add_argument("dotfile", action="store")
cfg = parser.parse_args()


from simpleai.search import breadth_first, astar, beam, simulated_annealing


print "Running algorithms and writting report.html..."
report(infile=cfg.dotfile,
       algorithms=[
            breadth_first,
            astar,
            beam,
            simulated_annealing,
           ],
       outfile="report.html",
       with_images=True)

########NEW FILE########
__FILENAME__ = missioners
# coding=utf-8
from simpleai.search import SearchProblem, astar


class MissionersProblem(SearchProblem):
    '''Missioners and cannibals problem.'''

    def __init__(self):
        super(MissionersProblem, self).__init__(initial_state=(3, 3, 0))
        # each action has a printable text, and the number of missioners
        # and cannibals to move on that action
        self._actions = [('1c', (0,1)),
                         ('1m', (1, 0)),
                         ('2c', (0, 2)),
                         ('2m', (2, 0)),
                         ('1m1c', (1, 1))]

    def actions(self, s):
        '''Possible actions from a state.'''
        # we try to generate every possible state and then filter those
        # states that are valid
        return [a for a in self._actions if self._is_valid(self.result(s, a))]

    def _is_valid(self, s):
        '''Check if a state is valid.'''
        # valid states: no more cannibals than missioners on each side,
        # and numbers between 0 and 3
        return ((s[0] >= s[1] or s[0] == 0)) and \
                ((3 - s[0]) >= (3 - s[1]) or s[0] == 3) and \
                (0 <= s[0] <= 3) and \
                (0 <= s[1] <= 3)

    def result(self, s, a):
        '''Result of applying an action to a state.'''
        # result: boat on opposite side, and numbers of missioners and
        # cannibals updated according to the move
        if s[2] == 0:
            return (s[0] - a[1][0], s[1] - a[1][1], 1)
        else:
            return (s[0] + a[1][0], s[1] + a[1][1], 0)

    def is_goal(self, state):
        return state == (0, 0, 1)

    def heuristic(self, state):
        return (state[0] + state[1]) / 2

    def value(self, state):
        return 6 - state[0] - state[1]


problem = MissionersProblem()

result = astar(problem)
print result.path()

########NEW FILE########
__FILENAME__ = simple_nary_to_binary
from simpleai.search import backtrack, CspProblem, convert_to_binary

variables = ('A', 'B', 'C')

domains = {
    'A': [1, 2, 3],
    'B': [1, 3, 4],
    'C': [1, 2],
}


def const_different(variables, values):
    return len(values) == len(set(values))  # remove repeated values and count


# a constraint that expects one variable to be bigger than other
def const_one_bigger_other(variables, values):
    return values[0] > values[1]


# a constraint thet expects two variables to be one odd and the other even,
# no matter which one is which type
def const_one_odd_one_even(variables, values):
    if values[0] % 2 == 0:
        return values[1] % 2 == 1  # first even, expect second to be odd
    else:
        return values[1] % 2 == 0  # first odd, expect second to be even


# a constraint that requires one variable to be different than 1
def const_not_1(variables, values):
    return values[0] != 1

constraints = [
    (('A', 'B', 'C'), const_different),
    (('A', 'C'), const_one_bigger_other),
    (('A', 'C'), const_one_odd_one_even),
    (('A',), const_not_1)
]

variables, domains, constraints = convert_to_binary(variables, domains, constraints)
problem = CspProblem(variables, domains, constraints)
result = backtrack(problem)
print result
# result, {'A':2, 'B': 3, 'C': 1})

########NEW FILE########
__FILENAME__ = sudoku
from time import time
from StringIO import StringIO
from string import uppercase
from itertools import combinations
from collections import OrderedDict
from copy import deepcopy

from simpleai.search import CspProblem, backtrack, convert_to_binary

variables = ["%s%d" % (i, j) for i in uppercase[:9] for j in xrange(1, 10)]

domains = OrderedDict((v, range(1, 10)) for v in variables)


def const_different(variables, values):
    return values[0] != values[1]  # expect the value of the neighbors to be different

sudoku = \
"""
  3 2 6
9  3 5  1
  18 64
  81 29
7       8
  67 82
  26 95
8  2 3  9
  5 1 3
"""


def parsepuzzle(puzzle):
    sudoku_lines = map(lambda s: s.rstrip("\n"), StringIO(puzzle).readlines()[1:])
    domains = {}

    for k, i in enumerate(uppercase[:9]):
        for j in xrange(1, 10):
            line = sudoku_lines[k]
            if len(line) <= (j - 1):
                continue
            val = line[j - 1]
            if val != ' ':
                var = "%s%d" % (i, j)
                domains[var] = [int(val)]

    return domains


def mkconstraints():
    """
    Make constraint list for binary constraint problem.
    """
    constraints = []

    for j in xrange(1, 10):
        vars = ["%s%d" % (i, j) for i in uppercase[:9]]
        constraints.extend((c, const_different) for c in combinations(vars, 2))

    for i in uppercase[:9]:
        vars = ["%s%d" % (i, j) for j in xrange(1, 10)]
        constraints.extend((c, const_different) for c in combinations(vars, 2))

    for b0 in ['ABC', 'DEF', 'GHI']:
        for b1 in [[1, 2, 3], [4, 5, 6], [7, 8, 9]]:
            vars = ["%s%d" % (i, j) for i in b0 for j in b1]
            l = list((c, const_different) for c in combinations(vars, 2))
            constraints.extend(l)

    return constraints


def mknaryconstraints():

    def alldiff(variables, values):
        return len(values) == len(set(values))  # remove repeated values and count

    constraints = []

    for j in xrange(1, 10):
        vars_ = ["%s%d" % (i, j) for i in uppercase[:9]]
        constraints.append((vars_, alldiff))

    for i in uppercase[:9]:
        vars_ = ["%s%d" % (i, j) for j in xrange(1, 10)]
        constraints.append((vars_, alldiff))

    for b0 in ['ABC', 'DEF', 'GHI']:
        for b1 in [[1, 2, 3], [4, 5, 6], [7, 8, 9]]:
            vars_ = ["%s%d" % (i, j) for i in b0 for j in b1]
            constraints.append((vars_, alldiff))

    return constraints


def display_solution(sol):
    for i in uppercase[:9]:
        print " ".join([str(sol["%s%d" % (i, j)]) for j in xrange(1, 10)])


domains.update(parsepuzzle(sudoku))

# -- Hand made binary constraints --
constraints = mkconstraints()
start = time()
domains0 = deepcopy(domains)
my_problem = CspProblem(variables, domains0, constraints)
sol = backtrack(my_problem)
elapsed = time() - start
display_solution(sol)
print "Took %d seconds to finish using binary constraints" % elapsed  # because of AC3 should be quick


# -- N-ary constraints made binary using hidden variables --
domains1 = deepcopy(domains)
start = time()
variables1, domains1, constraints = convert_to_binary(variables, domains1, mknaryconstraints())
my_problem = CspProblem(variables1, domains1, constraints)
sol = backtrack(my_problem)
elapsed = time() - start
display_solution(sol)
print "Took %d seconds to finish using binary constraints (hidden variables)" % elapsed


# -- N-ary constraints --
constraints = mknaryconstraints()
domains3 = deepcopy(domains)
start = time()
my_problem = CspProblem(variables, domains3, constraints)
sol = backtrack(my_problem)
elapsed = time() - start
display_solution(sol)
print "Took %d seconds to finish using n-ary constraints" % elapsed

########NEW FILE########
__FILENAME__ = threesat
from time import time

from copy import deepcopy

from simpleai.search import backtrack, CspProblem, convert_to_binary

variables = ('X1', 'X2', 'X3', 'X4', 'X5', 'X6')

domains = dict((v, [False, True]) for v in variables)

constraints = [
    (('X1', 'X2', 'X6'), lambda v, values: values[0] or values[1] or values[2]),
    (('X1', 'X3', 'X4'), lambda v, values: not values[0] or values[1] or values[2]),
    (('X4', 'X5', 'X6'), lambda v, values: not values[0] or not values[1] or values[2]),
    (('X2', 'X5', 'X6'), lambda v, values: values[0] or values[1] or not values[2]),
]

original_constraints = deepcopy(constraints)
original_domains = deepcopy(domains)

start = time()
problem = CspProblem(variables, original_domains, original_constraints)
result = backtrack(problem)
elapsed = time() - start
print result
print "Took %d seconds to finish using n-ary constraints" % elapsed


start = time()
variables, domains, constraints = convert_to_binary(variables, domains, constraints)
problem = CspProblem(variables, domains, constraints)
result = backtrack(problem)
elapsed = time() - start
print result
print "Took %d seconds to finish using binary constraints" % elapsed

########NEW FILE########
__FILENAME__ = environments
# -*- coding: utf-8 -*-


class Environment(object):

    def __init__(self, agents, initial_state):
        self.agents = agents
        self.initial_state = initial_state
        self.state = initial_state

    def run(self, steps=10000, viewer=None):
        self.state = self.initial_state
        for step in xrange(steps):
            if self.is_completed(self.state):
                return
            self.step(viewer=viewer)

    def step(self, viewer=None):
        "This method evolves one step in time"
        if not self.is_completed(self.state):
            for agent in self.agents:
                action = agent.program(self.percept(agent, self.state))
                next_state = self.do_action(self.state, action, agent)
                if viewer:
                    viewer.event(self.state, action, next_state, agent)
                self.state = next_state
                if self.is_completed(self.state):
                    return

    def do_action(self, state, action, agent):
        "Override this method to apply an action performed by an agent to a state and return a new state"
        raise NotImplementedError()

    def is_completed(self, state):
        "Override this method when the environment have terminal states"
        return False

    def percept(self, agent, state):
        "This method make agent's perception"
        return self.state


class RLEnvironment(Environment):

    def __init__(self, agents, initial_state):
        super(RLEnvironment, self).__init__(agents, initial_state)

    def step(self, viewer=None):
        super(RLEnvironment, self).step(viewer)
        for agent in self.agents:
            agent.set_reward(self.reward(self.state, agent), self.is_completed(self.state))

    def reward(self, state, agent):
        raise NotImplementedError()


########NEW FILE########
__FILENAME__ = classifiers
#!/usr/bin/env python
# coding: utf-8

"""
Classifiers implemented:
 * Decision tree:      See http://en.wikipedia.org/wiki/Decision_tree_learning
 * Naive Bayes:        See http://en.wikipedia.org/wiki/Naive_Bayes_classifier
 * K-Nearest Neighbor: See http://en.wikipedia.org/wiki/K-nearest_neighbor
"""

import numpy
from collections import defaultdict
from simpleai.machine_learning.models import Classifier
from simpleai.machine_learning.metrics import Counter, OnlineInformationGain, \
                                              OnlineLogProbability

try:
    import cPickle as pickle
except ImportError:
    import pickle


class DecisionTreeLearner(Classifier):
    """
    This implementation features an algorithm that *strictly* follows the
    pseudocode given in AIMA.

    It's obviously ineficient in too many ways (perhaps incomplete too), but
    it's intended to be used pedagogically.

    See the other implementations in this same file for some discusión and
    issues solved.

    This algorithm is equivalent to ID3.
    """

    def __init__(self, dataset, problem):
        self.dataset = dataset
        self.problem = problem
        self.root = self.learn(dataset, set(self.attributes), dataset)

    def learn(self, examples, attributes, parent_examples):
        """
        A decision tree learner that *strictly* follows the pseudocode given in
        AIMA. In 3rd edition, see Figure 18.5, page 702.
        """
        if not examples:
            return self.plurality_value(parent_examples)
        elif len(set(map(self.target, examples))) == 1:
            return self.plurality_value(examples)
        elif not attributes:
            return self.plurality_value(examples)
        A = max(attributes, key=lambda a: self.importance(a, examples))
        tree = DecisionTreeNode(attribute=A)
        for value in set(map(A, examples)):
            exs = [e for e in examples if A(e) == value]
            subtree = self.learn(exs, attributes - set([A]), examples)
            tree.add_branch(value, subtree)
        return tree

    def plurality_value(self, examples):
        if not examples:
            raise ValueError("Dataset is empty")
        counter = Counter(self.target)
        for example in examples:
            counter.add(example)
        tree = DecisionTreeNode()
        # Note that tie is *not* solved randomly here
        tree.set_results_from_counts(counter)
        return tree

    def importance(self, attribute, examples):
        """
        AIMA implies that importance should be information gain.
        Since AIMA only defines it for binary features this implementation
        was based on the wikipedia article:
        http://en.wikipedia.org/wiki/Information_gain_in_decision_trees
        """
        gain_counter = OnlineInformationGain(attribute, self.target)
        for example in examples:
            gain_counter.add(example)
        return gain_counter.get_gain()

    def classify(self, example):
        node = walk_to_leaf(self.root, example)
        return node.result


class NaiveBayes(Classifier):
    """
    Implements a classifier that uses the Bayes' theorem.
    """

    def learn(self):
        # Frequency count of target classes
        self.C = OnlineLogProbability()
        # Frequency count of P(Fi|C):
        self.Fi = defaultdict(lambda:  # For each class,
                      defaultdict(lambda:  # For each attribute,
                          OnlineLogProbability()))  # For each value, count it

        for example in self.dataset:
            class_ = self.target(example)
            self.C.add(class_)
            for attribute in self.attributes:
                value = attribute(example)
                self.Fi[class_][attribute].add(value)
        if not self.C:
            raise ValueError("Dataset is empty")

        # Cripple defaultdict to a regular dict, so now it can rasie KeyError
        self.Fi.default_factory = None
        for d in self.Fi.itervalues():
            d.default_factory = None

    def classify(self, example):
        values = [(attribute, attribute(example))
                  for attribute in self.attributes]
        hypotheses = []
        for class_ in self.C:
            try:
                ps = [self.Fi[class_][attr][val] for attr, val in values]
            except KeyError:
                continue  # A value not seen in training, so Prob(class) == 0
            ps.append(self.C[class_])
            hypotheses.append((sum(ps), class_))

        if hypotheses:
            logprob, best = max(hypotheses)
            Z = numpy.logaddexp.reduce([p for p, class_ in hypotheses])
            logprob = logprob - Z
        else:  # Something not at all seen in training, return best a priori
            logprob, best = max((p, class_) for class_, p
                                            in self.C.iteritems())
        p = numpy.exp(logprob)
        assert 0.0 <= p and p <= 1.0
        return best, p


class KNearestNeighbors(Classifier):
    """
    Classifies objects based on closest training example.
    Uses the k-nearest examples from the training and
    gets the most common classification among these.

    To use this classifier the problem must define a `distance`
    method to messure the distance between two examples.
    """

    def __init__(self, dataset, problem, k=1):
        self.k = k
        super(KNearestNeighbors, self).__init__(dataset, problem)

    def learn(self):
        try:
            next(iter(self.dataset))
        except StopIteration:
            raise ValueError("Empty dataset")
        try:
            example = next(iter(self.dataset))
            self.problem.distance(example, example)
        except NotImplementedError:
            message = "Classification problem not suitable for KNN. " \
                      "A problem with a distance defined is needed."
            raise ValueError(message)

    def classify(self, example):
        distances = [(self.problem.distance(e, example), e)
                     for e in self.dataset]
        best = sorted(distances)[:self.k]

        counter = Counter(self.problem.target)
        for _, example in best:
            counter.add(example)

        items = [(x[1], x[0]) for x in counter.iteritems()]
        items.sort(reverse=True)
        return (items[0][1], items[0][0] / counter.total)

    def save(self, filepath):
        """
        Saves the classifier to `filepath`.
        Because this classifier needs to save the dataset, it must
        be something that can be pickled and not something like an
        iterator.
        """

        if not filepath or not isinstance(filepath, basestring):
            raise ValueError("Invalid filepath")

        with open(filepath, "w") as filehandler:
            pickle.dump(self, filehandler)


def path_to_leaf(node, example):
    while node is not None:
        yield node
        node = node.take_branch(example)


def walk_to_leaf(node, example):
    for node in path_to_leaf(node, example):
        pass
    return node


def iter_tree(root):
    q = [(None, root, 0)]
    while q:
        value, node, depth = q.pop()
        yield value, node, depth
        for value, child in node.branches.iteritems():
            q.append((value, child, depth + 1))


def tree_to_str(root):
    """
    Returns a string representation of a decision tree with
    root node `root`.
    """

    xs = []
    for value, node, depth in iter_tree(root):
        template = "{indent}"
        if node is not root:
            template += "case={value}\t"
        if node.attribute is None:
            template += "result={result} -- P={prob:.2}"
        else:
            template += "split by {split}:\t" +\
                        "(partial result={result} -- P={prob:.2})"
        line = template.format(indent="    " * depth,
                               value=value,
                               result=node.result[0],
                               prob=node.result[1],
                               split=str(node.attribute))
        xs.append(line)
    return "\n".join(xs)


class DecisionTreeNode(object):
    """
    A node of a decision tree.
    """

    def __init__(self, attribute=None):
        self.branches = {}
        self.attribute = attribute
        self.parent = None
        self.result = None

    def take_branch(self, example):
        """
        Returns a `DecisionTreeNode` instance that can better classify
        `example` based on the selectors value.
        If there are no more branches (ie, this node is a leaf) or the
        attribute gives a value for an unexistent branch then this method
        returns None.
        """
        if self.attribute is None:
            return None
        value = self.attribute(example)
        return self.branches.get(value, None)

    def set_results_from_counts(self, counts):
        self.counts = counts
        total = sum(counts.itervalues())
        majority = max(counts, key=counts.get)  # Max frequency
        self.result = (majority, counts[majority] / float(total))

    def add_branch(self, value, branch=None):
        assert not value in self.branches
        if branch is None:
            branch = self.__class__()
        self.branches[value] = branch
        branch.parent = self
        return branch


class DecisionTreeLearner_Queued(Classifier):
    """
    This implementations has a few improvements over the one based on the book:
        -It uses a queue instead of recursion, so the python stack limit is
         never reached.
        -In case an attribute has a value not seen in training the intermediate
         nodes can give a "best so far" classification.
        -Abusive re-iteration of the train examples is avoided by calculating
         at the same time all information gains of a single node split.

         This algorithm is equivalent to ID3.
    """

    def learn(self):
        if not self.attributes:
            self.root = self._single_node_tree()
            return
        self.root = DecisionTreeNode()
        q = [(self.root, self.dataset)]
        while q:
            node, examples = q.pop()
            A = self._max_gain_split(examples)
            counts = A.get_target_class_counts()
            branches = A.get_branches()

            # Base case exception
            if node is self.root:
                node.set_results_from_counts(counts)

            if len(counts) == 1:
                continue  # Avoid splitting when there's a single target class
            if len(branches) == 1:
                continue  # Avoid splitting when there's a single child branch

            # Finally, go ahead and split
            node.attribute = A.attribute
            for value, counts in A.get_branches():
                branch = node.add_branch(value)
                branch.set_results_from_counts(counts)
                bdataset = [e for e in examples if node.attribute(e) == value]
                q.append((branch, bdataset))

    def _max_gain_split(self, examples):
        """
        Returns an OnlineInformationGain of the attribute with
        max gain based on `examples`.
        """
        gains = self._new_set_of_gain_counters()
        for example in examples:
            for gain in gains:
                gain.add(example)
        winner = max(gains, key=lambda gain: gain.get_gain())
        if not winner.get_target_class_counts():
            raise ValueError("Dataset is empty")
        return winner

    def _new_set_of_gain_counters(self):
        """
        Creates a new set of OnlineInformationGain objects
        for each attribute.
        """
        return [OnlineInformationGain(attribute, self.target)
                for attribute in self.attributes]

    def _single_node_tree(self):
        c = Counter(self.target)
        for example in self.dataset:
            c.add(example)
        node = DecisionTreeNode()
        node.set_results_from_counts(c)
        return node

    def classify(self, example):
        node = walk_to_leaf(self.root, example)
        return node.result


class DecisionTreeLearner_LargeData(DecisionTreeLearner_Queued):
    """
    This implementations is specifically designed to handle large dataset that
    don't fit into memory and has more improvements over the queued one:

        -Data is processed one-at-a-time, so the training data doesn't need to
         fit in memory.
        -The amount of times the train data is read is aproximately log(N) full
         iterations (from first to last) for a dataset with N examples.
         This is because the gain from all splits from all leaf nodes are
         estimated simultaneuosly, so every time the train data is read
         completely a full new level of the tree (ie, nodes with equal depth,
         leaves) is expanded simultaneously.

         This algorithm is equivalent to ID3.

    Is very important to note that in order to have a small memory footprint
    the `minsample` argument has to be set to a reasonable size, otherwhise
    there will be one tree leaf for every example in the training set and this
    totally defeats the pourpose of having a large data version of the
    algorithm.
    """
    def __init__(self, dataset, problem, minsample=1):
        self.minsample = minsample
        super(DecisionTreeLearner_Queued, self).__init__(dataset, problem)

    def learn(self):
        if not self.attributes:
            self.root = self._single_node_tree()
            return
        self.root = DecisionTreeNode()
        leaves = {self.root: self._new_set_of_gain_counters()}
        while leaves:
            leaf = None
            for example in self.dataset:
                leaf = walk_to_leaf(self.root, example)
                if leaf not in leaves:
                    continue  # Don't split leaves that where ignored
                for gain_counter in leaves[leaf]:
                    gain_counter.add(example)
            if leaf is None:
                raise ValueError("Dataset is empty")

            old_leaves = leaves
            leaves = {}
            for leaf, gains in old_leaves.iteritems():
                winner = max(gains, key=lambda gain: gain.get_gain())
                counts = winner.get_target_class_counts()
                branches = [(v, c) for v, c in winner.get_branches()
                            if c.total > self.minsample]

                # Base case exception
                if leaf is self.root:
                    leaf.set_results_from_counts(counts)

                if len(counts) == 1:
                    continue  # No split when there's a single target class
                if len(branches) <= 1:
                    continue  # No split when there's a single child branch
                              # Or all branches are too small

                # Finally, go ahead and split
                leaf.attribute = winner.attribute
                for value, counts in branches:
                    branch = leaf.add_branch(value)
                    branch.set_results_from_counts(counts)
                    leaves[branch] = self._new_set_of_gain_counters()

########NEW FILE########
__FILENAME__ = evaluation
#!/usr/bin/env python
# coding: utf-8

"""
Tools for evaluate the classification algorithms
"""


import random


def precision(classifier, testset):
    """
    Runs the classifier for each example in `testset`
    and verifies that the classification is correct
    using the `target`.

    Returns a number between 0.0 and 1.0 with the
    precision of classification for this test set.
    """

    hit = 0
    total = 0
    for example in testset:
        if classifier.classify(example)[0] == classifier.target(example):
            hit += 1
        total += 1
    if total == 0:
        raise ValueError("Empty testset!")
    return hit / float(total)


def kfold(dataset, problem, method, k=10):
    """
    Does a k-fold on `dataset` with `method`.
    This is, it randomly creates k-partitions of the dataset, and k-times
    trains the method with k-1 parts and runs it with the partition left.
    After all this, returns the overall success ratio.
    """

    if k <= 1:
        raise ValueError("k argument must be at least 2")

    dataset = list(dataset)
    random.shuffle(dataset)

    trials = 0
    positive = 0
    for i in xrange(k):
        train = [x for j, x in enumerate(dataset) if j % k != i]
        test = [x for j, x in enumerate(dataset) if j % k == i]
        classifier = method(train, problem)
        for data in test:
            trials += 1
            if classifier.classify(data)[0] == problem.target(data):
                positive += 1

    return float(positive) / float(trials)

########NEW FILE########
__FILENAME__ = metrics
#!/usr/bin/env python
# coding: utf-8

import math
import numpy
from collections import defaultdict


class Counter(defaultdict):
    """
    Counter of examples. Counts the total of examples added
    and also the times that the target of that example appears.

    To add an example use the `add` method and to check the
    values use it like a dictionary.
    """

    def __init__(self, target):
        super(Counter, self).__init__(int)
        self.target = target
        self.total = 0

    def add(self, example):
        value = self.target(example)
        self[value] += 1
        self.total += 1


class OnlineEntropy(Counter):
    def get_entropy(self):
        s = 0.0
        for count in self.itervalues():
            p = count / float(self.total)
            s += p * math.log(p, 2)
        return -s


class OnlineInformationGain(object):
    def __init__(self, attribute, target):
        self.attribute = attribute
        self.H = OnlineEntropy(target)
        self.G = defaultdict(lambda: OnlineEntropy(target))

    def add(self, example):
        self.H.add(example)
        value = self.attribute(example)
        self.G[value].add(example)

    def get_target_class_counts(self):
        return self.H

    def get_branches(self):
        return self.G.items()

    def get_gain(self):
        H1 = self.H.get_entropy()
        H2 = 0.0
        for G in self.G.itervalues():
            w = G.total / float(self.H.total)
            H2 += w * G.get_entropy()
        return H1 - H2


class OnlineLogProbability(object):
    def __init__(self):
        self.d = defaultdict(int)
        self._logtotal = None

    def add(self, x):
        if self._logtotal is not None:
            raise ValueError("OnlineLogProbability is frozen since first read")
        self.d[x] += 1

    def __getitem__(self, x):
        if x not in self:
            raise KeyError(x)
        if self._logtotal is None:
            self._logtotal = numpy.log(sum(self.d.itervalues()))
        return numpy.log(self.d[x]) - self._logtotal

    def __contains__(self, x):
        return x in self.d

    def __iter__(self):
        return iter(self.d)

    def __len__(self):
        return len(self.d)

    def iteritems(self):
        for x in self.d:
            yield x, self[x]

########NEW FILE########
__FILENAME__ = models
#!/usr/bin/env python
# coding: utf-8

"""
Basic API for modeling a classification problem.
"""

try:
    import cPickle as pickle
except ImportError:
    import pickle


class Classifier(object):
    """
    Base of all classifiers.
    This specifies the classifier API.

    Each classifier holds at least a dataset and a ClassificationProblem.
    """

    def __init__(self, dataset, problem):
        self.dataset = dataset
        self.problem = problem
        self.learn()

    def learn(self):
        """
        Does the training. Returns nothing.
        """
        raise NotImplementedError()

    @property
    def attributes(self):
        """
        The attributes of the problem.
        A list of callable objects.
        """
        return self.problem.attributes

    @property
    def target(self):
        """
        The problem's target.
        A callable that takes an observation and returns the correct
        classification for it.
        """
        return self.problem.target

    def classify(self, example):
        """
        Returns the classification for example.
        """
        raise NotImplementedError()

    def save(self, filepath):
        """
        Pickles the tree and saves it into `filepath`
        """

        if not filepath or not isinstance(filepath, basestring):
            raise ValueError("Invalid filepath")

        # Removes dataset so is not saved in the pickle
        self.dataset = None
        with open(filepath, "w") as filehandler:
            pickle.dump(self, filehandler)

    def distance(self, a, b):
        """
        Custom distance between `a` and `b`.
        """
        raise NotImplementedError()

    @classmethod
    def load(cls, filepath):
        """
        Loads a pickled version of the classifier saved in `filepath`
        """
        with open(filepath) as filehandler:
            classifier = pickle.load(filehandler)

        if not isinstance(classifier, Classifier):
            raise ValueError("Pickled object is not a Classifier")

        return classifier


class ClassificationProblem(object):
    """
    Abstract representation of a classification problem.
    It holds the attributes to be tested and defines them
    "target" of an example.

    You can define attributes by adding them to the `attributes`
    list or by defining a method and decorating it with `is_attribute`.

    The target method returns the real classification of an example from
    the dataset.
    """

    def __init__(self):
        self._load_self_attributes()

    def _load_self_attributes(self, attrs=None):
        if attrs is None:
            attrs = []
        for name in dir(self):
            method = getattr(self, name)
            if hasattr(method, "is_attribute"):
                attr = Attribute(method, method.name)
                attrs.append(attr)
        self.attributes = attrs
        # This sort is useful in cases where attributes are feeded vectorized
        # to the classifier (like SVMs) and you want to pickle and unpickle it
        # safely.
        # Requieres attributes to have names.
        self.attributes.sort(key=lambda attr: attr.name)

    def target(self, example):
        """
        Given an example it returns the classification for that
        example.
        """
        raise NotImplementedError()

    def __getstate__(self):
        # For pickle-ability of method objects
        attributes = [a for a in self.attributes
                      if not hasattr(a.function, "is_attribute")]
        d = dict(self.__dict__)
        d["attributes"] = attributes
        return d

    def __setstate__(self, d):
        # For pickle-ability
        for name, value in d.iteritems():
            setattr(self, name, value)
        self._load_self_attributes(self.attributes)


class VectorDataClassificationProblem(ClassificationProblem):
    """
    A classification problem that defines attribute for a dataset
    that is a set of vectors. An attribute for each index of the
    vector is created.
    """

    def __init__(self, dataset, target_index):
        """
        `dataset` should be an iterable, *not* an iterator.
        `target_index` is the index in the vector where the classification
        of an example is defined.
        """
        super(VectorDataClassificationProblem, self).__init__()
        try:
            example = next(iter(dataset))
        except StopIteration:
            raise ValueError("Dataset is empty")

        self.target_index = target_index

        N = len(example)
        if self.target_index < 0:  # Negative number allowed, counts in reverse
            self.target_index = N + self.target_index
        if self.target_index < 0 or N <= self.target_index:
            raise ValueError("Target index is out of range")
        for i in xrange(N):
            if i == self.target_index:
                continue
            attribute = VectorIndexAttribute(i, "data at index {}".format(i))
            self.attributes.append(attribute)

    def target(self, example):
        """
        Uses the target defined in the creation of the vector problem
        to return the target of `example`.
        """
        return example[self.target_index]


class Attribute(object):
    """
    Abstract base of an attribute, a feature to be tested on the
    examples.
    """

    def __init__(self, function=None, name=None, description=None):
        """
        Creates an attribute with `function`.
        Adds a name and a description if it's specified.
        """
        self.name = name
        self.function = function
        self.description = description

    def reason(self, example):
        """
        Returns a string with an explanation of
        why the attribute is being applied.
        """
        raise NotImplementedError()

    def __call__(self, example):
        return self.function(example)

    def __str__(self):
        if self.name is None:
            return "<undefined name>"
        return self.name


class VectorIndexAttribute(Attribute):
    """
    Attribute that returns the n-th element from a vector.
    """

    def __init__(self, n, name=None, description=None):
        super(VectorIndexAttribute, self).__init__(self, name, description)
        self.n = n

    def reason(self, vector):
        message = "{} is the {}-th element of the vector"
        return message.format(vector[self.n], self.n)

    def __call__(self, vector):
        return vector[self.n]


def is_attribute(method, name=None):
    """
    Decorator for methods that are attributes.
    """
    if name is None:
        name = method.__name__
    method.is_attribute = True
    method.name = name
    return method

########NEW FILE########
__FILENAME__ = reinforcement_learning
# -*- coding: utf-8 -*-
from collections import defaultdict, Counter
import math
import random
from simpleai.search.utils import argmax
import pickle
try:
    import matplotlib.pyplot as plt
    import numpy
except:
    plt = None  # lint:ok
    numpy = None  # lint:ok


def make_at_least_n_times(optimistic_reward, min_n):
    def at_least_n_times_exploration(actions, utilities, temperature, action_counter):
        utilities = [utilities[x] for x in actions]
        for i, utility in enumerate(utilities):
            if action_counter[actions[i]] < min_n:
                utilities[i] = optimistic_reward
        d = dict(zip(actions, utilities))
        uf = lambda action: d[action]
        return argmax(actions, uf)

    return at_least_n_times_exploration


def boltzmann_exploration(actions, utilities, temperature, action_counter):
    '''returns an action with a probability depending on utilities and temperature'''
    utilities = [utilities[x] for x in actions]
    temperature = max(temperature, 0.01)
    _max = max(utilities)
    _min = min(utilities)
    if _max == _min:
        return random.choice(actions)

    utilities = [math.exp(((u - _min) / (_max - _min)) / temperature) for u in utilities]
    probs = [u / sum(utilities) for u in utilities]
    i = 0
    tot = probs[i]
    r = random.random()
    while i < len(actions) and r >= tot:
        i += 1
        tot += probs[i]
    return actions[i]


def make_exponential_temperature(initial_temperature, alpha):
    '''returns a function like initial / exp(n * alpha)'''
    def _function(n):
        try:
            return initial_temperature / math.exp(n * alpha)
        except OverflowError:
            return 0.01
    return _function


class PerformanceCounter(object):

    def __init__(self, learners, names=None):
        self.learners = learners
        for i, learner in enumerate(learners):
            self.update_set_reward(learner)
            learner.accumulated_rewards = []
            learner.known_states = []
            learner.temperatures = []
            if names is None:
                learner.name = 'Learner %d' % i
            else:
                learner.name = names[i]

    def update_set_reward(self, learner):
        def set_reward(reward, terminal=False):
            if terminal:
                if len(learner.accumulated_rewards) > 0:
                    learner.accumulated_rewards.append(learner.accumulated_rewards[-1] + reward)
                else:
                    learner.accumulated_rewards.append(reward)
                learner.known_states.append(len(learner.Q))
                learner.temperatures.append(learner.temperature_function(learner.trials))
            learner.old_set_reward(reward, terminal)
        learner.old_set_reward = learner.set_reward
        learner.set_reward = set_reward

    def _make_plot(self, ax, data_name):
        for learner in self.learners:
            data = numpy.array(getattr(learner, data_name))
            ax.plot(numpy.arange(len(data)), data, label=learner.name)
        nice_name = data_name.replace('_', ' ').capitalize()
        ax.set_title(nice_name)
        ax.legend()

    def show_statistics(self):
        f, (ax1, ax2, ax3) = plt.subplots(3, 1, sharex=True)
        self._make_plot(ax1, 'accumulated_rewards')
        self._make_plot(ax2, 'known_states')
        self._make_plot(ax3, 'temperatures')
        plt.show()


class RLProblem(object):

    def actions(self, state):
        '''Returns the actions available to perform from `state`.
           The returned value is an iterable over actions.
        '''
        raise NotImplementedError()

    def update_state(self, percept, agent):
        'Override this method if you need to clean perception to a given agent'
        return percept


def inverse(n):
    if n == 0:
        return 1
    return 1.0 / n


def state_default():
    return defaultdict(int)


class QLearner(object):

    def __init__(self, problem, temperature_function=inverse,
                 discount_factor=1,
                 exploration_function=boltzmann_exploration,
                 learning_rate=inverse):

        self.Q = defaultdict(state_default)
        self.problem = problem
        self.discount_factor = discount_factor
        self.temperature_function = temperature_function
        self.exploration_function = exploration_function
        self.learning_rate = learning_rate

        self.last_state = None
        self.last_action = None
        self.last_reward = None
        self.counter = defaultdict(Counter)
        self.trials = 0

    def set_reward(self, reward, terminal=False):
        self.last_reward = reward
        if terminal:
            self.trials += 1
            self.Q[self.last_state][self.last_action] = reward

    def program(self, percept):
        s = self.last_state
        a = self.last_action

        state = self.problem.update_state(percept, self)
        actions = self.problem.actions(state)

        if len(actions) > 0:
            current_action = self.exploration_function(actions, self.Q[state],
                                                       self.temperature_function(self.trials),
                                                       self.counter[state])
        else:
            current_action = None

        if s is not None and current_action:
            self.counter[s][a] += 1
            self.update_rule(s, a, self.last_reward, state, current_action)

        self.last_state = state
        self.last_action = current_action
        return current_action

    def update_rule(self, s, a, r, cs, ca):
        raise NotImplementedError

    def dump(self, path):
        self.temperature_function = inverse
        with open(path, 'wb') as f:
            pickle.dump(self, f)

    @classmethod
    def load(self, path):
        with open(path, 'rb') as f:
            return pickle.load(f)


class TDQLearner(QLearner):

    def update_rule(self, s, a, r, cs, ca):
        lr = self.learning_rate(self.counter[s][a])
        self.Q[s][a] += lr * (r + self.discount_factor * max(self.Q[cs].values()) - self.Q[s][a])


class SARSALearner(QLearner):

    def update_rule(self, s, a, r, cs, ca):
        lr = self.learning_rate(self.counter[s][a])
        self.Q[s][a] += lr * (r + self.discount_factor * self.Q[cs][ca] - self.Q[s][a])


########NEW FILE########
__FILENAME__ = arc
# coding: utf-8
from operator import itemgetter

from csp import _call_constraint


# The first 3 functions are exported for testing purposes.
__all__ = ['all_arcs', 'revise', 'arc_consistency_3']

fst = itemgetter(0)


def revise(domains, arc, constraints):
    """
    Given the arc X, Y (variables), removes the values from X's domain that
    do not meet the constraint between X and Y.

    That is, given x1 in X's domain, x1 will be removed from the domain, if
    there is no value y in Y's domain that makes constraint(X,Y) True, for
    those constraints affecting X and Y.
    """
    x, y = arc
    related_constraints = [(neighbors, constraint)
                           for neighbors, constraint in constraints
                           if set(arc) == set(neighbors)]

    modified = False

    for neighbors, constraint in related_constraints:
        for x_value in domains[x]:
            constraint_results = (_call_constraint({x: x_value, y: y_value},
                                                   neighbors, constraint)
                                  for y_value in domains[y])

            if not any(constraint_results):
                domains[x].remove(x_value)
                modified = True

    return modified


def all_arcs(constraints):
    """
    For each constraint ((X, Y), const) adds:
        ((X, Y), const)
        ((Y, X), const)
    """
    arcs = set()

    for neighbors, constraint in constraints:
        if len(neighbors) == 2:
            x, y = neighbors
            map(arcs.add, ((x, y), (y, x)))

    return arcs


def arc_consistency_3(domains, constraints):
    """
    Makes a CSP problem arc consistent.

    Ignores any constraint that is not binary.
    """
    arcs = list(all_arcs(constraints))
    pending_arcs = set(arcs)

    while pending_arcs:
        x, y = pending_arcs.pop()
        if revise(domains, (x, y), constraints):
            if len(domains[x]) == 0:
                return False
            pending_arcs = pending_arcs.union((x2, y2) for x2, y2 in arcs
                                              if y2 == x)
    return True

########NEW FILE########
__FILENAME__ = csp
# coding=utf-8
import random
from copy import deepcopy, copy
from itertools import product
from utils import argmin

MOST_CONSTRAINED_VARIABLE = 'mcv'
HIGHEST_DEGREE_VARIABLE = 'degree'
LEAST_CONSTRAINING_VALUE = 'lvc'


def backtrack(problem, variable_heuristic='', value_heuristic='', inference=True):
    '''
    Backtracking search.

    variable_heuristic is the heuristic for variable choosing, can be
    MOST_CONSTRAINED_VARIABLE, HIGHEST_DEGREE_VARIABLE, or blank for simple
    ordered choosing.
    value_heuristic is the heuristic for value choosing, can be
    LEAST_CONSTRAINING_VALUE or blank for simple ordered choosing.
    '''
    assignment = {}
    domains = deepcopy(problem.domains)

    if variable_heuristic == MOST_CONSTRAINED_VARIABLE:
        variable_chooser = _most_constrained_variable_chooser
    elif variable_heuristic == HIGHEST_DEGREE_VARIABLE:
        variable_chooser = _highest_degree_variable_chooser
    else:
        variable_chooser = _basic_variable_chooser

    if value_heuristic == LEAST_CONSTRAINING_VALUE:
        values_sorter = _least_constraining_values_sorter
    else:
        values_sorter = _basic_values_sorter
    return _backtracking(problem,
                         assignment,
                         domains,
                         variable_chooser,
                         values_sorter,
                         inference=inference)


def _basic_variable_chooser(problem, variables, domains):
    '''
    Choose the next variable in order.
    '''
    return variables[0]


def _most_constrained_variable_chooser(problem, variables, domains):
    '''
    Choose the variable that has less available values.
    '''
    # the variable with fewer values available
    return sorted(variables, key=lambda v: len(domains[v]))[0]


def _highest_degree_variable_chooser(problem, variables, domains):
    '''
    Choose the variable that is involved on more constraints.
    '''
    # the variable involved in more constraints
    return sorted(variables, key=lambda v: problem.var_degrees[v], reverse=True)[0]


def _count_conflicts(problem, assignment, variable=None, value=None):
    '''
    Count the number of violated constraints on a given assignment.
    '''
    return len(_find_conflicts(problem, assignment, variable, value))


def _call_constraint(assignment, neighbors, constraint):
    variables, values = zip(*[(n, assignment[n])
                              for n in neighbors])
    return constraint(variables, values)


def _find_conflicts(problem, assignment, variable=None, value=None):
    '''
    Find violated constraints on a given assignment, with the possibility
    of specifying a new variable and value to add to the assignment before
    checking.
    '''
    if variable is not None and value is not None:
        assignment = deepcopy(assignment)
        assignment[variable] = value

    conflicts = []
    for neighbors, constraint in problem.constraints:
        # if all the neighbors on the constraint have values, check if conflict
        if all(n in assignment for n in neighbors):
            if not _call_constraint(assignment, neighbors, constraint):
                conflicts.append((neighbors, constraint))

    return conflicts


def _basic_values_sorter(problem, assignment, variable, domains):
    '''
    Sort values in the same original order.
    '''
    return domains[variable][:]


def _least_constraining_values_sorter(problem, assignment, variable, domains):
    '''
    Sort values based on how many conflicts they generate if assigned.
    '''
    # the value that generates less conflicts
    def update_assignment(value):
        new_assignment = deepcopy(assignment)
        new_assignment[variable] = value
        return new_assignment

    values = sorted(domains[variable][:],
                    key=lambda v: _count_conflicts(problem, assignment,
                                                   variable, v))
    return values


def _backtracking(problem, assignment, domains, variable_chooser, values_sorter, inference=True):
    '''
    Internal recursive backtracking algorithm.
    '''
    from arc import arc_consistency_3
    if len(assignment) == len(problem.variables):
        return assignment

    pending = [v for v in problem.variables
               if v not in assignment]
    variable = variable_chooser(problem, pending, domains)

    values = values_sorter(problem, assignment, variable, domains)

    for value in values:
        new_assignment = deepcopy(assignment)
        new_assignment[variable] = value

        if not _count_conflicts(problem, new_assignment):  # TODO on aima also checks if using fc
            new_domains = deepcopy(domains)
            new_domains[variable] = [value]

            if not inference or arc_consistency_3(new_domains, problem.constraints):
                result = _backtracking(problem,
                                       new_assignment,
                                       new_domains,
                                       variable_chooser,
                                       values_sorter,
                                       inference=inference)
                if result:
                    return result

    return None


def _min_conflicts_value(problem, assignment, variable):
    '''
    Return the value generate the less number of conflicts.
    In case of tie, a random value is selected among this values subset.
    '''
    return argmin(problem.domains[variable], lambda x: _count_conflicts(problem, assignment, variable, x))


def min_conflicts(problem, initial_assignment=None, iterations_limit=0):
    """
    Min conflicts search.

    initial_assignment the initial assignment, or None to generate a random
    one.
    If iterations_limit is specified, the algorithm will end after that
    number of iterations. Else, it will continue until if finds an assignment
    that doesn't generate conflicts (a solution).
    """
    assignment = {}
    if initial_assignment:
        assignment.update(initial_assignment)
    else:
        for variable in problem.variables:
            value = _min_conflicts_value(problem, assignment, variable)
            assignment[variable] = value

    iteration = 0
    run = True
    while run:
        conflicts = _find_conflicts(problem, assignment)

        conflict_variables = [v for v in problem.variables
                              if any(v in conflict[0] for conflict in conflicts)]

        if conflict_variables:
            variable = random.choice(conflict_variables)
            value = _min_conflicts_value(problem, assignment, variable)
            assignment[variable] = value

        iteration += 1

        if iterations_limit and iteration >= iterations_limit:
            run = False
        elif not _count_conflicts(problem, assignment):
            run = False

    return assignment


def convert_to_binary(variables, domains, constraints):
    """
    Returns new constraint list, all binary, using hidden variables.

    You can use it as previous step when creating a problem.
    """

    def wdiff(vars_):
        def diff(variables, values):
            hidden, other = variables
            if hidden.startswith('hidden'):
                idx = vars_.index(other)
                return values[1] == values[0][idx]
            else:
                idx = vars_.index(hidden)
                return values[0] == values[1][idx]
        diff.no_wrap = True  # so it's not wrapped to swap values
        return diff

    new_constraints = []
    new_domains = copy(domains)
    new_variables = list(variables)
    last = 0

    for vars_, const in constraints:
        if len(vars_) == 2:
            new_constraints.append((vars_, const))
            continue

        hidden = 'hidden%d' % last
        new_variables.append(hidden)
        last += 1
        new_domains[hidden] = [t for t in product(*map(domains.get, vars_)) if const(vars_, t)]
        for var in vars_:
            new_constraints.append(((hidden, var), wdiff(vars_)))
    return new_variables, new_domains, new_constraints

########NEW FILE########
__FILENAME__ = local
# coding=utf-8
from simpleai.search.utils import BoundedPriorityQueue, InverseTransformSampler
from simpleai.search.models import SearchNodeValueOrdered
import math
import random


def _all_expander(fringe, iteration, viewer):
    '''
    Expander that expands all nodes on the fringe.
    '''
    expanded_neighbors = [node.expand(local_search=True)
                          for node in fringe]

    if viewer:
        viewer.event('expanded', list(fringe), expanded_neighbors)

    map(fringe.extend, expanded_neighbors)


def beam(problem, beam_size=100, iterations_limit=0, viewer=None):
    '''
    Beam search.

    beam_size is the size of the beam.
    If iterations_limit is specified, the algorithm will end after that
    number of iterations. Else, it will continue until it can't find a
    better node than the current one.
    Requires: SearchProblem.actions, SearchProblem.result, SearchProblem.value,
    and SearchProblem.generate_random_state.
    '''
    return _local_search(problem,
                         _all_expander,
                         iterations_limit=iterations_limit,
                         fringe_size=beam_size,
                         random_initial_states=True,
                         stop_when_no_better=iterations_limit==0,
                         viewer=viewer)


def _first_expander(fringe, iteration, viewer):
    '''
    Expander that expands only the first node on the fringe.
    '''
    current = fringe[0]
    neighbors = current.expand(local_search=True)

    if viewer:
        viewer.event('expanded', [current], [neighbors])

    fringe.extend(neighbors)



def beam_best_first(problem, beam_size=100, iterations_limit=0, viewer=None):
    '''
    Beam search best first.

    beam_size is the size of the beam.
    If iterations_limit is specified, the algorithm will end after that
    number of iterations. Else, it will continue until it can't find a
    better node than the current one.
    Requires: SearchProblem.actions, SearchProblem.result, and
    SearchProblem.value.
    '''
    return _local_search(problem,
                         _first_expander,
                         iterations_limit=iterations_limit,
                         fringe_size=beam_size,
                         random_initial_states=True,
                         stop_when_no_better=iterations_limit==0,
                         viewer=viewer)


def hill_climbing(problem, iterations_limit=0, viewer=None):
    '''
    Hill climbing search.

    If iterations_limit is specified, the algorithm will end after that
    number of iterations. Else, it will continue until it can't find a
    better node than the current one.
    Requires: SearchProblem.actions, SearchProblem.result, and
    SearchProblem.value.
    '''
    return _local_search(problem,
                         _first_expander,
                         iterations_limit=iterations_limit,
                         fringe_size=1,
                         stop_when_no_better=True,
                         viewer=viewer)


def _random_best_expander(fringe, iteration, viewer):
    '''
    Expander that expands one randomly chosen nodes on the fringe that
    is better than the current (first) node.
    '''
    current = fringe[0]
    neighbors = current.expand(local_search=True)
    if viewer:
        viewer.event('expanded', [current], [neighbors])

    betters = [n for n in neighbors
               if n.value > current.value]
    if betters:
        chosen = random.choice(betters)
        if viewer:
            viewer.event('chosen_node', chosen)
        fringe.append(chosen)


def hill_climbing_stochastic(problem, iterations_limit=0, viewer=None):
    '''
    Stochastic hill climbing.

    If iterations_limit is specified, the algorithm will end after that
    number of iterations. Else, it will continue until it can't find a
    better node than the current one.
    Requires: SearchProblem.actions, SearchProblem.result, and
    SearchProblem.value.
    '''
    return _local_search(problem,
                         _random_best_expander,
                         iterations_limit=iterations_limit,
                         fringe_size=1,
                         stop_when_no_better=iterations_limit==0,
                         viewer=viewer)


def hill_climbing_random_restarts(problem, restarts_limit, iterations_limit=0, viewer=None):
    '''
    Hill climbing with random restarts.

    restarts_limit specifies the number of times hill_climbing will be runned.
    If iterations_limit is specified, each hill_climbing will end after that
    number of iterations. Else, it will continue until it can't find a
    better node than the current one.
    Requires: SearchProblem.actions, SearchProblem.result, SearchProblem.value,
    and SearchProblem.generate_random_state.
    '''
    restarts = 0
    best = None

    while restarts < restarts_limit:
        new = _local_search(problem,
                            _first_expander,
                            iterations_limit=iterations_limit,
                            fringe_size=1,
                            random_initial_states=True,
                            stop_when_no_better=True,
                            viewer=viewer)

        if not best or best.value < new.value:
            best = new

        restarts += 1

    if viewer:
        viewer.event('no_more_runs', best, 'returned after %i runs' % restarts_limit)

    return best


# Math literally copied from aima-python
def _exp_schedule(iteration, k=20, lam=0.005, limit=100):
    '''
    Possible scheduler for simulated_annealing, based on the aima example.
    '''
    return k * math.exp(-lam * iteration)


def _create_simulated_annealing_expander(schedule):
    '''
    Creates an expander that has a random chance to choose a node that is worse
    than the current (first) node, but that chance decreases with time.
    '''
    def _expander(fringe, iteration, viewer):
        T = schedule(iteration)
        current = fringe[0]
        neighbors = current.expand(local_search=True)

        if viewer:
            viewer.event('expanded', [current], [neighbors])

        if neighbors:
            succ = random.choice(neighbors)
            delta_e = succ.value - current.value
            if delta_e > 0 or random.random() < math.exp(delta_e / T):
                fringe.pop()
                fringe.append(succ)

                if viewer:
                    viewer.event('chosen_node', succ)

    return _expander


def simulated_annealing(problem, schedule=_exp_schedule, iterations_limit=0, viewer=None):
    '''
    Simulated annealing.

    schedule is the scheduling function that decides the chance to choose worst
    nodes depending on the time.
    If iterations_limit is specified, the algorithm will end after that
    number of iterations. Else, it will continue until it can't find a
    better node than the current one.
    Requires: SearchProblem.actions, SearchProblem.result, and
    SearchProblem.value.
    '''
    return _local_search(problem,
                         _create_simulated_annealing_expander(schedule),
                         iterations_limit=iterations_limit,
                         fringe_size=1,
                         stop_when_no_better=iterations_limit==0,
                         viewer=viewer)


def _create_genetic_expander(problem, mutation_chance):
    '''
    Creates an expander that expands the bests nodes of the population,
    crossing over them.
    '''
    def _expander(fringe, iteration, viewer):
        fitness = [x.value for x in fringe]
        sampler = InverseTransformSampler(fitness, fringe)
        new_generation = []

        expanded_nodes = []
        expanded_neighbors = []

        for _ in fringe:
            node1 = sampler.sample()
            node2 = sampler.sample()
            child = problem.crossover(node1.state, node2.state)
            action = 'crossover'
            if random.random() < mutation_chance:
                # Noooouuu! she is... he is... *IT* is a mutant!
                child = problem.mutate(child)
                action += '+mutation'

            child_node = SearchNodeValueOrdered(state=child, problem=problem, action=action)
            new_generation.append(child_node)

            expanded_nodes.append(node1)
            expanded_neighbors.append([child_node])
            expanded_nodes.append(node2)
            expanded_neighbors.append([child_node])

        if viewer:
            viewer.event('expanded', expanded_nodes, expanded_neighbors)

        fringe.clear()
        for node in new_generation:
            fringe.append(node)

    return _expander


def genetic(problem, population_size=100, mutation_chance=0.1,
            iterations_limit=0, viewer=None):
    '''
    Genetic search.

    population_size specifies the size of the population (ORLY).
    mutation_chance specifies the probability of a mutation on a child,
    varying from 0 to 1.
    If iterations_limit is specified, the algorithm will end after that
    number of iterations. Else, it will continue until it can't find a
    better node than the current one.
    Requires: SearchProblem.generate_random_state, SearchProblem.crossover,
    SearchProblem.mutate and SearchProblem.value.
    '''
    return _local_search(problem,
                         _create_genetic_expander(problem, mutation_chance),
                         iterations_limit=iterations_limit,
                         fringe_size=population_size,
                         random_initial_states=True,
                         stop_when_no_better=iterations_limit==0,
                         viewer=viewer)


def _local_search(problem, fringe_expander, iterations_limit=0, fringe_size=1,
                  random_initial_states=False, stop_when_no_better=True,
                  viewer=None):
    '''
    Basic algorithm for all local search algorithms.
    '''
    if viewer:
        viewer.event('started')

    fringe = BoundedPriorityQueue(fringe_size)
    if random_initial_states:
        for _ in xrange(fringe_size):
            s = problem.generate_random_state()
            fringe.append(SearchNodeValueOrdered(state=s, problem=problem))
    else:
        fringe.append(SearchNodeValueOrdered(state=problem.initial_state,
                                             problem=problem))

    finish_reason = ''
    iteration = 0
    run = True
    best = None

    while run:
        if viewer:
            viewer.event('new_iteration', list(fringe))

        old_best = fringe[0]
        fringe_expander(fringe, iteration, viewer)
        best = fringe[0]

        iteration += 1

        if iterations_limit and iteration >= iterations_limit:
            run = False
            finish_reason = 'reaching iteration limit'
        elif old_best.value >= best.value and stop_when_no_better:
            run = False
            finish_reason = 'not being able to improve solution'

    if viewer:
        viewer.event('finished', fringe, best, 'returned after %s' % finish_reason)

    return best

########NEW FILE########
__FILENAME__ = models
# coding=utf-8


class SearchProblem(object):
    '''Abstract base class to represent and manipulate the search space of a
       problem.
       In this class, the search space is meant to be represented implicitly as
       a graph.
       Each state corresponds with a problem state (ie, a valid configuration)
       and each problem action (ie, a valid transformation to a configuracion)
       corresponds with an edge.

       To use this class you should implement the methods required by the search
       algorithm you will use.
       '''

    def __init__(self, initial_state=None):
        self.initial_state = initial_state

    def actions(self, state):
        '''Returns the actions available to perform from `state`.
           The returned value is an iterable over actions.
           Actions are problem-specific and no assumption should be made about
           them.
        '''
        raise NotImplementedError

    def result(self, state, action):
        '''Returns the resulting state of applying `action` to `state`.'''
        raise NotImplementedError

    def cost(self, state, action, state2):
        '''Returns the cost of applying `action` from `state` to `state2`.
           The returned value is a number (integer or floating point).
           By default this function returns `1`.
        '''
        return 1

    def is_goal(self, state):
        '''Returns `True` if `state` is a goal state and `False` otherwise'''
        raise NotImplementedError

    def value(self, state):
        '''Returns the value of `state` as it is needed by optimization
           problems.
           Value is a number (integer or floating point).'''
        raise NotImplementedError

    def heuristic(self, state):
        '''Returns an estimate of the cost remaining to reach the solution
           from `state`.'''
        return 0

    def crossover(self, state1, state2):
        """
        Crossover method for genetic search. It should return a new state that
        is the 'mix' (somehow) of `state1` and `state2`.
        """
        raise NotImplementedError

    def mutate(self, state):
        """
        Mutation method for genetic search. It should return a new state that
        is a slight random variation of `state`.
        """
        raise NotImplementedError

    def generate_random_state(self):
        """
        Generates a random state for genetic search. It's mainly used for the
        seed states in the initilization of genetic search.
        """
        raise NotImplementedError

    def state_representation(self, state):
        """
        Returns a string representation of a state.
        By default it returns str(state).
        """
        return str(state)

    def action_representation(self, action):
        """
        Returns a string representation of an action.
        By default it returns str(action).
        """
        return str(action)


class SearchNode(object):
    '''Node of a search process.'''

    def __init__(self, state, parent=None, action=None, cost=0, problem=None,
                 depth=0):
        self.state = state
        self.parent = parent
        self.action = action
        self.cost = cost
        self.problem = problem or parent.problem
        self.depth = depth

    def expand(self, local_search=False):
        '''Create successors.'''
        new_nodes = []
        for action in self.problem.actions(self.state):
            new_state = self.problem.result(self.state, action)
            cost = self.problem.cost(self.state,
                                     action,
                                     new_state)
            nodefactory = self.__class__
            new_nodes.append(nodefactory(state=new_state,
                                         parent=None if local_search else self,
                                         problem=self.problem,
                                         action=action,
                                         cost=self.cost + cost,
                                         depth=self.depth + 1))
        return new_nodes

    def path(self):
        '''Path (list of nodes and actions) from root to this node.'''
        node = self
        path = []
        while node:
            path.append((node.action, node.state))
            node = node.parent
        return list(reversed(path))

    def __eq__(self, other):
        return isinstance(other, SearchNode) and self.state == other.state

    def state_representation(self):
        return self.problem.state_representation(self.state)

    def action_representation(self):
        return self.problem.action_representation(self.action)

    def __repr__(self):
        return 'Node <%s>' % self.state_representation().replace('\n', ' ')


class SearchNodeCostOrdered(SearchNode):
    def __lt__(self, other):
        return self.cost < other.cost


class SearchNodeValueOrdered(SearchNode):
    def __init__(self, *args, **kwargs):
        super(SearchNodeValueOrdered, self).__init__(*args, **kwargs)
        self.value = self.problem.value(self.state)

    def __lt__(self, other):
        # value must work inverted, because heapq sorts 1-9
        # and we need 9-1 sorting
        return -self.value < -other.value


class SearchNodeHeuristicOrdered(SearchNode):
    def __init__(self, *args, **kwargs):
        super(SearchNodeHeuristicOrdered, self).__init__(*args, **kwargs)
        self.heuristic = self.problem.heuristic(self.state)

    def __lt__(self, other):
        return self.heuristic < other.heuristic


class SearchNodeStarOrdered(SearchNodeHeuristicOrdered):
    def __lt__(self, other):
        return self.heuristic + self.cost < other.heuristic + other.cost


class CspProblem(object):
    def __init__(self, variables, domains, constraints):
        self.variables = variables
        self.domains = domains
        self.constraints = constraints

        # variable-based constraints dict
        self.var_contraints = dict([(v, [constraint
                                         for constraint in constraints
                                         if v in constraint[0]])
                                    for v in variables])

        # calculate degree of each variable
        self.var_degrees = dict([(v, len(self.var_contraints[v]))
                                 for v in variables])

########NEW FILE########
__FILENAME__ = traditional
# coding=utf-8
from simpleai.search.utils import FifoList, BoundedPriorityQueue, LifoList
from simpleai.search.models import (SearchNode, SearchNodeHeuristicOrdered,
                                    SearchNodeStarOrdered,
                                    SearchNodeCostOrdered)


def breadth_first(problem, graph_search=False, viewer=None):
    '''
    Breadth first search.

    If graph_search=True, will avoid exploring repeated states.
    Requires: SearchProblem.actions, SearchProblem.result, and
    SearchProblem.is_goal.
    '''
    return _search(problem,
                   FifoList(),
                   graph_search=graph_search,
                   viewer=viewer)


def depth_first(problem, graph_search=False, viewer=None):
    '''
    Depth first search.

    If graph_search=True, will avoid exploring repeated states.
    Requires: SearchProblem.actions, SearchProblem.result, and
    SearchProblem.is_goal.
    '''
    return _search(problem,
                   LifoList(),
                   graph_search=graph_search,
                   viewer=viewer)


def limited_depth_first(problem, depth_limit, graph_search=False, viewer=None):
    '''
    Limited depth first search.

    Depth_limit is the maximum depth allowed, being depth 0 the initial state.
    If graph_search=True, will avoid exploring repeated states.
    Requires: SearchProblem.actions, SearchProblem.result, and
    SearchProblem.is_goal.
    '''
    return _search(problem,
                   LifoList(),
                   graph_search=graph_search,
                   depth_limit=depth_limit,
                   viewer=viewer)


def iterative_limited_depth_first(problem, graph_search=False, viewer=None):
    '''
    Iterative limited depth first search.

    If graph_search=True, will avoid exploring repeated states.
    Requires: SearchProblem.actions, SearchProblem.result, and
    SearchProblem.is_goal.
    '''
    solution = None
    limit = 0

    while not solution:
        solution = limited_depth_first(problem,
                                       depth_limit=limit,
                                       graph_search=graph_search,
                                       viewer=viewer)
        limit += 1

    if viewer:
        viewer.event('no_more_runs', solution, 'returned after %i runs' % limit)

    return solution


def uniform_cost(problem, graph_search=False, viewer=None):
    '''
    Uniform cost search.

    If graph_search=True, will avoid exploring repeated states.
    Requires: SearchProblem.actions, SearchProblem.result,
    SearchProblem.is_goal, and SearchProblem.cost.
    '''
    return _search(problem,
                   BoundedPriorityQueue(),
                   graph_search=graph_search,
                   node_factory=SearchNodeCostOrdered,
                   graph_replace_when_better=True,
                   viewer=viewer)


def greedy(problem, graph_search=False, viewer=None):
    '''
    Greedy search.

    If graph_search=True, will avoid exploring repeated states.
    Requires: SearchProblem.actions, SearchProblem.result,
    SearchProblem.is_goal, SearchProblem.cost, and SearchProblem.heuristic.
    '''
    return _search(problem,
                   BoundedPriorityQueue(),
                   graph_search=graph_search,
                   node_factory=SearchNodeHeuristicOrdered,
                   graph_replace_when_better=True,
                   viewer=viewer)


def astar(problem, graph_search=False, viewer=None):
    '''
    A* search.

    If graph_search=True, will avoid exploring repeated states.
    Requires: SearchProblem.actions, SearchProblem.result,
    SearchProblem.is_goal, SearchProblem.cost, and SearchProblem.heuristic.
    '''
    return _search(problem,
                   BoundedPriorityQueue(),
                   graph_search=graph_search,
                   node_factory=SearchNodeStarOrdered,
                   graph_replace_when_better=True,
                   viewer=viewer)


def _search(problem, fringe, graph_search=False, depth_limit=None,
            node_factory=SearchNode, graph_replace_when_better=False,
            viewer=None):
    '''
    Basic search algorithm, base of all the other search algorithms.
    '''
    if viewer:
        viewer.event('started')

    memory = set()
    initial_node = node_factory(state=problem.initial_state,
                                problem=problem)
    fringe.append(initial_node)

    while fringe:
        if viewer:
            viewer.event('new_iteration', fringe.sorted())

        node = fringe.pop()

        if problem.is_goal(node.state):
            if viewer:
                viewer.event('chosen_node', node, True)
                viewer.event('finished', fringe.sorted(), node, 'goal found')
            return node
        else:
            if viewer:
                viewer.event('chosen_node', node, False)

        memory.add(node.state)

        if depth_limit is None or node.depth < depth_limit:
            expanded = node.expand()
            if viewer:
                viewer.event('expanded', [node], [expanded])

            for n in expanded:
                if graph_search:
                    others = [x for x in fringe if x.state == n.state]
                    assert len(others) in (0, 1)
                    if n.state not in memory and len(others) == 0:
                        fringe.append(n)
                    elif graph_replace_when_better and len(others) > 0 and n < others[0]:
                        fringe.remove(others[0])
                        fringe.append(n)
                else:
                    fringe.append(n)

    if viewer:
        viewer.event('finished', fringe.sorted(), None, 'goal not found')

########NEW FILE########
__FILENAME__ = utils
# coding=utf-8
import heapq
from collections import deque
from itertools import izip
import random


class LifoList(deque):
    '''List that pops from the end.'''

    def sorted(self):
        return list(self)[::-1]


class FifoList(deque):
    '''List that pops from the beginning.'''
    def pop(self):
        return super(FifoList, self).popleft()

    def sorted(self):
        return list(self)


class BoundedPriorityQueue(object):
    def __init__(self, limit=None, *args):
        self.limit = limit
        self.queue = list()

    def __getitem__(self, val):
        return self.queue[val]

    def __len__(self):
        return len(self.queue)

    def append(self, x):
        heapq.heappush(self.queue, x)
        if self.limit and len(self.queue) > self.limit:
            self.queue.remove(heapq.nlargest(1, self.queue)[0])

    def pop(self):
        return heapq.heappop(self.queue)

    def extend(self, iterable):
        for x in iterable:
            self.append(x)

    def clear(self):
        for x in self:
            self.queue.remove(x)

    def remove(self, x):
        self.queue.remove(x)

    def sorted(self):
        return heapq.nsmallest(len(self.queue), self.queue)


class InverseTransformSampler(object):
    def __init__(self, weights, objects):
        assert weights and objects and len(weights) == len(objects)
        self.objects = objects
        tot = float(sum(weights))
        if tot == 0:
            tot = len(weights)
            weights = [1 for x in weights]
        accumulated = 0
        self.probs = []
        for w, x in izip(weights, objects):
            p = w / tot
            accumulated += p
            self.probs.append(accumulated)

    def sample(self):
        target = random.random()
        i = 0
        while i + 1 != len(self.probs) and target > self.probs[i]:
            i += 1
        return self.objects[i]


def _generic_arg(iterable, function, better_function):
    values = [function(x) for x in iterable]
    better_value = better_function(values)
    candidates = [x for x, value in zip(iterable, values) if value == better_value]
    return random.choice(candidates)


def argmin(iterable, function):
    return _generic_arg(iterable, function, min)


def argmax(iterable, function):
    return _generic_arg(iterable, function, max)

########NEW FILE########
__FILENAME__ = viewers
# coding: utf-8
from os import path
import sys
from tempfile import mkdtemp
from time import sleep
from threading import Thread


class Event(object):
    def __init__(self, name, description):
        self.name = name
        self.description = description

    def __str__(self):
        return self.name


CONSOLE_HELP_TEXT = '''After each step, a prompt will be shown.
On the prompt, you can just press Enter to continue to the next step.
But you can also have this commands:
(write the command you want to use and then press Enter)
* h: get help.
* g PATH_TO_PNG_IMAGE: create png with graph of the current state.
* e: run non-interactively to the end of the algorithm.
* s: show statistics of the execution (max fringe size, visited nodes).
* q: quit program.'''


class BaseViewer(object):
    def __init__(self):
        self.successor_color = '#DD4814'
        self.fringe_color = '#20a0c0'
        self.solution_color = '#adeba8'
        self.font_size = 11

        self.last_event = None
        self.events = []

        self.stats = {
            'max_fringe_size': 0,
            'visited_nodes': 0,
            'iterations': 0,
        }

        self.clear_nodes_data()

    def clear_nodes_data(self):
        self.current_fringe = []
        self.last_chosen = None
        self.last_expandeds = []
        self.last_successors = []

    def event(self, name, *params):
        getattr(self, 'handle_' + name)(*params)

    def log_event(self, name, description):
        self.last_event = Event(name=name,
                                description=description)
        self.events.append(self.last_event)

    def handle_started(self):
        self.clear_nodes_data()
        self.log_event('started', 'Algorithm just started.')

    def handle_new_iteration(self, fringe):
        self.current_fringe = fringe
        self.stats['max_fringe_size'] = max(self.stats['max_fringe_size'], len(fringe))
        self.stats['iterations'] += 1

        description = 'New iteration with %i elements in the fringe:\n%s'
        description = description % (len(fringe), str(fringe))
        self.log_event('new_iteration', description)

    def handle_chosen_node(self, node, is_goal=None):
        self.last_chosen = node
        self.stats['visited_nodes'] += 1

        goal_text = 'Is goal!' if is_goal else 'Not goal'
        description = 'Chosen node: %s' % node
        if is_goal is not None:
            description += '\n' + goal_text
        self.log_event('chosen_node', description)

    def handle_expanded(self, nodes, successors):
        self.last_expandeds, self.last_successors = nodes, successors

        description = 'Expanded %s\nSuccessors: %s'
        description = description % (nodes, successors)
        self.log_event('expanded', description)

    def handle_finished(self, fringe, node, solution_type):
        self.clear_nodes_data()
        self.solution_node = node
        if node:
            self.current_fringe = [node]
        self.solution_type = solution_type

        description = 'Finished algorithm returning %s.\nSolution type: %s'
        description = description % (node, solution_type)

        if node is not None and node.parent is not None:
            description += '\nPath from initial to goal: %s' % str(node.path())
        self.log_event('finished', description)

    def handle_no_more_runs(self, node, solution_type):
        self.clear_nodes_data()
        self.solution_node = node
        if node:
            self.current_fringe = [node]
        self.solution_type = solution_type

        description = 'Finished all of the runs of the inner algorithm returning %s.\nSolution type: %s'
        description = description % (node, solution_type)

        if node is not None and node.parent is not None:
            description += '\nPath from initial to goal: %s' % str(node.path())
        self.log_event('no_more_runs', description)

    def create_graph(self, image_format, image_path):
        from pydot import Dot, Edge, Node

        graph = Dot(graph_type='digraph')

        graph_nodes = {}
        graph_edges = {}
        done = set()

        def add_node(node, expanded=False, chosen=False, in_fringe=False,
                     in_successors=False, solution=False):
            node_id = id(node)
            if node_id not in graph_nodes:
                label = node.state_representation()
                if hasattr(node, 'cost'):
                    label += '\nCost: %s' % node.cost
                if hasattr(node, 'heuristic'):
                    label += '\nHeuristic: %s' % node.heuristic
                if hasattr(node, 'value'):
                    label += '\nValue: %s' % node.value

                new_g_node = Node(node_id,
                                  label=label,
                                  style='filled',
                                  shape='circle',
                                  fillcolor='#ffffff',
                                  fontsize=self.font_size)

                graph_nodes[node_id] = new_g_node

            g_node =  graph_nodes[node_id]

            if expanded or chosen:
                g_node.set_fillcolor(self.fringe_color)
            if in_fringe:
                g_node.set_color(self.fringe_color)
                g_node.set_penwidth(3)
            if in_successors:
                g_node.set_color(self.successor_color)
                g_node.set_fontcolor(self.successor_color)
            if solution:
                g_node.set_fillcolor(self.solution_color)

            return g_node

        def add_edge_to_parent(node, is_successor=False, parent=None):
            if parent is None:
                parent = node.parent

            g_node = add_node(node, in_successors=is_successor)
            g_parent_node = add_node(parent)

            edge = Edge(g_parent_node,
                        g_node,
                        label=node.action_representation(),
                        fontsize=self.font_size)

            if is_successor:
                edge.set_color(self.successor_color)
                edge.set_labelfontcolor(self.successor_color)

            graph_edges[id(node), id(parent)] = edge

        if self.last_event.name == 'chosen_node':
            add_node(self.last_chosen, chosen=True)

        if self.last_event.name == 'finished':
            if self.solution_node:
                add_node(self.solution_node, solution=True)

        if self.last_event.name == 'expanded':
            for node, successors in zip(self.last_expandeds,
                                        self.last_successors):
                add_node(node, expanded=True)
                for successor_node in successors:
                    add_edge_to_parent(successor_node,
                                       is_successor=True,
                                       parent=node)

        for node in self.current_fringe:
            add_node(node, in_fringe=True)
            while node is not None and node not in done:
                if node.parent is not None:
                    add_edge_to_parent(node)
                else:
                    add_node(node)

                done.add(node)
                node = node.parent

        for node_id in sorted(graph_nodes.keys()):
            graph.add_node(graph_nodes[node_id])
        for node_id, parent_id in sorted(graph_edges.keys()):
            graph.add_edge(graph_edges[node_id, parent_id])

        graph.write(image_path, format=image_format)


class ConsoleViewer(BaseViewer):
    def __init__(self, interactive=True):
        super(ConsoleViewer, self).__init__()
        self.interactive = interactive

    def event(self, name, *params):
        if name == 'started':
            self.output(CONSOLE_HELP_TEXT)

        super(ConsoleViewer, self).event(name, *params)

        self.output('EVENT: %s' % self.last_event.name)
        self.output(self.last_event.description)

        self.pause()

    def pause(self):
        prompt = True
        while prompt and self.interactive:
            prompt = False
            option = raw_input('> ').strip()
            if option:
                if option == 'h':
                    self.output(CONSOLE_HELP_TEXT)
                    prompt = True
                elif option == 'e':
                    self.interactive = False
                elif option == 's':
                    self.output('Statistics:')
                    for stat, value in self.stats.items():
                        self.output('%s: %i' % (stat.replace('_', ' '), value))
                    prompt = True
                elif option == 'q':
                    sys.exit()
                elif option.startswith('g ') and len(option) > 2:
                    png_path = option[2:]
                    self.create_graph('png', png_path)
                    self.output('graph saved to %s' % png_path)
                    prompt = True
                else:
                    self.output('Incorrect command')
                    self.output(CONSOLE_HELP_TEXT)
                    self.pause()

    def output(self, text):
        print text


class WebViewer(BaseViewer):
    def __init__(self, host='0.0.0.0', port=8000):
        super(WebViewer, self).__init__()
        self.host = host
        self.port = port
        self.status = 'paused'
        self.creating_graph = False
        self.server_running = False

        tmp_folder = mkdtemp(prefix='simpleai_web_server_')
        self.graph_path = path.join(tmp_folder, 'graph.png')

    def event(self, name, *params):
        if name == 'started':
            self.start_server()

        super(WebViewer, self).event(name, *params)

        self.creating_graph = True
        self.create_graph(self.graph_path.split('.')[-1], self.graph_path)
        self.creating_graph = False

        if self.status == 'running_step':
            self.status = 'paused'

        while self.status == 'paused':
            sleep(0.5)

        sleep(0.5)

    def start_server(self):
        if not self.server_running:
            from web_viewer_server import run_server

            t = Thread(target=run_server, args=[self])
            t.daemon = True
            t.start()

            self.server_running = True

########NEW FILE########
__FILENAME__ = web_viewer_server
# coding: utf-8
import json
from os import path, _exit
from time import sleep
from flask import Flask, Response, send_file


def run_server(viewer):
    resources = path.join(path.dirname(path.realpath(__file__)),
                          'web_viewer_resources')

    app = Flask(__name__,
                static_folder=resources,
                static_path='/static')

    app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 0


    @app.route('/')
    def index():
        return send_file(path.join(resources, 'index.html'))


    @app.route('/graph')
    def graph():
        while viewer.creating_graph:
            sleep(0.1)
        return send_file(viewer.graph_path)


    @app.route('/control/<order>')
    def control(order):
        if order == 'play':
            viewer.status = 'running'
        elif order == 'step':
            viewer.status = 'running_step'
        elif order == 'pause':
            viewer.status = 'paused'
        elif order == 'stop':
            stop_server()

        return 'ok' # TODO should be a json or something


    @app.route('/event_stream')
    def stream():
        def event_stream():
            announced = 0
            while True:
                sleep(0.1)
                if len(viewer.events) > announced:
                    news_limit = len(viewer.events)

                    data = {}
                    data['stats'] = [{'name': stat.replace('_', ' '), 'value': value}
                                     for stat, value in viewer.stats.items()]

                    for event in viewer.events[announced:news_limit]:
                        data['event'] = event.__dict__
                        yield 'data: %s\n\n' % json.dumps(data)

                    announced = news_limit

        return Response(event_stream(), mimetype="text/event-stream")


    try:
        print 'Starting the WebViewer, access it from your web browser, navigating to the address:'
        print 'http://localhost:%i' % viewer.port
        print 'To stop the WebViewer, use the "Stop running" link (on the viewer site, from the browser)'

        app.run(host=viewer.host, port=viewer.port, threaded=True)
    except Exception as err:
        print 'Failed to start the WebViewer. Error:'
        print err
        stop_server()


def stop_server():
    _exit(1)

########NEW FILE########
__FILENAME__ = test_classifiers
#!/usr/bin/env python
# coding: utf-8

"""
Tests for dtree.
"""

import os
import math
import tempfile
import unittest
from collections import defaultdict


from simpleai.machine_learning import evaluation
from simpleai.machine_learning.models import VectorDataClassificationProblem
from simpleai.machine_learning.classifiers import DecisionTreeLearner, \
    DecisionTreeLearner_Queued, DecisionTreeLearner_LargeData, NaiveBayes, \
    KNearestNeighbors


def euclidean_vector_distance(x, y):
    return math.sqrt(sum([(a - b) ** 2 for a, b in zip(x, y)]))


class BaseTestClassifier(object):
    classifier = None

    def setup_dataset(self):
        raise NotImplementedError()

    def setUp(self):
        if self.classifier is None:
            raise NotImplementedError("Choose a classifier")
        self.setup_dataset()
        N = len(self.corpus) / 10
        self.test_set = []
        i = 1
        while len(self.test_set) != N:
            i = (i * 1223) % len(self.corpus) + 1  # "random" number generator
            self.test_set.append(self.corpus.pop(i - 1))
        self.this = self.classifier(self.corpus, self.problem)
        self.attributes = self.problem.attributes
        self.target = self.problem.target

    def test_better_than_majority(self):
        d = defaultdict(int)
        for example in self.corpus:
            d[self.target(example)] += 1
        majority = max(d, key=d.get)

        class MockClassifier(object):
            target = self.target

            def classify(self, example):
                return majority, 1.0

        mock = MockClassifier()
        mock_prec = evaluation.precision(mock, self.test_set)
        this_prec = evaluation.precision(self.this, self.test_set)
        try:
            self.assertGreaterEqual(this_prec, mock_prec)
        except:
            print self.corpus

    def test_tolerates_empty_attributes(self):
        self.problem.attributes = []
        self.this = self.classifier(self.corpus, self.problem)
        evaluation.precision(self.this, self.test_set)

    def test_handles_empty_dataset(self):
        self.assertRaises(ValueError, self.classifier,
                          [], self.problem)

    def test_target_in_attributes(self):
        """
        If target in attributes precision is 1.0.
        """
        self.problem.attributes = [self.target]
        self.this = self.classifier(self.corpus, self.problem)
        prec = evaluation.precision(self.this, self.test_set)
        self.assertEqual(prec, 1.0)

    def test_save_classifier(self):
        _, tmp_filepath = tempfile.mkstemp()

        # Bad values
        self.assertRaises(ValueError, self.this.save, None)
        self.assertRaises(ValueError, self.this.save, "")
        self.assertRaises(ValueError, self.this.save, 42)

        # Save the values before saving the tree
        classification_values = {}
        for test in self.test_set:
            classification_values[tuple(test)] = self.this.classify(test)

        self.this.save(tmp_filepath)
        self.assertTrue(os.path.exists(tmp_filepath))
        self.assertNotEqual(os.stat(tmp_filepath).st_size, 0)  # File not empty

        # The classification must remain equal after saving the dtree
        for test in self.test_set:
            self.assertEqual(classification_values[tuple(test)],
                             self.this.classify(test))

    def test_load(self):
        _, tmp_filepath = tempfile.mkstemp()
        self.this.save(tmp_filepath)

        # Save the values before saving the tree
        classification_values = {}
        for test in self.test_set:
            classification_values[tuple(test)] = self.this.classify(test)

        classifier = self.classifier.load(tmp_filepath)
        self.assertIsInstance(classifier, self.classifier)

        # The classification must remain equal after loading the dtree
        for test in self.test_set:
            self.assertEqual(classification_values[tuple(test)],
                             classifier.classify(test))

    def test_leave_one_out(self):
        fold = evaluation.kfold(self.corpus, self.problem,
                                self.classifier, len(self.corpus))
        self.assertNotEqual(fold, 0)


class BaseTestDtree_Pseudo(BaseTestClassifier):
    classifier = DecisionTreeLearner

    def test_no_target_split(self):
        nodes = [self.this.root]

        while nodes:
            node = nodes.pop()
            self.assertNotEqual(self.target, node.attribute)
            nodes.extend(node.branches.values())


class BaseTestDtree_LargeData(BaseTestDtree_Pseudo):
    classifier = DecisionTreeLearner_LargeData

    def test_equal_classification(self):
        """
        This checks that the three tree learning methods are equal.
        """

        pseudo = DecisionTreeLearner(self.corpus, self.problem)
        for test in self.test_set:
            self.assertEqual(pseudo.classify(test), self.this.classify(test))

    def test_every_node_can_classify(self):
        nodes = [self.this.root]

        while nodes:
            node = nodes.pop()
            self.assertNotEqual(node.result, None)
            nodes.extend(node.branches.values())


class BaseTestDtree_Queued(BaseTestDtree_LargeData):
    classifier = DecisionTreeLearner_Queued


class BaseTestNaiveBayes(BaseTestClassifier):
    classifier = NaiveBayes


class BaseTestKNearestNeighbors(BaseTestClassifier):
    classifier = KNearestNeighbors


class CorpusIris(object):
    IRIS_PATH = os.path.join(os.path.dirname(__file__), "iris.txt")

    def setup_dataset(self):
        """
        Creates a corpus with the iris dataset. Returns the dataset,
        the attributes getter and the target getter.
        """

        dataset = []
        with open(self.IRIS_PATH) as filehandler:
            file_data = filehandler.read()

        for line in file_data.split("\n"):
            line_data = [round(float(x)) for x in line.split()]
            if line_data:
                dataset.append(line_data)

        problem = VectorDataClassificationProblem(dataset, target_index=4)
        problem.distance = euclidean_vector_distance
        self.corpus = dataset
        self.problem = problem


class CorpusXor(object):
    def setup_dataset(self):
        """
        Creates a corpus  with n k-bit examples of the parity problem:
        k random bits followed by a 1 if an odd number of bits are 1, else 0
        """
        k = 2
        n = 100

        dataset = []
        for i in xrange(n):
            # Pseudo random generation of bits
            bits = [(((i + j) * 1223) % (n + 1)) % 2 for j in xrange(k)]
            bits.append(sum(bits) % 2)
            dataset.append(bits)

        problem = VectorDataClassificationProblem(dataset, target_index=k)
        self.corpus = dataset
        self.problem = problem


class CorpusPrimes(object):
    def setup_dataset(self):
        """
        Creates a corpus of primes. Returns the dataset,
        the attributes getter and the target getter.
        """
        size = 105  # Magic number, chosen to avoid an "error" that cannot be
                    # patched in Dtree Pseudo (with modifing the pseudocode).

        dataset = []
        for i in xrange(size):
            dataset.append([
                i % 2 == 0,
                i % 3 == 0,
                i % 5 == 0,
                i % 7 == 0,
                self.isprime(i)
            ])

        problem = VectorDataClassificationProblem(dataset, target_index=-1)
        problem.distance = euclidean_vector_distance
        self.corpus = dataset
        self.problem = problem

    def isprime(self, number):
        """
        Returns if a number is prime testing if
        is divisible by any number from 0 to sqrt(number)
        """

        if number < 2:
            return False
        if number == 2:
            return True
        if not number & 1:
            return False

        for i in range(3, int(number ** 0.5) + 1, 2):
            if number % i == 0:
                return False
        return True


def create_tstcase(classifier, corpus):
    name = "{}_{}".format(classifier.__name__, corpus.__name__)
    bases = (corpus, classifier, unittest.TestCase)
    newclass = type(name, bases, {})
    globals()[name] = newclass


TestDtree_Pseudo_CorpusIris = create_tstcase(BaseTestDtree_Pseudo, CorpusIris)
TestDtree_Pseudo_CorpusXor = create_tstcase(BaseTestDtree_Pseudo, CorpusXor)
TestDtree_Pseudo_CorpusPrimes = create_tstcase(BaseTestDtree_Pseudo, CorpusPrimes)

TestDtree_Queued_CorpusIris = create_tstcase(BaseTestDtree_Queued, CorpusIris)
TestDtree_Queued_CorpusXor = create_tstcase(BaseTestDtree_Queued, CorpusXor)
TestDtree_Queued_CorpusPrimes = create_tstcase(BaseTestDtree_Queued, CorpusPrimes)

TestDtree_LargeData_CorpusIris = create_tstcase(BaseTestDtree_LargeData, CorpusIris)
TestDtree_LargeData_CorpusXor = create_tstcase(BaseTestDtree_LargeData, CorpusXor)
TestDtree_LargeData_CorpusPrimes = create_tstcase(BaseTestDtree_LargeData, CorpusPrimes)

TestNaiveBayes_CorpusIris = create_tstcase(BaseTestNaiveBayes, CorpusIris)
TestNaiveBayes_CorpusXor = create_tstcase(BaseTestNaiveBayes, CorpusXor)
TestNaiveBayes_CorpusPrimes = create_tstcase(BaseTestNaiveBayes, CorpusPrimes)

TestKNearestNeighbors_CorpusPrimes = create_tstcase(BaseTestKNearestNeighbors, CorpusPrimes)
TestKNearestNeighbors_CorpusIris = create_tstcase(BaseTestKNearestNeighbors, CorpusIris)

########NEW FILE########
__FILENAME__ = test_evaluation
# -*- coding: utf-8 -*-

import unittest
from simpleai.machine_learning.evaluation import precision, kfold
from simpleai.machine_learning import VectorDataClassificationProblem, \
                                      Classifier


class MockClassifier(Classifier):
    """
    Classifies everything as the first item in the dataset.
    """
    def learn(self):
        pass

    def classify(self, x):
        return self.target(self.dataset[0]), 1.0


class TestPrecision(unittest.TestCase):
    train = [(0, 1, 1), (1, 1, 0), (0, 1, 0), (1, 7, 0), (0, 1, 9)]

    def setUp(self):
        self.p = VectorDataClassificationProblem(self.train, 0)
        self.c = MockClassifier(self.train, self.p)

    def test_is_1(self):
        test = [(0, 3, 3), (0, 2, 2)]
        p = precision(self.c, test)
        self.assertEqual(p, 1.0)

    def test_is_0(self):
        test = [(1, 3, 3), (1, 2, 2)]
        p = precision(self.c, test)
        self.assertEqual(p, 0.0)

    def test_bad_testset(self):
        test = []
        with self.assertRaises(ValueError):
            precision(self.c, test)


class TestKfold(unittest.TestCase):

    def my_setup(self, train):
        self.p = VectorDataClassificationProblem(train, 0)
        self.c = MockClassifier(train, self.p)

    def test_k1_is_bad(self):
        testset = [(0, 1, 1), (1, 1, 0), (1, 6, 5), (1, 7, 0), (0, 1, 9)]
        self.my_setup(testset)
        with self.assertRaises(ValueError):
            kfold(testset, self.p, MockClassifier, k=1)

    def test_kfold_is_0(self):
        testset = [(0, 1, 1), (1, 1, 0)]
        self.my_setup(testset)
        p = kfold(testset, self.p, MockClassifier, k=2)
        self.assertEqual(p, 0.0)

    def test_kfold_lt_75(self):
        testset = [(1, 0, 0), (1, 0, 1), (1, 1, 0), (0, 1, 1)]
        self.my_setup(testset)
        p = kfold(testset, self.p, MockClassifier, k=4)
        self.assertLessEqual(p, 0.75)

########NEW FILE########
__FILENAME__ = test_metrics
#!/usr/bin/env python
# coding: utf-8

"""
Tests for metrics module in machine learning.
"""

import unittest
from simpleai.machine_learning.metrics import Counter, OnlineEntropy, \
                                              OnlineLogProbability, \
                                              OnlineInformationGain


class TestCounter(unittest.TestCase):
    def test_total_starts_in_zero(self):
        counter = Counter(lambda x: None)
        self.assertEqual(counter.total, 0)

    def test_add_elements(self):
        counter = Counter(lambda x: None)
        for i in xrange(20):
            counter.add("something")
        self.assertEqual(counter.total, 20)

    def test_target_values(self):
        counter = Counter(lambda x: x % 2 == 0)
        for i in xrange(25):
            counter.add(i)
        self.assertEqual(counter[0], 12)
        self.assertEqual(counter[1], 13)

        counter = Counter(lambda x: None)
        for i in xrange(50):
            counter.add(i)
        self.assertEqual(counter[None], 50)


class TestOnlineEntropy(unittest.TestCase):
    def test_starts_in_zero(self):
        entropy = OnlineEntropy(lambda x: None)
        self.assertEqual(entropy.get_entropy(), 0)

    def test_valid_values(self):
        entropy = OnlineEntropy(lambda x: x % 10)
        for i in xrange(150):
            entropy.add(i)
        self.assertGreaterEqual(entropy.get_entropy(), 0.0)


class TestOnlineInformationGain(unittest.TestCase):
    def test_starts_in_zero(self):
        gain = OnlineInformationGain(lambda x: None, lambda x: None)
        self.assertEqual(gain.get_gain(), 0)
        self.assertEqual(gain.get_target_class_counts().items(), [])
        self.assertEqual(gain.get_branches(), [])

    def test_no_gain(self):
        f = lambda x: None
        gain = OnlineInformationGain(f, f)
        for i in xrange(30):
            gain.add(i)
        self.assertEqual(gain.get_gain(), 0)

    def test_full_gain(self):
        target = lambda x: x % 7
        gain = OnlineInformationGain(target, target)
        entropy = OnlineEntropy(target)
        for i in xrange(50):
            gain.add(i)
            entropy.add(i)
        self.assertEqual(gain.get_gain(), entropy.get_entropy())
        self.assertGreaterEqual(gain.get_gain(), 0)

########NEW FILE########
__FILENAME__ = test_reinforcement_learning
# -*- coding: utf-8 -*-
import unittest
from simpleai.machine_learning.reinforcement_learning import boltzmann_exploration, make_at_least_n_times
from collections import Counter


class TestBoltzmann_exploration(unittest.TestCase):

    def setUp(self):
        self.actions = ['a', 'b', 'c']
        self.utilities = dict(zip(self.actions, [1, 2, 3]))

    def test_high_randomness_in_hot(self):
        counter = Counter()
        for i in range(100):
            a = boltzmann_exploration(self.actions, self.utilities, 10000000, None)
            counter[a] += 1
        for a, c in counter.items():
            self.assertTrue(20 <= c <= 45)

    def test_low_randomness_in_cold(self):
        counter = Counter()
        for i in range(100):
            a = boltzmann_exploration(self.actions, self.utilities, 0.005, None)
            counter[a] += 1
        self.assertGreater(counter['c'], 95)

    def test_all_equals_utilities(self):
        self.utilities = dict(zip(self.actions, [0, 0, 0]))
        counter = Counter()
        for i in range(100):
            a = boltzmann_exploration(self.actions, self.utilities, 10000000, None)
            counter[a] += 1
        for a, c in counter.items():
            self.assertTrue(25 <= c <= 40)


class Testat_least_n_times_exploration(unittest.TestCase):

    def setUp(self):
        self.actions = ['a', 'b', 'c']
        self.utilities = dict(zip(self.actions, [1, 2, 3]))
        self.function = make_at_least_n_times(100, 5)

    def test_selection_with_lower_n(self):
        c = Counter()
        c['a'] = 4
        c['b'] = 6
        c['c'] = 5
        action = self.function(self.actions, self.utilities, 0, c)
        self.assertEquals(action, 'a')

    def test_selection_with_higher_n(self):
        c = Counter()
        c['a'] = 5
        c['b'] = 6
        c['c'] = 5
        action = self.function(self.actions, self.utilities, 0, c)
        self.assertEquals(action, 'c')
########NEW FILE########
__FILENAME__ = dummies
# coding=utf-8


class DummyNode(object):
    def __init__(self, value):
        self.value = value

    def __lt__(self, other):
        return self.value < other.value


GOAL = 'iabcabc'


class DummyProblem(object):
    def actions(self, state):
        return ['a', 'b', 'c'] if len(state) < len(GOAL) else []

    def result(self, state, action):
        return state + action

    def is_goal(self, state):
        return state == GOAL

    def heuristic(self, state):
        # incorrect or missing actions
        return (len(GOAL) - self.value(state)) - 1

    def value(self, state):
        # correct actions
        return sum(1 if state[i] == GOAL[i] else 0
                   for i in range(min(len(GOAL), len(state)))) - 1

    def cost(self, state1, action, state2):
        return 1

    def generate_random_state(self):
        return 'i'


class DummyGeneticProblem(object):
    def value(self, state):
        return state + 1

    def crossover(self, state1, state2):
        return state1 + 1

    def mutate(self, state):
        return 20  # Mutants are like that

    def generate_random_state(self):
        return 4  # Please see http://xkcd.com/221/


class DummyGraphProblem(object):

    _map = {
            'r': {'l': 16},
            'l': {'s': 26, 'a': 10, 'r': 16},
            'a': {'s': 15, 'l': 10},
            's': {'l': 26, 'a': 15},
            }

    consistent = {'r': 0, 'l': 15, 'a': 25, 's': 30}
    inconsistent = {'r': 0, 'l': 10, 'a': 25, 's': 30}
    inadmissible = {'r': 0, 'l': 15, 'a': 28, 's': 30}

    def __init__(self, heuristic_dict=None):
        self.initial_state = 's'
        self.goal = 'r'
        self.heuristic_dict = heuristic_dict

    def is_goal(self, state):
        return state == self.goal

    def actions(self, state):
        "returns state's neighbors"
        return self._map[state].keys()

    def result(self, state, action):
        'returns the action because it indicates the next city'
        return action

    def cost(self, state1, action, state2):
        return self._map[state1][state2]

    def heuristic(self, state):
        return self.heuristic_dict[state]

    def state_representation(self, state):
        return state

    def action_representation(self, action):
        return action
########NEW FILE########
__FILENAME__ = test_arc_concistency
# coding=utf-8
import unittest

from operator import itemgetter

from simpleai.search.arc import all_arcs, revise, arc_consistency_3

first = itemgetter(0)


class TestAllArcs(unittest.TestCase):

    def setUp(self):
        self.constraint = lambda variables, values: False

    def test_adds_pairs_in_both_directions(self):
        constraints = [(('A', 'B'), self.constraint)]

        arcs_result = all_arcs(constraints)
        arcs_expected = set([('A', 'B'),
                             ('B', 'A')])

        self.assertEqual(arcs_result, arcs_expected)

    def test_constraints_with_more_than_2_neighbors_arent_added(self):
        constraints = [(('A', 'B', 'C'), self.constraint)]

        arcs_result = all_arcs(constraints)
        arcs_expected = set()

        self.assertEqual(arcs_result, arcs_expected)


def is_square(variables, values):
    return values[0] ** 2 == values[1]


class TestReviseDomain(unittest.TestCase):
    def revise(self, domain_a, domain_b, duplicate_constraints=False):
        domains = {'A': domain_a, 'B': domain_b}
        constraints = [(('A', 'B'), is_square)]
        if duplicate_constraints:
            constraints = constraints * 2

        return revise(domains, ('A', 'B'), constraints), domains

    def test_if_all_values_have_possible_match_the_domain_is_untouched(self):
        result, domains = self.revise([1, 2, 3], [1, 4, 9])
        self.assertFalse(result)
        self.assertEquals(domains['A'], [1, 2, 3])

    def test_if_a_value_has_no_possible_match_remove_it_from_domain(self):
        result, domains = self.revise([1, 2, 3], [1, 4])
        self.assertTrue(result)
        self.assertEquals(domains['A'], [1, 2])

    def test_if_multiple_constraints_dont_fail_removing_twice(self):
        # there was a bug when two constraints tried to remove the same value
        result, domains = self.revise([1, 2, 3], [1, 4], True)
        self.assertTrue(result)
        self.assertEquals(domains['A'], [1, 2])


class TestAC3(unittest.TestCase):
    def ac3(self, domain_a, domain_b):
        domains = {'A': domain_a, 'B': domain_b}
        constraints = [(('A', 'B'), is_square)]

        return arc_consistency_3(domains, constraints), domains

    def test_values_available_for_all_returns_true(self):
        result, domains = self.ac3([1, 2, 3], [1, 4, 9])
        self.assertTrue(result)

    def test_if_variable_has_no_domain_left_returns_false(self):
        result, domains = self.ac3([1, 2, 3], [2, 3, 6])
        self.assertFalse(result)

    def test_chained_revise_calls_remove_non_obvious_problems(self):
        # if A, B, C must be all different, with domains [1, 1], [1, 2], [2, 2] you
        # can't find a solution, but it requires several chained calls to
        # revise:
        # revise(A, B) -> ok!                      [1, 1] [1, 2] [2, 2]
        # revise(A, C) -> ok!                      [1, 1] [1, 2] [2, 2]
        # revise(B, C) -> fail, remove 2 from B    [1, 1] [1] [2, 2]
        #    and re-revise A, B and C, B
        # revise(A, B) -> fail, remove 1 from A    [] [1] [2, 2]
        #    and re-revise ...
        # here A has no more values, ac3 returns a failure

        domains = {'A': [1, 1],
                   'B': [1, 2],
                   'C': [2, 2]}
        different = lambda variables, values: len(set(values)) == len(variables)
        constraints = [(('A', 'B'), different),
                       (('A', 'C'), different),
                       (('B', 'C'), different)]

        result = arc_consistency_3(domains, constraints)

        self.assertFalse(result)

########NEW FILE########
__FILENAME__ = test_csp
# coding=utf-8
import unittest
from simpleai.search.models import CspProblem
from simpleai.search.csp import (_find_conflicts, _count_conflicts,
                                 _most_constrained_variable_chooser,
                                 _highest_degree_variable_chooser,
                                 _least_constraining_values_sorter,
                                 _min_conflicts_value, backtrack,
                                 min_conflicts)


class TestCsp(unittest.TestCase):
    def setUp(self):
        self.variables = ('A', 'B', 'C')

        self.domains = {
            'A': [1, 2, 3],
            'B': [1, 3, 4],
            'C': [1, 2],
        }

        # a constraint that expects different variables to have different values
        def const_different(variables, values):
            return len(values) == len(set(values))  # remove repeated values and count

        # a constraint that expects one variable to be bigger than other
        def const_one_bigger_other(variables, values):
            return values[0] > values[1]

        # a constraint thet expects two variables to be one odd and the other even,
        # no matter which one is which type
        def const_one_odd_one_even(variables, values):
            if values[0] % 2 == 0:
                return values[1] % 2 == 1  # first even, expect second to be odd
            else:
                return values[1] % 2 == 0  # first odd, expect second to be even

        # a constraint that requires one variable to be different than 1
        def const_not_1(variables, values):
            return values[0] != 1

        self.constraints = [
            (('A', 'B', 'C'), const_different),
            (('A', 'C'), const_one_bigger_other),
            (('A', 'C'), const_one_odd_one_even),
            (('A',), const_not_1)
        ]

        self.problem = CspProblem(self.variables, self.domains, self.constraints)

    def test_most_constrained_variable_chooser(self):
        variable = _most_constrained_variable_chooser(self.problem, self.variables, self.domains)
        self.assertEquals(variable, 'C')

    def test_highest_degree_variable_chooser(self):
        variable = _highest_degree_variable_chooser(self.problem, self.variables, self.domains)
        self.assertEquals(variable, 'A')

    def test_find_conflicts(self):
        assignment = {'A': 1, 'B': 1, 'C': 3}
        conflicts = _find_conflicts(self.problem, assignment)
        self.assertEqual(conflicts, self.constraints)

    def test_find_conflicts_with_added_variable(self):
        assignment = {'A': 1, 'B': 1}
        conflicts = _find_conflicts(self.problem, assignment, 'C', 3)
        self.assertEqual(conflicts, self.constraints)

    def test_count_conflicts(self):
        assignment = {'A': 1, 'B': 1, 'C': 3}
        conflicts_count = _count_conflicts(self.problem, assignment)
        self.assertEqual(conflicts_count, 4)

    def test_count_conflicts_with_added_variable(self):
        assignment = {'A': 1, 'B': 1}
        conflicts_count = _count_conflicts(self.problem, assignment, 'C', 3)
        self.assertEqual(conflicts_count, 4)

    def test_least_constraining_values_sorter(self):
        assignment = {'A': 1, 'B': 1}
        values = _least_constraining_values_sorter(self.problem, assignment, 'C', self.domains)
        self.assertEquals(values, [2, 1])

    def test_min_conflicts_value(self):
        assignment = {'A': 1, 'B': 1}
        value = _min_conflicts_value(self.problem, assignment, 'C')
        self.assertEquals(value, 2)

    def test_backtrack(self):
        result = backtrack(self.problem)
        self.assertEqual(result, {'A': 2, 'B': 3, 'C': 1})

    def test_min_conflicts(self):
        result = min_conflicts(self.problem)
        c = _count_conflicts(self.problem, result)
        self.assertEqual(c, 0)

########NEW FILE########
__FILENAME__ = test_hidden_variables
import unittest
from operator import itemgetter
from simpleai.search import convert_to_binary

fst = itemgetter(0)


class TestHiddenVariableRepr(unittest.TestCase):

    def setUp(self):
        alldiff = lambda vars_, values_: len(set(values_)) == len(values_)
        const = lambda vars_, values_: True

        self.variables = ('A', 'B', 'C')

        self.domains = {
            'A': [1, 2, 3],
            'B': [1, 3, 4],
            'C': [1, 2],
        }

        self.constraints = [
            (('A', 'B', 'C'), alldiff),
            (('A', 'C'), const),
            (('A', 'C'), const),
            (('A',), lambda _vars, _value: _value[0] % 2 == 0)
        ]

    def test_conver_to_binary_adds_variables(self):
        v, d, c = convert_to_binary(self.variables, self.domains, self.constraints)
        self.assertNotEqual(v, self.variables)
        self.assertIn('hidden0', v)
        self.assertIn('hidden1', v)

    def test_conver_to_binary_constraints_variables(self):
        v, d, c = convert_to_binary(self.variables, self.domains, self.constraints)
        var_tuples = map(fst, c)
        self.assertIn(('hidden0', 'A'), var_tuples)
        self.assertIn(('hidden0', 'B'), var_tuples)
        self.assertIn(('hidden0', 'C'), var_tuples)
        self.assertIn(('hidden1', 'A'), var_tuples)

    def test_hidden_variable__domains_is_constraint_by_the_constraint_on_the_variable_it_hides(self):
        v, d, c = convert_to_binary(self.variables, self.domains, self.constraints)
        # hidden0 hides A, B, C
        domain = sorted(d['hidden0'])
        self.assertEqual(domain, [(1, 3, 2), (1, 4, 2), (2, 3, 1), (2, 4, 1), (3, 1, 2), (3, 4, 1), (3, 4, 2)])

        domain = sorted(d['hidden1'])
        self.assertEqual(domain, [(2,)])

########NEW FILE########
__FILENAME__ = test_local
# coding=utf-8
import unittest
from tests.search.dummies import DummyProblem, GOAL, DummyGeneticProblem
from simpleai.search.local import (beam, beam_best_first,
                                   hill_climbing,
                                   hill_climbing_stochastic,
                                   simulated_annealing,
                                   hill_climbing_random_restarts, genetic)
from simpleai.search.models import SearchNode


class TestLocalSearch(unittest.TestCase):
    def setUp(self):
        self.problem = DummyProblem()
        self.problem.initial_state = 'i'

    def test_beam(self):
        result = beam(self.problem)
        self.assertEquals(result.state, GOAL)

    def test_beam_best_first(self):
        result = beam_best_first(self.problem)
        self.assertEquals(result.state, GOAL)

    def test_hill_climbing(self):
        result = hill_climbing(self.problem)
        self.assertEquals(result.state, GOAL)

    def test_hill_climbing_stochastic(self):
        result = hill_climbing_stochastic(self.problem)
        self.assertEquals(result.state, GOAL)

    def test_hill_climbing_random_restarts(self):
        result = hill_climbing_random_restarts(self.problem, restarts_limit=2)
        self.assertEquals(result.state, GOAL)

    def test_simulated_annealing(self):
        # give the problem an actions function that always
        # goes up, to test if simulated_annealing takes the
        # correct states
        def dummy_actions(state):
            if len(state) < len(GOAL):
                return {'i': 'a',
                        'a': 'b',
                        'b': 'c',
                        'c': 'a'}[state[-1]]
            else:
                return []
        self.problem.actions = dummy_actions
        result = simulated_annealing(self.problem)
        self.assertEquals(result.state, GOAL)


class TestGeneticSearch(unittest.TestCase):

    def setUp(self):
        self.problem = DummyGeneticProblem()

    def test_solution_is_node(self):
        node = genetic(self.problem, iterations_limit=1, mutation_chance=0, population_size=1)
        self.assertIsInstance(node, SearchNode)

    def test_calls_crossover(self):
        node = genetic(self.problem, iterations_limit=1, mutation_chance=0, population_size=5)
        self.assertEqual(node.state, 5)

    def test_calls_mutation(self):
        node = genetic(self.problem, iterations_limit=1, mutation_chance=1, population_size=5)
        self.assertEqual(node.state, 20)

    def test_count_generations(self):
        node = genetic(self.problem, iterations_limit=10, mutation_chance=0, population_size=5)
        self.assertEqual(node.state, 14)  # initial is 4, plus 10 generations

    def test_zero_fitness_get_waxed(self):
        count = [-1]

        def g():
            count[0] = count[0] + 1  # Nasty trick uh? try without the list
            return [0, 0, 1, 0, 0][count[0]]

        def fitness(state):
            return state

        self.problem.generate_random_state = g
        self.problem.value = fitness
        node = genetic(self.problem, iterations_limit=1, mutation_chance=0, population_size=5)
        self.assertEqual(node.state, 2)

########NEW FILE########
__FILENAME__ = test_models
# coding=utf-8
import unittest
from tests.search.dummies import DummyProblem
from simpleai.search.models import (SearchNode, SearchNodeCostOrdered,
                                    SearchNodeValueOrdered,
                                    SearchNodeHeuristicOrdered,
                                    SearchNodeStarOrdered)


class TestSearchNode(unittest.TestCase):
    def setUp(self):
        self.problem = DummyProblem()
        self.node = SearchNode(state='i',
                               problem=self.problem)
        self.childs = self.node.expand()

    def test_expand_creates_node_for_each_action(self):
        self.assertEquals(len(self.childs), 3)

    def test_successors_have_correct_values(self):
        child = self.childs[0]
        self.assertEquals(child.state, 'ia')
        self.assertIs(child.parent, self.node)
        self.assertEquals(child.action, 'a')
        self.assertEquals(child.cost, 1)
        self.assertIs(child.problem, self.problem)
        self.assertEquals(child.depth, 1)

    def test_successors_dont_have_parent_when_local_search(self):
        childs = self.node.expand(local_search=True)
        self.assertEquals(childs[0].parent, None)

    def test_path(self):
        n1 = SearchNode(problem=self.problem, state='i')
        n2 = SearchNode(action='a', state='ia', parent=n1)
        n3 = SearchNode(action='b', state='iab', parent=n2)

        path = [(None, 'i'), ('a', 'ia'), ('b', 'iab')]

        self.assertEquals(n3.path(), path)

    def test_equals(self):
        n1 = SearchNode(problem=self.problem, state='i')
        n2 = SearchNode(problem=self.problem, state='i')
        n3 = SearchNode(problem=self.problem, state='i', action='a')
        n4 = SearchNode(problem=self.problem, state='ia')

        self.assertTrue(n1 == n2)
        self.assertTrue(n1 == n3)
        self.assertFalse(n1 == n4)


class TestOrderedSearchNodeClasses(unittest.TestCase):
    def setUp(self):
        self.problem = DummyProblem()

    def test_search_node_cost_sorted(self):
        n1 = SearchNodeCostOrdered(problem=self.problem, state='i', cost=1)
        n2 = SearchNodeCostOrdered(problem=self.problem, state='i', cost=2)

        self.assertTrue(n1 < n2)
        self.assertFalse(n2 < n1)

    def test_search_node_value_sorted(self):
        n1 = SearchNodeValueOrdered(problem=self.problem, state='iab')
        n2 = SearchNodeValueOrdered(problem=self.problem, state='iba')

        self.assertTrue(n1 < n2)
        self.assertFalse(n2 < n1)

    def test_search_node_heuristic_sorted(self):
        n1 = SearchNodeHeuristicOrdered(problem=self.problem, state='iab')
        n2 = SearchNodeHeuristicOrdered(problem=self.problem, state='iba')

        self.assertTrue(n1 < n2)
        self.assertFalse(n2 < n1)

    def test_search_node_star_sorted(self):
        n1 = SearchNodeStarOrdered(problem=self.problem, state='iab', cost=1)
        n2 = SearchNodeStarOrdered(problem=self.problem, state='iba', cost=2)

        self.assertTrue(n1 < n2)
        self.assertFalse(n2 < n1)


########NEW FILE########
__FILENAME__ = test_traditional
# coding=utf-8
import unittest
from tests.search.dummies import DummyProblem, GOAL, DummyGraphProblem
from simpleai.search.traditional import (breadth_first, depth_first,
                                         limited_depth_first,
                                         iterative_limited_depth_first,
                                         uniform_cost, greedy, astar)

from simpleai.search.viewers import BaseViewer


class TestViewer(BaseViewer):

    def __init__(self, expected_fringes):
        super(TestViewer, self).__init__()
        self.expected_fringes = expected_fringes

    def event(self, name, *params):
        super(TestViewer, self).event(name, *params)
        if name == 'new_iteration':
            expected = self.expected_fringes.pop(0)
            current = params[0]
            if not all([cu.state == ex_state and cu.cost == ex_cost
                        for cu, (ex_state, ex_cost) in zip(current, expected)]):
                current = ' '.join(['<{x.state}, {x.cost}>'.format(x=x) for x in current])
                expected = ' '.join(['<{x[0]}, {x[1]}>'.format(x=x) for x in expected])
                raise Exception('''Fringe unexpected: {0}. Expected: {1}'''.format(current, expected))


class TestSearch(unittest.TestCase):
    def setUp(self):
        self.problem = DummyProblem()
        self.problem.initial_state = 'i'
        self.graph_problem = DummyGraphProblem(DummyGraphProblem.consistent)

    def test_breadth_first(self):
        result = breadth_first(self.problem)
        self.assertEquals(result.state, GOAL)

    def test_depth_first(self):
        result = depth_first(self.problem)
        self.assertEquals(result.state, GOAL)

    def test_limited_depth_first(self):
        result = limited_depth_first(self.problem, depth_limit=3)
        self.assertEquals(result, None)

        result = limited_depth_first(self.problem, depth_limit=6)
        self.assertEquals(result.state, GOAL)

    def test_iterative_limited_depth_first(self):
        result = iterative_limited_depth_first(self.problem)
        self.assertEquals(result.state, GOAL)

    def test_uniform_cost(self):
        result = uniform_cost(self.problem)
        self.assertEquals(result.state, GOAL)

    def test_greedy(self):
        result = greedy(self.problem)
        self.assertEquals(result.state, GOAL)

    def test_astar(self):
        result = astar(self.problem)
        self.assertEquals(result.state, GOAL)

    def test_astar_graph_execution_with_repeated_states_chooses_better_state(self):
        result = astar(self.graph_problem, graph_search=True)
        self.assertEquals(result.state, self.graph_problem.goal)

    def test_astar_graph_doesnt_repeat_states_in_explore_set(self):
        v = TestViewer([[('s', 0)], [('l', 26), ('a', 15)], [('a', 15), ('r', 42)], [('r', 42)]])
        self.graph_problem.heuristic_dict = DummyGraphProblem.inconsistent
        result = astar(self.graph_problem, graph_search=True, viewer=v)
        self.assertEquals(result.state, self.graph_problem.goal)

    def test_astar_graph_consistent_heuristic(self):
        v = TestViewer([[('s', 0)], [('a', 15), ('l', 26)], [('l', 25)], [('r', 41)]])
        self.graph_problem.heuristic_dict = DummyGraphProblem.consistent
        result = astar(self.graph_problem, graph_search=True, viewer=v)
        self.assertEquals(result.state, self.graph_problem.goal)

    def test_astar_graph_inadmissible_heuristic(self):
        v = TestViewer([[('s', 0)], [('l', 26), ('a', 15)], [('r', 42), ('a', 15)]])
        self.graph_problem.heuristic_dict = DummyGraphProblem.inadmissible
        result = astar(self.graph_problem, graph_search=True, viewer=v)
        self.assertEquals(result.state, self.graph_problem.goal)

    def test_astar_tree_inadmissible_heuristic(self):
        v = TestViewer([[('s', 0)], [('l', 26), ('a', 15)], [('r', 42), ('a', 15), ('a', 36), ('s', 52)]])
        self.graph_problem.heuristic_dict = DummyGraphProblem.inadmissible
        result = astar(self.graph_problem, graph_search=False, viewer=v)
        self.assertEquals(result.state, self.graph_problem.goal)

########NEW FILE########
__FILENAME__ = test_utils
# coding=utf-8
import unittest
from tests.search.dummies import DummyNode
from simpleai.search.utils import FifoList, BoundedPriorityQueue, LifoList, argmax, argmin


def sorted_equals_pop(l):
    _sorted = l.sorted()
    _sorted_by_pop = [l.pop() for x in range(len(l))]
    return _sorted == _sorted_by_pop


class TestLifoList(unittest.TestCase):
    def setUp(self):
        self.f = LifoList()
        self.f.append(1)
        self.f.append(2)
        self.f.append(3)

    def test_sorted_lifo(self):
        self.assertTrue(sorted_equals_pop(self.f))


class TestFifoList(unittest.TestCase):
    def setUp(self):
        self.f = FifoList()
        self.f.append(1)
        self.f.append(2)
        self.f.append(3)

    def test_pop_returns_first_element(self):
        self.assertEquals(self.f.pop(), 1)
        self.assertEquals(len(self.f), 2)

    def test_sorted_fifo(self):
        self.assertTrue(sorted_equals_pop(self.f))


class TestBoundedPriorityQueue(unittest.TestCase):
    def test_append_works(self):
        q = BoundedPriorityQueue()
        q.append(DummyNode(1))
        q.append(DummyNode(1))
        self.assertEquals(len(q), 2)

    def test_extend_works(self):
        q = BoundedPriorityQueue()
        q.extend([DummyNode(1), DummyNode(1)])
        self.assertEquals(len(q), 2)

    def test_pop_works_with_order(self):
        q = BoundedPriorityQueue()
        q.append(DummyNode(3))
        q.append(DummyNode(1))
        q.append(DummyNode(2))
        self.assertEquals(q.pop().value, 1)

    def test_limit_works_on_append(self):
        q = BoundedPriorityQueue(2)
        q.append(DummyNode(1))
        q.append(DummyNode(1))
        q.append(DummyNode(1))
        self.assertEquals(len(q), 2)

    def test_limit_works_on_extend(self):
        q = BoundedPriorityQueue(2)
        q.extend([DummyNode(1), DummyNode(1), DummyNode(1)])
        self.assertEquals(len(q), 2)

    def test_remove(self):
        q = BoundedPriorityQueue(2)
        a = DummyNode(1)
        b = DummyNode(2)
        q.append(a)
        q.append(b)
        q.remove(a)
        self.assertEquals(len(q), 1)
        self.assertIs(q[0], b)

    def test_sorted_priority(self):
        q = BoundedPriorityQueue()
        q.append(DummyNode(3))
        q.append(DummyNode(1))
        q.append(DummyNode(2))
        self.assertTrue(sorted_equals_pop(q))


class TestArgMax(unittest.TestCase):
    def setUp(self):
        self.d = {'a': 3, 'b': 1, 'c': 3}

    def test_return_max(self):
        self.assertEquals('a', argmax(['a', 'b'], lambda x: self.d[x]))

    def test_random_tie(self):
        a = 0
        for x in range(100):
            if argmax(['a', 'b', 'c'], lambda x: self.d[x]) == 'a':
                a += 1
        self.assertTrue(25 < a < 75)

    def test_empty_sequence(self):
        self.assertRaises(ValueError, argmax, [], lambda x: x)


class TestArgMin(unittest.TestCase):
    def setUp(self):
        self.d = {'a': 1, 'b': 1, 'c': 3}

    def test_return_max(self):
        self.assertEquals('b', argmin(['c', 'b'], lambda x: self.d[x]))

    def test_random_tie(self):
        a = 0
        for x in range(100):
            if argmin(['a', 'b', 'c'], lambda x: self.d[x]) == 'a':
                a += 1
        self.assertTrue(25 < a < 75)

    def test_empty_sequence(self):
        self.assertRaises(ValueError, argmin, [], lambda x: x)



########NEW FILE########
