[
    "nltk.corpus.reader.framenet",
    "all",
    "textblob.nltk.test.unit.test_collocations",
    "senna",
    "misc.minimalset",
    "nltk.corpus.reader.pl196x",
    "textblob.nltk.classify.scikitlearn",
    "nltk.internals",
    "bracket_parse",
    "textblob.nltk.metrics.spearman",
    "stem.wordnet",
    "classify.util",
    "nltk.ccg",
    "naivebayes",
    "hole",
    "nltk.corpus.reader.ipipan",
    "rte_classify",
    "nltk.test.unit",
    "stem.regexp",
    "mallet",
    "inference.nonmonotonic",
    "parse.featurechart",
    "ccg.chart",
    "discourse_fixt",
    "textblob.en.inflect",
    "textblob.nltk.tag.sequential",
    "nltk.chat.zen",
    "textblob.nltk.corpus.reader.udhr",
    "textblob.en.sentiments",
    "nltk.chat.suntsu",
    "test_tokenizers",
    "inference.discourse",
    "app.wordnet_app",
    "mixins",
    "textblob.nltk.corpus.reader.chasen",
    "nltk.classify.decisiontree",
    "util",
    "string_category",
    "textblob.nltk.data",
    "tests.test_blob",
    "nltk.tag",
    "nltk.inference.prover9",
    "test_utils",
    "textblob.blob",
    "textblob.nltk.ccg.combinator",
    "tests.test_sentiments",
    "sem.hole",
    "doctest_nose_plugin",
    "parse.util",
    "textblob.nltk.parse.pchart",
    "reader.cmudict",
    "textblob.nltk.tag.crf",
    "nltk.parse.dependencygraph",
    "nltk.tokenize.simple",
    "textblob.nltk.stem.snowball",
    "tests.test_translate",
    "nltk.draw.tree",
    "textblob.nltk.sem.boxer",
    "cfg",
    "nltk.app.rdparser_app",
    "test_blob",
    "taggers",
    "textblob.nltk.collocations",
    "brill",
    "tokenize.regexp",
    "textblob.nltk.stem.rslp",
    "nltk.metrics.spearman",
    "nltk.app",
    "nltk.tag.hunpos",
    "textblob.nltk.app.collocations_app",
    "reader.conll",
    "chunk.util",
    "compat",
    "textblob.nltk.tree",
    "draw.table",
    "nltk.featstruct",
    "nltk.chat.eliza",
    "corpus.reader.aligned",
    "nltk.corpus.reader.lin",
    "eliza",
    "textblob.nltk.classify.positivenaivebayes",
    "textblob.nltk.corpus.reader.wordnet",
    "babelfish",
    "reader.plaintext",
    "chat.suntsu",
    "positivenaivebayes",
    "indian",
    "test.unit.test_corpora",
    "textblob.nltk.lazyimport",
    "nltk.sem.lfg",
    "test.semantics_fixt",
    "corpus.reader.pl196x",
    "test.childes_fixt",
    "ccg",
    "textblob.nltk.downloader",
    "reader.bracket_parse",
    "cluster.em",
    "test.classify_fixt",
    "downloader",
    "formats",
    "nltk.parse.pchart",
    "textblob.nltk.model.api",
    "test.align_fixt",
    "ccg.combinator",
    "nltk.inference.mace",
    "textblob.mixins",
    "nltk.metrics.segmentation",
    "reader.util",
    "stem",
    "metrics.agreement",
    "textblob.nltk.corpus.reader.propbank",
    "textblob.download_corpora",
    "chunked",
    "textblob.nltk.tokenize.punkt",
    "textblob.nltk.align",
    "model.ngram",
    "base",
    "cluster.util",
    "corpus.reader.util",
    "concordance_app",
    "rslp",
    "corpus.reader.string_category",
    "corpus.reader.lin",
    "tests.test_np_extractor",
    "tasks",
    "inference",
    "app",
    "run_tests",
    "nltk.sem.glue",
    "corpus.reader.plaintext",
    "api",
    "flask_theme_support",
    "treetransforms",
    "textblob.nltk.parse.projectivedependencyparser",
    "textblob.nltk.app.chartparser_app",
    "unit",
    "cluster",
    "textblob.nltk.corpus.reader.bnc",
    "parse.malt",
    "nltk.classify.mallet",
    "textblob.nltk.grammar",
    "nltk.classify.maxent",
    "tag.mapping",
    "nltk.cluster.em",
    "reader.framenet",
    "textblob.nltk.corpus.reader.sinica_treebank",
    "sem.boxer",
    "tokenize",
    "textblob",
    "tag.hunpos",
    "corpus.reader.ieer",
    "nltk.classify.positivenaivebayes",
    "textblob.nltk.test.unit.test_seekable_unicode_stream_reader",
    "test.unit.test_corpus_views",
    "sort",
    "collocations_app",
    "textblob.nltk.test.semantics_fixt",
    "textblob.nltk.corpus.reader.string_category",
    "senseval",
    "textblob.nltk.corpus.reader.dependency",
    "inflect",
    "reader.wordlist",
    "sem.cooper_storage",
    "nltk.corpus.reader.aligned",
    "tests.test_tokenizers",
    "nltk.tokenize.regexp",
    "textblob.nltk.model.ngram",
    "nltk.sem.linearlogic",
    "stem.porter",
    "test.unit",
    "test.unit.utils",
    "aligned",
    "textblob.nltk.cluster",
    "tnt",
    "nltk.test.gluesemantics_malt_fixt",
    "test.unit.test_naivebayes",
    "reader.aligned",
    "textblob.nltk.metrics.association",
    "textblob.nltk.toolbox",
    "malt",
    "classify.scikitlearn",
    "textblob.nltk.corpus.reader.pl196x",
    "tag",
    "nltk.parse.earleychart",
    "tests.test_utils",
    "exceptions",
    "corpus.util",
    "nltk.parse.nonprojectivedependencyparser",
    "spearman",
    "conf",
    "textblob.nltk.featstruct",
    "reader.verbnet",
    "test.wordnet_fixt",
    "wordnet_app",
    "textblob.nltk.chunk.regexp",
    "corpus.reader.conll",
    "nltk.misc.sort",
    "textblob.nltk.parse.malt",
    "nltk.stem.api",
    "nltk.tag.crf",
    "textblob.nltk.inference.discourse",
    "draw.dispersion",
    "textblob.nltk.app.concordance_app",
    "nltk.cluster.util",
    "reader.switchboard",
    "parse.earleychart",
    "textblob.nltk.parse.rd",
    "nltk.classify.weka",
    "inference_fixt",
    "textblob.translate",
    "textblob.nltk.corpus",
    "textblob.nltk.inference.mace",
    "tableau",
    "reader.toolbox",
    "reader.api",
    "textblob.nltk.sem.relextract",
    "textblob.taggers",
    "nltk.corpus.reader.switchboard",
    "classify",
    "nltk.test.doctest_nose_plugin",
    "rude",
    "model.api",
    "sem.drt",
    "corpus.reader.wordnet",
    "mapping",
    "en.sentiments",
    "_text",
    "textblob.nltk.test.gluesemantics_malt_fixt",
    "data",
    "test.runtests",
    "textblob.nltk.classify.svm",
    "sr",
    "nltk.parse.api",
    "textblob.nltk.help",
    "nltk.chunk.util",
    "metrics.scores",
    "textblob.nltk.corpus.reader.tagged",
    "nltk",
    "tagged",
    "classify_fixt",
    "chat.util",
    "textblob.nltk.chunk.named_entity",
    "nltk.inference.tableau",
    "ieer",
    "zen",
    "corpus.reader.nombank",
    "nltk.tag.stanford",
    "reader.timit",
    "earleychart",
    "parse.projectivedependencyparser",
    "nltk.misc.minimalset",
    "textblob.nltk.corpus.reader.ieer",
    "skolemize",
    "reader.nombank",
    "nltk.collocations",
    "corpus.reader.udhr",
    "textblob.nltk.sem.cooper_storage",
    "collocations",
    "nltk.parse.util",
    "nltk.classify.tadm",
    "classify.maxent",
    "textblob.nltk.tag.mapping",
    "nltk.classify.megam",
    "textblob.nltk.chat.suntsu",
    "textblob.nltk.sem.util",
    "nltk.test.inference_fixt",
    "textblob.nltk.test.segmentation_fixt",
    "chunk.api",
    "sentiments",
    "nltk.test.unit.test_hmm",
    "test.portuguese_en_fixt",
    "udhr",
    "propbank",
    "unit.test_hmm",
    "textblob.nltk.sem.logic",
    "nltk.inference",
    "nltk.align",
    "nemo_app",
    "docs",
    "nltk.tokenize.api",
    "app.rdparser_app",
    "kmeans",
    "textblob.nltk.chat.eliza",
    "snowball",
    "corpus.reader.semcor",
    "nltk.cluster.api",
    "docs.conf",
    "nltk.chat.util",
    "nltk.stem.snowball",
    "grammar",
    "nltk.cluster.kmeans",
    "textblob.nltk.inference.resolution",
    "parse.api",
    "textblob.nltk.chat.iesha",
    "suntsu",
    "textblob.nltk.classify.naivebayes",
    "textblob.nltk.corpus.reader.rte",
    "test.probability_fixt",
    "textblob.nltk.app.chunkparser_app",
    "tag.senna",
    "chat.zen",
    "em",
    "nltk.test.unit.utils",
    "en",
    "tokenize.simple",
    "corpus.europarl_raw",
    "nltk.test.unit.test_tag",
    "chunk",
    "stem.rslp",
    "childes",
    "textblob.nltk.test.classify_fixt",
    "tests.test_formats",
    "unit.test_corpora",
    "nltk.lazyimport",
    "segmentation_fixt",
    "nltk.app.srparser_app",
    "textblob.nltk.tag.brill",
    "nltk.examples",
    "textblob.nltk",
    "textblob.nltk.corpus.reader.api",
    "corpus.reader.wordlist",
    "nltk.model",
    "textblob.nltk.draw.table",
    "rd",
    "nltk.test.childes_fixt",
    "sem.skolemize",
    "nltk.test.wordnet_fixt",
    "nltk.test.unit.test_naivebayes",
    "reader",
    "nltk.test.semantics_fixt",
    "crf",
    "textblob.nltk.corpus.reader.aligned",
    "decorators",
    "corpus.reader.toolbox",
    "classify.naivebayes",
    "nltk.ccg.api",
    "punkt",
    "test.gluesemantics_malt_fixt",
    "app.collocations_app",
    "nltk.corpus.reader.chunked",
    "nltk.corpus.reader.timit",
    "nltk.sem",
    "textblob.nltk.corpus.reader.senseval",
    "textblob.nltk.tag.hunpos",
    "nltk.corpus.reader.indian",
    "generate",
    "reader.rte",
    "ppattach",
    "corpus.reader.sinica_treebank",
    "test_corpora",
    "nltk.book",
    "nltk.test.unit.test_classify",
    "app.chartparser_app",
    "textblob.nltk.corpus.reader.nps_chat",
    "nltk.metrics.agreement",
    "nltk.parse.malt",
    "en.taggers",
    "test_translate",
    "test_naivebayes",
    "ccg.api",
    "textblob.nltk.test.unit.test_naivebayes",
    "textblob.nltk.tag.util",
    "corpus.reader.api",
    "probability",
    "combinator",
    "misc",
    "tests.test_taggers",
    "parse.dependencygraph",
    "featstruct",
    "corpus.reader.tagged",
    "stem.snowball",
    "nltk.tag.api",
    "docs._themes",
    "classify.decisiontree",
    "tokenize.treebank",
    "reader.propbank",
    "stem.api",
    "textblob.nltk.inference",
    "inference.tableau",
    "unit.test_corpus_views",
    "weka",
    "chasen",
    "test_np_extractor",
    "textblob.nltk.sem.chat80",
    "nltk.test.unit.test_corpora",
    "pl196x",
    "textblob.nltk.tokenize.regexp",
    "nltk.classify.api",
    "textblob.nltk.examples.pt",
    "nltk.ccg.combinator",
    "textblob.nltk.test.unit.utils",
    "textblob.nltk.corpus.reader.chunked",
    "corpus.reader.childes",
    "classify.svm",
    "corpus",
    "textblob.nltk.test.unit.test_classify",
    "inference.api",
    "cluster.api",
    "inference.prover9",
    "gluesemantics_malt_fixt",
    "childes_fixt",
    "reader.tagged",
    "nltk.app.chunkparser_app",
    "megam",
    "reader.chasen",
    "nltk.corpus",
    "en.np_extractors",
    "nltk.chunk.regexp",
    "textblob.nltk.inference.api",
    "reader.semcor",
    "textblob.nltk.tag",
    "classifiers",
    "nltk.stem.porter",
    "distance",
    "textblob.utils",
    "textblob.nltk.parse.featurechart",
    "textblob.nltk.ccg.chart",
    "test.inference_fixt",
    "textblob.nltk.corpus.reader.wordlist",
    "nltk.tree",
    "tree",
    "sem.lfg",
    "reader.ycoe",
    "nltk.corpus.reader.bnc",
    "nltk.corpus.reader.cmudict",
    "textblob.nltk.test.unit",
    "nltk.corpus.reader.nps_chat",
    "corpus.reader.framenet",
    "nltk.tokenize",
    "nltk.metrics.scores",
    "prover9",
    "nltk.sem.relextract",
    "xmldocs",
    "plaintext",
    "viterbi",
    "textblob.nltk.parse.earleychart",
    "textblob.classifiers",
    "textblob.nltk.corpus.reader.bracket_parse",
    "relextract",
    "europarl_raw",
    "wordfinder",
    "nltk.corpus.reader.plaintext",
    "nltk.app.concordance_app",
    "test.unit.test_seekable_unicode_stream_reader",
    "test_corpus_views",
    "textblob.nltk.cluster.util",
    "textblob.nltk.metrics.confusionmatrix",
    "textblob.nltk.corpus.reader.timit",
    "textblob.nltk.misc.wordfinder",
    "nltk.corpus.reader.rte",
    "reader.nps_chat",
    "textblob.nltk.ccg",
    "lin",
    "nltk.help",
    "textblob.nltk.corpus.reader.cmudict",
    "textblob.nltk.util",
    "semcor",
    "nltk.classify.scikitlearn",
    "nltk.corpus.reader.childes",
    "test_taggers",
    "test_classify",
    "nltk.corpus.reader.knbc",
    "linearlogic",
    "nltk.corpus.reader.ppattach",
    "nltk.metrics",
    "nltk.corpus.reader.semcor",
    "chart",
    "metrics",
    "mace",
    "reader.udhr",
    "textblob.nltk.corpus.reader.nombank",
    "corpus.reader.ppattach",
    "textblob.nltk.chat.util",
    "textblob.nltk.metrics.segmentation",
    "misc.wordfinder",
    "nltk.corpus.reader.senseval",
    "textblob.nltk.sem.drt_glue_demo",
    "unit.test_2x_compat",
    "knbc",
    "test_hmm",
    "nltk.app.wordnet_app",
    "nltk.chat.iesha",
    "corpus.reader.nps_chat",
    "textblob.base",
    "textblob.nltk.test.unit.test_hmm",
    "nltk.metrics.association",
    "textblob.nltk.sem.lfg",
    "corpus_fixt",
    "nltk.tokenize.util",
    "rte",
    "reader.chunked",
    "nps_chat",
    "nltk.corpus.reader.tagged",
    "nltk.parse.chart",
    "nltk.tokenize.treebank",
    "treebank",
    "nltk.metrics.distance",
    "textblob.nltk.metrics.scores",
    "corpus.reader.bracket_parse",
    "test_2x_compat",
    "textblob.nltk.misc",
    "nltk.draw.table",
    "sem.relextract",
    "textblob.nltk.sem.drt",
    "textblob.nltk.classify",
    "textblob.nltk.tokenize.util",
    "nltk.tag.hmm",
    "textblob.nltk.chunk.util",
    "drt_glue_demo",
    "nltk.misc.wordfinder",
    "tokenize.util",
    "textblob.wordnet",
    "nltk.corpus.reader.udhr",
    "nltk.chat.rude",
    "corpus.reader.knbc",
    "draw.tree",
    "textblob.nltk.classify.tadm",
    "textblob.nltk.decorators",
    "nltk.corpus.reader.wordlist",
    "corpus.reader.ycoe",
    "nltk.draw.util",
    "stem.lancaster",
    "textblob.nltk.test.wordnet_fixt",
    "tag.util",
    "nltk.app.collocations_app",
    "test.unit.test_collocations",
    "textblob.nltk.corpus.reader.toolbox",
    "textblob.nltk.app.nemo_app",
    "en.parsers",
    "test.all",
    "textblob.nltk.parse.chart",
    "nltk.test.compat_fixt",
    "unit.utils",
    "corpus.reader.dependency",
    "textblob.nltk.classify.util",
    "reader.string_category",
    "nonmonotonic_fixt",
    "nltk.sem.evaluate",
    "textblob.nltk.compat",
    "nltk.treetransforms",
    "textblob.nltk.parse.sr",
    "chunkparser_app",
    "test_tag",
    "nltk.classify.svm",
    "textblob.nltk.app.wordfreq_app",
    "nltk.corpus.reader.toolbox",
    "textblob.en.taggers",
    "compat_fixt",
    "nltk.yamltags",
    "nltk.sem.util",
    "textblob.nltk.cluster.kmeans",
    "nltk.tag.util",
    "corpus.reader.verbnet",
    "nltk.chunk",
    "sem",
    "chat80",
    "verbnet",
    "lancaster",
    "nltk.chunk.api",
    "test_classifiers",
    "segmentation",
    "nltk.test.corpus_fixt",
    "classify.positivenaivebayes",
    "nltk.corpus.reader.nombank",
    "app.srparser_app",
    "textblob.nltk.sem.linearlogic",
    "textblob.nltk.draw.tree",
    "tokenize.punkt",
    "unit.test_tag",
    "test_parsers",
    "textblob.nltk.app.wordnet_app",
    "textblob.nltk.metrics.distance",
    "test.segmentation_fixt",
    "hunpos",
    "parse.nonprojectivedependencyparser",
    "textblob.nltk.misc.babelfish",
    "chartparser_app",
    "docs._themes.flask_theme_support",
    "nltk.tokenize.texttiling",
    "dependencygraph",
    "textblob.nltk.metrics.agreement",
    "textblob.nltk.text",
    "classify.rte_classify",
    "nltk.metrics.confusionmatrix",
    "textblob.nltk.corpus.reader.semcor",
    "test_seekable_unicode_stream_reader",
    "textblob.nltk.test",
    "textblob.nltk.test.runtests",
    "texttiling",
    "textblob.nltk.corpus.reader.plaintext",
    "parse.pchart",
    "textblob.nltk.test.unit.test_stem",
    "reader.childes",
    "sem.evaluate",
    "textblob.nltk.cluster.gaac",
    "textblob.en.np_extractors",
    "maxent",
    "textblob.nltk.misc.sort",
    "textblob.nltk.parse.api",
    "reader.dependency",
    "logic",
    "textblob.nltk.corpus.reader.ycoe",
    "metrics.confusionmatrix",
    "cluster.gaac",
    "download_corpora",
    "draw.cfg",
    "simple",
    "textblob.nltk.stem.porter",
    "textblob.nltk.corpus.reader",
    "nltk.corpus.reader.bracket_parse",
    "tag.api",
    "nltk.util",
    "textblob.nltk.stem.lancaster",
    "chunk.named_entity",
    "table",
    "textblob.nltk.draw.util",
    "textblob.nltk.test.all",
    "nltk.classify",
    "textblob.nltk.tokenize.simple",
    "test.doctest_nose_plugin",
    "packages",
    "pt",
    "textblob.nltk.test.corpus_fixt",
    "nltk.corpus.reader.dependency",
    "textblob.nltk.test.doctest_nose_plugin",
    "nltk.test.runtests",
    "yamltags",
    "nltk.misc.babelfish",
    "nombank",
    "nltk.corpus.reader.conll",
    "sem.linearlogic",
    "nltk.sem.chat80",
    "textblob.nltk.metrics",
    "tests.test_parsers",
    "reader.indian",
    "nltk.corpus.reader.string_category",
    "textblob.nltk.corpus.reader.verbnet",
    "nltk.corpus.reader.chasen",
    "_themes",
    "sem.drt_glue_demo",
    "cluster.kmeans",
    "textblob.compat",
    "nltk.data",
    "textblob.nltk.yamltags",
    "metrics.distance",
    "corpus.reader.rte",
    "test.unit.test_classify",
    "iesha",
    "textblob.nltk.examples",
    "textblob.nltk.corpus.reader.knbc",
    "test_collocations",
    "reader.wordnet",
    "app.concordance_app",
    "textblob.nltk.test.childes_fixt",
    "sem.logic",
    "align",
    "nltk.corpus.reader.api",
    "textblob.nltk.stem.regexp",
    "nltk.tag.brill",
    "textblob.nltk.sem.skolemize",
    "parsers",
    "nltk.test.unit.test_collocations",
    "textblob.nltk.corpus.reader.xmldocs",
    "textblob.nltk.test.discourse_fixt",
    "nltk.app.wordfreq_app",
    "nltk.inference.nonmonotonic",
    "textblob.nltk.tag.senna",
    "nltk.test.align_fixt",
    "textblob.nltk.corpus.reader.indian",
    "inference.mace",
    "textblob.nltk.treetransforms",
    "textblob.nltk.test.inference_fixt",
    "textblob.nltk.corpus.reader.lin",
    "nltk.tag.tnt",
    "ycoe",
    "textblob.nltk.stem",
    "textblob.nltk.inference.nonmonotonic",
    "nltk.corpus.reader.propbank",
    "utils",
    "textblob.nltk.cluster.api",
    "tests",
    "nltk.ccg.chart",
    "drt",
    "parse",
    "textblob.nltk.model",
    "nltk.probability",
    "corpus.reader.xmldocs",
    "textblob.nltk.corpus.reader.ppattach",
    "nltk.app.nemo_app",
    "semantics_fixt",
    "reader.sinica_treebank",
    "wordnet",
    "textblob.nltk.classify.megam",
    "nltk.test.segmentation_fixt",
    "nltk.downloader",
    "runtests",
    "nltk.stem.regexp",
    "test_stem",
    "nltk.corpus.reader.wordnet",
    "discourse",
    "_themes.flask_theme_support",
    "toolbox",
    "nltk.tokenize.sexpr",
    "textblob.nltk.chat",
    "nltk.parse",
    "test.discourse_fixt",
    "tokenize.sexpr",
    "cmudict",
    "nltk.inference.resolution",
    "draw.util",
    "np_extractors",
    "nltk.examples.pt",
    "textblob.nltk.test.align_fixt",
    "chat.iesha",
    "timit",
    "app.chunkparser_app",
    "nltk.test",
    "tests.test_decorators",
    "decisiontree",
    "unit.test_collocations",
    "classify.api",
    "textblob.nltk.classify.decisiontree",
    "nltk.parse.rd",
    "textblob.nltk.sem.evaluate",
    "pchart",
    "nltk.corpus.reader.sinica_treebank",
    "test_formats",
    "nltk.parse.projectivedependencyparser",
    "nltk.chunk.named_entity",
    "confusionmatrix",
    "corpus.reader.ipipan",
    "textblob.nltk.test.nonmonotonic_fixt",
    "nltk.classify.util",
    "textblob.nltk.corpus.reader.conll",
    "model",
    "classify.mallet",
    "corpus.reader.indian",
    "textblob.nltk.probability",
    "classify.megam",
    "unit.test_classify",
    "lazyimport",
    "tokenize.texttiling",
    "textblob.nltk.classify.api",
    "textblob.nltk.corpus.reader.childes",
    "nltk.test.classify_fixt",
    "ngram",
    "nltk.test.probability_fixt",
    "glue",
    "nltk.grammar",
    "misc.chomsky",
    "corpus.reader.chasen",
    "textblob.nltk.stem.api",
    "textblob.nltk.draw",
    "tag.hmm",
    "unit.test_naivebayes",
    "textblob.sentiments",
    "sinica_treebank",
    "help",
    "nltk.corpus.reader.util",
    "nltk.sem.drt_glue_demo",
    "textblob.nltk.test.unit.test_tag",
    "sem.util",
    "metrics.spearman",
    "blob",
    "tests.test_classifiers",
    "textblob.nltk.corpus.reader.switchboard",
    "bnc",
    "wordnet_fixt",
    "test.unit.test_hmm",
    "test.compat_fixt",
    "nltk.misc.chomsky",
    "chat.eliza",
    "sequential",
    "textblob.nltk.tag.tnt",
    "evaluate",
    "stem.isri",
    "textblob.nltk.classify.weka",
    "classify.weka",
    "nltk.chat",
    "boxer",
    "textblob.parsers",
    "minimalset",
    "nltk.sem.logic",
    "tag.sequential",
    "nltk.tag.mapping",
    "corpus.reader.chunked",
    "rdparser_app",
    "chat.rude",
    "corpus.reader.bnc",
    "classify.tadm",
    "nltk.corpus.reader.ieer",
    "app.wordfreq_app",
    "nltk.corpus.util",
    "nltk.text",
    "tag.brill",
    "reader.ieer",
    "textblob.nltk.app.rdparser_app",
    "nltk.parse.featurechart",
    "chunk.regexp",
    "textblob.nltk.corpus.util",
    "framenet",
    "textblob.nltk.parse.util",
    "textblob.nltk.inference.tableau",
    "textblob.tokenizers",
    "nltk.cluster.gaac",
    "textblob.nltk.app",
    "textblob.nltk.draw.cfg",
    "textblob.nltk.ccg.api",
    "textblob.nltk.corpus.reader.framenet",
    "reader.pl196x",
    "tokenize.api",
    "textblob.nltk.test.portuguese_en_fixt",
    "nltk.test.discourse_fixt",
    "parse.viterbi",
    "textblob.nltk.draw.dispersion",
    "examples",
    "textblob._text",
    "textblob.nltk.corpus.europarl_raw",
    "textblob.nltk.internals",
    "textblob.nltk.misc.minimalset",
    "nltk.test.portuguese_en_fixt",
    "textblob.nltk.test.unit.test_corpus_views",
    "corpus.reader.senseval",
    "nltk.stem.isri",
    "nltk.sem.skolemize",
    "corpus.reader.cmudict",
    "nltk.test.unit.test_corpus_views",
    "srparser_app",
    "textblob.decorators",
    "textblob.nltk.chat.rude",
    "nltk.sem.cooper_storage",
    "porter",
    "corpus.reader.timit",
    "lexicon",
    "nltk.test.nonmonotonic_fixt",
    "test_sentiments",
    "textblob.nltk.tokenize.texttiling",
    "nltk.classify.naivebayes",
    "corpus.reader",
    "textblob.nltk.tag.stanford",
    "nltk.cluster",
    "misc.babelfish",
    "projectivedependencyparser",
    "agreement",
    "misc.sort",
    "en.inflect",
    "nltk.draw.dispersion",
    "nltk.inference.api",
    "test_decorators",
    "app.nemo_app",
    "textblob.nltk.test.unit.test_2x_compat",
    "regexp",
    "textblob.formats",
    "ccg.lexicon",
    "test.corpus_fixt",
    "nltk.parse.viterbi",
    "textblob.nltk.tag.api",
    "chomsky",
    "nltk.model.api",
    "dependency",
    "textblob.nltk.sem.glue",
    "test.unit.test_stem",
    "textblob.nltk.parse.viterbi",
    "textblob.nltk.stem.isri",
    "textblob.nltk.ccg.lexicon",
    "reader.ppattach",
    "association",
    "nltk.app.chartparser_app",
    "textblob.nltk.tokenize.treebank",
    "nltk.test.all",
    "sexpr",
    "lfg",
    "inference.resolution",
    "tadm",
    "cooper_storage",
    "reader.ipipan",
    "parse.sr",
    "textblob.en.parsers",
    "textblob.nltk.book",
    "textblob.nltk.parse.nonprojectivedependencyparser",
    "gaac",
    "ipipan",
    "textblob.nltk.tokenize",
    "align_fixt",
    "nltk.corpus.reader.xmldocs",
    "nltk.ccg.lexicon",
    "tag.stanford",
    "dispersion",
    "nltk.corpus.reader.ycoe",
    "textblob.inflect",
    "test.nonmonotonic_fixt",
    "nltk.sem.hole",
    "parse.generate",
    "translate",
    "textblob.packages",
    "nltk.test.unit.test_stem",
    "nltk.corpus.reader.verbnet",
    "nltk.stem.wordnet",
    "metrics.association",
    "corpus.reader.switchboard",
    "nltk.sem.drt",
    "textblob.nltk.test.compat_fixt",
    "textblob.nltk.test.unit.test_corpora",
    "reader.knbc",
    "textblob.nltk.chat.zen",
    "isri",
    "switchboard",
    "textblob.nltk.corpus.reader.util",
    "parse.chart",
    "textblob.nltk.corpus.reader.ipipan",
    "scikitlearn",
    "nltk.tokenize.punkt",
    "tag.tnt",
    "textblob.nltk.tokenize.api",
    "sem.chat80",
    "nltk.parse.generate",
    "textblob.nltk.parse",
    "stanford",
    "textblob.nltk.inference.prover9",
    "textblob.nltk.classify.mallet",
    "tag.crf",
    "textblob.nltk.parse.generate",
    "textblob.nltk.cluster.em",
    "unit.test_seekable_unicode_stream_reader",
    "textblob.nltk.chunk",
    "wordfreq_app",
    "textblob.nltk.parse.dependencygraph",
    "nltk.stem.rslp",
    "tokenizers",
    "nltk.test.unit.test_2x_compat",
    "textblob.np_extractors",
    "nonprojectivedependencyparser",
    "nltk.parse.sr",
    "internals",
    "nltk.tag.senna",
    "nltk.tag.sequential",
    "nltk.corpus.reader",
    "nltk.inference.discourse",
    "examples.pt",
    "chat",
    "reader.xmldocs",
    "test.unit.test_2x_compat",
    "textblob.nltk.classify.rte_classify",
    "parse.rd",
    "nltk.classify.rte_classify",
    "textblob.exceptions",
    "unit.test_stem",
    "textblob.nltk.misc.chomsky",
    "metrics.segmentation",
    "nltk.toolbox",
    "nltk.test.unit.test_seekable_unicode_stream_reader",
    "nltk.misc",
    "book",
    "probability_fixt",
    "test",
    "nltk.model.ngram",
    "nonmonotonic",
    "featurechart",
    "textblob.en",
    "wordlist",
    "textblob.nltk.classify.maxent",
    "draw",
    "textblob.nltk.chunk.api",
    "conll",
    "nltk.compat",
    "nltk.stem",
    "reader.lin",
    "nltk.stem.lancaster",
    "portuguese_en_fixt",
    "nltk.corpus.europarl_raw",
    "nltk.draw",
    "scores",
    "reader.senseval",
    "reader.bnc",
    "nltk.sem.boxer",
    "corpus.reader.propbank",
    "textblob.nltk.stem.wordnet",
    "sem.glue",
    "textblob.nltk.sem.hole",
    "svm",
    "textblob.nltk.tag.hmm",
    "hmm",
    "nltk.decorators",
    "textblob.nltk.test.probability_fixt",
    "textblob.nltk.app.srparser_app",
    "nltk.draw.cfg",
    "named_entity",
    "text",
    "textblob.nltk.sem",
    "textblob.nltk.tokenize.sexpr",
    "resolution",
    "test.unit.test_tag"
]