__FILENAME__ = conf
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# Geofront documentation build configuration file, created by
# sphinx-quickstart on Sun Mar 30 18:52:45 2014.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys
import os
import os.path

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(
    0,
    os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
)

from geofront.version import VERSION

# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
needs_sphinx = '1.2'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.intersphinx',
    'sphinx.ext.todo',
    'sphinx.ext.extlinks',
    'sphinxcontrib.httpdomain',
    'sphinxcontrib.autohttp.flask',
    'sphinxcontrib.autoprogram'
]

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = 'Geofront'
copyright = '2014, Hong Minhee'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = VERSION
# The full version, including alpha/beta/rc tags.
release = VERSION

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all
# documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
html_title = '{} v{}'.format(project, release)

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# Add any extra paths that contain custom files (such as robots.txt or
# .htaccess) here, relative to this directory. These files are copied
# directly to the root of the documentation.
#html_extra_path = []

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Geofrontdoc'


# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title,
#  author, documentclass [howto, manual, or own class]).
latex_documents = [
  ('index', 'Geofront.tex', 'Geofront Documentation',
   'Hong Minhee', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output ---------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'geofront', 'Geofront Documentation',
     ['Hong Minhee'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output -------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Geofront', 'Geofront Documentation',
   'Hong Minhee', 'Geofront', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False


# Example configuration for intersphinx: refer to the Python standard library.
intersphinx_mapping = {
    'python': ('http://docs.python.org/3/', None),
    'paramiko': ('http://docs.paramiko.org/en/1.13/', None),
    'werkzeug': ('http://werkzeug.pocoo.org/docs/', None),
    'flask': ('http://flask.pocoo.org/docs/', None),
    'libcloud': ('https://libcloud.readthedocs.org/en/latest/', None),
    'waitress': ('http://docs.pylonsproject.org/projects/waitress/en/latest/',
                 None),
}


extlinks = {
    'issue': ('https://github.com/spoqa/geofront/issues/%s', '#'),
    'pr': ('https://github.com/spoqa/geofront/pull/%s', '#'),
    'branch': ('https://github.com/spoqa/geofront/compare/%s', ''),
    'commit': ('https://github.com/spoqa/geofront/commit/%s', '')
}


if os.environ.get('READTHEDOCS'):
    # http://read-the-docs.readthedocs.org/en/latest/faq.html#i-get-import-errors-on-libraries-that-depend-on-c-modules
    class Mock(object):
        def __init__(self, *a, **k):
            pass
        def __call__(self, *a, **k):
            return type(self)()
        def __getattr__(self, name):
            if name in {'__file__', '__path__'}:
                return '/dev/null'
            return Mock()
    sys.modules.update({
        'Crypto': Mock(),
        'Crypto.Cipher': Mock(),
        'Crypto.Cipher.AES': Mock(),
        'Crypto.Cipher.ARC2': Mock(),
        'Crypto.Cipher.ARC4': Mock(),
        'Crypto.Cipher.Blowfish': Mock(),
        'Crypto.Cipher.CAST': Mock(),
        'Crypto.Cipher.DES': Mock(),
        'Crypto.Cipher.DES3': Mock(),
        'Crypto.Cipher.PKCS1_OAEP': Mock(),
        'Crypto.Cipher.PKCS1_v1_5': Mock(),
        'Crypto.Cipher.XOR': Mock(),
        'Crypto.Cipher.blockalgo': Mock(),
        'Crypto.Hash': Mock(),
        'Crypto.Hash.HMAC': Mock(),
        'Crypto.Hash.MD2': Mock(),
        'Crypto.Hash.MD4': Mock(),
        'Crypto.Hash.MD5': Mock(),
        'Crypto.Hash.RIPEMD': Mock(),
        'Crypto.Hash.SHA': Mock(),
        'Crypto.Hash.SHA224': Mock(),
        'Crypto.Hash.SHA256': Mock(),
        'Crypto.Hash.SHA384': Mock(),
        'Crypto.Hash.SHA512': Mock(),
        'Crypto.Protocol': Mock(),
        'Crypto.Protocol.AllOrNothing': Mock(),
        'Crypto.Protocol.Chaffing': Mock(),
        'Crypto.Protocol.KDF': Mock(),
        'Crypto.PublicKey': Mock(),
        'Crypto.PublicKey.DSA': Mock(),
        'Crypto.PublicKey.ElGamal': Mock(),
        'Crypto.PublicKey.RSA': Mock(),
        'Crypto.Random': Mock(),
        'Crypto.Random.random': Mock(),
        'Crypto.Signature': Mock(),
        'Crypto.Signature.PKCS1_PSS': Mock(),
        'Crypto.Signature.PKCS1_v1_5': Mock(),
        'Crypto.Util': Mock(),
        'Crypto.Util.RFC1751': Mock(),
        'Crypto.Util.asn1': Mock(),
        'Crypto.Util.number': Mock(),
        'Crypto.Util.py21compat': Mock(),
        'Crypto.Util.randpool': Mock(),
        'Crypto.Util.strxor': Mock(),
        'Crypto.Util.winrandom': Mock(),
        'Crypto.pct_warnings': Mock(),
    })

########NEW FILE########
__FILENAME__ = example.cfg
# This is a configuration example.  See docs/config.rst as well.

# Scenario: Your team is using GitHub, and the organization login is @YOUR_TEAM.
# All members already registered their public keys to their GitHub accounts,
# and are using git through ssh public key authorization.

# First of all, you have to decide how to authorize team members.
# Geofront provides a built-in authorization method for GitHub organizations.
# It requires a pair of client keys (id and secret) for OAuth authentication.
# You can create one from:
#
# https://github.com/organizations/YOUR_TEAM/settings/applications/new
#
# Then import GitHubOrganization class, and configure a pair of client keys
# and your organization login name (@YOUR_TEAM in here).
from geofront.backends.github import GitHubOrganization

TEAM = GitHubOrganization(
   client_id='0123456789abcdef0123',
   client_secret='0123456789abcdef0123456789abcdef01234567',
   org_login='YOUR_TEAM'
)

# Your colleagues have already registered their public keys to GitHub,
# so you don't need additional storage for public keys.  We'd use GitHub
# as your public key store.
from geofront.backends.github import GitHubKeyStore

KEY_STORE = GitHubKeyStore()

# Unlike public keys, the master key ideally ought to be accessible by
# only Geofront.  Assume you use Amazon Web Services.  So you'll store
# the master key to the your private S3 bucket named your_team_master_key.
from geofront.backends.cloud import CloudMasterKeyStore
from libcloud.storage.types import Provider
from libcloud.storage.providers import get_driver

driver_cls = get_driver(Provider.S3)
driver = driver_cls('aws access key', 'aws secret key')
container = driver.get_container(container_name='your_team_master_key')
MASTER_KEY_STORE = CloudMasterKeyStore(driver, container, 'id_rsa')

# You have to let Geofront know what to manage remote servers.
# Although the list can be hard-coded in the configuration file,
# but you'll get the list dynamically from EC2 API.  Assume our all
# AMIs are Amazon Linux, so the usernames are always ec2-user.
# If you're using Ubuntu AMIs it should be ubuntu instead.
from geofront.backends.cloud import CloudRemoteSet
from libcloud.compute.types import Provider
from libcloud.compute.providers import get_driver

driver_cls = get_driver(Provider.EC2_US_WEST)
driver = driver_cls('aws access id', 'aws secret key')
REMOTE_SET = CloudRemoteSet(driver, user='ec2-user')

# Suppose your team is divided by several subgroups, and these subgroups are
# represented in teams of the GitHub organization.  So you can control
# who can access each remote by specifying allowed groups to its metadata.
# CloudRemoteSet which is used for above REMOTE_SET exposes each EC2 instance's
# metadata as it has.  We suppose every EC2 instance has Allowed-Groups
# metadata key and its value is space-separated list of group slugs.
# The following settings will allow only members who belong to corresponding
# groups to access.
from geofront.remote import GroupMetadataPermissionPolicy

PERMISSION_POLICY = GroupMetadataPermissionPolicy('Allowed-Groups')

# Geofront provisions access tokens (or you can think them as sessions)
# for Geofront clients.  Assume you already have a Redis server running
# on the same host.  We'd store tokens to the db 0 on that Redis server
# in the example.
from werkzeug.contrib.cache import RedisCache

TOKEN_STORE = RedisCache(host='localhost', db=0)

########NEW FILE########
__FILENAME__ = cloud
""":mod:`geofront.backends.cloud` --- Libcloud_-backed implementations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

This module provides built-in implementations of Geofront's some core
interfaces through libcloud.  Libcloud_ is "a library for interacting
with many of the popular cloud service providers using unified API."

.. versionadded:: 0.2.0

.. _Libcloud: http://libcloud.apache.org/

"""
import collections.abc
import re
try:
    from functools import singledispatch
except ImportError:
    from singledispatch import singledispatch
import io
import numbers
import os.path

from libcloud.compute.base import Node, NodeDriver
from libcloud.compute.drivers.gce import GCENodeDriver
from libcloud.compute.types import KeyPairDoesNotExistError
from libcloud.storage.base import Container, StorageDriver
from libcloud.storage.types import ObjectDoesNotExistError
from paramiko.pkey import PKey
from paramiko.rsakey import RSAKey

from ..identity import Identity
from ..keystore import (DuplicatePublicKeyError, KeyStore,
                        format_openssh_pubkey, get_key_fingerprint,
                        parse_openssh_pubkey)
from ..masterkey import EmptyStoreError, MasterKeyStore, read_private_key_file
from ..remote import Remote
from ..util import typed

__all__ = ('CloudKeyStore', 'CloudMasterKeyStore', 'CloudMasterPublicKeyStore',
           'CloudRemoteSet')


class CloudRemoteSet(collections.abc.Mapping):
    """Libcloud_-backed remote set.  It supports more than 20 cloud providers
    through the efforts of Libcloud_. ::

        from geofront.backends.cloud import CloudRemoteSet
        from libcloud.compute.types import Provider
        from libcloud.compute.providers import get_driver

        driver_cls = get_driver(Provider.EC2_US_WEST)
        driver = driver_cls('access id', 'secret key')
        REMOTE_SET = CloudRemoteSet(driver)

    If the given ``driver`` supports metadata feature (for example,
    AWS EC2, Google Compute Engine, and OpenStack support it)
    the resulted :class:`~geofront.remote.Remote` objects will
    fill their :attr:`~geofront.remote.Remote.metadata` as well.

    :param driver: libcloud compute driver
    :type driver: :class:`libcloud.compute.base.NodeDriver`
    :param user: the username to :program:`ssh`.
                 the default is ``'ec2-user'`` which is the default user
                 of amazon linux ami
    :type user: :class:`str`
    :param port: the port number to :program:`ssh`.
                the default is 22 which is the default :program:`ssh` port
    :type port: :class:`numbers.Integral`

    .. seealso::

       `Compute`__ --- Libcloud
          The compute component of libcloud allows you to manage
          cloud and virtual servers offered by different providers,
          more than 20 in total.

    .. _Libcloud: http://libcloud.apache.org/
    __ https://libcloud.readthedocs.org/en/latest/compute/

    .. versionchanged:: 0.2.0
       It fills :attr:`~geofront.remote.Remote.metadata` of the resulted
       :class:`~geofront.remote.Remote` objects if the ``driver`` supports.

    """

    @typed
    def __init__(self,
                 driver: NodeDriver,
                 user: str='ec2-user',
                 port: numbers.Integral=22):
        self.driver = driver
        self.user = user
        self.port = port
        self._nodes = None
        self._metadata = {} if supports_metadata(driver) else None

    def _get_nodes(self, refresh: bool=False) -> dict:
        if refresh or self._nodes is None:
            self._nodes = {node.name: node
                           for node in self.driver.list_nodes()
                           if node.public_ips}
            if self._metadata is not None:
                self._metadata.clear()
        return self._nodes

    def __len__(self) -> int:
        return len(self._get_nodes())

    def __iter__(self) -> collections.abc.Iterator:
        return iter(self._get_nodes(True))

    def __getitem__(self, alias: str) -> Remote:
        node = self._get_nodes()[alias]
        if self._metadata is None:
            metadata = {}
        else:
            try:
                metadata = self._metadata[alias]
            except KeyError:
                metadata = get_metadata(self.driver, node)
                self._metadata[alias] = metadata
        return Remote(self.user, node.public_ips[0], self.port, metadata)


@singledispatch
def supports_metadata(driver: NodeDriver) -> bool:
    """Whether this drive type supports metadata?"""
    return callable(getattr(driver, 'ex_get_metadata', None))


@singledispatch
def get_metadata(driver: NodeDriver, node: Node) -> collections.abc.Mapping:
    return driver.ex_get_metadata(node)


@supports_metadata.register(GCENodeDriver)
def gce_supports_metadata(driver: GCENodeDriver) -> bool:
    return True


@get_metadata.register(GCENodeDriver)
def gce_get_metadata(driver: GCENodeDriver,
                     node: Node) -> collections.abc.Mapping:
    return node.extra['metadata']


class CloudMasterKeyStore(MasterKeyStore):
    """Store the master key into the cloud object storage e.g. AWS S3_.
    It supports more than 20 cloud providers through the efforts of Libcloud_.
    ::

        from geofront.backends.cloud import CloudMasterKeyStore
        from libcloud.storage.types import Provider
        from libcloud.storage.providers import get_driver

        driver_cls = get_driver(Provider.S3)
        driver = driver_cls('api key', 'api secret key')
        container = driver.get_container(container_name='my-master-key-bucket')
        MASTER_KEY_STORE = CloudMasterKeyStore(container)

    :param driver: the libcloud storage driver
    :type driver: :class:`libcloud.storage.base.StorageDriver`
    :param container: the block storage container
    :type container: :class:`libcloud.storage.base.Container`
    :param object_name: the object name to use
    :type object_name: :class:`str`

    .. seealso::

       `Object Storage`__ --- Libcloud
          Storage API allows you to manage cloud object storage and
          services such as Amazon S3, Rackspace CloudFiles,
          Google Storage and others.

    .. _S3: http://aws.amazon.com/s3/
    .. _Libcloud: http://libcloud.apache.org/
    __ https://libcloud.readthedocs.org/en/latest/storage/

    """

    @typed
    def __init__(self,
                 driver: StorageDriver,
                 container: Container,
                 object_name: str):
        self.driver = driver
        self.container = container
        self.object_name = object_name

    @typed
    def load(self) -> PKey:
        try:
            obj = self.driver.get_object(self.container.name, self.object_name)
        except ObjectDoesNotExistError:
            raise EmptyStoreError()
        with io.BytesIO() as buffer_:
            for chunk in self.driver.download_object_as_stream(obj):
                if isinstance(chunk, str):  # DummyDriver yields str, not bytes
                    chunk = chunk.encode()
                buffer_.write(chunk)
            buffer_.seek(0)
            with io.TextIOWrapper(buffer_) as tio:
                return read_private_key_file(tio)

    @typed
    def save(self, master_key: PKey):
        with io.StringIO() as buffer_:
            master_key.write_private_key(buffer_)
            pem = buffer_.getvalue()
        self.driver.upload_object_via_stream(
            self._countable_iterator([pem]),
            self.container,
            self.object_name,
            {'content_type': 'application/x-pem-key'}
        )

    class _countable_iterator:
        """libcloud's storage driver takes an iterator as stream,
        but some drivers e.g. dummy driver try calling :func:`len()`
        to the iterator.  This adapter workarounds the situation.

        """

        @typed
        def __init__(self, sequence: collections.abc.Sequence):
            self.iterator = iter(sequence)
            self.length = len(sequence)

        def __len__(self):
            return self.length

        def __iter__(self):
            return self

        def __next__(self):
            return next(self.iterator)


class CloudKeyStore(KeyStore):
    """Store public keys into the cloud provider's key pair service.
    Note that not all providers support key pair service.  For example,
    Amazon EC2, and Rackspace (Next Gen) support it.  ::

        from geofront.backends.cloud import CloudKeyStore
        from libcloud.compute.types import Provider
        from libcloud.compute.providers import get_driver

        driver_cls = get_driver(Provider.EC2)
        driver = driver_cls('api key', 'api secret key')
        KEY_STORE = CloudKeyStore(driver)

    :param driver: libcloud compute driver
    :type driver: :class:`libcloud.compute.base.NodeDriver`
    :param key_name_format: the format which determines each key's name
                            used for the key pair service.
                            default is :const:`DEFAULT_KEY_NAME_FORMAT`
    :type key_name_format: :class:`str`

    """

    #: (:class:`str`) The default ``key_name_format``.  The type name of
    #: team followed by identifier, and then key fingerprint follows e.g.
    #: ``'geofront.backends.github.GitHubOrganization dahlia 00:11:22:..:ff'``.
    DEFAULT_KEY_NAME_FORMAT = ('{identity.team_type.__module__}.'
                               '{identity.team_type.__qualname__} '
                               '{identity.identifier} {fingerprint}')

    @typed
    def __init__(self, driver: NodeDriver, key_name_format: str=None):
        self.driver = driver
        self.key_name_format = key_name_format or self.DEFAULT_KEY_NAME_FORMAT

    def _get_key_name(self, identity: Identity, public_key: PKey):
        return self.key_name_format.format(
            identity=identity,
            public_key=public_key,
            fingerprint=get_key_fingerprint(public_key)
        )

    def _get_key_name_pattern(self, identity: Identity):
        """Make the regex pattern from the format string.  Put two different
        random keys, compare two outputs, and then replace the difference
        with wildcard.

        """
        cls = type(self)
        try:
            sample_keys = cls.sample_keys
        except AttributeError:
            sample_keys = RSAKey.generate(1024), RSAKey.generate(1024)
            cls.sample_keys = sample_keys
        sample_name_a = self._get_key_name(identity, sample_keys[0])
        sample_name_b = self._get_key_name(identity, sample_keys[1])
        if sample_name_a == sample_name_b:
            return re.compile('^' + re.escape(sample_name_a) + '$')
        prefix = os.path.commonprefix([sample_name_a, sample_name_b])
        postfix = os.path.commonprefix([sample_name_a[::-1],
                                        sample_name_b[::-1]])[::-1]
        return re.compile(
            '^{}.+?{}$'.format(re.escape(prefix), re.escape(postfix))
        )

    @typed
    def register(self, identity: Identity, public_key: PKey):
        name = self._get_key_name(identity, public_key)
        driver = self.driver
        try:
            driver.get_key_pair(name)
        except KeyPairDoesNotExistError:
            driver.import_key_pair_from_string(
                name,
                format_openssh_pubkey(public_key)
            )
        else:
            raise DuplicatePublicKeyError()

    @typed
    def list_keys(self, identity: Identity) -> collections.abc.Set:
        pattern = self._get_key_name_pattern(identity)
        return frozenset(
            parse_openssh_pubkey(key_pair.public_key)
            for key_pair in self.driver.list_key_pairs()
            if pattern.match(key_pair.name)
        )

    @typed
    def deregister(self, identity: Identity, public_key: PKey):
        try:
            key_pair = self.driver.get_key_pair(
                self._get_key_name(identity, public_key)
            )
        except KeyPairDoesNotExistError:
            return
        self.driver.delete_key_pair(key_pair)


class CloudMasterPublicKeyStore(MasterKeyStore):
    """It doesn't store the whole master key, but stores only public part of
    the master key into cloud provider's key pair registry.  So it requires
    the actual ``master_key_store`` to store the whole master key which is
    not only public part but also private part.

    It helps to create compute instances (e.g. Amazon EC2) that are already
    colonized.

    :param driver: libcloud compute driver
    :type driver: :class:`libcloud.compute.base.NodeDriver`
    :param key_pair_name: the name for cloud provider's key pair registry
    :type key_pair_name: :class:`str`
    :param master_key_store: "actual" master key store to store the whole
                             master key
    :type master_key_store: :class:`~geofront.masterkey.MasterKeyStore`

    .. versionadded:: 0.2.0

    """

    @typed
    def __init__(self,
                 driver: NodeDriver,
                 key_pair_name: str,
                 master_key_store: MasterKeyStore):
        self.driver = driver
        self.key_pair_name = key_pair_name
        self.master_key_store = master_key_store

    @typed
    def load(self) -> PKey:
        return self.master_key_store.load()

    @typed
    def save(self, master_key: PKey):
        public_key = format_openssh_pubkey(master_key)
        driver = self.driver
        try:
            key_pair = driver.get_key_pair(self.key_pair_name)
        except KeyPairDoesNotExistError:
            pass
        else:
            driver.delete_key_pair(key_pair)
        driver.import_key_pair_from_string(self.key_pair_name, public_key)
        self.master_key_store.save(master_key)

########NEW FILE########
__FILENAME__ = dbapi
""":mod:`geofront.backends.dbapi` --- Key store using DB-API 2.0
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. seealso::

   :pep:`249` --- Python Database API Specification v2.0

.. versionadded:: 0.2.0

"""
import base64
import collections.abc
import contextlib
import types

from paramiko.pkey import PKey

from ..identity import Identity
from ..keystore import (KEY_TYPES, DuplicatePublicKeyError, KeyStore,
                        KeyTypeError, get_key_fingerprint)
from ..util import typed

__all__ = 'DatabaseKeyStore',


class DatabaseKeyStore(KeyStore):
    """Store public keys into database through DB-API 2.0.  It takes
    a module that implements DB-API 2.0, and arguments/keywords to
    its ``connect()`` method.  For example, the following code stores
    public keys into SQLite 3 database::

        import sqlite3
        DatabaseKeyStore(sqlite3, 'geofront.db')

    The following code stores public keys into PostgreSQL database
    through psycopg2_::

        import psycopg2
        DatabaseKeyStore(psycopg2, database='geofront', user='postgres')

    It will create a table named ``geofront_public_key`` into the database.

    :param db_module: :pep:`249` DB-API 2.0 compliant module
    :type db_module: :class:`types.ModuleType`
    :param \*args: arguments to ``db_module.connect()`` function
    :param \*kwargs: keyword arguments to ``db_module.connect()`` function

    .. _psycopg2: http://initd.org/psycopg/

    """

    @typed
    def __init__(self, db_module: types.ModuleType, *args, **kwargs):
        if not callable(getattr(db_module, 'connect', None)):
            module_name = db_module.__name__
            raise TypeError('db_module must be DB-API 2.0 compliant, but {} '
                            'lacks connect() function'.format(module_name))
        self.db_module = db_module
        self.integrity_error = db_module.IntegrityError
        self.connection_args = args
        self.connection_kwargs = kwargs

    @contextlib.contextmanager
    def _connect(self):
        connection = self.db_module.connect(*self.connection_args,
                                            **self.connection_kwargs)
        cursor = connection.cursor()
        try:
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS geofront_public_key (
                    key_type VARCHAR(64) NOT NULL,
                    key_fingerprint VARCHAR(32) NOT NULL,
                    key_base64 VARCHAR(2048) NOT NULL,
                    team_type VARCHAR(128) NOT NULL,
                    identifier VARCHAR(128) NOT NULL,
                    PRIMARY KEY (key_type, key_fingerprint)
                )
            ''')
            connection.commit()
        finally:
            cursor.close()
        yield connection
        connection.close()

    def _execute(self, cursor, sql: str, params: tuple):
        """To support various paramstyles.  See the following specification:

        http://legacy.python.org/dev/peps/pep-0249/#paramstyle

        """
        paramstyle = self.db_module.paramstyle
        if paramstyle == 'format':
            sql = sql.replace('?', '%s')
        elif paramstyle != 'qmark':
            if paramstyle == 'numeric':
                fmt = ':{}'
                i = 1
            else:
                if paramstyle == 'named':
                    fmt = ':p{}'
                else:  # pyformat
                    fmt = '%(p{})s'
                params = {'p' + str(i): val for i, val in enumerate(params)}
                i = 0
            while '?' in sql:
                sql = sql.replace('?', fmt.format(i), 1)
                i += 1
        cursor.execute(sql, params)

    def _get_key_params(self, public_key: PKey) -> tuple:
        return public_key.get_name(), get_key_fingerprint(public_key, '')

    def _get_identity_params(self, identity: Identity) -> tuple:
        return ('{0.__module__}.{0.__qualname__}'.format(identity.team_type),
                str(identity.identifier))

    def _get_key_class(self, keytype: str) -> type:
        try:
            return KEY_TYPES[keytype]
        except KeyError:
            raise KeyTypeError('unsupported key type: ' + repr(keytype))

    @typed
    def register(self, identity: Identity, public_key: PKey):
        with self._connect() as connection:
            cursor = connection.cursor()
            try:
                params = (self._get_key_params(public_key) +
                          (public_key.get_base64(),) +
                          self._get_identity_params(identity))
                self._execute(cursor, '''
                    INSERT INTO geofront_public_key (
                        key_type, key_fingerprint, key_base64,
                         team_type, identifier
                    ) VALUES (?, ?, ?, ?, ?)
                ''', params)
                connection.commit()
            except self.integrity_error as e:
                raise DuplicatePublicKeyError(str(e))
            finally:
                cursor.close()

    @typed
    def list_keys(self, identity: Identity) -> collections.abc.Set:
        with self._connect() as connection:
            cursor = connection.cursor()
            try:
                self._execute(cursor, '''
                    SELECT key_type, key_base64
                    FROM geofront_public_key
                    WHERE team_type = ? AND identifier = ?
                ''', self._get_identity_params(identity))
                return frozenset(
                    self._get_key_class(keytype)(data=base64.b64decode(b64))
                    for keytype, b64 in cursor.fetchall()
                )
            finally:
                cursor.close()

    @typed
    def deregister(self, identity: Identity, public_key: PKey):
        with self._connect() as connection:
            cursor = connection.cursor()
            try:
                params = (self._get_key_params(public_key) +
                          self._get_identity_params(identity))
                self._execute(cursor, '''
                    DELETE FROM geofront_public_key
                    WHERE key_type = ? AND key_fingerprint = ? AND
                          team_type = ? AND identifier = ?
                ''', params)
                connection.commit()
            finally:
                cursor.close()

########NEW FILE########
__FILENAME__ = github
""":mod:`geofront.backends.github` --- GitHub organization and key store
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

"""
import base64
import collections
import collections.abc
import contextlib
import io
import json
import logging
import urllib.request

from paramiko.pkey import PKey
from paramiko.rsakey import RSAKey
from werkzeug.http import parse_options_header
from werkzeug.urls import url_encode, url_decode_stream
from werkzeug.wrappers import Request

from ..identity import Identity
from ..keystore import (DuplicatePublicKeyError, KeyStore,
                        format_openssh_pubkey, get_key_fingerprint,
                        parse_openssh_pubkey)
from ..team import AuthenticationError, Team
from ..util import typed


__all__ = 'GitHubKeyStore', 'GitHubOrganization', 'request'


def request(access_token, url: str, method: str='GET', data: bytes=None):
    """Make a request to GitHub API, and then return the parsed JSON result.

    :param access_token: api access token string,
                         or :class:`~geofront.identity.Identity` instance
    :type access_token: :class:`str`, :class:`~geofront.identity.Identity`
    :param url: the api url to request
    :type url: :class:`str`
    :param method: an optional http method.  ``'GET'`` by default
    :type method: :class:`str`
    :param data: an optional content body
    :type data: :class:`bytes`

    """
    if isinstance(access_token, Identity):
        access_token = access_token.access_token
    req = urllib.request.Request(
        url,
        headers={
            'Authorization': 'token ' + access_token,
            'Accept': 'application/json'
        },
        method=method,
        data=data
    )
    with contextlib.closing(urllib.request.urlopen(req)) as response:
        content_type = response.headers.get('Content-Type')
        mimetype, options = parse_options_header(content_type)
        assert mimetype == 'application/json' or method == 'DELETE', \
            'Content-Type of {} is not application/json but {}'.format(
                url,
                content_type
            )
        charset = options.get('charset', 'utf-8')
        io_wrapper = io.TextIOWrapper(response, encoding=charset)
        logger = logging.getLogger(__name__ + '.request')
        if logger.isEnabledFor(logging.DEBUG):
            read = io_wrapper.read()
            logger.debug(
                'HTTP/%d.%d %d %s\n%s\n\n%s',
                response.version // 10,
                response.version % 10,
                response.status,
                response.reason,
                '\n'.join('{}: {}'.format(k, v)
                          for k, v in response.headers.items()),
                read
            )
            if method == 'DELETE':
                return
            return json.loads(read)
        else:
            if method == 'DELETE':
                io_wrapper.read()
                return
            return json.load(io_wrapper)


class GitHubOrganization(Team):
    """Authenticate team membership through GitHub, and authorize to
    access GitHub key store.

    Note that group identifiers :meth:`list_groups()` method returns
    are GitHub team *slugs*.  You can find what team slugs are there in
    the organization using GitHub API:

    .. code-block:: console

       $ curl -u YourUserLogin https://api.github.com/orgs/YourOrgLogin/teams
       Enter host password for user 'YourUserLogin':
       [
         {
           "name": "Owners",
           "id": 111111,
           "slug": "owners",
           "permission": "admin",
           "url": "https://api.github.com/teams/111111",
           ...
         },
         {
           "name": "Programmers",
           "id": 222222,
           "slug": "programmers",
           "permission": "pull",
           "url": "https://api.github.com/teams/222222",
           ...
         }
       ]

    In the above example, ``owners`` and ``programmers`` are team slugs.

    :param client_id: github api client id
    :type client_id: :class:`str`
    :param client_secret: github api client secret
    :type client_secret: :class:`str`
    :param org_login: github org account name.  for example ``'spoqa'``
                      in https://github.com/spoqa
    :type org_login: :class:`str`

    """

    AUTHORIZE_URL = 'https://github.com/login/oauth/authorize'
    ACCESS_TOKEN_URL = 'https://github.com/login/oauth/access_token'
    USER_URL = 'https://api.github.com/user'
    ORGS_LIST_URL = 'https://api.github.com/user/orgs'
    TEAMS_LIST_URL = 'https://api.github.com/user/teams'

    @typed
    def __init__(self, client_id: str, client_secret: str, org_login: str):
        self.client_id = client_id
        self.client_secret = client_secret
        self.org_login = org_login

    @typed
    def request_authentication(self,
                               auth_nonce: str,
                               redirect_url: str) -> str:
        query = url_encode({
            'client_id': self.client_id,
            'redirect_uri': redirect_url,
            'scope': 'read:org,admin:public_key',
            'state': auth_nonce
        })
        authorize_url = '{}?{}'.format(self.AUTHORIZE_URL, query)
        return authorize_url

    @typed
    def authenticate(self,
                     auth_nonce: str,
                     requested_redirect_url: str,
                     wsgi_environ: collections.abc.Mapping) -> Identity:
        req = Request(wsgi_environ, populate_request=False, shallow=True)
        try:
            code = req.args['code']
            if req.args['state'] != auth_nonce:
                raise AuthenticationError()
        except KeyError:
            raise AuthenticationError()
        data = url_encode({
            'client_id': self.client_id,
            'client_secret': self.client_secret,
            'code': code,
            'redirect_uri': requested_redirect_url
        }).encode()
        response = urllib.request.urlopen(self.ACCESS_TOKEN_URL, data)
        content_type = response.headers['Content-Type']
        mimetype, options = parse_options_header(content_type)
        if mimetype == 'application/x-www-form-urlencoded':
            token_data = url_decode_stream(response)
        elif mimetype == 'application/json':
            charset = options.get('charset')
            token_data = json.load(
                io.TextIOWrapper(response, encoding=charset)
            )
        else:
            response.close()
            raise AuthenticationError(
                '{} sent unsupported content type: {}'.format(
                    self.ACCESS_TOKEN_URL,
                    content_type
                )
            )
        response.close()
        user_data = request(token_data['access_token'], self.USER_URL)
        identity = Identity(
            type(self),
            user_data['login'],
            token_data['access_token']
        )
        if self.authorize(identity):
            return identity
        raise AuthenticationError(
            '@{} user is not a member of @{} organization'.format(
                user_data['login'],
                self.org_login
            )
        )

    def authorize(self, identity: Identity) -> bool:
        if not issubclass(identity.team_type, type(self)):
            return False
        try:
            response = request(identity, self.ORGS_LIST_URL)
        except IOError:
            return False
        if isinstance(response, collections.abc.Mapping) and \
           'error' in response:
            return False
        return any(o['login'] == self.org_login for o in response)

    def list_groups(self, identity: Identity):
        if not issubclass(identity.team_type, type(self)):
            return frozenset()
        try:
            response = request(identity, self.TEAMS_LIST_URL)
        except IOError:
            return frozenset()
        if isinstance(response, collections.abc.Mapping) and \
           'error' in response:
            return frozenset()
        return frozenset(t['slug']
                         for t in response
                         if t['organization']['login'] == self.org_login)


class GitHubKeyStore(KeyStore):
    """Use GitHub account's public keys as key store."""

    LIST_URL = 'https://api.github.com/user/keys'
    DEREGISTER_URL = 'https://api.github.com/user/keys/{id}'

    @typed
    def register(self, identity: Identity, public_key: PKey):
        title = get_key_fingerprint(public_key)
        data = json.dumps({
            'title': title,
            'key': format_openssh_pubkey(public_key)
        })
        try:
            request(identity, self.LIST_URL, 'POST', data=data.encode())
        except urllib.request.HTTPError as e:
            if e.code != 422:
                raise
            content_type = e.headers.get('Content-Type')
            mimetype, options = parse_options_header(content_type)
            if mimetype != 'application/json':
                raise
            charset = options.get('charset', 'utf-8')
            response = json.loads(e.read().decode(charset))
            for error in response.get('errors', []):
                if not isinstance(error, dict):
                    continue
                elif error.get('field') != 'key':
                    continue
                message = error.get('message', '').strip().lower()
                if message != 'key is already in use':
                    continue
                raise DuplicatePublicKeyError(message)
            raise

    @typed
    def list_keys(self, identity: Identity) -> collections.abc.Set:
        keys = request(identity, self.LIST_URL)
        return {RSAKey(data=base64.b64decode(key['key'].split()[1]))
                for key in keys}

    @typed
    def deregister(self, identity: Identity, public_key: PKey):
        keys = request(identity, self.LIST_URL)
        for key in keys:
            if parse_openssh_pubkey(key['key']) == public_key:
                request(identity, self.DEREGISTER_URL.format(**key), 'DELETE')
                break

########NEW FILE########
__FILENAME__ = identity
""":mod:`geofront.identity` --- Member identification
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

"""
import collections.abc

from .util import typed

__all__ = 'Identity',


class Identity(collections.abc.Hashable):
    """Hashable value object which purposes to identify the owner of
    each public key in the store.

    :param team_type: a sbclass of :class:`~.team.Team`
    :type team_type: :class:`type`
    :param identifier: any hashable identifier for the owner.
                       it's interpreted by ``team_type``
    :type identifier: :class:`collections.abc.Hashable`
    :param access_token: an optional access token which may used by key store

    """

    #: (:class:`type`) A subclass of :class:`~.team.Team`.
    team_type = None

    #: (:class:`collections.abc.Hashable`) Any hashable identifier for
    #: the owner.  It's interpreted by :attr:`team_type`.
    identifier = None

    #: An optional access token which may be used by key store.
    #:
    #: .. note::
    #:
    #:    The attribute is ignored by :token:`==`, and :token:`!=`
    #:    operators, and :func:`hash()` function.
    access_token = None

    @typed
    def __init__(self,
                 team_type: type,
                 identifier: collections.abc.Hashable,
                 access_token=None):
        self.team_type = team_type
        self.identifier = identifier
        self.access_token = access_token

    def __eq__(self, other):
        return (isinstance(other, type(self)) and
                self.team_type is other.team_type and
                self.identifier == other.identifier)

    def __ne__(self, other):
        return not (self == other)

    def __hash__(self):
        return hash((self.team_type, self.identifier))

    def __repr__(self):
        fmt = ('{0.__module__}.{0.__qualname__}'
               '({1.__module__}.{1.__qualname__}, {2!r}, access_token={3!r})')
        return fmt.format(
            type(self),
            self.team_type,
            self.identifier,
            self.access_token
        )

########NEW FILE########
__FILENAME__ = keystore
""":mod:`geofront.keystore` --- Public key store
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

"""
import base64
import collections.abc

from paramiko.dsskey import DSSKey
from paramiko.rsakey import RSAKey
from paramiko.pkey import PKey

from .identity import Identity
from .util import typed

__all__ = ('KEY_TYPES', 'AuthorizationError', 'DuplicatePublicKeyError',
           'KeyStore', 'KeyStoreError', 'KeyTypeError',
           'format_openssh_pubkey', 'get_key_fingerprint',
           'parse_openssh_pubkey')


#: (:class:`collections.Mapping`) The mapping of supported key types.
KEY_TYPES = {
    'ssh-rsa': RSAKey,
    'ssh-dss': DSSKey
}


@typed
def parse_openssh_pubkey(line: str) -> PKey:
    """Parse an OpenSSH public key line, used by :file:`authorized_keys`,
    :file:`id_rsa.pub`, etc.

    :param line: a line of public key
    :type line: :class:`str`
    :return: the parsed public key
    :rtype: :class:`paramiko.pkey.PKey`
    :raise ValueError: when the given ``line`` is an invalid format
    :raise KeyTypeError: when it's an unsupported key type

    """
    keytype, b64, *_ = line.split()
    try:
        cls = KEY_TYPES[keytype]
    except KeyError:
        raise KeyTypeError('unsupported key type: ' + repr(keytype))
    return cls(data=base64.b64decode(b64))


@typed
def format_openssh_pubkey(key: PKey) -> str:
    """Format the given ``key`` to an OpenSSH public key line, used by
    :file:`authorized_keys`, :file:`id_rsa.pub`, etc.

    :param key: the key object to format
    :type key: :class:`paramiko.pkey.PKey`
    :return: a formatted openssh public key line
    :rtype: :class:`str`

    """
    return '{} {} '.format(key.get_name(), key.get_base64())


@typed
def get_key_fingerprint(key: PKey, glue: str=':') -> str:
    """Get the hexadecimal fingerprint string of the ``key``.

    :param key: the key to get fingerprint
    :type key: :class:`paramiko.pkey.PKey`
    :param glue: glue character to be placed between bytes.
                 ``':'`` by default
    :type glue: :class:`str`
    :return: the fingerprint string
    :rtype: :class:`str`

    """
    return glue.join(map('{:02x}'.format, key.get_fingerprint()))


class KeyStore:
    """The key store backend interface.  Every key store has to guarantee
    that public keys are unique for all identities i.e. the same public key
    can't be registered across more than an identity.

    """

    @typed
    def register(self, identity: Identity, public_key: PKey):
        """Register the given ``public_key`` to the ``identity``.

        :param ientity: the owner identity
        :type identity: :class:`~.identity.Identity`
        :param public_key: the public key to register
        :type public_key: :class:`paramiko.pkey.PKey`
        :raise geofront.keystore.AuthorizationError:
            when the given ``identity`` has no required permission
            to the key store
        :raise geofront.keystore.DuplicatePublicKeyError:
            when the ``public_key`` is already in use


        """
        raise NotImplementedError('register() has to be implemented')

    @typed
    def list_keys(self, identity: Identity) -> collections.abc.Set:
        """List registered public keys of the given ``identity``.

        :param identity: the owner of keys to list
        :type identity: :class:`~.identity.Identity`
        :return: the set of :class:`paramiko.pkey.PKey`
                 owned by the ``identity``
        :rtype: :class:`collections.abc.Set`
        :raise geofront.keystore.AuthorizationError:
            when the given ``identity`` has no required permission
            to the key store

        """
        raise NotImplementedError('list_keys() has to be implemented')

    @typed
    def deregister(self, identity: Identity, public_key: PKey):
        """Remove the given ``public_key`` of the ``identity``.
        It silently does nothing if there isn't the given ``public_key``
        in the store.

        :param ientity: the owner identity
        :type identity: :class:`~.identity.Identity`
        :param public_key: the public key to remove
        :type public_key: :class:`paramiko.pkey.PKey`
        :raise geofront.keystore.AuthorizationError:
            when the given ``identity`` has no required permission
            to the key store

        """
        raise NotImplementedError('deregister() has to be implemented')


class KeyStoreError(Exception):
    """Exceptions related to :class:`KeyStore` are an instance of this."""


class AuthorizationError(KeyStoreError):
    """Authorization exception that rise when the given identity has
    no required permission to the key store.

    """


class DuplicatePublicKeyError(KeyStoreError):
    """Exception that rise when the given public key is already registered."""


class KeyTypeError(ValueError):
    """Unsupported public key type raise this type of error."""

########NEW FILE########
__FILENAME__ = masterkey
""":mod:`geofront.masterkey` --- Master key management
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Master key renewal process:

1. Create a new master key without updating the master key store.
2. Update every :file:`authorized_keys` to authorize both the previous
   and the new master keys.
3. Store the new master key to the master key store,
   and remove the previous master key.
4. Update very :file:`authorized_keys` to authorize only
   the new master key.

For more details, see also :class:`TwoPhaseRenewal`.

.. versionchanged:: 0.2.0
   ``CloudMasterKeyStore`` is moved from this module to
   :mod:`geofront.backends.cloud`.
   See :class:`~.backends.cloud.CloudMasterKeyStore`.

"""
import collections.abc
import datetime
import io
import logging
import os.path
import threading

from paramiko.pkey import PKey
from paramiko.rsakey import RSAKey
from paramiko.sftp_client import SFTPClient
from paramiko.ssh_exception import SSHException
from paramiko.transport import Transport

from .keystore import get_key_fingerprint
from .remote import AuthorizedKeyList, Remote
from .util import typed

__all__ = ('EmptyStoreError', 'FileSystemMasterKeyStore', 'MasterKeyStore',
           'PeriodicalRenewal', 'TwoPhaseRenewal',
           'read_private_key_file', 'renew_master_key')


class MasterKeyStore:
    """The master key store backend interface.  It can have only one
    master key at the most.

    """

    @typed
    def load(self) -> PKey:
        """Load the stored master key.

        :return: the stored master key
        :rtype: :class:`paramiko.pkey.PKey`
        :raise geofront.masterkey.EmptyStoreError:
            when there's no master key yet in the store

        """
        raise NotImplementedError('load() has to be implemented')

    @typed
    def save(self, master_key: PKey):
        """Remove the stored master key, and then save the new master key.
        The operation should be atomic.

        :param master_key: the new master key to replace the existing
                           master key
        :type master_key: :class:`paramiko.pkey.PKey`

        """
        raise NotImplementedError('save() has to be implemented')


class EmptyStoreError(Exception):
    """Exception that rises when there's no master key yet in the store."""


def read_private_key_file(file_: io.IOBase) -> PKey:
    """Read a private key file.  Similar to :meth:`PKey.from_private_key()
    <paramiko.pkey.PKey.from_private_key>` except it guess the key type.

    :param file_: a stream of the private key to read
    :type file_: :class:`io.IOBase`
    :return: the read private key
    :rtype: :class:`paramiko.pkey.PKery`
    :raise paramiko.ssh_exception.SSHException: when something goes wrong

    """
    classes = PKey.__subclasses__()
    last = len(classes) + 1
    for i, cls in enumerate(classes):
        try:
            return cls.from_private_key(file_)
        except SSHException:
            if i == last:
                raise
            file_.seek(0)
            continue


class TwoPhaseRenewal:
    """Renew the master key for the given ``servers``.  It's a context
    manager for :keyword:`with` statement.

    ::

        # State: servers allow only old_key;
        #        old_key is in the master_key_store
        with TwoPhaseRenewal(servers, old_key, new_key):
            # State: *servers allow both old_key and new_key;*
            #        old_key is in the master_key_store
            master_key_store.save(new_key)
            # State: servers allow both old_key and new_key;
            #        *new_key is in the master_key_store.*
        # State: *servers allow only new_key;*
        #        new_key is in the master_key_store

    :param servers: the set of :class:`~geofront.remote.Remote` servers
                    to renew their master key
    :type servers: :class:`collections.abc.Set`
    :param old_key: the previous master key to expire
    :type old_key: :class:`paramiko.pkey.PKey`
    :param new_key: the new master key to replace ``old_key``
    :type new_key: :class:`paramiko.pkey.PKey`

    """

    def __init__(self,
                 servers: collections.abc.Set,
                 old_key: PKey,
                 new_key: PKey):
        for server in servers:
            if not isinstance(server, Remote):
                raise TypeError('{0!r} is not an instance of {1.__module__}.'
                                '{1.__qualname__}'.format(server, Remote))
        self.servers = servers
        self.old_key = old_key
        self.new_key = new_key
        self.sftp_clients = None

    def __enter__(self):
        assert self.sftp_clients is None, 'the context is already started'
        sftp_clients = {}
        for server in self.servers:
            try:
                transport = Transport((server.host, server.port))
                transport.connect(pkey=self.old_key)
            except SSHException as e:
                for t, _, __ in sftp_clients.values():
                    t.close()
                l = logging.getLogger(__name__ + '.TwoPhaseRenewal.__enter__')
                l.exception(
                    'An exception rise during master key renewal '
                    '(%s -> %s, server: %s@%s:%d): %s',
                    get_key_fingerprint(self.old_key),
                    get_key_fingerprint(self.new_key),
                    server.user, server.host, server.port, str(e)
                )
                raise
            sftp_client = SFTPClient.from_transport(transport)
            authorized_keys = AuthorizedKeyList(sftp_client)
            sftp_clients[server] = transport, sftp_client, authorized_keys
            authorized_keys.append(self.new_key)
        self.sftp_clients = sftp_clients
        return self.servers

    def __exit__(self, exc_type, exc_val, exc_tb):
        assert self.sftp_clients is not None, 'the context is not started yet'
        for transport, client, authorized_keys in self.sftp_clients.values():
            if exc_val is None:
                authorized_keys[:] = [self.new_key]
            client.close()
            transport.close()
        self.sftp_clients = None


@typed
def renew_master_key(servers: collections.abc.Set,
                     key_store: MasterKeyStore,
                     bits: int=2048) -> PKey:
    """Renew the master key.  It creates a new master key, makes ``servers``
    to authorize the new key, replaces the existing master key with the
    new key in the ``key_store``, and then makes ``servers`` to deauthorize
    the old key.  All these operations are done in a two-phase renewal
    transaction.

    :param servers: servers to renew the master key.
                    every element has to be an instance of
                    :class:`~.remote.Remote`
    :type servers: :class:`collections.abc.Set`
    :param key_store: the master key store to update
    :type key_store: :class:`MasterKeyStore`
    :param bits: the number of bits the generated key should be.
                 it has to be 1024 at least, and a multiple of 256.
                 2048 by default
    :type bits: :class:`int`
    :returns: the created new master key
    :rtype: :class:`paramiko.pkey.PKey`

    .. versionadded:: 0.2.0
       The ``bits`` optional parameter.

    """
    logger = logging.getLogger(__name__ + '.renew_master_key')
    logger.info('renew the master key...')
    old_key = key_store.load()
    logger.info('the existing master key: %s', get_key_fingerprint(old_key))
    new_key = RSAKey.generate(bits)
    logger.info('created new master key: %s', get_key_fingerprint(new_key))
    logger.info('authorize the new master key...')
    with TwoPhaseRenewal(servers, old_key, new_key):
        logger.info('the new master key is authorized; '
                    'update the key store...')
        key_store.save(new_key)
        logger.info('master key store is successfully updated; '
                    'deauthorize the existing master key...')
    logger.info('master key renewal has finished')
    return new_key


class PeriodicalRenewal(threading.Thread):
    """Periodically renew the master key in the separated background thread.

    :param servers: servers to renew the master key.
                    every element has to be an instance of
                    :class:`~.remote.Remote`
    :type servers: :class:`collections.abc.Set`
    :param key_store: the master key store to update
    :type key_store: :class:`MasterKeyStore`
    :param interval: the interval to renew
    :type interval: :class:`datetime.timedelta`
    :param bits: the number of bits the generated key should be.
                 it has to be 1024 at least, and a multiple of 256.
                 2048 by default
    :type bits: :class:`int`
    :param start: whether to start the background thread immediately.
                  :const:`True` by default
    :type start: :class:`bool`

    .. versionadded:: 0.2.0
       The ``bits`` optional parameter.

    """

    @typed
    def __init__(self,
                 servers: collections.abc.Set,
                 key_store: MasterKeyStore,
                 interval: datetime.timedelta,
                 bits: int=2048,
                 start: bool=True):
        super().__init__()
        self.servers = servers
        self.key_store = key_store
        self.interval = interval
        self.bits = bits
        self.terminated = threading.Event()
        if self.start:
            self.start()

    def run(self):
        seconds = self.interval.total_seconds()
        terminated = self.terminated
        while not terminated.is_set():
            terminated.wait(seconds)
            if terminated.is_set():
                break
            renew_master_key(self.servers, self.key_store, self.bits)

    def terminate(self):
        """Graceful termination."""
        self.terminated.set()
        self.join(5)


class FileSystemMasterKeyStore(MasterKeyStore):
    """Store the master key into the file system.  Although not that secure,
    but it might help you to try out Geofront.

    :param path: the path to save file.  it has to end with the filename
    :type path: :class:`str`
    :raise OSError: when the ``path`` is not writable

    """

    @typed
    def __init__(self, path: str):
        dirname = os.path.dirname(path)
        if not os.path.isdir(dirname):
            raise NotADirectoryError(dirname + ' is not a directory')
        elif os.path.isdir(path):
            raise IsADirectoryError(path + ' is not a file, but a directory')
        self.path = path

    @typed
    def load(self) -> PKey:
        if os.path.isfile(self.path):
            classes = PKey.__subclasses__()
            last = len(classes) + 1
            for i, cls in enumerate(classes):
                try:
                    return cls.from_private_key_file(self.path)
                except SSHException:
                    if i == last:
                        raise
                    continue
        raise EmptyStoreError()

    @typed
    def save(self, master_key: PKey):
        master_key.write_private_key_file(self.path)

########NEW FILE########
__FILENAME__ = regen
""":mod:`geofront.regen` --- Regen master key
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

.. versionadded:: 0.2.0

"""
import argparse
import collections.abc
import logging
import os.path

from paramiko.rsakey import RSAKey

from .keystore import get_key_fingerprint
from .masterkey import EmptyStoreError, MasterKeyStore, renew_master_key
from .util import typed
from .version import VERSION

__all__ = 'main', 'main_parser', 'regenerate'


@typed
def main_parser(
    parser: argparse.ArgumentParser=None
) -> argparse.ArgumentParser:  # pragma: no cover
    """Create an :class:`~argparse.ArgumentParser` object for
    :program:`geofront-key-regen` CLI program.  It also is used for
    documentation through `sphinxcontrib-autoprogram`__.

    :return: a properly configured :class:`~argparse.ArgumentParser`
    :rtype: :class:`argparse.ArgumentParser`

    __ https://pythonhosted.org/sphinxcontrib-autoprogram/

    """
    parser = parser or argparse.ArgumentParser(
        description='Regen the Geofront master key'
    )
    parser.add_argument('config',
                        metavar='FILE',
                        help='geofront configuration file (Python script)')
    parser.add_argument('--create-master-key',
                        action='store_true',
                        help='create a new master key if no master key yet')
    parser.add_argument('-d', '--debug',
                        action='store_true',
                        help='debug mode')
    parser.add_argument('-v', '--version',
                        action='version',
                        version='%(prog)s ' + VERSION)
    return parser


@typed
def regenerate(master_key_store: MasterKeyStore,
               remote_set: collections.abc.Mapping,
               bits: int=2048,
               *,
               create_if_empty: bool,
               renew_unless_empty: bool):
    """Regenerate or create the master key."""
    logger = logging.getLogger(__name__ + '.regenerate')
    try:
        key = master_key_store.load()
    except EmptyStoreError:
        if create_if_empty:
            logger.warn('no master key;  create one...')
            key = RSAKey.generate(bits)
            master_key_store.save(key)
            logger.info('created new master key: %s', get_key_fingerprint(key))
        else:
            raise RegenError('no master key;  try --create-master-key option '
                             'if you want to create one')
    else:
        if renew_unless_empty:
            renew_master_key(frozenset(remote_set.values()),
                             master_key_store,
                             bits)


class RegenError(Exception):
    """Error raised by :func:`regenerate()`."""


def main():  # pragma: no cover
    """The main function of :program:`geofront-key-regen` CLI program."""
    from .server import app, get_master_key_store, get_remote_set
    parser = main_parser()
    args = parser.parse_args()
    try:
        app.config.from_pyfile(os.path.abspath(args.config), silent=False)
    except FileNotFoundError:
        parser.error('unable to load configuration file: ' + args.config)
    logger = logging.getLogger('geofront.masterkey')
    handler = logging.StreamHandler()
    level = logging.DEBUG if args.debug else logging.INFO
    handler.setLevel(level)
    logger.addHandler(handler)
    logger.setLevel(level)
    try:
        regenerate(
            get_master_key_store(),
            get_remote_set(),
            create_if_empty=args.create_master_key,
            renew_unless_empty=True
        )
    except RegenError as e:
        parser.error(str(e))

########NEW FILE########
__FILENAME__ = remote
""":mod:`geofront.remote` --- Remote sets
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Every remote set is represented as a mapping (which is immutable, or mutable)
of alias :class:`str` to :class:`Remote` object e.g.::

    {
        'web-1': Remote('ubuntu', '192.168.0.5'),
        'web-2': Remote('ubuntu', '192.168.0.6'),
        'web-3': Remote('ubuntu', '192.168.0.7'),
        'worker-1': Remote('ubuntu', '192.168.0.25'),
        'worker-2': Remote('ubuntu', '192.168.0.26'),
        'db-1': Remote('ubuntu', '192.168.0.50'),
        'db-2': Remote('ubuntu', '192.168.0.51')
    }

However, in the age of the cloud, you don't have to manage the remote set
since the most of cloud providers offer their API to list provisioned
remote nodes.

Geofront provides builtin :class:`~.backends.cloud.CloudRemoteSet`,
a subtype of :class:`collections.abc.Mapping`, that proxies to the list
dynamically made by cloud providers.

.. versionchanged:: 0.2.0
   ``CloudRemoteSet`` is moved from this module to
   :mod:`geofront.backends.cloud`.
   See :class:`~.backends.cloud.CloudRemoteSet`.

"""
import collections.abc
import datetime
import io
import itertools
import numbers
import threading
import time

from paramiko.pkey import PKey
from paramiko.sftp_client import SFTPClient
from paramiko.transport import Transport
from geofront.identity import Identity

from .keystore import format_openssh_pubkey, parse_openssh_pubkey
from .util import typed

__all__ = ('AuthorizedKeyList', 'DefaultPermissionPolicy',
           'GroupMetadataPermissionPolicy', 'PermissionPolicy', 'Remote',
           'authorize')


class Remote:
    """Remote node to SSH.

    :param user: the username to :program:`ssh`
    :type user: :class:`str`
    :param host: the host to access
    :type host: :class:`str`
    :param port: the port number to :program:`ssh`.
                 the default is 22 which is the default :program:`ssh` port
    :type port: :class:`numbers.Integral`
    :param metadata: optional metadata mapping.  keys and values have to
                     be all strings.  empty by default
    :type metadata: :class:`collections.abc.Mapping`

    .. versionadded:: 0.2.0
       Added optional ``metadata`` parameter.

    """

    #: (:class:`str`) The username to SSH.
    user = None

    #: (:class:`Address`) The hostname to access.
    host = None

    #: (:class:`numbers.Integral`) The port number to SSH.
    port = None

    #: (:class:`collections.abc.Mapping`) The additional metadata.
    #: Note that it won't affect to :func:`hash()` of the object,
    #: nor :token:`==`/:token:`!=` comparison of the object.
    #:
    #: .. versionadded:: 0.2.0
    metadata = None

    @typed
    def __init__(self, user: str, host: str, port: numbers.Integral=22,
                 metadata: collections.abc.Mapping={}):
        self.user = user
        self.host = host
        self.port = port
        self.metadata = dict(metadata)

    def __eq__(self, other):
        return (isinstance(other, type(self)) and
                self.user == other.user and
                self.host == other.host and
                self.port == other.port)

    def __ne__(self, other):
        return not (self == other)

    def __hash__(self):
        return hash((self.user, self.host, self.port))

    def __str__(self):  # pragma: no cover
        return '{}@{}:{}'.format(self.user, self.host, self.port)

    def __repr__(self):
        return '{0.__module__}.{0.__qualname__}{1!r}'.format(
            type(self), (self.user, self.host, self.port, self.metadata)
        )


class AuthorizedKeyList(collections.abc.MutableSequence):
    """List-like abstraction for remote :file:`authorized_keys`.

    Note that the contents are all lazily evaluated, so in order to
    pretend heavy duplicate communications over SFTP use :func:`list()`
    to eagerly evaluate e.g.::

        lazy_list = AuthorizedKeyList(sftp_client)
        eager_list = list(lazy_list)
        # ... some modifications on eager_list ...
        lazy_list[:] = eager_list

    :param sftp_client: the remote sftp connection to access
                        :file:`authorized_keys`
    :type sftp_client: :class:`paramiko.sftp_client.SFTPClient`

    """

    #: (:class:`str`) The path of :file:`authorized_keys` file.
    FILE_PATH = '.ssh/authorized_keys'

    @typed
    def __init__(self, sftp_client: SFTPClient):
        self.sftp_client = sftp_client

    def _iterate_lines(self):
        with io.BytesIO() as fo:
            self.sftp_client.getfo(self.FILE_PATH, fo)
            fo.seek(0)
            for line in fo:
                line = line.decode().strip()
                if line:
                    yield line

    def _save(self, authorized_keys: str):
        with io.BytesIO(authorized_keys.encode()) as fo:
            self.sftp_client.putfo(fo, self.FILE_PATH)

    def __iter__(self):
        for line in self._iterate_lines():
            line = line.strip()
            if line:
                yield parse_openssh_pubkey(line)

    def __len__(self):
        i = 0
        for _ in self._iterate_lines():
            i += 1
        return i

    def __getitem__(self, index):
        if isinstance(index, slice):
            lines = list(self._iterate_lines())
            return list(map(parse_openssh_pubkey, lines[index]))
        elif isinstance(index, numbers.Integral):
            if index >= 0:
                for i, line in enumerate(self._iterate_lines()):
                    if i == index:
                        return parse_openssh_pubkey(line)
            else:
                lines = list(self._iterate_lines())
                line = lines[index]
                return parse_openssh_pubkey(line)
            raise IndexError('authorized_keys out of range: ' + repr(index))
        raise TypeError(
            'authorized_keys indices must be integers, not '
            '{0.__module__}.{0.__qualname__}'.format(type(index))
        )

    def __setitem__(self, index, value):
        lines = list(self._iterate_lines())
        if isinstance(index, slice):
            lines[index] = map(format_openssh_pubkey, value)
        elif isinstance(index, numbers.Integral):
            lines[index] = format_openssh_pubkey(value)
        else:
            raise TypeError(
                'authorized_keys indices must be integers, not '
                '{0.__module__}.{0.__qualname__}'.format(type(index))
            )
        self._save('\n'.join(lines))

    def insert(self, index, value):
        if not isinstance(index, numbers.Integral):
            raise TypeError(
                'authorized_keys indices must be integers, not '
                '{0.__module__}.{0.__qualname__}'.format(type(index))
            )
        lines = list(self._iterate_lines())
        lines.insert(index, format_openssh_pubkey(value))
        self._save('\n'.join(lines))

    def extend(self, values):
        lines = itertools.chain(
            self._iterate_lines(),
            map(format_openssh_pubkey, values)
        )
        self._save('\n'.join(lines))

    def __delitem__(self, index):
        if not isinstance(index, (numbers.Integral, slice)):
            raise TypeError(
                'authorized_keys indices must be integers, not '
                '{0.__module__}.{0.__qualname__}'.format(type(index))
            )
        lines = list(self._iterate_lines())
        del lines[index]
        self._save('\n'.join(lines))


@typed
def authorize(public_keys: collections.abc.Set,
              master_key: PKey,
              remote: Remote,
              timeout: datetime.timedelta) -> datetime.datetime:
    """Make an one-time authorization to the ``remote``, and then revokes
    it when ``timeout`` reaches soon.

    :param public_keys: the set of public keys (:class:`paramiko.pkey.PKey`)
                        to authorize
    :type public_keys: :class:`collections.abc.Set`
    :param master_key: the master key (*not owner's key*)
    :type master_key: :class:`paramiko.pkey.PKey`
    :param remote: a remote to grant access permission
    :type remote: :class:`~.remote.Remote`
    :param timeout: the time an authorization keeps alive
    :type timeout: :class:`datetime.timedelta`
    :return: the expiration time
    :rtype: :class:`datetime.datetime`

    """
    transport = Transport((remote.host, remote.port))
    transport.connect(username=remote.user, pkey=master_key)
    try:
        sftp_client = SFTPClient.from_transport(transport)
        try:
            authorized_keys = AuthorizedKeyList(sftp_client)
            authorized_keys.extend(public_keys)
        except:
            sftp_client.close()
            raise
    except:
        transport.close()
        raise

    def rollback():
        time.sleep(timeout.total_seconds())
        authorized_keys[:] = [master_key]
        sftp_client.close()
        transport.close()
    timer = threading.Thread(target=rollback)
    expires_at = datetime.datetime.now(datetime.timezone.utc) + timeout
    timer.start()
    return expires_at


class PermissionPolicy:
    """Permission policy determines which remotes are visible by a team
    member, and which remotes are allowed to SSH.  So each remote
    can have one of three states for each team member:

    Listed and allowed
        A member can SSH to the remote.

    Listed but disallowed
        A member can be aware of the remote, but cannot SSH to it.

    Unlisted and disallowed
        A member can't be aware of the remote, and can't SSH to it either.

    Unlisted but allowed
        It is possible in theory, but mostly meaningless in practice.

    The implementation of this interface has to implement two methods.
    One is :meth:`filter()` which determines whether remotes are listed or
    unlisted.  Other one is :meth:`permit()` which determines whether
    remotes are allowed or disallowed to SSH.

    .. versionadded:: 0.2.0

    """

    @typed
    def filter(self,
               remotes: collections.abc.Mapping,
               identity: Identity,
               groups: collections.abc.Set) -> collections.abc.Mapping:
        """Determine which ones in the given ``remotes`` are visible
        to the ``identity`` (which belongs to ``groups``).  The resulted
        mapping of filtered remotes has to be a subset of the input
        ``remotes``.

        :param remotes: the remotes set to filter.  keys are alias strings
                        and values are :class:`Remote` objects
        :type remotes: :class:`collections.abc.Mapping`
        :param identity: the identity that the filtered remotes would
                         be visible to
        :type identity: :class:`~.identity.Identity`
        :param groups: the groups that the given ``identity`` belongs to.
                       every element is a group identifier and
                       :class:`collections.abc.Hashable`
        :type groups: :class:`collections.abc.Set`

        """
        raise NotImplementedError('filter() method has to be implemented')

    @typed
    def permit(self,
               remote: Remote,
               identity: Identity,
               groups: collections.abc.Set) -> bool:
        """Determine whether to allow the given ``identity`` (which belongs
        to ``groups``) to SSH the given ``remote``.

        :param remote: the remote to determine
        :type remote: :class:`Remote`
        :param identity: the identity to determine
        :type identity: :class:`~.identity.Identity`
        :param groups: the groups that the given ``identity`` belongs to.
                       every element is a group identifier and
                       :class:`collections.abc.Hashable`
        :type groups: :class:`collections.abc.Set`

        """
        raise NotImplementedError('permit() method has to be implemented')


class DefaultPermissionPolicy(PermissionPolicy):
    """All remotes are listed and allowed for everyone in the team.

    .. versionadded:: 0.2.0

    """

    @typed
    def filter(self,
               remotes: collections.abc.Mapping,
               identity: Identity,
               groups: collections.abc.Set) -> collections.abc.Mapping:
        return remotes

    @typed
    def permit(self,
               remote: Remote,
               identity: Identity,
               groups: collections.abc.Set) -> bool:
        return True


class GroupMetadataPermissionPolicy(PermissionPolicy):
    """Allow/disallow remotes according their metadata.  It assumes every
    remote has a metadata key that stores a set of groups to allow.
    For example, suppose there's the following remote set::

        {
            'web-1': Remote('ubuntu', '192.168.0.5', metadata={'role': 'web'}),
            'web-2': Remote('ubuntu', '192.168.0.6', metadata={'role': 'web'}),
            'web-3': Remote('ubuntu', '192.168.0.7', metadata={'role': 'web'}),
            'worker-1': Remote('ubuntu', '192.168.0.25',
                               metadata={'role': 'worker'}),
            'worker-2': Remote('ubuntu', '192.168.0.26',
                               metadata={'role': 'worker'}),
            'db-1': Remote('ubuntu', '192.168.0.50', metadata={'role': 'db'}),
            'db-2': Remote('ubuntu', '192.168.0.51', metadata={'role': 'db'})
        }

    and there are groups identified as ``'web'``, ``'worker'``, and ``'db'``.
    So the following policy would allow only members who belong to
    the corresponding groups:

        GroupMetadataPermissionPolicy('role')

    :param metadata_key: the key to find corresponding groups in metadata
                         of each remote
    :type metadata_key: :class:`str`
    :param separator: the character separates multiple group identifiers
                      in the metadata value.  for example, if the groups
                      are stored as like ``'sysadmin,owners'`` then
                      it should be ``','``.  it splits group identifiers
                      by all whitespace characters by default
    :type separator: :class:`str`

    .. versionadded:: 0.2.0

    """

    @typed
    def __init__(self, metadata_key: str, separator: str=None):
        self.metadata_key = metadata_key
        self.separator = separator

    def _get_groups(self, remote):
        groups = remote.metadata.get(self.metadata_key, '')
        if self.separator is None:
            groups = groups.split()
        else:
            groups = groups.split(self.separator)
        return frozenset(groups)

    @typed
    def filter(self,
               remotes: collections.abc.Mapping,
               identity: Identity,
               groups: collections.abc.Set) -> collections.abc.Mapping:
        return {alias: remote
                for alias, remote in remotes.items()
                if self.permit(remote, identity, groups)}

    @typed
    def permit(self,
               remote: Remote,
               identity: Identity,
               groups: collections.abc.Set) -> bool:
        return not self._get_groups(remote).isdisjoint(groups)

########NEW FILE########
__FILENAME__ = server
""":mod:`geofront.server` --- Key management service
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Although Geofront provides :program:`geofront-server`, a CLI to run
the server, it also provides an interface as a WSGI application as well.
Note that there might some limitations like lack of periodical master key
renewal.

First of all, the server need a configuration, there are several ways to
configure it.

:meth:`app.config.from_pyfile() <flask.Config.from_pyfile>`
    If you can freely execute arbitrary Python code before start the server,
    the method is the most straightforward way to configure the server.
    Note that the argument should be an absolute path, because it interprets
    paths relative to the path of Geofront program, not the current
    working directory (CWD).

    There also are other methods as well:

    - :meth:`~flask.Config.from_object()`
    - :meth:`~flask.Config.from_json()`
    - :meth:`~flask.Config.from_envvar()`

:envvar:`GEOFRONT_CONFIG`
    If you can't execute any arbitrary Python code,
    set the :envvar:`GEOFRONT_CONFIG` environment variable.
    It's useful when to use a CLI frontend of the WSGI server e.g.
    :program:`gunicorn`, :program:`waitress-serve`.

    .. code-block:: console

       $ GEOFRONT_CONFIG="/etc/geofront.cfg.py" gunicorn geofront.server:app

Then you can run a Geofront server using your favorite WSGI server.
Pass the following WSGI application object to the server.  It's a documented
endpoint for WSGI:

    :data:`geofront.server:app <app>`

"""
import argparse
import collections.abc
import datetime
import logging
import os
import os.path
import re
import warnings

from flask import (Flask, Response, current_app, json, jsonify, make_response,
                   request, url_for)
from paramiko.pkey import PKey
from paramiko.ssh_exception import SSHException
from waitress import serve
from waitress.adjustments import Adjustments
from werkzeug.contrib.cache import BaseCache, SimpleCache
from werkzeug.exceptions import BadRequest, Forbidden, HTTPException, NotFound
from werkzeug.routing import BaseConverter, ValidationError
from werkzeug.utils import html
from werkzeug.contrib.fixers import ProxyFix

from .identity import Identity
from .keystore import (DuplicatePublicKeyError, KeyStore, KeyTypeError,
                       format_openssh_pubkey, get_key_fingerprint,
                       parse_openssh_pubkey)
from .masterkey import MasterKeyStore, PeriodicalRenewal
from .regen import RegenError, main_parser as regen_main_parser, regenerate
from .remote import (DefaultPermissionPolicy, PermissionPolicy, Remote,
                     authorize)
from .team import AuthenticationError, Team
from .util import typed
from .version import VERSION

__all__ = ('AUTHORIZATION_TIMEOUT',
           'FingerprintConverter', 'Token', 'TokenIdConverter',
           'add_public_key', 'app', 'authenticate', 'authorize_remote',
           'create_access_token', 'delete_public_key', 'get_identity',
           'get_key_store', 'get_master_key_store', 'get_permission_policy',
           'get_public_key', 'get_remote_set', 'get_team', 'get_token_store',
           'list_public_keys', 'main', 'main_parser', 'master_key',
           'public_key', 'remote_dict', 'server_endpoint', 'server_version',
           'token')


#: (:class:`datetime.timedelta`) How long does each temporary authorization
#: keep alive after it's issued.  A minute.
AUTHORIZATION_TIMEOUT = datetime.timedelta(minutes=1)


class TokenIdConverter(BaseConverter):
    """Werkzeug custom converter which accepts valid token ids."""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.regex = r'[A-Za-z0-9._-]{8,100}'
        self.pattern = re.compile('^\s*({})\s*$'.format(self.regex))

    def to_python(self, value):
        match = self.pattern.match(value)
        if match:
            return match.group(1)
        raise ValidationError()

    def to_url(self, value):
        match = self.pattern.match(value)
        if match:
            return match.group(1)
        raise ValueError(repr(value) + ' is an invalid token id')


class FingerprintConverter(BaseConverter):
    """Werkzeug custom converter which accepts valid public key
    fingerprints.

    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.regex = r'(?:[A-Fa-f0-9]{2}:){15}[A-Fa-f0-9]{2}'
        self.pattern = re.compile('^\s*({})\s*$'.format(self.regex))

    def to_python(self, value):
        match = self.pattern.match(value)
        if match:
            return bytes(int(hex_, 16) for hex_ in match.group(1).split(':'))
        raise ValidationError()

    @typed
    def to_url(self, value: bytes):
        return ':'.join(map('{:02x}'.format, value))


#: (:class:`flask.Flask`) The WSGI application of the server.
app = Flask(__name__)
app.url_map.converters.update(
    token_id=TokenIdConverter,
    fingerprint=FingerprintConverter
)
app.config.update(  # Config defaults
    PERMISSION_POLICY=DefaultPermissionPolicy(),
    MASTER_KEY_BITS=2048,
    MASTER_KEY_RENEWAL=datetime.timedelta(days=1),
    TOKEN_EXPIRE=datetime.timedelta(days=7)
)


@app.after_request
def server_version(response: Response) -> Response:
    """Indicate the version of Geofront server using :mailheader:`Server`
    and :mailheader:`X-Geofront-Version` headers.

    """
    headers = response.headers
    headers['Server'] = 'Geofront/' + VERSION
    headers['X-Geofront-Version'] = VERSION
    return response


@app.route('/')
def server_endpoint():
    """The endpoint of HTTP API which provide the url to create a new token.

    .. code-block:: http

       GET / HTTPS/1.1
       Accept: application/json

    .. code-block:: http

       HTTP/1.0 200 OK
       Content-Type: application/json
       Link: <https://example.com/tokens/>; rel=tokens

       {
         "tokens_url": "https://example.com/tokens/"
       }

    :resheader Link: the url to create a new token.  the equivalent to
                     the response content
    :status 200: when the server is available

    .. versionadded:: 0.2.0

    """
    tokens_url = url_for(
        'token',
        token_id='TOKEN_ID',
        _external=True
    ).replace('/TOKEN_ID/', '/')  # FIXME
    response = jsonify(tokens_url=tokens_url)
    response.headers.add('Link', '<{}>'.format(tokens_url), rel='tokens')
    return response


def get_team() -> Team:
    """Get the configured team implementation, an instance of
    :class:`.team.Team`.

    It raises :exc:`RuntimeError` if ``'TEAM'`` is not configured.

    """
    try:
        team = app.config['TEAM']
    except KeyError:
        raise RuntimeError('TEAM configuration is not present')
    if isinstance(team, Team):
        return team
    raise RuntimeError(
        'TEAM configuration must be an instance of {0.__module__}.'
        '{0.__qualname__}, not {1!r}'.format(Team, team)
    )


def get_token_store() -> BaseCache:
    """Get the configured token store, an instance of
    :class:`werkzeug.contrib.cache.BaseCache`.

    It raises :exc:`RuntimeError` if ``'TOKEN_STORE'`` is not configured,
    but it just warns :exc:`RuntimeWarning` when it comes to debug mode.

    :return: the configured session store
    :rtype: :class:`werkzeug.contrib.cache.BaseCache`
    :raise RuntimeError: when ``'TOKEN_STORE'`` is not configured, or
                         the value is not an instance of
                         :class:`werkzeug.contrib.cache.BaseCache`

    .. todo::

       Change the backend system from :mod:`werzkeug.contrib.cache`
       to :mod:`dogpile.cache`.

    """
    try:
        store = app.config['TOKEN_STORE']
    except KeyError:
        if app.debug:
            warnings.warn(
                'TOKEN_STORE configuration is not present, so use '
                '{0.__module__}.{0.__qualname__} instead.  This defaulting is '
                'only for debug purpose, and you must not expect it from '
                'production mode'.format(SimpleCache),
                RuntimeWarning
            )
            store = SimpleCache()
            app.config['TOKEN_STORE'] = store
        else:
            raise RuntimeError('TOKEN_STORE configuration is not present')
    if isinstance(store, BaseCache):
        return store
    raise RuntimeError(
        'TOKEN_STORE configuration must be an instance of {0.__module__}.'
        '{0.__qualname__}, not {1!r}'.format(BaseCache, store)
    )


#: (:class:`type`) The named tuple type that stores a token.
Token = collections.namedtuple('Token', 'identity, expires_at')


@app.route('/tokens/<token_id:token_id>/', methods=['PUT'])
@typed
def create_access_token(token_id: str):
    """Create a new access token.

    .. code-block:: http

       PUT /tokens/0123456789abcdef/ HTTPS/1.1
       Accept: application/json
       Content-Length: 0

    .. code-block:: http

       HTTPS/1.1 202 Accepted
       Content-Type: application/json
       Date: Tue, 15 Apr 2014 03:44:43 GMT
       Expires: Tue, 15 Apr 2014 04:14:43 GMT
       Link: <https://example.com/login/page/?redirect_uri=...>; rel=next

       {
         "next_url": "https://example.com/login/page/?redirect_uri=..."
       }

    :param token_id: an arbitrary token id to create.
                     it should be enough random to avoid duplication
    :type token_id: :class:`str`
    :status 202: when the access token is prepared
    :resheader Link: the link owner's browser should redirect to

    """
    token_store = get_token_store()
    team = get_team()
    auth_nonce = ''.join(map('{:02x}'.format, os.urandom(16)))
    current_app.logger.debug('created auth_nonce: %r', auth_nonce)
    timeout = 60 * 30  # wait for 30 minutes
    token_store.set(token_id, auth_nonce, timeout)
    next_url = team.request_authentication(
        auth_nonce,
        url_for('authenticate', token_id=token_id, _external=True)
    )
    response = jsonify(next_url=next_url)
    assert isinstance(response, Response)
    response.status_code = 202
    response.headers.add('Link', '<{}>'.format(next_url), rel='next')
    response.expires = (datetime.datetime.now(datetime.timezone.utc) +
                        datetime.timedelta(seconds=timeout))
    return response


@app.route('/tokens/<token_id:token_id>/authenticate/')
@typed
def authenticate(token_id: str):
    """Finalize the authentication process.  It will be shown on web browser.

    :param token_id: token id created by :func:`create_access_token()`
    :type token_id: :class:`str`
    :status 400: when authentication is failed
    :status 404: when the given ``token_id`` doesn't exist
    :status 403: when the ``token_id`` is already finalized
    :status 200: when authentication is successfully done

    """
    token_store = get_token_store()
    team = get_team()
    token_expire = app.config['TOKEN_EXPIRE']
    if not isinstance(token_expire, datetime.timedelta):
        raise RuntimeError(
            'TOKEN_EXPIRE configuration must be an instance of '
            'datetime.timedelta, not {!r}'.format(token_expire)
        )
    try:
        auth_nonce = token_store.get(token_id)
        current_app.logger.debug('stored auth_nonce: %r', auth_nonce)
    except TypeError:
        raise NotFound()
    if not isinstance(auth_nonce, str):
        raise Forbidden()
    requested_redirect_url = url_for(
        'authenticate',
        token_id=token_id,
        _external=True
    )
    try:
        identity = team.authenticate(
            auth_nonce,
            requested_redirect_url,
            request.environ
        )
    except AuthenticationError:
        raise BadRequest()
    expires_at = datetime.datetime.now(datetime.timezone.utc) + token_expire
    token_store.set(token_id, Token(identity, expires_at),
                    timeout=int(token_expire.total_seconds()))
    return '<!DOCTYPE html>\n' + html.html(
        html.head(
            html.meta(charset='utf-8'),
            html.title('Geofront: Authentication success')
        ),
        html.body(
            html.h1(html.dfn('Geofront:'), ' Authentication success'),
            html.p('You may close the browser, and go back to the CLI.')
        )
    )


@typed
def get_identity(token_id: str) -> Identity:
    """Get the identity object from the given ``token_id``.

    :param token_id: the token id to get the identity it holds
    :type token_id: :class:`str`
    :return: the identity the token holds
    :rtype: :class:`~.identity.Identity`
    :raise werkzeug.exceptions.HTTPException:
        :http:statuscode:`404` (``token-not-found``)
        when the token does not exist.
        :http:statuscode:`412` (``unfinished-authentication``)
        when the authentication process is not finished yet.
        :http:statuscode:`410` (``expired-token``)
        when the token was expired.
        :http:statuscode:`403` (``not-authorized``)
        when the token is not unauthorized.

    """
    store = get_token_store()
    team = get_team()
    token = store.get(token_id)
    if not token:
        response = jsonify(
            error='token-not-found',
            message='Access token {0} does not exist.'.format(token_id)
        )
        response.status_code = 404
        raise HTTPException(response=response)
    elif not isinstance(token, Token):
        response = jsonify(
            error='unfinished-authentication',
            message='Authentication process is not finished yet.'
        )
        response.status_code = 412  # Precondition Failed
        raise HTTPException(response=response)
    elif token.expires_at < datetime.datetime.now(datetime.timezone.utc):
        response = jsonify(
            error='expired-token',
            message='Access token {0} was expired. '
                    'Please authenticate again.'.format(token_id)
        )
        response.status_code = 410  # Gone
        raise HTTPException(response=response)
    elif team.authorize(token.identity):
        return token.identity
    response = jsonify(
        error='not-authorized',
        message='Access token {0} is unauthorized.'.format(token_id)
    )
    response.status_code = 403
    raise HTTPException(response=response)


@app.route('/tokens/<token_id:token_id>/')
@typed
def token(token_id: str):
    """The owner identity that the given token holds if the token is
    authenticated.  Otherwise it responds :http:statuscode:`403`,
    :http:statuscode:`404`, :http:statuscode:`410`, or
    :http:statuscode:`412`.  See also :func:`get_identity()`.

    .. code-block:: http

       GET /tokens/0123456789abcdef/ HTTPS/1.1
       Accept: application/json

    .. code-block:: http

       HTTPS/1.0 200 OK
       Content-Type: application/json
       Link: <https://example.com/tokens/0123456789abcdef/remo...>; rel=remotes
       Link: <https://example.com/tokens/0123456789abcdef/keys/>; rel=keys
       Link: <https://example.com/tokens/0123456789abcdef/ma...>; rel=masterkey

       {
         "identifier": "dahlia",
         "team_type": "geofront.backends.github.GitHubOrganization",
         "remotes_url": "https://example.com/tokens/0123456789abcdef/remotes/",
         "keys_url": "https://example.com/tokens/0123456789abcdef/keys/",
         "master_key_url": "https://example.com/tokens/0123456789abcdef/mas..."
       }

    :param token_id: the token id that holds the identity
    :type token_id: :class:`str`
    :resheader Link: the url to list remotes (``rel=remotes``), public keys
                     (``rel=keys``), and master key (``rel=masterkey``)
    :status 200: when the token is authenticated

    .. versionchanged:: 0.2.0
       The response contains ``"remotes_url"``, ``"keys_url"``, and
       ``"master_key_url"``, and equivalent three :mailheader:`Link` headers.

    """
    identity = get_identity(token_id)
    links = {
        'remotes': url_for('list_remotes', token_id=token_id, _external=True),
        'keys': url_for('list_public_keys', token_id=token_id, _external=True),
        'master_key': url_for('master_key', token_id=token_id, _external=True)
    }
    response = jsonify(
        {rel + '_url': url for rel, url in links.items()},
        team_type='{0.__module__}.{0.__qualname__}'.format(identity.team_type),
        identifier=identity.identifier,
    )
    for rel, href in links.items():
        response.headers.add('Link', '<{}>'.format(href),
                             rel=rel.replace('_', ''))
    return response


def get_master_key_store() -> MasterKeyStore:
    """Get the configured master key store implementation.

    :return: the configured master key store
    :rtype: :class:`~.masterkey.MasterKeyStore`
    :raise RuntimeError: when ``'MASTER_KEY_STORE'`` is not configured,
                         or it's not an instance of
                         :class:`~.masterkey.MasterKeyStore`

    """
    try:
        master_key_store = app.config['MASTER_KEY_STORE']
    except KeyError:
        raise RuntimeError('MASTER_KEY_STORE configuration is not present')
    if isinstance(master_key_store, MasterKeyStore):
        return master_key_store
    raise RuntimeError(
        'MASTER_KEY_STORE configuration must be an instance of {0.__module__}.'
        '{0.__qualname__}, not {1!r}'.format(MasterKeyStore, master_key_store)
    )


@app.route('/tokens/<token_id:token_id>/masterkey/')
def master_key(token_id: str):
    """Public part of the master key in OpenSSH authorized_keys
    (public key) format.

    .. code-block:: http

       GET /tokens/0123456789abcdef/masterkey/ HTTPS/1.1
       Accept: text/plain

    .. code-block:: http

       HTTPS/1.1 200 OK
       Content-Type: text/plain

       ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDAEMUvjBcX.../MuLLzC/m8Q==

    :param token_id: the token id that holds the identity
    :type token_id: :class:`str`
    :status 200: when the master key is available
    :status 500: when the master key is unavailable

    """
    get_identity(token_id)
    master_key_store = get_master_key_store()
    return format_openssh_pubkey(master_key_store.load()), 200, {
        'Content-Type': 'text/plain'
    }


def get_key_store() -> KeyStore:
    """Get the configured key store implementation.

    :return: the configured key store
    :rtype: :class:`~.keystore.KeyStore`
    :raise RuntimeError: when ``'KEY_STORE'`` is not configured, or
                         it's not an instance of :class:`~.keystore.KeyStore`

    """
    try:
        key_store = app.config['KEY_STORE']
    except KeyError:
        raise RuntimeError('KEY_STORE configuration is not present')
    if isinstance(key_store, KeyStore):
        return key_store
    raise RuntimeError(
        'KEY_STORE configuration must be an instance of {0.__module__}.'
        '{0.__qualname__}, not {1!r}'.format(KeyStore, key_store)
    )


@app.route('/tokens/<token_id:token_id>/keys/')
@typed
def list_public_keys(token_id: str):
    """List registered keys to the token owner.

    .. code-block:: http

       GET /tokens/0123456789abcdef/keys/ HTTPS/1.1
       Accept: application/json

    .. code-block:: http

       HTTPS/1.1 200 OK
       Content-Type: application/json

       {
         "50:5a:9a:12:75:8b:b0:88:7d:7a:8d:66:29:63:d0:47":
           "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDAEMUvjBcX.../MuLLzC/m8Q== ",
         "72:00:60:24:66:e8:2d:4d:2a:2a:a2:0e:7b:7f:fc:af":
           "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCom2CDLekY...5CeYsvSdrTWA5 ",
         "78:8a:09:c8:c1:24:5c:89:76:92:b0:1e:93:95:5d:48":
           "ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAIEA16iSKKjFHOgj...kD62SYXNKY9c= ",
         "ab:3a:fb:30:44:e3:5e:1e:10:a0:c9:9a:86:f4:67:59":
           "ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAzzF8c07pzgKk...r+b6Q9VnWWQ== "
       }

    :param token_id: the token id that holds the identity
    :type token_id: :class:`str`
    :status 200: when listing is successful, even if there are no keys

    """
    identity = get_identity(token_id)
    key_store = get_key_store()
    keys = key_store.list_keys(identity)
    data = json.dumps({
        get_key_fingerprint(key): format_openssh_pubkey(key) for key in keys
    })
    return data, 200, {'Content-Type': 'application/json'}


@app.route('/tokens/<token_id:token_id>/keys/', methods=['POST'])
@typed
def add_public_key(token_id: str):
    """Register a public key to the token.  It takes an OpenSSH public key
    line through the request content body.

    .. code-block:: http

       POST /tokens/0123456789abcdef/keys/ HTTPS/1.1
       Accept: application/json
       Content-Type: text/plain

       ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDAEMUvjBcX.../MuLLzC/m8Q==

    .. code-block:: http

       HTTPS/1.1 201 Created
       Content-Type: text/plain
       Location: /tokens/0123456789abcdef/keys/\
50:5a:9a:12:75:8b:b0:88:7d:7a:8d:66:29:63:d0:47

       ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDAEMUvjBcX.../MuLLzC/m8Q==

    :param token_id: the token id that holds the identity
    :type token_id: :class:`str`
    :status 201: when key registration is successful
    :status 400: (``unsupported-key-type``) when the key type is unsupported,
                 or (``invalid-key``) the key format is invalid,
                 or (``deuplicate-key``) the key is already used
    :status 415: (``unsupported-content-type``) when the
                 :mailheader:`Content-Type` is not :mimetype:`text/plain`

    """
    identity = get_identity(token_id)
    key_store = get_key_store()
    if request.mimetype != 'text/plain':
        response = jsonify(
            error='unsupported-content-type',
            message='it accepts only text/plain which is an OpenSSH '
                    'public key line'
        )
        response.status_code = 415  # Unsupported Media Type
        return response
    request_body = request.get_data(as_text=True)
    try:
        pkey = parse_openssh_pubkey(request_body)
    except KeyTypeError as e:
        response = jsonify(
            error='unsupported-key-type',
            message=str(e)
        )
        response.status_code = 400  # Bad Request
        return response
    except ValueError:
        response = jsonify(
            error='invalid-key',
            message='failed to parse the key'
        )
        response.status_code = 400
        return response
    try:
        key_store.register(identity, pkey)
    except DuplicatePublicKeyError:
        response = jsonify(
            error='duplicate-key',
            message='the given key is already used'
        )
        response.status_code = 400
        return response
    response = make_response(
        public_key(token_id=token_id, fingerprint=pkey.get_fingerprint())
    )
    response.status_code = 201  # Created
    response.location = url_for('public_key',
                                token_id=token_id,
                                fingerprint=pkey.get_fingerprint(),
                                _external=True)
    return response


@typed
def get_public_key(token_id: str, fingerprint: bytes) -> PKey:
    """Internal function to find the public key by its ``fingerprint``.

    :param token_id: the token id that holds the identity
    :type token_id: :class:`str`
    :param fingerprint: the fingerprint of a public key to find
    :type fingerprint: :class:`bytes`
    :return: the found public key
    :rtype: :class:`paramiko.pkey.PKey`
    :raise werkzeug.exceptions.HTTPException: (``not-found``) when there's
                                              no such public key

    """
    identity = get_identity(token_id)
    key_store = get_key_store()
    keys = key_store.list_keys(identity)
    for key in keys:
        if key.get_fingerprint() == fingerprint:
            return key
    response = jsonify(
        error='not-found',
        message='No such public key: {}.'.format(
            ':'.join(map('{:02x}'.format, fingerprint))
        )
    )
    response.status_code = 404
    raise HTTPException(response=response)


@app.route('/tokens/<token_id:token_id>/keys/<fingerprint:fingerprint>/')
def public_key(token_id: str, fingerprint: bytes):
    """Find the public key by its ``fingerprint`` if it's registered.

    .. code-block:: http

       GET /tokens/0123456789abcdef/keys/\
50:5a:9a:12:75:8b:b0:88:7d:7a:8d:66:29:63:d0:47/ HTTPS/1.1
       Accept: text/plain

    .. code-block:: http

       HTTPS/1.1 200 OK
       Content-Type: text/plain

       ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAAAgQDAEMUvjBcX.../MuLLzC/m8Q==

    :param token_id: the token id that holds the identity
    :type token_id: :class:`str`
    :param fingerprint: the fingerprint of a public key to find
    :type fingerprint: :class:`bytes`
    :status 200: when the public key is registered
    :status 404: (``not-found``) when there's no such public key

    """
    key = get_public_key(token_id, fingerprint)
    return format_openssh_pubkey(key), 200, {'Content-Type': 'text/plain'}


@app.route('/tokens/<token_id:token_id>/keys/<fingerprint:fingerprint>/',
           methods=['DELETE'])
def delete_public_key(token_id: str, fingerprint: bytes):
    """Delete a public key.

    .. code-block:: http

       DELETE /tokens/0123456789abcdef/keys/\
50:5a:9a:12:75:8b:b0:88:7d:7a:8d:66:29:63:d0:47/ HTTPS/1.1
       Accept: application/json

    .. code-block:: http

       HTTPS/1.1 200 OK
       Content-Type: application/json

       {
         "72:00:60:24:66:e8:2d:4d:2a:2a:a2:0e:7b:7f:fc:af":
           "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCom2CDLekY...5CeYsvSdrTWA5 ",
         "78:8a:09:c8:c1:24:5c:89:76:92:b0:1e:93:95:5d:48":
           "ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAIEA16iSKKjFHOgj...kD62SYXNKY9c= ",
         "ab:3a:fb:30:44:e3:5e:1e:10:a0:c9:9a:86:f4:67:59":
           "ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAzzF8c07pzgKk...r+b6Q9VnWWQ== "
       }

    :param token_id: the token id that holds the identity
    :type token_id: :class:`str`
    :param fingerprint: the fingerprint of a public key to delete
    :type fingerprint: :class:`bytes`
    :status 200: when the public key is successfully deleted
    :status 404: (``not-found``) when there's no such public key

    """
    key = get_public_key(token_id, fingerprint)
    get_key_store().deregister(get_identity(token_id), key)
    return make_response(list_public_keys(token_id))


def get_remote_set() -> collections.abc.Mapping:
    """Get the configured remote set.

    :return: the configured remote set
    :rtype: :class:`collections.abc.Mapping`
    :raise RuntimeError: if ``'REMOTE_SET'`` is not configured,
                         or it's not a mapping object

    """
    try:
        set_ = app.config['REMOTE_SET']
    except KeyError:
        raise RuntimeError('REMOTE_SET configuration is not present')
    if isinstance(set_, collections.abc.Mapping):
        return set_
    raise RuntimeError(
        'REMOTE_SET configuration must be an instance of {0.__module__}.'
        '{0.__qualname__}, not {1!r}'.format(collections.abc.Mapping, set_)
    )


def get_permission_policy() -> PermissionPolicy:
    """Get the configured permission policy.

    :return: the configured permission policy
    :rtype: :class:`~.remote.PermissionPolicy`
    :raise RuntimeError: if ``'PERMISSION_POLICY'`` is not configured,
                         or it's not an instance of
                         :class:`~.remote.PermissionPolicy`

    .. versionadded:: 0.2.0

    """
    try:
        policy = app.config['PERMISSION_POLICY']
    except KeyError:
        raise RuntimeError('PERMISSION_POLICY configuration is not present')
    if isinstance(policy, PermissionPolicy):
        return policy
    raise RuntimeError(
        'PERMISSION_POLICY configuration must be an instance of {0.__module__}'
        '.{0.__qualname__}, not {1!r}'.format(PermissionPolicy, policy)
    )


def remote_dict(remote: Remote) -> collections.abc.Mapping:
    """Convert a ``remote`` to a simple dictionary that can be serialized
    to JSON.

    :param remote: a remote instance to serialize
    :type remote: :class:`~.remote.Remote`
    :return: the converted dictionary
    :rtype: :class:`collections.abc.Mapping`

    """
    return {'user': remote.user, 'host': remote.host, 'port': remote.port}


@app.route('/tokens/<token_id:token_id>/remotes/')
def list_remotes(token_id: str):
    """List all available remotes and their aliases.

    .. code-block:: http

       GET /tokens/0123456789abcdef/remotes/ HTTPS/1.1
       Accept: application/json

    .. code-block:: http

       HTTPS/1.1 200 OK
       Content-Type: application/json

       {
         "web-1": {"user": "ubuntu", "host": "192.168.0.5", "port": 22},
         "web-2": {"user": "ubuntu", "host": "192.168.0.6", "port": 22},
         "web-3": {"user": "ubuntu", "host": "192.168.0.7", "port": 22},
         "worker-1": {"user": "ubuntu", "host": "192.168.0.25", "port": 22},
         "worker-2": {"user": "ubuntu", "host": "192.168.0.26", "port": 22},
         "db-1": {"user": "ubuntu", "host": "192.168.0.50", "port": 22},
         "db-2": {"user": "ubuntu", "host": "192.168.0.51", "port": 22}
       }

    :param token_id: the token id that holds the identity
    :type token_id: :class:`str`
    :status 200: when listing is successful, even if there are no remotes

    .. todo:: Filter by query string.

    """
    team = get_team()
    identity = get_identity(token_id)  # 404/410 if not authenticated
    groups = team.list_groups(identity)
    policy = get_permission_policy()
    remotes = policy.filter(get_remote_set(), identity, groups)
    return jsonify(
        {alias: remote_dict(remote) for alias, remote in remotes.items()}
    )


@app.route('/tokens/<token_id:token_id>/remotes/<alias>/', methods=['POST'])
def authorize_remote(token_id: str, alias: str):
    """Temporarily authorize the token owner to access a remote.
    A made authorization keeps alive in a minute, and then will be expired.

    .. code-block:: http

       POST /tokens/0123456789abcdef/remotes/web-1/ HTTPS/1.1
       Accept: application/json
       Content-Length: 0

    .. code-block:: http

       HTTPS/1.1 200 OK
       Content-Type: application/json

       {
         "success": "authorized",
         "remote": {"user": "ubuntu", "host": "192.168.0.5", "port": 22},
         "expires_at": "2014-04-14T14:57:49.822844+00:00"
       }

    :param token_id: the token id that holds the identity
    :type token_id: :class:`str`
    :param alias: the alias of the remote to access
    :type alias: :class:`str`
    :status 200: when successfully granted a temporary authorization
    :status 404: (``not-found``) when there's no such remote

    """
    team = get_team()
    identity = get_identity(token_id)
    key_store = get_key_store()
    master_key_store = get_master_key_store()
    remotes = get_remote_set()
    policy = get_permission_policy()
    try:
        remote = remotes[alias]
    except KeyError:
        response = jsonify(
            error='not-found',
            message='No such remote alias: {}.'.format(alias)
        )
        response.status_code = 404
        return response
    if not policy.permit(remote, identity, team.list_groups(identity)):
        response = jsonify(
            error='forbidden',
            message='Remote {0} is disallowed.  Contact the system '
                    'administrator.'.format(alias)
        )
        response.status_code = 403
        return response
    public_keys = key_store.list_keys(identity)
    master_key = master_key_store.load()
    remote_mapping = remote_dict(remote)
    try:
        expires_at = authorize(public_keys, master_key, remote,
                               AUTHORIZATION_TIMEOUT)
    except SSHException as e:
        response = jsonify(
            error='connection-failure',
            remote=remote_mapping,
            message=str(e)
        )
        response.status_code = 500
        return response
    return jsonify(
        success='authorized',
        remote=remote_mapping,
        expires_at=expires_at.isoformat()
    )


def main_parser() -> argparse.ArgumentParser:  # pragma: no cover
    """Create an :class:`~argparse.ArgumentParser` object for
    :program:`geofront-server` CLI program.  It also is used for
    documentation through `sphinxcontrib-autoprogram`__.

    :return: a properly configured :class:`~argparse.ArgumentParser`
    :rtype: :class:`argparse.ArgumentParser`

    __ https://pythonhosted.org/sphinxcontrib-autoprogram/

    """
    parser = argparse.ArgumentParser(
        description='Simple SSH key management service'
    )
    parser = regen_main_parser(parser)
    parser.add_argument('-H', '--host',
                        default='0.0.0.0',
                        help='host to bind [%(default)s]')
    parser.add_argument('-p', '--port',
                        default=5000,
                        help='port to bind [%(default)s]')
    parser.add_argument('--renew-master-key',
                        action='store_true',
                        help='renew the master key before the server starts. '
                             'implies --create-master-key option')
    parser.add_argument('--trusted-proxy',
                        action='store_true',
                        help='IP address of a client allowed to override '
                             'url_scheme via the X-Forwarded-Proto header. '
                             'useful when it runs behind reverse proxy. '
                             '-d/--debug option disables this option')
    return parser


def main():  # pragma: no cover
    """The main function for :program:`geofront-server` CLI program."""
    parser = main_parser()
    args = parser.parse_args()
    try:
        app.config.from_pyfile(os.path.abspath(args.config), silent=False)
    except FileNotFoundError:
        parser.error('unable to load configuration file: ' + args.config)
    logger = logging.getLogger('geofront')
    handler = logging.StreamHandler()
    level = logging.DEBUG if args.debug else logging.INFO
    handler.setLevel(level)
    logger.addHandler(handler)
    logger.setLevel(level)
    master_key_store = get_master_key_store()
    remote_set = get_remote_set()
    servers = frozenset(remote_set.values())
    master_key_bits = app.config['MASTER_KEY_BITS']
    if not isinstance(master_key_bits, int):
        parser.error('MASTER_KEYS_BITS configuration must be an integer, not '
                     + repr(master_key_bits))
    elif master_key_bits < 1024:
        parser.error('MASTER_KEY_BITS has to be 1024 at least.')
    elif master_key_bits % 256:
        parser.error('MASTER_KEY_BITS has to be a multiple of 256.')
    try:
        regenerate(
            master_key_store,
            remote_set,
            master_key_bits,
            create_if_empty=args.create_master_key or args.renew_master_key,
            renew_unless_empty=(args.renew_master_key and
                                not os.environ.get('WERKZEUG_RUN_MAIN'))
        )
    except RegenError as e:
        parser.error(str(e))
    master_key_renewal_interval = app.config['MASTER_KEY_RENEWAL']
    if not (master_key_renewal_interval is None or
            isinstance(master_key_renewal_interval, datetime.timedelta)):
        raise RuntimeError(
            'MASTER_KEY_RENEWAL configuration must be an instance of '
            'datetime.timedelta, not {!r}'.format(master_key_renewal_interval)
        )
    if master_key_renewal_interval is not None:
        master_key_renewal = PeriodicalRenewal(
            servers,
            master_key_store,
            master_key_renewal_interval,
            master_key_bits
        )
    waitress_options = {}
    if args.trusted_proxy:
        if hasattr(Adjustments, 'trusted_proxy'):
            # > 0.8.8
            # https://github.com/Pylons/waitress/pull/42
            waitress_options['trusted_proxy'] = True
        else:
            # <= 0.8.8
            app.wsgi_app = ProxyFix(app.wsgi_app)
    try:
        if args.debug:
            app.run(args.host, args.port, debug=True)
        else:
            serve(app, host=args.host, port=args.port, asyncore_use_poll=True,
                  **waitress_options)
    finally:
        if master_key_renewal_interval is not None:
            master_key_renewal.terminate()


# If there is ``GEOFRONT_CONFIG`` environment variable, implicitly load
# the configuration file.  It's useful for using custom WSGI server e.g.::
#
#     $ GEOFRONT_CONFIG="/etc/geofront.cfg.py" gunicorn geofront.server:app
if 'GEOFRONT_CONFIG' in os.environ:  # pragma: no cover
    app.config.from_pyfile(
        os.path.abspath(os.environ['GEOFRONT_CONFIG']),
        silent=False
    )

########NEW FILE########
__FILENAME__ = team
""":mod:`geofront.team` --- Team authentication
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Geofront doesn't force you to manage team members by yourself.
Instead it hides how to manage team members, and offers :class:`Team`,
the layering interface to implement custom team data provider
e.g. :class:`~.backends.github.GitHubOrganization`.

It is theologically possible to implement a straightforward RDBMS-backed
team provider, but we rather recommend to adapt your existing team data
instead e.g. `GitHub organization`__, `Google Apps organization`__,
`Bitbucket team`__.

__ https://github.com/blog/674-introducing-organizations
__ https://support.google.com/a/answer/182433?hl=en
__ http://blog.bitbucket.org/2012/05/30/bitbucket-teams/

"""
import collections.abc

from .identity import Identity
from .util import typed

__all__ = 'AuthenticationError', 'Team'


class Team:
    """Backend interface for team membership authentication.

    Authorization process consists of three steps (and therefore every
    backend subclass has to implement these three methods):

    1. :meth:`request_authentication()` makes the url to interact with
       the owner of the identity to authenticate.  I.e. the url to login
       web page of the backend service.
    2. :meth:`authenticate()` finalize authentication of the identity,
       and then returns :class:`~.identity.Identity`.
    3. :meth:`authorize()` tests the given :class:`~.identity.Identity`
       belongs to the team.  It might be a redundant step for several
       backends, but is a necessary step for some backends that distinguish
       identity authentication between team membership authorization.
       For example, Any Gmail users can authenticate they own their Gmail
       account, but only particular users can authenticate their account
       belongs to the configured Google Apps organization.

    """

    @typed
    def request_authentication(self,
                               auth_nonce: str,
                               redirect_url: str) -> str:
        """First step of authentication process, to prepare the "sign in"
        interaction with the owner.  It typically returns a url to
        the login web page.

        :param auth_nonce: a random string to guarantee it's a part of
                           the same process to following :meth:`authenticate()`
                           call which is the second step
        :type auth_nonce: :class:`str`
        :param redirect_url: a url that owner's browser has to redirect to
                             after the "sign in" interaction finishes
        :type redirect_url: :class:`str`
        :return: a url to the web page to interact with the owner
                 in their browser
        :rtype: :class:`str`

        """
        raise NotImplementedError('request_authentication() method has to '
                                  'be implemented')

    @typed
    def authenticate(self,
                     auth_nonce: str,
                     requested_redirect_url: str,
                     wsgi_environ: collections.abc.Mapping) -> Identity:
        """Second step of authentication process, to create a verification
        token for the identity.  The token is used by :meth:`authorize()`
        method, and the key store as well (if available).

        :param auth_nonce: a random string to guarantee it's a part of
                           the same process to :meth:`request_authentication()`
                           call followed by this which is the first step
        :type auth_nonce: :class:`str`
        :param requested_redirect_url: a url that was passed to
                                       :meth:`request_authentication()`'s
                                       ``redirect_url`` parameter
        :type requested_redirect_url: :class:`str`
        :param wsgi_environ: forwarded wsgi environ dictionary
        :type wsgi_environ: :class:`collections.abc.Mapping`
        :return: an identity which contains a verification token
        :rtype: :class:`~.identity.Identity`
        :raise geofront.team.AuthenticationError:
            when something goes wrong e.g. network errors,
            the user failed to verify their ownership

        """
        raise NotImplementedError('authenticate() method has to '
                                  'be implemented')

    @typed
    def authorize(self, identity: Identity) -> bool:
        """The last step of authentication process.
        Test whether the given ``identity`` belongs to the team.

        Note that it can be called every time the owner communicates with
        Geofront server, out of authentication process.

        :param identity: the identity to authorize
        :type identity: :class:`~.identity.Identity`
        :return: :const:`True` only if the ``identity`` is a member of the team
        :rtype: :class:`bool`

        """
        raise NotImplementedError('authorize() method has to be implemented')

    @typed
    def list_groups(self, identity: Identity) -> collections.abc.Set:
        """List the all groups that the given ``identity`` belongs to.
        Any hashable value can be an element to represent a group e.g.::

            {1, 4, 9}

        Or::

            {'owners', 'programmers'}

        Whatever value the set consists of these would be referred by
        :class:`~.remote.Remote` objects.

        Some team implementations might not have a concept like groups.
        It's okay to return always an empty set then.

        :param identity: the identity to list his/her groups
        :type identity: :class:`~.identity.Identity`
        :return: the set of groups associated with the ``identity``
        :rtype: :class:`collections.abc.Set`

        .. versionadded:: 0.2.0

        """
        raise NotImplementedError('list_groups() method has to be implemented')


class AuthenticationError(Exception):
    """Authentication exception which rise when the authentication process
    has trouble including network problems.

    .. todo:: Exception hierarchy is needed.

    """

########NEW FILE########
__FILENAME__ = util
""":mod:`geofront.util` --- Utilities
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

"""
import builtins
import functools
import inspect
import types

__all__ = 'typed',


def typed(function: types.FunctionType) -> types.FunctionType:
    """Automatically check argument types using function's annotated
    parameters.  For example, the following code will raise :exc:`TypeError`:

    >>> @typed
    ... def add(a: int, b: int):
    ...     return a + b
    ...
    >>> add('strings are not ', 'accepted')

    :param function: a function to make automatically type checked
    :type function: :class:`types.FunctionType`

    """
    if not isinstance(function, types.FunctionType):
        raise TypeError('expected a function, not ' + repr(function))
    sig = inspect.signature(function)

    @functools.wraps(function)
    def wrapped(*args, **kwargs):
        annotations = function.__annotations__
        for param, arg in sig.bind(*args, **kwargs).arguments.items():
            try:
                cls = annotations[param]
            except KeyError:
                continue
            else:
                if not (isinstance(arg, cls) or
                        arg is sig.parameters[param].default):
                    if cls.__module__ == 'builtins' and \
                       getattr(builtins, cls.__name__, None) is cls:
                        raise TypeError(
                            '{0} must be an instance of {1.__name__}, not '
                            '{2!r}'.format(param, cls, arg)
                        )
                    raise TypeError(
                        '{0} must be an instance of {1.__module__}.'
                        '{1.__qualname__}, not {2!r}'.format(param, cls, arg)
                    )
        return function(*args, **kwargs)
    return wrapped

########NEW FILE########
__FILENAME__ = version
""":mod:`geofront.version` --- Version data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

"""

#: (:class:`tuple`) The triple of version numbers e.g. ``(1, 2, 3)``.
VERSION_INFO = (0, 2, 1)

#: (:class:`str`) The version string e.g. ``'1.2.3'``.
VERSION = '{}.{}.{}'.format(*VERSION_INFO)


if __name__ == '__main__':
    print(VERSION)

########NEW FILE########
__FILENAME__ = cloud_test
import hashlib
import io
import os

from libcloud.compute.base import Node, KeyPair
from libcloud.compute.drivers.dummy import DummyNodeDriver
from libcloud.compute.types import KeyPairDoesNotExistError
from libcloud.storage.drivers import dummy
from libcloud.storage.drivers.dummy import DummyStorageDriver
from paramiko.rsakey import RSAKey
from pytest import raises

from geofront.backends.cloud import (CloudKeyStore, CloudMasterKeyStore,
                                     CloudMasterPublicKeyStore, CloudRemoteSet,
                                     get_metadata, supports_metadata)
from geofront.identity import Identity
from geofront.keystore import (format_openssh_pubkey, get_key_fingerprint,
                               parse_openssh_pubkey)
from geofront.masterkey import EmptyStoreError
from geofront.remote import Remote
from ..keystore_test import assert_keystore_compliance
from ..server_test import DummyTeam, MemoryMasterKeyStore


@supports_metadata.register(DummyNodeDriver)
def dummy_supports_metadata(driver: DummyNodeDriver):
    return True


@get_metadata.register(DummyNodeDriver)
def dummy_get_metadata(driver: DummyNodeDriver, node: Node):
    return {'dummy': 'test'}


def test_cloud_remote_set():
    driver = DummyNodeDriver('')
    set_ = CloudRemoteSet(driver)
    assert len(set_) == 2
    assert set_['dummy-1'] == Remote('ec2-user', '127.0.0.1')
    assert set_['dummy-1'].metadata == {'dummy': 'test'}
    assert set_['dummy-2'] == Remote('ec2-user', '127.0.0.1')
    assert set_['dummy-2'].metadata == {'dummy': 'test'}


def test_cloud_master_key_store():
    driver = DummyStorageDriver('', '')
    container = driver.create_container('geofront-test')
    s = CloudMasterKeyStore(driver, container, 'test_id_rsa')
    with raises(EmptyStoreError):
        s.load()
    key = RSAKey.generate(1024)
    s.save(key)
    driver.get_object(container.name, 'test_id_rsa')  # assert object exists
    # Mocking implementation
    with io.StringIO() as mock:
        key.write_private_key(mock)
        mock.seek(0)
        dummy.DummyFileObject = lambda *a, **k: mock
        stored_key = s.load()
        assert isinstance(stored_key, RSAKey)
        assert stored_key.get_base64() == stored_key.get_base64()


class KeyPairSupportedDummyNodeDriver(DummyNodeDriver):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.key_pairs = {}

    def get_key_pair(self, name):
        try:
            key_material = self.key_pairs[name]
        except KeyError:
            raise KeyPairDoesNotExistError(name, self)
        return KeyPair(name,
                       key_material,
                       get_key_fingerprint(parse_openssh_pubkey(key_material)),
                       self)

    def list_key_pairs(self):
        return [self.get_key_pair(name) for name in self.key_pairs]

    def import_key_pair_from_string(self, name, key_material):
        self.key_pairs[name] = key_material

    def delete_key_pair(self, key_pair):
        del self.key_pairs[key_pair.name]

    def import_key_pair_from_file(self, name, key_file_path):
        with open(key_file_path) as f:
            self.import_key_pair_from_string(name, f.read())

    def create_key_pair(self, name):
        self.import_key_pair_from_string(
            name,
            format_openssh_pubkey(RSAKey.generate(1024))
        )


def test_cloud_key_store():
    driver = KeyPairSupportedDummyNodeDriver('')
    keystore = CloudKeyStore(driver)
    identity = Identity(DummyTeam, 'abcd')
    assert_keystore_compliance(keystore, identity)
    identity2 = Identity(DummyTeam, 'efg')
    assert_keystore_compliance(keystore, identity2)


def test_cloud_key_store_get_key_name_pattern():
    driver = KeyPairSupportedDummyNodeDriver('')
    keystore = CloudKeyStore(driver)
    identity = Identity(DummyTeam, 'abcd')
    pattern = keystore._get_key_name_pattern(identity)
    random_fp = lambda: ':'.join(
        map('{:02x}'.format, hashlib.md5(os.urandom(100)).digest())
    )
    actual = {
        'tests.server_test.DummyTeam abcd ' + random_fp()
        for _ in range(5)
    }
    result = filter(pattern.match, actual | {
        'tests.server_test.DummyTeam defg ' + random_fp(),
        'tests.server_test.OtherTeam abcd ' + random_fp(),
        'tests.server_test.DummyTeam abcd ',
        'junk'
    })
    assert frozenset(result) == actual


def test_cloud_master_public_key_store():
    driver = KeyPairSupportedDummyNodeDriver('')
    actual_store = MemoryMasterKeyStore()
    store = CloudMasterPublicKeyStore(driver,
                                      'geofront-masterkey',
                                      actual_store)
    for _ in range(2):
        master_key = RSAKey.generate(1024)
        store.save(master_key)
        assert actual_store.load() == store.load() == master_key
        assert parse_openssh_pubkey(
            driver.get_key_pair('geofront-masterkey').public_key
        ) == master_key

########NEW FILE########
__FILENAME__ = dbapi_test
from pytest import fail, fixture, skip, yield_fixture
from werkzeug.utils import import_string

from geofront.backends.dbapi import DatabaseKeyStore
from geofront.identity import Identity
from ..keystore_test import assert_keystore_compliance
from ..server_test import DummyTeam


DRIVERS = {
    'sqlite3': 'pysqlite',  # https://docs.python.org/3/library/sqlite3.html
    'psycopg2': 'psycopg2',  # http://initd.org/psycopg/
    'pymysql': 'PyMySQL',  # http://www.pymysql.org/
    'mysql.connector': 'mysql-connector-python',
    # http://dev.mysql.com/doc/connector-python/en/
}


@yield_fixture(scope='function', params=list(DRIVERS.keys()))
def fx_db_module(request, tmpdir):
    import_name = request.param
    package = DRIVERS[import_name]
    try:
        db_module = import_string(import_name)
    except ImportError:
        skip(package + ' is not installed; skipped')
    args = ()
    kwargs = {}
    getoption = request.config.getoption
    if import_name == 'sqlite3':
        args = str(tmpdir.join('geofront_test.db')),
    elif package == 'psycopg2':
        try:
            pgdatabase = getoption('--postgresql-database')
        except ValueError:
            pgdatabase = None
        if pgdatabase is None:
            skip('--postgresql-database is not provided; skipped')
        kwargs['database'] = pgdatabase
        for option in 'host', 'port', 'user', 'password':
            try:
                kwargs[option] = getoption('--postgresql-' + option)
            except ValueError:
                continue
    elif 'mysql' in import_name:
        try:
            mysql_db = getoption('--mysql-database')
        except ValueError:
            mysql_db = None
        if mysql_db is None:
            skip('--mysql-database is not provided; skipped')
        kwargs['database'] = mysql_db
        for option in 'host', 'port', 'user', 'passwd':
            try:
                kwargs[option] = getoption('--mysql-' + option)
            except ValueError:
                continue
            if kwargs[option] is None:
                del kwargs[option]
    else:
        fail('arguments to {}.connect() are not ready'.format(import_name))
    yield db_module, args, kwargs
    if 'sqlite' not in import_name.lower():
        connection = db_module.connect(*args, **kwargs)
        try:
            cursor = connection.cursor()
            try:
                cursor.execute('DROP TABLE geofront_public_key')
            finally:
                cursor.close()
        finally:
            connection.close()


@fixture
def fx_db_key_store(fx_db_module):
    mod, args, kwargs = fx_db_module
    return DatabaseKeyStore(mod, *args, **kwargs)


def test_db_key_store(fx_db_key_store):
    identity = Identity(DummyTeam, 'abcd')
    assert_keystore_compliance(fx_db_key_store, identity)
    identity2 = Identity(DummyTeam, 'efg')
    assert_keystore_compliance(fx_db_key_store, identity2)

########NEW FILE########
__FILENAME__ = github_test
from pytest import fixture, skip, yield_fixture

from geofront.backends.github import (GitHubKeyStore, GitHubOrganization,
                                      request)
from geofront.identity import Identity
from ..keystore_test import assert_keystore_compliance


@fixture
def fx_github_access_token(request):
    try:
        token = request.config.getoption('--github-access-token')
    except ValueError:
        token = None
    if not token:
        skip('--github-access-token is not set; skipped')
    return token


@fixture
def fx_github_org_login(request):
    try:
        org_login = request.config.getoption('--github-org-login')
    except ValueError:
        org_login = None
    if not org_login:
        skip('--github-org-login is not provided; skipped')
    return org_login


@fixture
def fx_github_team_slugs(request):
    try:
        slugs = request.config.getoption('--github-team-slugs')
    except ValueError:
        slugs = None
    if not slugs:
        skip('--github-team-slugs is not provided; skipped')
    return {slug.strip() for slug in slugs.split()}


_fx_github_identity_cache = None


@fixture
def fx_github_identity(fx_github_access_token):
    global _fx_github_identity_cache
    if not _fx_github_identity_cache:
        _fx_github_identity_cache = request(
            fx_github_access_token,
            'https://api.github.com/user',
            'GET'
        )
    return Identity(
        GitHubOrganization,
        _fx_github_identity_cache['login'],
        fx_github_access_token
    )


def test_request(fx_github_access_token, fx_github_identity):
    result = request(
        fx_github_access_token,
        'https://api.github.com/user',
        'GET'
    )
    assert result['type'] == 'User'
    result2 = request(
        fx_github_identity,
        'https://api.github.com/user',
        'GET'
    )
    assert result == result2


def test_authorize(fx_github_identity, fx_github_org_login):
    org = GitHubOrganization('', '', fx_github_org_login)
    assert org.authorize(fx_github_identity)


def test_list_groups(fx_github_identity, fx_github_org_login,
                     fx_github_team_slugs):
    org = GitHubOrganization('', '', fx_github_org_login)
    groups = org.list_groups(fx_github_identity)
    assert groups == fx_github_team_slugs


def cleanup_ssh_keys(identity):
    keys = request(identity, GitHubKeyStore.LIST_URL, 'GET')
    for key in keys:
        url = GitHubKeyStore.DEREGISTER_URL.format(**key)
        request(identity, url, 'DELETE')


@yield_fixture
def fx_github_keystore(fx_github_identity):
    cleanup_ssh_keys(fx_github_identity)
    yield GitHubKeyStore()
    cleanup_ssh_keys(fx_github_identity)


def test_github_keystore(fx_github_identity, fx_github_keystore):
    assert_keystore_compliance(fx_github_keystore, fx_github_identity)

########NEW FILE########
__FILENAME__ = conftest
import datetime
import os
import threading

from paramiko.rsakey import RSAKey
from paramiko.sftp_client import SFTPClient
from paramiko.transport import Transport
from pytest import fixture, yield_fixture

from geofront.keystore import format_openssh_pubkey
from geofront import server
from .sftpd import start_server


# By default it's a minute, but a minute is enough to make the test suite
# very slow.  For faster unit testing we shorten this constant.
server.AUTHORIZATION_TIMEOUT = datetime.timedelta(seconds=5)


def env_default(env):
    return {'default': os.environ[env]} if env in os.environ else {}


def pytest_addoption(parser):
    parser.addoption('--sshd-port-min',
                     metavar='PORT',
                     type=int,
                     default=12220,
                     help='the minimum unused port number [%default(s)]')
    parser.addoption('--sshd-port-max',
                     metavar='PORT',
                     type=int,
                     default=12399,
                     help='the maximum unused port number [%default(s)]')
    parser.addoption('--redis-host',
                     metavar='HOSTNAME',
                     help='redis host',
                     **env_default('REDIS_HOST'))
    parser.addoption('--redis-port',
                     metavar='PORT',
                     type=int,
                     default=6379,
                     help='redis port [%default(s)]')
    parser.addoption('--redis-password',
                     metavar='PASSWORD',
                     default=None,
                     help='redis password')
    parser.addoption('--redis-db',
                     metavar='DB',
                     type=int,
                     default=1,
                     help='redis db number [%(default)s]')
    parser.addoption('--postgresql-host',
                     metavar='HOSTNAME',
                     help='postgresql database server host [%(default)s]',
                     **env_default('PGHOST'))
    parser.addoption('--postgresql-port',
                     metavar='PORT',
                     type=int,
                     help='postgresql database server port [%(default)s]',
                     **env_default('PGPORT'))
    parser.addoption('--postgresql-user',
                     metavar='USER',
                     help='postgresql user [%(default)s]',
                     **env_default('PGUSER'))
    parser.addoption('--postgresql-password',
                     metavar='PASSWORD',
                     help='postgresql user password [%(default)s]',
                     **env_default('PGPASSWORD'))
    parser.addoption('--postgresql-database',
                     metavar='DBNAME',
                     help='postgresql database name [%(default)s]',
                     **env_default('PGDATABASE'))
    parser.addoption('--mysql-host',
                     metavar='HOSTNAME',
                     help='mysql database server host [%(default)s]',
                     **env_default('MYSQL_HOST'))
    parser.addoption('--mysql-port',
                     metavar='PORT',
                     type=int,
                     help='mysql database server port [%(default)s]',
                     **env_default('MYSQL_PORT'))
    parser.addoption('--mysql-user',
                     metavar='USER',
                     help='mysql user [%(default)s]',
                     **env_default('MYSQL_USER'))
    parser.addoption('--mysql-passwd',
                     metavar='PASSWD',
                     help='mysql user password [%(default)s]',
                     **env_default('MYSQL_PASSWD'))
    parser.addoption('--mysql-database',
                     metavar='DATABASE',
                     help='mysql database name [%(default)s]',
                     **env_default('MYSQL_DATABASE'))
    parser.addoption('--github-access-token',
                     metavar='TOKEN',
                     help='github access token for key store test (caution: '
                          'it will remove all ssh keys of the account)',
                     **env_default('GITHUB_ACCESS_TOKEN'))
    parser.addoption('--github-org-login',
                     metavar='LOGIN',
                     help='github org login for team test',
                     **env_default('GITHUB_ORG_LOGIN'))
    parser.addoption('--github-team-slugs',
                     metavar='SLUGS',
                     help='space-separated github team slugs for group '
                          'listing test',
                     **env_default('GITHUB_TEAM_SLUGS'))


used_port = 0


@yield_fixture
def fx_sftpd(request, tmpdir):
    global used_port
    getopt = request.config.getoption
    port_min = max(used_port + 1, getopt('--sshd-port-min'))
    port_max = min(port_min + 2, getopt('--sshd-port-max'))
    used_port = port_max
    servers = {}
    for port in range(port_min, port_max + 1):
        path = tmpdir.mkdir(str(port))
        terminated = threading.Event()
        thread = threading.Thread(
            target=start_server,
            args=(str(path), '127.0.0.1', port, terminated)
        )
        servers[port] = thread, path, terminated
    yield servers
    for port, (th, _, ev) in servers.items():
        ev.set()
    for port, (th, _, ev) in servers.items():
        if th.is_alive():
            th.join(10)
        assert not th.is_alive(), '{!r} (for port #{}) is still alive'.format(
            th, port
        )


@fixture
def fx_authorized_keys():
    return [RSAKey.generate(1024) for _ in range(5)]


@yield_fixture
def fx_authorized_sftp(fx_sftpd, fx_authorized_keys):
    port, (thread, path, ev) = fx_sftpd.popitem()
    thread.start()
    key = RSAKey.generate(1024)
    dot_ssh = path.mkdir('.ssh')
    with dot_ssh.join('authorized_keys').open('w') as f:
        print(format_openssh_pubkey(key), file=f)
        for authorized_key in fx_authorized_keys:
            print(format_openssh_pubkey(authorized_key), file=f)
    transport = Transport(('127.0.0.1', port))
    transport.connect(pkey=key)
    sftp_client = SFTPClient.from_transport(transport)
    yield sftp_client, path, [key] + fx_authorized_keys
    sftp_client.close()
    transport.close()


@fixture
def fx_master_key():
    return RSAKey.generate(1024)


@fixture
def fx_authorized_servers(fx_sftpd, fx_master_key):
    for port, (thread, path, ev) in fx_sftpd.items():
        with path.mkdir('.ssh').join('authorized_keys').open('w') as f:
            f.write(format_openssh_pubkey(fx_master_key))
        thread.start()
    return fx_sftpd

########NEW FILE########
__FILENAME__ = identity_test
from geofront.identity import Identity


def test_identity_eq():
    assert Identity(int, 1) == Identity(int, 1)
    assert not (Identity(int, 1) == Identity(int, 2))
    assert not (Identity(int, 1) == Identity(str, 1))
    assert not (Identity(int, 1) == Identity(str, 2))


def test_identity_ne():
    assert not (Identity(int, 1) != Identity(int, 1))
    assert Identity(int, 1) != Identity(int, 2)
    assert Identity(int, 1) != Identity(str, 1)
    assert Identity(int, 1) != Identity(str, 2)


def test_identity_hash():
    assert hash(Identity(int, 1)) == hash(Identity(int, 1))

########NEW FILE########
__FILENAME__ = keystore_test
import collections.abc

from paramiko.dsskey import DSSKey
from paramiko.rsakey import RSAKey
from pytest import fixture, raises

from geofront.keystore import (DuplicatePublicKeyError, KeyTypeError,
                               format_openssh_pubkey,
                               get_key_fingerprint, parse_openssh_pubkey)


@fixture
def fx_id_rsa_pub():
    return (
        'AAAAB3NzaC1yc2EAAAABIwAAAQEA0ql70Tsi8ToDGm+gkkRGv12Eb15QSgdVQeIFbasK+'
        'yHNITAOVHtbM3nlUTIxFh7sSga7UmEjCya0ljU0GJ+zvnFOxKvRypBoUY38W8XkR3f2IJ'
        'QwbWE7/t4Vs4DViramrZr/wnQtRstLZRncIj307ApQuB18uedbtreGdg+cd75/KfTvDc3'
        'L17ZYlgdmJ+tTdzTi5mYbiPmtn631Qm8/OCBazwUSfidRlG1SN97QJdV5ZFLNN+3BRR7R'
        'IRzYZ/2KEJqiOI5nqi3TEiPeq49/LJElu4tdJ8icXT7COrGllnhBbpZdxRM26hhVXv62v'
        'OTQwXm1fumg0PgMACP2S1WVNw=='
    )


def test_parse_openssh_pubkey_rsa(fx_id_rsa_pub):
    pkey = parse_openssh_pubkey('ssh-rsa ' + fx_id_rsa_pub)
    assert isinstance(pkey, RSAKey)
    assert pkey.get_name() == 'ssh-rsa'
    assert pkey.get_base64() == fx_id_rsa_pub
    pkey = parse_openssh_pubkey('ssh-rsa ' + fx_id_rsa_pub + ' comment')
    assert isinstance(pkey, RSAKey)
    assert pkey.get_name() == 'ssh-rsa'
    assert pkey.get_base64() == fx_id_rsa_pub


def test_parse_openssh_pubkey_dsa():
    id_dsa_pub = (
        'AAAAB3NzaC1kc3MAAACBALTeFi9rlCkORWTj2sznDx2p/nUDFGZY0j9ynIioho0vlNfgj'
        '4U9/3SCq4JjhXhH7OB6h0NyUSNEVe9bbe7mHFTpQWwy1bmXEBaJALv1IqIBme1ZJcdUbe'
        'ZM3PCLmbPTE7sjgUwk98hT3TI8CI5hLkJmsV1nFckEONgIG9IPjnmnAAAAFQCb72U4lNY'
        '2DsZ+e2TaxTtT8i996QAAAIEAlO7/8Vypf5bgAkeHGJ15cfiuR1X/gkSUj+sAhJYJ7pyB'
        'h7vnJbBPztgxVvuHxELFcCufFyps7sibUq4MifqBPrVwLiK4PiNNcK8M2hjDJmWrqo/Bw'
        'LRXkc1LWWxLr/PCBVeqAe2OTFEtu4ZLaqlex+WI2Ezgn4pItAH9lIACBlcAAACAa5GI36'
        'nWqU89z07Pdh7q8gZHR9KXHMS3T6dGxkOhLb+XSATV14+udjqtrULs552d+d7Pdq+0KBm'
        '+6lC/YRn6ETsJ2AJzWxlG+sJ/eTFEWw9Q2uTWOBRbAqL2VJG5DG+K+lhgRRNNKHMtUF1j'
        '1MeJb71HT7amaOcE+dNEgKS0xi4='
    )
    pkey = parse_openssh_pubkey('ssh-dss ' + id_dsa_pub)
    assert isinstance(pkey, DSSKey)
    assert pkey.get_name() == 'ssh-dss'
    assert pkey.get_base64() == id_dsa_pub
    pkey = parse_openssh_pubkey('ssh-dss ' + id_dsa_pub + ' comment')
    assert isinstance(pkey, DSSKey)
    assert pkey.get_name() == 'ssh-dss'
    assert pkey.get_base64() == id_dsa_pub


def test_parse_openssh_unsupported():
    with raises(KeyTypeError):
        parse_openssh_pubkey(
            'ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyN'
            'TYAAABBBDs0y6X8UquYBtTvDjbK+RZIAWduMbfWfUmh2MRtWpo2ZqEyQiyeTRDJ/4'
            '1A5heiONtm7QhUJoBF5VBUjsxiIFk= dahlia@hongminhee-thinkpad-e435'
        )


def test_format_openssh_pubkey():
    rsakey = RSAKey.generate(1024)
    assert parse_openssh_pubkey(format_openssh_pubkey(rsakey)) == rsakey
    dsskey = DSSKey.generate(1024)
    assert parse_openssh_pubkey(format_openssh_pubkey(dsskey)) == dsskey


def test_get_key_fingerprint(fx_id_rsa_pub):
    pkey = parse_openssh_pubkey('ssh-rsa ' + fx_id_rsa_pub)
    assert (get_key_fingerprint(pkey) ==
            'f5:6e:03:1c:cd:2c:84:64:d7:94:18:8b:79:60:11:df')
    assert (get_key_fingerprint(pkey, '-') ==
            'f5-6e-03-1c-cd-2c-84-64-d7-94-18-8b-79-60-11-df')
    assert get_key_fingerprint(pkey, '') == 'f56e031ccd2c8464d794188b796011df'


def assert_keystore_compliance(keystore, identity):
    """Test basic behaviors of a KeyStore implementation."""
    # "List registered public keys of the given ``identity``."
    keys = keystore.list_keys(identity)
    assert isinstance(keys, collections.abc.Set)
    assert not keys
    # "Register the given ``public_key`` to the ``identity``."
    key = RSAKey.generate(1024)
    keystore.register(identity, key)
    keys = keystore.list_keys(identity)
    assert isinstance(keys, collections.abc.Set)
    assert keys == {key}
    # ":raise geofront.keystore.DuplicatePublicKeyError:
    # when the ``public_key`` is already in use"
    with raises(DuplicatePublicKeyError):
        keystore.register(identity, key)
    # "Remove the given ``public_key`` of the ``identity``."
    keystore.deregister(identity, key)
    keys = keystore.list_keys(identity)
    assert isinstance(keys, collections.abc.Set)
    assert not keys
    # "It silently does nothing if there isn't the given ``public_key``
    # in the store."
    keystore.deregister(identity, key)

########NEW FILE########
__FILENAME__ = masterkey_test
import datetime
import os.path
import time

from paramiko.pkey import PKey
from paramiko.rsakey import RSAKey
from pytest import raises

from geofront.keystore import parse_openssh_pubkey
from geofront.masterkey import (EmptyStoreError, FileSystemMasterKeyStore,
                                PeriodicalRenewal, TwoPhaseRenewal,
                                read_private_key_file, renew_master_key)
from geofront.remote import Remote


def test_fs_master_key_store_load():
    path = os.path.join(os.path.dirname(__file__), 'test_id_rsa')
    s = FileSystemMasterKeyStore(path)
    key = s.load()
    assert isinstance(key, RSAKey)
    assert key.get_base64() == (
        'AAAAB3NzaC1yc2EAAAADAQABAAABAQC7+fDpQ9sQKIdzXvqT3TzrPp2OpUCOJtUW3k0oi'
        'trqqHe1XiCke++DSpAv56poCppTj9qo3N1HyhZhSv/jH7/ejZ8NZdtvLIZGOCQZVdKNy0'
        'cg7jlimrWA2s8X201Yn3hYpUrYJYbhAAuQM5flvbyBtn5/miONQ8NVimgjG6UVANVqX4W'
        'H9kqdr4SBf45/+BAdenf2j5DC3xceOOW8wZfe2rOJpQ0msVxMeXExGqF9DS2E3bqOwE1C'
        'MPEGYr5KZCx7IeJ/4udBuKc/gOXb8tPiTTNxtYXEBcqhBdCa/M6pEdW5LiHxxoF5b6xY9'
        'q0nmi7Rn0weXK0SufhGgKrpSH+B'
    )


def test_fs_master_key_store_save(tmpdir):
    path = tmpdir.join('id_rsa')
    s = FileSystemMasterKeyStore(str(path))
    with raises(EmptyStoreError):
        s.load()
    key = RSAKey.generate(1024)
    s.save(key)
    stored_key = s.load()
    assert isinstance(stored_key, RSAKey)
    assert stored_key.get_base64() == stored_key.get_base64()


def test_read_private_key_file():
    path = os.path.join(os.path.dirname(__file__), 'test_id_rsa')
    with open(path) as f:
        key = read_private_key_file(f)
    assert isinstance(key, RSAKey)
    assert key.get_base64() == (
        'AAAAB3NzaC1yc2EAAAADAQABAAABAQC7+fDpQ9sQKIdzXvqT3TzrPp2OpUCOJtUW3k0oi'
        'trqqHe1XiCke++DSpAv56poCppTj9qo3N1HyhZhSv/jH7/ejZ8NZdtvLIZGOCQZVdKNy0'
        'cg7jlimrWA2s8X201Yn3hYpUrYJYbhAAuQM5flvbyBtn5/miONQ8NVimgjG6UVANVqX4W'
        'H9kqdr4SBf45/+BAdenf2j5DC3xceOOW8wZfe2rOJpQ0msVxMeXExGqF9DS2E3bqOwE1C'
        'MPEGYr5KZCx7IeJ/4udBuKc/gOXb8tPiTTNxtYXEBcqhBdCa/M6pEdW5LiHxxoF5b6xY9'
        'q0nmi7Rn0weXK0SufhGgKrpSH+B'
    )


def authorized_key_set(path):
    dotssh = path.join('.ssh')
    if not dotssh.isdir():
        dotssh = path.mkdir('.ssh')
    with dotssh.join('authorized_keys').open() as f:
        return {parse_openssh_pubkey(line.strip()) for line in f}


def test_two_phase_renewal(fx_authorized_servers, fx_master_key):
    remote_set = {
        Remote('user', '127.0.0.1', port)
        for port in fx_authorized_servers
    }
    old_key = fx_master_key
    new_key = RSAKey.generate(1024)
    for t, path, ev in fx_authorized_servers.values():
        assert authorized_key_set(path) == {old_key}
    with TwoPhaseRenewal(remote_set, old_key, new_key):
        for t, path, ev in fx_authorized_servers.values():
            assert authorized_key_set(path) == {old_key, new_key}
    for t, path, ev in fx_authorized_servers.values():
        assert authorized_key_set(path) == {new_key}


def test_two_phase_renewal_stop(fx_authorized_servers, fx_master_key):
    remote_set = {
        Remote('user', '127.0.0.1', port)
        for port in fx_authorized_servers
    }
    old_key = fx_master_key
    new_key = RSAKey.generate(1024)
    for t, path, ev in fx_authorized_servers.values():
        assert authorized_key_set(path) == {old_key}
    SomeException = type('SomeException', (Exception,), {})
    with raises(SomeException):
        with TwoPhaseRenewal(remote_set, old_key, new_key):
            for t, path, ev in fx_authorized_servers.values():
                assert authorized_key_set(path) == {old_key, new_key}
            raise SomeException('something went wrong')
    for t, path, ev in fx_authorized_servers.values():
        assert old_key in authorized_key_set(path)


def test_renew_master_key(fx_authorized_servers, fx_master_key, tmpdir):
    remote_set = {
        Remote('user', '127.0.0.1', port)
        for port in fx_authorized_servers
    }
    store = FileSystemMasterKeyStore(str(tmpdir.join('id_rsa')))
    store.save(fx_master_key)
    for t, path, ev in fx_authorized_servers.values():
        assert authorized_key_set(path) == {fx_master_key}
    new_key = renew_master_key(remote_set, store)
    assert new_key != fx_master_key
    assert store.load() == new_key
    for t, path, ev in fx_authorized_servers.values():
        assert authorized_key_set(path) == {new_key}


class FailureTestMasterKeyStore(FileSystemMasterKeyStore):

    def save(self, master_key: PKey):
        try:
            self.load()
        except EmptyStoreError:
            super().save(master_key)
        else:
            raise RenewalFailure()


class RenewalFailure(Exception):

    pass


def test_renew_master_key_fail(fx_authorized_servers, fx_master_key, tmpdir):
    remote_set = {
        Remote('user', '127.0.0.1', port)
        for port in fx_authorized_servers
    }
    store = FailureTestMasterKeyStore(str(tmpdir.join('id_rsa')))
    store.save(fx_master_key)
    for t, path, ev in fx_authorized_servers.values():
        assert authorized_key_set(path) == {fx_master_key}
    with raises(RenewalFailure):
        renew_master_key(remote_set, store)
    assert store.load() == fx_master_key
    for t, path, ev in fx_authorized_servers.values():
        assert fx_master_key in authorized_key_set(path)


def wait_for(seconds: int, condition):
    for _ in range(seconds * 2):
        if condition():
            break
        time.sleep(0.5)


def test_periodical_renewal(fx_authorized_servers, fx_master_key, tmpdir):
    remote_set = {
        Remote('user', '127.0.0.1', port)
        for port in fx_authorized_servers
    }
    store = FileSystemMasterKeyStore(str(tmpdir.join('id_rsa')))
    store.save(fx_master_key)
    for t, path, ev in fx_authorized_servers.values():
        assert authorized_key_set(path) == {fx_master_key}
    p = PeriodicalRenewal(remote_set, store, datetime.timedelta(seconds=3))
    assert store.load() == fx_master_key
    for t, path, ev in fx_authorized_servers.values():
        assert fx_master_key in authorized_key_set(path)
    wait_for(20, lambda: store.load() != fx_master_key)
    second_key = store.load()
    assert second_key != fx_master_key
    for t, path, ev in fx_authorized_servers.values():
        key_set = authorized_key_set(path)
        assert second_key in key_set
    wait_for(20, lambda: store.load() != second_key)
    third_key = store.load()
    assert third_key != fx_master_key
    assert third_key != second_key
    for t, path, ev in fx_authorized_servers.values():
        key_set = authorized_key_set(path)
        assert third_key in key_set
    p.terminate()
    last_key = store.load()
    time.sleep(10)
    assert store.load() == last_key
    for t, path, ev in fx_authorized_servers.values():
        assert authorized_key_set(path) == {last_key}

########NEW FILE########
__FILENAME__ = remote_test
import datetime
import time

from paramiko.rsakey import RSAKey
from pytest import mark, raises

from geofront.identity import Identity
from geofront.keystore import format_openssh_pubkey, parse_openssh_pubkey
from geofront.remote import (AuthorizedKeyList, DefaultPermissionPolicy,
                             GroupMetadataPermissionPolicy, Remote, authorize)
from geofront.team import Team


@mark.parametrize(('b', 'equal'), [
    (Remote('a', '192.168.0.1', 22), True),
    (Remote('a', '192.168.0.1', 2222), False),
    (Remote('b', '192.168.0.1', 22), False),
    (Remote('b', '192.168.0.1', 2222), False),
    (Remote('a', '192.168.0.2', 22), False),
    (Remote('b', '192.168.0.2', 22), False),
    (Remote('a', '192.168.0.2', 2222), False),
    (Remote('b', '192.168.0.2', 2222), False),
    (Remote('a', '192.168.0.1', 22, {'a': 1}), True),
    (Remote('a', '192.168.0.1', 2222, {'a': 1}), False),
    (Remote('b', '192.168.0.1', 22, {'a': 1}), False),
    (Remote('b', '192.168.0.1', 2222, {'a': 1}), False),
    (Remote('a', '192.168.0.2', 22, {'a': 1}), False),
    (Remote('b', '192.168.0.2', 22, {'a': 1}), False),
    (Remote('a', '192.168.0.2', 2222, {'a': 1}), False),
    (Remote('b', '192.168.0.2', 2222, {'a': 1}), False)
])
def test_remote(b, equal):
    a = Remote('a', '192.168.0.1')
    assert (a == b) is equal
    assert (a != b) is (not equal)
    assert (hash(a) == hash(b)) is equal


def test_authorized_keys_list_iter(fx_authorized_sftp):
    sftp_client, path, keys = fx_authorized_sftp
    key_list = AuthorizedKeyList(sftp_client)
    it = iter(key_list)
    assert next(it) == keys[0]
    assert next(it) == keys[1]
    assert next(it) == keys[2]
    assert next(it) == keys[3]
    assert next(it) == keys[4]
    assert next(it) == keys[5]
    with raises(StopIteration):
        next(it)
    # It's lazily evaluated; changes should reflect
    with path.join('.ssh', 'authorized_keys').open('w') as f:
        f.write(format_openssh_pubkey(keys[0]))
    it = iter(key_list)
    assert next(it) == keys[0]
    with raises(StopIteration):
        next(it)


def test_authorized_keys_list_len(fx_authorized_sftp):
    sftp_client, path, keys = fx_authorized_sftp
    key_list = AuthorizedKeyList(sftp_client)
    assert len(key_list) == 6
    # It's lazily evaluated; changes should reflect
    with path.join('.ssh', 'authorized_keys').open('w') as f:
        f.write(format_openssh_pubkey(keys[0]))
    assert len(key_list) == 1


def test_authorized_keys_list_getitem(fx_authorized_sftp):
    sftp_client, path, keys = fx_authorized_sftp
    key_list = AuthorizedKeyList(sftp_client)
    for i in range(-6, 6):
        assert key_list[i] == keys[i]
        assert key_list[i:] == keys[i:]
        assert key_list[:i] == keys[:i]
        assert key_list[i:i + 3] == keys[i:i + 3]
    with raises(IndexError):
        assert key_list[-7]
    with raises(IndexError):
        assert key_list[6]
    with raises(TypeError):
        key_list['key']
    # It's lazily evaluated; changes should reflect
    with path.join('.ssh', 'authorized_keys').open('w') as f:
        f.write(format_openssh_pubkey(keys[0]))
    assert key_list[0] == key_list[-1] == keys[0]
    with raises(IndexError):
        key_list[1]
    with raises(IndexError):
        key_list[-2]


def test_authorized_keys_list_setitem(fx_authorized_sftp):
    sftp_client, path, keys = fx_authorized_sftp
    key_list = AuthorizedKeyList(sftp_client)
    # Slice assignment
    key_list[3:] = []
    with path.join('.ssh', 'authorized_keys').open() as f:
        for i in range(3):
            assert parse_openssh_pubkey(f.readline().strip()) == keys[i]
        assert not f.readline().strip()
    # Positive index
    key_list[2] = keys[3]
    with path.join('.ssh', 'authorized_keys').open() as f:
        assert parse_openssh_pubkey(f.readline().strip()) == keys[0]
        assert parse_openssh_pubkey(f.readline().strip()) == keys[1]
        assert parse_openssh_pubkey(f.readline().strip()) == keys[3]
        assert not f.readline().strip()
    # Negative index
    key_list[-1] = keys[4]
    with path.join('.ssh', 'authorized_keys').open() as f:
        assert parse_openssh_pubkey(f.readline().strip()) == keys[0]
        assert parse_openssh_pubkey(f.readline().strip()) == keys[1]
        assert parse_openssh_pubkey(f.readline().strip()) == keys[4]
        assert not f.readline().strip()


def test_authorized_keys_list_insert(fx_authorized_sftp):
    sftp_client, path, keys = fx_authorized_sftp
    key_list = AuthorizedKeyList(sftp_client)
    new_key = RSAKey.generate(1024)
    key_list.insert(2, new_key)
    with path.join('.ssh', 'authorized_keys').open() as f:
        assert parse_openssh_pubkey(f.readline().strip()) == keys[0]
        assert parse_openssh_pubkey(f.readline().strip()) == keys[1]
        assert parse_openssh_pubkey(f.readline().strip()) == new_key
        for i in range(2, 6):
            assert parse_openssh_pubkey(f.readline().strip()) == keys[i]
        assert not f.readline().strip()


def test_authorized_keys_list_extend(fx_authorized_sftp):
    sftp_client, path, keys = fx_authorized_sftp
    key_list = AuthorizedKeyList(sftp_client)
    new_keys = [RSAKey.generate(1024) for _ in range(3)]
    key_list.extend(new_keys)
    with path.join('.ssh', 'authorized_keys').open() as f:
        for i in range(6):
            assert parse_openssh_pubkey(f.readline().strip()) == keys[i]
        for i in range(3):
            assert parse_openssh_pubkey(f.readline().strip()) == new_keys[i]
        assert not f.readline().strip()


def test_authorized_keys_list_delitem(fx_authorized_sftp):
    sftp_client, path, keys = fx_authorized_sftp
    key_list = AuthorizedKeyList(sftp_client)
    # Slice deletion
    del key_list[3:]
    with path.join('.ssh', 'authorized_keys').open() as f:
        for i in range(3):
            assert parse_openssh_pubkey(f.readline().strip()) == keys[i]
        assert not f.readline().strip()
    # Positive index
    del key_list[2]
    with path.join('.ssh', 'authorized_keys').open() as f:
        assert parse_openssh_pubkey(f.readline().strip()) == keys[0]
        assert parse_openssh_pubkey(f.readline().strip()) == keys[1]
        assert not f.readline().strip()
    # Negative index
    del key_list[-1]
    with path.join('.ssh', 'authorized_keys').open() as f:
        assert parse_openssh_pubkey(f.readline().strip()) == keys[0]
        assert not f.readline().strip()


def test_authorize(fx_sftpd):
    port, (thread, path, ev) = fx_sftpd.popitem()
    thread.start()
    master_key = RSAKey.generate(1024)
    public_keys = {RSAKey.generate(1024), RSAKey.generate(1024)}
    authorized_keys_path = path.mkdir('.ssh').join('authorized_keys')
    with authorized_keys_path.open('w') as f:
        print(format_openssh_pubkey(master_key), file=f)
    expires_at = authorize(
        public_keys,
        master_key,
        Remote('user', '127.0.0.1', port),
        timeout=datetime.timedelta(seconds=5)
    )
    with authorized_keys_path.open() as f:
        saved_keys = map(parse_openssh_pubkey, f)
        assert frozenset(saved_keys) == (public_keys | {master_key})
    while datetime.datetime.now(datetime.timezone.utc) <= expires_at:
        time.sleep(1)
    time.sleep(1)
    with authorized_keys_path.open() as f:
        saved_keys = map(parse_openssh_pubkey, f)
        assert frozenset(saved_keys) == {master_key}


class DummyTeam(Team):

    pass


def test_default_permission_policy():
    remotes = {
        'a': Remote('a', 'localhost'),
        'b': Remote('b', 'localhost')
    }
    identity = Identity(DummyTeam, 'a')
    p = DefaultPermissionPolicy()
    assert p.filter(remotes, identity, {'x'}) == remotes
    for remote in remotes.values():
        assert p.permit(remote, identity, {'x'})


@mark.parametrize(('key', 'separator'), [
    ('role', None),
    ('role', ','),
    ('role', '/'),
    ('groups', None)
])
def test_group_metadata_permission_policy(key, separator):
    sep = separator or ' '
    remotes = {
        'web-1': Remote(
            'ubuntu', '192.168.0.5',
            metadata={key: sep.join(['web', 'a']), 'other': 'ignore'}
        ),
        'web-2': Remote(
            'ubuntu', '192.168.0.6',
            metadata={key: sep.join(['web', 'b']), 'other': 'ignore'}
        ),
        'web-3': Remote(
            'ubuntu', '192.168.0.7',
            metadata={key: sep.join(['web', 'c']), 'other': 'ignore'}
        ),
        'worker-1': Remote(
            'ubuntu', '192.168.0.25',
            metadata={key: sep.join(['worker', 'a']), 'other': 'ignore'}
        ),
        'worker-2': Remote(
            'ubuntu', '192.168.0.26',
            metadata={key: sep.join(['worker', 'b']), 'other': 'ignore'}
        ),
        'db-1': Remote(
            'ubuntu', '192.168.0.50',
            metadata={key: sep.join(['db', 'a']), 'other': 'ignore'}
        ),
        'db-2': Remote(
            'ubuntu', '192.168.0.51',
            metadata={key: sep.join(['db', 'b']), 'other': 'ignore'}
        )
    }
    subset = lambda *keys: {a: r for a, r in remotes.items() if a in keys}
    p = GroupMetadataPermissionPolicy(key, separator)
    identity = Identity(DummyTeam, 1)
    assert (p.filter(remotes, identity, {'web', 'a'}) ==
            subset('web-1', 'web-2', 'web-3', 'worker-1', 'db-1'))
    assert (p.filter(remotes, identity, {'db', 'c'}) ==
            subset('web-3', 'worker-3', 'db-1', 'db-2'))
    assert p.permit(remotes['db-1'], identity, {'web', 'a'})
    assert not p.permit(remotes['db-1'], identity, {'web', 'b'})
    assert p.permit(remotes['db-1'], identity, {'db', 'a'})
    assert p.permit(remotes['db-1'], identity, {'db', 'b'})

########NEW FILE########
__FILENAME__ = server_test
import collections.abc
import datetime
import os
import random
import time

from flask import json, request, url_for
from iso8601 import parse_date
from paramiko.pkey import PKey
from paramiko.rsakey import RSAKey
from pytest import fail, fixture, mark, raises, skip, yield_fixture
from werkzeug.contrib.cache import (BaseCache, FileSystemCache, RedisCache,
                                    SimpleCache)
from werkzeug.exceptions import HTTPException, NotFound
from werkzeug.http import parse_options_header
from werkzeug.routing import Map, Rule
from werkzeug.urls import url_decode, url_encode

from geofront.identity import Identity
from geofront.keystore import (DuplicatePublicKeyError, KeyStore,
                               format_openssh_pubkey, get_key_fingerprint,
                               parse_openssh_pubkey)
from geofront.masterkey import MasterKeyStore
from geofront.remote import PermissionPolicy, Remote
from geofront.server import (FingerprintConverter, Token, TokenIdConverter,
                             app, get_identity, get_key_store, get_public_key,
                             get_remote_set, get_team, get_token_store,
                             remote_dict)
from geofront.team import AuthenticationError, Team
from geofront.util import typed
from geofront.version import VERSION


@fixture
def fx_url_map():
    return Map([
        Rule('/tokens/<token_id:token_id>', endpoint='create_session'),
        Rule('/fp/<fingerprint:fingerprint>', endpoint='get_key')
    ], converters={
        'token_id': TokenIdConverter,
        'fingerprint': FingerprintConverter
    })


@mark.parametrize('sample_id', {
    'VALID_ID', 'valid.id', 'Valid1234', '1234valid', '-._-._-._'
})
def test_token_id_converter_match_success(fx_url_map: Map, sample_id):
    path = '/tokens/' + sample_id
    urls = fx_url_map.bind('example.com', path)
    endpoint, values = urls.match(path)
    assert endpoint == 'create_session'
    assert values == {'token_id': sample_id}


@mark.parametrize('sample_id', {
    'invalid', '#INVALID', '/invalid', '@invalid', 'i', ('invalid' * 15)[:101]
})
def test_token_id_converter_match_failure(fx_url_map: Map, sample_id):
    path = '/tokens/' + sample_id
    urls = fx_url_map.bind('example.com', path)
    with raises(NotFound):
        urls.match(path)


@mark.parametrize(('f_hex', 'f_bytes'), {
    ('89:6d:a8:23:18:7a:c7:c0:24:f9:20:e7:7d:75:18:1c',
     b'\x89m\xa8#\x18z\xc7\xc0$\xf9 \xe7}u\x18\x1c'),
    ('f7:08:76:37:03:56:47:5a:e6:e3:bf:44:f4:18:11:1d',
     b'\xf7\x08v7\x03VGZ\xe6\xe3\xbfD\xf4\x18\x11\x1d'),
    ('e5:68:2e:93:36:70:d5:70:66:8c:79:56:c5:f1:3c:62',
     b'\xe5h.\x936p\xd5pf\x8cyV\xc5\xf1<b')
})
def test_fingerprint_converter_match_success(fx_url_map: Map, f_hex, f_bytes):
    path = '/fp/' + f_hex
    urls = fx_url_map.bind('example.com', path)
    endpoint, values = urls.match(path)
    assert endpoint == 'get_key'
    assert values == {'fingerprint': f_bytes}


@mark.parametrize('sample_fp', {
    'invalid',
    '89:6d:a8:23:18:7a:c7:c0:24:f9:20:e7:7d:75:18:1c:00',
    '89:6d:a8:23:18:7a:c7:c0:24:f9:20:e7:7d:75:18:1c:',
    '89:6d:a8:23:18:7a:c7:c0:24:f9:20:e7:7d:75:18:',
    '89:6d:a8:23:18:7a:c7:c0:24:f9:20:e7:7d:75:18',
})
def test_fingerprint_converter_match_failure(fx_url_map: Map, sample_fp):
    path = '/fp/' + sample_fp
    urls = fx_url_map.bind('example.com', path)
    with raises(NotFound):
        urls.match(path)


def test_server_version():
    with app.test_client() as client:
        response = client.get('/')
        assert 'Geofront/' + VERSION in response.headers['Server']
        assert response.headers['X-Geofront-Version'] == VERSION


def parse_link_header(link_header):
    href, options = parse_options_header(link_header)
    assert href.startswith('<')
    assert href.endswith('>')
    assert list(options.keys()) == ['rel']
    return href[1:-1], options['rel']


def test_server_endpoint():
    with app.test_client() as client:
        assert get_url('server_endpoint') == '/'
        expected_url = get_url(
            'token',
            token_id='TOKEN_ID',
            _external=True
        ).replace('/TOKEN_ID/', '/')
        response = client.get('/')
        assert (parse_link_header(response.headers['Link']) ==
                (expected_url, 'tokens'))
        assert json.loads(response.data) == {'tokens_url': expected_url}


def test_get_token_store__no_config():
    with raises(RuntimeError):
        with app.app_context():
            get_token_store()


def test_get_token_store__invalid_type():
    app.config['TOKEN_STORE'] = 'invalid type'
    with raises(RuntimeError):
        with app.app_context():
            get_token_store()


@fixture(scope='function', params=[
    SimpleCache,
    FileSystemCache,
    RedisCache
])
def fx_token_store(request, tmpdir):
    cls = request.param
    if cls is FileSystemCache:
        cache = cls(str(tmpdir.join('token_store')))
    elif cls is RedisCache:
        getoption = request.config.getoption
        try:
            redis_host = getoption('--redis-host')
        except ValueError:
            redis_host = None
        if not redis_host:
            skip('--redis-host is not set; skipped')
        cache = cls(
            host=redis_host,
            port=getoption('--redis-port'),
            password=getoption('--redis-password'),
            db=getoption('--redis-db'),
            key_prefix='gftest_{0}_'.format(
                ''.join(map('{:02x}'.format, os.urandom(8)))
            )
        )
    else:
        cache = cls()
    return cache


def test_get_token(fx_token_store):
    app.config['TOKEN_STORE'] = fx_token_store
    with app.app_context():
        token_store = get_token_store()
        assert isinstance(token_store, BaseCache)
        token_store.add('abc', 123)
        assert fx_token_store.get('abc') == 123
        token_store.set('def', 456)
        assert fx_token_store.get('def') == 456
        token_store.inc('def')
        assert fx_token_store.get('def') == 457
        token_store.dec('abc')
        assert fx_token_store.get('abc') == 122
        token_store.delete('def')
        assert not fx_token_store.get('def')


class DummyTeam(Team):

    def __init__(self):
        self.states = []

    def request_authentication(self,
                               auth_nonce: str,
                               redirect_url: str) -> str:
        self.states.append((auth_nonce, redirect_url))
        return 'http://example.com/auth/?' + url_encode({
            'auth_nonce': auth_nonce,
            'redirect_url': redirect_url
        })

    def authenticate(self, auth_nonce: str, requested_redirect_url: str,
                     wsgi_environ: dict) -> Identity:
        try:
            pair = self.states.pop()
        except IndexError:
            raise AuthenticationError()
        if pair[0] != auth_nonce or pair[1] != requested_redirect_url:
            raise AuthenticationError()
        return Identity(type(self), len(self.states))

    def authorize(self, identity: Identity) -> bool:
        return (issubclass(identity.team_type, type(self)) and
                identity.access_token is not False)

    def list_groups(self, identity: Identity):
        return {'odd' if identity.identifier % 2 else 'even'}


def test_get_team__no_config():
    with raises(RuntimeError):
        with app.app_context():
            get_team()


def test_get_team__invalid_type():
    app.config['TEAM'] = 'invalid type'
    with raises(RuntimeError):
        with app.app_context():
            get_team()


@fixture
def fx_team():
    return DummyTeam()


def test_get_team(fx_team):
    app.config['TEAM'] = fx_team
    with app.app_context():
        assert get_team() is fx_team


class MemoryMasterKeyStore(MasterKeyStore):

    @typed
    def __init__(self, master_key: PKey=None):
        if master_key is not None:
            self.save(master_key)

    @typed
    def load(self) -> PKey:
        return self.master_key

    @typed
    def save(self, master_key: PKey):
        self.master_key = master_key


@yield_fixture
def fx_app(fx_team, fx_token_store, fx_key_store, fx_master_key):
    app.config.update(
        TEAM=fx_team,
        TOKEN_STORE=fx_token_store,
        KEY_STORE=fx_key_store,
        MASTER_KEY_STORE=MemoryMasterKeyStore(fx_master_key)
    )
    yield app
    del app.config['TEAM'], \
        app.config['TOKEN_STORE'], \
        app.config['KEY_STORE'], \
        app.config['MASTER_KEY_STORE']


@fixture
def fx_token_id():
    """Random generated token id."""
    return ''.join(map('{:02x}'.format, os.urandom(random.randrange(4, 51))))


def get_url(endpoint, **values):
    with app.test_request_context():
        return url_for(endpoint, **values)


def test_create_access_token(fx_app, fx_token_id):
    url = get_url('create_access_token', token_id=fx_token_id)
    with app.test_client() as c:
        response = c.put(url)
        assert response.status_code == 202
        link = response.headers['Link']
        assert link.startswith('<http://example.com/auth/')
        assert link.endswith('>; rel=next')
        qs = url_decode(link[link.find('?') + 1:link.find('>')])
        result = json.loads(response.data)
        assert qs['redirect_url'] == get_url('authenticate',
                                             token_id=fx_token_id,
                                             _external=True)
        assert result == {'next_url': link[1:link.find('>')]}


def test_authenticate(fx_app, fx_token_store, fx_token_id):
    token_url = get_url('create_access_token', token_id=fx_token_id)
    auth_url = get_url('authenticate', token_id=fx_token_id)
    with app.test_client() as c:
        response = c.put(token_url)
        assert response.status_code == 202
        response = c.get(auth_url)
        assert response.status_code == 200
        token = fx_token_store.get(fx_token_id)
        assert isinstance(token, Token)
        assert token.identity == Identity(DummyTeam, 0)


@fixture
def fx_authorized_identity(fx_token_store, fx_token_id):
    identity = Identity(DummyTeam, 1, True)
    expires_at = (datetime.datetime.now(datetime.timezone.utc) +
                  datetime.timedelta(hours=1))
    fx_token_store.set(fx_token_id, Token(identity, expires_at))
    return identity


def test_get_identity(fx_app, fx_authorized_identity, fx_token_id):
    with fx_app.test_request_context():
        identity = get_identity(fx_token_id)
        assert identity == fx_authorized_identity


def test_get_identity_403(fx_app, fx_token_store, fx_token_id):
    expires_at = (datetime.datetime.now(datetime.timezone.utc) +
                  datetime.timedelta(hours=1))
    fx_token_store.set(
        fx_token_id,
        Token(Identity(DummyTeam, 1, False), expires_at)
    )
    with fx_app.test_request_context():
        try:
            result = get_identity(fx_token_id)
        except HTTPException as e:
            response = e.get_response(request.environ)
            assert response.status_code == 403
            data = json.loads(response.data)
            assert data['error'] == 'not-authorized'
        else:
            fail('get_identity() does not raise HTTPException, but returns ' +
                 repr(result))


def test_get_identity_404(fx_app, fx_token_id):
    with fx_app.test_request_context():
        try:
            result = get_identity(fx_token_id)
        except HTTPException as e:
            response = e.get_response(request.environ)
            assert response.status_code == 404
            data = json.loads(response.data)
            assert data['error'] == 'token-not-found'
        else:
            fail('get_identity() does not raise HTTPException, but returns ' +
                 repr(result))


def test_get_identity_412(fx_app, fx_token_store, fx_token_id):
    fx_token_store.set(fx_token_id, 'nonce')
    with fx_app.test_request_context():
        try:
            result = get_identity(fx_token_id)
        except HTTPException as e:
            response = e.get_response(request.environ)
            assert response.status_code == 412
            data = json.loads(response.data)
            assert data['error'] == 'unfinished-authentication'
        else:
            fail('get_identity() does not raise HTTPException, but returns ' +
                 repr(result))


def test_token(fx_app, fx_authorized_identity, fx_token_id):
    with fx_app.test_client() as c:
        response = c.get(get_url('token', token_id=fx_token_id))
        assert response.status_code == 200
        links = dict(parse_link_header(link)[::-1]
                     for link in response.headers.getlist('Link'))
        assert links == {
            'remotes': get_url('list_remotes',
                               token_id=fx_token_id, _external=True),
            'keys': get_url('list_public_keys',
                            token_id=fx_token_id, _external=True),
            'masterkey': get_url('master_key',
                                 token_id=fx_token_id,
                                 _external=True)
        }
        t = fx_authorized_identity.team_type
        assert json.loads(response.data) == {
            'team_type': t.__module__ + '.' + t.__qualname__,
            'identifier': fx_authorized_identity.identifier,
            'remotes_url': links['remotes'],
            'keys_url': links['keys'],
            'master_key_url': links['masterkey']
        }


def test_token_412(fx_app, fx_token_store, fx_token_id):
    fx_token_store.set(fx_token_id, 'nonce')
    with fx_app.test_client() as c:
        response = c.get(get_url('token', token_id=fx_token_id))
        assert response.status_code == 412
        assert (json.loads(response.data)['error'] ==
                'unfinished-authentication')


def test_token_404(fx_app, fx_token_id):
    with fx_app.test_client() as c:
        response = c.get(get_url('token', token_id=fx_token_id))
        assert response.status_code == 404
        assert json.loads(response.data)['error'] == 'token-not-found'


def test_master_key(fx_app, fx_master_key,
                    fx_authorized_identity, fx_token_id):
    with fx_app.test_client() as c:
        response = c.get(get_url('master_key', token_id=fx_token_id))
        assert response.status_code == 200
        assert response.mimetype == 'text/plain'
        assert parse_openssh_pubkey(response.data.decode()) == fx_master_key


class DummyKeyStore(KeyStore):

    def __init__(self):
        self.keys = {}
        self.identities = {}

    def register(self, identity: Identity, public_key: PKey):
        if public_key in self.keys:
            raise DuplicatePublicKeyError()
        self.keys[public_key] = identity
        self.identities.setdefault(identity, set()).add(public_key)

    def list_keys(self, identity: Identity) -> collections.abc.Set:
        try:
            keys = self.identities[identity]
        except KeyError:
            return frozenset()
        return frozenset(keys)

    def deregister(self, identity: Identity, public_key: PKey):
        try:
            del self.keys[public_key]
            del self.identities[identity]
        except KeyError:
            pass


def test_get_key_store__no_config():
    with raises(RuntimeError):
        with app.app_context():
            get_key_store()


def test_get_key_store__invalid_type():
    app.config['KEY_STORE'] = 'invalid type'
    with raises(RuntimeError):
        with app.app_context():
            get_key_store()


@fixture
def fx_key_store():
    return DummyKeyStore()


def test_get_key_store(fx_key_store):
    app.config['KEY_STORE'] = fx_key_store
    with app.app_context():
        assert get_key_store() is fx_key_store


def test_list_public_keys(fx_app, fx_key_store,
                          fx_authorized_identity,
                          fx_token_id):
    with fx_app.test_client() as c:
        response = c.get(get_url('list_public_keys', token_id=fx_token_id))
        assert response.status_code == 200
        assert response.mimetype == 'application/json'
        assert response.data == b'{}'
    key = RSAKey.generate(1024)
    fx_key_store.register(fx_authorized_identity, key)
    with fx_app.test_client() as c:
        response = c.get(get_url('list_public_keys', token_id=fx_token_id))
        assert response.status_code == 200
        assert response.mimetype == 'application/json'
        data = {f: parse_openssh_pubkey(k)
                for f, k in json.loads(response.data).items()}
        assert data == {get_key_fingerprint(key): key}


def test_add_public_key_415(fx_app, fx_key_store,
                            fx_authorized_identity, fx_token_id):
    pkey = RSAKey.generate(1024)
    with fx_app.test_client() as c:
        response = c.post(
            get_url('add_public_key', token_id=fx_token_id),
            data={'key': format_openssh_pubkey(pkey)}
        )
        assert response.status_code == 415
        error = json.loads(response.data)
        assert error['error'] == 'unsupported-content-type'
        assert pkey not in fx_key_store.list_keys(fx_authorized_identity)


def test_add_public_key_unsupported_type(fx_app, fx_key_store,
                                         fx_authorized_identity, fx_token_id):
    pkey = RSAKey.generate(1024)
    with fx_app.test_client() as c:
        response = c.post(
            get_url('add_public_key', token_id=fx_token_id),
            content_type='text/plain',
            data=('invalid-type ' + format_openssh_pubkey(pkey)[7:]).encode()
        )
        assert response.status_code == 400
        error = json.loads(response.data)
        assert error['error'] == 'unsupported-key-type'
        assert pkey not in fx_key_store.list_keys(fx_authorized_identity)


def test_add_public_key_invalid_key(fx_app, fx_key_store,
                                    fx_authorized_identity, fx_token_id):
    with fx_app.test_client() as c:
        response = c.post(
            get_url('add_public_key', token_id=fx_token_id),
            content_type='text/plain',
            data=b'INVALID-FORMAT!!'
        )
        assert response.status_code == 400
        error = json.loads(response.data)
        assert error['error'] == 'invalid-key'


def test_add_public_key_duplicate_key(fx_app, fx_key_store,
                                      fx_authorized_identity, fx_token_id):
    pkey = RSAKey.generate(1024)
    fx_key_store.register(fx_authorized_identity, pkey)
    with fx_app.test_client() as c:
        response = c.post(
            get_url('add_public_key', token_id=fx_token_id),
            content_type='text/plain',
            data=format_openssh_pubkey(pkey).encode()
        )
        assert response.status_code == 400
        error = json.loads(response.data)
        assert error['error'] == 'duplicate-key'


def test_add_public_key(fx_app, fx_key_store,
                        fx_authorized_identity, fx_token_id):
    pkey = RSAKey.generate(1024)
    with fx_app.test_client() as c:
        response = c.post(
            get_url('add_public_key', token_id=fx_token_id),
            content_type='text/plain',
            data=format_openssh_pubkey(pkey).encode()
        )
        assert response.status_code == 201
        key_data = response.data
        assert parse_openssh_pubkey(key_data.decode()) == pkey
        assert pkey in fx_key_store.list_keys(fx_authorized_identity)
        r = c.get(response.location)
        assert r.data == key_data


def test_get_public_key(fx_app, fx_key_store,
                        fx_authorized_identity,
                        fx_token_id):
    key = RSAKey.generate(1024)
    fx_key_store.register(fx_authorized_identity, key)
    with fx_app.test_request_context():
        found = get_public_key(fx_token_id, key.get_fingerprint())
        assert found == key


def test_get_public_key_404(fx_app, fx_key_store,
                            fx_authorized_identity,
                            fx_token_id):
    with fx_app.test_request_context():
        try:
            result = get_public_key(fx_token_id, os.urandom(16))
        except HTTPException as e:
            response = e.get_response(request.environ)
            assert response.status_code == 404
            assert response.mimetype == 'application/json'
            error = json.loads(response.data.decode('utf-8'))
            assert error['error'] == 'not-found'
        else:
            fail('get_public_key() does not raise HTTPException, but returns '
                 + repr(result))


def test_public_key(fx_app, fx_key_store,
                    fx_authorized_identity,
                    fx_token_id):
    key = RSAKey.generate(1024)
    fx_key_store.register(fx_authorized_identity, key)
    with fx_app.test_client() as client:
        response = client.get(
            get_url(
                'public_key',
                token_id=fx_token_id,
                fingerprint=key.get_fingerprint()
            )
        )
        assert response.status_code == 200
        assert response.mimetype == 'text/plain'
        assert parse_openssh_pubkey(response.data.decode()) == key
    with fx_app.test_client() as client:
        response = client.get(
            get_url(
                'public_key',
                token_id=fx_token_id,
                fingerprint=os.urandom(16)
            )
        )
        assert response.status_code == 404
        assert response.mimetype == 'application/json'
        error = json.loads(response.data.decode('utf-8'))
        assert error['error'] == 'not-found'


def test_delete_public_key(fx_app, fx_key_store,
                           fx_authorized_identity,
                           fx_token_id):
    key = RSAKey.generate(1024)
    fx_key_store.register(fx_authorized_identity, key)
    with fx_app.test_client() as client:
        response = client.delete(
            get_url(
                'delete_public_key',
                token_id=fx_token_id,
                fingerprint=key.get_fingerprint()
            )
        )
        assert response.status_code == 200
    assert key not in fx_key_store.list_keys(fx_authorized_identity)
    with fx_app.test_client() as client:
        response = client.delete(
            get_url(
                'delete_public_key',
                token_id=fx_token_id,
                fingerprint=key.get_fingerprint()
            )
        )
        assert response.status_code == 404
        assert response.mimetype == 'application/json'
        error = json.loads(response.data.decode('utf-8'))
        assert error['error'] == 'not-found'


def test_get_remote_set__no_config():
    with raises(RuntimeError):
        with app.app_context():
            get_remote_set()


def test_get_remote_set__invalid_type():
    app.config['REMOTE_SET'] = 'invalid type'
    with raises(RuntimeError):
        with app.app_context():
            get_remote_set()


@yield_fixture
def fx_mock_remote_set():
    remote_set = {
        'web-1': Remote('user', '192.168.0.5'),
        'web-2': Remote('user', '192.168.0.6')
    }
    app.config['REMOTE_SET'] = remote_set
    yield remote_set
    del app.config['REMOTE_SET']


def test_get_remote_set(fx_mock_remote_set):
    app.config['REMOTE_SET'] = fx_mock_remote_set
    with app.app_context():
        assert get_remote_set() == fx_mock_remote_set


def test_remote_dict():
    remote = Remote('username', '127.0.0.1', 2222)
    assert remote_dict(remote) == {
        'user': 'username',
        'host': '127.0.0.1',
        'port': 2222
    }


class DisallowAllPolicy(PermissionPolicy):

    def filter(self,
               remotes: collections.abc.Mapping,
               identity: Identity,
               groups: collections.abc.Set) -> collections.abc.Mapping:
        return {}

    def permit(self,
               remote: Remote,
               identity: Identity,
               groups: collections.abc.Set) -> bool:
        return False


def test_list_remotes(fx_app, fx_mock_remote_set,
                      fx_authorized_identity, fx_token_id):
    with fx_app.test_client() as client:
        response = client.get(get_url('list_remotes', token_id=fx_token_id))
        assert response.status_code == 200
        assert response.mimetype == 'application/json'
        assert json.loads(response.data) == {
            alias: remote_dict(remote)
            for alias, remote in fx_mock_remote_set.items()
        }


def test_list_remotes_filtered(fx_app, fx_mock_remote_set,
                               fx_authorized_identity, fx_token_id):
    default = fx_app.config['PERMISSION_POLICY']
    try:
        fx_app.config['PERMISSION_POLICY'] = DisallowAllPolicy()
        with fx_app.test_client() as client:
            response = client.get(
                get_url('list_remotes', token_id=fx_token_id)
            )
            assert response.status_code == 200
            assert response.mimetype == 'application/json'
            assert json.loads(response.data) == {}
    finally:
        fx_app.config['PERMISSION_POLICY'] = default


@yield_fixture
def fx_authorized_remote_set(fx_authorized_servers):
    remote_set = {
        'port-' + str(port): Remote('user', '127.0.0.1', port)
        for port in fx_authorized_servers
    }
    app.config['REMOTE_SET'] = remote_set
    yield remote_set
    del app.config['REMOTE_SET']


def test_authorize_remote(fx_app, fx_authorized_servers, fx_master_key,
                          fx_authorized_remote_set, fx_authorized_identity,
                          fx_token_id, fx_key_store):
    public_key = RSAKey.generate(1024)
    fx_key_store.register(fx_authorized_identity, public_key)
    alias, remote = dict(fx_authorized_remote_set).popitem()
    with fx_app.test_client() as client:
        response = client.post(
            get_url('authorize_remote', token_id=fx_token_id, alias=alias)
        )
        assert response.status_code == 200
        assert response.mimetype == 'application/json'
        result = json.loads(response.data)
        assert result['success'] == 'authorized'
        assert result['remote'] == remote_dict(remote)
        expires_at = parse_date(result['expires_at'])
    thread, path, ev = fx_authorized_servers[remote.port]
    authorized_keys_path = path.join('.ssh', 'authorized_keys')
    with authorized_keys_path.open() as f:
        saved_keys = map(parse_openssh_pubkey, f)
        assert frozenset(saved_keys) == {fx_master_key, public_key}
    while datetime.datetime.now(datetime.timezone.utc) <= expires_at:
        time.sleep(1)
    time.sleep(1)
    with authorized_keys_path.open() as f:
        saved_keys = map(parse_openssh_pubkey, f)
        assert frozenset(saved_keys) == {fx_master_key}


def test_authorize_remote_404(fx_app, fx_mock_remote_set,
                              fx_authorized_identity, fx_token_id):
    with fx_app.test_client() as client:
        response = client.post(
            get_url('authorize_remote', token_id=fx_token_id, alias='notexist')
        )
        assert response.status_code == 404
        assert response.mimetype == 'application/json'
        result = json.loads(response.data)
        assert result['error'] == 'not-found'


def test_authorize_remote_403(fx_app, fx_mock_remote_set,
                              fx_authorized_identity, fx_token_id):
    default = fx_app.config['PERMISSION_POLICY']
    try:
        fx_app.config['PERMISSION_POLICY'] = DisallowAllPolicy()
        with fx_app.test_client() as client:
            response = client.post(
                get_url('authorize_remote',
                        token_id=fx_token_id,
                        alias='web-1')
            )
            assert response.status_code == 403
            assert response.mimetype == 'application/json'
            result = json.loads(response.data)
            assert result['error'] == 'forbidden'
    finally:
        fx_app.config['PERMISSION_POLICY'] = default

########NEW FILE########
__FILENAME__ = sftpd
import os.path
try:
    import selectors
except ImportError:
    from asyncio import selectors
import socket
import threading
import time

from paramiko.common import AUTH_FAILED, AUTH_SUCCESSFUL, OPEN_SUCCEEDED
from paramiko.rsakey import RSAKey
from paramiko.server import ServerInterface
from paramiko.sftp_server import SFTPServer
from paramiko.transport import Transport
from sftpserver.stub_sftp import StubSFTPServer

from geofront.keystore import parse_openssh_pubkey


class StubServer(ServerInterface):

    def __init__(self, path):
        self.path = path

    @property
    def authorized_keys(self):
        list_file = os.path.join(self.path, '.ssh', 'authorized_keys')
        with open(list_file) as f:
            for line in f.readlines():
                yield parse_openssh_pubkey(line.strip())

    def get_allowed_auths(self, username):
        return 'publickey'

    def check_auth_password(self, username, password):
        return AUTH_FAILED

    def check_auth_publickey(self, username, key):
        for authorized_key in self.authorized_keys:
            if authorized_key == key:
                return AUTH_SUCCESSFUL
        return AUTH_FAILED

    def check_channel_request(self, kind, chanid):
        return OPEN_SUCCEEDED


def start_server(path: str, host: str, port: int, terminated: threading.Event):
    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    server_socket.settimeout(1)
    server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True)
    server_socket.bind((host, port))
    server_socket.listen(1)
    stub_cls = type('StubSFTPServer', (StubSFTPServer,), {'ROOT': path})
    host_key = RSAKey.generate(1024)

    def accept(server_socket, mask):
        conn, addr = server_socket.accept()
        transport = Transport(conn)
        transport.add_server_key(host_key)
        transport.set_subsystem_handler('sftp', SFTPServer, stub_cls)
        server = StubServer(path)
        transport.start_server(server=server)
        while not terminated.is_set():
            channel = transport.accept(1)
            if channel is not None and not terminated.is_set():
                while transport.is_active() and not terminated.is_set():
                    terminated.wait(1)
                break

    sel = selectors.DefaultSelector()
    sel.register(server_socket, selectors.EVENT_READ, accept)
    last_used = time.time()
    while not terminated.is_set() and last_used + 10 > time.time():
        events = sel.select(1)
        for key, mask in events:
            key.data(key.fileobj, mask)
            last_used = time.time()

########NEW FILE########
__FILENAME__ = util_test
import numbers

from pytest import raises

from geofront.util import typed


@typed
def add(a: int, b: int):
    return a + b


def test_typed():
    with raises(TypeError):
        add('strings are not ', 'accepted')
    with raises(TypeError):
        add('string', 2)
    with raises(TypeError):
        add(1, 'string')
    assert add(1, 2) == 3


@typed
def typed_function(a, b: numbers.Real):
    return a, b


def test_typed_subtype():
    with raises(TypeError):
        typed_function(None, 'string')
    assert typed_function(None, 123) == (None, 123)
    assert typed_function(None, 123.56) == (None, 123.56)


@typed
def typed_with_default(a: int, b: int=None):
    return a, b


def test_typed_with_default():
    with raises(TypeError):
        typed_with_default(None)
    with raises(TypeError):
        typed_with_default(None, None)
    assert typed_with_default(1, None) == (1, None)
    assert typed_with_default(1) == (1, None)

########NEW FILE########
