__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Korean documentation build configuration file, created by
# sphinx-quickstart on Sun Jun  3 00:27:44 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('_themes'))
sys.path.insert(0, os.path.abspath('..'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.doctest', 'sphinx.ext.autodoc']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'Korean'
copyright = u'2012-2013, Heungsub Lee'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
from korean import __version__ as version
# The full version, including alpha/beta/rc tags.
release = version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
language = None
locale_dirs = ['translated']

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
#pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'korean'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
html_theme_options = {'github_fork': 'sublee/korean',
                      'google_analytics': 'UA-28655602-1'}

# Add any paths that contain custom themes here, relative to this directory.
html_theme_path = ['_themes']

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'Koreandoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'Korean.tex', u'Korean Documentation',
   u'Heungsub Lee', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'korean', u'Korean Documentation',
     [u'Heungsub Lee'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'Korean', u'Korean Documentation',
   u'Heungsub Lee', 'Korean', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

########NEW FILE########
__FILENAME__ = korean
# -*- coding: utf-8 -*-
"""
    korean.ext.django.templatetags.korean
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    A module containing Django template tag and filter for korean.

    .. versionadded:: 0.1.7

    .. _Django: https://www.djangoproject.com/

    :copyright: (c) 2012-2013 by Heungsub Lee, Hyunwoo Park
    :license: BSD, see LICENSE for more details.
"""
from __future__ import absolute_import, unicode_literals

from django import template
from django.template.defaultfilters import stringfilter

from .... import l10n


register = template.Library()


class ProofReadNode(template.Node):

    def __init__(self, nodelist):
        self.nodelist = nodelist

    def render(self, context):
        output = self.nodelist.render(context)
        return l10n.proofread(output)


@register.tag(name='proofread')
def do_proofread(parser, token):
    """A Django tag for ``proofread``

    .. sourcecode:: django

       <h1>proofread tag Usage</h1>

       {% load korean %}
       {% proofread %}
         {{ name }}은(는) {{ obj }}을(를) 획득했다.
       {% endproofread %}
    """
    nodelist = parser.parse(['endproofread'])
    parser.delete_first_token()
    return ProofReadNode(nodelist)


@register.filter
@stringfilter
def proofread(value):
    """A Django filter for ``proofread``

    .. sourcecode:: django

       <h1>proofread filter Usage</h1>

       {% load korean %}
       {{ 용사은(는) 검을(를) 획득했다.|proofread }}
    """
    return l10n.proofread(value)

########NEW FILE########
__FILENAME__ = gettext
# -*- coding: utf-8 -*-
"""
    korean.ext.gettext
    ~~~~~~~~~~~~~~~~~~

    `Gettext <http://www.gnu.org/software/gettext>`_ is an internationalization
    and localization system commonly used for writing multilingual programs on
    Unix-like OS. This module contains utilities to integrate Korean and the
    Gettext system. It also works well with Babel_.

    .. _Babel: http://babel.edgewall.org/

    :copyright: (c) 2012-2013 by Heungsub Lee
    :license: BSD, see LICENSE for more details.
"""
from __future__ import absolute_import, unicode_literals
from functools import partial

from ..l10n import Template


def patch_gettext(translations):
    """Patches Gettext translations object to wrap the result with
    :class:`korean.l10n.Template`. Then the result can work with a particle
    format spec.

    For example, here's a Gettext catalog for ko_KR:

    .. sourcecode:: pot

        msgid "{0} appears."
        msgstr "{0:이} 나타났다."

        msgid "John"
        msgstr "존"

        msgid "Christina"
        msgstr "크리스티나"

    You can use a particle format spec in Gettext messages after translations
    object is patched:

    .. sourcecode:: pycon

        >>> translations = patch_gettext(translations)
        >>> _ = translations.ugettext
        >>> _('{0} appears.').format(_('John'))
        '존이 나타났다.'
        >>> _('{0} appears.').format(_('Christina'))
        '크리스티나가 나타났다.'

    :param translations: the Gettext translations object to be patched that
                         would refer the catalog for ko_KR.
    """
    methods_to_patch = ['gettext', 'ngettext']
    if hasattr(translations, 'ugettext'):
        methods_to_patch = ['u' + meth for meth in methods_to_patch]
    for meth in methods_to_patch:
        def patched(orig, *args, **kwargs):
            return Template(orig(*args, **kwargs))
        patched.__name__ = str(meth)
        orig = getattr(translations, meth)
        setattr(translations, meth, partial(patched, orig))
    return translations

########NEW FILE########
__FILENAME__ = jinja2
# -*- coding: utf-8 -*-
"""
    korean.ext.jinja2
    ~~~~~~~~~~~~~~~~~

    Jinja2_ is one of the most used template engines for Python. This module
    contains Jinja2 template engine extensions to make :mod:`korean` easy to
    use.

    .. versionadded:: 0.1.5

    .. versionchanged:: 0.1.6
       Moved from :mod:`korean.l10n.jinja2ext` to :mod:`korean.ext.jinja2`.

    .. _Jinja2: http://jinja.pocoo.org/docs

    :copyright: (c) 2012-2013 by Heungsub Lee
    :license: BSD, see LICENSE for more details.
"""
from __future__ import absolute_import, unicode_literals

from jinja2 import nodes
from jinja2.ext import Extension
from jinja2.utils import Markup

from .. import l10n


class ProofreadingExtension(Extension):
    """A Jinja2 extention which registers the ``proofread`` filter and the
    ``proofread`` block:

    .. sourcecode:: jinja

       <h1>ProofreadingExtension Usage</h1>

       <h2>Single filter</h2>
       {{ (name ~ '은(는) ' ~ obj ~ '을(를) 획득했다.')|proofread }}

       <h2>Filter chaining</h2>
       {{ '%s은(는) %s을(를) 획득했다.'|format(name, obj)|proofread }}

       <h2><code>proofread</code> block</h2>
       {% proofread %}
         {{ name }}은(는) {{ obj }}을(를) 획득했다.
       {% endproofread %}

       <h2>Conditional <code>proofread</code> block</h2>
       {% proofread locale.startswith('ko') %}
         {{ name }}은(는) {{ obj }}을(를) 획득했다.
       {% endproofread %}

    The import name is ``korean.ext.jinja2.proofread``. Just add it into
    your Jinja2 environment by the following code::

       from jinja2 import Environment
       jinja_env = Environment(extensions=['korean.ext.jinja2.proofread'])

    .. versionadded:: 0.1.5

    .. versionchanged:: 0.1.6
       Added ``enabled`` argument to ``{% proofread %}``.
    """

    tags = ['proofread', 'autoproofread']

    def __init__(self, environment):
        environment.filters['proofread'] = l10n.proofread

    def _proofread(self, enabled, caller):
        return l10n.proofread(caller()) if enabled else caller()

    def parse(self, parser):
        tag = parser.stream.current.value
        lineno = next(parser.stream).lineno
        if parser.stream.current.type == 'block_end':
            args = [nodes.Const(True)]
        else:
            args = [parser.parse_expression()]
        body = parser.parse_statements(['name:end%s' % tag], drop_needle=True)
        call = self.call_method('_proofread', args)
        return nodes.CallBlock(call, [], [], body, lineno=lineno)


# nicer import name
proofread = ProofreadingExtension

########NEW FILE########
__FILENAME__ = hangul
# -*- coding: utf-8 -*-
"""
    korean.hangul
    ~~~~~~~~~~~~~

    Processing a string written by Hangul. All code of here is based on
    `hangul.py
    <https://raw.github.com/sublee/hangulize/master/hangulize/hangul.py>`_ by
    `Hye-Shik Chang <http://openlook.org/>`_ at 2003.

    :copyright: (c) 2012-2013 by Heungsub Lee and 2003 by Hye-Shik Chang
    :license: BSD, see LICENSE for more details.
"""
from __future__ import unicode_literals


__all__ = ['char_offset', 'is_hangul', 'is_vowel', 'is_consonant',
           'is_initial', 'is_final', 'get_initial', 'get_vowel', 'get_final',
           'split_char', 'join_char']


def S(*sequences):
    def to_tuple(sequence):
        if not sequence:
            return (sequence,)
        return tuple(sequence)
    return sum(map(to_tuple, sequences), ())
VOWELS = S('ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ')
CONSONANTS = S('ㄱㄲㄳㄴㄵㄶㄷㄸㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅃㅄㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ')
INITIALS = S('ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎ')
FINALS = S('', 'ㄱㄲㄳㄴㄵㄶㄷㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅄㅅㅆㅇㅈㅊㅋㅌㅍㅎ')
LETTER_ELEMENTS = (INITIALS, VOWELS, FINALS)
HANGUL_RANGE = xrange(ord('가'), ord('힣') + 1)
FIRST_HANGUL = HANGUL_RANGE[0]
del S


def char_offset(char):
    """Returns Hangul character offset from "가"."""
    if isinstance(char, int):
        offset = char
    else:
        assert len(char) == 1
        assert is_hangul(char)
        offset = ord(char) - FIRST_HANGUL
    assert offset < len(HANGUL_RANGE)
    return offset


def is_hangul(char):
    """Checks if the given character is written in Hangul."""
    return ord(char) in HANGUL_RANGE


def is_vowel(char):
    """Checks if the given character is a vowel of Hangul."""
    return char in VOWELS


def is_consonant(char):
    """Checks if the given character is a consonant of Hangul."""
    return char in CONSONANTS


def is_initial(char):
    """Checks if the given character is an initial consonant of Hangul."""
    return char in INITIALS


def is_final(char):
    """Checks if the given character is a final consonant of Hangul. The final
    consonants contain what a joined multiple consonant and empty character.
    """
    return char in FINALS


def get_initial(char):
    """Returns an initial consonant from the given character."""
    if is_initial(char):
        return char
    return INITIALS[int(char_offset(char) / (len(VOWELS) * len(FINALS)))]


def get_vowel(char):
    """Returns a vowel from the given character."""
    if is_vowel(char):
        return char
    return VOWELS[int(char_offset(char) / len(FINALS)) % len(VOWELS)]


def get_final(char):
    """Returns a final consonant from the given character."""
    if is_final(char):
        return char
    return FINALS[char_offset(char) % len(FINALS)]


def split_char(char):
    """Splits the given character to a tuple where the first item is the
    initial consonant and the second the vowel and the third the final.
    """
    code = char_offset(char)
    return (get_initial(code), get_vowel(code), get_final(code))


def join_char(splitted):
    """Joins a tuple in the form ``(initial, vowel, final)`` to a Hangul
    character.
    """
    assert len(splitted) == len(LETTER_ELEMENTS)
    if not (splitted[0] and splitted[1]):
        return splitted[0] or splitted[1]
    indexes = [tuple.index(*args) for args in zip(LETTER_ELEMENTS, splitted)]
    offset = (indexes[0] * len(VOWELS) + indexes[1]) * len(FINALS) + indexes[2]
    return unichr(FIRST_HANGUL + offset)

########NEW FILE########
__FILENAME__ = jinja2ext
# -*- coding: utf-8 -*-
"""
    korean.l10n.jinja2ext
    ~~~~~~~~~~~~~~~~~~~~~

    This module has been moved to :mod:`korean.ext.jinja2`.

    .. versionadded:: 0.1.5

    .. versionchanged:: 0.1.6
       Moved to :mod:`korean.ext.jinja2`.

    :copyright: (c) 2012-2013 by Heungsub Lee
    :license: BSD, see LICENSE for more details.
"""
from __future__ import absolute_import, unicode_literals
import warnings

from ..ext.jinja2 import ProofreadingExtension, proofread


warnings.warn('This module has been moved to %r' % proofread.__module__,
              DeprecationWarning)

########NEW FILE########
__FILENAME__ = morpheme
# -*- coding: utf-8 -*-
"""
    korean.morphology.morpheme
    ~~~~~~~~~~~~~~~~~~~~~~~~~~

    :copyright: (c) 2012-2013 by Heungsub Lee
    :license: BSD, see LICENSE for more details.
"""
from __future__ import absolute_import, unicode_literals
import sys

from ..hangul import get_final, is_hangul


__all__ = ['Morpheme']


class MorphemeMetaclass(type):

    def __new__(meta, name, bases, attrs):
        from . import Morphology
        cls = type.__new__(meta, name, bases, attrs)
        cls._registry = {}
        Morphology._register_morpheme(cls)
        return cls

    def __call__(cls, *forms):
        if len(forms) == 1:
            try:
                return cls.get(forms[0])
            except KeyError:
                pass
        return super(MorphemeMetaclass, cls).__call__(*forms)


class Morpheme(object):
    """This class presents a morpheme (형태소) or allomorph (이형태). It
    can have one or more forms. The first form means the basic allomorph
    (기본형).

    :param forms: each forms of allomorph. the first form will be basic
                  allomorph.
    """

    __metaclass__ = MorphemeMetaclass

    _registry = None

    def __init__(self, *forms):
        assert all([isinstance(form, unicode) for form in forms])
        self.forms = forms

    @classmethod
    def get(cls, key):
        """Returns a pre-defined morpheme object by the given key."""
        return cls._registry[key]

    @classmethod
    def register(cls, key, obj):
        """Registers a pre-defined morpheme object to the given key."""
        cls._registry[key] = obj

    def read(self):
        """Every morpheme class would implement this method. They should make a
        morpheme to the valid Korean text with Hangul.
        """
        return unicode(self)

    def basic(self):
        """The basic form of allomorph."""
        return self.forms[0]

    def __unicode__(self):
        return self.basic()

    def __str__(self):
        return unicode(self).encode('utf-8')

    if sys.version_info >= (3,):
        __str__ = __unicode__
        del __unicode__

    def __getitem__(self, i):
        return unicode(self)[i]

    def __getslice__(self, start, stop, step=None):
        return unicode(self)[start:stop:step]

    def __format__(self, suffix):
        return '{0!s}{1}'.format(self, suffix)

    def __repr__(self):
        return '{0}({1!s})'.format(type(self).__name__, unicode(self))

########NEW FILE########
__FILENAME__ = particle
# -*- coding: utf-8 -*-
"""
    korean.morphology.particle
    ~~~~~~~~~~~~~~~~~~~~~~~~~~

    :copyright: (c) 2012-2013 by Heungsub Lee
    :license: BSD, see LICENSE for more details.
"""
from __future__ import absolute_import, unicode_literals

from . import define_allomorph_picker
from .morpheme import Morpheme
from .substantive import Noun, NumberWord, Loanword
from .. import hangul


__all__ = ['Particle']


class Particle(Morpheme):
    """Particle (조사) is a postposition in Korean. Some particles have
    different allomorphs such as 을/를, 이/가. These forms follow forward
    syllable ends what phoneme; a vowel, a consonant, or a Rieul (ㄹ).
    """

    def __init__(self, after_vowel, after_consonant=None, after_rieul=None):
        if after_rieul:
            forms = (after_vowel, after_consonant, after_rieul)
        elif after_consonant:
            forms = (after_vowel, after_consonant)
        else:
            forms = (after_vowel,)
        super(Particle, self).__init__(*forms)

    @classmethod
    def get(cls, key):
        try:
            return super(Particle, cls).get(key)
        except KeyError:
            return cls.guess(key)

    @classmethod
    def guess(cls, key):
        length_of_first = lambda x: len(x[0])
        for other_key, particle in sorted(cls._registry.items(),
                                          key=length_of_first):
            if key.startswith(other_key):
                suffix = key[len(other_key):]
                return cls(*(form + suffix for form in particle.forms))
        raise KeyError('There is no guessable particle')

    @property
    def after_vowel(self):
        return self.basic()

    @property
    def after_consonant(self):
        try:
            return self.forms[1]
        except IndexError:
            return self.basic()

    @property
    def after_rieul(self):
        try:
            return self.forms[2]
        except IndexError:
            return self.basic()

    def naive(self):
        rv = []
        seen = set()
        unique_forms = [form for form in self.forms
                        if form not in seen and seen.add(form) is None]
        for forms in zip(unique_forms[:-1], unique_forms[1:]):
            length = map(len, forms)
            if len(set(length)) == 1:
                # such as "를(을)", "을(를)", "(를)을", "(을)를"
                rv.append('{0}({1})'.format(*forms))
                rv.append('{1}({0})'.format(*forms))
                rv.append('({0}){1}'.format(*forms))
                rv.append('({1}){0}'.format(*forms))
            else:
                # such as "(으)로"
                x = int(length[0] > length[1])
                args = forms[1 - x].rstrip(forms[x]), forms[x]
                rv.append('({0}){1}'.format(*args))
        return tuple(rv)

    def pick_allomorph_after_char(self, char):
        final = hangul.get_final(char)
        if not final:
            return self.after_vowel
        elif final == 'ㄹ':
            return self.after_rieul
        else:
            return self.after_consonant

    @define_allomorph_picker(suffix_of=Noun)
    @define_allomorph_picker(suffix_of=NumberWord)
    @define_allomorph_picker(suffix_of=Loanword)
    def pick_allomorph_after_substantive(self, substantive):
        return self.pick_allomorph_after_char(substantive.read()[-1])

########NEW FILE########
__FILENAME__ = substantive
# -*- coding: utf-8 -*-
"""
    korean.morphology.substantive
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

    :copyright: (c) 2012-2013 by Heungsub Lee
    :license: BSD, see LICENSE for more details.
"""
from __future__ import absolute_import, unicode_literals
import re

from .morpheme import Morpheme
from ..hangul import is_hangul


__all__ = ['Substantive', 'Noun', 'NumberWord', 'Loanword']


class Substantive(Morpheme):
    """A class for Korean substantive that is called "체언" in Korean."""

    def __format__(self, spec):
        """:class:`Substantive`'s custom formatter appends the correct particle
        after the substantive string using particle format spec such as
        ``{0:은}`` or ``{1:로}``:

            >>> format(Noun('엄마'), '을')
            '엄마를'
            >>> '{0:은} {1:로}'.format(Noun('아들'), Noun('마을'))
            '아들은 마을로'
            >>> '{0:은} {1:로}'.format(Noun('아들'), Noun('산'))
            '아들은 산으로'
        """
        from .particle import Particle
        from . import merge
        separated_spec = spec.split(':')
        if separated_spec[0] and is_hangul(separated_spec[0][0]):
            text = merge(self, Particle(separated_spec.pop(0)))
        else:
            text = unicode(self)
        try:
            spec = separated_spec[0]
        except IndexError:
            spec = ''
        return format(text, spec)


class Noun(Substantive):
    """A class for Korean noun that is called "명사" in Korean."""

    READING_PATTERN = re.compile(r'(?P<other>[^0-9]+)?(?P<number>[0-9]+)?')

    def read(self):
        """Reads a noun as Korean. The result will be Hangul.

            >>> Noun('레벨42').read()
            '레벨사십이'
        """
        rv = []
        for match in self.READING_PATTERN.finditer(unicode(self)):
            if match.group('other'):
                rv.append(match.group('other'))
            if match.group('number'):
                rv.append(NumberWord(int(match.group('number'))).read())
        return ''.join(rv)


class NumberWord(Substantive):
    """A class for Korean number word that is called "수사" in Korean."""

    __numbers__ = {}
    __digits__ = {}
    __unary_operations__ = {}

    def __init__(self, number):
        self.number = number

    def read(self):
        """Reads number as Korean.

            >>> NumberWord(1234567890).read()
            '십이억삼천사백오십육만칠천팔백구십'
            >>> NumberWord.read(0)
            '영'
        """
        return ''.join(type(self).read_phases(self.number))

    @classmethod
    def read_phases(cls, number):
        """Reads number as Korean but seperates the result at each 10k.

            >>> NumberWord.read_phases(1234567890)
            ('십이억', '삼천사백오십육만', '칠천팔백구십')
            >>> NumberWord.read_phases(0)
            ('영',)
        """
        rv, phase = [], []
        digit = 0
        negative = number < 0
        number = abs(number)
        while True:
            single = number % 10
            if digit >= 4:
                try:
                    phase.append(cls.__digits__[digit])
                except KeyError:
                    pass
            if single:
                try:
                    phase.append(cls.__digits__[digit % 4])
                except KeyError:
                    pass
            number //= 10
            if (single or number) and (single != 1 or digit) and (single <= 1):
                pass
            else:
                phase.append(cls.__numbers__[single])
            if not number or digit % 4 == 3:
                if digit < 4 or len(phase) > 1:
                    rv.append(''.join(phase[::-1]))
                else:
                    rv.append('')
                phase = []
                if not number:
                    break
            digit += 1
        if negative:
            rv.append(cls.__unary_operations__['-'])
        return tuple(rv[::-1])

    def basic(self):
        return unicode(self.number)

    def __format__(self, spec):
        if ':' in spec:
            number_spec, spec = spec.split(':', 1)
            formatted_number = format(self.number, number_spec)
        else:
            formatted_number = None
        try:
            rv = super(NumberWord, self).__format__(spec)
        except ValueError:
            return format(self.number, spec)
        if formatted_number is not None:
            rv = formatted_number + rv[len(str(self.number)):]
        return rv


class Loanword(Substantive):
    """A class for loanword that is called "외래어" in Korean. This depends
    on `Hangulize <http://packages.python.org/hangulize>`_ which automatically
    transcribes a non-Korean word into Hangul.

    .. versionadded:: 0.1.4
    """

    def _import_hangulize(self):
        try:
            return self._hangulize
        except AttributeError:
            pass
        try:
            import hangulize
        except ImportError:
            raise ImportError('%s needs hangulize>=0.0.5' %
                              type(self).__name__)
        self._hangulize = hangulize
        return hangulize

    def __init__(self, word, code=None, iso639=None, lang=None):
        hangulize = self._import_hangulize()
        self.lang = lang or hangulize.get_lang(code, iso639)
        super(Loanword, self).__init__(word)

    def read(self):
        """Transcribes into Hangul using `Hangulize
        <http://packages.python.org/hangulize>`_.

        >>> Loanword('Guido van Rossum', 'nld').read()
        '히도 판로쉼'
        >>> Loanword('საქართველო', 'kat').read()
        '사카르트벨로'
        >>> Loanword('Leonardo da Vinci', 'ita').read()
        '레오나르도 다 빈치'
        """
        hangulize = self._import_hangulize()
        return hangulize.hangulize(self.basic(), lang=self.lang)

########NEW FILE########
__FILENAME__ = __main__
# -*- coding: utf-8 -*-
"""
    korean.__main__
    ~~~~~~~~~~~~~~~

    Command-line tools.

    :copyright: (c) 2012-2013 by Heungsub Lee
    :license: BSD, see LICENSE for more details.
"""
from __future__ import absolute_import
import contextlib
import sys

from baker import Baker

from . import l10n


baker = Baker()


@contextlib.contextmanager
def file_or_stdin(path):
    f = open(path) if path is not None else sys.stdin
    yield f
    f.close()


@baker.command
def proofread(path=None, charset='utf-8'):
    with file_or_stdin(path) as f:
        for line in f.xreadlines():
            print l10n.proofread(line.decode(charset)),


@baker.command
def validate(path=None, charset='utf-8'):
    pass


if __name__ == '__main__':
    baker.run()

########NEW FILE########
__FILENAME__ = koreantests
# -*- coding: utf-8 -*-
from __future__ import unicode_literals, with_statement
import contextlib
import sys
import textwrap

from pytest import deprecated_call, raises

from korean import *


@contextlib.contextmanager
def disable_imports(*names):
    """Stolen from Attest."""
    import __builtin__
    import_ = __builtin__.__import__
    def __import__(name, *args, **kwargs):
        if name in names:
            raise ImportError('%r is disabled' % name)
        return import_(name, *args, **kwargs)
    __builtin__.__import__ = __import__
    try:
        yield
    finally:
        __builtin__.__import__ = import_


class TestParticle(object):

    def test_allomorph(self):
        # case clitics
        assert Particle('가') is Particle('이')
        assert Particle('를') is Particle('을')
        assert Particle('로') is Particle('으로')
        assert Particle('와') is Particle('과')
        assert Particle('랑') is Particle('이랑')
        # informational litics
        assert Particle('는') is Particle('은')
        assert Particle('나') is Particle('이나')

    def test_naive(self):
        assert Particle('을').naive() == \
               ('를(을)', '을(를)', '(를)을', '(을)를')
        assert Particle('로').naive() == ('(으)로',)

    def test_pick_allomorph_with_noun(self):
        pick_allomorph = morphology.pick_allomorph
        P, N = Particle, Noun
        assert pick_allomorph(P('가'), suffix_of=N('받침')) == '이'
        assert pick_allomorph(P('가'), suffix_of=N('나비')) == '가'
        assert pick_allomorph(P('로'), suffix_of=N('마을')) == '로'
        assert pick_allomorph(P('로'), suffix_of=N('파이썬')) == '으로'
        assert pick_allomorph(P('다'), suffix_of=N('파이썬')) == '이다'
        assert pick_allomorph(P('일랑'), suffix_of=N('게임')) == '일랑'
        assert pick_allomorph(P('일랑'), suffix_of=N('서버')) == 'ㄹ랑'
        assert pick_allomorph(P('란'), suffix_of=N('자바')) == '란'
        assert pick_allomorph(P('란'), suffix_of=N('파이썬')) == '이란'

    def test_pick_allomorph_with_number_word(self):
        pick_allomorph = morphology.pick_allomorph
        P, Nw = Particle, NumberWord
        assert pick_allomorph(P('가'), suffix_of=Nw(1)) == '이'
        assert pick_allomorph(P('가'), suffix_of=Nw(2)) == '가'
        assert pick_allomorph(P('일랑'), suffix_of=Nw(3)) == '일랑'
        #assert pick_allomorph(P('일랑'), suffix_of=Nw(4)) == '일랑'

    def test_pick_allomorph_with_loanword(self):
        pick_allomorph = morphology.pick_allomorph
        P, Lw = Particle, Loanword
        assert pick_allomorph(P('가'), suffix_of=Lw('Emil', 'ron')) == '이'

    def test_merge_with_noun(self):
        merge = morphology.merge
        P, N = Particle, Noun
        assert merge(N('게임'), P('일랑')) == '게임일랑'
        assert merge(N('서버'), P('일랑')) == '서벌랑'


class TestNoun(object):

    def test_read(self):
        assert Noun('주인공').read() == '주인공'
        assert Noun('컴퓨터').read() == '컴퓨터'
        assert Noun('한국어').read() == '한국어'

    def test_read_with_number(self):
        assert Noun('레벨 4').read() == '레벨 사'
        assert Noun('레벨 50').read() == '레벨 오십'
        assert Noun('64렙').read() == '육십사렙'

    def test_null_format(self):
        assert '{0}'.format(Noun('소년')) == '소년'

    def test_unicode_format(self):
        assert '{0:6}'.format(Noun('소년')) == '소년    '
        assert '{0:^6}'.format(Noun('소녀')) == '  소녀  '
        assert '{0:>6}'.format(Noun('한국어')) == '   한국어'

    def test_particle_format(self):
        assert '{0:는}'.format(Noun('소년')) == '소년은'
        assert '{0:는}'.format(Noun('소녀')) == '소녀는'
        assert '{0:을}'.format(Noun('한국어')) == '한국어를'
        assert '{0:이}'.format(Noun('레벨 2')) == '레벨 2가'

    def test_undefined_particle_format(self):
        assert '{0:에게}'.format(Noun('소년')) == '소년에게'

    def test_guessable_particle_format(self):
        assert '{0:로서}'.format(Noun('학생')) == '학생으로서'
        assert '{0:로써}'.format(Noun('컴퓨터')) == '컴퓨터로써'
        assert '{0:로써}'.format(Noun('칼')) == '칼로써'
        assert '{0:로써}'.format(Noun('음식')) == '음식으로써'
        assert '{0:랑은}'.format(Noun('녀석')) == '녀석이랑은'

    def test_combination_format(self):
        with raises(ValueError):
            '{0:을:를}'.format(Noun('한국어'))
        assert '{0:는:5}'.format(Noun('소년')) == '소년은  '
        assert '{0:는:^5}'.format(Noun('소녀')) == ' 소녀는 '
        assert '{0:을:>5}'.format(Noun('한국어')) == ' 한국어를'


class TestNumberWord(object):

    def test_read(self):
        assert NumberWord(5).read() == '오'
        assert NumberWord(32).read() == '삼십이'
        assert NumberWord(42).read() == '사십이'
        assert NumberWord(152400).read() == '십오만이천사백'
        assert NumberWord(600000109).read() == '육억백구'
        assert NumberWord(72009852).read() == '칠천이백만구천팔백오십이'
        assert NumberWord(-8).read() == '마이너스팔'

    def test_read_phases(self):
        assert NumberWord.read_phases(32) == ('삼십이',)
        assert NumberWord.read_phases(42) == ('사십이',)
        assert NumberWord.read_phases(152400) == ('십오만', '이천사백')
        assert NumberWord.read_phases(600000109) == ('육억', '', '백구')
        assert NumberWord.read_phases(-8) == ('마이너스', '팔')

    def test_null_format(self):
        assert '{0}'.format(NumberWord(12)) == '12'

    def test_number_format(self):
        assert '{0:.1f}'.format(NumberWord(4)) == '4.0'
        assert '{0:4d}'.format(NumberWord(4)) == '   4'

    def test_particle_format(self):
        assert '레벨 {0:이}'.format(NumberWord(4)) == '레벨 4가'
        assert '레벨 {0:이}'.format(NumberWord(3)) == '레벨 3이'
        assert '레벨 {0:이}'.format(NumberWord(15)) == '레벨 15가'

    def test_combination_format(self):
        with raises(ValueError):
            '{0:을:를}'.format(NumberWord(19891212))
        if sys.version_info > (2, 7):
            # Python 2.6 doesn't support PEP 378
            assert '{0:,:을}'.format(NumberWord(19891212)) == '19,891,212를'


class TestLoanword(object):

    def test_need_hangulize(self):
        with disable_imports('hangulize'):
            with raises(ImportError):
                Loanword('štěstí', 'ces')

    def test_read(self):
        assert Loanword('italia', 'ita').read() == '이탈리아'
        assert Loanword('gloria', 'ita').read() == '글로리아'
        assert Loanword('Αλεξάνδρεια', 'ell').read() == '알렉산드리아'

    def test_null_format(self):
        assert '{0}'.format(Loanword('Вадзім Махнеў', 'bel')) == \
               'Вадзім Махнеў'

    def test_particle_format(self):
        assert '{0:으로} 여행 가자'.format(Loanword('Italia', 'ita')) == \
               'Italia로 여행 가자'
        van_gogh = Loanword('Vincent Willem van Gogh', 'nld')
        assert '이 작품은 {0:이} 그렸다.'.format(van_gogh) == \
               '이 작품은 Vincent Willem van Gogh가 그렸다.'


class TestLocalization(object):

    def test_template(self):
        assert l10n.Template('{0:로}').format(123) == '123으로'
        if sys.version_info < (3,):
            assert l10n.Template('{0:로}').format(long(123)) == '123으로'

    def test_proofreading(self):
        assert l10n.proofread('사과은(는) 맛있다.') == '사과는 맛있다.'
        assert l10n.proofread('집(으)로 가자.') == '집으로 가자.'
        assert l10n.proofread('용사은(는) 검을(를) 획득했다.') == \
               '용사는 검을 획득했다.'

    def test_meaningless_proofreading(self):
        assert l10n.proofread('사과다.') == '사과다.'
        assert l10n.proofread('집') == '집'
        assert l10n.proofread('의 식 주') == '의 식 주'
        assert l10n.proofread('the grammatical rules of a language') == \
               'the grammatical rules of a language'

    def test_unworkable_proofreading(self):
        assert l10n.proofread('Korean를(을)') == 'Korean를(을)'
        assert l10n.proofread('Korean을(를)') == 'Korean를(을)'
        assert l10n.proofread('Korean(을)를') == 'Korean를(을)'

    def test_complex_proofreading(self):
        assert l10n.proofread('말을(를)(를)') == '말을(를)'

    def test_proofreading_lyrics(self):
        assert textwrap.dedent(l10n.proofread('''
        나의 영혼 물어다줄 평화시장 비둘기 위(으)로 떨어지는 투명한 소나기
        다음날엔 햇빛 쏟아지길 바라며 참아왔던 고통이(가) 찢겨져 버린 가지
        될 때까지 묵묵히 지켜만 보던 벙어리 몰아치는 회오리 속에 지친 모습이(가)
        말해주는 가슴에 맺힌 응어리 여전히 가슴속에 쏟아지는 빛줄기
        ''')) == textwrap.dedent('''
        나의 영혼 물어다줄 평화시장 비둘기 위로 떨어지는 투명한 소나기
        다음날엔 햇빛 쏟아지길 바라며 참아왔던 고통이 찢겨져 버린 가지
        될 때까지 묵묵히 지켜만 보던 벙어리 몰아치는 회오리 속에 지친 모습이
        말해주는 가슴에 맺힌 응어리 여전히 가슴속에 쏟아지는 빛줄기
        ''')
        assert textwrap.dedent(l10n.proofread('''
        빨간 꽃 노란 꽃 꽃밭 가득 피어도 하얀 나비 꽃나비 담장 위에 날아도
        따스한 봄바람이(가) 불고 또 불어도 미싱은(는) 잘도 도네 돌아가네
        흰 구름 솜구름 탐스러운 애기 구름 짧은 셔츠 짧은치마 뜨거운 여름
        소금 땀 피지 땀 흐르고 또 흘러도 미싱은(는) 잘도 도네 돌아가네
        저 하늘엔 별들이(가) 밤새 빛나고
        찬바람 소슬바람 산너머 부는 바람 간밤에 편지 한 장 적어 실어 보내고
        낙엽은(는) 떨어지고 쌓이고 또 쌓여도 미싱은(는) 잘도 도네 돌아가네
        흰눈이 온 세상에 소복소복 쌓이면 하얀 공장 하얀 불빛 새하얀 얼굴들
        우리네 청춘이(가) 저물고 저물도록 미싱은(는) 잘도 도네 돌아가네
        공장엔 작업등이(가) 밤새 비추고
        빨간 꽃 노란 꽃 꽃밭 가득 피어도 하얀 나비 꽃나비 담장 위에 날아도
        따스한 봄바람이(가) 불고 또 불어도 미싱은(는) 잘도 도네 돌아가네
        ''')) == textwrap.dedent('''
        빨간 꽃 노란 꽃 꽃밭 가득 피어도 하얀 나비 꽃나비 담장 위에 날아도
        따스한 봄바람이 불고 또 불어도 미싱은 잘도 도네 돌아가네
        흰 구름 솜구름 탐스러운 애기 구름 짧은 셔츠 짧은치마 뜨거운 여름
        소금 땀 피지 땀 흐르고 또 흘러도 미싱은 잘도 도네 돌아가네
        저 하늘엔 별들이 밤새 빛나고
        찬바람 소슬바람 산너머 부는 바람 간밤에 편지 한 장 적어 실어 보내고
        낙엽은 떨어지고 쌓이고 또 쌓여도 미싱은 잘도 도네 돌아가네
        흰눈이 온 세상에 소복소복 쌓이면 하얀 공장 하얀 불빛 새하얀 얼굴들
        우리네 청춘이 저물고 저물도록 미싱은 잘도 도네 돌아가네
        공장엔 작업등이 밤새 비추고
        빨간 꽃 노란 꽃 꽃밭 가득 피어도 하얀 나비 꽃나비 담장 위에 날아도
        따스한 봄바람이 불고 또 불어도 미싱은 잘도 도네 돌아가네
        ''')
        assert textwrap.dedent(l10n.proofread('''
        어둠에다크에서 죽음의데스(을)를 느끼며
        서쪽에서 불어오는 바람의윈드을(를) 맞았다.
        그것은(는) 운명의데스티니.
        그(은)는 인생의 라이프를(을) 끝내기 위해 디엔드.
        모든것을(를) 옭아매는 폭풍같은 스톰에서 벗어나기 위해
        결국 자신 스스로(을)를 죽음에데스(으)로 몰아갔다.
        후에 전설의 레전드로써 기억에 메모리- 기적에미라클
        길이길이 가슴속의하트에 기억될 리멤버.
        -끝에 Fin-
        ''')) == textwrap.dedent('''
        어둠에다크에서 죽음의데스를 느끼며
        서쪽에서 불어오는 바람의윈드를 맞았다.
        그것은 운명의데스티니.
        그는 인생의 라이프를 끝내기 위해 디엔드.
        모든것을 옭아매는 폭풍같은 스톰에서 벗어나기 위해
        결국 자신 스스로를 죽음에데스로 몰아갔다.
        후에 전설의 레전드로써 기억에 메모리- 기적에미라클
        길이길이 가슴속의하트에 기억될 리멤버.
        -끝에 Fin-
        ''')

    def test_parse(self):
        assert l10n.proofread.parse('말을(를)(를)') == \
               ('말', Particle('를'), '(를)')
        assert l10n.proofread.parse('용사은(는) 감를(을) 먹었다.') == \
               ('용사', Particle('은'), ' 감', Particle('을'), ' 먹었다.')


class TestExtensions(object):

    def generate_translations(self):
        # from io import BytesIO
        # from babel.messages import Catalog, mofile, pofile
        # from babel.support import Translations
        # catalog = Catalog(locale='ko_KR')
        # po = '''
        # # ugettext
        # msgid "I like a {0}."
        # msgstr "나는 {0:을} 좋아합니다.'
        # # ungettext
        # msgid "Here is a {0}."
        # msgid_plural "Here are {1} {0}."
        # msgstr[0] "여기 {0:이} 있습니다."
        # msgstr[1] "여기 {0:이} {1}개 있습니다."
        # # ugettext
        # msgid "I reached level {0}."
        # msgstr "나는 레벨{0:이} 되었습니다.'
        # '''
        # catalog = pofile.read_po(BytesIO(po.encode('utf-8')))
        # buf = BytesIO()
        # mofile.write_mo(buf, catalog)
        # buf.seek(0)
        # return Translations(buf)
        from io import BytesIO
        import gettext
        # .mo binary generated from the above .po string
        buf = BytesIO(b'\xde\x12\x04\x95\x00\x00\x00\x00\x04\x00\x00\x00\x1c'
                      b'\x00\x00\x00<\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
                      b'\x00\x00\x00\x00\x00\\\x00\x00\x00 \x00\x00\x00]\x00'
                      b'\x00\x00\r\x00\x00\x00~\x00\x00\x00\x14\x00\x00\x00'
                      b'\x8c\x00\x00\x00\\\x01\x00\x00\xa1\x00\x00\x00@\x00'
                      b'\x00\x00\xfe\x01\x00\x00\x1f\x00\x00\x00?\x02\x00\x00%'
                      b'\x00\x00\x00_\x02\x00\x00\x00Here is a {0}.\x00Here '
                      b'are {1} {0}.\x00I like a {0}.\x00I reached level {0}.'
                      b'\x00Project-Id-Version: PROJECT VERSION\nReport-Msgid-'
                      b'Bugs-To: EMAIL@ADDRESS\nPOT-Creation-Date: 2013-01-03 '
                      b'22:35+0900\nPO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n'
                      b'Last-Translator: FULL NAME <EMAIL@ADDRESS>\nLanguage-'
                      b'Team: LANGUAGE <LL@li.org>\nMIME-Version: 1.0\nContent'
                      b'-Type: text/plain; charset=utf-8\nContent-Transfer-'
                      b'Encoding: 8bit\nGenerated-By: Babel 0.9.6\n\x00\xec'
                      b'\x97\xac\xea\xb8\xb0 {0:\xec\x9d\xb4} \xec\x9e\x88\xec'
                      b'\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\x00\xec\x97\xac\xea'
                      b'\xb8\xb0 {0:\xec\x9d\xb4} {1}\xea\xb0\x9c \xec\x9e\x88'
                      b'\xec\x8a\xb5\xeb\x8b\x88\xeb\x8b\xa4.\x00\xeb\x82\x98'
                      b'\xeb\x8a\x94 {0:\xec\x9d\x84} \xec\xa2\x8b\xec\x95\x84'
                      b'\xed\x95\xa9\xeb\x8b\x88\xeb\x8b\xa4.\x00\xeb\x82\x98'
                      b'\xeb\x8a\x94 \xeb\xa0\x88\xeb\xb2\xa8{0:\xec\x9d\xb4} '
                      b'\xeb\x90\x98\xec\x97\x88\xec\x8a\xb5\xeb\x8b\x88\xeb'
                      b'\x8b\xa4.\x00')
        return gettext.GNUTranslations(buf)

    def gettext_functions(self, translations):
        try:
            gettext = translations.ugettext
        except AttributeError:
            # gettext.GNUTranslations on Python 3 hasn't ugettext
            gettext = translations.gettext
            ngettext = translations.ngettext
        else:
            ngettext = translations.ungettext
        return (gettext, ngettext)

    def test_patched_gettext(self):
        from korean.ext.gettext import patch_gettext
        t = patch_gettext(self.generate_translations())
        _, ngettext = self.gettext_functions(t)
        assert isinstance(_(''), l10n.Template)
        assert _('I like a {0}.').format('바나나') == \
               '나는 바나나를 좋아합니다.'
        assert _('I reached level {0}.').format(4) == \
               '나는 레벨4가 되었습니다.'
        assert _('Undefined') == 'Undefined'
        def gen_text(obj, n):
            fmt = ngettext('Here is a {0}.', 'Here are {1} {8}.', n)
            return fmt.format(obj, n)
        assert gen_text('콩', 1) == '여기 콩이 있습니다.'
        assert gen_text('사과', 2) == '여기 사과가 2개 있습니다.'

    def test_deprecated_patch_gettext(self):
        t = deprecated_call(l10n.patch_gettext, self.generate_translations())
        _, ngettext = self.gettext_functions(t)
        assert isinstance(_(''), l10n.Template)

    def test_jinja2_ext(self):
        from jinja2 import Environment
        env = Environment(extensions=['korean.ext.jinja2.proofread'])
        context = dict(name='용사', obj='검')
        expectation = '용사는 검을 획득했다.'
        assert 'proofread' in env.filters
        templ1 = env.from_string('''
        {{ (name ~ '은(는) ' ~ obj ~ '을(를) 획득했다.')|proofread }}
        ''')
        assert templ1.render(**context).strip() == expectation
        templ2 = env.from_string('''
        {{ '%s은(는) %s을(를) 획득했다.'|format(name, obj)|proofread }}
        ''')
        assert templ2.render(**context).strip() == expectation
        templ3 = env.from_string('''
        {% proofread %}
          {{ name }}은(는) {{ obj }}을(를) 획득했다.
        {% endproofread %}
        ''')
        assert templ3.render(**context).strip() == expectation
        templ4 = env.from_string('''
        {% proofread true %}
          {{ name }}은(는) {{ obj }}을(를) 획득했다.
        {% endproofread %}
        ''')
        assert templ4.render(**context).strip() == expectation
        templ5 = env.from_string('''
        {% proofread false %}
          {{ name }}은(는) {{ obj }}을(를) 획득했다.
        {% endproofread %}
        ''')
        assert templ5.render(**context).strip() != expectation
        templ6 = env.from_string('''
        {% proofread locale.startswith('ko') %}
          {{ name }}은(는) {{ obj }}을(를) 획득했다.
        {% endproofread %}
        ''')
        assert templ6.render(locale='ko_KR', **context).strip() == expectation
        templ7 = env.from_string('''
        {% autoproofread locale.startswith('ko') %}
          {{ name }}은(는) {{ obj }}을(를) 획득했다.
        {% endautoproofread %}
        ''')
        assert templ7.render(locale='ko_KR', **context).strip() == expectation

    def test_deprecated_jinja2_ext_location(self):
        from jinja2 import Environment
        old_ext_name = 'korean.l10n.jinja2ext.proofread'
        env = deprecated_call(Environment, extensions=[old_ext_name])
        assert 'proofread' in env.filters

    def test_django_ext(self):
        from django.conf import settings
        from django.template import Context, Template
        settings.configure(INSTALLED_APPS=('korean.ext.django',))
        context = Context({'name': '용사', 'obj': '검'})
        expectation = '용사는 검을 획득했다.'
        templ1 = Template('''
        {% load korean %}
        {{ '용사은(는) 검을(를) 획득했다.'|proofread }}
        ''')
        assert templ1.render(Context()).strip() == expectation
        templ2 = Template('''
        {% load korean %}
        {% proofread %}
          {{ name }}은(는) {{ obj }}을(를) 획득했다.
        {% endproofread %}
        ''')
        assert templ2.render(context).strip() == expectation


try:
    __import__('hangulize')
except ImportError:
    del TestParticle.test_pick_allomorph_with_loanword
    del TestLoanword
try:
    __import__('django')
except ImportError:
    del TestExtensions.test_django_ext

########NEW FILE########
