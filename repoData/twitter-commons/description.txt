The checkstyle checks configured for the build use some custom rules built with the target
'src/java/com/twitter/common/checkstyle'.  To develop new checkstyle rules or fix
existing custom rules, the following workflow is reccomended:
1.) Pick a target that has source code you'd like to test your new rule
against - say 'src/java/com/twitter/common/base:base' and temporarily add
pants('src/java/com/twitter/common/checkstyle') to its dependencies list.  This will
place the rule you are fixing or developing early on the checkstyle classpath.
2.) Code your rule and run the test target until the rule works in the way you
want.
3.) send out a review with your rule changes/additions
4.) When you get ship it, submit and push a new checkstyle jar then update
BUILD.tools:checkstyle with the new custom check jar revision and send
another review.


This directory contains scripts to help automate releases to and merges from the Twitter Commons
open source repository hosted on github @ http://github.com/twitter/commons.

I want to:

+ publish new api docs to http://twitter.github.com/commons/apidocs
  use publish-docs.sh in a clone of the github repo


Twitter common libraries for python and the jvm

== Installation ==

Building requires:
+ jdk 1.6+
+ python 2.6+

The build tool is custom and hosted in the repository itself.

== Usage ==

To build all jvm code and run all tests:
$ ./pants goal test tests/{java,scala}/com/twitter/common::

Likewise for python commons:
$ ./pants tests/python/twitter/common/:all

And for the pants build tool itself:
$ ./pants tests/python/twitter/pants:all

To get help on pants:
$ ./pants help

Read more http://twitter.github.com/commons/

TODO(John Sirois): migrate pants documentation to the public wiki

== Usage questions and feature discussions ==

Please check the archives for twitter-commons@googlegroups.com then fire
away if the question has not been addressed.

== Reporting bugs ==

Please use the github issue tracker for twitter commons at:
https://github.com/twitter/commons/issues

== Copyright and License ==

Copyright 2011 Twitter, Inc.

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this work except in compliance with the License.
   You may obtain a copy of the License in the LICENSE file, or at:

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.



This directory contains the canonical ANTLR example files,
copied from http://www.antlr.org/wiki/display/ANTLR3/Example.
We use these to test the python_antlr_library functionality in pants.
Ideally this would live under tests/antlr, but pants currently
doesn't support python_antlr_library targets there.

#Usage

	migrate-history.sh [-b branch] [-s subdir] <path-to-immigrant>

Migrate the repository at <path-to-repo> into this repository at
subdir.  If -s is omitted, it will be the basename of
<path-to-repo>.

You can use -b to get a branch other than master from the immigrant.
This repository's master will always be used.

Run this script from inside your repository, at the root directory.  The
result will be a branch named migrated-\$subdir

If you run this command a second time on the same repo/subdir, you'll
get a second copy of the history on top of the first set.  So don't do
that.  This would be relatively straightforward to fix, but I haven't
gotten to it yet.  Make the changes in the new repo instead.

#Motivation

A monorepo is one of the popular ways to manage complexity at scale.
The problem with large software projects is that the dependency graph
becomes very complicated.  When these dependencies cross repository
boundaries, it can require multiple commits to update a version.  This
breaks the atomicity of commits (and is a hassle).  The solution is to
store the entire dependency graph (except maybe leaves) in a single
repository: the monorepo.

To explain this, we'll have two example repositories: mono (the
monorepo) and immigrant (the repo that we'll be importing).  Let's
imagine that inside immigrant, there's a file called foo/bar.txt.  We
want to import immigrant into mono, such that mono contains
immigrant/foo/bar.txt.

Projects that have historically been managed outside the monorepo
might need to be imported.  The traditional solution to this is to use
git-subtree.  However, git-subtree does a weird thing to the immigrant
project's history: it treats the import as a move. In other words,
immigrant/foo/bar.txt was previously foo/bar.txt and now it's been
moved.  This means that git log doesn't work across the move boundary.
You can use various tricks to get the old history, but it's a hassle.

The solution is a shell script that I put together called
migrate-history.sh.  The idea is trying to import immigrant into mono
as a subtree.

The simple solution would be to rewrite history using eg
filter-branch, and then rebase on top of master.  But this only works
for a single branch; for complex history, it doesn't.

Instead, we use git plumbing operations to rewrite each commit on
immigrant such that its tree appears inside of the root tree of mono
at the appropriate place.  In order to preserve ancestry, we also need
to change the parent pointer on each migrated commit such that it
points to the migrated version of its parent.

If you're developing custom checkstyle rules or fixing existing custom rules,
please see: build-support/checkstyle/README.

The goal of this example is to help you learn how to best structure your code and configure pants to effectively manage dependencies within a single code repository.

Let's begin by surveying the echo example, located at `src/java/com/twitter/common/examples/echo`.

    $ ls -1 src/java/com/twitter/common/examples/echo
    BUILD
    EchoMain.java
    Echoer.java
    FileEchoer.java
    HadoopEchoer.java
    OWNERS
    README.md

Here we see an application called `EchoMain` that prints a string provided by an implementation of `Echoer`. Two implementations exist:

* `FileEchoer`, a file-based implementation that only depends on the interface, guava, and standard library.
* `HadoopEchoer`, a Hadoop-based implementation that depends on the interface, guava, and Hadoop.

Let's see an example run:

    $ ./pants goal clean-all run src/java/com/twitter/common/examples/echo:echo-bin \
      --jvm-run-args='com.twitter.common.examples.echo.HadoopEchoer'
    Using Echoer: com.twitter.common.examples.echo.HadoopEchoer
    # BEGIN hosts added by Network Connect

Now let's use the local file-based implementation.

    $ ./pants goal clean-all run src/java/com/twitter/common/examples/echo:echo-bin \
      --jvm-run-args='com.twitter.common.examples.echo.FileEchoer'
    Using Echoer: com.twitter.common.examples.echo.FileEchoer
    # BEGIN hosts added by Network Connect

And let's create a bundle. Notice how the archive is quite large because it includes all Hadoop dependencies.

    $ ./pants goal clean-all bundle src/java/com/twitter/common/examples/echo:echo-bin --bundle-archive=zip
    $ du -sh dist/echo-bin.zip
    5.1M	dist/echo-bin.zip
    $ ls -l dist/echo-bin-bundle/libs | wc -l
           8

While the application may work well for its current needs there are a number of issues with this current approach.

* Users must currently bundle the entire echoer, even if they do not need all available echo providers. This causes bloat in deploy artifacts and increases the risk of dependency conflicts.

* Developers may wish to implement a custom `Echoer`, as we'll do shortly. As a single `java_library` exposes the entire echoer, to get the interface users get all dependencies of that target, including Hadoop for example.

Pants provides solutions to these issues by allowing developers to structure their code and build targets such that dependencies are straightforward to manage and users have great flexibility in the construction of their bundles.

# Adding an Echoer

Let's put our developer hat on and extend this application with a new `Echoer`. Conveniently, one already exists that you can copy into place.

    # Paste the code below into StaticEchoer.java
    $ mkdir -p src/java/com/twitter/myapp/echo
    $ vi src/java/com/twitter/myapp/echo/StaticEchoer.java

    package com.twitter.common.myapp.echo;
    import com.twitter.common.examples.echo.Echoer;
    public class StaticEchoer implements Echoer {
      @Override
      public String echo() {
        return "tall cat is tall";
      }
    }

This simple implementation always returns the same string. Now, let's write the BUILD file for this library.

    # Paste the following into:
    $ vi src/java/com/twitter/myapp/echo/BUILD

    java_library(name='echo',
      dependencies=[
        # Necessary for Echoer interface - but with many fellow travelers!
        pants('src/java/com/twitter/common/examples/echo'),
      ],
      sources=globs('*.java'),
    )

    jvm_binary(name='echo-bin',
      main='com.twitter.common.examples.echo.EchoMain',
      dependencies=[pants(':echo')],
    )

Let's run our new echoer implementation and view the dependencies in our bundle. Notice how Hadoop is included even though we use nothing beyond the standard library.

    $ ./pants goal clean-all run src/java/com/twitter/myapp/echo:echo-bin \
      --jvm-run-args='com.twitter.common.myapp.echo.StaticEchoer'
    Using Echoer: com.twitter.common.myapp.echo.StaticEchoer
    tall cat is tall
    $ ./pants goal bundle src/java/com/twitter/myapp/echo:echo-bin --bundle-archive=zip
    $ du -sh dist/echo-bin.zip
    5.1M	dist/echo-bin.zip
    $ ls dist/echo-bin-bundle/libs/ | wc -l
           8

# Rule of thumb: Use a subpackage when adding large dependencies

Let's remind ourselves of the echoer source files:

    src/java/com/twitter/common/examples/echo/Echoer.java
    src/java/com/twitter/common/examples/echo/EchoMain.java
    src/java/com/twitter/common/examples/echo/FileEchoer.java
    src/java/com/twitter/common/examples/echo/HadoopEchoer.java

Hadoop and its transitive dependencies are quite large, and not critical to the echoer, making `HadoopEchoer` a great candidate to refactor into a subpackage. Let's move `HadoopEchoer` into a subpackage and expose it as a stand-alone library.

    $ mkdir src/java/com/twitter/common/examples/echo/hadoop
    $ mv src/java/com/twitter/common/examples/echo/HadoopEchoer.java \
        src/java/com/twitter/common/examples/echo/hadoop/
    # Update package to:
    #   package com.twitter.common.examples.echo.hadoop;
    # Add import:
    #   import com.twitter.common.examples.echo.Echoer;
    $ vi src/java/com/twitter/common/examples/echo/hadoop/HadoopEchoer.java
    # Add the following to:
    $ vi src/java/com/twitter/common/examples/echo/hadoop/BUILD

    java_library(name='hadoop',
      dependencies=[
        pants('3rdparty:hadoop-core'),
        pants('src/java/com/twitter/common/examples/echo'),
      ]
      sources=globs('*.java'),
    )

Now we can remove the `hadoop-core` dependency from `src/java/com/twitter/common/examples/echo`. Now `src/java/com/twitter/myapp/echo` no longer has a transitive dependency on Hadoop!

Let's create a bundle with `StaticEchoer` and see how much fat we've cut.

    $ ./pants goal clean-all run src/java/com/twitter/myapp/echo:echo-bin \
      --jvm-run-args='com.twitter.common.myapp.echo.StaticEchoer'
    Using Echoer: com.twitter.common.myapp.echo.StaticEchoer
    tall cat is tall
    $ ./pants goal bundle src/java/com/twitter/myapp/echo:echo-bin --bundle-archive=zip
    $ du -sh dist/echo-bin.zip
    1.9M	dist/echo-bin.zip
    $ ls dist/echo-bin-bundle/libs/ | wc -l
           6

Prior to this refactor our bundle was ~5 MB with 8 dependencies. By simply refactoring the Hadoop-based functionality into an optional library we've shrunk the application bundle.

Before moving on, let's remember `FileEchoer` is still bundled with the interface. As `FileEchoer` only depends on guava and the standard library there's no harm in combining them in a single target. Use your judgement for how thin to define your targets.

=================================================================================================
Copyright 2013 Twitter, Inc.
-------------------------------------------------------------------------------------------------
Licensed under the Apache License, Version 2.0 (the "License");
you may not use this work except in compliance with the License.
You may obtain a copy of the License in the LICENSE file, or at:

  http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
=================================================================================================

Running pingpong tests:

./pants goal test tests/java/com/twitter/common/examples/pingpong

Running the pingpong example, pinging itself:

./pants goal run src/java/com/twitter/common/examples/pingpong/main \
    --jvm-run-args="-http_port=8888 -ping_target=localhost:8888"

Initiate the pingpong sequence:
$ curl localhost:8888/ping/hello

To see diagnostics, just point your browser to:
  http://localhost:8888/ (index page, which links to the below)
  http://localhost:8888/vars
  http://localhost:8888/graphview
  http://localhost:8888/threads
  http://localhost:8888/contention
  http://localhost:8888/pprof/profile

Building the pingpong example:

./pants src/python/twitter/common/examples:pingpong

Running pingpong tests:

./pants tests/python/twitter/common/examples -v

Running the pingpong example (in two separate windows):
dist/pingpong.pex --http_port=12345 --target_port=12346
dist/pingpong.pex --http_port=12346 --target_port=12345

Then curl http://localhost:12345/ping/hello/10 to start a pingpong.

To see diagnostics, just point your browser to:
  http://localhost:12345/vars
  http://localhost:12345/threads
  http://localhost:12345/profile (requires you to start app with --app_profiling)

You can also start the application with --app_debug to see
twitter.common.app startup and teardown.  Lastly, you can leverage portions
of PEX files to introspect the application:

To see the PEX environment setup:
  PEX_VERBOSE=1 dist/pingpong.pex --help

To run an interpreter in the environment of the PEX file:
  PEX_INTERPRETER=1 dist/pingpong.pex

Flask is being introduced to twitter.common.  Please see https://jira.twitter.biz/browse/HWAUT-869
for more details.
Pex.pex: Installation
=====================

Download
--------

You can download the latest stable version published on this page

Build Latest
------------

You can also build the latest using the following:

~~~~~~~~~~~~~
:::console
# From within a checked out repository
./pants src/python/twitter/common/python/bin:pex
cp dist/pex.pex ~/bin
~~~~~~~~~~~~~

Notes
-----

Ensure pex.pex is in the PATH environment variable. E.g.

~~~~~~~~~~~~~
:::console
export PATH=$PATH:$HOME/bin
~~~~~~~~~~~~~

Usage
-----

See this doc: [[pex.pex.readme|pants('src/python/twitter/common/python:pexreadme')]]

Pex.pex: Usage
==============

[PEX](https://github.com/twitter/commons/blob/master/src/python/twitter/pants/python/README.md) files are single-file lightweight virtual Python environments.

pex.pex is a utility that:
* creates PEX files
* provides a single use run-environment

Installation
------------

See this doc: [[pex.pex.install|pants('src/python/twitter/common/python:pexinstall')]]

Usage
-----
~~~~~~~~~
:::console
Usage: pex.pex [options]

pex.pex builds a PEX (Python Executable) file based on the given specifications: sources, requirements, their dependencies and other options

Options:
  --version             show program's version number and exit
  -h, --help            show this help message and exit
  --pypi, --no-pypi     Whether to use pypi to resolve dependencies; Default:
                        use pypi
  --cache-dir=CACHE_DIR
                        The local cache directory to use for speeding up
                        requirement lookups; Default: ~/.pex/install
  -p PEX_NAME, --pex-name=PEX_NAME
                        The name of the generated .pex file: Omiting this will
                        run PEX immediately and not save it to a file
  -e ENTRY_POINT, --entry-point=ENTRY_POINT
                        The entry point for this pex; Omiting this will enter
                        the python IDLE with sources and requirements
                        available for import
  -r REQUIREMENT, --requirement=REQUIREMENT
                        requirement to be included; may be specified multiple
                        times.
  --repo=PATH           Additional repository path (directory or URL) to look
                        for requirements.
  -s DIR, --source-dir=DIR
                        Source to be packaged; This <DIR> should be a pip-
                        installable project with a setup.py.
  -v, --verbosity       Turn on logging verbosity.
~~~~~~~~~

Use cases
---------

* An isolated python environment containing your requirements and its dependencies for one time use

        :::console
        pex.pex --requirement fabric
        ...
        >>> import fabric
        >>> ^D

* A PEX file encapsulating your requirements and its dependencies for repeated use and sharing

        :::console
        pex.pex --requirement fabric --pex-name my_fabric.pex
        ./my_fabric.pex
        ...
        >>> import fabric
        >>> ^D

* A PEX file encapsulating your requirements intended to be run with a specific entry point

        :::console
        pex.pex --requirement fabric --entry-point fabric.main:main --pex-name my_fabric.pex
        ...
        ./my_fabric.pex -h

        Usage: fab [options] <command>[:arg1,arg2=val2,host=foo,hosts='h1;h2',...] ...
 
        Options:
          -h, --help            show this help message and exit
          -d NAME, --display=NAME
                                print detailed info about command NAME


        PEX_INTERPRETER=1 ./my_fabric.pex
        >>> import fabric
        >>> ^D


Bootstrapping pex.pex
---------------------------

* Download virtualenv and create twitter.common.python virtualenv

        :::console
        curl -O https://pypi.python.org/packages/source/v/virtualenv/virtualenv-1.11.tar.gz
        tar zxf virtualenv-1.11.tar.gz
        python virtualenv-1.11/virtualenv.py twitter.common.python.venv

* Activate and install twitter.common.python

        :::console
        cd twitter.common.python.venv
        source bin/activate
        pip install twitter.common.python

* Use bin/pex to bootstrap itself

        :::console
        pex -r twitter.common.python -e twitter.common.python.bin.pex:main -p pex.pex

* Copy and deactivate virtualenv

        :::console
        cp pex.pex ~/bin/pex
        deactivate

* Use pex utility

        :::console
        # Presumes that ~/bin is on $PATH
        pex -r fabric -e fabric.main:main

These are the Twitter Python commons: implementations of common libraries in
use throughout Twitter's codebase.

With the exception of twitter.common.python, all should be released in
lockstep.  This entails incrementing the VERSION file within this directory,
then running build-support/commons/scripts/build_py_commons.sh and uploading
the resulting source distributions to PyPI.

# DO NOT EDIT THIS PAGE DIRECTLY
### This file is managed in git - edit the markdown source at `src/python/twitter/common/styleguide.md`, and publish with `./pants goal confluence src/python/twitter/common:python-styleguide`


## Overview

The Python style at Twitter closely follows [PEP-8](http://www.python.org/dev/peps/pep-0008/) + [PEP-257](http://www.python.org/dev/peps/pep-0257/) with the following modifications:

* 2-space indents instead of 4
* 100-character lines are allowed

## Automated checking

An automated checker for the Twitter Python style guide can be found in Science.

      $ ./pants src/python/twitter/checkstyle:check
      $ dist/check.pex path1 path2 ...

Paths may be files or directories. You may also check the diff of the current branch against another branch, e.g.

      $ dist/check.pex --diff=master


## Basic naming tenets
* Class names should be CamelCased with the first character always capitalized.
* Toplevel and class methods should be snake_cased.
* Private class methods and variables should be prefixed with '_'

## Science-specific guidelines

### Internal libraries
* Do not reinvent the wheel. Take a look in `twitter.common` first.
* If what you're doing seems generic enough, consider factoring it out, adding tests and adding it to `twitter.common`
* Unless your application is trivial, you should probably leverage `twitter.common.app`
* If you need argument parsing, you should definitely be using `twitter.common.app`
* If your script is basic, `print` + `sys.stdout`/`stderr` is fine
* If you ever anticipate running in production, consider using `twitter.common.log`

### External libraries
* No use of global site-packages; instead leverage `python_requirement`s to manage external dependencies.
* In most cases, `python_requirement`s should be specified in 3rdparty/python/BUILD and tied to an explicit version number so as to reduce the possibility of version conflicts within the repository.

### Testing
* Our preferred testing harness is [pytest](https://pypi.python.org/pypi/pytest) and is automatically added to the environment of all Python test targets
* Our preferred mocking framework is [mock](https://pypi.python.org/pypi/mock)

### Naming
* For autogenerated Python Thrift code, if your project is in `src/python/twitter/thermos/runner`, namespace the Python thrift into `gen.twitter.thermos.runner`. Namespace packages slow down importing for everything, so isolating it into a single `gen` namespace is preferred.

## Importing

Imports should be done in the following order:

* standard library
* science libraries
* code generated libraries
* third party libraries

Within each collection, imports should be lexically ordered. For example:

      import os
      import sys
      import time

      try:
        from twitter.common import log
      except ImportError:
        import logging as log
      from twitter.common.rpc import make_client
      from twitter.common.rpc.finagle import TFinagleProtocolWithClientId

      from gen.twitter.gizmoduck import UserService
      from gen.twitter.gizmoduck.models import ttypes as UserServiceModels
      from gen.twitter.gizmoduck.ttypes import (
          AccessDenied,
          InternalServerError,
          LookupContext,
          OverCapacity,
          QueryFields)

      from thrift.Thrift import TApplicationException
      import zookeeper

If you are importing more than two or three symbols from a single package, consider wrapping the imports as well.


## Best practices

1. Wrapped lines should be indented 4 spaces, rather than aligned with the opening delimiter:

    _No:_

            def my_function(some_args,
                            that_would_be,
                            too_long_for_one_line):
              do_something()

    _Yes:_

            def my_function(
                some_args,
                that_would_be,
                too_long_for_one_line):

              do_something()

    *Note:* For function definitions, the first arg is on its own line, and there's a blank line between the end of the args and the first line of the function.

2. Prefer accessors/getters for all but the most trivial externally accessible variables, for which you may use properties.


3. Try the least magical implementation first. Avoid metaclasses and overriding `__getattr__` unless absolutely necessary.


4. If you use print, use it as a function, preferably importing it from `__future__`. This way
your code is compliant with both Python 2.6+ and 3.x.

    _Bad:_

          print 'Hello world'
          print >> sys.stderr, 'Get off my lawn!'
          print 'Processing...',

    _Better:_

          print('Hello world')

    _Best:_

          from __future__ import print_function
          print('Hello world')
          print('Get off my lawn!', file=sys.stderr)
          print('Processing...', end='')


5. Only use new style classes, e.g.:

          class MyClass(object):
            ...

    instead of

          class MyClass:
            ...


6. If your class has exceptional behavior, prefer to declare your exceptions inside your class, e.g.:

          class GarbageCollector(object):
            class CouldNotRecoverEnoughSpaceError(Exception): pass
            def __init__(self):
              ...
            def collect(self):
              ...
              raise GarbageCollector.CouldNotRecoverEnoughSpaceError("Path %s insufficient." % ...)

    This means that if the user wants to catch exceptions, they do not need tons of import statements.

    It is occasionally fine to put user-defined exceptions elsewhere, e.g. in `__init__.py` for libraries. Whatever you can do to avoid excessive imports.


7. Do not rely upon `__file__`. Instead prefer `pkgutil`, `pkg_resources` and `__name__`. By using the latter, you may run inside a zip archive or in an exploded directory structure and it will work the same way.

    _No:_

          with open(os.path.join(os.path.dirname(__file__), 'resources', 'data.txt')) as fp:
          data = fp.read()

    _Yes:_

          from pkg_resources import resource_string
          data = resource_string(__name__, os.path.join('resources', 'data.txt'))


8. Utilize context managers as much as possible, especially with files and locks:

    _Yes:_

          with open("my_file.txt") as fp:
            data = fp.read()

          lock = threading.Lock()
          with lock:
            print('Holding the lock!')

    _No:_

          data = open("my_file.txt").read()

    _Nor:_

          fp = open("my_file.txt")
          data = fp.read()
          fp.close()

    For things like `zipfile` which does not have a context manager in Python 2.6, use `contextlib.closing`:

          from contextlib import closing
          with closing(zipfile('/tmp/myfile.zip')) as zf:
            data = zf.read('manifest.txt')


9. When catching exceptions, use new-style grammar:

    _Yes:_

          try:
            val = array[key]
          except KeyError as e:
            print('Could not access key: %s!' % e)

    _No:_

          try:
            val = array[key]
          except KeyError, e:
            print >> sys.stderr, 'Could not access key %s!' % e


10. Use the os module for path manipulation as much as possible, e.g. `os.path.join`.

    Similarly, avoid string concatenation operations as much as possible. `''.join([a,b,c,d])` will likely be much faster than `a+b+c+d`.


11. Never put dashes in Python filenames because you will not be able to import code from them. Use underscores instead.


12. Use string.format _only_ when you need to interpolate strings with both keyword and positional
arguments. Basic printf-style string interpolation is sufficient 99.9% of the time and does not
require learning a new DSL.


## Tips for 2.x / 3.x interoperability:

1. Remember that in 3.x all strings are unicode. `basestring` no longer exists, so if you're in
   science, do the following to test for stringyness:

          from twitter.common.lang import Compatibility
          if isinstance(input, Compatibility.string):
            ...

2. In most situations, you probably want to open files in 'rb' or 'wb' mode instead.

3. Use `Compatibility` from `twitter.common.lang` for:
    - `Compatibility.integer`
    - `Compatibility.real`
    - `Compatibility.PY2` and `Compatibility.PY3` booleans
    - `Compatibility.exec_function` since `exec` is no longer a statement in Python 3.x.
    - `Compatibility.StringIO` to avoid complex `try`/`except ImportError` chains.

4. Avoid metaclasses because syntax has changed. But if you must use a metaclass, do not use the `__metaclass__ = MyMetaclass` syntax, instead:

          MyMetaclassBase = MyMetaclass('MyMetaclassBase', (object,), {})
          class MyClassThatNeedsAMetaclass(MyMetaclassBase):
            ...

5. Relative imports must be .-delimited, so from within `application.py` in `foo/bar` along with `baz.py`:

    _Yes:_

          from foo.bar import baz

    _or (for same-level imports):_

          from .baz import poop

    _No (won't work on Python 3.x):_

          import baz
          from baz import poop

6. Almost always use list/generator comprehensions instead of `filter` or `map`. The latter should only be used in the specific circumstance where a) the equivalent comprehension would be significantly longer; and b) the use case is clearly consume-once (for example, as input to `for` loops).

    Further, `filter`s or `map`s should _never_ be returned from functions, or as part of an API - this is particularly dangerous with the change in their behaviour between Python 2.x and 3.x (i.e. returning lists in the former and generators in the latter).

    _Yes:_

          odd_numbers = [i for i in range(1, 10) if i % 2]

    _No (different behaviour between Python 2.x/3.x!):_

          odd_numbers = filter(lambda i: i % 2, range(1, 10))

    Similarly, when dealing with dictionaries, prefer the use of their list-returning functions
    over their iterator counterparts, unless performance is demonstrably impacted:

    _Yes:_

          for k, v in my_dict.items():
            ...

    _No (won't work on Python 3.x):_

          for k, v in my_dict.iteritems():
            ...


Using Pants for Python development
==================================

Why use Pants for Python development?
-------------------------------------

Pants makes the manipulation and distribution of hermetically sealed Python environments
painless.

But why another system?

Alternatives
^^^^^^^^^^^^

There are several solutions for package management in Python.  Almost
everyone is familiar with running `sudo easy_install PackageXYZ`.  This
leaves a lot to be desired.  Over time, your Python installation will
collect dozens of packages, become annoyingly slow or even broken, and
reinstalling it will invariably break a number of the applications
that you were using.

A marked improvement over the `sudo easy_install` model is virtualenv_
to isolate Python environments on a project by project basis.  This is
useful for development but does not directly solve any problems
related to deployment, whether it be to a production environment or to
your peers.  It is also challenging to explain to a Python non-expert.

.. _virtualenv: http://www.virtualenv.org

A different solution altogether, `zc.buildout`_ attempts to provide a
framework and recipes for many common development environments.  It
has arguably gone the farthest for automating environment
reproducibility amongst the popular tools, but shares the same
complexity problems as all the other abovementioned solutions.

.. _zc.buildout: http://www.buildout.org/

Most solutions leave deployment as an afterthought.  Why not make the
development and deployment environments the same by taking the
environment along with you?

Pants and PEX
^^^^^^^^^^^^^

The lingua franca of Pants is the PEX file (PEX itself does not stand for
anything in particular, though in spirit you can think of it as a "Python
EXecutable".)

**PEX files are single-file lightweight virtual Python environments.**

The only difference is no virtualenv setup instructions or
`pip install foo bar baz`.  PEX files are self-bootstrapping Python
environments with no strings attached and no side-effects.  Just a simple
mechanism that unifies both your development and your deployment.

Getting started
---------------

First it is necessary to install Pants. See :doc:`install`.

It is also helpful to read the :doc:`first_concepts`.


TL;DR - 'Hello world!' with Pants Python
----------------------------------------

.. code-block:: bash

  $ git clone git://github.com/twitter/commons
  $ cd commons
  $ mkdir -p src/python/twitter/my_project
  $ vi src/python/twitter/my_project/BUILD


`src/python/twitter/my_project/BUILD`::

  python_binary(
    name = 'hello_world',
    source = 'hello_world.py'
  )

.. code-block:: bash

  $ vi src/python/twitter/my_project/hello_world.py


`src/python/twitter/my_project/hello_world.py` might have contents::

  print('Hello world!')

To run directly:

.. code-block:: bash

  $ ./pants py src/python/twitter/my_project:hello_world
  Build operating on target: PythonBinary(src/python/twitter/my_project/BUILD:hello_world)
  Hello world!


To build:

.. code-block:: bash
                
  $ ./pants src/python/twitter/my_project:hello_world
  Build operating on targets: OrderedSet([PythonBinary(src/python/twitter/my_project/BUILD:hello_world)])
  Building PythonBinary PythonBinary(src/python/twitter/my_project/BUILD:hello_world):
  Wrote /Users/wickman/clients/science-py-csl/dist/hello_world.pex


and run separately:

.. code-block:: bash
                
  $ dist/hello_world.pex
  Hello world!


NOTE: The first time you run `./pants` will likely take a ridiculous amount
of time as Pants bootstraps itself inside your directory.  Note, it never
installs anything in a global site-packages.


Describing Python environments in Pants
---------------------------------------

Build dependencies in Pants are managed with `BUILD` files that are
co-located with your source.  These files are used to describe the following:

1. libraries:  bundles of sources and resources, that may or may not also depend on other libraries
2. binaries:  a single source (the executable) and libraries it depends upon
3. requirements:  external dependencies as resolved by dependency managers e.g. pypi in Python or ivy on the JVM

The main point of Pants is to take these `BUILD` files and do something useful with them.


BUILD file format
^^^^^^^^^^^^^^^^^

These descriptions are stored in files named BUILD and colocated near the
binaries/libraries they describe.  Let's take for example the
src/python/twitter/tutorial subtree in commons:

.. code-block:: bash
                
  $ ls -lR src/python/twitter/tutorial/
  total 16
  -rw-r--r--  1 wickman  wheel  137 Apr  9 22:59 BUILD
  -rw-r--r--  1 wickman  wheel  118 Apr  9 22:59 hello_world.py


Let's take a look at the BUILD file in `src/python/twitter/tutorial/BUILD`::

  python_binary(
    name = "hello_world",
    source = "hello_world.py",
    dependencies = [
      pants("src/python/twitter/common/app"),
    ]
  )

This BUILD file names one target: `hello_world`, which is a `python_binary` target.  The `hello_world` target
contains one source file, `hello_world.py` and depends upon one other
target, the format of which will be described shortly.

It should be noted that sources are relative to the location of the BUILD
file itself, e.g.  `hello_world.py` inside of `src/python/twitter/tutorial/BUILD` actually refers to
`src/python/twitter/tutorial/hello_world.py`::

  from twitter.common import app

  def main():
    print('Hello world!')

  app.main()


Dependencies, on the other hand, are relative to the *source root* of the repository which is defined
by the BUILD file that sits next to the `pants` command::


  # Define the repository layout

  source_root('src/antlr', doc, page, java_antlr_library, python_antlr_library)
  source_root('src/java', annotation_processor, doc, jvm_binary, java_library, page)
  source_root('src/protobuf', doc, java_protobuf_library, page)
  source_root('src/python', doc, page, python_binary, python_library)
  source_root('src/scala', doc, jvm_binary, page, scala_library)
  source_root('src/thrift', doc, java_thrift_library, page, python_thrift_library)

  source_root('tests/java', doc, java_library, java_tests, page)
  source_root('tests/python', doc, page, python_library, python_tests, python_test_suite)
  source_root('tests/scala', doc, page, scala_library, scala_tests)


This file can be tailored to map to any source root structure such as Maven
style, Twitter style (as described above) or something more flat such as a
`setup.py`-based project.  This however is an advanced topic that is not
covered in this document.


Addressing targets
^^^^^^^^^^^^^^^^^^

Within the `src/python/twitter/tutorial/BUILD`, only one target is defined,
specifically `hello_world`.  This target is addressed by
`src/python/twitter/tutorial:hello_world` which means the target
`hello_world` within `src/python/twitter/tutorial/BUILD`.  In general,
targets take the form `<path>:<target name>` with the special cases:

1. in the case of `path/to/directory/BUILD:target`, the `BUILD` component may be elided and instead `path/to/directory:target` may be used
2. `path/to/directory` is short form for `path/to/directory:directory`, so `src/python/twitter/common/app` is short form for `src/python/twitter/common/app/BUILD:app`

`src/python/twitter/tutorial/BUILD` referenced `pants('src/python/twitter/common/app')` in its
dependencies.  The `pants()` keyword is akin to a "pointer dereference" for an address.  It will point
to whatever target is described at that address, in this case a `python_library` target:

`src/python/twitter/common/app/BUILD`::

  python_library(
    name = "app",
    sources = globs('*.py'),
    dependencies = [
      pants('src/python/twitter/common/dirutil'),
      pants('src/python/twitter/common/lang'),
      pants('src/python/twitter/common/options'),
      pants('src/python/twitter/common/util'),
      pants('src/python/twitter/common/app/modules'),
    ]
  )

which in turn includes even more dependencies.  The job of Pants is to manage the transitive closure
of all these dependencies and manipulate collections of these targets for you.


Python target types
^^^^^^^^^^^^^^^^^^^

BUILD files themselves are just Python.  The only thing magical is that the
statement `from twitter.pants import *` has been autoinjected.  This
provides a number of Python-specific targets such as:

1. `python_library`
2. `python_binary`
3. `python_requirement`
4. `python_thrift_library`

and a whole host of other targets including Java, Scala, Python, Markdown,
the universal `pants` target and so forth.  See
`src/python/twitter/pants/__init__.py` for a comprehensive list of targets.


`python_library`
""""""""""""""""

A `python_library` target has a name, zero or more source files, zero or
more resource files, and zero or more dependencies.  These dependencies may
include other `python_library`-like targets (`python_library`,
`python_thrift_library`, `python_antlr_library` and so forth) or
`python_requirement` targets.


`python_binary`
"""""""""""""""

A `python_binary` target is almost identical to a `python_library` target except instead of `sources`, it takes one
of two possible parameters:

1. `source`: The source file that should be executed within the "library" otherwise defined by `python_binary`

2. `entry_point`: The entry point that should be executed within the "library" otherwise defined by
`python_binary`.  Entry points take the format of `pkg_resources.EntryPoint`, which is something
akin to `some.module.name:my.attr` which means run the function pointed by `my.attr` inside the
module `some.module` inside the environment.  The `:my.attr` component can be omitted and the
module is executed directly (presuming it has a `__main__.py`.)


`python_requirement`
""""""""""""""""""""

A `python_requirement` target describes an external dependency as understood by easy_install or pip.  It takes only
a single non-keyword argument of the `Requirement`-style string, e.g. ::


  python_requirement('django-celery')
  python_requirement('tornado==2.2')
  python_requirement('kombu>=2.1.1,<3.0')


This will resolve the dependency and its transitive closure, for example `django-celery` pulls down the following
dependencies: `celery>=2.5.1`, `django-picklefield>=0.2.0`, `ordereddict`, `python-dateutil`,
`kombu>=2.1.1,<3.0`, `anyjson>=0.3.1`, `importlib`, and `amqplib>=1.0`.

Pants takes care of handling these dependencies for you.  It will never install anything globally.  Instead it will
build the dependency and cache it in `.pants.d` and assemble them a la carte into an execution environment.

The `python_requirement` for a particular dependency should appear
only once in a BUILD file.  It creates a local target name which can
then be included in other dependencies in the file.::


  python_requirement('django-celery')

  python_library(
    name = 'mylib_1',
    sources = [
      'mylib_1.py',
    ],
    dependencies = [
      pants(':django-celery')
    ]
  )

  python_library(
    name = 'mylib_2',
    sources = [
      'mylib_2.py',
    ],
    dependencies = [
      pants(':django-celery')
    ]
  )

`python_thrift_library`
"""""""""""""""""""""""

A `python_thrift_library` target takes the same arguments as `python_library` arguments, except that files described
in `sources` must be thrift files.  If your library or binary depends upon this target type, Python bindings
will be autogeNerated and included within your environment.


`python_tests`
""""""""""""""

A `python_tests` target takes the same arguments as `python_library` arguments, with the addition of the optional
`coverage` argument that is a list of namespaces that you want to generate coverage data for.


Building your first PEX
-----------------------

Now you're ready to build your first PEX file (technically you already have,
by building Pants itself.)  By default if you specify `./pants <target>`, it
assumes you mean `./pants build <target>` and does precisely that:

.. code-block:: bash
                
  $ PANTS_VERBOSE=1 ./pants src/python/twitter/tutorial:hello_world
  Build operating on targets: OrderedSet([PythonBinary(src/python/twitter/tutorial/BUILD:hello_world)])
    Resolver: Calling environment super => 0.046ms
  Building PythonBinary PythonBinary(src/python/twitter/tutorial/BUILD:hello_world):
  Building PythonBinary PythonBinary(src/python/twitter/tutorial/BUILD:hello_world):
    Dumping library: PythonLibrary(src/python/twitter/common/app/BUILD:app) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/dirutil/BUILD:dirutil) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/lang/BUILD:lang) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/options/BUILD:options) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/util/BUILD:util) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/app/modules/BUILD:modules) [relative module: ]
    Resolver: Calling environment super => 0.016ms
    Dumping binary: twitter/tutorial/hello_world.py
  Wrote /private/tmp/wickman-commons/dist/hello_world.pex

You will see that despite specifying just one dependency, the transitive
closure of `hello_world` pulled in all of `src/python/twitter/common/app`
and its direct descendants.  That's because those library targets depended
upon other library targets, than in turn depending on even more.  At the end
of the day, we bundle up the closed set of all dependencies and bundle them
into `hello_world.pex`.

Since it uses the `twitter.common.app` framework, we know we can fire it up
and poke around with `--help`:

.. code-block:: bash
                
  $ dist/hello_world.pex --help
  Options:
    -h, --help, --short-help
                          show this help message and exit.
    --long-help           show options from all registered modules, not just the
                          __main__ module.


If we specify `--long-help`, we can see the help of transitively included
modules, e.g.  `twitter.common.app` itself:

.. code-block:: bash

  $ dist/hello_world.pex --long-help
  Options:
    -h, --help, --short-help
                          show this help message and exit.
    --long-help           show options from all registered modules, not just the
                          __main__ module.

    From module twitter.common.app:
      --app_daemonize     Daemonize this application. [default: False]
      --app_profile_output=FILENAME
                          Dump the profiling output to a binary profiling
                          format. [default: None]
      --app_daemon_stderr=TWITTER_COMMON_APP_DAEMON_STDERR
                          Direct this app\'s stderr to this file if daemonized.
                          [default: /dev/null]
      --app_debug         Print extra debugging information during application
                          initialization. [default: False]
      --app_daemon_stdout=TWITTER_COMMON_APP_DAEMON_STDOUT
                          Direct this app's stdout to this file if daemonized .
                          [default: /dev/null]
      --app_profiling     Run profiler on the code while it runs.  Note this can
                          cause slowdowns. [default: False]
      --app_ignore_rc_file
                          Ignore default arguments from the rc file. [default:
                          False]
      --app_pidfile=TWITTER_COMMON_APP_PIDFILE
                          The pidfile to use if --app_daemonize is specified.
                          [default: None]


Or we can simply execute it as intended:

.. code-block:: bash
                
  $ dist/hello_world.pex
  Hello world!



Environment manipulation with `pants py`
----------------------------------------

We've only discussed so far the "pants build" command.  There's also a
dedicated "py" command that allows you to manipulate the environments
described by `python_binary` and `python_library` targets, such as drop into
an interpreter with the environment set up for you.

`pants py` semantics
^^^^^^^^^^^^^^^^^^^^

The default behavior of `pants py <target>` is the following:

1. For `python_binary` targets, build the environment and execute the target
2. For one or more `python_library` targets, build the environment that is the transitive closure of all targets and drop into an interpreter.
3. For a combination of `python_binary` and `python_library` targets, build the transitive closure of all targets and execute the first binary target.


external dependencies
^^^^^^^^^^^^^^^^^^^^^

Let's take `src/python/twitter/tutorial/BUILD` and split out the dependencies from
our `hello_world` target into `hello_world_lib` and add dependencies upon
Tornado_ and psutil_.

.. _Tornado: http://github.com/facebook/tornado
.. _psutil: http://code.google.com/p/psutil/

::
   
  python_binary(
    name = "hello_world",
    source = "hello_world.py",
    dependencies = [
      pants(":hello_world_lib")
    ]
  )

  python_library(
    name = "hello_world_lib",
    dependencies = [
      pants("src/python/twitter/common/app"),
      python_requirement("tornado"),
      python_requirement("psutil"),
    ]
  )


This uses the `python_requirement` target which can refer to any string in `pkg_resources.Requirement` format as
recognized by tools such as `easy_install` and `pip` as described above.

Now that we've created a library-only target `src/python/twitter/tutorial:hello_world_lib`, let's drop
into it using `pants py` with verbosity turned on so that we can see what's
going on in the background:

.. code-block:: bash

  $ PANTS_VERBOSE=1 ./pants py src/python/twitter/tutorial:hello_world_lib
  Build operating on target: PythonLibrary(src/python/twitter/tutorial/BUILD:hello_world_lib)
    Resolver: Calling environment super => 0.019ms
  Building PythonBinary PythonLibrary(src/python/twitter/tutorial/BUILD:hello_world_lib):
    Dumping library: PythonLibrary(src/python/twitter/tutorial/BUILD:hello_world_lib) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/app/BUILD:app) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/dirutil/BUILD:dirutil) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/lang/BUILD:lang) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/options/BUILD:options) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/util/BUILD:util) [relative module: ]
    Dumping library: PythonLibrary(src/python/twitter/common/app/modules/BUILD:modules) [relative module: ]
    Dumping requirement: tornado
    Dumping requirement: psutil
    Resolver: Calling environment super => 0.029ms
    Resolver: Activating cache /private/tmp/wickman-commons/3rdparty/python => 356.432ms
    Resolver: Resolved tornado => 357.219ms
    Resolver: Activating cache /private/tmp/wickman-commons/.pants.d/.python.install.cache => 41.117ms
    Resolver: Fetching psutil => 10144.264ms
    Resolver: Building psutil => 1794.474ms
    Resolver: Distilling psutil => 224.896ms
    Resolver: Constructing distribution psutil => 2.855ms
    Resolver: Resolved psutil => 12210.066ms
    Dumping distribution: .../tornado-2.2-py2.6.egg
    Dumping distribution: .../psutil-0.4.1-py2.6-macosx-10.4-x86_64.egg
  Python 2.6.7 (r267:88850, Aug 31 2011, 15:49:05)
  [GCC 4.2.1 (Apple Inc. build 5664)] on darwin
  Type "help", "copyright", "credits" or "license" for more information.
  (InteractiveConsole)
  >>> 
  


In the background, `pants` used cached version of `tornado` but fetched
`psutil` from pypi and any necessary transitive dependencies (none in this
case) and built a platform-specific version for us.

You can convince yourself that the environment contains all the dependencies
by inspecting `sys.path` and importing libraries as you desire::

  >>> import psutil
  >>> help(psutil)
  >>> from twitter.common import app
  >>> help(app)


It should be stressed that *dependencies built by Pants are never installed globally*.
These dependencies only exist for the duration of the Python interpreter forked by Pants.


Running an application using `pants py`
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Let us turn our `hello_world.py` into a basic `top` application using `tornado`::


  from twitter.common import app

  import psutil
  import tornado.ioloop
  import tornado.web

  class MainHandler(tornado.web.RequestHandler):
    def get(self):
      self.write('<pre>Running pids:\n%s</pre>' % '\n'.join(map(str, psutil.get_pid_list())))

  def main():
    application = tornado.web.Application([
      (r"/", MainHandler)
    ])
    application.listen(8888)
    tornado.ioloop.IOLoop.instance().start()

  app.main()

We have now split our application into two parts: the `hello_world` binary
target and the `hello_world_lib` library target.  If we run `pants py
src/python/twitter/tutorial:hello_world_lib`, the default behavior is to
drop into an interpreter.

If we run `pants py src/python/twitter/tutorial:hello_world`, the default behavior is to run
the binary target pointed to by `hello_world`:

.. code-block:: bash
                
  $ ./pants py src/python/twitter/tutorial:hello_world

Then point your browser to http://localhost:8888

pants py --pex
^^^^^^^^^^^^^^

There is also a `--pex` option to pants py that allows you to build a PEX
file from a union of python_library targets that does not necessarily have a
`python_binary` target defined for it.  Since there is no entry point
specified, the resulting .pex file just behaves like a Python interpreter,
but with the sys.path bootstrapped for you:

.. code-block:: bash
                
  $ ./pants py --pex src/python/twitter/tutorial:hello_world_lib
  Build operating on target: PythonLibrary(src/python/twitter/tutorial/BUILD:hello_world_lib)
  Wrote /private/tmp/wickman-commons/dist/hello_world_lib.pex

  $ ls -la dist/hello_world_lib.pex
  -rwxr-xr-x  1 wickman  wheel  1404174 Apr 10 13:00 dist/hello_world_lib.pex

Now if you use dist/hello_world_lib.pex, since it has no entry point, it will drop you into an interpreter:

.. code-block:: bash
                
  $ dist/hello_world_lib.pex
  Python 2.6.7 (r267:88850, Aug 31 2011, 15:49:05)
  [GCC 4.2.1 (Apple Inc. build 5664)] on darwin
  Type "help", "copyright", "credits" or "license" for more information.
  (InteractiveConsole)
  >>> import tornado

As mentioned before, it's like a single-file lightweight alternative to a
virtualenv.  We can even use it to run our `hello_world.py` application:

.. code-block:: bash
                
  $ dist/hello_world_lib.pex src/python/twitter/tutorial/hello_world.py

This can be an incredibly powerful and lightweight way to manage and deploy
virtual environments without using `virtualenv`.

PEX file as interpreter
^^^^^^^^^^^^^^^^^^^^^^^

As mentioned above, PEX files without default entry points behave like Python interpreters that
carry their dependencies with them.  For example, let's create a target that
provides a Fabric dependency within `src/python/twitter/tutorial/BUILD`::

  python_library(
    name = 'fabric',
    dependencies = [
      python_requirement('Fabric')
    ]
  )

And let's build a fabric PEX file:

.. code-block:: bash
                
  $ ./pants py --pex src/python/twitter/tutorial:fabric
  Build operating on target: PythonLibrary(src/python/twitter/tutorial/BUILD:fabric)
  Wrote /private/tmp/wickman-commons/dist/fabric.pex

By default it does nothing more than drop us into an interpreter:

.. code-block:: bash
                
  $ dist/fabric.pex
  Python 2.6.7 (r267:88850, Aug 31 2011, 15:49:05)
  [GCC 4.2.1 (Apple Inc. build 5664)] on darwin
  Type "help", "copyright", "credits" or "license" for more information.
  (InteractiveConsole)
  >>>


But suppose we have a local script that depends upon Fabric, `fabric_hello_world.py`::


  from fabric.api import *

  def main():
    local('echo hello world')

  if __name__ == '__main__':
    main()

We can now use `fabric.pex` as if it were a Python interpreter but with
fabric available in its environment.  Note that fabric has never been
installed globally in any site-packages anywhere.  It is just bundled inside
of fabric.pex:

.. code-block:: bash
                
  $ dist/fabric.pex fabric_hello_world.py
  [localhost] local: echo hello world
  hello world



python_binary entry_point
^^^^^^^^^^^^^^^^^^^^^^^^^

An advanced feature of `python_binary` targets, you may in addition specify
direct entry points into PEX files rather than a source file.  For example,
if we wanted to build an a la carte `fab` wrapper for fabric::

  python_binary(name = "fab",
    entry_point = "fabric.main:main",
    dependencies = [
      python_requirement("fabric"),
    ]
  )


We build:

.. code-block:: bash
                
  $ ./pants src/python/twitter/tutorial:fab
  Build operating on targets: OrderedSet([PythonBinary(src/python/twitter/tutorial/BUILD:fab)])
  Building PythonBinary PythonBinary(src/python/twitter/tutorial/BUILD:fab):
  Wrote /private/tmp/wickman-commons/dist/fab.pex

And now `dist/fab.pex` behaves like a standalone `fab` binary:

.. code-block:: bash
                
  $ dist/fab.pex -h
  Usage: fab [options] <command>[:arg1,arg2=val2,host=foo,hosts='h1;h2',...] ...

  Options:
    -h, --help            show this help message and exit
    -d NAME, --display=NAME
                          print detailed info about command NAME
    -F FORMAT, --list-format=FORMAT
                          formats --list, choices: short, normal, nested
    -l, --list            print list of possible commands and exit
    --set=KEY=VALUE,...   comma separated KEY=VALUE pairs to set Fab env vars
    --shortlist           alias for -F short --list
    -V, --version         show program's version number and exit
    -a, --no_agent        don't use the running SSH agent
    -A, --forward-agent   forward local agent to remote end
    --abort-on-prompts    abort instead of prompting (for password, host, etc)
    ...

Pants also has excellent support for JVM-based builds and can do similar
things like resolving external JARs and packaging them as standalone
environments with default entry points.

Python Tests
------------

By default Python tests are run via `pytest`. Any option that `py.test` has can be used since
arguments are passed on by `pants`.

Defining `python_tests` Targets
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When setting up your test targets, the BUILD file will be something like::

  python_tests(
    name = "your_tests",
    sources = globs("*.py"),
    coverage = ["twitter.your_namespace"],
    dependencies = [
      pants("3rdparty/python:mock")
      pants("src/python/twitter/your_namespace")
   ]
  )

The above target is very similar to a `python_library` with the addition of the `coverage` argument.
`coverage` allows you to retrict the namespaces for which code coverage data is generated.

Running Python Tests
^^^^^^^^^^^^^^^^^^^^

To run your Python tests, you use `./pants build` although `build` can be left off:

.. code-block:: bash
                
  $ ./pants tests/python/twitter/your_tests/BUILD:your_tests
  Build operating on targets: OrderedSet([PythonTests(tests/python/twitter/your_tests/BUILD:your_tests)])
  ================================================== test session starts ===================================================
  platform darwin -- Python 2.6.7 -- pytest-2.3.5
  collected 15 items:

  tests/python/twitter/your_tests/module1_test.py ....
  tests/python/twitter/your_tests/module2_test.py ....
  tests/python/twitter/your_tests/module3_test.py ....

  =============================================== 15 passed in 0.44 seconds ================================================
  tests.python.twitter.your_tests.your_tests                                    .....   SUCCESS


Sometimes you only want to run specific tests (or exclude them). The `-k` option controls the
tests to run. `-k` will do substring matches on test method names and can also use keywords like
`not` and `or` to refine results.

.. code-block:: bash
                
  $ ./pants tests/python/twitter/your_tests/BUILD:your_tests -k 'module1_instantiation_test or module1_foo_test' -v
  Build operating on targets: OrderedSet([PythonTests(tests/python/twitter/your_tests/BUILD:your_tests)])
  ================================================== test session starts ===================================================
  platform darwin -- Python 2.6.7 -- pytest-2.3.5
  collected 15 items:

  tests/python/twitter/your_tests/module1_test.py:3: Module1Test.module1_instantiation_test PASSED
  tests/python/twitter/your_tests/module1_test.py:21: Module1Test.module1_foo_test PASSED

  ======================= 13 tests deselected by '-kmodule1_instantiation_test or module1_foo_test' ========================
  ================================================ 2 passed in 0.14 seconds ================================================
  tests.python.twitter.your_tests.your_tests                                    .....   SUCCESS

You can also mark tests via a decorator::


  @pytest.mark.module1
  def module1_instantiation_test():
      # testing code here


Using `-m` you can specify the marks of tests that you want to execute.

Getting Python Code Coverage
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To get code coverage data, set the `PANTS_PY_COVERAGE` environment variable:

.. code-block:: bash
                
  $ PANTS_PY_COVERAGE=1 ./pants tests/python/twitter/your_tests/BUILD:your_tests
  Build operating on targets: OrderedSet([PythonTests(tests/python/twitter/your_tests/BUILD:your_tests)])
  ============================================================ test session starts ============================================================
  platform darwin -- Python 2.6.7 -- pytest-2.3.5
  collected 15 items:

  tests/python/twitter/your_tests/module1_test.py ....
  tests/python/twitter/your_tests/module2_test.py ....
  tests/python/twitter/your_tests/module3_test.py ....
  ---------------------------------------------- coverage: platform darwin, python 2.6.7-final-0 ----------------------------------------------
  Name                                                                                                     Stmts   Miss Branch BrMiss  Cover
  ------------------------------------------------------------------------------------------------------------------------------------------
  /private/var/folders/p0/ztm93vq94qzfc1nyfkq_4l7r0000gn/T/tmp6BcJ1r/twitter/your_namespace/__init__           0      0      0      0   100%
  /private/var/folders/p0/ztm93vq94qzfc1nyfkq_4l7r0000gn/T/tmp6BcJ1r/twitter/your_namespace/module1           62     62      8      8     0%
  /private/var/folders/p0/ztm93vq94qzfc1nyfkq_4l7r0000gn/T/tmp6BcJ1r/twitter/your_namespace/module2           34      6      6      0    85%
  /private/var/folders/p0/ztm93vq94qzfc1nyfkq_4l7r0000gn/T/tmp6BcJ1r/twitter/your_namespace/module3          170    170     51     51     0%
  ------------------------------------------------------------------------------------------------------------------------------------------
  TOTAL                                                                                                      266    238     57     59    11%
  Coverage HTML written to dir /Users/your_username/workspace/science/dist/coverage/tests/python/twitter/your_tests
  ========================================================= 15 passed in 2.07 seconds =========================================================
  tests.python.twitter.your_tests.your_tests                                    .....   SUCCESS


Interactve Debugging on Test Failure
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Passing `--pdb` to your test build will invoke the Python debugger if one of the tests fails. This can be useful for
inspecting the stat of objects especially if you are mocking interfaces.

Using Other Testing Frameworks
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Although most tests can run under `pytest`, if you need to use a different testing framework, you
can. Set the `entry_point` keyword argument when calling python_tests::

  python_tests(
    name = 'tests',
    sources = [],
    dependencies = [
      pants('src/python/twitter/infraops/supplybird:supplybird-lib'),
      pants('3rdparty/python:mock')
    ],
    entry_point="twitter.infraops.supplybird.core.run_tests"
  )

The `entry_point` should exit with a non-zero status if there are any test failures.

Keep in mind, however, that much of the above documentation assumes you are using `pytest`.

Manipulating PEX behavior with environment variables
----------------------------------------------------

Given a PEX file, it is possible to alter its default behavior during invocation.

PEX_INTERPRETER=1
^^^^^^^^^^^^^^^^^

If you have a PEX file with a prescribed executable source or `entry_point` specified, it may still
occasionally be useful to drop into an interpreter with the environment bootstrapped.  If you
set `PEX_INTERPRETER=1` in your environment, the PEX bootstrapper will skip any execution and instead
launch an interactive interpreter session.


PEX_VERBOSE=1
^^^^^^^^^^^^^

If your environment is failing to bootstrap or simply bootstrapping very slowly, it can be useful to
set `PEX_VERBOSE=1` in your environment to get debugging output printed to the console.  Debugging output
includes:

1. Fetched dependencies
2. Built dependencies
3. Activated dependencies
4. Packages scrubbed out of `sys.path`
5. The `sys.path` used to launch the interpreter

PEX_MODULE=entry_point
^^^^^^^^^^^^^^^^^^^^^^

If you have a PEX file without a prescribed entry point, or want to change
the `entry_point` for the duration of a single invocation, you can set
`PEX_MODULE=entry_point` using the same format as described in the
`python_binary` Pants target.

This can be a useful tool for bundling up a number of packages together and
being able to use a single file to execute scripts from each of them.

Another common pattern is to link `pytest` into your PEX file, and run
`PEX_MODULE=pytest my_pex.pex tests/*.py` to run your test suite in its
isolated environment.

PEX_COVERAGE
^^^^^^^^^^^^

There is nascent support for performing code coverage within PEX files by
setting `PEX_COVERAGE=<suffix>`.  By default the coverage files will be written
into the current working directory with the file pattern `.coverage.<suffix>`.  This
requires that the `coverage` Python module has been linked into your PEX.

You can then combine the coverage files by running `PEX_MODULE=coverage
my_pex.pex .coverage.suffix*` and run a report using `PEX_MODULE=coverage
my_pex.pex report`.  Since PEX files are just zip files, `coverage` is able
to understand and extract source and line numbers from them in order to
produce coverage reports.


How PEX files work
------------------

the utility of zipimport and `__main__.py`
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

As an aside, in Python, you may not know that you can import code from directories:

.. code-block:: bash
                
  $ mkdir -p foo
  $ touch foo/__init__.py
  $ echo "print 'spam'" > foo/bar.py
  $ python -c 'import foo.bar'
  spam


All that is necessary is the presence of `__init__.py` to signal to the importer that we
are dealing with a package.  Similarly, a directory can be made "executable":

.. code-block:: bash

  $ echo "print 'i like flowers'" > foo/__main__.py
  $ python foo
  i like flowers


And because the `zipimport` module now provides a default import hook for
Pythons >= 2.4, if the Python import framework sees a zip file, with the
inclusion of a proper `__init__.py`, it can be treated similarly to a
directory.  But since a directory can be executable, if we just drop a
`__main__.py` into a zip file, it suddenly becomes executable:

.. code-block:: bash

  $ pushd foo && zip /tmp/flower.zip __main__.py && popd
  /tmp/foo /tmp
    adding: __main__.py (stored 0%)
  /tmp
  $ python flower.zip
  i like flowers

And since zip files don't actually start until the zip magic number, you can
embed arbitrary strings at the beginning of them and they're still valid
zips.  Hence simple PEX files are born:

.. code-block:: bash

  $ echo '#!/usr/bin/env python2.6' > flower.pex && cat flower.zip >> flower.pex
  $ chmod +x flower.pex
  $ ./flower.pex
  i like flowers


Remember `pants.pex`?

.. code-block:: bash
                
  $ unzip -l pants.pex | tail -2
  warning [pants.pex]:  25 extra bytes at beginning or within zipfile
    (attempting to process anyway)
   --------                   -------
    7900812                   543 files

  $ head -c 25 pants.pex
  #!/usr/bin/env python2.6

PEX `__main__.py`
^^^^^^^^^^^^^^^^^

The `__main__.py` in a real PEX file is somewhat special::

  import os
  import sys

  __entry_point__ = None
  if '__file__' in locals() and __file__ is not None:
    __entry_point__ = os.path.dirname(__file__)
  elif '__loader__' in locals():
    from pkgutil import ImpLoader
    if hasattr(__loader__, 'archive'):
      __entry_point__ = __loader__.archive
    elif isinstance(__loader__, ImpLoader):
      __entry_point__ = os.path.dirname(__loader__.get_filename())

  if __entry_point__ is None:
    sys.stderr.write('Could not launch python executable!\n')
    sys.exit(2)

  sys.path.insert(0, os.path.join(__entry_point__, '.bootstrap'))

  from twitter.common.python.importer import monkeypatch
  monkeypatch()
  del monkeypatch

  from twitter.common.python.pex import PEX
  PEX(__entry_point__).execute()

`PEX` is just a class that manages requirements (often embedded within PEX
files as egg distributions in the `.deps` directory) and autoimports them
into the `sys.path`, then executes a prescribed entry point.

If you read the code closely, you'll notice that it relies upon monkeypatching `zipimport`.  Inside
the `twitter.common.python` library we've provided a recursive zip importer derived from Google's
`pure Python zipimport <http://code.google.com/appengine/articles/django10_zipimport.html>`_ module
that allows for depending upon eggs within eggs or zips (and so forth) so that PEX files need not
extract egg dependencies to disk a priori.  This even extends to C extensions (.so and .dylib
files) which are written to disk long enough to be dlopened before being unlinked.

Strictly speaking this monkeypatching is not necessary and we may consider
making that optional.

Advanced Pants/PEX features
---------------------------

TODO: converting python_library targets to eggs

TODO: auto dependency resolution from within PEX files

TODO: dynamically self-updating PEX files

TODO: tailoring your dependency resolution environment with pants.ini, including local cheeseshop mirrors

This package contains the resources file SystemProperties.class compiled from SystemProperties.java
with:

``` console
javac -source 1.2 -target 1.1 SystemProperties.java
```

This is used by the python Distribution class in this package to test the java distribution version
in a controlled manner as well as provide the java system properties as a python dict.

[Pants documentation](http://pantsbuild.github.io/python-readme.html) has moved...
[Pants documentation](http://pantsbuild.github.io/) has moved...
We use these thrift files to test the 'namespace packages' functionality
in python_thrift_library:

Python does not normally allow the contents of a package to be retrieved from
more than one location. If two modules on the pythonpath share some package
prefix (in our case two python_thrift_library eggs containing two different
modules under 'twitter.birds') then python will only consider the first location
at which it finds that package prefix. Namespace packages solve this by adding
some magic words to the __init__.py files in the intermediate modules.

// =================================================================================================
// Copyright 2011 Twitter, Inc.
// -------------------------------------------------------------------------------------------------
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this work except in compliance with the License.
// You may obtain a copy of the License in the LICENSE file, or at:
//
//  http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
// =================================================================================================

namespace java com.twitter.thrift.descriptors
#@namespace scala com.twitter.thrift.descriptors.thriftscala
namespace py gen.twitter.thrift.descriptors
namespace rb Thriftutils.Descriptors

// Descriptors for all the various entities defined in a thrift file: types, services etc.
// These can be populated by a thrift file parser and then passed as template arguments
// to code generators.
//
// The descriptors are pretty self-explanatory, and so have minimal comments. The only tricky
// part is how recursive types are represented, which is explained in detail below.


/* Headers. */

struct Include {
  1: required string path
}

struct Namespace {
  1: required string language,
  2: required string name
}

struct Annotation {
  1: required string key,
  2: required string value
}

/* Types. */

enum SimpleBaseType {
  BOOL = 0,
  BYTE = 1,
  I16 = 2,
  I32 = 3,
  I64 = 4,
  DOUBLE = 5,
  STRING = 6,
  BINARY = 7
}

struct BaseType {
  1: required SimpleBaseType simpleBaseType,
  99: optional list<Annotation> annotations = []
}

// Thrift struct definitions cannot be recursive, so container types cannot contain
// their element types directly. Instead they indirect via a type id that can be
// dereferenced from a TypeRegistry.
// Note that type ids are opaque, not durable, and can change from parse to parse.

struct ListType {
  1: required string elementTypeId
}

struct SetType {
  1: required string elementTypeId
}

struct MapType {
  1: required string keyTypeId,
  2: required string valueTypeId
}

// Exactly one of these must be present. In languages with support for 'union' (currently
// Java and Ruby) this will be enforced automatically. In other languages this is just a
// regular struct, and we enforce the union constraint in code.
// TODO: Add Python support for 'union' in the Thrift compiler.
union SimpleContainerType {
  1: ListType listType,
  2: SetType setType,
  3: MapType mapType
}

struct ContainerType {
  1: required SimpleContainerType simpleContainerType,
  99: optional list<Annotation> annotations = []
}

// A reference to a type by its name or typedef'd alias.
struct Typeref {
  1: required string typeAlias
}

// Exactly one of these must be present. In languages with support for 'union' (currently
// Java and Ruby) this will be enforced automatically. In other languages this is just a
// regular struct, and we enforce the union constraint in code.
// TODO: Add Python support for 'union' in the Thrift compiler.
union SimpleType {
  1: BaseType baseType,
  2: ContainerType containerType,
  3: Typeref typeref
}

struct Type {
  1: required string id,
  2: required SimpleType simpleType
}

struct Typedef {
  1: required string typeId,
  2: required string typeAlias
}

// A registry of all the types referenced in a thrift program.
//
// Note that identical types are not unique: E.g., two different mentions of list<string>
// will get two different type ids. This is necessary, since types can be annotated.
struct TypeRegistry {
  // A map from id to type. Used to resolve type ids, e.g., in container types.
  // Note that type ids are opaque, not durable, and can change from parse to parse.
  1: map<string, Type> idToType,

  // A map from alias to type id. Aliases are created using typedef.
  2: map<string, string> aliasToTypeId
}


/* Constants. */

struct Const {
  1: required string typeId,
  2: required string name,
  3: required string value
}


/* Enumerations. */

struct EnumElement {
  1: required string name,
  2: required i32 value
}

struct Enum {
  1: required string name,
  2: required list<EnumElement> elements
}


/* Structs, unions and exceptions. */

enum Requiredness {
  REQUIRED = 0,
  OPTIONAL = 1
}

struct Field {
  1: required i16 identifier,
  2: required string name,
  3: required string typeId,
  4: optional Requiredness requiredness,
  5: optional string defaultValue,
  99: optional list<Annotation> annotations = []
}

struct Struct {
  1: required string name,
  2: required list<Field> fields,
  99: optional list<Annotation> annotations = []
}

struct Union {
  1: required string name,
  2: required list<Field> fields,
  99: optional list<Annotation> annotations = []
}

struct Exception {
  1: required string name,
  2: required list<Field> fields
}


/* Services. */

struct Function {
  1: required string name,
  2: optional string returnTypeId,  // Unspecified means void.
  3: optional bool oneWay = 0,  // Thrift doesn't allow 'false'/'true' when specifying the default.
  4: required list<Field> argz,
  5: required list<Field> throwz
}

struct Service {
  1: required string name,
  2: optional string extendz,
  3: required list<Function> functions
}


// In the Thrift parsing code the collection of all elements in a .thrift file
// is referred to as a 'program'.
struct Program {
  1: optional list<Namespace> namespaces = [],
  2: optional list<Include> includes = [],
  3: optional list<Const> constants = [],
  4: optional list<Enum> enums = [],
  5: optional list<Typedef> typedefs = [],
  6: optional list<Struct> structs = [],
  7: optional list<Union> unions = [],
  8: optional list<Exception> exceptions = [],
  9: optional list<Service> services = [],

  // A registry of all types in the program. Used for resolving type references.
  98: required TypeRegistry typeRegistry
}

This directory contains various versions of the apache scribe project thrift interface.  We do not
maintain the checked in thrift IDL files, we just import them from released versions of scribe to
provide a dependency jar for science and twitter via maven.

Testing ConsoleRunner and other classes in src/java/com/twitter/common/junit/runner
is non-trivial because of bootstrapping issues. It should become somewhat easier
in the future, but in the mean time, here are the steps one needs to perform
if they change anything under src/java/com/twitter/common/junit/runner:

I.) On the dev branch:
1) Publish to the local maven cache
$ yes | ./pants goal clean-all publish --no-publish-dryrun src/java/com/twitter/common/junit/runner --publish-local=~/.m2/repository

< lots of output... >

published junit-runner to /home/jsirois/.m2/repository/com/twitter/common/junit-runner/0.0.32-SNAPSHOT/junit-runner-0.0.32-SNAPSHOT.jar
published junit-runner to /home/jsirois/.m2/repository/com/twitter/common/junit-runner/0.0.32-SNAPSHOT/junit-runner-0.0.32-SNAPSHOT.pom
published junit-runner to /home/jsirois/.m2/repository/com/twitter/common/junit-runner/0.0.32-SNAPSHOT/junit-runner-0.0.32-SNAPSHOT-sources.jar
published junit-runner to /home/jsirois/.m2/repository/com/twitter/common/junit-runner/0.0.32-SNAPSHOT/junit-runner-0.0.32-SNAPSHOT-javadoc.jar
published ivy to /home/jsirois/.m2/repository/com/twitter/common/junit-runner/0.0.32-SNAPSHOT/ivy-0.0.32-SNAPSHOT.xml

2) Edit the profile ivy.xml to pick up the local SNAPSHOT you created in 1,
so that the end result looks like (modulo concrete rev numbers):

$ git diff 
diff --git a/build-support/profiles/junit.ivy.xml b/build-support/profiles/junit.ivy.xml
index c33ab3e..86f4197 100644
--- a/build-support/profiles/junit.ivy.xml
+++ b/build-support/profiles/junit.ivy.xml
@@ -27,6 +27,6 @@ limitations under the License.
   <dependencies>
     <dependency org="junit" name="junit-dep" rev="4.10"/>
     <dependency org="org.hamcrest" name="hamcrest-core" rev="1.2"/>
-    <dependency org="com.twitter.common" name="junit-runner" rev="0.0.31"/>
+    <dependency org="com.twitter.common" name="junit-runner" rev="0.0.32-SNAPSHOT" changing="true"/>
   </dependencies>
 </ivy-module>

3) Kill the profile cache so this get picked up
$ rm -rf build-support/profiles/junit.libs*

As you edit the source files, you repeat steps 1 and 3 to re-publish and pick up the change.

II.) Revert the change made in I-2 above, mark with @Ignore the tests that rely on
code changes in the runner (or the entire test class), and submit changes from I
to master

III.) The operation below should be done on MASTER. Publish a jar with:

1) git checkout master; git pull

2) dry run:
./pants goal clean-all publish src/java/com/twitter/common/junit/runner

3) looks ok? do it:
yes | ./pants goal publish --no-publish-dryrun src/java/com/twitter/common/junit/runner

IV.) Switch back to a dev branch. Make a change that bumps the revision number in
build-support/profiles/junit.ivy.xml and un-@Ignores any tests temporarily ignored in step I.

All thrift test data files in this directory licensed to the Apache Software Foundation are taken
from the thrift project test thrift files here: http://svn.apache.org/repos/asf/thrift/trunk/test/.

