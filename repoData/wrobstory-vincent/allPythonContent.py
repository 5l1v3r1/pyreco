__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# vincent documentation build configuration file, created by
# sphinx-quickstart on Fri May 24 02:28:04 2013.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

# Use a better theme for the docs
html_theme = 'bootstrap'
html_theme_path = ['themes']

# (Optional) Logo. Should be exactly 24x24 px to fit the nav. bar.
# Path should be relative to the static files directory.
#html_logo = "vincent.jpg"

# Theme options are theme-specific and customize the look and feel of a
# theme further.
html_theme_options = {
    # Global TOC depth for "site" navbar tab. (Default: 1)
    # Switching to -1 shows all levels.
    'globaltoc_depth': 2,

    # HTML navbar class (Default: "navbar") to attach to <div> element.
    # For black navbar, do "navbar navbar-inverse"
    #'navbar_class': "navbar navbar-inverse",

    # Bootswatch (http://bootswatch.com/) theme.
    'bootswatch_theme': 'spacelab',
    #
    # Options are nothing with "" (default) or the name of a valid theme
    # such as "amelia" or "cosmo".
    #
    # Note that this is served off CDN, so won't be available offline.
    #'bootswatch_theme': "spacelab",
}

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('../../vincent'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.doctest', 'sphinx.ext.mathjax']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = 'Vincent'
copyright = '2013, Rob Story, Dan Miller, et. al.'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.4'
# The full version, including alpha/beta/rc tags.
release = '0.4'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
#html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'vincentdoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'vincent.tex', 'vincent Documentation',
   'Rob Story, Dan Miller, et. al.', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'vincent', 'vincent Documentation',
     ['Rob Story, Dan Miller, et. al.'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'vincent', 'vincent Documentation',
   'Rob Story, Dan Miller, et. al.', 'vincent', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False

from sphinx.ext import autodoc


class FieldPropertyDocumenter(autodoc.AttributeDocumenter):
    objtype = "field"

    #do not indent the content
    content_indent = '            '

    #do not add a header to the docstring
    def add_directive_header(self, sig):
        self.add_line('**' + self.name.split('.')[-1] + '**', '<autodoc>')
        self.add_line('        .. rst-class:: field-property', '<autodoc>')

    def add_content(self, more_content, no_docstring=False):
        autodoc.AttributeDocumenter.add_content(
            self, more_content, no_docstring=False)


def setup(app):
    app.add_autodocumenter(FieldPropertyDocumenter)

########NEW FILE########
__FILENAME__ = area_chart_examples
# -*- coding: utf-8 -*-
"""

Vincent Area Examples

"""

#Build an Area Chart from scratch

from vincent import *
import pandas.io.data as web
all_data = {}
for ticker in ['AAPL', 'GOOG', 'IBM', 'YHOO', 'MSFT']:
    all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2010', '1/1/2013')
price = pd.DataFrame({tic: data['Adj Close']
                      for tic, data in all_data.items()})

vis = Visualization(width=500, height=300)
vis.padding = {'top': 10, 'left': 50, 'bottom': 50, 'right': 100}
vis.scales['x'] = Scale(name='x', type='time', range='width',
                        domain=DataRef(data='table', field="data.idx"))
vis.scales['y'] = Scale(name='y', range='height', type='linear', nice=True,
                        domain=DataRef(data='table', field="data.val"))
vis.scales['color'] = Scale(name='color', type='ordinal',
                            domain=DataRef(data='table', field='data.col'),
                            range='category20')
vis.axes.extend([Axis(type='x', scale='x'),
                 Axis(type='y', scale='y')])

#Marks
transform = MarkRef(data='table',
                    transform=[Transform(type='facet', keys=['data.col'])])
enter_props = PropertySet(x=ValueRef(scale='x', field="data.idx"),
                          y=ValueRef(scale='y', field="data.val"),
                          interpolate=ValueRef(value='monotone'),
                          y2=ValueRef(value=0, scale='y'),
                          fill=ValueRef(scale='color', field='data.col'))
mark = Mark(type='group', from_=transform,
            marks=[Mark(type='area',
            properties=MarkProperties(enter=enter_props))])
vis.marks.append(mark)

data = Data.from_pandas(price['AAPL'])

#Using a Vincent Keyed List here
vis.data['table'] = data
vis.axis_titles(x='Date', y='AAPL Price')
vis.to_json('vega.json')

#Convenience method

vis = Area(price['AAPL'])
vis.axis_titles(x='Date', y='AAPL Price')
vis.to_json('vega.json')

########NEW FILE########
__FILENAME__ = bar_chart_examples
# -*- coding: utf-8 -*-
"""

Vincent Bar Chart Example

"""

#Build a Bar Chart from scratch

from vincent import *
import pandas as pd

farm_1 = {'apples': 10, 'berries': 32, 'squash': 21, 'melons': 13, 'corn': 18}
farm_2 = {'apples': 15, 'berries': 43, 'squash': 17, 'melons': 10, 'corn': 22}
farm_3 = {'apples': 6, 'berries': 24, 'squash': 22, 'melons': 16, 'corn': 30}
farm_4 = {'apples': 12, 'berries': 30, 'squash': 15, 'melons': 9, 'corn': 15}

data = [farm_1, farm_2, farm_3, farm_4]
index = ['Farm 1', 'Farm 2', 'Farm 3', 'Farm 4']

df = pd.DataFrame(data, index=index)

vis = Visualization(width=500, height=300)
vis.scales['x'] = Scale(name='x', type='ordinal', range='width',
                        domain=DataRef(data='table', field="data.idx"))
vis.scales['y'] = Scale(name='y', range='height', nice=True,
                        domain=DataRef(data='table', field="data.val"))
vis.axes.extend([Axis(type='x', scale='x'),
                 Axis(type='y', scale='y')])

#Marks
enter_props = PropertySet(x=ValueRef(scale='x', field="data.idx"),
                          y=ValueRef(scale='y', field="data.val"),
                          width=ValueRef(scale='x', band=True, offset=-1),
                          y2=ValueRef(scale='y', value=0))

update_props = PropertySet(fill=ValueRef(value='steelblue'))

mark = Mark(type='rect', from_=MarkRef(data='table'),
            properties=MarkProperties(enter=enter_props,
                                      update=update_props))
vis.marks.append(mark)

data = Data.from_pandas(df['apples'])

#Using a Vincent KeyedList here
vis.data['table'] = data
vis.axis_titles(x='Farms', y='Data')
vis.to_json('vega.json')

#Convenience methods

vis = Bar(df['apples'])

#Fruit
trans = df.T
vis = Bar(trans['Farm 1'])

#From dict
vis = Bar(farm_1)

#From dict of iterables
vis = Bar({'x': ['apples', 'berries', 'squash', 'melons', 'corn'],
           'y': [10, 32, 21, 13, 18]}, iter_idx='x')

#Finally, a boring bar chart from a list
vis = Bar([10, 20, 30, 15, 35, 10, 20])

########NEW FILE########
__FILENAME__ = grouped_bar_examples
# -*- coding: utf-8 -*-
"""

Vincent Grouped Bar Examples

"""

#Build a Grouped Bar Chart from scratch

import pandas as pd
from vincent import *
from vincent.core import KeyedList

farm_1 = {'apples': 10, 'berries': 32, 'squash': 21, 'melons': 13, 'corn': 18}
farm_2 = {'apples': 15, 'berries': 40, 'squash': 17, 'melons': 10, 'corn': 22}
farm_3 = {'apples': 6, 'berries': 24, 'squash': 22, 'melons': 16, 'corn': 30}
farm_4 = {'apples': 12, 'berries': 30, 'squash': 15, 'melons': 9, 'corn': 15}
farm_5 = {'apples': 20, 'berries': 35, 'squash': 19, 'melons': 17, 'corn': 19}
farm_6 = {'apples': 3, 'berries': 28, 'squash': 21, 'melons': 11, 'corn': 23}

data = [farm_1, farm_2, farm_3, farm_4, farm_5, farm_6]
index = ['Farm 1', 'Farm 2', 'Farm 3', 'Farm 4', 'Farm 5', 'Farm 6']

df = pd.DataFrame(data, index=index)

vis = Visualization(width=500, height=300)
vis.padding = {'top': 10, 'left': 50, 'bottom': 50, 'right': 100}

data = Data.from_pandas(df, grouped=True)
vis.data['table'] = data

vis.scales['x'] = Scale(name='x', type='ordinal', range='width',
                        domain=DataRef(data='table', field="data.idx"),
                        padding=0.2)
vis.scales['y'] = Scale(name='y', range='height', nice=True,
                        domain=DataRef(data='table', field="data.val"))
vis.scales['color'] = Scale(name='color', type='ordinal',
                            domain=DataRef(data='table', field='data.col'),
                            range='category20')
vis.axes.extend([Axis(type='x', scale='x'),
                 Axis(type='y', scale='y')])

enter_props = PropertySet(x=ValueRef(scale='pos', field="data.group"),
                          y=ValueRef(scale='y', field="data.val"),
                          width=ValueRef(scale='pos', band=True, offset=-1),
                          y2=ValueRef(value=0, scale='y'),
                          fill=ValueRef(scale='color', field='data.col'))
mark = Mark(type='group', from_=transform,
            marks=[Mark(type='rect',
            properties=MarkProperties(enter=enter_props))])
vis.marks.append(mark)

#Mark group properties
facet = Transform(type='facet', keys=['data.idx'])
transform = MarkRef(data='table',transform=[facet])
group_props = PropertySet(x=ValueRef(scale='x', field="key"),
                                     width=ValueRef(scale='x', band=True))
vis.marks[0].properties = MarkProperties(enter=group_props)
vis.marks[0].scales = KeyedList()
vis.marks[0].scales['pos'] = Scale(name='pos', type='ordinal',
                                   range='width',
                                   domain=DataRef(field='data.group'))

vis.axis_titles(x='Farms', y='Total Produce')
vis.legend(title='Produce Type')
vis.to_json('vega.json')

#Convenience method
vis = GroupedBar(df)
vis.axis_titles(x='Farms', y='Total Produce')
vis.width = 700
vis.legend(title='Produce Type')
vis.colors(brew='Pastel1')
vis.to_json('vega.json')

########NEW FILE########
__FILENAME__ = line_chart_examples
# -*- coding: utf-8 -*-
"""

Vincent Line Examples

"""

#Build a Line Chart from scratch

from vincent import *
import pandas as pd
import pandas.io.data as web
import datetime
all_data = {}
date_start = datetime.datetime(2010, 1, 1)
date_end = datetime.datetime(2014, 1, 1)
for ticker in ['AAPL', 'IBM', 'YHOO', 'MSFT']:
    all_data[ticker] = web.DataReader(ticker, 'yahoo', date_start, date_end)
price = pd.DataFrame({tic: data['Adj Close']
                      for tic, data in all_data.items()})


#Note that we're using timeseries, so x-scale type is "time". For non
#timeseries data, use "linear"
vis = Visualization(width=500, height=300)
vis.scales['x'] = Scale(name='x', type='time', range='width',
                        domain=DataRef(data='table', field="data.idx"))
vis.scales['y'] = Scale(name='y', range='height', type='linear', nice=True,
                        domain=DataRef(data='table', field="data.val"))
vis.scales['color'] = Scale(name='color', type='ordinal',
                            domain=DataRef(data='table', field='data.col'),
                            range='category20')
vis.axes.extend([Axis(type='x', scale='x'),
                 Axis(type='y', scale='y')])

#Marks
transform = MarkRef(data='table',
                    transform=[Transform(type='facet', keys=['data.col'])])
enter_props = PropertySet(x=ValueRef(scale='x', field="data.idx"),
                          y=ValueRef(scale='y', field="data.val"),
                          stroke=ValueRef(scale="color", field='data.col'),
                          stroke_width=ValueRef(value=2))
mark = Mark(type='group', from_=transform,
            marks=[Mark(type='line',
            properties=MarkProperties(enter=enter_props))])
vis.marks.append(mark)

data = Data.from_pandas(price)

#Using a Vincent Keyed List here
vis.data['table'] = data
vis.axis_titles(x='Date', y='Price')
vis.legend(title='Tech Stocks')
vis.to_json('vega.json')

#Convenience method

vis = Line(price)
vis.axis_titles(x='Date', y='Price')
vis.legend(title='Tech Stocks')
vis.colors(brew='Set1')
vis.to_json('vega.json', html_out=True)

########NEW FILE########
__FILENAME__ = map_examples
# -*- coding: utf-8 -*-
"""

Vincent Map Examples

"""

#Build a map from scratch

from vincent import *

world_topo = r'world-countries.topo.json'
state_topo = r'us_states.topo.json'
lake_topo = r'lakes_50m.topo.json'
county_geo = r'us_counties.geo.json'
county_topo = r'us_counties.topo.json'
or_topo = r'or_counties.topo.json'

vis = Visualization(width=960, height=500)
vis.data['countries'] = Data(
    name='countries',
    url=world_topo,
    format={'type': 'topojson', 'feature': 'world-countries'}
    )

geo_transform = Transform(
                type='geopath', value="data", projection='winkel3', scale=200,
                translate=[480, 250]
                )

geo_from = MarkRef(data='countries', transform=[geo_transform])

enter_props = PropertySet(
    stroke=ValueRef(value='#000000'),
    path=ValueRef(field='path')
    )

update_props = PropertySet(fill=ValueRef(value='steelblue'))

mark_props = MarkProperties(enter=enter_props, update=update_props)

vis.marks.append(
    Mark(type='path', from_=geo_from, properties=mark_props)
    )

vis.to_json('vega.json')

#Convenience Method

geo_data = [{'name': 'countries',
             'url': world_topo,
             'feature': 'world-countries'}]

vis = Map(geo_data=geo_data, scale=200)
vis.to_json('vega.json')

#States & Counties

geo_data = [{'name': 'counties',
             'url': county_topo,
             'feature': 'us_counties.geo'},
            {'name': 'states',
             'url': state_topo,
             'feature': 'us_states.geo'}
             ]

vis = Map(geo_data=geo_data, scale=1000, projection='albersUsa')
del vis.marks[1].properties.update
vis.marks[0].properties.update.fill.value = '#084081'
vis.marks[1].properties.enter.stroke.value = '#fff'
vis.marks[0].properties.enter.stroke.value = '#7bccc4'
vis.to_json('vega.json')

#Choropleth
import json
import pandas as pd
#Map the county codes we have in our geometry to those in the
#county_data file, which contains additional rows we don't need
with open('us_counties.topo.json', 'r') as f:
    get_id = json.load(f)

#A little FIPS code munging
new_geoms = []
for geom in get_id['objects']['us_counties.geo']['geometries']:
    geom['properties']['FIPS'] = int(geom['properties']['FIPS'])
    new_geoms.append(geom)

get_id['objects']['us_counties.geo']['geometries'] = new_geoms

with open('us_counties.topo.json', 'w') as f:
    json.dump(get_id, f)

#Grab the FIPS codes and load them into a dataframe
geometries = get_id['objects']['us_counties.geo']['geometries']
county_codes = [x['properties']['FIPS'] for x in geometries]
county_df = pd.DataFrame({'FIPS': county_codes}, dtype=str)
county_df = county_df.astype(int)

#Read into Dataframe, cast to int for consistency
df = pd.read_csv('data/us_county_data.csv', na_values=[' '])
df['FIPS'] = df['FIPS'].astype(int)

#Perform an inner join, pad NA's with data from nearest county
merged = pd.merge(df, county_df, on='FIPS', how='inner')
merged = merged.fillna(method='pad')

geo_data = [{'name': 'counties',
             'url': county_topo,
             'feature': 'us_counties.geo'}]

vis = Map(data=merged, geo_data=geo_data, scale=1100, projection='albersUsa',
          data_bind='Employed_2011', data_key='FIPS',
          map_key={'counties': 'properties.FIPS'})
vis.marks[0].properties.enter.stroke_opacity = ValueRef(value=0.5)
#Change our domain for an even inteager
vis.scales['color'].domain = [0, 189000]
vis.legend(title='Number Employed 2011')
vis.to_json('vega.json')

#Lets look at different stats
vis.rebind(column='Civilian_labor_force_2011', brew='BuPu')
vis.to_json('vega.json')

vis.rebind(column='Unemployed_2011', brew='PuBu')
vis.to_json('vega.json')

vis.rebind(column='Unemployment_rate_2011', brew='YlGnBu')
vis.to_json('vega.json')

vis.rebind(column='Median_Household_Income_2011', brew='RdPu')
vis.to_json('vega.json')

#Mapping US State Level Data

state_data = pd.read_csv('data/US_Unemployment_Oct2012.csv')
geo_data = [{'name': 'states',
             'url': state_topo,
             'feature': 'us_states.geo'}]
vis = Map(data=state_data, geo_data=geo_data, scale=1000,
          projection='albersUsa', data_bind='Unemployment', data_key='NAME',
          map_key={'states': 'properties.NAME'})
vis.legend(title='Unemployment (%)')
vis.to_json('vega.json')

#Iterating State Level Data
yoy = pd.read_table('data/State_Unemp_YoY.txt', delim_whitespace=True)
#Standardize State names to match TopoJSON for keying
names = []
for row in yoy.iterrows():
    pieces = row[1]['NAME'].split('_')
    together = ' '.join(pieces)
    names.append(together.title())
yoy['NAME'] = names
geo_data = [{'name': 'states',
             'url': state_topo,
             'feature': 'us_states.geo'}]
vis = Map(data=yoy, geo_data=geo_data, scale=1000,
          projection='albersUsa', data_bind='AUG_2012', data_key='NAME',
          map_key={'states': 'properties.NAME'}, brew='YlGnBu')
#Custom threshold scale
vis.scales[0].type='threshold'
vis.scales[0].domain = [0, 2, 4, 6, 8, 10, 12]
vis.legend(title='Unemployment (%)')
vis.to_json('vega.json')

#Rebind and set our scale again
vis.rebind(column='AUG_2013', brew='YlGnBu')
vis.scales[0].type='threshold'
vis.scales[0].domain = [0, 2, 4, 6, 8, 10, 12]
vis.to_json('vega.json')

vis.rebind(column='CHANGE', brew='YlGnBu')
vis.scales[0].type='threshold'
vis.scales[0].domain = [-1.5, -1.3, -1.1, 0, 0.1, 0.3, 0.5, 0.8]
vis.legends[0].title = "YoY Change in Unemployment (%)"
vis.to_json('vega.json')


#Oregon County-level population data
or_data = pd.read_table('data/OR_County_Data.txt', delim_whitespace=True)
or_data['July_2012_Pop']= or_data['July_2012_Pop'].astype(int)
#Standardize keys
with open('or_counties.topo.json', 'r') as f:
    counties = json.load(f)

def split_county(name):
    parts = name.split(' ')
    parts.pop(-1)
    return ''.join(parts).upper()

#A little FIPS code munging
new_geoms = []
for geom in counties['objects']['or_counties.geo']['geometries']:
    geom['properties']['COUNTY'] = split_county(geom['properties']['COUNTY'])
    new_geoms.append(geom)

counties['objects']['or_counties.geo']['geometries'] = new_geoms

with open('or_counties.topo.json', 'w') as f:
    json.dump(counties, f)

geo_data = [{'name': 'states',
             'url': state_topo,
             'feature': 'us_states.geo'},
            {'name': 'or_counties',
             'url': or_topo,
             'feature': 'or_counties.geo'}]

vis = Map(data=or_data, geo_data=geo_data, scale=3700,
          translate=[1480, 830],
          projection='albersUsa', data_bind='July_2012_Pop', data_key='NAME',
          map_key={'or_counties': 'properties.COUNTY'})
vis.marks[0].properties.update.fill.value = '#c2c2c2'
vis.to_json('vega.json')


########NEW FILE########
__FILENAME__ = pie_chart_example
# -*- coding: utf-8 -*-
"""

Vincent Pie Chart Example

"""

#Build a Pie Chart from scratch


from vincent import *

farm_1 = {'apples': 10, 'berries': 32, 'squash': 21, 'melons': 13, 'corn': 18}

vis = Visualization(width=960, height=500)
outer_radius = min(vis.width, vis.height)/2
inner_radius = 0
data = Data.from_iter(farm_1)
vis.data['table'] = data

vis.scales["color"] = Scale(
    name="color", type="ordinal", range="category10",
    domain=DataRef(data="table", field="data.idx"))

transform = MarkRef(
    data="table", transform=[Transform(type="pie", value="data.val")])

enter_props = PropertySet(
    x=ValueRef(group="width", mult=0.5),
    y=ValueRef(group="height", mult=0.5),
    start_angle=ValueRef(field="startAngle"),
    end_angle=ValueRef(field="endAngle"),
    inner_radius=ValueRef(value=inner_radius),
    outer_radius=ValueRef(value=outer_radius),
    stroke=ValueRef(value="white"),
    fill=ValueRef(scale="color", field="data.idx"))

mark = Mark(type="arc", from_=transform,
            properties=MarkProperties(enter=enter_props))

vis.marks.append(mark)
vis.legend('Farm 1 Fruit')
vis.to_json('vega.json')

#Convenience method
vis = vincent.Pie(farm_1)
vis.legend('Farm 1 Fruit')
vis.to_json('vega.json')

#Donut chart, different colors
vis = vincent.Pie(farm_1, inner_radius=200)
vis.colors(brew="Set2")
vis.legend('Farm 1 Fruit')
vis.to_json('vega.json')
########NEW FILE########
__FILENAME__ = scatter_chart_examples
# -*- coding: utf-8 -*-
"""

Vincent Scatter Examples

"""

#Build a Line Chart from scratch

from vincent import *
import pandas as pd
import pandas.io.data as web
import datetime
all_data = {}
date_start = datetime.datetime(2010, 1, 1)
date_end = datetime.datetime(2014, 1, 1)
for ticker in ['AAPL', 'IBM', 'YHOO', 'MSFT']:
    all_data[ticker] = web.DataReader(ticker, 'yahoo', date_start, date_end)
price = pd.DataFrame({tic: data['Adj Close']
                      for tic, data in all_data.items()})

#Note that we're using timeseries, so x-scale type is "time". For non
#timeseries data, use "linear"
vis = Visualization(width=500, height=300)
vis.scales['x'] = Scale(name='x', type='time', range='width',
                        domain=DataRef(data='table', field="data.idx"))
vis.scales['y'] = Scale(name='y', range='height', type='linear', nice=True,
                        domain=DataRef(data='table', field="data.val"))
vis.scales['color'] = Scale(name='color', type='ordinal',
                            domain=DataRef(data='table', field='data.col'),
                            range='category20')
vis.axes.extend([Axis(type='x', scale='x'),
                 Axis(type='y', scale='y')])

#Marks
transform = MarkRef(data='table',
                    transform=[Transform(type='facet', keys=['data.col'])])
enter_props = PropertySet(x=ValueRef(scale='x', field="data.idx"),
                          y=ValueRef(scale='y', field="data.val"),
                          fill=ValueRef(scale='color', field='data.col'),
                          size=ValueRef(value=10))
mark = Mark(type='group', from_=transform,
            marks=[Mark(type='symbol',
            properties=MarkProperties(enter=enter_props))])
vis.marks.append(mark)

data = Data.from_pandas(price[['MSFT', 'AAPL']])

#Using a Vincent Keyed List here
vis.data['table'] = data
vis.axis_titles(x='Date', y='Price')
vis.legend(title='MSFT vs AAPL')
vis.to_json('vega.json')

#Convenience method

vis = Scatter(price[['MSFT', 'AAPL']])
vis.axis_titles(x='Date', y='Price')
vis.legend(title='MSFT vs AAPL')
vis.colors(brew='RdBu')
vis.to_json('vega.json')

########NEW FILE########
__FILENAME__ = stacked_area_examples
# -*- coding: utf-8 -*-
"""

Vincent Stacked Area Examples

"""

#Build a Stacked Area Chart from scratch

from vincent import *
import pandas as pd
import pandas.io.data as web
all_data = {}
for ticker in ['AAPL', 'GOOG', 'IBM', 'YHOO', 'MSFT']:
    all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2010', '1/1/2013')
price = pd.DataFrame({tic: data['Adj Close']
                      for tic, data in all_data.items()})

vis = Visualization(width=500, height=300)
vis.padding = {'top': 10, 'left': 50, 'bottom': 50, 'right': 100}


data = Data.from_pandas(price)
vis.data['table'] = data
facets = Transform(type='facet', keys=['data.idx'])
stats = Transform(type='stats', value='data.val')
stat_dat = Data(name='stats', source='table', transform=[facets, stats])
vis.data['stats'] = stat_dat


vis.scales['x'] = Scale(name='x', type='time', range='width',
                        domain=DataRef(data='table', field="data.idx"))
vis.scales['y'] = Scale(name='y', range='height', type='linear', nice=True,
                        domain=DataRef(data='stats', field="sum"))
vis.scales['color'] = Scale(name='color', type='ordinal',
                            domain=DataRef(data='table', field='data.col'),
                            range='category20')
vis.axes.extend([Axis(type='x', scale='x'),
                 Axis(type='y', scale='y')])


facet = Transform(type='facet', keys=['data.col'])
stack = Transform(type='stack', point='data.idx', height='data.val')
transform = MarkRef(data='table',transform=[facet, stack])
enter_props = PropertySet(x=ValueRef(scale='x', field="data.idx"),
                          y=ValueRef(scale='y', field="y"),
                          interpolate=ValueRef(value='monotone'),
                          y2=ValueRef(field='y2', scale='y'),
                          fill=ValueRef(scale='color', field='data.col'))
mark = Mark(type='group', from_=transform,
            marks=[Mark(type='area',
            properties=MarkProperties(enter=enter_props))])
vis.marks.append(mark)

vis.axis_titles(x='Date', y='Price')
vis.legend(title='Tech Stocks')
vis.to_json('vega.json')

#Convenience method

vis = StackedArea(price)
vis.axis_titles(x='Date', y='Price')
vis.legend(title='Tech Stocks')
vis.colors(brew='Paired')
vis.to_json('vega.json')

########NEW FILE########
__FILENAME__ = stacked_bar_examples
# -*- coding: utf-8 -*-
"""

Vincent Stacked Bar Examples

"""

#Build a Stacked Bar Chart from scratch

import pandas as pd
from vincent import *

farm_1 = {'apples': 10, 'berries': 32, 'squash': 21, 'melons': 13, 'corn': 18}
farm_2 = {'apples': 15, 'berries': 40, 'squash': 17, 'melons': 10, 'corn': 22}
farm_3 = {'apples': 6, 'berries': 24, 'squash': 22, 'melons': 16, 'corn': 30}
farm_4 = {'apples': 12, 'berries': 30, 'squash': 15, 'melons': 9, 'corn': 15}
farm_5 = {'apples': 20, 'berries': 35, 'squash': 19, 'melons': 17, 'corn': 19}
farm_6 = {'apples': 3, 'berries': 28, 'squash': 21, 'melons': 11, 'corn': 23}

data = [farm_1, farm_2, farm_3, farm_4, farm_5, farm_6]
index = ['Farm 1', 'Farm 2', 'Farm 3', 'Farm 4', 'Farm 5', 'Farm 6']

df = pd.DataFrame(data, index=index)

vis = Visualization(width=500, height=300)
vis.padding = {'top': 10, 'left': 50, 'bottom': 50, 'right': 100}

data = Data.from_pandas(df)
vis.data['table'] = data
facets = Transform(type='facet', keys=['data.idx'])
stats = Transform(type='stats', value='data.val')
stat_dat = Data(name='stats', source='table', transform=[facets, stats])
vis.data['stats'] = stat_dat


vis.scales['x'] = Scale(name='x', type='ordinal', range='width',
                        domain=DataRef(data='table', field="data.idx"))
vis.scales['y'] = Scale(name='y', range='height', type='linear', nice=True,
                        domain=DataRef(data='stats', field="sum"))
vis.scales['color'] = Scale(name='color', type='ordinal',
                            domain=DataRef(data='table', field='data.col'),
                            range='category20')
vis.axes.extend([Axis(type='x', scale='x'),
                 Axis(type='y', scale='y')])


facet = Transform(type='facet', keys=['data.col'])
stack = Transform(type='stack', point='data.idx', height='data.val')
transform = MarkRef(data='table',transform=[facet, stack])
enter_props = PropertySet(x=ValueRef(scale='x', field="data.idx"),
                          y=ValueRef(scale='y', field="y"),
                          width=ValueRef(scale='x', band=True, offset=-1),
                          y2=ValueRef(field='y2', scale='y'),
                          fill=ValueRef(scale='color', field='data.col'))
mark = Mark(type='group', from_=transform,
            marks=[Mark(type='rect',
            properties=MarkProperties(enter=enter_props))])
vis.marks.append(mark)

vis.axis_titles(x='Farms', y='Total Produce')
vis.legend(title='Produce Type')
vis.to_json('vega.json')

#Convenience method
vis = StackedBar(df)
vis.axis_titles(x='Farms', y='Total Produce')
vis.legend(title='Produce Type')
vis.scales['x'].padding = 0.2
vis.colors(brew='Set2')
vis.to_json('vega.json')

########NEW FILE########
__FILENAME__ = test_charts
# -*- coding: utf-8 -*-
"""
Test Vincent.charts
-------------------

Tests for Vincent chart types, which also serve as reference grammar.
"""

import pandas as pd
import nose.tools as nt
from vincent.charts import (data_type, Chart, Bar, Scatter, Line, Area,
                            GroupedBar, Map, Pie, Word)


def chart_runner(chart, scales, axes, marks):
    """Iterate through each chart element for check for contents"""

    for i, scale in enumerate(scales):
        nt.assert_dict_equal(chart.scales[i].grammar(), scale)

    for i, axis in enumerate(axes):
        nt.assert_dict_equal(chart.axes[i].grammar(), axis)

    for i, mark in enumerate(marks):
        nt.assert_dict_equal(chart.marks[i].grammar(), mark)


def test_data_type():
    """Test automatic data type importing"""

    puts1 = [10, 20, 30, 40, 50]
    puts2 = {'apples': 10, 'bananas': 20, 'oranges': 30}

    gets1 = [{'col': 'data', 'idx': 0, 'val': 10},
             {'col': 'data', 'idx': 1, 'val': 20},
             {'col': 'data', 'idx': 2, 'val': 30},
             {'col': 'data', 'idx': 3, 'val': 40},
             {'col': 'data', 'idx': 4, 'val': 50}]
    gets2 = [{'col': 'data', 'idx': 'apples', 'val': 10},
             {'col': 'data', 'idx': 'bananas', 'val': 20},
             {'col': 'data', 'idx': 'oranges', 'val': 30}]

    for ins, outs in zip([puts1, puts2], [gets1, gets2]):
        test = data_type(ins)
        nt.assert_list_equal(test.values, outs)

    # From Iters
    puts = {'x': [1, 2, 3], 'y': [10, 20, 30], 'z': [40, 50, 60]}
    gets = [{'col': 'y', 'idx': 1, 'val': 10},
            {'col': 'y', 'idx': 2, 'val': 20},
            {'col': 'y', 'idx': 3, 'val': 30},
            {'col': 'z', 'idx': 1, 'val': 40},
            {'col': 'z', 'idx': 2, 'val': 50},
            {'col': 'z', 'idx': 3, 'val': 60}]

    test = data_type(puts, iter_idx='x')
    nt.assert_list_equal(test.values, gets)

    # Pandas
    df = pd.DataFrame({'one': [1, 2, 3], 'two': [4, 5, 6]})
    series = pd.Series([1, 2, 3], name='test')
    gets1 = [{'col': 'one', 'idx': 0, 'val': 1},
             {'col': 'two', 'idx': 0, 'val': 4},
             {'col': 'one', 'idx': 1, 'val': 2},
             {'col': 'two', 'idx': 1, 'val': 5},
             {'col': 'one', 'idx': 2, 'val': 3},
             {'col': 'two', 'idx': 2, 'val': 6}]
    gets2 = [{'col': 'test', 'idx': 0, 'val': 1},
             {'col': 'test', 'idx': 1, 'val': 2},
             {'col': 'test', 'idx': 2, 'val': 3}]
    test_df = data_type(df)
    test_series = data_type(series)
    nt.assert_list_equal(test_df.values, gets1)
    nt.assert_list_equal(test_series.values, gets2)

    # Bad type
    class BadType(object):
        'Bad data type'
        pass

    test = BadType()
    nt.assert_raises(ValueError, data_type, test)


class TestChart(object):
    """Test Chart ABC"""

    def test_init(self):
        chart = Chart([0, 1], width=100, height=100)
        nt.assert_equal(chart.width, 100)
        nt.assert_equal(chart.height, 100)
        padding = "auto"
        nt.assert_equal(chart.padding, padding)

        # Data loading errors
        nt.assert_raises(ValueError, Chart)
        nt.assert_raises(ValueError, Chart, [])


class TestScatter(object):
    """Test Scatter Chart"""

    def test_init(self):

        scatter = Scatter([1, 2, 3])

        scales = [{'domain': {'data': 'table', 'field': 'data.idx'},
                   'name': 'x',
                   'range': 'width',
                   'type': 'linear'},
                  {'domain': {'data': 'table', 'field': 'data.val'},
                   'name': 'y',
                   'range': 'height',
                   'nice': True},
                  {'domain': {'data': 'table', 'field': 'data.col'},
                   'name': 'color',
                   'range': 'category20',
                   'type': 'ordinal'}]

        axes = [{'scale': 'x', 'type': 'x'},
                {'scale': 'y', 'type': 'y'}]

        marks = [{
            'type': 'group',
            'from': {
                'data': 'table',
                'transform': [
                    {'keys': ['data.col'], 'type': 'facet'}
                ]
            },
            'marks': [{
                'type': 'symbol',
                'properties': {
                    'enter': {
                        'fill': {'field': 'data.col', 'scale': 'color'},
                        'size': {'value': 100},
                        'x': {'field': 'data.idx', 'scale': 'x'},
                        'y': {'field': 'data.val', 'scale': 'y'}}},
            }]
        }]

        chart_runner(scatter, scales, axes, marks)


class TestLine(object):
    """Test Line Chart"""

    def test_init(self):
        line = Line([1, 2, 3])

        scales = [{'domain': {'data': 'table', 'field': 'data.idx'},
                   'name': 'x',
                   'type': 'linear',
                   'range': 'width'},
                  {'domain': {'data': 'table', 'field': 'data.val'},
                   'name': 'y',
                   'nice': True,
                   'range': 'height'},
                  {'domain': {'data': 'table', 'field': 'data.col'},
                   'name': 'color',
                   'range': 'category20',
                   'type': 'ordinal'}]

        axes = [{'scale': 'x', 'type': 'x'},
                {'scale': 'y', 'type': 'y'}]

        marks = [{
            'type': 'group',
            'from': {
                'data': 'table',
                'transform': [
                    {'keys': ['data.col'], 'type': 'facet'}
                ]
            },
            'marks': [{
                'type': 'line',
                'properties': {
                    'enter': {
                        'stroke': {'field': 'data.col', 'scale': 'color'},
                        'strokeWidth': {'value': 2},
                        'x': {'field': 'data.idx', 'scale': 'x'},
                        'y': {'field': 'data.val', 'scale': 'y'}
                    }
                }
            }]
        }]

        chart_runner(line, scales, axes, marks)


class TestArea(object):
    """Test Area and Stacked Area Chart"""

    def test_init(self):
        area = Area([1, 2, 3])
        stacked_area = Area({'x': [1, 2, 3], 'y': [4, 5, 6], 'z': [7, 8, 9]},
                            iter_idx='x')

        # Test stacked area data
        datas = [
            {'name': 'table',
             'values': [
                 {'col': 'y', 'idx': 1, 'val': 4},
                 {'col': 'y', 'idx': 2, 'val': 5},
                 {'col': 'y', 'idx': 3, 'val': 6},
                 {'col': 'z', 'idx': 1, 'val': 7},
                 {'col': 'z', 'idx': 2, 'val': 8},
                 {'col': 'z', 'idx': 3, 'val': 9}]},
            {'name': 'stats',
             'source': 'table',
             'transform': [
                 {'type': 'facet', 'keys': ['data.idx']},
                 {'type': 'stats', 'value': 'data.val'}]}
        ]

        for i, data in enumerate(datas):
            nt.assert_dict_equal(stacked_area.data[i].grammar(), data)

        # Test area grammar
        scales = [{'domain': {'data': 'table', 'field': 'data.idx'},
                   'name': 'x',
                   'range': 'width',
                   'zero': False,
                   'type': 'linear'},
                  {'domain': {'data': 'stats', 'field': 'sum'},
                   'name': 'y',
                   'nice': True,
                   'range': 'height'},
                  {'domain': {'data': 'table', 'field': 'data.col'},
                   'name': 'color',
                   'range': 'category20',
                   'type': 'ordinal'}]

        axes = [{'scale': 'x', 'type': 'x'},
                {'scale': 'y', 'type': 'y'}]

        marks = [{
            'type': 'group',
            'from': {
                'data': 'table',
                'transform': [
                    {'type': 'facet', 'keys': ['data.col']},
                    {'type': 'stack', 'height': 'data.val',
                     'point': 'data.idx'}]
            },
            'marks': [{
                'type': 'area',
                'properties': {
                    'enter': {
                        'x': {'field': 'data.idx', 'scale': 'x'},
                        'y': {'field': 'y', 'scale': 'y'},
                        'y2': {'field': 'y2', 'scale': 'y'},
                        'fill': {'field': 'data.col', 'scale': 'color'},
                        'interpolate': {'value': 'monotone'}
                    }
                }
            }]
        }]

        chart_runner(area, scales, axes, marks)
        chart_runner(stacked_area, scales, axes, marks)


class TestBar(object):
    """Test Bar and Stacked Bar Chart"""

    def test_init(self):
        bar = Bar([1, 2, 3])
        stacked_bar = Bar({'x': [1, 2, 3], 'y': [4, 5, 6], 'z': [7, 8, 9]},
                          iter_idx='x')

        # Test stacked bar data
        datas = [
            {'name': 'table',
             'values': [
                 {'col': 'y', 'idx': 1, 'val': 4},
                 {'col': 'y', 'idx': 2, 'val': 5},
                 {'col': 'y', 'idx': 3, 'val': 6},
                 {'col': 'z', 'idx': 1, 'val': 7},
                 {'col': 'z', 'idx': 2, 'val': 8},
                 {'col': 'z', 'idx': 3, 'val': 9}]},
            {'name': 'stats',
             'source': 'table',
             'transform': [
                 {'type': 'facet', 'keys': ['data.idx']},
                 {'type': 'stats', 'value': 'data.val'}]}
        ]
        for i, data in enumerate(datas):
            nt.assert_dict_equal(stacked_bar.data[i].grammar(), data)

        # Test bar grammar
        scales = [{'domain': {'data': 'table', 'field': 'data.idx'},
                   'name': 'x',
                   'range': 'width',
                   'zero': False,
                   'type': 'ordinal'},
                  {'domain': {'data': 'stats', 'field': 'sum'},
                   'name': 'y',
                   'nice': True,
                   'range': 'height'},
                  {'domain': {'data': 'table', 'field': 'data.col'},
                   'name': 'color',
                   'range': 'category20',
                   'type': 'ordinal'}]

        axes = [{'scale': 'x', 'type': 'x'},
                {'scale': 'y', 'type': 'y'}]

        marks = [{
            'type': 'group',
            'from': {
                'data': 'table',
                'transform': [
                    {'type': 'facet', 'keys': ['data.col']},
                    {'type': 'stack', 'height': 'data.val',
                     'point': 'data.idx'}]
            },
            'marks': [{
                'type': 'rect',
                'properties': {
                    'enter': {
                        'x': {'field': 'data.idx', 'scale': 'x'},
                        'width': {'band': True, 'offset': -1, 'scale': 'x'},
                        'y': {'field': 'y', 'scale': 'y'},
                        'y2': {'field': 'y2', 'scale': 'y'},
                        'fill': {'field': 'data.col', 'scale': 'color'}
                    }
                }
            }]
        }]

        chart_runner(bar, scales, axes, marks)
        chart_runner(stacked_bar, scales, axes, marks)


class TestGroupedBar(object):
    """Test grouped bar chart"""

    def test_init(self):

        farm_1 = {'apples': 10, 'berries': 32, 'squash': 21}
        farm_2 = {'apples': 15, 'berries': 40, 'squash': 17}
        data = [farm_1, farm_2]
        index = ['Farm 1', 'Farm 2']
        df = pd.DataFrame(data, index=index)
        group = GroupedBar(df)

        # Test grouped bar data
        datas = [{
            'name': 'table',
            'values': [
                {'col': 'apples', 'idx': 'Farm 1', 'val': 10},
                {'col': 'berries', 'idx': 'Farm 1', 'val': 32},
                {'col': 'squash', 'idx': 'Farm 1', 'val': 21},
                {'col': 'apples', 'idx': 'Farm 2', 'val': 15},
                {'col': 'berries', 'idx': 'Farm 2', 'val': 40},
                {'col': 'squash', 'idx': 'Farm 2', 'val': 17}
            ]
        }]
        for i, data in enumerate(datas):
            nt.assert_dict_equal(group.data[i].grammar(), data)

        # Test grouped bar grammar
        scales = [{'domain': {'data': 'table', 'field': 'data.idx'},
                   'name': 'x',
                   'padding': 0.2,
                   'range': 'width',
                   'type': 'ordinal'},
                  {'domain': {'data': 'table', 'field': 'data.val'},
                   'name': 'y',
                   'nice': True,
                   'range': 'height'},
                  {'domain': {'data': 'table', 'field': 'data.col'},
                   'name': 'color',
                   'range': 'category20',
                   'type': 'ordinal'}]

        axes = [{'scale': 'x', 'type': 'x'},
                {'scale': 'y', 'type': 'y'}]

        marks = [{
            'type': 'group',
            'from': {
                'data': 'table',
                'transform': [{'keys': ['data.idx'], 'type': 'facet'}]
            },
            'marks': [{
                'type': 'rect',
                'properties': {
                    'enter': {
                        'fill': {'field': 'data.col', 'scale': 'color'},
                        'width': {'band': True, 'offset': -1, 'scale': 'pos'},
                        'x': {'field': 'data.col', 'scale': 'pos'},
                        'y': {'field': 'data.val', 'scale': 'y'},
                        'y2': {'scale': 'y', 'value': 0}}
                }
            }],
            'properties': {
                'enter': {
                    'width': {'band': True, 'scale': 'x'},
                    'x': {'field': 'key', 'scale': 'x'}
                }
            },
            'scales': [{
                'domain': {'field': 'data.col'},
                'name': 'pos',
                'range': 'width',
                'type': 'ordinal'
            }]
        }]

        chart_runner(group, scales, axes, marks)


class TestPie(object):
    """Test Pie Chart"""

    def test_init(self):
        pie = Pie([12, 23, 34])

        axes = []

        scales = [{
            "domain": {"data": "table", "field": "data.idx"},
            "name": "color",
            "range": "category10",
            "type": "ordinal"
        }]

        marks = [{
            "type": "arc",
            "from": {
                "data": "table",
                "transform": [{"type": "pie", "value": "data.val"}]
            },
            "properties": {
                "enter": {
                    "x": {"group": "width", "mult": 0.5},
                    "y": {"group": "height", "mult": 0.5},
                    "endAngle": {"field": "endAngle"},
                    "innerRadius": {"value": 0},
                    "outerRadius": {"value": 250},
                    "startAngle": {"field": "startAngle"},
                    "stroke": {"value": "white"},
                    "fill": {"field": "data.idx", "scale": "color"}
                }
            }
        }]

        chart_runner(pie, scales, axes, marks)


class TestMaps(object):
    """Test maps, both simple and with data binding"""

    def setup(self):

        # Data
        self.df = pd.DataFrame({'one': [1, 2, 3], 'two': [4, 5, 6],
                                'three': [7, 8, 9]})
        self.series = pd.Series([1, 2, 3], name='test')

        self.geo_data = [{
            'name': 'fake_data',
            'url': 'mapdata.topo.json',
            'feature': 'topo_feature'
        },
            {
                'name': 'fake_data_2',
                'url': 'mapdata2.topo.json',
                'feature': 'topo_feature'
            }]

    def test_simple(self):

        map_ = Map(geo_data=[self.geo_data[0]], projection='albersUsa',
                   center=[10, 20], scale=200, rotate=10)

        axes = []
        scales = []

        datas = [{'name': 'fake_data',
                  'url': 'mapdata.topo.json',
                  'format': {'feature': 'topo_feature', 'type': 'topojson'},
                  'transform': [{
                      'center': [10, 20],
                      'projection': 'albersUsa',
                      'rotate': 10,
                      'scale': 200,
                      'translate': [480, 250],
                      'type': 'geopath',
                      'value': 'data'
                  }]
                  }]

        marks = [{'type': 'path',
                  'from': {'data': 'fake_data'},
                  'properties': {
                      'enter': {
                          'path': {'field': 'path'},
                          'stroke': {'value': '#000000'}
                      },
                      'update': {
                          'fill': {'value': 'steelblue'}
                      }
                  }
                  }]

        chart_runner(map_, scales, axes, marks)

        for i, data in enumerate(datas):
            nt.assert_dict_equal(map_.data[i].grammar(), data)

    def test_binding(self):

        with nt.assert_raises(ValueError) as err:
            map_df = Map(data=self.df, geo_data=self.geo_data,
                         projection='albersUsa', center=[10, 20], scale=200,
                         rotate=10, map_key={'fake_data_2': 'properties.id'})
            nt.assert_equal(
                err.exception.args[0],
                'If passing data, you must pass data cols to key/bind on'
            )

        map_df = Map(data=self.df, geo_data=self.geo_data,
                     projection='albersUsa',
                     center=[10, 20], scale=200, rotate=10,
                     map_key={'fake_data_2': 'properties.id'}, data_key='one',
                     data_bind='two')

        axes = []
        scales = [{
            'name': 'color',
            'type': 'quantize',
            'domain': [4.0, 5.9],
            'range': ['#f7fcf0', '#e0f3db', '#ccebc5', '#a8ddb5', '#7bccc4',
                      '#4eb3d3', '#2b8cbe', '#0868ac', '#084081']
        }]

        datas = [{'name': 'fake_data',
                  'url': 'mapdata.topo.json',
                  'format': {'feature': 'topo_feature', 'type': 'topojson'},
                  'transform': [{
                      'center': [10, 20],
                      'projection': 'albersUsa',
                      'rotate': 10,
                      'scale': 200,
                      'translate': [480, 250],
                      'type': 'geopath',
                      'value': 'data'
                  }],
                  },
                 {'name': 'table',
                  'values': [
                      {'x': 1, 'y': 4},
                      {'x': 2, 'y': 5},
                      {'x': 3, 'y': 6}
                  ]
                  },
                 {'name': 'fake_data_2',
                  'url': 'mapdata2.topo.json',
                  'format': {'feature': 'topo_feature', 'type': 'topojson'},
                  'transform': [
                      {
                          'as': 'value',
                          'default': 'noval',
                          'key': 'data.properties.id',
                          'type': 'zip',
                          'with': 'table',
                          'withKey': 'data.x'
                      },
                      {
                          'test': "d.path!='noval' && d.value!='noval'",
                          'type': 'filter'
                      },
                      {
                          'center': [10, 20],
                          'projection': 'albersUsa',
                          'rotate': 10,
                          'scale': 200,
                          'translate': [480, 250],
                          'type': 'geopath',
                          'value': 'data'
                      }]
                  }
                 ]

        marks = [{'type': 'path',
                  'from': {'data': 'fake_data'},
                  'properties': {
                      'enter': {
                          'path': {'field': 'path'},
                          'stroke': {'value': '#000000'}
                      },
                      'update': {
                          'fill': {'value': 'steelblue'}
                      }
                  }
                  },
                 {'type': 'path',
                  'from': {'data': 'fake_data_2'},
                  'properties': {
                      'enter': {
                          'path': {'field': 'path'},
                          'stroke': {'value': '#000000'}
                      },
                      'update': {
                          'fill': {'field': 'value.data.y', 'scale': 'color'}
                      }
                  }
                  }]

        chart_runner(map_df, scales, axes, marks)

        for i, data in enumerate(datas):
            nt.assert_dict_equal(map_df.data[i].grammar(), data)

        map_df.rebind(column='three', brew='PuBu')

        rebound = {'name': 'table',
                   'values': [
                       {'x': 1, 'y': 7},
                       {'x': 2, 'y': 8},
                       {'x': 3, 'y': 9}
                   ]
                   }

        new_scale = {
            'name': 'color',
            'type': 'quantize',
            'domain': [7.0, 8.9],
            'range': [
                "#fff7fb",
                "#ece7f2",
                "#d0d1e6",
                "#a6bddb",
                "#74a9cf",
                "#3690c0",
                "#0570b0",
                "#045a8d",
                "#023858"
            ]
        }

        assert map_df.data['table'].grammar() == rebound
        assert map_df.scales['color'].grammar() == new_scale


class TestWord(object):
    """Test Pie Chart"""

    def test_init(self):
        d = {'emop': 32, 'epom': 28, 'meop': 36, 'mepo': 12,
             'moep': 40, 'mope': 56, 'omep': 20, 'opem': 24,
             'pemo': 10, 'peom': 44, 'poem': 80, 'pome': 10}
        word = Word(d)

        axes = []

        scales = [{'domain': {'data': 'table', 'field': 'data.idx'},
                   'name': 'color',
                   'range': 'category10',
                   'type': 'ordinal'}]

        marks = [{
            'type': 'text',
            'from': {'data': 'table'},
            'properties': {
                'enter': {
                    'align': {'value': 'center'},
                    'angle': {'field': 'angle'},
                    'baseline': {'value': 'middle'},
                    'fill': {'field': 'data.idx', 'scale': 'color'},
                    'font': {'field': 'font'},
                    'fontSize': {'field': 'fontSize'},
                    'text': {'field': 'data.idx'},
                    'x': {'field': 'x'},
                    'y': {'field': 'y'}
                }
            }
        }]

        chart_runner(word, scales, axes, marks)

########NEW FILE########
__FILENAME__ = test_unicode_literals
# -*- coding: utf-8 -*-
from __future__ import unicode_literals

from vincent.charts import Bar


def test_unicode_axes():
    """Verify that python2.7 will allow arbitrary unicode strings
       in the same way python 3.2/3.3 does.
       We use unicode_literals __future__ to make this test cross platform
       without using version switches,
       """
    bar = Bar([1, 2, 3])
    bar.axis_titles(x="老特洛伊呗", y="ZAŻÓŁĆ GĘŚLĄ JAŹŃ")
    # XXX: if this proves to be correct fix, we should test more methods here

########NEW FILE########
__FILENAME__ = test_vega
# -*- coding: utf-8 -*-
'''
Test Vincent.vega
-----------------

'''
from datetime import datetime, timedelta
from itertools import product
import time
import json

from vincent.charts import Line
from vincent.core import (grammar, GrammarClass, GrammarDict, KeyedList,
                          LoadError, ValidationError)
from vincent.visualization import Visualization
from vincent.data import Data
from vincent.transforms import Transform
from vincent.properties import PropertySet
from vincent.scales import DataRef, Scale
from vincent.marks import ValueRef, MarkProperties, MarkRef, Mark
from vincent.axes import AxisProperties, Axis
from vincent.legends import LegendProperties, Legend

import nose.tools as nt

import pandas as pd
import numpy as np


sequences = {
    'int': range,
    'float': lambda l: list(map(float, list(range(l)))),
    'char': lambda l: list(map(chr, list(range(97, 97 + l)))),
    'datetime': lambda l: [datetime.now() + timedelta(days=i)
                           for i in range(l)],
    'Timestamp': lambda l: pd.date_range('1/2/2000', periods=l),
    'numpy float': lambda l: list(map(np.float32, list(range(l)))),
    'numpy int': lambda l: list(map(np.int32, list(range(l))))}


def test_keyed_list():
    """Test keyed list implementation"""

    class TestKey(object):
        """Test object for Keyed List"""
        def __init__(self, name=None):
            self.name = name

    key_list = KeyedList(attr_name='name')

    # Basic usage
    test_key = TestKey(name='test')
    key_list.append(test_key)
    nt.assert_equal(test_key, key_list['test'])

    # Bad key
    with nt.assert_raises(KeyError) as err:
        key_list['test_1']
    nt.assert_equal(err.exception.args[0], ' "test_1" is an invalid key')

    # Repeated keys
    test_key_1 = TestKey(name='test')
    key_list.append(test_key_1)
    with nt.assert_raises(ValidationError) as err:
        key_list['test']
    nt.assert_equal(err.expected, ValidationError)
    nt.assert_equal(err.exception.args[0], 'duplicate keys found')

    # Setting keys
    key_list.pop(-1)
    test_key_2 = TestKey(name='test_2')
    key_list['test_2'] = test_key_2
    nt.assert_equal(key_list['test_2'], test_key_2)

    mirror_key_2 = TestKey(name='test_2')
    key_list['test_2'] = mirror_key_2
    nt.assert_equal(key_list['test_2'], mirror_key_2)

    key_list[0] = mirror_key_2
    nt.assert_equal(key_list[0], mirror_key_2)

    # Keysetting errors
    test_key_3 = TestKey(name='test_3')
    with nt.assert_raises(ValidationError) as err:
        key_list['test_4'] = test_key_3
    nt.assert_equal(err.expected, ValidationError)
    nt.assert_equal(err.exception.args[0],
                    "key must be equal to 'name' attribute")

    key_list = KeyedList(attr_name='type')
    test_key_4 = TestKey(name='test_key_4')
    with nt.assert_raises(ValidationError) as err:
        key_list['test_key_4'] = test_key_4
    nt.assert_equal(err.expected, ValidationError)
    nt.assert_equal(err.exception.args[0], 'object must have type attribute')


def test_grammar():
    """Grammar decorator behaves correctly."""

    validator_fail = False

    class DummyType(object):
        pass

    class TestGrammarClass(object):
        def __init__(self):
            self.grammar = GrammarDict()

        @grammar
        def test_grammar(value):
            if validator_fail:
                raise ValueError('validator failed')

        @grammar(grammar_type=DummyType)
        def test_grammar_with_type(value):
            if validator_fail:
                raise ValueError('validator failed')

        @grammar(grammar_name='a name')
        def test_grammar_with_name(value):
            if validator_fail:
                raise ValueError('validator failed')

    test = TestGrammarClass()
    nt.assert_is_none(test.test_grammar)
    nt.assert_dict_equal(test.grammar, {})

    test.test_grammar = 'testing'
    nt.assert_equal(test.test_grammar, 'testing')
    nt.assert_dict_equal(test.grammar, {'test_grammar': 'testing'})

    del test.test_grammar
    nt.assert_is_none(test.test_grammar)
    nt.assert_dict_equal(test.grammar, {})

    validator_fail = True
    nt.assert_raises_regexp(ValueError, 'validator failed', setattr, test,
                            'test_grammar', 'testing')

    # grammar with type checking
    test = TestGrammarClass()
    validator_fail = False
    dummy = DummyType()
    test.test_grammar_with_type = dummy
    nt.assert_equal(test.test_grammar_with_type, dummy)
    nt.assert_dict_equal(test.grammar, {'test_grammar_with_type': dummy})
    nt.assert_raises_regexp(ValueError, 'must be DummyType', setattr, test,
                            'test_grammar_with_type', 'testing')
    validator_fail = True
    nt.assert_raises_regexp(ValueError, 'validator failed', setattr, test,
                            'test_grammar_with_type', dummy)

    # grammar with field name
    test = TestGrammarClass()
    validator_fail = False
    test.test_grammar_with_name = 'testing'
    nt.assert_equal(test.test_grammar_with_name, 'testing')
    nt.assert_dict_equal(test.grammar, {'a name': 'testing'})
    validator_fail = True
    nt.assert_raises_regexp(ValueError, 'validator failed', setattr, test,
                            'test_grammar_with_name', 'testing')


def test_grammar_dict():
    """Test Vincent Grammar Dict"""

    g_dict = GrammarDict()
    test = Visualization()
    test_dict = {'axes': [], 'data': [], 'marks': [],
                 'scales': [], 'legends': []}
    test_str = ('{"axes": [], "data": [], "legends": [], '
                '"marks": [], "scales": []}')

    nt.assert_equal(test.grammar(), test_dict)
    print(json.dumps(test.grammar, sort_keys=True))
    nt.assert_equal(json.dumps(test.grammar, sort_keys=True),
                    test_str)
    nt.assert_equal(g_dict.encoder(test), test.grammar)


def assert_grammar_typechecking(grammar_types, test_obj):
    """Assert that the grammar fields of a test object are correctly
    type-checked.

    `grammar_types` should be a list of (name, type) pairs, and `test_obj`
    should be an instance of the object to test.
    """
    class BadType(object):
        pass

    for name, objects in grammar_types:
        for obj in objects:
            tmp_obj = obj()
            setattr(test_obj, name, tmp_obj)
            nt.assert_equal(getattr(test_obj, name), tmp_obj)
            bad_obj = BadType()
            nt.assert_raises_regexp(ValueError, name + '.*' + obj.__name__,
                                    setattr, test_obj, name, bad_obj)
            nt.assert_equal(getattr(test_obj, name), tmp_obj)


def assert_manual_typechecking(bad_grammar, test_obj):
    """Some attrs use the _assert_is_type func for typechecking"""

    for attr, value in bad_grammar:
        with nt.assert_raises(ValueError) as err:
            setattr(test_obj, attr, value)

        nt.assert_equal(err.expected, ValueError)


def assert_grammar_validation(grammar_errors, test_obj):
    """Check grammar methods for validation errors"""

    for attr, value, error, message in grammar_errors:
        with nt.assert_raises(error) as err:
            setattr(test_obj, attr, value)

        nt.assert_equal(err.exception.args[0], message)


class TestGrammarClass(object):
    """Test GrammarClass's built-in methods that aren't tested elsewhere"""

    def test_bad_init(self):
        """Test bad initialization"""
        nt.assert_raises(ValueError, GrammarClass, width=50)

    def test_validation(self):
        """Test validation of grammar"""
        test = Visualization()
        test.axes.append({'bad axes': 'ShouldRaiseError'})
        with nt.assert_raises(ValidationError) as err:
            test.validate()
        nt.assert_equal(err.exception.args[0],
                        'invalid contents: axes[0] must be Axis')


class TestVisualization(object):
    """Test the Visualization Class"""

    def test_grammar_typechecking(self):
        """Visualization fields are correctly type checked"""

        grammar_types = [('name', [str]),
                         ('width', [int]),
                         ('height', [int]),
                         ('data', [list, KeyedList]),
                         ('scales', [list, KeyedList]),
                         ('axes', [list, KeyedList]),
                         ('marks', [list, KeyedList])]

        assert_grammar_typechecking(grammar_types, Visualization())

    def test_validation_checking(self):
        """Visualization fields are grammar-checked"""

        grammar_errors = [('width', -1, ValueError,
                           'width cannot be negative'),
                          ('height', -1, ValueError,
                           'height cannot be negative'),
                          ('viewport', [1], ValueError,
                           'viewport must have 2 dimensions'),
                          ('viewport', [-1, -1], ValueError,
                           'viewport dimensions cannot be negative'),
                          ('padding', {'top': 2}, ValueError,
                           ('Padding must have keys "top", "left", "right",'
                            ' "bottom".')),
                          ('padding',
                           {'top': 1, 'left': 1, 'right': 1, 'bottom': -1},
                           ValueError, 'Padding cannot be negative.'),
                          ('padding', -1, ValueError,
                           'Padding cannot be negative.')]

        assert_grammar_validation(grammar_errors, Visualization())

    def test_manual_typecheck(self):
        """Test manual typechecking for elements like marks"""

        test_attr = [('data', [1]), ('scales', [1]),
                     ('axes', [1]), ('marks', [1]),
                     ('legends', [1])]

        assert_manual_typechecking(test_attr, Visualization())

    def test_validation(self):
        """Test Visualization validation"""

        test_obj = Visualization()
        with nt.assert_raises(ValidationError) as err:
            test_obj.validate()
        nt.assert_equal(err.exception.args[0],
                        'data must be defined for valid visualization')

        test_obj.data = [Data(name='test'), Data(name='test')]
        with nt.assert_raises(ValidationError) as err:
            test_obj.validate()
        nt.assert_equal(err.exception.args[0],
                        'data has duplicate names')

    def test_axis_labeling(self):
        """Test convenience method for axis label setting"""

        # With Axes already in place
        test_obj = Visualization()
        test_obj.axes.extend([Axis(type='x'), Axis(type='y')])
        test_obj.axis_titles(x="test1", y="test2")
        nt.assert_equals(test_obj.axes['x'].title, 'test1')
        nt.assert_equals(test_obj.axes['y'].title, 'test2')

        # With no Axes already defined
        del test_obj.axes[0]
        del test_obj.axes[0]
        test_obj.axis_titles(x="test1", y="test2")
        nt.assert_equals(test_obj.axes['x'].title, 'test1')
        nt.assert_equals(test_obj.axes['y'].title, 'test2')

    def test_axis_properties(self):

        test_vis = Visualization()
        with nt.assert_raises(ValueError) as err:
            test_vis.x_axis_properties(title_size=20, label_angle=30)
        nt.assert_equals(err.exception.args[0],
                         'This Visualization has no axes!')
        test_vis.axes = [Axis(scale='x'), Axis(scale='y')]
        test_vis.x_axis_properties(title_size=20, title_offset=10,
                                   label_angle=30, color='#000')
        test_vis.y_axis_properties(title_size=20, title_offset=10,
                                   label_angle=30, color='#000')

        def check_axis_colors():
            for axis in test_vis.axes:
                props = axis.properties
                for prop in [props.title.fill, props.labels.fill]:
                    nt.assert_equals(getattr(prop, 'value'), '#000')
                for prop in [props.axis.stroke, props.major_ticks.stroke,
                             props.minor_ticks.stroke, props.ticks.stroke]:
                    nt.assert_equals(getattr(prop, 'value'), '#000')

        for axis in test_vis.axes:
            props = axis.properties
            nt.assert_equals(props.labels.angle.value, 30)
            nt.assert_equals(props.title.font_size.value, 20)
            nt.assert_equals(props.title.dy.value, 10)
        check_axis_colors()

        test_vis.axes = [Axis(scale='x'), Axis(scale='y')]
        test_vis.common_axis_properties(color='#000')
        for axis in test_vis.axes:
            check_axis_colors()

    def test_legends(self):
        test_vis = Visualization()
        test_vis.legend(title='Test', text_color='#000')
        nt.assert_equals(test_vis.legends[0].title, 'Test')
        nt.assert_equals(test_vis.legends[0].properties.labels.fill.value,
                         '#000')
        nt.assert_equals(test_vis.legends[0].properties.title.fill.value,
                         '#000')

    def test_colors(self):
        test_vis = Line([1, 2, 3])
        rng = ['foo', 'bar']
        test_vis.colors(range_=rng)
        nt.assert_equals(test_vis.scales['color'].range, rng)

    def test_to_json(self):
        """Test JSON to string"""

        pretty = '''{
          "marks": [],
          "axes": [],
          "data": [],
          "scales": [],
          "legends": []
        }'''

        test = Visualization()
        actual, tested = json.loads(pretty), json.loads(test.to_json())
        nt.assert_dict_equal(actual, tested)


class TestData(object):
    """Test the Data class"""

    def test_grammar_typechecking(self):
        """Data fields are correctly type-checked"""
        grammar_types = [
            ('name', [str]),
            ('url', [str]),
            ('values', [list]),
            ('source', [str]),
            ('transform', [list])]

        assert_grammar_typechecking(grammar_types, Data('name'))

    def test_validate(self):
        """Test Data name validation"""
        test_obj = Data()
        del test_obj.name
        nt.assert_raises(ValidationError, test_obj.validate)

    def test_serialize(self):
        """Objects are serialized to JSON-compatible objects"""

        def epoch(obj):
            """Convert to JS Epoch time"""
            return int(time.mktime(obj.timetuple())) * 1000

        types = [('test', str, 'test'),
                 (pd.Timestamp('2013-06-08'), int,
                  epoch(pd.Timestamp('2013-06-08'))),
                 (datetime.utcnow(), int, epoch(datetime.utcnow())),
                 (1, int, 1),
                 (1.0, float, 1.0),
                 (np.float32(1), float, 1.0),
                 (np.int32(1), int, 1),
                 (np.float64(1), float, 1.0),
                 (np.int64(1), int, 1)]

        for puts, pytype, gets in types:
            nt.assert_equal(Data.serialize(puts), gets)

        class BadType(object):
            """Bad object for type warning"""

        test_obj = BadType()
        with nt.assert_raises(LoadError) as err:
            Data.serialize(test_obj)
        nt.assert_equals(err.exception.args[0],
                         'cannot serialize index of type BadType')

    def test_pandas_series_loading(self):
        """Pandas Series objects are correctly loaded"""
        # Test valid series types
        name = ['_x', ' name']
        length = [0, 1, 2]
        index_key = [None, 'ix', 1]
        index_types = ['int', 'char', 'datetime', 'Timestamp']
        value_key = [None, 'x', 1]
        value_types = ['int', 'char', 'datetime', 'Timestamp', 'float',
                       'numpy float', 'numpy int']

        series_info = product(name, length, index_key, index_types,
                              value_key, value_types)

        for n, l, ikey, itype, vkey, vtype in series_info:
            index = sequences[itype](l)
            series = pd.Series(sequences[vtype](l), index=index, name=n,)

            vkey = series.name or vkey
            expected = [{'idx': Data.serialize(i), 'col': vkey,
                         'val': Data.serialize(v)}
                        for i, v in zip(index, series)]

            data = Data.from_pandas(series, name=n, series_key=vkey)
            nt.assert_list_equal(expected, data.values)
            nt.assert_equal(n, data.name)
            data.to_json()

        # Missing a name
        series = pd.Series(np.random.randn(10))
        data = Data.from_pandas(series)
        nt.assert_equal(data.name, 'table')

    def test_pandas_dataframe_loading(self):

        # Simple columns/key_on tests
        df = pd.DataFrame({'one': [1, 2, 3], 'two': [6, 7, 8],
                           'three': [11, 12, 13], 'four': [17, 18, 19]})
        get_all = [{'col': 'four', 'idx': 0, 'val': 17},
                   {'col': 'one', 'idx': 0, 'val': 1},
                   {'col': 'three', 'idx': 0, 'val': 11},
                   {'col': 'two', 'idx': 0, 'val': 6},
                   {'col': 'four', 'idx': 1, 'val': 18},
                   {'col': 'one', 'idx': 1, 'val': 2},
                   {'col': 'three', 'idx': 1, 'val': 12},
                   {'col': 'two', 'idx': 1, 'val': 7},
                   {'col': 'four', 'idx': 2, 'val': 19},
                   {'col': 'one', 'idx': 2, 'val': 3},
                   {'col': 'three', 'idx': 2, 'val': 13},
                   {'col': 'two', 'idx': 2, 'val': 8}]
        get1 = [{'col': 'one', 'idx': 0, 'val': 1},
                {'col': 'one', 'idx': 1, 'val': 2},
                {'col': 'one', 'idx': 2, 'val': 3}]
        get2 = [{'col': 'one', 'idx': 0, 'val': 1},
                {'col': 'two', 'idx': 0, 'val': 6},
                {'col': 'one', 'idx': 1, 'val': 2},
                {'col': 'two', 'idx': 1, 'val': 7},
                {'col': 'one', 'idx': 2, 'val': 3},
                {'col': 'two', 'idx': 2, 'val': 8}]
        getkey2 = [{'col': 'one', 'idx': 6, 'val': 1},
                   {'col': 'one', 'idx': 7, 'val': 2},
                   {'col': 'one', 'idx': 8, 'val': 3}]
        getkey3 = [{'col': 'one', 'idx': 11, 'val': 1},
                   {'col': 'two', 'idx': 11, 'val': 6},
                   {'col': 'one', 'idx': 12, 'val': 2},
                   {'col': 'two', 'idx': 12, 'val': 7},
                   {'col': 'one', 'idx': 13, 'val': 3},
                   {'col': 'two', 'idx': 13, 'val': 8}]
        val_all = Data.from_pandas(df)
        val1 = Data.from_pandas(df, columns=['one'])
        val2 = Data.from_pandas(df, columns=['one', 'two'])
        key2 = Data.from_pandas(df, columns=['one'], key_on='two')
        key3 = Data.from_pandas(df, columns=['one', 'two'], key_on='three')

        nt.assert_list_equal(val_all.values, get_all)
        nt.assert_list_equal(val1.values, get1)
        nt.assert_list_equal(val2.values, get2)
        nt.assert_list_equal(key2.values, getkey2)
        nt.assert_list_equal(key3.values, getkey3)

        # Missing a name
        dataframe = pd.DataFrame(np.random.randn(10, 3))
        data = Data.from_pandas(dataframe)
        nt.assert_equal(data.name, 'table')

        # Bad obj
        nt.assert_raises(ValueError, Data.from_pandas, {})

    def test_numpy_loading(self):
        """Numpy ndarray objects are correctly loaded"""
        test_data = np.random.randn(6, 3)
        index = range(test_data.shape[0])
        columns = ['a', 'b', 'c']

        data = Data.from_numpy(test_data, name='name', columns=columns)
        ikey = Data._default_index_key
        expected_values = [
            {ikey: i, 'a': row[0], 'b': row[1], 'c': row[2]}
            for i, row in zip(index, test_data.tolist())]
        nt.assert_list_equal(expected_values, data.values)
        nt.assert_equal('name', data.name)

        index_key = 'akey'
        data = Data.from_numpy(test_data, name='name', columns=columns,
                               index_key=index_key)
        expected_values = [
            {index_key: i, 'a': row[0], 'b': row[1], 'c': row[2]}
            for i, row in zip(index, test_data.tolist())]
        nt.assert_list_equal(expected_values, data.values)

        index = ['a', 'b', 'c', 'd', 'e', 'f']
        data = Data.from_numpy(test_data, name='name', index=index,
                               columns=columns)
        expected_values = [
            {ikey: i, 'a': row[0], 'b': row[1], 'c': row[2]}
            for i, row in zip(index, test_data.tolist())]
        nt.assert_list_equal(expected_values, data.values)

        # Bad loads
        with nt.assert_raises(LoadError) as err:
            Data.from_numpy(test_data, 'test', columns, index=range(4))
        nt.assert_equal(err.expected, LoadError)

        columns = ['a', 'b']
        with nt.assert_raises(LoadError) as err:
            Data.from_numpy(test_data, 'test', columns, index)
        nt.assert_equal(err.expected, LoadError)

    def test_from_mult_iters(self):
        """Test set of iterables"""
        test1 = Data.from_mult_iters(x=[0, 1, 2], y=[3, 4, 5], z=[7, 8, 9],
                                     idx='x')
        test2 = Data.from_mult_iters(fruit=['apples', 'oranges', 'grapes'],
                                     count=[12, 16, 54], idx='fruit')
        values1 = [{'col': 'y', 'idx': 0, 'val': 3},
                   {'col': 'y', 'idx': 1, 'val': 4},
                   {'col': 'y', 'idx': 2, 'val': 5},
                   {'col': 'z', 'idx': 0, 'val': 7},
                   {'col': 'z', 'idx': 1, 'val': 8},
                   {'col': 'z', 'idx': 2, 'val': 9}]
        values2 = [{'col': 'count', 'idx': 'apples', 'val': 12},
                   {'col': 'count', 'idx': 'oranges', 'val': 16},
                   {'col': 'count', 'idx': 'grapes', 'val': 54}]

        nt.assert_list_equal(test1.values, values1)
        nt.assert_list_equal(test2.values, values2)

        # Iter errors
        nt.assert_raises(ValueError, Data.from_mult_iters, x=[0], y=[1, 2])

    def test_from_iter(self):
        """Test data from single iterable"""
        test_list = Data.from_iter([10, 20, 30])
        test_dict = Data.from_iter({
            'apples': 10, 'bananas': 20, 'oranges': 30})
        get1 = [{'col': 'data', 'idx': 0, 'val': 10},
                {'col': 'data', 'idx': 1, 'val': 20},
                {'col': 'data', 'idx': 2, 'val': 30}]
        get2 = [{'col': 'data', 'idx': 'apples', 'val': 10},
                {'col': 'data', 'idx': 'bananas', 'val': 20},
                {'col': 'data', 'idx': 'oranges', 'val': 30}]
        nt.assert_list_equal(test_list.values, get1)
        nt.assert_list_equal(test_dict.values, get2)

    def test_serialize_error(self):
        """Test serialization error"""

        class badType(object):
            """I am a bad actor"""

        broken = badType()

        nt.assert_raises(LoadError, Data.serialize, broken)

    def test_keypairs(self):
        Data.keypairs([0, 10, 20, 30, 40])
        Data.keypairs(((0, 1), (0, 2), (0, 3)))
        Data.keypairs({'A': 10, 'B': 20, 'C': 30, 'D': 40, 'E': 50})


class TestTransform(object):
    """Test the Transform class"""

    def test_grammar_typechecking(self):
        """Transform field typechecking"""
        grammar_types = [
            ('fields', [list]), ('from_', [str]),
            ('as_', [list]), ('keys', [list]), ('sort', [str]),
            ('test', [str]), ('field', [str]), ('expr', [str]),
            ('by', [str, list]), ('value', [str]), ('median', [bool]),
            ('with_', [str]), ('key', [str]), ('with_key', [str]),
            ('links', [str]), ('size', [list]), ('iterations', [int]),
            ('charge', [int, str]), ('link_distance', [int, str]),
            ('link_strength', [int, str]), ('friction', [int, float]),
            ('theta', [int, float]), ('gravity', [int, float]),
            ('alpha', [int, float]), ('point', [str]),
            ('height', [str])]

        assert_grammar_typechecking(grammar_types, Transform())


class TestValueRef(object):
    """Test the ValueRef class"""

    def test_grammar_typechecking(self):
        """ValueRef fields are correctly type-checked"""
        grammar_types = [
            ('value', [str]),
            ('value', [int]),
            ('value', [float]),
            ('field', [str]),
            ('scale', [str]),
            ('mult', [int]),
            ('mult', [float]),
            ('offset', [int]),
            ('offset', [float]),
            ('band', [bool])]
        assert_grammar_typechecking(grammar_types, ValueRef())

    def test_json_serialization(self):
        """ValueRef JSON is correctly serialized"""
        vref = ValueRef()
        nt.assert_equal(json.dumps({}), vref.to_json(pretty_print=False))

        props = {
            'value': 'test-value',
            'band': True}
        vref = ValueRef(**props)
        nt.assert_equal(json.dumps(props, sort_keys=True),
                        vref.to_json(pretty_print=False))

        props = {
            'value': 'test-value',
            'field': 'test-field',
            'scale': 'test-scale',
            'mult': 1.2,
            'offset': 4,
            'band': True}
        vref = ValueRef(**props)
        nt.assert_equal(json.dumps(props, sort_keys=True),
                        vref.to_json(pretty_print=False))


class TestPropertySet(object):
    """Test the PropertySet Class"""

    def test_grammar_typechecking(self):
        """PropertySet fields are correctly type-checked"""
        # All fields must be ValueRef for Mark properties
        fields = [
            'x', 'x2', 'width', 'y', 'y2', 'height', 'opacity', 'fill',
            'fill_opacity', 'stroke', 'stroke_width', 'stroke_opacity',
            'size', 'shape', 'path', 'inner_radius', 'outer_radius',
            'start_angle', 'end_angle', 'interpolate', 'tension', 'url',
            'align', 'baseline', 'text', 'dx', 'dy', 'angle', 'font',
            'font_size', 'font_weight', 'font_style']
        grammar_types = [(f, [ValueRef]) for f in fields]
        assert_grammar_typechecking(grammar_types, PropertySet())

    def test_validation_checking(self):
        """ValueRef fields are grammar-checked"""

        grammar_errors = [('fill_opacity', ValueRef(value=-1), ValueError,
                           'fill_opacity must be between 0 and 1'),
                          ('fill_opacity', ValueRef(value=2), ValueError,
                           'fill_opacity must be between 0 and 1'),
                          ('stroke_width', ValueRef(value=-1), ValueError,
                           'stroke width cannot be negative'),
                          ('stroke_opacity', ValueRef(value=-1), ValueError,
                           'stroke_opacity must be between 0 and 1'),
                          ('stroke_opacity', ValueRef(value=2), ValueError,
                           'stroke_opacity must be between 0 and 1'),
                          ('size', ValueRef(value=-1), ValueError,
                           'size cannot be negative')]

        assert_grammar_validation(grammar_errors, PropertySet())

        bad_shape = ValueRef(value="BadShape")
        nt.assert_raises(ValueError, PropertySet, shape=bad_shape)

    def test_manual_typecheck(self):
        """Test manual typechecking for elements like marks"""

        test_attr = [('fill', ValueRef(value=1)),
                     ('fill_opacity', ValueRef(value='str')),
                     ('stroke', ValueRef(value=1)),
                     ('stroke_width', ValueRef(value='str')),
                     ('stroke_opacity', ValueRef(value='str')),
                     ('size', ValueRef(value='str')),
                     ('shape', ValueRef(value=1)),
                     ('path', ValueRef(value=1))]

        assert_manual_typechecking(test_attr, PropertySet())


class TestMarkProperties(object):
    """Test the MarkProperty Class"""

    def test_grammar_typechecking(self):
        """Test grammar of MarkProperty"""

        fields = ['enter', 'exit', 'update', 'hover']
        grammar_types = [(f, [PropertySet]) for f in fields]
        assert_grammar_typechecking(grammar_types, MarkProperties())


class TestMarkRef(object):
    """Test the MarkRef Class"""

    def test_grammar_typechecking(self):
        """Test grammar of MarkRef"""

        grammar_types = [('data', [str]), ('transform', [list])]
        assert_grammar_typechecking(grammar_types, MarkRef())


class TestMark(object):
    """Test Mark Class"""

    def test_grammar_typechecking(self):
        """Test grammar of Mark"""

        grammar_types = [('name', [str]), ('description', [str]),
                         ('from_', [MarkRef]),
                         ('properties', [MarkProperties]), ('key', [str]),
                         ('key', [str]), ('delay', [ValueRef]),
                         ('ease', [str]), ('marks', [list]),
                         ('scales', [list, KeyedList])]
        assert_grammar_typechecking(grammar_types, Mark())

    def test_validation_checking(self):
        """Mark fields are grammar checked"""

        nt.assert_raises(ValueError, Mark, type='panda')


class TestDataRef(object):
    """Test DataRef class"""

    def test_grammar_typechecking(self):
        """Test grammar of DataRef"""

        grammar_types = [('data', [str]), ('field', [str])]
        assert_grammar_typechecking(grammar_types, DataRef())


class TestScale(object):
    """Test Scale class"""

    def test_grammar_typechecking(self):
        """Test grammar of Scale"""

        grammar_types = [('name', [str]), ('type', [str]),
                         ('domain', [list, DataRef]),
                         ('domain_min', [float, int, DataRef]),
                         ('domain_max', [float, int, DataRef]),
                         ('range', [list, str]),
                         ('range_min', [float, int, DataRef]),
                         ('range_max', [float, int, DataRef]),
                         ('reverse', [bool]), ('round', [bool]),
                         ('points', [bool]), ('clamp', [bool]),
                         ('nice', [bool, str]),
                         ('exponent', [float, int]),
                         ('zero', [bool])]

        assert_grammar_typechecking(grammar_types, Scale())


class TestAxisProperties(object):
    """Test AxisProperties Class"""

    def test_grammar_typechecking(self):
        """Test grammar of AxisProperties"""

        grammar_types = [('major_ticks', [PropertySet]),
                         ('minor_ticks', [PropertySet]),
                         ('labels', [PropertySet]),
                         ('axis', [PropertySet])]

        assert_grammar_typechecking(grammar_types, AxisProperties())


class TestAxis(object):
    """Test Axis Class"""

    def test_grammar_typechecking(self):
        """Test grammar of Axis"""

        grammar_types = [('title', [str]),
                         ('title_offset', [int]),
                         ('grid', [bool]),
                         ('scale', [str]),
                         ('orient', [str]), ('format', [str]),
                         ('ticks', [int]), ('values', [list]),
                         ('subdivide', [int, float]),
                         ('tick_padding', [int]), ('tick_size', [int]),
                         ('tick_size_major', [int]),
                         ('tick_size_minor', [int]),
                         ('tick_size_end', [int]),
                         ('offset', [int]),
                         ('properties', [AxisProperties])]

        assert_grammar_typechecking(grammar_types, Axis())

    def test_validation_checking(self):
        """Axis fields are grammar checked"""

        nt.assert_raises(ValueError, Axis, type='panda')


class TestLegendProperties(object):
    """Test LegendProperties class"""

    def test_grammar_typechecking(self):
        """Test grammar of LegendProperties"""

        grammar_types = [('title', [PropertySet]),
                         ('labels', [PropertySet]),
                         ('symbols', [PropertySet]),
                         ('gradient', [PropertySet]),
                         ('legend', [PropertySet])]

        assert_grammar_typechecking(grammar_types, LegendProperties())


class TestLegend(object):
    """Test Legend Class"""

    def test_grammar_typechecking(self):
        """Test grammar of Legend"""

        grammar_types = [('size', [str]),
                         ('shape', [str]),
                         ('fill', [str]),
                         ('stroke', [str]),
                         ('title', [str]),
                         ('format', [str]),
                         ('values', [list]),
                         ('properties', [LegendProperties])]

        assert_grammar_typechecking(grammar_types, Legend())

    def test_validation_checking(self):
        """Legend fields are grammar checked"""

        nt.assert_raises(ValueError, Legend, orient='center')

########NEW FILE########
__FILENAME__ = axes
# -*- coding: utf-8 -*-
"""

Axes: Classes for defining Vega axis properties

"""
from .core import grammar, GrammarClass
from .properties import PropertySet
from ._compat import str_types


class AxisProperties(GrammarClass):
    """Definitions for the rendering of axes

    Like Marks, axis properties can be broken into various subcomponents,
    but instead of events, the axes are divided into major ticks, minor
    ticks, labels, and the axis itself.
    """
    @grammar(grammar_type=PropertySet, grammar_name='majorTicks')
    def major_ticks(value):
        """PropertySet : Definition of major tick marks"""

    @grammar(grammar_type=PropertySet, grammar_name='minorTicks')
    def minor_ticks(value):
        """PropertySet : Definition of minor tick marks"""

    @grammar(PropertySet)
    def labels(value):
        """PropertySet : Definition of marks for axis labels"""

    @grammar(PropertySet)
    def title(value):
        """PropertySet : Definition of marks for axis labels"""

    @grammar(PropertySet)
    def axis(value):
        """PropertySet : Definition of axis line style"""


class Axis(GrammarClass):
    """Definitions for axes

    Axes are visual cues that the viewer uses to interpret the marks
    representing the data itself.
    """
    @grammar(str_types)
    def type(value):
        """string : Type of axis - ``'x'`` or ``'y'``"""
        if value not in ('x', 'y'):
            raise ValueError('Axis.type must be "x" or "y"')

    @grammar(str_types)
    def title(value):
        """string: Axis title"""

    @grammar(grammar_type=int, grammar_name='titleOffset')
    def title_offset(value):
        """int: Offset in pixels from the axis on which to place the title"""

    @grammar(bool)
    def grid(value):
        """bool: If True, gridlines are created"""

    @grammar(str_types)
    def layer(value):
        """string: A string indicating if the axis (and any gridlines) should
        be placed above or below the data marks.
        Can only be "front" (default) or "back".
        """
        if value not in ("front", "back"):
            raise ValueError("Axis.layer must be front or back")

    @grammar(str_types)
    def scale(value):
        """string : Name of scale used for axis"""

    @grammar(str_types)
    def orient(value):
        """string : Orientation of the axis

        Should be one of ``'top'``, ``'bottom'``, ``'left'``, or ``'right'``.
        """

    @grammar(str_types)
    def format(value):
        """string : Formatting to use for axis labels

        See d3's formatting documentation for format pattern.
        """

    @grammar(int)
    def ticks(value):
        """int : Number of ticks to use"""

    @grammar(list)
    def values(value):
        """list of objects in scale's domain : Explicit definitions for
        values

        Values should be in the domain of the Axis's scale. Custom ticks can
        be used by setting ``properties``.
        """

    @grammar((int, float))
    def subdivide(value):
        """int or float : Number of minor ticks in between major ticks

        Only valid for quantitative scales.
        """

    @grammar(grammar_type=(int), grammar_name='tickPadding')
    def tick_padding(value):
        """int : Pixels between ticks and text labels"""

    @grammar(grammar_type=(int), grammar_name='tickSize')
    def tick_size(value):
        """int : Size in pixels of all ticks"""

    @grammar(grammar_type=(int), grammar_name='tickSizeMajor')
    def tick_size_major(value):
        """int : Size in pixels of major ticks"""

    @grammar(grammar_type=(int), grammar_name='tickSizeMinor')
    def tick_size_minor(value):
        """int : Size in pixels of minor ticks"""

    @grammar(grammar_type=(int), grammar_name='tickSizeEnd')
    def tick_size_end(value):
        """int : Size in pixels of end ticks"""

    @grammar(int)
    def offset(value):
        """int : Offset in pixels to displace the edge of the axis from the
        referenced area
        """

    @grammar(AxisProperties)
    def properties(value):
        """AxisProperties : Custom styling for ticks and tick labels
        """

########NEW FILE########
__FILENAME__ = charts
# -*- coding: utf-8 -*-
"""

Charts: Constructors for different chart types in Vega grammar.

"""
from .visualization import Visualization
from .data import Data
from .transforms import Transform
from .values import ValueRef
from .properties import PropertySet
from .scales import DataRef, Scale
from .marks import MarkProperties, MarkRef, Mark
from .axes import Axis
from .colors import brews

try:
    import pandas as pd
except ImportError:
    pd = None

try:
    import numpy as np
except ImportError:
    np = None


def data_type(data, grouped=False, columns=None, key_on='idx', iter_idx=None):
    '''Data type check for automatic import'''
    if iter_idx:
        return Data.from_mult_iters(idx=iter_idx, **data)
    if pd:
        if isinstance(data, (pd.Series, pd.DataFrame)):
            return Data.from_pandas(data, grouped=grouped, columns=columns,
                                    key_on=key_on)
    if isinstance(data, (list, tuple, dict)):
            return Data.from_iter(data)
    else:
        raise ValueError('This data type is not supported by Vincent.')


class Chart(Visualization):
    """Abstract Base Class for all Chart types"""

    def __init__(self, data=None, columns=None, key_on='idx', iter_idx=None,
                 width=960, height=500, grouped=False, no_data=False,
                 *args, **kwargs):
        """Create a Vega Chart

        Parameters
        -----------
        data: Tuples, List, Dict, Pandas Series, or Pandas DataFrame
            Input data. Tuple of paired tuples, List of single values,
            dict of key/value pairs, Pandas Series/DataFrame, Numpy ndarray
        columns: list, default None
            Pandas DataFrame columns to plot.
        key_on: string, default 'idx'
            Pandas DataFrame column to key on, if not index
        iter_index: string, default None
            Pass an index key if data is a dict of multiple iterables. Ex:
            {'x': [0, 1, 2, 3, 4, 5], 'y': [6, 7, 8, 9, 10]}
        width: int, default 960
            Chart width
        height: int, default 500
            Chart height
        grouped: boolean, default False
            Pass true for grouped charts. Currently only enabled for Pandas
            DataFrames
        no_data: boolean, default False
            Pass true to indicate that data is not being passed. For example,
            this is used for the Map class, where geodata is passed as a
            separate attibute

        Returns
        -------
        Vega Chart

        Example
        -------
        >>>vis = vincent.Chart([10, 20, 30, 40, 50], width=200, height=100)

        """

        super(Chart, self).__init__(*args, **kwargs)

        self.width, self.height = width, height
        self.padding = "auto"
        self.columns = columns
        self._is_datetime = False

        # Data
        if data is None and not no_data:
            raise ValueError('Please initialize the chart with data.')

        if not no_data:
            if isinstance(data, (list, tuple, dict)):
                if not data:
                    raise ValueError('The data structure is empty.')
            if isinstance(data, (pd.Series, pd.DataFrame)):
                if isinstance(data.index, pd.DatetimeIndex):
                    self._is_datetime = True

            # Using a vincent KeyedList here
            self.data['table'] = (
                data_type(data, grouped=grouped, columns=columns,
                          key_on=key_on, iter_idx=iter_idx)
                )


class Line(Chart):
    """Vega Line chart

    Support line and multi-lines chart.
    """

    def __init__(self, *args, **kwargs):
        """Create a Vega Line Chart"""

        super(Line, self).__init__(*args, **kwargs)

        # Scales
        x_type = 'time' if self._is_datetime else 'linear'
        self.scales += [
            Scale(name='x', type=x_type, range='width',
                  domain=DataRef(data='table', field="data.idx")),
            Scale(name='y', range='height', nice=True,
                  domain=DataRef(data='table', field="data.val")),
            Scale(name='color', type='ordinal',
                  domain=DataRef(data='table', field='data.col'),
                  range='category20')
        ]

        # Axes
        self.axes += [Axis(type='x', scale='x'),
                      Axis(type='y', scale='y')]

        # Marks
        from_ = MarkRef(
            data='table',
            transform=[Transform(type='facet', keys=['data.col'])])
        enter_props = PropertySet(
            x=ValueRef(scale='x', field="data.idx"),
            y=ValueRef(scale='y', field="data.val"),
            stroke=ValueRef(scale="color", field='data.col'),
            stroke_width=ValueRef(value=2))
        marks = [Mark(type='line',
                      properties=MarkProperties(enter=enter_props))]
        mark_group = Mark(type='group', from_=from_, marks=marks)
        self.marks.append(mark_group)


class Scatter(Chart):
    """Vega Scatter chart"""

    def __init__(self, *args, **kwargs):
        """Create a Vega Scatter Chart"""

        super(Scatter, self).__init__(*args, **kwargs)

        # Scales
        x_type = 'time' if self._is_datetime else 'linear'
        self.scales += [
            Scale(name='x', type=x_type, range='width',
                  domain=DataRef(data='table', field="data.idx")),
            Scale(name='y', range='height', nice=True,
                  domain=DataRef(data='table', field="data.val")),
            Scale(name='color', type='ordinal',
                  domain=DataRef(data='table', field='data.col'),
                  range='category20')
        ]

        # Axes
        self.axes += [Axis(type='x', scale='x'),
                      Axis(type='y', scale='y')]

        # Marks
        from_ = MarkRef(
            data='table',
            transform=[Transform(type='facet', keys=['data.col'])])
        enter_props = PropertySet(
            x=ValueRef(scale='x', field="data.idx"),
            y=ValueRef(scale='y', field="data.val"),
            size=ValueRef(value=100),
            fill=ValueRef(scale="color", field='data.col'))
        marks = [Mark(type='symbol',
                      properties=MarkProperties(enter=enter_props))]
        mark_group = Mark(type='group', from_=from_, marks=marks)
        self.marks.append(mark_group)


class Bar(Chart):
    """Vega Bar chart

    Support both bar and stacked bar charts.
    """

    def __init__(self, *args, **kwargs):
        """Create a Vega Bar Chart"""

        super(Bar, self).__init__(*args, **kwargs)

        # Scales
        self.scales += [
            Scale(name='x', type='ordinal', range='width', zero=False,
                  domain=DataRef(data='table', field='data.idx')),
            Scale(name='y', range='height', nice=True,
                  domain=DataRef(data='stats', field='sum')),
            Scale(name='color', type='ordinal', range='category20',
                  domain=DataRef(data='table', field='data.col'))
        ]

        # Axes
        self.axes += [Axis(type='x', scale='x'),
                      Axis(type='y', scale='y')]

        # Stats Data
        stats_transform = [Transform(type='facet', keys=['data.idx']),
                           Transform(type='stats', value='data.val')]
        stats_data = Data(name='stats', source='table',
                          transform=stats_transform)
        self.data.append(stats_data)

        # Marks
        from_transform = [
            Transform(type='facet', keys=['data.col']),
            Transform(type='stack', point='data.idx', height='data.val')
        ]
        from_ = MarkRef(data='table', transform=from_transform)
        enter_props = PropertySet(
            x=ValueRef(scale='x', field='data.idx'),
            y=ValueRef(scale='y', field='y'),
            y2=ValueRef(scale='y', field='y2'),
            width=ValueRef(scale='x', band=True, offset=-1),
            fill=ValueRef(scale='color', field='data.col'))
        marks = [Mark(type='rect',
                      properties=MarkProperties(enter=enter_props))]
        mark_group = Mark(type='group', from_=from_, marks=marks)
        self.marks.append(mark_group)
StackedBar = Bar


class Area(Chart):
    """Vega Area Chart"""

    def __init__(self, *args, **kwargs):
        """Create a Vega Area Chart"""

        super(Area, self).__init__(*args, **kwargs)

        # Scales
        x_type = 'time' if self._is_datetime else 'linear'
        self.scales += [
            Scale(name='x', type=x_type, range='width', zero=False,
                  domain=DataRef(data='table', field="data.idx")),
            Scale(name='y', range='height', nice=True,
                  domain=DataRef(data='stats', field='sum')),
            Scale(name='color', type='ordinal', range='category20',
                  domain=DataRef(data='table', field='data.col'))
        ]

        # Axes
        self.axes += [Axis(type='x', scale='x'),
                      Axis(type='y', scale='y')]

        # Stats Data
        stats_transform = [Transform(type='facet', keys=['data.idx']),
                           Transform(type='stats', value='data.val')]
        stats_data = Data(name='stats', source='table',
                          transform=stats_transform)
        self.data.append(stats_data)

        # Marks
        from_transform = [
            Transform(type='facet', keys=['data.col']),
            Transform(type='stack', point='data.idx', height='data.val')
        ]
        from_ = MarkRef(data='table', transform=from_transform)
        enter_props = PropertySet(
            x=ValueRef(scale='x', field='data.idx'),
            y=ValueRef(scale='y', field='y'),
            y2=ValueRef(scale='y', field='y2'),
            interpolate=ValueRef(value='monotone'),
            fill=ValueRef(scale='color', field='data.col'))
        marks = [Mark(type='area',
                      properties=MarkProperties(enter=enter_props))]
        mark_group = Mark(type='group', from_=from_, marks=marks)
        self.marks.append(mark_group)
StackedArea = Area


class GroupedBar(Chart):
    """Vega Grouped Bar Chart"""

    def __init__(self, *args, **kwargs):
        """Create a Vega Grouped Bar Chart"""

        super(GroupedBar, self).__init__(*args, **kwargs)

        # Scales
        self.scales += [
            Scale(name='x', type='ordinal', range='width', padding=0.2,
                  domain=DataRef(data='table', field='data.idx')),
            Scale(name='y', range='height', nice=True,
                  domain=DataRef(data='table', field="data.val")),
            Scale(name='color', type='ordinal', range='category20',
                  domain=DataRef(data='table', field='data.col'))
        ]

        # Axes
        self.axes += [Axis(type='x', scale='x'),
                      Axis(type='y', scale='y')]

        # Marks
        mark_props = MarkProperties(
            enter=PropertySet(
                x=ValueRef(scale='pos', field='data.col'),
                y=ValueRef(scale='y', field='data.val'),
                y2=ValueRef(scale='y', value=0),
                width=ValueRef(scale='pos', band=True, offset=-1),
                fill=ValueRef(scale='color', field='data.col')))

        mark_group_marks = [Mark(type='rect', properties=mark_props)]
        mark_group_from = MarkRef(
            data='table',
            transform=[Transform(type='facet', keys=['data.idx'])])
        mark_group_props = MarkProperties(
            enter=PropertySet(x=ValueRef(scale='x', field='key'),
                              width=ValueRef(scale='x', band=True)))
        mark_group_scales = [Scale(name="pos", range="width", type="ordinal",
                             domain=DataRef(field="data.col"))]
        mark_group = Mark(
            type='group', from_=mark_group_from,
            properties=mark_group_props, scales=mark_group_scales,
            marks=mark_group_marks)
        self.marks.append(mark_group)


class Map(Chart):
    """Vega Simple Map"""

    def __init__(self, data=None, geo_data=None, projection="winkel3",
                 center=None, translate=None, scale=None, rotate=None,
                 data_bind=None, data_key=None, map_key=None,
                 brew='GnBu', *args, **kwargs):
        """Create a Vega Map. Takes standard Chart class parameters.

        Note: Data binding only works with Pandas DataFrames right now.

        `geo_data` needs to be passed as a list of dicts with the following
        format:
        {
            name: data name
            url: path_to_data,
            feature: TopoJSON object set (ex: 'countries')
        }

        Parameters
        ----------
        data: Tuples, List, Dict, Pandas Series, or Pandas DataFrame
            Input data. Tuple of paired tuples, List of single values,
            dict of key/value pairs, Pandas Series/DataFrame, Numpy ndarray.
            Used to bind to map for choropleth mapping.
        geo_data: list, default None
            List of dicts
        projection: string, default "winkel3"
            Map projection
        center: list, default None
            Two element list with projection center
        translate: list, default None
            Two element list with projection translation
        scale: integer, default None
            Projection scale
        rotate: integer, default None
            Projection rotation
        data_bind:str, default None
            Column you want to visualize. E.g. the data value you are binding
            to the map
        data_key: str, default None
            If passing data to bind to the map, data field to key-on. For a
            Pandas DataFrame, this would be the column name.
        map_key: dict, default None
            Key: The geo-data you are keying to. Value: The map property that
            you are keying your data on. This can be nested with dot notation.
            Ex: 'properties.name'
        brew: str, default GnBu
            Color brewer abbreviation. See colors.py

        Returns
        -------
        Vega Chart

        """

        self.raw_data = data
        self.data_key = data_key

        super(Map, self).__init__(no_data=True, *args, **kwargs)

        # Don't want to pass None to property setters
        geo_kwargs = {}
        for param in [('projection', projection), ('center', center),
                      ('translate', translate), ('scale', scale),
                      ('rotate', rotate)]:
            if param[1]:
                geo_kwargs[param[0]] = param[1]

        if not translate:
            geo_kwargs['translate'] = [self.width/2, self.height/2]

        # Add Data
        for dat in geo_data:
            # Data
            transforms = []
            if data is not None and list(map_key.keys())[0] == dat['name']:
                get_brewer = True
                if not data_key or not data_bind:
                    raise ValueError('If passing data, '
                                     'you must pass data cols to key/bind on')
                self.data['table'] = Data.keypairs(
                    data, columns=[data_key, data_bind]
                    )
                key_join = '.'.join(['data', map_key[dat['name']]])
                data_transform = Transform(
                    type='zip', key=key_join, with_='table',
                    with_key='data.x', as_='value', default='noval'
                    )
                transforms.append(data_transform)
                null_trans = Transform(
                    type='filter', test="d.path!='noval' && d.value!='noval'"
                    )
                transforms.append(null_trans)
            else:
                get_brewer = False

            geo_transform = Transform(
                type='geopath', value="data", **geo_kwargs
                )
            transforms.append(geo_transform)
            self.data[dat['name']] = Data(
                name=dat['name'], url=dat['url'], transform=transforms
                )
            if dat.get('feature'):
                self.data[dat['name']].format = {
                    'type': "topojson",
                    'feature': dat['feature']
                    }

            # Marks

            geo_from = MarkRef(data=dat['name'])

            enter_props = PropertySet(
                stroke=ValueRef(value='#000000'),
                path=ValueRef(field='path')
                )

            if get_brewer:
                update_props = PropertySet(
                    fill=ValueRef(scale='color', field='value.data.y')
                    )
                domain = [Data.serialize(data[data_bind].min()),
                          Data.serialize(data[data_bind].quantile(0.95))]
                scale = Scale(name='color', type='quantize', domain=domain,
                              range=brews[brew])
                self.scales['color'] = scale
            else:
                update_props = PropertySet(fill=ValueRef(value='steelblue'))

            mark_props = MarkProperties(enter=enter_props, update=update_props)

            self.marks.append(
                Mark(type='path', from_=geo_from, properties=mark_props)
                )

    def rebind(self, column=None, brew='GnBu'):
        """Bind a new column to the data map

        Parameters
        ----------
        column: str, default None
            Pandas DataFrame column name
        brew: str, default None
            Color brewer abbreviation. See colors.py

        """
        self.data['table'] = Data.keypairs(
            self.raw_data, columns=[self.data_key, column])
        domain = [Data.serialize(self.raw_data[column].min()),
                  Data.serialize(self.raw_data[column].quantile(0.95))]
        scale = Scale(name='color', type='quantize', domain=domain,
                      range=brews[brew])
        self.scales['color'] = scale


class Pie(Chart):
    """Vega Pie chart"""

    def __init__(self, data=None, inner_radius=0, outer_radius=None,
                 *args, **kwargs):
        """Create a Vega Pie Chart"""

        super(Pie, self).__init__(data, *args, **kwargs)

        outer_radius = outer_radius or min(self.width, self.height) / 2

        self.scales["color"] = Scale(
            name="color", type="ordinal", range="category10",
            domain=DataRef(data="table", field="data.idx"))

        transform = MarkRef(
            data="table", transform=[Transform(type="pie", value="data.val")])

        enter_props = PropertySet(
            x=ValueRef(group="width", mult=0.5),
            y=ValueRef(group="height", mult=0.5),
            start_angle=ValueRef(field="startAngle"),
            end_angle=ValueRef(field="endAngle"),
            inner_radius=ValueRef(value=inner_radius),
            outer_radius=ValueRef(value=outer_radius),
            stroke=ValueRef(value="white"),
            fill=ValueRef(scale="color", field="data.idx"))

        mark = Mark(type="arc", from_=transform,
                    properties=MarkProperties(enter=enter_props))

        self.marks.append(mark)


class Word(Chart):
    """Vega Word chart"""

    def __init__(self, *args, **kwargs):
        """Create a Vega Word Chart"""

        super(Word, self).__init__(*args, **kwargs)

        # Scales
        self.scales["color"] = Scale(
            name="color", type="ordinal", range="category10",
            domain=DataRef(data="table", field="data.idx"))

        # Data transform
        wordcloud_transform = [
            Transform(type="wordcloud", text="data.idx",
                      font="Helvetica Neue", font_size="data.val",
                      rotate={"random": list(range(-90, 90, 30))})]
        self.data[0].transform = wordcloud_transform

        # Marks
        enter_props = PropertySet(
            x=ValueRef(field="x"),
            y=ValueRef(field="y"),
            angle=ValueRef(field="angle"),
            align=ValueRef(value="center"),
            baseline=ValueRef(value="middle"),
            font=ValueRef(field="font"),
            font_size=ValueRef(field="fontSize"),
            text=ValueRef(field="data.idx"),
            fill=ValueRef(scale="color", field="data.idx"))

        mark = Mark(type="text", from_=MarkRef(data="table"),
                    properties=MarkProperties(enter=enter_props))

        self.marks.append(mark)

########NEW FILE########
__FILENAME__ = colors
  # -*- coding: utf-8 -*-
'''
Vincent Color Brewer scales
-------------------

A home for color brewer scales for Vincent integration.

The origin specs were created by Cynthia Brewer: http://colorbrewer.org/

These were pulled from the awesome folks working on D3:
https://github.com/mbostock/d3/blob/master/lib/colorbrewer/colorbrewer.js


'''

brews = {'YlGn': ["#ffffe5", "#f7fcb9", "#d9f0a3", "#addd8e", "#78c679",
                  "#41ab5d", "#238443", "#006837", "#004529"],
         'YlGnBu': ["#ffffd9", "#edf8b1", "#c7e9b4", "#7fcdbb", "#41b6c4",
                    "#1d91c0", "#225ea8", "#253494", "#081d58"],
         'GnBu': ["#f7fcf0", "#e0f3db", "#ccebc5", "#a8ddb5", "#7bccc4",
                  "#4eb3d3", "#2b8cbe", "#0868ac", "#084081"],
         'BuGn': ["#f7fcfd", "#e5f5f9", "#ccece6", "#99d8c9", "#66c2a4",
                  "#41ae76", "#238b45", "#006d2c", "#00441b"],
         'PuBuGn': ["#fff7fb", "#ece2f0", "#d0d1e6", "#a6bddb", "#67a9cf",
                    "#3690c0", "#02818a", "#016c59", "#014636"],
         'PuBu': ["#fff7fb", "#ece7f2", "#d0d1e6", "#a6bddb", "#74a9cf",
                  "#3690c0", "#0570b0", "#045a8d", "#023858"],
         'BuPu': ["#f7fcfd", "#e0ecf4", "#bfd3e6", "#9ebcda", "#8c96c6",
                  "#8c6bb1", "#88419d", "#810f7c", "#4d004b"],
         'RdPu': ["#fff7f3", "#fde0dd", "#fcc5c0", "#fa9fb5", "#f768a1",
                  "#dd3497", "#ae017e", "#7a0177", "#49006a"],
         'PuRd': ["#f7f4f9", "#e7e1ef", "#d4b9da", "#c994c7", "#df65b0",
                  "#e7298a", "#ce1256", "#980043", "#67001f"],
         'OrRd': ["#fff7ec", "#fee8c8", "#fdd49e", "#fdbb84", "#fc8d59",
                  "#ef6548", "#d7301f", "#b30000", "#7f0000"],
         'YlOrRd': ["#ffffcc", "#ffeda0", "#fed976", "#feb24c", "#fd8d3c",
                    "#fc4e2a", "#e31a1c", "#bd0026", "#800026"],
         'YlOrBr': ["#ffffe5", "#fff7bc", "#fee391", "#fec44f", "#fe9929",
                    "#ec7014", "#cc4c02", "#993404", "#662506"],
         'Purples': ["#fcfbfd", "#efedf5", "#dadaeb", "#bcbddc", "#9e9ac8",
                     "#807dba", "#6a51a3", "#54278f", "#3f007d"],
         'Blues': ["#f7fbff", "#deebf7", "#c6dbef", "#9ecae1", "#6baed6",
                   "#4292c6", "#2171b5", "#08519c", "#08306b"],
         'Greens': ["#f7fcf5", "#e5f5e0", "#c7e9c0", "#a1d99b", "#74c476",
                    "#41ab5d", "#238b45", "#006d2c", "#00441b"],
         'Oranges': ["#fff5eb", "#fee6ce", "#fdd0a2", "#fdae6b", "#fd8d3c",
                     "#f16913", "#d94801", "#a63603", "#7f2704"],
         'Reds': ["#fff5f0", "#fee0d2", "#fcbba1", "#fc9272", "#fb6a4a",
                  "#ef3b2c", "#cb181d", "#a50f15", "#67000d"],
         'Greys': ["#ffffff", "#f0f0f0", "#d9d9d9", "#bdbdbd", "#969696",
                   "#737373", "#525252", "#252525", "#000000"],
         'PuOr': ["#7f3b08", "#b35806", "#e08214", "#fdb863", "#fee0b6",
                  "#f7f7f7", "#d8daeb", "#b2abd2", "#8073ac", "#542788",
                  "#2d004b"],
         'BrBG': ["#543005", "#8c510a", "#bf812d", "#dfc27d", "#f6e8c3",
                  "#f5f5f5", "#c7eae5", "#80cdc1", "#35978f", "#01665e",
                  "#003c30"],
         'PRGn': ["#40004b", "#762a83", "#9970ab", "#c2a5cf", "#e7d4e8",
                  "#f7f7f7", "#d9f0d3", "#a6dba0", "#5aae61", "#1b7837",
                  "#00441b"],
         'PiYG': ["#8e0152", "#c51b7d", "#de77ae", "#f1b6da", "#fde0ef",
                  "#f7f7f7", "#e6f5d0", "#b8e186", "#7fbc41", "#4d9221",
                  "#276419"],
         'RdBu': ["#67001f", "#b2182b", "#d6604d", "#f4a582", "#fddbc7",
                  "#f7f7f7", "#d1e5f0", "#92c5de", "#4393c3", "#2166ac",
                  "#053061"],
         'RdGy': ["#67001f", "#b2182b", "#d6604d", "#f4a582", "#fddbc7",
                  "#ffffff", "#e0e0e0", "#bababa", "#878787", "#4d4d4d",
                  "#1a1a1a"],
         'RdYlBu': ["#a50026", "#d73027", "#f46d43", "#fdae61", "#fee090",
                    "#ffffbf", "#e0f3f8", "#abd9e9", "#74add1", "#4575b4",
                    "#313695"],
         'Spectral': ["#9e0142", "#d53e4f", "#f46d43", "#fdae61", "#fee08b",
                      "#ffffbf", "#e6f598", "#abdda4", "#66c2a5", "#3288bd",
                      "#5e4fa2"],
         'RdYlGn': ["#a50026", "#d73027", "#f46d43", "#fdae61", "#fee08b",
                    "#ffffbf", "#d9ef8b", "#a6d96a", "#66bd63", "#1a9850",
                    "#006837"],
         'Accent': ["#7fc97f", "#beaed4", "#fdc086", "#ffff99", "#386cb0",
                    "#f0027f", "#bf5b17", "#666666"],
         'Dark2': ["#1b9e77", "#d95f02", "#7570b3", "#e7298a", "#66a61e",
                   "#e6ab02", "#a6761d", "#666666"],
         'Paired': ["#a6cee3", "#1f78b4", "#b2df8a", "#33a02c", "#fb9a99",
                    "#e31a1c", "#fdbf6f", "#ff7f00", "#cab2d6", "#6a3d9a",
                    "#ffff99", "#b15928"],
         'Pastel1': ["#fbb4ae", "#b3cde3", "#ccebc5", "#decbe4", "#fed9a6",
                     "#ffffcc", "#e5d8bd", "#fddaec", "#f2f2f2"],
         'Pastel2': ["#b3e2cd", "#fdcdac", "#cbd5e8", "#f4cae4", "#e6f5c9",
                     "#fff2ae", "#f1e2cc", "#cccccc"],
         'Set1': ["#e41a1c", "#377eb8", "#4daf4a", "#984ea3", "#ff7f00",
                  "#ffff33", "#a65628", "#f781bf", "#999999"],
         'Set2': ["#66c2a5", "#fc8d62", "#8da0cb", "#e78ac3", "#a6d854",
                  "#ffd92f", "#e5c494", "#b3b3b3"],
         'Set3': ["#8dd3c7", "#ffffb3", "#bebada", "#fb8072", "#80b1d3",
                  "#fdb462", "#b3de69", "#fccde5", "#d9d9d9", "#bc80bd",
                  "#ccebc5", "#ffed6f"]}

########NEW FILE########
__FILENAME__ = core
# -*- coding: utf-8 -*-
"""

Core: The core functionality for Vincent to map to Vega grammar

"""
from __future__ import (print_function, division)
import json
from string import Template
from pkg_resources import resource_string

try:
    import pandas as pd
except ImportError:
    pd = None

try:
    import numpy as np
except ImportError:
    np = None

from ._compat import str_types


def initialize_notebook():
    """Initialize the IPython notebook display elements"""
    try:
        from IPython.core.display import display, HTML
    except ImportError:
        print("IPython Notebook could not be loaded.")

    # Thanks to @jakevdp:
    # https://github.com/jakevdp/mpld3/blob/master/mpld3/_display.py#L85
    load_lib = """
                function vct_load_lib(url, callback){
                      if(typeof d3 !== 'undefined' &&
                         url === 'http://d3js.org/d3.v3.min.js'){
                        callback()
                      }
                      var s = document.createElement('script');
                      s.src = url;
                      s.async = true;
                      s.onreadystatechange = s.onload = callback;
                      s.onerror = function(){
                        console.warn("failed to load library " + url);
                        };
                      document.getElementsByTagName("head")[0].appendChild(s);
                };
                var vincent_event = new CustomEvent(
                  "vincent_libs_loaded",
                  {bubbles: true, cancelable: true}
                );
                """
    lib_urls = [
        "'http://d3js.org/d3.v3.min.js'",
        "'http://d3js.org/d3.geo.projection.v0.min.js'",
        "'http://wrobstory.github.io/d3-cloud/d3.layout.cloud.js'",
        "'http://wrobstory.github.io/vega/vega.v1.3.3.js'"
    ]
    get_lib = """vct_load_lib(%s, function(){
                  %s
                  });"""
    load_js = get_lib
    ipy_trigger = "window.dispatchEvent(vincent_event);"
    for elem in lib_urls[:-1]:
        load_js = load_js % (elem, get_lib)
    load_js = load_js % (lib_urls[-1], ipy_trigger)
    html = """
           <script>
               %s
               function load_all_libs(){
                  console.log('Loading Vincent libs...')
                  %s
               };
               if(typeof define === "function" && define.amd){
                    if (window['d3'] === undefined ||
                        window['topojson'] === undefined){
                        require.config(
                            {paths: {
                              d3: 'http://d3js.org/d3.v3.min',
                              topojson: 'http://d3js.org/topojson.v1.min'
                              }
                            }
                          );
                        require(["d3"], function(d3){
                            console.log('Loading Vincent from require.js...')
                            window.d3 = d3;
                            require(["topojson"], function(topojson){
                                window.topojson = topojson;
                                load_all_libs();
                            });
                        });
                    } else {
                        load_all_libs();
                    };
               }else{
                    console.log('Require.js not found, loading manually...')
                    load_all_libs();
               };

           </script>""" % (load_lib, load_js,)
    return display(HTML(html))


def _assert_is_type(name, value, value_type):
    """Assert that a value must be a given type."""
    if not isinstance(value, value_type):
        if type(value_type) is tuple:
            types = ', '.join(t.__name__ for t in value_type)
            raise ValueError('{0} must be one of ({1})'.format(name, types))
        else:
            raise ValueError('{0} must be {1}'
                             .format(name, value_type.__name__))


class ValidationError(Exception):
    """Exception raised with validation fails

    This exception is raised only when the ``validate`` functions of classes
    that inherit from ``FieldClass`` are called. It implies that the classes
    do not contain valid Vega JSON."""
    pass


class KeyedList(list):
    """A list that can optionally be indexed by the ``name`` attribute of
    its elements"""
    def __init__(self, attr_name='name', *args, **kwargs):
        self.attr_name = attr_name
        list.__init__(self, *args, **kwargs)

    def get_keys(self):
        keys = [getattr(x, self.attr_name) for x in self]
        if len(keys) != len(set(keys)):
            raise ValidationError('duplicate keys found')
        return keys

    def __getitem__(self, key):
        if isinstance(key, str_types):
            keys = self.get_keys()
            if key not in keys:
                raise KeyError(' "{0}" is an invalid key'.format(key))
            else:
                return self[keys.index(key)]
        else:
            return list.__getitem__(self, key)

    def __delitem__(self, key):
        if isinstance(key, str_types):
            keys = self.get_keys()
            if key not in keys:
                raise KeyError(' "{0}" is an invalid key'.format(key))
            else:
                list.__delitem__(self, keys.index(key))
        else:
            return list.__delitem__(self, key)

    def __setitem__(self, key, value):
        if isinstance(key, str_types):
            if not hasattr(value, self.attr_name):
                raise ValidationError(
                    'object must have ' + self.attr_name + ' attribute')
            elif getattr(value, self.attr_name) != key:
                raise ValidationError(
                    "key must be equal to '" + self.attr_name +
                    "' attribute")

            keys = self.get_keys()
            if key not in keys:
                self.append(value)
            else:
                list.__setitem__(self, keys.index(key), value)
        else:
            list.__setitem__(self, key, value)


def grammar(grammar_type=None, grammar_name=None):
    """Decorator to define properties that map to the ``grammar``
    dict. This dict is the canonical representation of the Vega grammar
    within Vincent.

    This decorator is intended for classes that map to some pre-defined JSON
    structure, such as axes, data, marks, scales, etc. It is assumed that this
    decorates functions with an instance of ``self.grammar``.

    Parameters
    ----------
    grammar_type : type or tuple of types, default None
        If the argument to the decorated function is not of the given types,
        then a ValueError is raised. No type checking is done if the type is
        None (default).
    grammar_name : string, default None
        An optional name to map to the internal ``grammar`` dict. If None
        (default), then the key for the dict is the name of the function
        being decorated. If not None, then it will be the name specified
        here. This is useful if the expected JSON field name is a Python
        keyword or has an un-Pythonic name.

    This should decorate a "validator" function that should return no value
    but raise an exception if the provided value is not valid Vega grammar. If
    the validator throws no exception, then the value is assigned to the
    ``grammar`` dict.

    The validator function should take only one argument - the value to be
    validated - so that no ``self`` argument is included; the validator
    should not modify the class.

    If no arguments are given, then no type-checking is done the property
    will be mapped to a field with the name of the decorated function.

    The doc string for the property is taken from the validator functions's
    doc string.
    """
    def grammar_creator(validator, name):
        def setter(self, value):
            if isinstance(grammar_type, (type, tuple)):
                _assert_is_type(validator.__name__, value, grammar_type)
            validator(value)
            self.grammar[name] = value

        def getter(self):
            return self.grammar.get(name, None)

        def deleter(self):
            if name in self.grammar:
                del self.grammar[name]

        return property(getter, setter, deleter, validator.__doc__)

    if isinstance(grammar_type, (type, tuple)):
        # If grammar_type is a type, return another decorator.
        def grammar_dec(validator):
            # Make sure to use the grammar name if it's there.
            if grammar_name:
                return grammar_creator(validator, grammar_name)
            else:
                return grammar_creator(validator, validator.__name__)
        return grammar_dec
    elif isinstance(grammar_name, str_types):
        # If grammar_name is a string, use that name and return another
        # decorator.
        def grammar_dec(validator):
            return grammar_creator(validator, grammar_name)
        return grammar_dec
    else:
        # Otherwise we assume that grammar_type is actually the function being
        # decorated.
        return grammar_creator(grammar_type, grammar_type.__name__)


class GrammarDict(dict):
    """The Vega Grammar. When called, obj.grammar returns a Python data
    structure for the Vega Grammar. When printed, obj.grammar returns a
    string representation."""

    def __init__(self, *args, **kwargs):
        """Standard Dict init"""
        dict.__init__(self, *args, **kwargs)

    def encoder(self, obj):
        """Encode grammar objects for each level of hierarchy"""
        if hasattr(obj, 'grammar'):
            return obj.grammar

    def __call__(self):
        """When called, return the Vega grammar as a Python data structure."""

        return json.loads(json.dumps(self, default=self.encoder))

    def __str__(self):
        """String representation of Vega Grammar"""

        return json.dumps(self, default=self.encoder)


class GrammarClass(object):
    """Base class for objects that rely on an internal ``grammar`` dict. This
    dict contains the complete Vega grammar.

    This should be used as a superclass for classes that map to some JSON
    structure. The JSON content is stored in an internal dict named
    ``grammar``.
    """
    def __init__(self, **kwargs):
        """Initialize a GrammarClass

        **kwargs are attribute-value pairs that are set on initialization.
        These will generally be keys for the ``grammar`` dict. If the
        attribute does not already exist as a property, then a
        ``ValueError`` is raised.
        """
        self.grammar = GrammarDict()

        for attr, value in sorted(kwargs.items()):
            if hasattr(self, attr):
                setattr(self, attr, value)
            else:
                raise ValueError('unknown keyword argument ' + attr)

    def validate(self):
        """Validate the contents of the object.

        This calls ``setattr`` for each of the class's grammar properties. It
        will catch ``ValueError``s raised by the grammar property's setters
        and re-raise them as :class:`ValidationError`.
        """
        for key, val in self.grammar.items():
            try:
                setattr(self, key, val)
            except ValueError as e:
                raise ValidationError('invalid contents: ' + e.args[0])

    def to_json(self, path=None, html_out=False,
                html_path='vega_template.html', validate=False,
                pretty_print=True):
        """Convert object to JSON

        Parameters
        ----------
        path: string, default None
            Path to write JSON out. If there is no path provided, JSON
            will be returned as a string to the console.
        html_out: boolean, default False
            If True, vincent will output an simple HTML scaffold to
            visualize the vega json output.
        html_path: string, default 'vega_template.html'
            Path for the html file (if html_out=True)
        validate : boolean
            If True, call the object's `validate` method before
            serializing. Default is False.
        pretty_print : boolean
            If True (default), JSON is printed in more-readable form with
            indentation and spaces.

        Returns
        -------
        string
            JSON serialization of the class's grammar properties.
        """
        if validate:
            self.validate()

        if pretty_print:
            dumps_args = {'indent': 2, 'separators': (',', ': ')}
        else:
            dumps_args = {}

        def encoder(obj):
            if hasattr(obj, 'grammar'):
                return obj.grammar

        if html_out:
            template = Template(
                str(resource_string('vincent', 'vega_template.html')))
            with open(html_path, 'w') as f:
                f.write(template.substitute(path=path))

        if path:
            with open(path, 'w') as f:
                json.dump(self.grammar, f, default=encoder, sort_keys=True,
                          **dumps_args)
        else:
            return json.dumps(self.grammar, default=encoder, sort_keys=True,
                              **dumps_args)

    def from_json(self):
        """Load object from JSON

        Not yet implemented.
        """
        raise NotImplementedError()


class LoadError(Exception):
    """Exception for errors on loading data from third-party objects"""
    pass

########NEW FILE########
__FILENAME__ = data
# -*- coding: utf-8 -*-
"""

Data: Vincent Data Class for data importing and Vega Data type

"""
from __future__ import (print_function, division)
import time
import json
from .core import (
    _assert_is_type,
    ValidationError,
    grammar,
    GrammarClass,
    LoadError
)
from ._compat import str_types

try:
    import pandas as pd
except ImportError:
    pd = None

try:
    import numpy as np
except ImportError:
    np = None


class Data(GrammarClass):
    """Data container for visualization

    The Vega document may contain the data itself or a reference to a URL
    containing the data and formatting instructions. Additionally, new data
    can be created from old data via the transform fields.
    """
    _default_index_key = 'idx'

    def __init__(self, name=None, **kwargs):
        """Initialize a Data object

        Parameters
        ----------
        name : string, default None
            Name of the data set. If None (default), then the name will be
            set to ``'table'``.
        **kwargs : dict
            Attributes to set on initialization.
        """
        super(self.__class__, self).__init__(**kwargs)
        self.name = name if name else 'table'

    @grammar(str_types)
    def name(value):
        """string : Name of the data

        This is used by other components (``Mark``, etc.) for reference.
        """

    @grammar(str_types)
    def url(value):
        """string : URL from which to load the data

            This can be used as an alternative to defining the data in the
            ``values`` attribute.
        """

    @grammar(list)
    def values(value):
        """list : Data contents

        Data is represented in tabular form, where each element of
        ``values`` corresponds to a row of data.  Each row of data is
        represented by a dict or a raw number. The keys of the dict are
        columns and the values are individual data points. The keys of the
        dicts must be strings for the data to correctly serialize to JSON.

        The data will often have an "index" column representing the
        independent variable, with the remaining columns representing the
        dependent variables, though this is not required. The ``Data`` class
        itself, however, is agnostic to which columns are dependent and
        independent.

        For example, the values attribute
        ``[{'x': 0, 'y': 3.2}, {'x': 1, 'y': 1.3}]``
        could represent two rows of two variables - possibly an independent
        variable ``'x'`` and a dependent variable ``'y'``.
        For simple data sets, an alternative values attribute could be a
        simple list of numbers such as
        ``[2, 12, 3, 5]``.

        It may be more convenient to load data from pandas or NumPy objects.
        See the methods :func:`Data.from_pandas` and
        :func:`Data.from_numpy`.
        """
        for row in value:
            _assert_is_type('values row', row, (float, int, dict))

    @grammar(str_types)
    def source(value):
        """string : ``name`` field of another data set

        This is typically used with data transforms to create new data
        values.
        """

    @grammar(list)
    def transform(value):
        """list : transforms to apply to the data

        Note: Transform-relational classes are not yet implemented.
        """

    @grammar(dict)
    def format(value):
        """dict : information about the data format

        This is only used when loading data from the ``url`` attribute.
        Format-relational classes are not yet implemented.
        """

    def validate(self, *args):
        """Validate contents of class
        """
        super(self.__class__, self).validate(*args)
        if not self.name:
            raise ValidationError('name is required for Data')

    @staticmethod
    def serialize(obj):
        """Convert an object into a JSON-serializable value

        This is used by the ``from_pandas`` and ``from_numpy`` functions to
        convert data to JSON-serializable types when loading.
        """
        if isinstance(obj, str_types):
            return obj
        elif hasattr(obj, 'timetuple'):
            return int(time.mktime(obj.timetuple())) * 1000
        elif hasattr(obj, 'item'):
            return obj.item()
        elif hasattr(obj, '__float__'):
            if isinstance(obj, int):
                return int(obj)
            else:
                return float(obj)
        elif hasattr(obj, '__int__'):
            return int(obj)
        else:
            raise LoadError('cannot serialize index of type '
                            + type(obj).__name__)

    @classmethod
    def from_pandas(cls, data, columns=None, key_on='idx', name=None,
                    series_key='data', grouped=False, records=False, **kwargs):
        """Load values from a pandas ``Series`` or ``DataFrame`` object

        Parameters
        ----------
        data : pandas ``Series`` or ``DataFrame``
            Pandas object to import data from.
        columns: list, default None
            DataFrame columns to convert to Data. Keys default to col names.
            If columns are given and on_index is False, x-axis data will
            default to the first column.
        key_on: string, default 'index'
            Value to key on for x-axis data. Defaults to index.
        name : string, default None
            Applies to the ``name`` attribute of the generated class. If
            ``None`` (default), then the ``name`` attribute of ``pd_obj`` is
            used if it exists, or ``'table'`` if it doesn't.
        series_key : string, default 'data'
            Applies only to ``Series``. If ``None`` (default), then defaults to
            data.name. For example, if ``series_key`` is ``'x'``, then the
            entries of the ``values`` list
            will be ``{'idx': ..., 'col': 'x', 'val': ...}``.
        grouped: boolean, default False
            Pass true for an extra grouping parameter
        records: boolean, defaule False
            Requires Pandas 0.12 or greater. Writes the Pandas DataFrame
            using the df.to_json(orient='records') formatting.
        **kwargs : dict
            Additional arguments passed to the :class:`Data` constructor.
        """
        # Note: There's an experimental JSON encoder floating around in
        # pandas land that hasn't made it into the main branch. This
        # function should be revisited if it ever does.
        if not pd:
            raise LoadError('pandas could not be imported')
        if not hasattr(data, 'index'):
            raise ValueError('Please load a Pandas object.')

        if name:
            vega_data = cls(name=name, **kwargs)
        else:
            vega_data = cls(name='table', **kwargs)

        pd_obj = data.copy()
        if columns:
            pd_obj = data[columns]
        if key_on != 'idx':
            pd_obj.index = data[key_on]
        if records:
            # The worst
            vega_data.values = json.loads(pd_obj.to_json(orient='records'))
            return vega_data

        vega_data.values = []

        if isinstance(pd_obj, pd.Series):
            data_key = data.name or series_key
            for i, v in pd_obj.iteritems():
                value = {}
                value['idx'] = cls.serialize(i)
                value['col'] = data_key
                value['val'] = cls.serialize(v)
                vega_data.values.append(value)

        elif isinstance(pd_obj, pd.DataFrame):
            # We have to explicitly convert the column names to strings
            # because the json serializer doesn't allow for integer keys.
            for i, row in pd_obj.iterrows():
                for num, (k, v) in enumerate(row.iteritems()):
                    value = {}
                    value['idx'] = cls.serialize(i)
                    value['col'] = cls.serialize(k)
                    value['val'] = cls.serialize(v)
                    if grouped:
                        value['group'] = num
                    vega_data.values.append(value)
        else:
            raise ValueError('cannot load from data type '
                             + type(pd_obj).__name__)
        return vega_data

    @classmethod
    def from_numpy(cls, np_obj, name, columns, index=None, index_key=None,
                   **kwargs):
        """Load values from a numpy array

        Parameters
        ----------
        np_obj : numpy.ndarray
            numpy array to load data from
        name : string
            ``name`` field for the data
        columns : iterable
            Sequence of column names, from left to right. Must have same
            length as the number of columns of ``np_obj``.
        index : iterable, default None
            Sequence of indices from top to bottom. If ``None`` (default),
            then the indices are integers starting at 0. Must have same
            length as the number of rows of ``np_obj``.
        index_key : string, default None
            Key to use for the index. If ``None`` (default), ``idx`` is
            used.
        **kwargs : dict
            Additional arguments passed to the :class:`Data` constructor

        Notes
        -----
        The individual elements of ``np_obj``, ``columns``, and ``index``
        must return valid values from :func:`Data.serialize`.
        """
        if not np:
            raise LoadError('numpy could not be imported')

        _assert_is_type('numpy object', np_obj, np.ndarray)

        # Integer index if none is provided
        index = index or range(np_obj.shape[0])
        # Explicitly map dict-keys to strings for JSON serializer.
        columns = list(map(str, columns))

        index_key = index_key or cls._default_index_key

        if len(index) != np_obj.shape[0]:
            raise LoadError(
                'length of index must be equal to number of rows of array')
        elif len(columns) != np_obj.shape[1]:
            raise LoadError(
                'length of columns must be equal to number of columns of '
                'array')

        data = cls(name=name, **kwargs)
        data.values = [
            dict([(index_key, cls.serialize(idx))] +
                 [(col, x) for col, x in zip(columns, row)])
            for idx, row in zip(index, np_obj.tolist())]

        return data

    @classmethod
    def from_mult_iters(cls, name=None, idx=None, **kwargs):
        """Load values from multiple iters

        Parameters
        ----------
        name : string, default None
            Name of the data set. If None (default), the name will be set to
            ``'table'``.
        idx: string, default None
            Iterable to use for the data index
        **kwargs : dict of iterables
            The ``values`` field will contain dictionaries with keys for
            each of the iterables provided. For example,

                d = Data.from_iters(idx='x', x=[0, 1, 5], y=(10, 20, 30))

            would result in ``d`` having a ``values`` field with

                [{'idx': 0, 'col': 'y', 'val': 10},
                 {'idx': 1, 'col': 'y', 'val': 20}

            If the iterables are not the same length, then ValueError is
            raised.
        """
        if not name:
            name = 'table'

        lengths = [len(v) for v in kwargs.values()]

        if len(set(lengths)) != 1:
            raise ValueError('Iterables must all be same length')

        if not idx:
            raise ValueError('Must provide iter name index reference')

        index = kwargs.pop(idx)
        vega_vals = []
        for k, v in sorted(kwargs.items()):
            for idx, val in zip(index, v):
                value = {}
                value['idx'] = idx
                value['col'] = k
                value['val'] = val
                vega_vals.append(value)

        return cls(name, values=vega_vals)

    @classmethod
    def from_iter(cls, data, name=None):
        """Convenience method for loading data from an iterable.

        Defaults to numerical indexing for x-axis.

        Parameters
        ----------
        data: iterable
            An iterable of data (list, tuple, dict of key/val pairs)
        name: string, default None
            Name of the data set. If None (default), the name will be set to
            ``'table'``.

        """

        if not name:
            name = 'table'
        if isinstance(data, (list, tuple)):
            data = {x: y for x, y in enumerate(data)}

        values = [{'idx': k, 'col': 'data', 'val': v}
                  for k, v in sorted(data.items())]
        return cls(name, values=values)

    @classmethod
    def keypairs(cls, data, columns=None, use_index=False, name=None):
        """This will format the data as Key: Value pairs, rather than the
        idx/col/val style. This is useful for some transforms, and to
        key choropleth map data

        Standard Data Types:
            List: [0, 10, 20, 30, 40]
            Paired Tuples: ((0, 1), (0, 2), (0, 3))
            Dict: {'A': 10, 'B': 20, 'C': 30, 'D': 40, 'E': 50}

        Plus Pandas DataFrame and Series, and Numpy ndarray

        Parameters
        ----------
        data:
            List, Tuple, Dict, Pandas Series/DataFrame, Numpy ndarray
        columns: list, default None
            If passing Pandas DataFrame, you must pass at least one column
            name.If one column is passed, x-values will default to the index
            values.If two column names are passed, x-values are columns[0],
            y-values columns[1].
        use_index: boolean, default False
            Use the DataFrame index for your x-values

        """
        if not name:
            name = 'table'
        cls.raw_data = data

        # Tuples
        if isinstance(data, tuple):
            values = [{"x": x[0], "y": x[1]} for x in data]

        # Lists
        elif isinstance(data, list):
            values = [{"x": x, "y": y}
                      for x, y in zip(range(len(data) + 1), data)]

        # Dicts
        elif isinstance(data, dict) or isinstance(data, pd.Series):
            values = [{"x": x, "y": y} for x, y in sorted(data.items())]

        # Dataframes
        elif isinstance(data, pd.DataFrame):
            if len(columns) > 1 and use_index:
                raise ValueError('If using index as x-axis, len(columns)'
                                 'cannot be > 1')
            if use_index or len(columns) == 1:
                values = [{"x": cls.serialize(x[0]),
                           "y": cls.serialize(x[1][columns[0]])}
                          for x in data.iterrows()]
            else:

                values = [{"x": cls.serialize(x[1][columns[0]]),
                           "y": cls.serialize(x[1][columns[1]])}
                          for x in data.iterrows()]

        # NumPy arrays
        elif isinstance(data, np.ndarray):
            values = cls._numpy_to_values(data)
        else:
            raise TypeError('unknown data type %s' % type(data))

        return cls(name, values=values)

    @staticmethod
    def _numpy_to_values(data):
        '''Convert a NumPy array to values attribute'''
        def to_list_no_index(xvals, yvals):
            return [{"x": x, "y": np.asscalar(y)}
                    for x, y in zip(xvals, yvals)]

        if len(data.shape) == 1 or data.shape[1] == 1:
            xvals = range(data.shape[0] + 1)
            values = to_list_no_index(xvals, data)
        elif len(data.shape) == 2:
            if data.shape[1] == 2:
                # NumPy arrays and matrices have different iteration rules.
                if isinstance(data, np.matrix):
                    xidx = (0, 0)
                    yidx = (0, 1)
                else:
                    xidx = 0
                    yidx = 1

                xvals = [np.asscalar(row[xidx]) for row in data]
                yvals = [np.asscalar(row[yidx]) for row in data]
                values = [{"x": x, "y": y} for x, y in zip(xvals, yvals)]
            else:
                raise ValueError('arrays with > 2 columns not supported')
        else:
            raise ValueError('invalid dimensions for ndarray')

        return values

    def to_json(self, validate=False, pretty_print=True, data_path=None):
        """Convert data to JSON

        Parameters
        ----------
        data_path : string
            If not None, then data is written to a separate file at the
            specified path. Note that the ``url`` attribute if the data must
            be set independently for the data to load correctly.

        Returns
        -------
        string
            Valid Vega JSON.
        """
        # TODO: support writing to separate file
        return super(self.__class__, self).to_json(validate=validate,
                                                   pretty_print=pretty_print)

########NEW FILE########
__FILENAME__ = legends
# -*- coding: utf-8 -*-
"""

Legend: Classes to define Vega Legends

"""
from __future__ import (print_function, division)
from .core import grammar, GrammarClass
from .properties import PropertySet
from ._compat import str_types


class LegendProperties(GrammarClass):
    """Sets of Legend Properties.

    These properties enable custom mark properties for the legend
    elements. Each element can use a standard ValueRef for values.

    """

    @grammar(PropertySet)
    def title(value):
        """Legend title properties """

    @grammar(PropertySet)
    def labels(value):
        """Legend label properties"""

    @grammar(PropertySet)
    def symbols(value):
        """Legend symbol properties"""

    @grammar(PropertySet)
    def gradient(value):
        """Continuous color gradient for legend"""

    @grammar(PropertySet)
    def legend(value):
        """Legend styling properties"""


class Legend(GrammarClass):
    """Definition for Vega Legends

    Legends visualize scales, and take one or more scales as their input.
    They can be customized via a LegendProperty object.

    """

    @grammar(str_types)
    def size(value):
        """The name of the scale that determines an item's size"""

    @grammar(str_types)
    def shape(value):
        """The name of the scale that determines an item's shape"""

    @grammar(str_types)
    def fill(value):
        """The name of the scale that determines an item's fill color"""

    @grammar(str_types)
    def stroke(value):
        """The name of the scale that determine's stroke color"""

    @grammar(str_types)
    def orient(value):
        """The orientation of the legend.

        Must be one of 'left' or 'right'
        """

        if value not in ('left', 'right'):
            raise ValueError('Value must be one of "left" or "right".')

    @grammar(int)
    def offset(value):
        """Pixel offset from figure"""

    @grammar(str_types)
    def title(value):
        """The Legend title"""

    @grammar(str_types)
    def format(value):
        """Optional formatting pattern for legend labels.

        See the D3 formatting pattern:
        https://github.com/mbostock/d3/wiki/Formatting
        """

    @grammar(list)
    def values(value):
        """Explicitly set visible legend values"""

    @grammar(LegendProperties)
    def properties(value):
        """Optional mark property definitions for custom styling"""

########NEW FILE########
__FILENAME__ = marks
# -*- coding: utf-8 -*-
"""

Marks: Classes to define Vega Marks

"""
from .core import grammar, GrammarClass, KeyedList
from .values import ValueRef
from .properties import PropertySet
from ._compat import str_types


class MarkProperties(GrammarClass):
    """Sets of all Mark properties

    Mark properties can change depending on user interaction or changing
    data. This class defines four events for which the properties may
    change.
    """
    @grammar(PropertySet)
    def enter(value):
        """PropertySet : properties applied when data is loaded
        """

    @grammar(PropertySet)
    def exit(value):
        """PropertySet : properties applied when data is removed
        """

    @grammar(PropertySet)
    def update(value):
        """PropertySet : properties applied for all non-exiting data

        (This is vague. Need better Vega docs.)
        """

    @grammar(PropertySet)
    def hover(value):
        """PropertySet, properties applied on mouse-over

        On mouse out, the ``update`` properties are applied.
        """


class MarkRef(GrammarClass):
    """Definitions for Mark source data
    """
    @grammar(str_types)
    def data(value):
        """string : Name of the source `Data`"""

    @grammar(list)
    def transform(value):
        """list : List of transforms to apply to the data"""


class Mark(GrammarClass):
    """Definitions for data marks

    Marks are the fundamental component that the viewer sees - such as a
    bar, line etc.. This class defines how the marks appear and what data
    the marks represent.
    """
    _valid_type_values = frozenset(['rect', 'symbol', 'path', 'arc', 'area',
                                    'line', 'image', 'text', 'group'])

    @grammar(str_types)
    def name(value):
        """string : Optional unique name for mark"""

    @grammar(str_types)
    def description(value):
        """string : Optional description for mark"""

    @grammar(str_types)
    def type(value):
        """string : Type of mark

        Valid types are ``'rect'``, ``'symbol'``, ``'path'``, ``'arc'``,
        ``'area'``, ``'line'``, ``'image'``, and ``'text'``.
        """
        if value not in Mark._valid_type_values:
            raise ValueError(
                'invalid mark type %s, valid types are %s' % (
                    value, Mark._valid_type_values))

    @grammar(grammar_type=MarkRef, grammar_name='from')
    def from_(value):
        """dict : Description of data to visualize

        Note that although the property has the name ``from_`` (using
        ``from`` is invalid Python syntax), the JSON will contain the
        correct property ``from``.
        """

    @grammar(MarkProperties)
    def properties(value):
        """MarkProperties : Mark property set definitions"""

    @grammar(str_types)
    def key(value):
        """string : Field to use for data binding

        When updating data dynamically, restrict dynamic transitions from
        affecting data with the given key. This can be useful for something
        like scrolling time series. See the Vega examples.
        """

    @grammar(ValueRef)
    def delay(value):
        """ValueRef, number : Transitional delay in milliseconds.
        """

    @grammar(str_types)
    def ease(value):
        """string : Type of transition easing

        Valid types are ``'linear'``, ``'quad'``, ``'cubic'``, ``'sin'``,
        ``'exp'``, ``'circle'``, and ``'bounce'``, which can be appended
        with the modifiers ``'in'``, ``'out'``, ``'in-out'``, and
        ``'out-in'``. The default is ``'cubic-in-out'``.

        See the documentation for the d3 ease function for more details.
        """

    @grammar(list)
    def marks(value):
        """list: For grouped marks, you can define a "marks" with a mark
        """

    @grammar((list, KeyedList))
    def scales(value):
        """list or KeyedList: For grouped marks, you can define a set of scales
        for within the mark groups
        """

########NEW FILE########
__FILENAME__ = properties
# -*- coding: utf-8 -*-
"""

PropertySet: Definition of properties for ``Mark`` objects and labels of
``Axis``objects

"""

from .core import _assert_is_type, grammar, GrammarClass
from .values import ValueRef
from ._compat import str_types


class PropertySet(GrammarClass):
    """Definition of properties for ``Mark`` objects and labels of ``Axis``
    objects

    These define the appearance details for marks and axes.

    All properties are defined by ``ValueRef`` classes. As a warning,
    validation of the values is only performed on the ``value`` field of the
    class, which is ignored by Vega if the ``field`` property is set.
    """
    @grammar(ValueRef)
    def x(value):
        """ValueRef : number, left-most x-coordinate

        For most marks, this will be equal to the field of the independent
        variable. For example,
        ``{"scale": "x", "field": "data.x"}``
        will place a mark with its left-most coordinate at the x-values of
        the data. Something like
        ``{"scale": "x", "value": 10}``
        will place a single mark at given x-coordinate.
        """

    @grammar(ValueRef)
    def x2(value):
        """ValueRef : number, right-most x-coordinate

        Generally, for marks where the width is significant, it's better to
        use the ``width`` property.
        """

    @grammar(ValueRef)
    def width(value):
        """ValueRef : number, width of the mark

        Set the ``band`` property of the ``ValueRef`` to True to use the
        full width.
        """

    @grammar(ValueRef)
    def y(value):
        """ValueRef : number, top-most y-coordinate

        The same remarks for the ``x`` property apply here.
        """

    @grammar(ValueRef)
    def y2(value):
        """ValueRef : number, bottom-most y-coordinate

        The same remarks for the ``x2`` property apply here.
        """

    @grammar(ValueRef)
    def height(value):
        """ValueRef : number, height of the mark
        """

    @grammar(ValueRef)
    def opacity(value):
        """ValueRef : number, overall opacity (0 to 1)
        """

    @grammar(ValueRef)
    def fill(value):
        """ValueRef : string, fill color for the mark

        Colors can be specified in standard HTML hex notation or as CSS3
        compatible strings. The color string is not validated due to its
        large number of valid values.
        """
        if value.value:
            _assert_is_type('fill.value', value.value, str_types)

    @grammar(grammar_type=ValueRef, grammar_name='fillOpacity')
    def fill_opacity(value):
        """ValueRef : int or float, opacity of the fill (0 to 1)
        """
        if value.value:
            _assert_is_type('fill_opacity.value', value.value,
                            (float, int))
            if value.value < 0 or value.value > 1:
                raise ValueError(
                    'fill_opacity must be between 0 and 1')

    @grammar(ValueRef)
    def stroke(value):
        """ValueRef : color, stroke color for the mark

        Colors can be specified in standard HTML hex notation or as CSS3
        compatible strings. The color string is not validated due to its
        large number of valid values.
        """
        if value.value:
            _assert_is_type('stroke.value', value.value, str)

    @grammar(grammar_type=ValueRef, grammar_name='strokeWidth')
    def stroke_width(value):
        """ValueRef : int, width of the stroke in pixels
        """
        if value.value:
            _assert_is_type('stroke_width.value', value.value, int)
            if value.value < 0:
                raise ValueError('stroke width cannot be negative')

    @grammar(grammar_type=ValueRef, grammar_name='strokeOpacity')
    def stroke_opacity(value):
        """ValueRef : number, opacity of the stroke (0 to 1)
        """
        if value.value:
            _assert_is_type('stroke_opacity.value', value.value,
                            (float, int))
            if value.value < 0 or value.value > 1:
                raise ValueError(
                    'stroke_opacity must be between 0 and 1')

    @grammar(ValueRef)
    def size(value):
        """ValueRef : number, area of the mark in pixels

        This is the total area of a symbol. For example, a value of 500 and
        a ``shape`` of ``'circle'`` would result in circles with an area of
        500 square pixels. Only used if ``type`` is ``'symbol'``.
        """
        if value.value:
            _assert_is_type('size.value', value.value, int)
            if value.value < 0:
                raise ValueError('size cannot be negative')

    _valid_shapes = frozenset([
        "circle", "square", "cross", "diamond", "triangle-up", "triangle-down"
        ])

    @grammar(ValueRef)
    def shape(value):
        """ValueRef : string, type of symbol to use

        Possible values are ``'circle'`` (default), ``'square'``,
        ``'cross'``, ``'diamond'``, ``'triangle-up'``, and
        ``'triangle-down'``. Only used if ``type`` is ``'symbol'``.
        """
        if value.value:
            _assert_is_type('shape.value', value.value, str_types)
            if value.value not in PropertySet._valid_shapes:
                raise ValueError(value.value + ' is not a valid shape')

    @grammar(ValueRef)
    def path(value):
        """ValueRef : string, SVG path string

        This would typically be used for maps and other things where the
        path is taken from the data.
        """
        if value.value:
            _assert_is_type('path.value', value.value, str_types)

    @grammar(grammar_type=ValueRef, grammar_name='innerRadius')
    def inner_radius(value):
        """ValueRef : number, inner radius of arc in pixels

        Only used if ``type`` is ``'arc'``."""

    @grammar(grammar_type=ValueRef, grammar_name='outerRadius')
    def outer_radius(value):
        """ValueRef : number, outer radius of the arc in pixels

        Only used if ``type`` is ``'arc'``."""

    @grammar(grammar_type=ValueRef, grammar_name='startAngle')
    def start_angle(value):
        """ValueRef : number, start angle of the arc in radians

        Only used if ``type`` is ``'arc'``."""

    @grammar(grammar_type=ValueRef, grammar_name='endAngle')
    def end_angle(value):
        """ValueRef : number, end angle of the arc in radians

        Only used if ``type`` is ``'arc'``."""

    _area_methods = [
        "linear", "step-before", "step-after", "basis", "basis-open",
        "cardinal", "cardinal-open", "monotone"
        ]
    _line_methods = [
        "linear", "step-before", "step-after", "basis", "basis-open",
        "basis-closed", "bundle", "cardinal", "cardinal-open",
        "cardinal-closed", "monotone"
        ]
    _valid_methods = frozenset(_area_methods + _line_methods)

    @grammar(ValueRef)
    def interpolate(value):
        """ValueRef : string, line interpolation method to use

        Possible values for ``area`` types are `'linear'`,
        ``'step-before'``, ``'step-after'``, ``'basis'``, ``'basis-open'``,
        ``'cardinal'``, ``'cardinal-open'``, ``'monotone'``. ``line`` types
        have all values for ``area`` as well as ``'basis-closed'``,
        ``'bundle'``, and ``'cardinal-closed'``.

        Only used if ``type`` is ``'area'`` or ``'line'``.
        """
        if value.value:
            _assert_is_type('shape.value', value.value, str_types)
            if value.value not in PropertySet._valid_methods:
                raise ValueError(value.value + ' is not a valid method')

    @grammar(ValueRef)
    def tension(value):
        """ValueRef : number, tension used for interpolation

        Only used if ``type`` is ``'area'`` or ``'line'``.
        """

    @grammar(ValueRef)
    def url(value):
        """ValueRef : string, url of image

        Only used if ``type`` is ``'image'``.
        """

    _valid_align = frozenset(["left", "right", "center"])

    @grammar(ValueRef)
    def align(value):
        """ValueRef : string, horizontal alignment of mark

        Possible values are ``'left'``, ``'right'``, and ``'center'``. Only
        used if ``type`` is ``'image'`` or ``'text'``.
        """
        if value.value:
            _assert_is_type('shape.value', value.value, str_types)
            if value.value not in PropertySet._valid_align:
                raise ValueError(value.value + ' is not a valid alignment')

    _valid_baseline = frozenset(["top", "middle", "bottom"])

    @grammar(ValueRef)
    def baseline(value):
        """ValueRef : string, vertical alignment of mark

        Possible values are ``'top'``, ``'middle'``, and ``'bottom'``. Only
        used if ``type`` is ``'image'`` or ``'text'``.
        """
        if value.value:
            _assert_is_type('shape.value', value.value, str_types)
            if value.value not in PropertySet._valid_baseline:
                raise ValueError(value.value + ' is not a valid baseline')

    @grammar(ValueRef)
    def text(value):
        """ValueRef : string, text to display

        Only used if ``type`` is ``'text'``."""

    @grammar(ValueRef)
    def dx(value):
        """ValueRef : number, horizontal margin between text and anchor
        point in pixels

        Ignored if ``align`` is ``'center'``. Only used if ``type`` is
        ``'text'``.
        """

    @grammar(ValueRef)
    def dy(value):
        """ValueRef : number, vertical margin between text and anchor
        point in pixels

        Ignored if ``baseline`` is ``'middle'``. Only used if ``type`` is
        ``'text'``.
        """

    @grammar(ValueRef)
    def angle(value):
        """ValueRef : number, rotation of text in degrees

        Only used if ``type`` is ``'text'``.
        """

    @grammar(ValueRef)
    def font(value):
        """ValueRef : string, typeface for text

        Only used if ``type`` is ``'text'``.
        """

    @grammar(grammar_type=ValueRef, grammar_name='fontSize')
    def font_size(value):
        """ValueRef : number, font size in pixels

        Only used if ``type`` is ``'text'``.
        """

    @grammar(grammar_type=ValueRef, grammar_name='fontWeight')
    def font_weight(value):
        """ValueRef : string, font weight

        Should be a valid SVG font weight. Only used if ``type`` is
        ``'text'``.
        """

    @grammar(grammar_type=ValueRef, grammar_name='fontStyle')
    def font_style(value):
        """ValueRef : string, font style

        Should be a valid SVG font style. Only used if ``type`` is
        ``'text'``.
        """

########NEW FILE########
__FILENAME__ = scales
# -*- coding: utf-8 -*-
"""

Scales: Classes to define Vega scales

"""
from .core import grammar, GrammarClass
from ._compat import str_types


class DataRef(GrammarClass):
    """Definitions for how data is referenced by scales

    Data can be referenced in multiple ways, and sometimes it makes sense to
    reference multiple data fields at once.
    """
    @grammar(str_types)
    def data(value):
        """string : Name of data-set containing the domain values"""

    @grammar((list,) + str_types)
    def field(value):
        """string or list of strings : Reference to desired data field(s)

        If multiple fields are given, then the values of all fields are
        included in the domain.
        """


class Scale(GrammarClass):
    """Definitions for mapping from data space to visual space

    Scales determine the way in which data is mapped from a data space (such
    as numbers, time stamps, etc.) to a visual space (length of a line,
    height of a bar, etc.), for both independent and dependent variables.
    """
    @grammar(str_types)
    def name(value):
        """string : Unique name for the scale

        This is used for referencing by other components (mainly ``Mark``).
        """

    @grammar(str_types)
    def type(value):
        """string : Type of the scale

        Valid types are as follows:

        * ``'ordinal'``: ordinal scale types
        * ``'time'`` or ``'utc'``: time scale types
        * ``'linear'``, ``'log'``, ``'pow'``, ``'sqrt'``, ``'quantile'``,
          ``'quantize'``, and ``'threshold'``: quantitative scale types

        For time scales, the value should be a Javascript-style numeric
        value of seconds.  ``'time'`` implies the value is in local time.

        If unspecified, then the scale is assumed to be linear. See the d3
        documentation for scale type details.
        """

    @grammar((list, DataRef))
    def domain(value):
        """list or DataRef : Domain of the scale
        """

    @grammar(grammar_type=(float, int, DataRef), grammar_name='domainMin')
    def domain_min(value):
        """float, int, or DataRef : Minimum domain value

        Only used for quantitative/time scales. This takes precedence over
        the minimum of the ``domain`` property.
        """

    @grammar(grammar_type=(float, int, DataRef),
             grammar_name='domainMax')
    def domain_max(value):
        """float, int, or DataRef : Maximum domain value

        Only used for quantitative/time scales. This takes precedence over
        the maximum of the ``domain`` property.
        """

    @grammar((list,) + str_types)
    def range(value):
        """list or string : Range of the scale

        For quantitative scales, the range may be specified as a two-element
        list of min/max values. For ordinal scales, the range should be a
        list of output values mapped to the input values.

        String values may be used to automatically set a range:
            - ``'width'`` - Set the range to the width of the visualization
            - ``'height'`` - Set the range to the height of the visualization
            - ``'shapes'`` - Equivalent to the symbol types ``['circle',
              'cross', 'diamond', 'square', 'triangle-down',
              'triangle-up']``
            - ``'category10'`` - A pre-determined 10-color pallet
            - ``'category20'`` - A pre-determined 20-color pallet
        """

    @grammar(grammar_type=(float, int, DataRef), grammar_name='rangeMin')
    def range_min(value):
        """float, int, or DataRef : Minimum range value

        Only used for quantitative/time scales. This takes precedence over
        the minimum of the ``range`` property.
        """

    @grammar(grammar_type=(float, int, DataRef), grammar_name='rangeMax')
    def range_max(value):
        """float, int, or DataRef : Maximum range value

        Only used for quantitative/time scales. This takes precedence over
        the maximum of the ``range`` property.
        """

    @grammar(bool)
    def reverse(value):
        """boolean : If True, flip the scale range"""

    @grammar(bool)
    def round(value):
        """boolean : If True, numeric output values are rounded to
        integers"""

    @grammar(bool)
    def points(value):
        """boolean : If True, distribute ordinal values over evenly spaced
        points between ``range_min`` and ``range_max``

        Ignored for non-ordinal scales.
        """

    @grammar(bool)
    def clamp(value):
        """boolean : If True, values that exceed the domain are clamped to
        within the domain

        Ignored for ordinal scales.
        """

    @grammar((bool,) + str_types)
    def nice(value):
        """boolean or string : scale the domain to a more human-friendly set

        If the scale ``type`` is ``'time'`` or ``'utc'``, then the value
        should be one of ``'second'``, ``'minute'``, ``'hour'``, ``'day'``,
        ``'week'``, ``'month'``, or ``'year'``.

        If the scale ``type`` is a quantitative scale, then the value should
        be a boolean. The input values are rounded to a more human-friendly
        value. The details of the rounding are in the d3 documentation.

        Ignored for ordinal scales.
        """

    @grammar((float, int))
    def exponent(value):
        """float or int : Exponent for ``'pow'`` scale types

        Ignored for all scale types other than ``'pow'``.
        """

    @grammar(bool)
    def zero(value):
        """boolean : If True, include zero in the domain

        Only valid for quantitative scale types. This is useful if the
        domain is defined as a DataRef that may not include 0 exactly.
        """

    @grammar((float, int))
    def padding(value):
        """string: Ordinal element padding

        Only valid for ordinal scale types
        """

########NEW FILE########
__FILENAME__ = transforms
# -*- coding: utf-8 -*-
"""

Transforms: Vincent Data Class for Vega Transform types

"""
from __future__ import (print_function, division)
from .core import grammar, GrammarClass
from ._compat import str_types


class Transform(GrammarClass):
    """Container to Transforma metrics

    As detailed in the Vega wiki:

    "A data transform performs operations on a data set prior to visualization.
    Common examples include filtering and grouping (e.g., group data points
    with the same stock ticker for plotting as separate lines).

    All transform definitions must include a "type" parameter,
    which specifies the transform to apply.
    Each transform then has a set of transform-specific parameters."

    """

    @grammar(str_types)
    def type(value):
        """string: property name in which to store the computed transform
        value.

        The valid transform types are as follows:
        'array', 'copy', 'cross', 'facet', 'filter', 'flatten', 'fold',
        'formula', 'slice', 'sort', 'stats', 'truncate', 'unique', 'window',
        'zip', 'force', 'geo', 'geopath', 'link', 'pie', 'stack', 'treemap',
        'wordcloud'

        """

        valid_transforms = frozenset([
            'array', 'copy', 'cross', 'facet', 'filter',
            'flatten', 'fold', 'formula', 'slice', 'sort', 'stats',
            'truncate', 'unique', 'window', 'zip', 'force', 'geo', 'geopath',
            'link', 'pie', 'stack', 'treemap', 'wordcloud'
        ])

        if value not in valid_transforms:
            raise ValueError('Transform type must be'
                             ' one of {0}'.format(str(valid_transforms)))

    @grammar(list)
    def fields(value):
        """list: Can take data references or object references

        Only used if ``type`` is ``array`` or ``copy``

        """

    @grammar(grammar_type=str_types, grammar_name='from')
    def from_(value):
        """str: The name of the object to copy values from

        Only used if ``type`` is ``copy``

        """

    @grammar(grammar_type=(list,) + str_types, grammar_name='as')
    def as_(value):
        """list: The field names to copy the values to.

        Can be used with the following ``type``:
        ``copy``
        ``unique``
        ``zip``

        """

    @grammar(list)
    def keys(value):
        """list: Each key value corresponds to a single facet in the output.

        Only used if ``type`` is ``facet``
        """

    @grammar(str_types)
    def sort(value):
        """string: Optional for sorting facet values

        Only used if ``type`` is ``facet``
        """

    @grammar(str_types)
    def test(value):
        """string: A string containing a javascript filtering expression.

        Ex: d.data.y >= 3

        Only used if ``type`` is ``filter``
        """

    @grammar(str_types)
    def field(value):
        """string: Property name to store computed formula value.

        Only used if ``type`` is ``formula`` or ``unique``

        See: https://github.com/trifacta/vega/wiki/Data-Transforms#-formula
        """

    @grammar(str_types)
    def expr(value):
        """string: Javascript expression of a formula, referencing the data as
        d.

        Only used if ``type`` is formula

        See: https://github.com/trifacta/vega/wiki/Data-Transforms#-formula
        """

    @grammar(str_types + (list,))
    def by(value):
        """str, list: a field or list of fields to sort. Can prepend with - to
        sort descending.

        Only used if ``type`` is ``sort``
        """

    @grammar(str_types)
    def value(value):
        """str: Field for which to compute statistics.

        Only used if ``type`` is ``stats``
        """

    @grammar(bool)
    def median(value):
        """boolean: If true, median statistic will also be computed.

        Only used if ``type`` is stats``
        """

    @grammar(grammar_type=str_types, grammar_name='with')
    def with_(value):
        """string: Name of dataset to zip to current dataset

        Only used if ``type`` is ``zip``
        """

    @grammar(str_types)
    def key(value):
        """string: Primary dataset field to match to secondary data

        Only used if ``type`` is ``zip``
        """

    @grammar(grammar_type=str_types, grammar_name='withKey')
    def with_key(value):
        """string: Field in secondary dataset to match to primary

        Only used if ``type`` is ``zip``
        """

    @grammar((int, float,) + str_types)
    def default(value):
        """Default value to use if no matching key value is found for zip
        transformation"""

    @grammar(str_types)
    def links(value):
        """string: Name of link (edge) data set.

        To be used with ``force`` types
        """

    @grammar((int, list))
    def size(value):
        """list: Dimensions of force layout
        Number: The size (in number of elements) of the sliding window.
            Defaults to 2.

        To be used with ``force`` types
        """

    @grammar(int)
    def iterations(value):
        """int: Number of iterations to run force directed layout.

        To be used with ``force`` types
        """

    @grammar((int,) + str_types)
    def charge(value):
        """int or string: Strength of the charge each node exerts.

        To be used with ``force`` types
        """

    @grammar(grammar_type=(int,) + str_types, grammar_name='linkDistance')
    def link_distance(value):
        """int or string: Determines lenght of the edges, in pixels.

        To be used with ``force`` types
        """

    @grammar(grammar_type=(int,) + str_types, grammar_name='linkStrength')
    def link_strength(value):
        """int or string: Determines the tension of the edges.

        To be used with ``force`` types
        """

    @grammar((int, float))
    def friction(value):
        """int or float: Strength of friction force to stabilize layout

        To be used with ``force`` types
        """

    @grammar((int, float))
    def theta(value):
        """int or float: theta parameter for the Barnes-Hut algorithm.

        To be used with ``force`` types
        """

    @grammar((int, float))
    def gravity(value):
        """int or float: Strength of pseudo-gravity force

        To be used with ``force`` types
        """

    @grammar((int, float))
    def alpha(value):
        """int or float: "temperature" parameter to determine node position
        adjustment

        To be used with ``force`` types
        """

    @grammar(str_types)
    def point(value):
        """string: Data field determining the points at which to stack. When
        stacked vertically, these are the x-coords.

        To be used with ``stack`` types
        """

    @grammar(str_types)
    def height(value):
        """string: Data field determining thickness, or height of stacks.

        To be used with ``stack`` types
        """

    @grammar(str_types)
    def offset(value):
        """string: Baseline offset style. Must be one of the following:

        ``zero``, ``silhouette``, ``wiggle``, ``expand``

         To be used with ``stack`` types
         """
        offsets = ['zero', 'silhouette', 'wiggle', 'expand']
        if value not in offsets:
            raise ValueError('offset must be one of {0}'.format(offsets))

    @grammar(str_types)
    def order(value):
        """str: The sort order for stack layers. Must be one of the following:

        ``default``, ``reverse``, ``inside-out``

        To be used with ``stack`` types
        """
        orders = ['default', 'reverse', 'inside-out']
        if value not in orders:
            raise ValueError('order must be one of {0}'.format(orders))

    @grammar(str_types)
    def projection(value):
        """str: Cartographic projection. Accepts any projection supported by
        the D3 projection plug-in:

        https://github.com/mbostock/d3/wiki/Geo-Projections
        """

    @grammar(list)
    def center(value):
        """Center of the projection. Should be length=2"""

        if len(value) != 2:
            raise ValueError('len(center) must = 2')

    @grammar(list)
    def translate(value):
        """Translation of the projection. Should be length=2"""

        if len(value) != 2:
            raise ValueError('len(center) must = 2')

    @grammar(int)
    def scale(value):
        """The scale of the projection"""

        if value < 0:
            raise ValueError('Scale cannot be negative.')

    @grammar((int, str_types, dict))
    def rotate(value):
        """The rotation of the projection or rotation define of word cloud
        """

        if isinstance(value, int):
            if value < 0:
                raise ValueError('The rotation cannot be negative.')

    @grammar(str_types)
    def font(value):
        """str: Font of word cloud.
        """

    @grammar(grammar_type=str_types, grammar_name='fontSize')
    def font_size(value):
        """str: The font size field of word cloud.
        """

    @grammar(str_types)
    def text(value):
        """str: The text field of word cloud.
        """

    @grammar(bool)
    def diagonal(value):
        """True: Elements on diagonal will be included in cross product.
        False (default): Elements on diagonal will not be included in cross
        product.
        """

    @grammar(bool)
    def assign(value):
        """bool: If true, a stats property will be added to each individual
        data element. This property references an object containing all the
        computed statistics. This option is useful if you want construct
        downstream formulas that reference both individual values and aggregate
        statistics.
        """

    @grammar(str_types)
    def output(value):
        """str: The name of the field in which to store the truncated value.
        Defaults to "truncate".
        """

    @grammar(int)
    def limit(value):
        """int: The maximum length of the truncated string.
        """

    @grammar(str_types)
    def ellipsis(value):
        """str: The text to use as an ellipsis for truncated text.
        Defaults to "...".
        """

    @grammar(bool)
    def wordbreak(value):
        """bool: If true, the truncation algorithm will truncate along word
        boundaries.
        """

    @grammar((int, float))
    def step(value):
        """Number: The step size (in number of elements) by which to advance
        the window per frame. Defaults to 1.
        """

    @grammar((int, float))
    def precision(value):
        """Number: The desired precision of the projection.
        """

    @grammar((int, float), grammar_name='clipAngle')
    def clip_angle(value):
        """Number: The clip angle of the projection.
        """

    @grammar(str_types)
    def shape(value):
        """str: A string describing the path shape to use. One of
        "line" (default), "curve", "diagonal", "diagonalX", or "diagonalY".
        """
        link_shapes = frozenset([
            "line", "curve", "diagonal", "diagonalX", "diagonalY"
            ])
        if value not in link_shapes:
            raise ValueError(
                'Link shape must be one of %s' % (str(link_shapes),)
                )

    @grammar(grammar_type=str_types, grammar_name='fontWeight')
    def font_weight(value):
        """str: The font weight (e.g., "bold") to use.
        """

    @grammar((int, list))
    def padding(value):
        """The padding (in pixels) to provide around text in the word cloud.
        The padding value can either be a single number or an array of four
        numbers [top, right, bottom, left]. The default padding is zero pixels.
        """

    @grammar(str_types)
    def lon(value):
        """string: The input longitude values.
        """

    @grammar(str_types)
    def lat(value):
        """string: The input latitude values.
        """

    @grammar(str_types)
    def source(value):
        """string: The data field that references the source node for this
        link.
        """

    @grammar(str_types)
    def target(value):
        """string: The data field that references the target node for this
        link.
        """

########NEW FILE########
__FILENAME__ = values
# -*- coding: utf-8 -*-
"""

ValueRef: Generally used in a PropertySet class to define a set of values
within a property

"""
from .core import grammar, GrammarClass
from ._compat import str_types


class ValueRef(GrammarClass):
    """Container for the value-referencing properties of marks

    It is often useful for marks to share properties to maintain consistency
    when parts of the visualization are changed. Additionally, the marks
    themselves may have properties somehow mapped from the data (i.e. mark
    size proportional to some data field). The ``ValueRef`` class can be
    used to either define values locally or reference other fields.

    ValueRefs can reference numbers, strings, or arbitrary objects,
    depending on their use.
    """
    @grammar(str_types + (int, float))
    def value(value):
        """int, float, or string : used for constant values

        This is ignored if the ``field`` property is defined.
        """

    @grammar(str_types)
    def field(value):
        """string : reference to a field of the data in dot-notation

        The data is taken from the Mark's ``from_`` property. For instance, if
        the data has a definition
        ``[{'x': 2}, {'x': 3}, {'x': 1}]``
        then the data should be referenced as ``data.x``. Note that the first
        element is always `data` regardless of the name of the data.
        """

    @grammar((str_types, bool))
    def group(value):
        """string, boolean: Similar to field, but references a property of the
        enclosing group's data, not the current mark.

        If "width" or "height" are specified, the width or height of the
        enclosing group mark is returned.
        """

    @grammar(str_types)
    def scale(value):
        """string : reference to the name of a ``Scale``

        The scale is applied to the ``value`` and ``field`` attributes.
        """

    @grammar((int, float))
    def mult(value):
        """int or float : multiplier applied to the data after any scaling
        """

    @grammar((int, float))
    def offset(value):
        """int or float : additive offset applied to the data after any
        scaling and multipliers
        """

    @grammar(bool)
    def band(value):
        """boolean : use the range of the scale if applicable

        If this is True and ``scale`` is defined, then the value referenced
        is the range band referenced scale. See the d3 documentation on
        ``ordinal.rangeBand`` for more info.
        """

########NEW FILE########
__FILENAME__ = visualization
# -*- coding: utf-8 -*-
"""

Visualization: Top level class for Vega Grammar

"""
from __future__ import (print_function, division)
from uuid import uuid4
from .core import (_assert_is_type, ValidationError,
                   KeyedList, grammar, GrammarClass)
from .data import Data
from .scales import Scale
from .marks import Mark
from .axes import Axis, AxisProperties
from .legends import Legend, LegendProperties
from .properties import PropertySet
from .values import ValueRef
from .colors import brews
from ._compat import str_types


class Visualization(GrammarClass):
    """Visualization container class.

    This class defines the full visualization. Calling its ``to_json``
    method should return a complete Vega definition.

    The sub-elements of the visualization are stored in the ``data``,
    ``axes``, ``marks``, and ``scales`` attributes. See the docs for each
    attribute for details.
    """
    def __init__(self, *args, **kwargs):
        """Initialize a Visualization

        In addition to setting any attributes, this sets the data, marks,
        scales, and axes properties to empty KeyedLists if they aren't
        defined by the arguments.
        """
        super(Visualization, self).__init__(*args, **kwargs)

        for attrib in ('data', 'scales'):
            if not getattr(self, attrib):
                setattr(self, attrib, KeyedList(attr_name='name'))

        for attrib in ('axes', 'marks'):
            if not getattr(self, attrib):
                setattr(self, attrib, KeyedList(attr_name='type'))

        # Legends don't get keyed.
        if not self.legends:
            self.legends = []

    @grammar(str_types)
    def name(value):
        """string : Name of the visualization (optional)
        """

    @grammar(int)
    def width(value):
        """int : Width of the visualization in pixels

        Default is 500 if undefined.
        """
        if value < 0:
            raise ValueError('width cannot be negative')

    @grammar(int)
    def height(value):
        """int : Height of the visualization in pixels

        Default is 500 if undefined.
        """
        if value < 0:
            raise ValueError('height cannot be negative')

    @grammar(list)
    def viewport(value):
        """2-element list of ints : Dimensions of the viewport

        The viewport is a bounding box containing the visualization. If the
        dimensions of the visualization are larger than the viewport, then
        the visualization will be scrollable.

        If undefined, then the full visualization is shown.
        """
        if len(value) != 2:
            raise ValueError('viewport must have 2 dimensions')
        for v in value:
            _assert_is_type('viewport dimension', v, int)
            if v < 0:
                raise ValueError('viewport dimensions cannot be negative')

    @grammar((int, dict,) + str_types)
    def padding(value):
        """int or dict : Padding around visualization

        The padding defines the distance between the edge of the
        visualization canvas to the visualization box. It does not count as
        part of the visualization width/height. Values cannot be negative.

        If a dict, padding must have all keys ``''top'``, ``'left'``,
        ``'right'``, and ``'bottom'`` with int values.
        """
        if isinstance(value, dict):
            required_keys = ['top', 'left', 'right', 'bottom']
            for key in required_keys:
                if key not in value:
                    error = ('Padding must have keys "{0}".'
                             .format('", "'.join(required_keys)))
                    raise ValueError(error)
                _assert_is_type('padding: {0}'.format(key), value[key], int)
                if value[key] < 0:
                    raise ValueError('Padding cannot be negative.')
        elif isinstance(value, int):
            if value < 0:
                raise ValueError('Padding cannot be negative.')
        else:
            if value not in ("auto", "strict"):
                raise ValueError('Padding can only be auto or strict.')

    @grammar((list, KeyedList))
    def data(value):
        """list or KeyedList of ``Data`` : Data definitions

        This defines the data being visualized. See the :class:`Data` class
        for details.
        """
        for i, entry in enumerate(value):
            _assert_is_type('data[{0}]'.format(i), entry,  Data)

    @grammar((list, KeyedList))
    def scales(value):
        """list or KeyedList of ``Scale`` : Scale definitions

        Scales map the data from the domain of the data to some
        visualization space (such as an x-axis). See the :class:`Scale`
        class for details.
        """
        for i, entry in enumerate(value):
            _assert_is_type('scales[{0}]'.format(i), entry, Scale)

    @grammar((list, KeyedList))
    def axes(value):
        """list or KeyedList of ``Axis`` : Axis definitions

        Axes define the locations of the data being mapped by the scales.
        See the :class:`Axis` class for details.
        """
        for i, entry in enumerate(value):
            _assert_is_type('axes[{0}]'.format(i), entry, Axis)

    @grammar((list, KeyedList))
    def marks(value):
        """list or KeyedList of ``Mark`` : Mark definitions

        Marks are the visual objects (such as lines, bars, etc.) that
        represent the data in the visualization space. See the :class:`Mark`
        class for details.
        """
        for i, entry in enumerate(value):
            _assert_is_type('marks[{0}]'.format(i), entry, Mark)

    @grammar((list, KeyedList))
    def legends(value):
        """list or KeyedList of ``Legends`` : Legend definitions

        Legends visualize scales, and take one or more scales as their input.
        They can be customized via a LegendProperty object.
        """
        for i, entry in enumerate(value):
            _assert_is_type('legends[{0}]'.format(i), entry, Legend)

    def axis_titles(self, x=None, y=None):
        """Apply axis titles to the figure.

        This is a convenience method for manually modifying the "Axes" mark.

        Parameters
        ----------
        x: string, default 'null'
            X-axis title
        y: string, default 'null'
            Y-axis title

        Example
        -------
        >>>vis.axis_titles(y="Data 1", x="Data 2")

        """
        keys = self.axes.get_keys()

        if keys:
            for key in keys:
                if key == 'x':
                    self.axes[key].title = x
                elif key == 'y':
                    self.axes[key].title = y
        else:
            self.axes.extend([Axis(type='x', title=x),
                              Axis(type='y', title=y)])
        return self

    def _set_axis_properties(self, axis):
        """Set AxisProperties and PropertySets"""
        if not getattr(axis, 'properties'):
            axis.properties = AxisProperties()
            for prop in ['ticks', 'axis', 'major_ticks', 'minor_ticks',
                         'title', 'labels']:
                setattr(axis.properties, prop, PropertySet())

    def _set_all_axis_color(self, axis, color):
        """Set axis ticks, title, labels to given color"""
        for prop in ['ticks', 'axis', 'major_ticks', 'minor_ticks', 'title',
                     'labels']:
            prop_set = getattr(axis.properties, prop)
            if color and prop in ['title', 'labels']:
                prop_set.fill = ValueRef(value=color)
            elif color and prop in ['axis', 'major_ticks', 'minor_ticks',
                                    'ticks']:
                prop_set.stroke = ValueRef(value=color)

    def _axis_properties(self, axis, title_size, title_offset, label_angle,
                         label_align, color):
        """Assign axis properties"""
        if self.axes:
            axis = [a for a in self.axes if a.scale == axis][0]
            self._set_axis_properties(axis)
            self._set_all_axis_color(axis, color)

            if title_size:
                axis.properties.title.font_size = ValueRef(value=title_size)
            if label_angle:
                axis.properties.labels.angle = ValueRef(value=label_angle)
            if label_align:
                axis.properties.labels.align = ValueRef(value=label_align)
            if title_offset:
                axis.properties.title.dy = ValueRef(value=title_offset)
        else:
            raise ValueError('This Visualization has no axes!')

    def common_axis_properties(self, color=None, title_size=None):
        """Set common axis properties such as color

        Parameters
        ----------
        color: str, default None
            Hex color str, etc
        """
        if self.axes:
            for axis in self.axes:
                self._set_axis_properties(axis)
                self._set_all_axis_color(axis, color)
                if title_size:
                    ref = ValueRef(value=title_size)
                    axis.properties.title.font_size = ref
        else:
            raise ValueError('This Visualization has no axes!')
        return self

    def x_axis_properties(self, title_size=None, title_offset=None,
                          label_angle=None, label_align=None, color=None):
        """Change x-axis title font size and label angle

        Parameters
        ----------
        title_size: int, default None
            Title size, in px
        title_offset: int, default None
            Pixel offset from given axis
        label_angle: int, default None
            label angle in degrees
        label_align: str, default None
            Label alignment
        color: str, default None
            Hex color
        """
        self._axis_properties('x', title_size, title_offset, label_angle,
                              label_align, color)
        return self

    def y_axis_properties(self, title_size=None, title_offset=None,
                          label_angle=None, label_align=None, color=None):
        """Change y-axis title font size and label angle

        Parameters
        ----------
        title_size: int, default None
            Title size, in px
        title_offset: int, default None
            Pixel offset from given axis
        label_angle: int, default None
            label angle in degrees
        label_align: str, default None
            Label alignment
        color: str, default None
            Hex color
        """
        self._axis_properties('y', title_size, title_offset, label_angle,
                              label_align, color)
        return self

    def legend(self, title=None, scale='color', text_color=None):
        """Convience method for adding a legend to the figure.

        Important: This defaults to the color scale that is generated with
        Line, Area, Stacked Line, etc charts. For bar charts, the scale ref is
        usually 'y'.

        Parameters
        ----------
        title: string, default None
            Legend Title
        scale: string, default 'color'
            Scale reference for legend
        text_color: str, default None
            Title and label color
        """

        self.legends.append(Legend(title=title, fill=scale, offset=0,
                                   properties=LegendProperties()))
        if text_color:
            color_props = PropertySet(fill=ValueRef(value=text_color))
            self.legends[0].properties.labels = color_props
            self.legends[0].properties.title = color_props
        return self

    def colors(self, brew=None, range_=None):
        """Convenience method for adding color brewer scales to charts with a
        color scale, such as stacked or grouped bars.

        See the colors here: http://colorbrewer2.org/

        Or here: http://bl.ocks.org/mbostock/5577023

        This assumes that a 'color' scale exists on your chart.

        Parameters
        ----------
        brew: string, default None
            Color brewer scheme (BuGn, YlOrRd, etc)
        range: list, default None
            List of colors. Ex: ['#ac4142', '#d28445', '#f4bf75']
        """
        if brew:
            self.scales['color'].range = brews[brew]
        elif range_:
            self.scales['color'].range = range_
        return self

    def validate(self, require_all=True, scale='colors'):
        """Validate the visualization contents.

        Parameters
        ----------
        require_all : boolean, default True
            If True (default), then all fields ``data``, ``scales``,
            ``axes``, and ``marks`` must be defined. The user is allowed to
            disable this if the intent is to define the elements
            client-side.

        If the contents of the visualization are not valid Vega, then a
        :class:`ValidationError` is raised.
        """
        super(self.__class__, self).validate()
        required_attribs = ('data', 'scales', 'axes', 'marks')
        for elem in required_attribs:
            attr = getattr(self, elem)
            if attr:
                # Validate each element of the sets of data, etc
                for entry in attr:
                    entry.validate()
                names = [a.name for a in attr]
                if len(names) != len(set(names)):
                    raise ValidationError(elem + ' has duplicate names')
            elif require_all:
                raise ValidationError(
                    elem + ' must be defined for valid visualization')

    def _repr_html_(self):
        """Build the HTML representation for IPython."""
        vis_id = str(uuid4()).replace("-", "")
        html = """<div id="vis%s"></div>
<script>
   ( function() {
     var _do_plot = function() {
       if (typeof vg === 'undefined') {
         window.addEventListener('vincent_libs_loaded', _do_plot)
         return;
       }
       vg.parse.spec(%s, function(chart) {
         chart({el: "#vis%s"}).update();
       });
     };
     _do_plot();
   })();
</script>
<style>.vega canvas {width: 100%%;}</style>
        """ % (vis_id, self.to_json(pretty_print=False), vis_id)
        return html

    def display(self):
        """Display the visualization inline in the IPython notebook.

        This is deprecated, use the following instead::

            from IPython.display import display
            display(viz)
        """
        from IPython.core.display import display, HTML
        display(HTML(self._repr_html_()))

########NEW FILE########
__FILENAME__ = _compat
# -*- coding: utf-8 -*-
"""
Compat: Minimal, required compatibility layer for py2/py3
"""

import sys

PY2 = sys.version_info[0] == 2


if not PY2:
    str_types = (str, )
else:
    str_types = (unicode, str)

########NEW FILE########
