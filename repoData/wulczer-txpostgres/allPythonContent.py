__FILENAME__ = basic_example
from txpostgres import txpostgres

from twisted.internet import reactor
from twisted.python import log, util

# connect to the database
conn = txpostgres.Connection()
d = conn.connect('dbname=postgres')

# run the query and print the result
d.addCallback(lambda _: conn.runQuery('select tablename from pg_tables'))
d.addCallback(lambda result: util.println('All tables:', result))

# close the connection, log any errors and stop the reactor
d.addCallback(lambda _: conn.close())
d.addErrback(log.err)
d.addBoth(lambda _: reactor.stop())

# start the reactor to kick off connection estabilishing
reactor.run()

########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# txpostgres documentation build configuration file, created by
# sphinx-quickstart on Fri Jan  6 22:33:43 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('..'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.extlinks',
              'sphinx.ext.viewcode']

autodoc_default_flags = ['members', 'private-members', 'show-inheritance']
autodoc_member_order = 'bysource'

_tm_base = 'http://twistedmatrix.com/documents/current/api/'
extlinks = {'tm': (_tm_base + 'twisted.%s.html', ''),
            'd': (_tm_base + 'twisted.internet.defer.%s.html', ''),
            'psycopg': ('http://initd.org/psycopg/docs/%s', ''),
            'pg': ('http://www.postgresql.org/docs/'
                   'current/static/sql-%s.html', '')}

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'txpostgres'
copyright = u'2010-2012, Jan Urbański'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.

sys.path.insert(0, os.path.abspath('..'))
import txpostgres
# The short X.Y version.
version = '.'.join([str(n) for n in txpostgres.__version__[:3]])
# The full version, including alpha/beta/rc tags.
release = version
del sys.modules['txpostgres']
sys.path.pop(0)

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
#html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'txpostgresdoc'


# -- Options for LaTeX output --------------------------------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'txpostgres.tex', u'txpostgres Documentation',
   u'Jan Urbański', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'txpostgres', u'txpostgres Documentation',
     [u'Jan Urbański'], 1)
]

########NEW FILE########
__FILENAME__ = cursor_example
from txpostgres import txpostgres

from twisted.internet import reactor
from twisted.python import log, util

# define the libpq connection string and the query to use
connstr = 'dbname=postgres'
query = 'select tablename from pg_tables order by tablename'

# connect to the database
conn = txpostgres.Connection()
d = conn.connect('dbname=postgres')

def useCursor(cur):
    # execute a query
    d = cur.execute(query)
    # fetch the first row from the result
    d.addCallback(lambda _: cur.fetchone())
    # output it
    d.addCallback(lambda result: util.println('First table name:', result[0]))
    # and close the cursor
    return d.addCallback(lambda _: cur.close())

# create a cursor and use it
d.addCallback(lambda _: conn.cursor())
d.addCallback(useCursor)

# log any errors and stop the reactor
d.addErrback(log.err)
d.addBoth(lambda _: reactor.stop())

# start the reactor to kick off connection estabilishing
reactor.run()

########NEW FILE########
__FILENAME__ = dictcursor_example
import psycopg2
import psycopg2.extras
from txpostgres import txpostgres

from twisted.internet import reactor
from twisted.python import log, util


def dict_connect(*args, **kwargs):
    kwargs['connection_factory'] = psycopg2.extras.DictConnection
    return psycopg2.connect(*args, **kwargs)


class DictConnection(txpostgres.Connection):
    connectionFactory = staticmethod(dict_connect)


# connect using the custom connection class
conn = DictConnection()
d = conn.connect('dbname=postgres')

# run a query and print the result
d.addCallback(lambda _: conn.runQuery('select * from pg_tablespace'))
# access the column by its name
d.addCallback(lambda result: util.println('All tablespace names:',
                                          [row['spcname'] for row in result]))

# close the connection, log any errors and stop the reactor
d.addCallback(lambda _: conn.close())
d.addErrback(log.err)
d.addBoth(lambda _: reactor.stop())

# start the reactor to kick off connection estabilishing
reactor.run()

########NEW FILE########
__FILENAME__ = notify_example
from txpostgres import txpostgres

from twisted.internet import reactor
from twisted.python import util


def outputResults(results, payload):
    print "Tables with `%s' in their name:" % payload
    for result in results:
        print result[0]


def observer(notify):
    if not notify.payload:
        print "No payload"
        return

    query = ("select tablename from pg_tables "
             "where tablename like '%%' || %s || '%%'")
    d = conn.runQuery(query, (notify.payload, ))
    d.addCallback(outputResults, notify.payload)


# connect to the database
conn = txpostgres.Connection()
d = conn.connect('dbname=postgres')

# add a NOTIFY observer
conn.addNotifyObserver(observer)
# start listening for NOTIFY events on the 'list' channel
d.addCallback(lambda _: conn.runOperation("listen list"))
d.addCallback(lambda _: util.println("Listening on the `list' channel"))

# process events until killed
reactor.run()

########NEW FILE########
__FILENAME__ = reconnection_example
from txpostgres import txpostgres, reconnection

from twisted.internet import reactor, task


class LoggingDetector(reconnection.DeadConnectionDetector):

    def startReconnecting(self, f):
        print '[*] database connection is down (error: %r)' % f.value
        return reconnection.DeadConnectionDetector.startReconnecting(self, f)

    def reconnect(self):
        print '[*] reconnecting...'
        return reconnection.DeadConnectionDetector.reconnect(self)

    def connectionRecovered(self):
        print '[*] connection recovered'
        return reconnection.DeadConnectionDetector.connectionRecovered(self)


def result(res):
    print '-> query returned result: %s' % res


def error(f):
    print '-> query failed with %r' % f.value


def connectionError(f):
    print '-> connecting failed with %r' % f.value


def runLoopingQuery(conn):
    d = conn.runQuery('select 1')
    d.addCallbacks(result, error)


def connected(_, conn):
    print '-> connected, running a query periodically'
    lc = task.LoopingCall(runLoopingQuery, conn)
    return lc.start(2)


# connect to the database using reconnection
conn = txpostgres.Connection(detector=LoggingDetector())
d = conn.connect('dbname=postgres')

# if the connection failed, log the error and start reconnecting
d.addErrback(conn.detector.checkForDeadConnection)
d.addErrback(connectionError)
d.addCallback(connected, conn)

# process events until killed
reactor.run()

########NEW FILE########
__FILENAME__ = transaction_example
from txpostgres import txpostgres

from twisted.internet import reactor
from twisted.python import log

# connect to the database
conn = txpostgres.Connection()
d = conn.connect('dbname=postgres')

# define a callable that will execute inside a transaction
def interaction(cur):
    # the parameter is a txpostgres Cursor
    d = cur.execute('create table test(x integer)')
    d.addCallback(lambda _: cur.execute('insert into test values (%s)', (1, )))
    return d

# run the interaction, making sure that if the insert fails, the table won't be
# left behind created but empty
d.addCallback(lambda _: conn.runInteraction(interaction))

# close the connection, log any errors and stop the reactor
d.addCallback(lambda _: conn.close())
d.addErrback(log.err)
d.addBoth(lambda _: reactor.stop())

# start the reactor to kick off connection estabilishing
reactor.run()

########NEW FILE########
__FILENAME__ = test_reconnection
from twisted.internet import defer
from twisted.trial import unittest

from txpostgres import reconnection


class ArbitraryException(Exception):
    pass


class Reconnectable(object):
    def __init__(self):
        self.calls = []
        self.connects = []

    def call(self):
        self.calls.append(defer.Deferred())
        return self.calls[-1]

    def connect(self):
        self.connects.append(defer.Deferred())
        return self.connects[-1]

    def close(self):
        pass


class BrokenReconnectable(Reconnectable):

    def close(self):
        raise RuntimeError()


class TestDeadConnectionDetector(unittest.TestCase):

    def setUp(self):
        self.recoveries = 0
        self.reconnectable = Reconnectable()
        self.detector = reconnection.DeadConnectionDetector(self.deathChecker)

        self.detector.setReconnectable(self.reconnectable)
        self.detector.addRecoveryHandler(self.recovery)

    def deathChecker(self, f):
        return f.check(ArbitraryException)

    def recovery(self):
        self.recoveries += 1

    def brokenRecovery(self):
        self.recoveries += 1
        raise RuntimeError()

    def test_basic(self):
        """
        Only the failure recognized by the death checker causes reconnection to
        trigger. Until the connection recovers, all calls through the detector
        are immediately failed.
        """
        # the first call is successful
        d1 = self.detector.callChecking(self.reconnectable.call)
        self.reconnectable.calls.pop().callback(None)

        self.assertEquals(len(self.reconnectable.connects), 0)

        # the second call has an error, but the death checker does not
        # recognize it
        d2 = self.detector.callChecking(self.reconnectable.call)
        self.reconnectable.calls.pop().errback(RuntimeError())

        self.assertFailure(d2, RuntimeError)

        self.assertEquals(len(self.reconnectable.connects), 0)

        # the third and the fourth call discover that the connection is dead,
        # but only one reconnection is triggered
        d3 = self.detector.callChecking(self.reconnectable.call)
        d4 = self.detector.callChecking(self.reconnectable.call)
        self.reconnectable.calls.pop().errback(ArbitraryException())
        self.reconnectable.calls.pop().errback(ArbitraryException())

        self.assertFailure(d3, ArbitraryException)
        self.assertFailure(d4, ArbitraryException)

        # only one reconnection
        self.assertEquals(len(self.reconnectable.connects), 1)

        # the fifth call finds the connection dead
        d5 = self.detector.callChecking(self.reconnectable.call)
        self.assertEquals(len(self.reconnectable.calls), 0)

        self.assertFailure(d5, reconnection.ConnectionDead)

        rd = self.reconnectable.connects.pop()

        self.assertEquals(self.recoveries, 0)
        rd.callback(None)
        self.assertEquals(self.recoveries, 1)

        d6 = self.detector.callChecking(self.reconnectable.call)
        self.reconnectable.calls.pop().callback(None)

        d = defer.gatherResults([d1, d2, d3, d4, d5, d6])
        return d.addCallback(lambda ret: self.assertEquals(ret[5], None))

    def test_brokenRecovery(self):
        """
        Errors in recovery handlers are logged and discarded.
        """
        self.detector.removeRecoveryHandler(self.recovery)
        self.detector.addRecoveryHandler(self.brokenRecovery)

        d = self.detector.callChecking(self.reconnectable.call)
        self.reconnectable.calls.pop().errback(ArbitraryException())
        self.assertFailure(d, ArbitraryException)

        self.reconnectable.connects.pop().callback(None)
        # the error gets logged and discarded
        self.assertEquals(len(self.flushLoggedErrors(RuntimeError)), 1)

        d = self.detector.callChecking(self.reconnectable.call)
        self.reconnectable.calls.pop().callback(None)
        return d.addCallback(self.assertEquals, None)

    def test_brokenReconnectable(self):
        """
        Errors when closing the reconnectable are logged and discarded.
        """
        reconnectable = BrokenReconnectable()
        self.detector.setReconnectable(reconnectable)

        d = self.detector.callChecking(reconnectable.call)
        reconnectable.calls.pop().errback(ArbitraryException())
        self.assertFailure(d, ArbitraryException)

        reconnectable.connects.pop().callback(None)
        # the the error in BrokenReconnectable.close got ignored
        self.assertEquals(len(self.flushLoggedErrors()), 0)

        d = self.detector.callChecking(reconnectable.call)
        reconnectable.calls.pop().callback(None)
        return d.addCallback(self.assertEquals, None)

########NEW FILE########
__FILENAME__ = test_retrying
from twisted.trial import unittest
from twisted.internet import defer, task
from twisted.python import failure

from txpostgres import retrying


class ArbitraryException(Exception):
    pass


class TestSimpleBackoffIterator(unittest.TestCase):

    def test_simple(self):
        """
        Consecutive delays are increasing.
        """
        it = retrying.simpleBackoffIterator()

        # by default "now" is set
        self.assertEquals(it.next(), 0)

        r1, r2, r3 = it.next(), it.next(), it.next()
        self.assertTrue(r1 < r2 < r3)

    def test_maxDelay(self):
        """
        The delay is capped at some point.
        """
        it = retrying.simpleBackoffIterator(maxDelay=2.0)

        res = [it.next() for _ in range(5)]
        self.assertEquals(res[-1], 2.0)

    def test_notNow(self):
        """
        If now is not set, the first delay is not zero.
        """
        it = retrying.simpleBackoffIterator(now=False)
        self.assertNotEquals(it.next(), 0)

    def test_maxRetries(self):
        """
        The iterator gets exhausted if retries are capped.
        """
        it = retrying.simpleBackoffIterator(maxRetries=3)

        it.next(), it.next(), it.next()
        self.assertRaises(StopIteration, it.next)

    def test_noMaxRetries(self):
        """
        The iterator does not get exhausted if retries are not capped.
        """
        it = retrying.simpleBackoffIterator(maxRetries=0, maxDelay=1)

        alot = [it.next() for _ in range(1000)]
        self.assertEquals(alot[-1], 1)

    def test_noMaxDelay(self):
        """
        Without maximum delay, the consecutive delays grow unboundedly.
        """
        it = retrying.simpleBackoffIterator(maxRetries=0, maxDelay=0)

        # putting range(1000) here makes Python return a NaN, so be moderate
        alot = [it.next() for _ in range(100)]
        self.assertTrue(alot[-2] < alot[-1])

    def test_precise(self):
        """
        Knowing starting values and disabling jitter, it is possible to predict
        consecutive values.
        """
        it = retrying.simpleBackoffIterator(initialDelay=10, maxDelay=90,
                                            factor=2, jitter=0)

        self.assertEquals(it.next(), 0)
        self.assertEquals(it.next(), 20)
        self.assertEquals(it.next(), 40)
        self.assertEquals(it.next(), 80)
        self.assertEquals(it.next(), 90)
        self.assertEquals(it.next(), 90)


class TestRetryingCall(unittest.TestCase):

    def setUp(self):
        self.calls = 0
        self.raiseError = None

        self.clock = task.Clock()
        self.call = retrying.RetryingCall(self.func)
        self.call.reactor = self.clock
        self.sillyIterator = retrying.simpleBackoffIterator(
            initialDelay=1, factor=1, jitter=0, maxDelay=0, maxRetries=0)

    def func(self):
        self.calls += 1

        if self.raiseError:
            raise self.raiseError()

    def test_basic(self):
        """
        First retrying call is synchronous.
        """
        d = self.call.start()

        # the first call is synchronous, no need to advance the clock
        return d.addCallback(lambda _: self.assertEquals(self.calls, 1))

    def test_someFailures(self):
        """
        If the function fails a few times and then succeeds, the whole Deferred
        succeeds.
        """
        self.raiseError = ArbitraryException
        tests = []

        def tester(f):
            tests.append(f)

        d = self.call.start(self.sillyIterator, tester)

        self.assertEquals(len(tests), 1)
        self.assertIsInstance(tests[0], failure.Failure)
        self.assertIsInstance(tests[0].value, ArbitraryException)

        self.clock.advance(0.5)
        self.assertEquals(len(tests), 1)
        self.assertEquals(self.calls, 1)

        self.clock.advance(0.5)
        self.assertEquals(len(tests), 2)
        self.assertEquals(self.calls, 2)

        self.raiseError = None

        self.clock.advance(0.8)
        self.assertEquals(len(tests), 2)
        self.assertEquals(self.calls, 2)

        self.clock.advance(0.2)
        self.assertTrue(d.called)
        self.assertEquals(len(tests), 2)
        self.assertEquals(self.calls, 3)

        return d

    def test_ranOutOfRetries(self):
        """
        If the function fails too many times, the whole Deferred fails.
        """
        self.raiseError = ArbitraryException

        d = self.call.start([1, 1])

        self.clock.advance(1)
        self.assertEquals(self.calls, 1)

        self.clock.advance(1)
        self.assertEquals(self.calls, 2)

        self.clock.advance(1)
        # already failed, not called again
        self.assertEquals(self.calls, 2)
        return self.assertFailure(d, ArbitraryException)

    def test_customTester(self):
        """
        A failure tester function that only recognizes TypeErrors will cause
        the call to fail with another exception.
        """
        self.raiseError = TypeError

        # swallow type errors
        d = self.call.start(self.sillyIterator,
                            lambda f: isinstance(f.value, TypeError) or f)

        self.clock.advance(0)
        self.assertEquals(self.calls, 1)
        self.clock.advance(1)
        self.assertEquals(self.calls, 2)
        self.clock.advance(1)
        self.assertEquals(self.calls, 3)

        self.raiseError = ArbitraryException

        self.clock.advance(1)
        self.assertEquals(self.calls, 4)

        self.clock.advance(1)
        # already failed, not called again
        self.assertEquals(self.calls, 4)
        return self.assertFailure(d, ArbitraryException)

    def test_failureInFailureTester(self):
        """
        Failures in the failure tester will cause the entire call to fail and
        the error will be propagated to the call's Deferred.
        """
        self.raiseError = RuntimeError

        def failingTester(f):
            raise ArbitraryException()

        d = self.call.start(self.sillyIterator, failingTester)

        self.assertEquals(self.calls, 1)
        self.clock.advance(1)
        # already failed, not called again
        self.assertEquals(self.calls, 1)
        return self.assertFailure(d, ArbitraryException)

    def test_resetBackoff(self):
        """
        Changing the backoff iterator causes the next delay to be taken from
        the new iterator.
        """
        self.raiseError = ArbitraryException

        everysecond = [1, 1, 1, 1]
        everytwo = [2, 2, 2, 2]

        d = self.call.start(everysecond)

        self.assertEquals(self.calls, 0)
        self.clock.advance(1)
        self.assertEquals(self.calls, 1)
        self.clock.advance(1)
        self.assertEquals(self.calls, 2)

        self.call.resetBackoff(everytwo)

        self.clock.advance(1)
        # the call gets executed, because the previous delay is still pending
        self.assertEquals(self.calls, 3)
        self.clock.advance(1)
        # but another advance of one second does not fire the call
        self.assertEquals(self.calls, 3)
        self.clock.advance(1)
        self.assertEquals(self.calls, 4)
        self.clock.pump([2, 2, 2])

        return self.assertFailure(d, ArbitraryException)

    def test_cancel(self):
        """
        Cancelling the call causes it to fail with a CancelledError.
        """
        self.raiseError = ArbitraryException
        everysecond = [1, 1, 1, 1]

        d = self.call.start(everysecond)
        self.assertEquals(self.calls, 0)
        self.clock.advance(1)
        self.assertEquals(self.calls, 1)
        self.clock.advance(1)
        self.assertEquals(self.calls, 2)
        d.cancel()
        self.clock.advance(1)
        self.assertEquals(self.calls, 2)

        return self.assertFailure(d, defer.CancelledError)

########NEW FILE########
__FILENAME__ = test_txpostgres
import os

try:
    import psycopg2
    import psycopg2.extensions
except ImportError:
    # try psycopg2-ctypes
    try:
        import psycopg2ct as psycopg2
    except ImportError:
        raise ImportError('no module named psycopg2 or psycopg2ct')

from txpostgres import txpostgres, reconnection

from twisted.trial import unittest
from twisted.internet import defer, error, main, posixbase, reactor, task
from twisted.python import failure

simple_table_schema = "CREATE TABLE simple (x integer)"

DB_NAME = os.getenv("TXPOSTGRES_TEST_DATABASE", "twisted_test")
DB_HOST = os.getenv("TXPOSTGRES_TEST_HOST", "localhost")
DB_USER = os.getenv("TXPOSTGRES_TEST_USER", "twisted_test")
DB_PASS = os.getenv("TXPOSTGRES_TEST_PASSWORD", "twisted_test")


def getSkipForPsycopg2():
    try:
        psycopg2.extensions.POLL_OK
    except AttributeError:
        return ("psycopg2 does not have async support. "
                "You need at least version 2.2.0 of psycopg2 "
                "to use txpostgres.")
    try:
        psycopg2.connect(user=DB_USER, password=DB_PASS,
                         host=DB_HOST, database=DB_NAME).close()
    except psycopg2.Error, e:
        return ("cannot connect to test database %r "
                "using host %r, user %r and password %r: %s" %
                (DB_NAME, DB_HOST, DB_USER, DB_PASS, e))
    return None


_skip = getSkipForPsycopg2()


class Psycopg2TestCase(unittest.TestCase):

    skip = _skip


class PollableThing(object):
    """
    A fake thing that provides a psycopg2 pollable interface.
    """
    closed = 0
    notifies = []

    def __init__(self):
        self.NEXT_STATE = psycopg2.extensions.POLL_READ

    def poll(self):
        if isinstance(self.NEXT_STATE, Exception):
            raise self.NEXT_STATE
        return self.NEXT_STATE

    def fileno(self):
        return 42


class CancellablePollableThing(PollableThing):

    cancelled = False

    def cancel(self):
        assert not self.cancelled
        self.cancelled = True


class FakeReactor(object):
    """
    A reactor that just counts how many things were added and removed.
    """
    readersAdded = 0
    writersAdded = 0
    readersRemoved = 0
    writersRemoved = 0

    def reset(self):
        self.readersAdded = self.writersAdded = 0
        self.readersRemoved = self.writersRemoved = 0

    def addReader(self, _):
        self.readersAdded += 1

    def addWriter(self, _):
        self.writersAdded += 1

    def removeReader(self, _):
        self.readersRemoved += 1

    def removeWriter(self, _):
        self.writersRemoved += 1

    def callLater(self, delay, callable, *args, **kwargs):
        callable(*args, **kwargs)


class FakeWrapper(txpostgres._PollingMixin):
    """
    A mock subclass of L{txpostgres._PollingMixin}.
    """
    reactor = FakeReactor()
    prefix = "fake-wrapper"

    def pollable(self):
        return self._pollable


class TxPostgresPollingMixinTestCase(Psycopg2TestCase):

    def test_empty(self):
        """
        The default L{txpostgres._PollingMixin} implementation raises an
        exception on pollable().
        """
        p = txpostgres._PollingMixin()
        self.assertRaises(NotImplementedError, p.pollable)

    def check(self, r, *args):
        self.assertEquals(args, (r.readersAdded, r.writersAdded,
                                 r.readersRemoved, r.writersRemoved))

    def test_polling(self):
        """
        L{txpostgres._PollingMixin} adds and removes itself from the reactor
        according to poll() results from the wrapped pollable.
        """
        p = FakeWrapper()
        p._pollable = PollableThing()
        p.reactor.reset()

        # start off with reading
        p._pollable.NEXT_STATE = psycopg2.extensions.POLL_READ
        d = p.poll()
        # after the initial poll we should get a Deferred and one reader added
        self.check(p.reactor, 1, 0, 0, 0)

        p._pollable.NEXT_STATE = psycopg2.extensions.POLL_WRITE
        p.doRead()
        # the reader should get removed and a writer should get added, because
        # we made the next poll() return POLL_WRITE
        self.check(p.reactor, 1, 1, 1, 0)

        p._pollable.NEXT_STATE = psycopg2.extensions.POLL_READ
        p.doWrite()
        # the writer is removed, a reader is added
        self.check(p.reactor, 2, 1, 1, 1)

        p._pollable.NEXT_STATE = psycopg2.extensions.POLL_READ
        p.doRead()
        # the reader is removed, but then readded because we returned POLL_READ
        self.check(p.reactor, 3, 1, 2, 1)

        p._pollable.NEXT_STATE = psycopg2.extensions.POLL_OK
        p.doRead()
        # we're done, the reader should just get removed
        self.check(p.reactor, 3, 1, 3, 1)

        # and the Deferred should succeed
        return d

    def test_interface(self):
        """
        L{txpostgres._PollingMixin} correctly provides the
        L{interfaces.IReadWriteDescriptor} interface.
        """
        p = FakeWrapper()
        p._pollable = PollableThing()

        self.assertEquals(p.fileno(), 42)
        self.assertEquals(p.logPrefix(), "fake-wrapper")

        # check if it will correctly return -1 after the connection got lost,
        # to work with Twisted affected by bug #4539
        p._pollable.closed = 1
        self.assertEquals(p.fileno(), -1)

    def test_connectionLost(self):
        """
        Calls to connectionLost() get swallowed.
        """
        p = FakeWrapper()
        p._pollable = PollableThing()
        p._pollable.NEXT_STATE = psycopg2.extensions.POLL_OK

        d = p.poll()
        p.connectionLost(failure.Failure(RuntimeError("boom")))
        p.connectionLost(failure.Failure(RuntimeError("bam")))
        return d.addCallback(self.assertEquals, p)

    def test_connectionLostWhileWaiting(self):
        """
        If the connection is lost while waiting for the socket to become
        writable, the C{Deferred} returned from poll() still errbacks.
        """
        p = FakeWrapper()
        p._pollable = PollableThing()
        p._pollable.NEXT_STATE = psycopg2.extensions.POLL_WRITE

        d = p.poll()
        p._pollable.NEXT_STATE = RuntimeError("forced poll error")
        p.connectionLost(failure.Failure(main.CONNECTION_LOST))
        return self.assertFailure(d, RuntimeError)
    test_connectionLostWhileWaiting.timeout = 5

    def test_connectionLostWhileReading(self):
        """
        If the connection is closed after the polling succeeded and after the
        socket became readable again, but not all of the data has been read
        from the socket, the closed flag is set and no errors are reported.

        This might seem elaborated, but a hypothetical error scenario is:
         * the connection is estabilished and starts watching for socket
           readability to get NOTIFY events
         * a NOTIFY comes through and doRead is triggered
         * not all data is read from the socket and it remains readable
         * the connection is closed and the Deferred returned from poll()
           called inside doRead is errbacked without being ever available to user
           code

        It has been reported that under heavy load this can happen.
        """
        p = FakeWrapper()
        p._pollable = PollableThing()

        # the connection is estabilished
        p._pollable.NEXT_STATE = psycopg2.extensions.POLL_OK
        d = p.poll()
        # doRead is called, but the socket is still readable
        p._pollable.NEXT_STATE = psycopg2.extensions.POLL_READ
        p.doRead()
        # the connection is closed
        p._pollable.closed = True
        p.connectionLost(failure.Failure(main.CONNECTION_LOST))
        # return the connection Deferred
        return d

    def test_errors(self):
        """
        Unexpected results from poll() make L{txpostgres._PollingMixin} raise
        an exception.
        """
        p = FakeWrapper()
        p._pollable = PollableThing()

        p._pollable.NEXT_STATE = "foo"
        d = p.poll()
        return self.assertFailure(d, txpostgres.UnexpectedPollResult)

    def test_cancel(self):
        """
        Cancelling a C{Deferred} returned from poll() proxies the cancellation
        to the pollable and raises C{_CancelInProgress}.
        """
        p = FakeWrapper()
        p._pollable = CancellablePollableThing()

        d = p.poll()
        self.assertRaises(txpostgres._CancelInProgress, d.cancel)
        self.assertEquals(p._pollable.cancelled, True)

    def test_noCancelSupport(self):
        """
        Cancelling a C{Deferred} returned from poll() with a pollable that does
        not support cancelling just raises C{_CancelInProgress}.
        """
        p = FakeWrapper()
        p._pollable = PollableThing()

        d = p.poll()
        self.assertRaises(txpostgres._CancelInProgress, d.cancel)
        self.assertRaises(AttributeError, getattr, p._pollable, 'cancel')
        self.assertRaises(AttributeError, getattr, p._pollable, 'cancelled')


class TxPostgresConnectionTestCase(Psycopg2TestCase):

    def test_simpleConnection(self):
        """
        Just connecting and disconnecting works.
        """
        conn = txpostgres.Connection()
        d = conn.connect(user=DB_USER, password=DB_PASS,
                         host=DB_HOST, database=DB_NAME)
        d.addCallback(lambda c: c.close())
        return d

    def test_connectionSetup(self):
        """
        The created connection should be asynchronous and in autocommit mode
        and the C{Deferred} returned from connect() should fire with the
        connection itself.
        """
        conn = txpostgres.Connection()
        d = conn.connect(user=DB_USER, password=DB_PASS,
                         host=DB_HOST, database=DB_NAME)

        def doChecks(c):
            self.assertIdentical(c, conn)
            self.assertTrue(c.async)
            self.assertEquals(c.isolation_level, 0)
            return c
        d.addCallback(doChecks)
        return d.addCallback(lambda c: c.close())

    def test_multipleConnections(self):
        """
        Trying to connect twice raises an exception, but after closing you can
        connect again.
        """
        conn = txpostgres.Connection()
        d = conn.connect(user=DB_USER, password=DB_PASS,
                         host=DB_HOST, database=DB_NAME)

        d.addCallback(lambda c: conn.connect(
                user=DB_USER, password=DB_PASS,
                host=DB_HOST, database=DB_NAME))
        d = self.failUnlessFailure(d, txpostgres.AlreadyConnected)

        d.addCallback(lambda _: conn.close())
        d.addCallback(lambda _: conn.connect(
                user=DB_USER, password=DB_PASS,
                host=DB_HOST, database=DB_NAME))
        return d.addCallback(lambda c: c.close())

    def test_errors(self):
        """
        Errors from psycopg2's poll() make connect() return failures. Errors on
        creating the psycopg2 connection too. Unexpected results from poll()
        also make connect() return a failure.
        """
        conn = txpostgres.Connection()

        def setFactory(conn, factory):
            conn.connectionFactory = factory

        class BadPollable(object):
            closed = 1

            def __init__(*args, **kwars):
                pass

            def poll(self):
                raise RuntimeError("booga")

            def close(self):
                pass

        setFactory(conn, BadPollable)

        d = conn.connect()
        d = self.assertFailure(d, RuntimeError)
        d.addCallback(lambda _: conn.close())

        class BadThing(object):
            closed = 1

            def __init__(*args, **kwargs):
                raise RuntimeError("wooga")

            def close(self):
                pass

        d.addCallback(lambda _: setFactory(conn, BadThing))

        d.addCallback(lambda _: conn.connect())
        d = self.assertFailure(d, RuntimeError)

        class BrokenPollable(object):
            closed = 1

            def __init__(*args, **kwars):
                pass

            def poll(self):
                return "tee hee hee"

            def close(self):
                pass

        d.addCallback(lambda _: setFactory(conn, BrokenPollable))

        d.addCallback(lambda _: conn.connect())
        return self.assertFailure(d, txpostgres.UnexpectedPollResult)

    def test_openRunCloseOpen(self):
        conn = txpostgres.Connection()
        connargs = dict(user=DB_USER, password=DB_PASS,
                        host=DB_HOST, database=DB_NAME)
        d = conn.connect(**connargs)
        d.addCallback(lambda _: conn.runQuery("select 1"))
        # make sure the txpostgres.Cursor created by runQuery got closed,
        # otherwise it will still be polled and will result in an error
        d.addCallback(lambda _: conn.close())
        d.addCallback(lambda _: conn.connect(**connargs))
        return d.addCallback(lambda _: conn.close())

    def test_closeTwice(self):
        """
        Calling close() on the connection twice does not result in an error.
        """
        conn = txpostgres.Connection()
        d = conn.connect(user=DB_USER, password=DB_PASS,
                         host=DB_HOST, database=DB_NAME)

        def closeTwice(_):
            conn.close()
            conn.close()

        d.addCallback(closeTwice)
        return d.addCallback(lambda _: self.assertTrue(conn.closed))

    def test_connectionRemovingReader(self):
        """
        The connection is not reading from the socket while a cursor is
        running.
        """
        class ExclusiveCursor(txpostgres.Cursor):
            testcase = self

            def doRead(self):
                for reader in self.reactor.getReaders():
                    if isinstance(reader, txpostgres.Connection):
                        self.testcase.fail(
                            "doRead called on Cursor "
                            "while a Connection is among readers: %r" %
                            self.reactor.getReaders())

                return txpostgres.Cursor.doRead(self)

        conn = txpostgres.Connection()
        conn.cursorFactory = ExclusiveCursor
        d = conn.connect(user=DB_USER, password=DB_PASS,
                         host=DB_HOST, database=DB_NAME)
        # use something more complex than select 1 or otherwise the query might
        # complete in a single reactor cycle
        d.addCallback(lambda _: conn.cursor().execute("select pg_sleep(0.1)"))
        return d.addCallback(lambda _: conn.close())


class _SimpleDBSetupMixin(object):

    connectionClass = txpostgres.Connection

    def setUp(self):
        d = self.restoreConnection(None)
        d.addCallback(lambda _: self.conn.cursor())
        return d.addCallback(lambda c: c.execute(simple_table_schema))

    def tearDown(self):
        c = self.conn.cursor()
        d = c.execute("drop table simple")
        return d.addCallback(lambda _: self.conn.close())

    def restoreConnection(self, res):
        """
        Restore the connection to the database and return whatever argument has
        been passed through. Useful as an addBoth handler for tests that
        disconnect from the database.
        """
        self.conn = self.connectionClass()
        d = self.conn.connect(user=DB_USER, password=DB_PASS,
                              host=DB_HOST, database=DB_NAME)
        return d.addCallback(lambda _: res)


class TxPostgresManualQueryTestCase(_SimpleDBSetupMixin, Psycopg2TestCase):

    def test_simpleQuery(self):
        """
        A simple select works.
        """
        c = self.conn.cursor()
        return c.execute("select * from simple")

    def test_simpleCallproc(self):
        """
        A simple procedure call works.
        """
        c = self.conn.cursor()
        return c.callproc("now")

    def test_closeCursor(self):
        """
        Closing the cursor works.
        """
        c = self.conn.cursor()
        d = c.execute("select 1")
        return d.addCallback(lambda c: c.close())

    def test_queryResults(self):
        """
        Query results are obtainable from the asynchronous cursor.
        """
        c = self.conn.cursor()
        d = defer.Deferred()
        d.addCallback(
            lambda c: c.execute("insert into simple values (%s)", (1, )))
        d.addCallback(
            lambda c: c.execute("insert into simple values (%s)", (2, )))
        d.addCallback(
            lambda c: c.execute("insert into simple values (%s)", (3, )))
        d.addCallback(
            lambda c: c.execute("select * from simple"))
        d.addCallback(
            lambda c: self.assertEquals(c.fetchall(), [(1, ), (2, ), (3, )]))
        d.callback(c)
        return d

    def test_cursorKwargs(self):
        """
        Cursor methods can be called using keyword arguments.
        """
        c = self.conn.cursor()
        d = c.execute(params=(1, ), query="select %s")
        return d.addCallback(
            lambda c: self.assertEquals(c.fetchall(), [(1, )]))

    def test_errors(self):
        """
        Errors from the database are reported as failures.
        """
        c = self.conn.cursor()
        d = c.execute("select * from nonexistent")
        return self.assertFailure(d, psycopg2.ProgrammingError)

    def test_wrongCall(self):
        """
        Errors raised inside psycopg2 are reported as failures.
        """
        c = self.conn.cursor()
        d = c.execute("select %s", "whoops")
        return self.assertFailure(d, TypeError)

    def test_manualTransactions(self):
        """
        Transactions can be constructed manually by issuing BEGIN and ROLLBACK
        as appropriate, and should work.
        """
        c = self.conn.cursor()
        d = defer.Deferred()
        d.addCallback(
            lambda c: c.execute("begin"))
        d.addCallback(
            lambda c: c.execute("insert into simple values (%s)", (1, )))
        d.addCallback(
            lambda c: c.execute("insert into simple values (%s)", (2, )))
        d.addCallback(
            lambda c: c.execute("select * from simple order by x"))
        d.addCallback(
            lambda c: self.assertEquals(c.fetchall(), [(1, ), (2, )]))
        d.addCallback(
            lambda _: c.execute("rollback"))
        d.addCallback(
            lambda c: c.execute("select * from simple"))
        d.addCallback(
            lambda c: self.assertEquals(c.fetchall(), []))
        d.callback(c)
        return d


class NotRollingBackCursor(txpostgres.Cursor):
    """
    A cursor that does not like rolling back.
    """
    def _doit(self, name, *args, **kwargs):
        if name == "execute" and args == ("rollback", None):
            raise RuntimeError("boom")
        return txpostgres.Cursor._doit(self, name, *args, **kwargs)


class TxPostgresQueryTestCase(_SimpleDBSetupMixin, Psycopg2TestCase):

    def test_runQuery(self):
        """
        runQuery() works and returns the result.
        """
        d = self.conn.runQuery("select 1")
        return d.addCallback(self.assertEquals, [(1, )])

    def test_runQueryMultiple(self):
        """
        Multiple calls to runQuery() without waiting for the previous one work
        and return correct results.
        """
        d = defer.gatherResults([self.conn.runQuery("select %s", (i, ))
                                 for i in range(5)])
        d.addCallback(
            lambda results: self.assertEquals(
                sorted(map(lambda res: res[0][0], results)),
                [0, 1, 2, 3, 4]))
        return d

    def test_runOperation(self):
        """
        runOperation() works and executes the operation while returning None.
        """
        d = self.conn.runQuery("select count(*) from simple")
        d.addCallback(self.assertEquals, [(0, )])

        d.addCallback(lambda _: self.conn.runOperation(
                "insert into simple values (%s)", (1, )))
        d.addCallback(self.assertIdentical, None)

        d.addCallback(lambda _: self.conn.runQuery(
                    "select count(*) from simple"))
        return d.addCallback(self.assertEquals, [(1, )])

    def test_runSimpleInteraction(self):
        """
        Interactions are being run in a transaction, the parameters from
        runInteraction are being passed to them and they are being committed
        after they return. Their return value becomes the return value of the
        Deferred from runInteraction.
        """
        def interaction(c, arg1, kwarg1):
            self.assertEquals(arg1, "foo")
            self.assertEquals(kwarg1, "bar")
            d = c.execute("insert into simple values (1)")
            d.addCallback(lambda c: c.execute("insert into simple values (2)"))
            return d.addCallback(lambda _: "interaction done")

        d = self.conn.runInteraction(interaction, "foo", kwarg1="bar")

        d.addCallback(self.assertEquals, "interaction done")

        d.addCallback(lambda _: self.conn.runQuery(
                "select * from simple order by x"))
        return d.addCallback(self.assertEquals, [(1, ), (2, )])

    def test_runErrorInteraction(self):
        """
        Interactions that produce errors are rolled back and the correct error
        is reported.
        """
        def interaction(c):
            d = c.execute("insert into simple values (1)")
            return d.addCallback(
                lambda c: c.execute("select * from nope_not_here"))

        d = self.conn.runInteraction(interaction)
        d = self.assertFailure(d, psycopg2.ProgrammingError)

        d.addCallback(lambda _: self.conn.runQuery(
                "select count(*) from simple"))
        return d.addCallback(self.assertEquals, [(0, )])

    def test_errorOnRollback(self):
        """
        Interactions that produce errors and are unable to roll back return a
        L{txpostgres.RollbackFailed} failure that has references to the faulty
        connection and the original failure that cause all that trouble.
        """
        def interaction(c):
            d = c.execute("insert into simple values (1)")
            return d.addCallback(
                lambda c: c.execute("select * from nope_not_here"))

        mp = self.patch(self.conn, 'cursorFactory', NotRollingBackCursor)

        d = self.conn.runInteraction(interaction)
        d.addCallback(lambda _: self.fail("No exception"))

        def checkError(f):
            f.trap(txpostgres.RollbackFailed)
            original = f.value.originalFailure
            # original should reference the error that started all the mess
            self.assertIsInstance(original.value,
                                  psycopg2.ProgrammingError)
            self.assertEquals(
                str(f.value),
                "<RollbackFailed, original error: %s>" % original)
            # the error from the failed rollback should get logged
            errors = self.flushLoggedErrors()
            self.assertEquals(len(errors), 1)
            self.assertEquals(errors[0].value.args[0], "boom")
            # restore or we won't be able to clean up the mess
            mp.restore()
        d.addErrback(checkError)

        # rollback for real, or tearDown won't be able to drop the table
        return d.addCallback(lambda _: self.conn.runOperation("rollback"))

    def test_terminatedConnection(self):
        """
        If the connection gets terminated (because of a segmentation fault,
        administrative backend termination or other circumstances), a failure
        wrapping the original psycopg2 error is returned and subsequent queries
        fail with an error indicating that the connection is already closed.
        """
        # this tests uses pg_terminate_backend, so it only works on PostgreSQL
        # 8.4+ and if the user running the tests is a superuser.
        if self.conn.server_version < 84000:
            raise unittest.SkipTest(
                "PostgreSQL < 8.4.0 does not have pg_terminate_backend")

        # check if this Twisted has a patch for #4539, otherwise the test will
        # fail because the terminated cursor will have fileno() called on it
        if not getattr(posixbase, '_PollLikeMixin', None):
            raise unittest.SkipTest("This test fails on versions of Twisted "
                                    "affected by Twisted bug #4539")

        # Check if we're running under psycopg2ct from before the patch that
        # added correct terminated connection handling. Then only way to know
        # that seems to be looking at the __version__ string.
        if (getattr(psycopg2, '_impl', None) and
            'ctypes' not in psycopg2.__version__):
            raise unittest.SkipTest(
                "This test fails on versions of psycopg2ct 0.3 and older, "
                "which have a bug in terminated connection handling")

        def checkSuperuser(ret):
            if ret[0][0] != 'on':
                raise unittest.SkipTest(
                    "This test uses pg_terminate_backend, "
                    "which can only be called by a database superuser")

        d = self.conn.runQuery("show is_superuser")
        d.addCallback(checkSuperuser)

        def terminateAndRunQuery():
            d = self.conn.runQuery("select pg_terminate_backend(%s)",
                                   (self.conn.get_backend_pid(), ))

            def fail(ignore):
                self.fail("did not catch an error, instead got %r" % (ignore,))

            def checkDatabaseError(f):
                if f.check(psycopg2.DatabaseError):
                    return f.value

                if f.check(SystemError):
                    raise unittest.SkipTest(
                        "This test fails on versions of psycopg2 before 2.4.1 "
                        "which have a bug in libpq error handling")

                self.fail(("\nExpected: %r\nGot:\n%s"
                           % (psycopg2.DatabaseError, str(f))))

            def runSimpleQuery(_):
                d = self.conn.runQuery("select 1")
                return self.assertFailure(d, psycopg2.InterfaceError)

            d.addCallbacks(fail, checkDatabaseError)
            d.addCallback(runSimpleQuery)
            # restore the connection, otherwise all the other tests will fail
            return d.addBoth(self.restoreConnection)

        return d.addCallback(lambda _: terminateAndRunQuery())

    def test_connectionLostWhileRunning(self):
        """
        If the connection is lost while a query is still underway, the polling
        cycle is continued until psycopg2 either reports success or an error.
        """
        cursors = []

        class RetainingCursor(txpostgres.Cursor):

            def __init__(self, cursor, connection):
                cursors.append(self)
                txpostgres.Cursor.__init__(self, cursor, connection)

        mp = self.patch(self.conn, 'cursorFactory', RetainingCursor)

        d1 = self.conn.runQuery("select 1")
        d2 = self.conn.runQuery("select 1")

        self.assertEquals(len(cursors), 1)
        # even if the cursor gets connectionLost called on it, it will continue
        # to poll the connection, which is mandated by the API (the client
        # can't stop polling the connection until either POLL_OK is returned or
        # an exception is raised.
        cursors[0].connectionLost(failure.Failure(RuntimeError("boom")))

        # since no error was reported from psycopg2, both Deferreds callback
        d = defer.gatherResults([d1, d2])
        d.addCallback(self.assertEquals, [[(1, )], [(1, )]])
        return d.addCallback(lambda _: mp.restore())

    def test_disconnectWhileRunning(self):
        """
        Disconnecting from the server when there is a query underway causes the
        query to fail with ConnectionDone.
        """
        # check if this Twisted has a patch for #4539, otherwise the cursor
        # will have fileno() called on it after the psycopg2 closes the
        # connection socket, resulting in an error
        if not getattr(posixbase, '_PollLikeMixin', None):
            raise unittest.SkipTest("This test fails on versions of Twisted "
                                    "affected by Twisted bug #4539")

        def _checkConnectionLost(f, testcase):
            if not isinstance(f, failure.Failure):
                testcase.fail("connectionLost got non-Failure: %r" % f)
            if not f.check(error.ConnectionDone):
                testcase.fail("connectionLost got wrong Failure: %r" % f.value)

        producedCursors = []

        class StrictLosingConnection(txpostgres.Connection):
            testcase = self
            seenConnectionLost = False

            def connectionLost(self, reason):
                txpostgres.Connection.connectionLost(self, reason)
                self.seenConnectionLost = True
                _checkConnectionLost(reason, self.testcase)

            def cursor(self, *args, **kwargs):
                cursor = txpostgres.Connection.cursor(self, *args, **kwargs)
                producedCursors.append(cursor)
                return cursor

        class StrictLosingCursor(txpostgres.Cursor):
            testcase = self
            seenConnectionLost = False

            def connectionLost(self, reason):
                txpostgres.Cursor.connectionLost(self, reason)
                self.seenConnectionLost = True
                _checkConnectionLost(reason, self.testcase)

        def _runAndClose():
            # start executing the query and close it in the next reactor cycle
            d = conn.runQuery("select pg_sleep(5)")
            reactor.callLater(0, conn.close)
            return d

        def _waitReactorCycle():
            # wait one reactor cycle to allow callback to propagate
            d = defer.Deferred()
            reactor.callLater(0, d.callback, None)
            return d

        def _checkSeenConnectionLost():
            self.assertTrue(conn.seenConnectionLost)
            for cursor in producedCursors:
                self.assertTrue(cursor.seenConnectionLost)

        conn = StrictLosingConnection()
        conn.cursorFactory = StrictLosingCursor
        d = conn.connect(user=DB_USER, password=DB_PASS,
                         host=DB_HOST, database=DB_NAME)

        d.addCallback(lambda _: _runAndClose())
        # the query fails with a disconnected error
        d = self.assertFailure(d, error.ConnectionDone)
        d.addCallback(lambda _: _waitReactorCycle())
        return d.addCallback(lambda _: _checkSeenConnectionLost())


class TxPostgresConnectionPoolTestCase(Psycopg2TestCase):

    def setUp(self):
        self.pool = txpostgres.ConnectionPool(
            None, user=DB_USER, password=DB_PASS,
            host=DB_HOST, database=DB_NAME)
        return self.pool.start()

    def tearDown(self):
        return self.pool.close()

    def test_basics(self):
        """
        Exactly 'min' connections are always created.
        """
        self.assertEquals(len(self.pool.connections), self.pool.min)

    def test_simpleQuery(self):
        """
        The pool can run 'min' queries in parallel without making any of them
        wait. The queries return correct values.
        """
        ds = [self.pool.runQuery("select 1") for _ in range(self.pool.min)]
        self.assertEquals(len(self.pool._semaphore.waiting), 0)

        d = defer.gatherResults(ds)
        return d.addCallback(self.assertEquals, [[(1, )]] * self.pool.min)

    def test_moreQueries(self):
        """
        The pool can handle more parallel queries than its size.
        """
        d = defer.gatherResults(
            [self.pool.runQuery("select 1") for _ in range(self.pool.min * 5)])
        return d.addCallback(self.assertEquals, [[(1, )]] * self.pool.min * 5)

    def test_operation(self):
        """
        The pool's runOperation works.
        """
        d = self.pool.runOperation("create table x (i int)")
        # give is a workout, 20 x the number of connections
        d.addCallback(lambda _: defer.gatherResults(
                [self.pool.runOperation("insert into x values (%s)", (i, ))
                 for i in range(self.pool.min * 20)]))
        d.addCallback(lambda _: self.pool.runQuery(
                "select * from x order by i"))
        d.addCallback(self.assertEquals, [(i, ) for i in
                                         range(self.pool.min * 20)])
        return d.addCallback(lambda _: self.pool.runOperation(
                "drop table x"))

    def test_interaction(self):
        """
        The pool's runInteraction works.
        """
        def interaction(c):
            # cursors can only be declared in a transaction, so that's a good
            # indication that we're in one
            d = c.execute("declare x cursor for values (1), (2)")
            d.addCallback(lambda c: c.execute("fetch 1 from x"))
            d.addCallback(lambda c: self.assertEquals(c.fetchone()[0], 1))
            d.addCallback(lambda _: c.execute("fetch 1 from x"))
            d.addCallback(lambda c: self.assertEquals(c.fetchone()[0], 2))
            return d

        return defer.gatherResults([self.pool.runInteraction(interaction)
                                    for _ in range(self.pool.min * 20)])


class TxPostgresConnectionPoolErrorsTestCase(Psycopg2TestCase):

    def test_errorsInConnections(self):
        """
        A failure in any connection makes the Deferred returned from start()
        fail.
        """
        class ErrorConnection(object):
            connid = 0

            def __init__(self, *args):
                pass

            def connect(self, *args, **kwargs):
                # the third connection fails
                ErrorConnection.connid += 1
                if ErrorConnection.connid == 3:
                    return defer.fail(RuntimeError("boom"))
                return defer.succeed(None)

        class ErrorConnectionPool(txpostgres.ConnectionPool):
            connectionFactory = ErrorConnection

        pool = ErrorConnectionPool(None, min=3)
        d = pool.start()

        d = self.assertFailure(d, defer.FirstError)
        return d.addCallback(lambda exc: exc.subFailure.trap(RuntimeError))


class TxPostgresConnectionPoolHotswappingTestCase(Psycopg2TestCase):

    def test_errorsInInteractionHotswappingConnections(self):
        """
        After getting a RollbackFailed failure it is possible to remove the
        offending connection from the pool, open a new one and put it in the
        pool to replace the removed one.
        """
        pool = txpostgres.ConnectionPool(
            None, user=DB_USER, password=DB_PASS,
            host=DB_HOST, database=DB_NAME, min=1)
        self.assertEquals(pool.min, 1)
        d = pool.start()

        # poison the connection
        c, = pool.connections
        c.cursorFactory = NotRollingBackCursor

        # run stuff that breaks
        def brokenInteraction(c):
            return c.execute("boom")
        d.addCallback(lambda _: pool.runInteraction(brokenInteraction))
        d.addCallback(lambda _: self.fail("No exception"))

        def checkErrorAndHotswap(f):
            f.trap(txpostgres.RollbackFailed)
            e = f.value
            self.assertIdentical(e.connection.cursorFactory,
                                 NotRollingBackCursor)
            errors = self.flushLoggedErrors()
            self.assertEquals(len(errors), 1)
            self.assertEquals(errors[0].value.args[0], "boom")
            pool.remove(e.connection)
            e.connection.close()
            c = txpostgres.Connection()
            self.assertNotIdentical(c.cursorFactory,
                                    NotRollingBackCursor)
            d = c.connect(user=DB_USER, password=DB_PASS,
                          host=DB_HOST, database=DB_NAME)
            return d.addCallback(lambda c: pool.add(c))

        d.addErrback(checkErrorAndHotswap)

        d.addCallback(lambda _: defer.gatherResults([
                    pool.runQuery("select 1") for _ in range(3)]))
        d.addCallback(self.assertEquals, [[(1, )]] * 3)
        return d.addCallback(lambda _: pool.close())

    def test_removeWhileBusy(self):
        """
        Removing a connection from the pool while it's running a query raises
        an exception.
        """
        pool = txpostgres.ConnectionPool(
            None, user=DB_USER, password=DB_PASS,
            host=DB_HOST, database=DB_NAME, min=1)

        d = pool.start()

        def simple(c):
            self.assertRaises(ValueError, pool.remove, c._connection)
        d.addCallback(lambda pool: pool.runInteraction(simple))
        return d.addCallback(lambda _: pool.close())


class TxPostgresCancellationTestCase(_SimpleDBSetupMixin, Psycopg2TestCase):

    def setUp(self):
        def checkCancellationSupport():
            # check for cancellation support in psycopg2, skip if not present
            if not getattr(self.conn.pollable(), "cancel", None):
                raise unittest.SkipTest(
                    "psycopg2 does not have query cancellation support. "
                    "You need at least version 2.3.0 of psycopg2 "
                    "to use query cancellation.")

        def createAdditionalConnection():
            # Create an additional connection that will be used to check if the
            # main one is already waiting on pg_sleep.
            self.extra = txpostgres.Connection()
            return self.extra.connect(user=DB_USER, password=DB_PASS,
                                      host=DB_HOST, database=DB_NAME)

        d = _SimpleDBSetupMixin.setUp(self)
        d.addCallback(lambda _: checkCancellationSupport())
        return d.addCallback(lambda _: createAdditionalConnection())

    def tearDown(self):
        d = _SimpleDBSetupMixin.tearDown(self)
        return d.addCallback(lambda _: self.extra.close())

    def waitForSleep(self):
        """
        Return a Deferred that fires when the main connection starts executing
        pg_sleep. This is done by polling pg_stat_statements from the extra
        connection.
        """
        # XXX is this really the only way to make these tests not racy?
        interval = 0.5
        initial_remaining = 10

        def gotResult(res, remaining):
            if res and res[0][0]:
                # the result of the query was True, we're done
                return

            if not remaining:
                self.fail('main connection did not execute pg_sleep')

            # main connection still not executing pg_sleep, wait
            return task.deferLater(reactor, interval, checkActivity, remaining)

        def checkActivity(remaining):
            d = self.extra.runQuery("select current_query like '%%pg_sleep%%' "
                                    "from pg_stat_activity where procpid = %s",
                                    (self.conn.get_backend_pid(), ))
            return d.addCallback(gotResult, remaining - 1)

        return checkActivity(initial_remaining)

    def test_simpleCancellation(self):
        d = self.conn.runQuery("select pg_sleep(5)")

        def cancelQuery(_):
            self.conn.cancel(d)
            return self.failUnlessFailure(d, defer.CancelledError)

        waiting = self.waitForSleep()
        return waiting.addCallback(cancelQuery)

    def test_directCancellation(self):
        d = self.conn.runQuery("select pg_sleep(5)")

        def tryDirectCancel(_):
            self.assertRaises(txpostgres._CancelInProgress, d.cancel)
            return self.failUnlessFailure(d, defer.CancelledError)

        waiting = self.waitForSleep()
        return waiting.addCallback(tryDirectCancel)

    def test_cancelInteraction(self):
        def interaction(c):
            def cancelQuery(_):
                self.conn.cancel(d)
                return d

            d = c.execute("insert into simple values (1)")
            d.addCallback(lambda c: c.execute("insert into simple values (2)"))
            d.addCallback(lambda c: c.execute("select pg_sleep(5)"))
            d.addCallback(lambda _: "interaction done")

            waiting = self.waitForSleep()
            return waiting.addCallback(cancelQuery)

        d = self.conn.runInteraction(interaction)
        d = self.failUnlessFailure(d, defer.CancelledError)
        d.addCallback(lambda _: self.conn.runQuery(
                "select * from simple"))
        return d.addCallback(self.assertEquals, [])

    def test_cancelMultipleQueries(self):
        d1 = self.conn.runQuery("select pg_sleep(5)")
        d2 = self.conn.runQuery("select pg_sleep(5)")

        def cancelQueries(_):
            self.conn.cancel(d1)
            self.conn.cancel(d2)

            self.failUnlessFailure(d1, defer.CancelledError)
            self.failUnlessFailure(d2, defer.CancelledError)

            return defer.gatherResults([d1, d2])

        waiting = self.waitForSleep()
        return waiting.addCallback(cancelQueries)


class TxPostgresNotifyObserversTestCase(Psycopg2TestCase):

    def test_sameObserverAddedTwice(self):
        """
        Adding the same observer twice results in just one registration.
        """
        c = txpostgres.Connection()

        def observer(notify):
            pass

        self.assertEquals(len(c.getNotifyObservers()), 0)

        c.addNotifyObserver(observer)
        c.addNotifyObserver(observer)

        self.assertEquals(len(c.getNotifyObservers()), 1)

    def test_removeNonexistentObserver(self):
        """
        Removing an observer twice is valid and results in the observer being
        removed. Removing one that does not exist at all is valid as well.
        """
        c = txpostgres.Connection()

        def observer1(notify):
            pass
        def observer2(notify):
            pass

        c.addNotifyObserver(observer1)
        c.addNotifyObserver(observer2)

        self.assertEquals(len(c.getNotifyObservers()), 2)

        c.removeNotifyObserver(observer1)
        c.removeNotifyObserver(observer1)
        c.removeNotifyObserver(lambda _: _)

        self.assertEquals(len(c.getNotifyObservers()), 1)
        self.assertIn(observer2, c.getNotifyObservers())


class TxPostgresNotifyTestCase(_SimpleDBSetupMixin, Psycopg2TestCase):

    def setUp(self):
        self.notifyconn = txpostgres.Connection()
        self.notifies = []

        d = self.notifyconn.connect(user=DB_USER, password=DB_PASS,
                                    host=DB_HOST, database=DB_NAME)
        return d.addCallback(lambda _: _SimpleDBSetupMixin.setUp(self))

    def tearDown(self):
        self.notifyconn.close()
        return _SimpleDBSetupMixin.tearDown(self)

    def sendNotify(self):
        return self.notifyconn.runOperation('notify txpostgres_test')

    def test_simpleNotify(self):
        """
        Notifications sent form another session are delivered to the listening
        session.
        """
        notifyD = defer.Deferred()

        def observer(notify):
            self.notifies.append(notify)
            notifyD.callback(None)

        self.conn.addNotifyObserver(observer)

        d = self.conn.runOperation("listen txpostgres_test")
        d.addCallback(lambda _: self.sendNotify())
        # wait for the notification to be processed
        d.addCallback(lambda _: notifyD)
        d.addCallback(lambda _: self.assertEquals(len(self.notifies), 1))
        return d.addCallback(lambda _: self.assertEquals(
                self.notifies[0][1], "txpostgres_test"))

    def test_simpleNotifySameConnection(self):
        """
        Notifications sent from the listening session are delivered to the session.
        """
        notifyD = defer.Deferred()

        def observer(notify):
            self.notifies.append(notify)
            notifyD.callback(None)

        self.notifyconn.addNotifyObserver(observer)

        d = self.notifyconn.runOperation("listen txpostgres_test")
        d.addCallback(lambda _: self.sendNotify())
        # wait for the notification to be processed
        d.addCallback(lambda _: notifyD)
        d.addCallback(lambda _: self.assertEquals(len(self.notifies), 1))
        return d.addCallback(lambda _: self.assertEquals(
                self.notifies[0][1], "txpostgres_test"))

    def test_listenUnlisten(self):
        """
        Unlistening causes notifications not to be delivered anymore.
        """
        notifyD = defer.Deferred()

        def observer(notify):
            self.notifies.append(notify)
            notifyD.callback(None)

        self.conn.addNotifyObserver(observer)

        d = self.conn.runOperation("listen txpostgres_test")
        d.addCallback(lambda _: self.sendNotify())
        d.addCallback(lambda _: notifyD)
        d.addCallback(lambda _: self.assertEquals(len(self.notifies), 1))
        d.addCallback(lambda _: self.conn.runOperation(
                "unlisten txpostgres_test"))
        d.addCallback(lambda _: self.sendNotify())
        # run a query to force the reactor to spin and flush eventual pending
        # notifications, which there should be none since we did unlisten
        d.addCallback(lambda _: self.conn.runOperation("select 1"))
        return d.addCallback(lambda _: self.assertEquals(
                len(self.notifies), 1))

    def test_multipleNotifies(self):
        """
        Multiple notifications sent in a row are gradually delivered.
        """
        dl = [defer.Deferred(), defer.Deferred(), defer.Deferred()]
        notifyD = defer.DeferredList(dl)

        def observer(notify):
            self.notifies.append(notify)
            dl.pop().callback(None)

        self.conn.addNotifyObserver(observer)

        d = self.conn.runOperation("listen txpostgres_test")
        d.addCallback(lambda _: self.sendNotify())
        d.addCallback(lambda _: self.sendNotify())
        d.addCallback(lambda _: self.sendNotify())
        d.addCallback(lambda _: notifyD)
        return d.addCallback(lambda _: self.assertEquals(
                len(self.notifies), 3))

    def test_multipleObservers(self):
        """
        Multiple registered notify observers each get notified.
        """
        dl1 = [defer.Deferred(), defer.Deferred()]
        dl2 = [defer.Deferred()]

        firstNotifyD = defer.DeferredList([dl1[1], dl2[0]])
        secondNotifyD = dl1[0]

        def observer1(notify):
            self.notifies.append(1)
            dl1.pop().callback(None)

        def observer2(notify):
            self.notifies.append(2)
            dl2.pop().callback(None)

        self.conn.addNotifyObserver(observer1)
        self.conn.addNotifyObserver(observer2)

        d = self.conn.runOperation("listen txpostgres_test")
        d.addCallback(lambda _: self.sendNotify())
        # two observers mean two notifications received
        d.addCallback(lambda _: firstNotifyD)
        # the order is not determined though
        d.addCallback(lambda _: self.assertEquals(
                set(self.notifies), set([1, 2])))
        d.addCallback(lambda _: self.conn.removeNotifyObserver(observer2))
        d.addCallback(lambda _: self.sendNotify())
        d.addCallback(lambda _: secondNotifyD)
        # the second observer has been removed, so there should be three
        # notifies and the last one should come from the first observer
        d.addCallback(lambda _: self.assertEquals(len(self.notifies), 3))
        return d.addCallback(lambda _: self.assertEquals(self.notifies[-1], 1))

    def test_errorInObserver(self):
        """
        An exception in an observer function gets logged and ignored.
        """
        dl = [defer.Deferred(), defer.Deferred()]
        notifyD = defer.DeferredList(dl)
        errorD = defer.Deferred()

        def observer1(notify):
            self.notifies.append(1)
            dl.pop().callback(None)

        def observer2(notify):
            errorD.callback(None)
            raise RuntimeError("boom")

        self.conn.addNotifyObserver(observer1)
        self.conn.addNotifyObserver(observer2)

        d = self.conn.runOperation("listen txpostgres_test")
        d.addCallback(lambda _: self.sendNotify())
        # at some point both observer functions will get called, one of them
        # raising an exception, to make sure they still are registered and
        # executing, send another notify
        d.addCallback(lambda _: errorD)
        d.addCallback(lambda _: self.conn.removeNotifyObserver(observer2))
        d.addCallback(lambda _: self.sendNotify())
        d.addCallback(lambda _: notifyD)
        d.addCallback(lambda _: self.assertEquals(
                len(self.flushLoggedErrors(RuntimeError)), 1))
        return d.addCallback(lambda _: self.assertEquals(
                self.notifies, [1, 1]))

    def test_observerReturnsDeferred(self):
        """
        If the observer function returns a Deferred, the next notify won't be
        processed until it fires.
        """
        observerDs = [defer.Deferred(), defer.Deferred()]
        notifyDs = [defer.Deferred(), defer.Deferred()]

        oneObserverDone = defer.DeferredList(notifyDs, fireOnOneCallback=True)
        allObserversDone = defer.DeferredList(notifyDs)

        def fireAllObserverDs():
            for observerD in observerDs:
                observerD.callback(None)
            return allObserversDone

        def observer(notify, observerD, notifyD):
            self.notifies.append(notify)
            # don't callback notifyD synchronously, or oneObserverDone might
            # start processing immediately
            reactor.callLater(0, notifyD.callback, None)
            return observerD

        def makeObserver(observerD, notifyD):
            return lambda notify: observer(notify, observerD, notifyD)

        for observerD, notifyD in zip(observerDs, notifyDs):
            self.conn.addNotifyObserver(makeObserver(observerD, notifyD))

        d = self.conn.runOperation("listen txpostgres_test")
        d.addCallback(lambda _: self.sendNotify())
        # wait for one of the observers to finish -- there's no guarantee of
        # order, so can't say which
        d.addCallback(lambda _: oneObserverDone)
        # only one observer should have been called
        d.addCallback(lambda _: self.assertEquals(len(self.notifies), 1))
        # fire both observer Deferreds to make sure the processing finishes
        d.addCallback(lambda _: fireAllObserverDs())
        # both observers should now be called
        return d.addCallback(lambda _: self.assertEquals(
                len(self.notifies), 2))

    def test_observerReturnsFailingDeferred(self):
        """
        If the observer function returns a failing Deferred, the failure is
        logged and processing continues.
        """
        dl = [defer.Deferred(), defer.Deferred()]
        notifyD = defer.DeferredList(dl)

        # use a factory function to ensure that id(observer1) != id(observer2)
        def makeObserver():
            def observer(notify):
                self.notifies.append(1)
                # callback asynchronously to make sure the function runs to
                # completion before continuing notifyD's callback chain
                reactor.callLater(0, dl.pop().callback, None)
                return defer.fail(RuntimeError("boom"))

            return observer

        self.conn.addNotifyObserver(makeObserver())
        self.conn.addNotifyObserver(makeObserver())

        d = self.conn.runOperation("listen txpostgres_test")
        d.addCallback(lambda _: self.sendNotify())
        # even though the observer functions return a failing Deferred, both of
        # them will be called
        d.addCallback(lambda _: notifyD)
        # both errors get logged
        d.addCallback(lambda _: self.assertEquals(
                len(self.flushLoggedErrors(RuntimeError)), 2))
        return d.addCallback(lambda _: self.assertEquals(
                self.notifies, [1, 1]))

    def test_customNotifyCooperator(self):
        """
        Using a custom cooperator for notifies is possible.
        """
        cooperateD = defer.Deferred()

        class FakeCooperator(object):

            def cooperate(self, iterator):
                self.result = []

                for ret in iterator:
                    defer.maybeDeferred(lambda: ret).addCallback(
                        self.result.append)

                cooperateD.callback(None)

        cooperator = FakeCooperator()

        def observer(notify):
            return True

        c = txpostgres.Connection(cooperator=cooperator)
        c.addNotifyObserver(observer)

        d = c.connect(user=DB_USER, password=DB_PASS,
                      host=DB_HOST, database=DB_NAME)
        d.addCallback(lambda _: c.runOperation("listen txpostgres_test"))
        d.addCallback(lambda _: self.sendNotify())
        d.addCallback(lambda _: cooperateD)
        d.addCallback(lambda _: self.assertEquals(
                cooperator.result, [True]))
        return d.addCallback(lambda _: c.close())


class SignallingDetector(reconnection.DeadConnectionDetector):

    died = False

    def startReconnecting(self, f):
        self.died = True
        return reconnection.DeadConnectionDetector.startReconnecting(self, f)


class ReconnectingConnection(txpostgres.Connection):

    def __init__(self, *args, **kwargs):
        self.clock = task.Clock()

        detector = SignallingDetector(
            deathChecker=self.checkDataError,
            reconnectionIterator=self.sillyIterator,
            reactor=self.clock)

        kwargs['detector'] = detector
        txpostgres.Connection.__init__(self, *args, **kwargs)

    def checkDataError(self, f):
        return f.check(psycopg2.DataError)

    def sillyIterator(self):
        return [1, 1, 1]


class TxPostgresReconnectionTestCase(_SimpleDBSetupMixin, Psycopg2TestCase):

    connectionClass = ReconnectingConnection

    def test_reconnection(self):
        """
        An error causing the connection to die starts the reconnection process.
        """
        recovery_d = defer.Deferred()
        self.conn.detector.addRecoveryHandler(
            lambda: recovery_d.callback(None))

        d = self.conn.runOperation('insert into simple values (1)')
        d.addCallback(lambda _: self.assertFalse(self.conn.detector.died))

        # try inserting text, which will cause a DataError and cause a
        # reconnection
        d.addCallback(lambda _: self.conn.runOperation(
            "insert into simple values ('sometext')"))
        self.assertFailure(d, psycopg2.DataError)
        d.addCallback(lambda _: self.assertTrue(self.conn.detector.died))

        # the next query will fail immediately
        d.addCallback(lambda _: self.conn.runQuery('select 1'))
        self.assertFailure(d, reconnection.ConnectionDead)

        # after the delay expires, a reconnection attempt will be triggered and
        # the connection will recover eventually
        d.addCallback(lambda _: self.conn.clock.advance(1))
        d.addCallback(lambda _: recovery_d)

        # now the query will no loger fail
        d.addCallback(lambda _: self.conn.runQuery('select 1'))
        return d.addCallback(self.assertEquals, [(1, )])

########NEW FILE########
__FILENAME__ = reconnection
"""
Reconnection support for txpostgres.
"""
from __future__ import absolute_import

import psycopg2

from twisted.internet import defer
from twisted.python import log

from txpostgres import retrying
from txpostgres.txpostgres import RollbackFailed


class ConnectionDead(Exception):
    """
    The connection is dead.
    """


def defaultDeathChecker(f):
    """
    Checker function suitable for use with
    :class:`.DeadConnectionDetector`.
    """
    return f.check(psycopg2.InterfaceError, psycopg2.OperationalError,
                   RollbackFailed)


def defaultReconnectionIterator():
    """
    A function returning sane defaults for a reconnection iterator, for use
    with :class:`.DeadConnectionDetector`.

    The defaults have maximum reconnection delay capped at 10 seconds and no
    limit on the number of retries.
    """
    return retrying.simpleBackoffIterator(
        initialDelay=1.0, maxDelay=10.0, factor=1.7, maxRetries=0, now=True)


class DeadConnectionDetector(object):
    """
    A class implementing reconnection strategy. When the connection is
    discovered to be dead, it will start the reconnection process.

    The object being reconnected should proxy all operations through the
    detector's :meth:`.callChecking` which will automatically fail them if the
    connection is currently dead. This is done to prevent sending requests to a
    resource that's not currently available.

    When an instance of :class:`~txpostgres.txpostgres.Connection` is passed a
    :class:`.DeadConnectionDetector` it automatically starts using it to
    provide reconnection.

    Another way of using this class is manually calling
    :meth:`.checkForDeadConnection` passing it a :tm:`Failure
    <python.failure.Failure>` instance to trigger reconnection. This is useful
    to handle initial connection errors, for example::

        conn = txpostgres.Connection(detector=DeadConnectionDetector())
        d = conn.connect('dbname=test')
        d.addErrback(conn.detector.checkForDeadConnection)

    :var reconnectable: An object to be reconnected. It should provide a
        `connect` and a `close` method.
    :vartype reconnectable: :class:`object`

    :var connectionIsDead: If the connection is currently believed to be dead.
    :vartype connectionIsDead: :class:`bool`
    """
    reconnectable = None
    connectionIsDead = None

    def __init__(self, deathChecker=None,
                 reconnectionIterator=None, reactor=None):
        """
        Create a new detector.

        :param deathChecker: A one-argument callable that will be called with a
            failure instance and should return True if reconnection should be
            triggered. If :class:`None` then :func:`.defaultDeathChecker` will
            be used.
        :type deathChecker: callable

        :param reconnectionIterator: A zero-argument callable that should
            return a iterator yielding reconnection delay periods. If
            :class:`None` then :func:`.defaultReconnectionIterator` will be
            used.
        :type reconnectionIterator: callable

        :param reactor: A Twisted reactor or :class:`None`, which means the current
            reactor.
        """
        self.deathChecker = deathChecker or defaultDeathChecker
        self.reconnectionIterator = reconnectionIterator or defaultReconnectionIterator

        if not reactor:
            from twisted.internet import reactor

        self.reactor = reactor
        self.connectionIsDead = False
        self._recoveryHandlers = set()

    def setReconnectable(self, reconnectable, *connargs, **connkw):
        """
        Register a reconnectable with the detector. Needs to be called before
        the detector will be used. The remaining arguments will be passed to
        the reconnectable's `connect` method on each reconnection.

        :param reconnectable: An object to be reconnected. It should provide a
            `connect` and a `close` method.
        :type reconnectable: :class:`object`
        """
        self.reconnectable = reconnectable
        self._connargs = connargs
        self._connkw = connkw

    def callChecking(self, method, *args, **kwargs):
        """
        Call a method if the connection is still alive.
        """
        # the connection is already dead and a reconnect is underway
        if self.connectionIsDead:
            return defer.fail(ConnectionDead())

        # call the method and check if the connection died
        d = defer.maybeDeferred(method, *args, **kwargs)
        return d.addErrback(self.checkForDeadConnection)

    def checkForDeadConnection(self, f):
        """
        Get passed a :tm:`Failure <python.failure.Failure>` instance and determine
        if it means that the connection is dead. If so, start reconnecting.
        """
        # if the error does not indicate that the connection is dead, just
        # return the failure
        if not self.deathChecker(f):
            return f

        # if we already know that the connection is dead, we just need to wait
        if self.connectionIsDead:
            return f

        # we detected that the connection died, start the reconnection process
        self.connectionIsDead = True
        self.startReconnecting(f)

        # return the original failure, we never want to swallow errors
        return f

    def startReconnecting(self, f):
        """
        Called when the connection is detected to be dead.
        """
        # set up a retrying reconnecting call and start it
        rc = retrying.RetryingCall(self.reconnect)
        rc.reactor = self.reactor

        d = rc.start(self.reconnectionIterator())
        d.addCallback(lambda _: self.connectionRecovered())
        # the reconnection should never fail (it doesn't with the default
        # iterator), but buggy recovery handlers and custom iterators migh
        # cause that, so just log the error and swallow it
        d.addErrback(log.err)

    def reconnect(self):
        """
        Called on each attempt of reconnection.
        """
        # if the connection is down even closing it might cause error, but
        # then they should be safe to ignore (probably it's already closed)
        try:
            self.reconnectable.close()
        except:
            pass
        # reuse the stored connection arguments
        return self.reconnectable.connect(
            *self._connargs, **self._connkw)

    def connectionRecovered(self):
        """
        Called when the connection has recovered.
        """
        self.connectionIsDead = False

        dl = []
        for handler in self.getRecoveryHandlers():
            d = defer.maybeDeferred(handler)
            d.addErrback(log.err)
            dl.append(d)

        return defer.gatherResults(dl)

    def addRecoveryHandler(self, handler):
        """
        Add a handler function that will get called whenever the connection is
        recovered. Any number of handlers can be added. Adding a handler that's
        already been added is ignored.

        Recovery handlers are ran in parallel. If any of them return a
        :d:`Deferred`, recovery will wait until it fires.

        There are no guarantees as to the order in which handler functions are
        called. Exceptions in handlers are logged and discarded.

        :param handler: A zero-argument callable.
        """
        self._recoveryHandlers.add(handler)

    def removeRecoveryHandler(self, handler):
        """
        Remove a previously added recovery handler. Removing a handler that's never
        been added will be ignored.

        :param handler: A callable that should no longer be called when the
            connection recovers.
        """
        self._recoveryHandlers.discard(handler)

    def getRecoveryHandlers(self):
        """
        Get the currently registered recovery handlers.

        :return: A set of callables that will get called on recovery.
        :rtype: :class:`set`
        """
        return set(self._recoveryHandlers)

########NEW FILE########
__FILENAME__ = retrying
"""
Simple implementation of a retrying call.

This code is based on a snippet send to the twisted-python mailing list:

http://twistedmatrix.com/pipermail/twisted-python/2009-November/020818.html

as well as published as txretry:

https://github.com/fluidinfo/txretry

It has been modified to allow resetting the backoff iterator and not store a
list of past failures.
"""

import random

from twisted.internet import reactor, defer, task
from twisted.python import failure


def simpleBackoffIterator(initialDelay=1.0, maxDelay=3600,
                          factor=2.7182818284590451, jitter=0.11962656472,
                          maxRetries=10, now=True):
    """
    Yields increasing timeout values between retries of a call. The default
    factor and jitter are taken from Twisted's :tm:`ReconnectingClientFactory
    <internet.protocol.ReconnectingClientFactory>`.

    :var initialDelay: Initial delay, in seconds.
    :vartype initialDelay: :class:`float`

    :var maxDelay: Maximum cap for the delay, if zero then no maximum is
        applied.
    :vartype maxDelay: :class:`float`

    :var factor: Multiplicative factor for increasing the delay.
    :vartype factor: :class:`float`

    :var jitter: Randomness factor to include when increasing the delay, to
        prevent stampeding.
    :vartype jitter: :class:`float`

    :var maxRetries: If non-zero, only yield so many values after exhausting
        the iterator.
    :vartype maxRetries: :class:`int`

    :var now: If the very first delay yielded should always be zero.
    :vartype now: :class:`bool`
    """
    retries = 0
    delay = initialDelay

    if now:
        retries += 1
        yield 0.0

    while not maxRetries or retries < maxRetries:
        retries += 1

        delay = delay * factor
        if jitter:
            delay = random.normalvariate(delay, delay * jitter)

        if maxDelay:
            delay = min(delay, maxDelay)
        yield delay


class RetryingCall(object):
    """
    Calls a function repeatedly, passing it args and keyword args. Failures are
    passed to a user-supplied failure testing function. If the failure is
    ignored, the function is called again after a delay whose duration is
    obtained from a user-supplied iterator. The start method (below) returns a
    :d:`Deferred` that fires with the eventual non-error result of calling the
    supplied function, or fires its errback if no successful result can be
    obtained before the delay backoff iterator raises :class:`StopIteration`.

    It is important to note the behaviour when the delay of any of the steps is
    zero. The function is the called synchronously, ie. control does not go
    back to the reactor between obtaining the delay from the iterator and
    calling the function if the iterator returns zero.

    The :meth:`.resetBackoff` method replaces the backoff iterator with another
    one and is useful to reset the delay if some phase of the process has
    succeeded and that makes the desirable initial delay different again.
    """
    reactor = None

    def __init__(self, f, *args, **kw):
        if self.reactor is None:
            self.reactor = reactor
        self._f = f
        self._args = args
        self._kw = kw

    def _err(self, fail):
        if self.failure is None:
            self.failure = fail
        try:
            if not self.cancelled:
                fail = self._failureTester(fail)
        except:
            self._deferred.errback()
        else:
            if isinstance(fail, failure.Failure):
                self._deferred.errback(fail)
            else:
                self._call()

    def _call(self):
        try:
            delay = self._backoffIterator.next()
        except StopIteration:
            self._deferred.errback(self.failure)
        else:
            self._callWithDelay(delay)

    def _callWithDelay(self, delay):
        # if the delay is 0, call the function synchronously
        if not delay:
            self._inProgress = defer.maybeDeferred(
                self._f, *self._args, **self._kw)
        else:
            self._inProgress = task.deferLater(
                self.reactor, delay, self._f, *self._args, **self._kw)
        self._inProgress.addCallbacks(self._deferred.callback, self._err)

    def _cancel(self, d):
        self.cancelled = True
        self._inProgress.cancel()

    def start(self, backoffIterator=None, failureTester=None):
        """
        Start the call and retry it until it succeeds and fails.

        :param backoffIterator: A zero-argument callable that should
            return a iterator yielding reconnection delay periods. If
            :class:`None` then :func:`.simpleBackoffIterator` will be
            used.
        :type backoffIterator: callable

        :param failureTester: A one-argument callable that will be called with
            a :tm:`Failure <python.failure.Failure>` instance each time the
            function being retried fails. It should return
            :class:`None` if the call should be retried or a
            :tm:`Failure <python.failure.Failure>` if the retrying process should
            be stopped. If :class:`None` is used for this parameter, retrying
            will never stop until the backoff iterator is exhausted.
        :type failureTester: callable
        """
        self.resetBackoff(backoffIterator)

        if failureTester is None:
            failureTester = lambda _: None
        self._failureTester = failureTester

        self._deferred = defer.Deferred(self._cancel)
        self._inProgress = None
        self.failure = None
        self.cancelled = False

        self._call()
        return self._deferred

    def resetBackoff(self, backoffIterator=None):
        """
        Replace the current backoff iterator with a new one.
        """
        if backoffIterator is None:
            backoffIterator = simpleBackoffIterator()
        self._backoffIterator = iter(backoffIterator)

########NEW FILE########
__FILENAME__ = txpostgres
# -*- test-case-name: test.test_txpostgres -*-
# -*- coding: utf-8 -*-
# Copyright (c) 2010-2012, Jan Urbanski.
# See LICENSE for details.
"""
txpostgres is a library for accessing a PostgreSQL_ database from the Twisted_
framework. It builds upon asynchronous features of the Psycopg_ database
library, which in turn exposes the asynchronous features of libpq_, the
PostgreSQL C library.

It requires a version of Psycopg that includes support for `asynchronous
connections`_ (versions 2.2.0 and later) and a reasonably recent Twisted (it
has been tested with Twisted 10.2 onward). Alternatively, psycopg2-ctypes_ can
be used in lieu of Psycopg.

txpostgres tries to present an interface that will be familiar to users of both
Twisted and Psycopg. It features a :class:`~txpostgres.txpostgres.Cursor` wrapper class
that mimics the interface of a Psycopg :psycopg:`cursor <cursor.html#cursor>`
but returns :d:`Deferred` objects. It also provides a
:class:`~txpostgres.txpostgres.Connection` class that is meant to be a drop-in replacement
for Twisted's :tm:`adbapi.Connection <enterprise.adbapi.Connection>` with some
small differences regarding connection establishing.

The main advantage of txpostgres over Twisted's built-in database support is
non-blocking connection building and complete lack of thread usage.

The library is distributed under the MIT License, see the LICENSE file for
details. You can contact the author, Jan Urbański, at wulczer@wulczer.org. Feel
free to download the source_, file bugs in the `issue tracker`_ and consult the
documentation_

.. _PostgreSQL: http://www.postgresql.org/
.. _Twisted: http://twistedmatrix.com/
.. _Psycopg: http://initd.org/psycopg/
.. _Python: http://www.python.org/
.. _libpq: http://www.postgresql.org/docs/current/static/libpq-async.html
.. _`asynchronous connections`: http://initd.org/psycopg/docs/advanced.html#async-support
.. _psycopg2-ctypes: http://pypi.python.org/pypi/psycopg2ct
.. _source: https://github.com/wulczer/txpostgres
.. _issue tracker: https://github.com/wulczer/txpostgres/issues
.. _documentation: http://txpostgres.readthedocs.org/
"""

try:
    import psycopg2
except ImportError:
    # try psycopg2-ctypes
    try:
        import psycopg2ct as psycopg2
    except ImportError:
        raise ImportError('no module named psycopg2 or psycopg2ct')

from zope.interface import implements

from twisted.internet import interfaces, main, defer, task
from twisted.python import failure, log

try:
    psycopg2.extensions.POLL_OK
except AttributeError:
    import warnings
    warnings.warn(RuntimeWarning(
            "psycopg2 does not have async support. "
            "You need at least version 2.2.0 of psycopg2 "
            "to use txpostgres."))


__all__ = ['Connection', 'Cursor', 'ConnectionPool', '_PollingMixin',
           'AlreadyConnected', 'RollbackFailed',
           'UnexpectedPollResult', 'AlreadyPolling']


class UnexpectedPollResult(Exception):
    """
    Polling returned an unexpected result.
    """


class AlreadyPolling(Exception):
    """
    The previous poll cycle has not been finished yet.

    This probably indicates an issue in txpostgres, rather than in user code.
    """


class _CancelInProgress(Exception):
    """
    A query cancellation is in progress.
    """


class _PollingMixin(object):
    """
    An object that wraps something pollable. It can take care of waiting for
    the wrapped pollable to reach the OK state and adapts the pollable's
    interface to :tm:`interfaces.IReadWriteDescriptor
    <internet.interfaces.IReadWriteDescriptor>`. It will forward all attribute
    access that is has not been wrapped to the underlying pollable. Useful as a
    mixin for classes that wrap a psycopg2 pollable object.

    :var reactor: The reactor that the class will use to wait for the wrapped
        pollable to reach the OK state.
    :vartype reactor: an :tm:`IReactorFDSet
        <internet.interfaces.IReactorFDSet>` provider

    :var prefix: Prefix used during log formatting to indicate context.
    :vartype prefix: :class:`str`
    """

    implements(interfaces.IReadWriteDescriptor)

    reactor = None
    prefix = "pollable"
    _pollingD = None

    def pollable(self):
        """
        Return the pollable object. Subclasses should override this.

        :return: A psycopg2 pollable.
        """
        raise NotImplementedError()

    def poll(self):
        """
        Start polling the wrapped pollable.

        :return: A :d:`Deferred` that will fire with an instance of this class
            when the pollable reaches the OK state.
        """
        # this should never be called while the previous Deferred is still
        # active, as it would clobber its reference
        if self._pollingD:
            return defer.fail(AlreadyPolling())

        ret = self._pollingD = defer.Deferred(self._cancel)
        # transform a psycopg2 QueryCanceledError into CancelledError
        self._pollingD.addErrback(self._handleCancellation)

        self.continuePolling()

        return ret

    def continuePolling(self, swallowErrors=False):
        """
        Move forward in the poll cycle. This will call psycopg2's
        :psycopg:`poll() <connection.html#connection.poll>` on the wrapped
        pollable and either wait for more I/O or callback or errback the
        :d:`Deferred` returned earlier if the polling cycle has been completed.

        :param swallowErrors: Should errors with no one to report them to be
            ignored.
        :type swallowErrors: bool

        :raise: :exc:`~txpostgres.txpostgres.UnexpectedPollResult` when
            :meth:`poll` returns a result from outside of the
            :psycopg:`expected list <extensions.html#poll-constants>`.
        """
        # This method often gets called from the reactor's doRead/doWrite
        # handlers. Don't callback or errback the polling Deferred here, as
        # arbitrary user code can be run by that and we don't want to deal with
        # reentrancy issues if this user code tries running queries. The
        # polling Deferred might also be simply not present, if we got called
        # from a doRead after receiving a NOTIFY event.

        try:
            state = self.pollable().poll()
        except:
            if self._pollingD:
                d, self._pollingD = self._pollingD, None
                self.reactor.callLater(0, d.errback, failure.Failure())
            elif not swallowErrors:
                # no one to report the error to
                raise
        else:
            if state == psycopg2.extensions.POLL_OK:
                if self._pollingD:
                    d, self._pollingD = self._pollingD, None
                    self.reactor.callLater(0, d.callback, self)
            elif state == psycopg2.extensions.POLL_WRITE:
                self.reactor.addWriter(self)
            elif state == psycopg2.extensions.POLL_READ:
                self.reactor.addReader(self)
            else:
                if self._pollingD:
                    d, self._pollingD = self._pollingD, None
                    self.reactor.callLater(0, d.errback, UnexpectedPollResult())
                elif not swallowErrors:
                    # no one to report the error to
                    raise UnexpectedPollResult()

    def doRead(self):
        self.reactor.removeReader(self)
        if not self.pollable().closed:
            self.continuePolling()

    def doWrite(self):
        self.reactor.removeWriter(self)
        if not self.pollable().closed:
            self.continuePolling()

    def logPrefix(self):
        return self.prefix

    def fileno(self):
        # this should never get called after the pollable has been
        # disconnected, but Twisted versions affected by bug #4539 might cause
        # it to happen, in which case we should return -1
        if self.pollable().closed:
            return -1

        return self.pollable().fileno()

    def connectionLost(self, reason):
        # Do not errback self._pollingD here if the connection is still open!
        # We need to keep on polling until it reports an error, which will
        # errback self._pollingD with the correct failure. If we errback here,
        # we won't finish the polling cycle, which would leave psycopg2 in a
        # state where it thinks there's still an async query underway.
        #
        # If the connection got lost right after the first poll(), the Deferred
        # returned from it will never fire, leaving the caller hanging forever,
        # unless we push the connection state forward here. OTOH, if the
        # connection is already closed, there's no pollable to poll, so if
        # self._pollingD is still present, the only option is to errback it to
        # prevent its waiters from hanging (you can't poll() a closed psycopg2
        # connection)
        if not self.pollable().closed:
            # we're pushing the polling cycle to report pending failures, so if
            # there's no one to report them to, swallow them
            self.continuePolling(swallowErrors=True)
        elif self._pollingD:
            d, self._pollingD = self._pollingD, None
            d.errback(reason)

    def _cancel(self, d):
        try:
            self.pollable().cancel()
        except AttributeError:
            # the pollable has no cancellation support, ignore
            pass
        # prevent Twisted from errbacking the deferred being cancelled, because
        # the PostgreSQL protocol requires finishing the entire polling process
        # before reusing the connection
        raise _CancelInProgress()

    def _handleCancellation(self, f):
        f.trap(psycopg2.extensions.QueryCanceledError)
        return failure.Failure(defer.CancelledError())

    # Hack required to work with the Gtk2 reactor in Twisted <=11.0, which
    # tries to access the "disconnected" property on the IReadWriteDescriptor
    # it polls. To avoid attribute errors, forward that access to the "closed"
    # property of the underlying connection.
    def disconnected(self):
        return self.pollable().closed
    disconnected = property(disconnected)

    # forward all other access to the underlying connection
    def __getattr__(self, name):
        return getattr(self.pollable(), name)


class Cursor(_PollingMixin):
    """
    A wrapper for a psycopg2 asynchronous cursor.

    The wrapper will forward almost everything to the wrapped cursor, so the
    usual DB-API interface can be used, but it will return :d:`Deferred`
    objects that will fire with the DB-API results.

    Remember that the PostgreSQL protocol does not support concurrent
    asynchronous queries execution, so you need to take care not to execute a
    query while another is still being processed.

    In most cases you should just use the
    :class:`~txpostgres.txpostgres.Connection` methods that will handle the
    locking necessary to prevent concurrent query execution.
    """

    def __init__(self, cursor, connection):
        self.reactor = connection.reactor
        self.prefix = "cursor"

        self._connection = connection
        self._cursor = cursor

    def pollable(self):
        return self._connection.pollable()

    def execute(self, query, params=None):
        """
        A regular DB-API execute, but returns a :d:`Deferred`.

        The caller must be careful not to call this method twice on cursors
        from the same connection without waiting for the previous execution to
        complete.

        :return: A :d:`Deferred` that will fire with the results of the
            DB-API execute.
        """
        return self._doit('execute', query, params)

    def callproc(self, procname, params=None):
        """
        A regular DB-API callproc, but returns a :d:`Deferred`.

        The caller must be careful not to call this method twice on cursors
        from the same connection without waiting for the previous execution to
        complete.

        :return: A :d:`Deferred` that will fire with the results of the
            DB-API callproc.
        """
        return self._doit('callproc', procname, params)

    def _doit(self, name, *args, **kwargs):
        try:
            getattr(self._cursor, name)(*args, **kwargs)
        except:
            return defer.fail()

        # tell the connection that a cursor is starting its poll cycle
        self._connection.cursorRunning(self)

        def finishedAndPassthrough(ret):
            # tell the connection that the poll cycle has finished
            self._connection.cursorFinished(self)
            return ret

        d = self.poll()
        return d.addBoth(finishedAndPassthrough)

    def close(self):
        """
        Close the cursor.

        Once closed, the cursor cannot be used again.

        :returns: :class:`None`
        """
        return self._cursor.close()

    def __getattr__(self, name):
        # the pollable is the connection, but the wrapped object is the cursor
        return getattr(self._cursor, name)


class AlreadyConnected(Exception):
    """
    The database connection is already open.
    """


class RollbackFailed(Exception):
    """
    Rolling back the transaction failed, the connection might be in an unusable
    state.

    :var connection: The connection that failed to roll back its transaction.
    :vartype connection: :class:`~txpostgres.txpostgres.Connection`

    :var originalFailure: The failure that caused the connection to try to
        roll back the transaction.
    :vartype originalFailure: a Twisted :tm:`Failure <python.failure.Failure>`
    """

    def __init__(self, connection, originalFailure):
        self.connection = connection
        self.originalFailure = originalFailure

    def __str__(self):
        return "<RollbackFailed, original error: %s>" % self.originalFailure


class Connection(_PollingMixin):
    """
    A wrapper for a psycopg2 asynchronous connection.

    The wrapper forwards almost everything to the wrapped connection, but
    provides additional methods for compatibility with :tm:`adbapi.Connection
    <enterprise.adbapi.Connection>`.

    :param reactor: A Twisted reactor or :class:`None`, which means the current
        reactor

    :param cooperator: A Twisted :tm:`Cooperator <internet.task.Cooperator>` to
        process :pg:`NOTIFY <notify>` events or :class:`None`, which means
        using :tm:`task.cooperate <internet.task.cooperate>`

    :var connectionFactory: The factory used to produce connections, defaults
        to :psycopg:`psycopg2.connect <module.html#psycopg2.connect>`
    :vartype connectionFactory: any callable

    :var cursorFactory: The factory used to produce cursors, defaults to
        :class:`~txpostgres.txpostgres.Cursor`
    :vartype cursorFactory: a callable accepting two positional arguments, a
        :psycopg:`psycopg2.cursor <cursor.html#cursor>` and a
        :class:`~txpostgres.txpostgres.Connection`
    """

    connectionFactory = staticmethod(psycopg2.connect)
    cursorFactory = Cursor

    def __init__(self, reactor=None, cooperator=None, detector=None):
        if not reactor:
            from twisted.internet import reactor
        if not cooperator:
            # the task module provides cooperate()
            cooperator = task

        self.reactor = reactor
        self.cooperator = cooperator
        self.detector = detector
        self.prefix = "connection"

        # this lock will be used to prevent concurrent query execution
        self.lock = defer.DeferredLock()
        self._connection = None
        # a set of cursors that should be notified about a disconnection
        self._cursors = set()
        # observers for NOTIFY events
        self._notifyObservers = set()

    def pollable(self):
        return self._connection

    def connect(self, *args, **kwargs):
        """
        Connect to the database.

        Any arguments will be passed to :attr:`connectionFactory`. Use them to
        pass database names, usernames, passwords, etc.

        :return: A :d:`Deferred` that will fire when the connection is open.

        :raise: :exc:`~txpostgres.txpostgres.AlreadyConnected` when the
            connection has already been opened.
        """
        if self.detector:
            self.detector.setReconnectable(self, *args, **kwargs)

        if self._connection and not self._connection.closed:
            return defer.fail(AlreadyConnected())

        kwargs['async'] = True
        try:
            self._connection = self.connectionFactory(*args, **kwargs)
        except:
            return defer.fail()

        def startReadingAndPassthrough(ret):
            self.reactor.addReader(self)
            return ret

        # The connection is always a reader in the reactor, to receive NOTIFY
        # events immediately when they're available.
        d = self.poll()
        return d.addCallback(startReadingAndPassthrough)

    def close(self):
        """
        Close the connection and disconnect from the database.

        :return: :class:`None`
        """
        # We'll be closing the underlying socket so stop watching it.
        self.reactor.removeReader(self)
        self.reactor.removeWriter(self)

        # make it safe to call Connection.close() multiple times, psycopg2
        # treats this as an error but we don't
        if not self._connection.closed:
            self._connection.close()

        # The above closed the connection socket from C code. Normally we would
        # get connectionLost called on all readers and writers of that socket,
        # but not if we're using the epoll reactor. According to the epoll(2)
        # man page, closing a file descriptor causes it to be removed from all
        # epoll sets automatically. In that case, the reactor might not have
        # the chance to notice that the connection has been closed. To cover
        # that, call connectionLost explicitly on the Connection and all
        # outstanding Cursors. It's OK if connectionLost ends up being called
        # twice, as the second call will not have any effects.

        for cursor in set(self._cursors):
            cursor.connectionLost(failure.Failure(main.CONNECTION_DONE))

        self.connectionLost(failure.Failure(main.CONNECTION_DONE))

    def cursor(self):
        """
        Create an asynchronous cursor using :attr:`cursorFactory`.
        """
        return self.cursorFactory(self._connection.cursor(), self)

    def runQuery(self, *args, **kwargs):
        """
        Execute an SQL query and return the result.

        An asynchronous cursor will be created and its
        :meth:`~txpostgres.txpostgres.Cursor.execute` method will be invoked
        with the provided arguments. After the query completes the results will
        be fetched and the returned :d:`Deferred` will fire with the result.

        The connection is always in autocommit mode, so the query will be run
        in a one-off transaction. In case of errors a :tm:`Failure
        <python.failure.Failure>` will be returned.

        It is safe to call this method multiple times without waiting for the
        first query to complete.

        :return: A :d:`Deferred` that will fire with the return value of the
            cursor's :meth:`fetchall` method.
        """
        return self._doit(self._runQuery, *args, **kwargs)

    def _runQuery(self, *args, **kwargs):
        c = self.cursor()
        d = c.execute(*args, **kwargs)
        d.addCallback(lambda c: c.fetchall())
        return d.addCallback(lambda ret: (c.close(), ret)[1])

    def runOperation(self, *args, **kwargs):
        """
        Execute an SQL query and discard the result.

        Identical to :meth:`~txpostgres.txpostgres.Connection.runQuery`, but
        the result won't be fetched and instead :class:`None` will be
        returned. It is intended for statements that do not normally return
        values, like INSERT or DELETE.

        It is safe to call this method multiple times without waiting for the
        first query to complete.

        :return: A :d:`Deferred` that will fire :class:`None`.
        """
        return self._doit(self._runOperation, *args, **kwargs)

    def _runOperation(self, *args, **kwargs):
        c = self.cursor()
        d = c.execute(*args, **kwargs)
        d.addCallback(lambda _: None)
        return d.addCallback(lambda ret: (c.close(), ret)[1])

    def runInteraction(self, interaction, *args, **kwargs):
        """
        Run commands in a transaction and return the result.

        :obj:`interaction` should be a callable that will be passed a
        :class:`~txpostgres.txpostgres.Cursor` object. Before calling
        :obj:`interaction` a new transaction will be started, so the callable
        can assume to be running all its commands in a transaction. If
        :obj:`interaction` returns a :d:`Deferred` processing will wait for it
        to fire before proceeding.

        After :obj:`interaction` finishes work the transaction will be
        automatically committed. If it raises an exception or returns a
        :tm:`Failure <python.failure.Failure>` the connection will be rolled
        back instead.

        If committing the transaction fails it will be rolled back instead and
        the failure obtained trying to commit will be returned.

        If rolling back the transaction fails the failure obtained from the
        rollback attempt will be logged and a
        :exc:`~txpostgres.txpostgres.RollbackFailed` failure will be
        returned. The returned failure will contain references to the original
        failure that caused the transaction to be rolled back and to the
        :class:`~txpostgres.txpostgres.Connection` in which that happend, so
        the user can take a decision whether she still wants to be using it or
        just close it, because an open transaction might have been left open in
        the database.

        It is safe to call this method multiple times without waiting for the
        first query to complete.

        :param interaction: A callable whose first argument is a
            :class:`~txpostgres.txpostgres.Cursor`.
        :type interaction: any callable

        :return: A :d:`Deferred` that will fire with the return value of
            :obj:`interaction`.
        """
        return self._doit(self._runInteraction, interaction, *args, **kwargs)

    def _runInteraction(self, interaction, *args, **kwargs):
        c = self.cursor()
        d = c.execute("begin")
        d.addCallback(interaction, *args, **kwargs)

        def commitAndPassthrough(ret, cursor):
            e = cursor.execute("commit")
            return e.addCallback(lambda _: ret)

        def rollbackAndPassthrough(f, cursor):
            # maybeDeferred in case cursor.execute raises a synchronous
            # exception
            e = defer.maybeDeferred(cursor.execute, "rollback")

            def justPanic(rf):
                log.err(rf)
                return defer.fail(RollbackFailed(self, f))

            # if rollback failed panic
            e.addErrback(justPanic)
            # reraise the original failure afterwards
            return e.addCallback(lambda _: f)

        d.addCallback(commitAndPassthrough, c)
        d.addErrback(rollbackAndPassthrough, c)
        d.addCallback(lambda ret: (c.close(), ret)[1])

        return d

    def _doit(self, method, *args, **kwargs):
        if self.detector:
            args = (method, ) + args
            method = self.detector.callChecking

        return self.lock.run(method, *args, **kwargs)

    def cancel(self, d):
        """
        Cancel the current operation. The cancellation does not happen
        immediately, because the PostgreSQL protocol requires that the
        application waits for confirmation after the query has been cancelled.
        Be carefil when cancelling an interaction, because if the interaction
        includes sending multiple queries to the database server, you can't
        really be sure which one are you cancelling.

        :param d: a :d:`Deferred` returned by one of
            :class:`~txpostgres.txpostgres.Connection` methods.
        """
        try:
            d.cancel()
        except _CancelInProgress:
            pass

    def cursorRunning(self, cursor):
        """
        Called automatically when a :class:`~txpostgres.txpostgres.Cursor` created
        by this :class:`~txpostgres.txpostgres.Connection` starts polling after
        executing a query. User code should never have to call this method.
        """
        # The cursor will now proceed to poll the psycopg2 connection, so stop
        # polling it ourselves until it's done. Failure to do so would result
        # in the connection "stealing" the POLL_OK result that appears after
        # the query is completed and the Deferred returned from the cursor's
        # poll() will never fire.
        self.reactor.removeReader(self)
        self._cursors.add(cursor)

    def cursorFinished(self, cursor):
        """
        Called automatically when a :class:`~txpostgres.txpostgres.Cursor` created
        by this :class:`~txpostgres.txpostgres.Connection` is done with polling
        after executing a query. User code should never have to call this
        method.
        """
        self._cursors.remove(cursor)
        # The cursor is done polling, resume watching the connection for NOTIFY
        # events. Be careful to check the connection state, because it might
        # have been closed while the cursor was polling and adding ourselves as
        # a reader to a closed connection would be an error.
        if not self._connection.closed:
            self.reactor.addReader(self)
            # While cursor was running, some notifies could have been
            # delivered, so check for them.
            self.checkForNotifies()

    def doRead(self):
        # call superclass to handle the pending read event on the socket
        _PollingMixin.doRead(self)

        # check for NOTIFY events
        self.checkForNotifies()

        # continue watching for NOTIFY events, but be careful to check the
        # connection state in case one of the notify handler function caused a
        # disconnection
        if not self._connection.closed:
            self.reactor.addReader(self)

    def connectionLost(self, reason):
        _PollingMixin.connectionLost(self, reason)

        if self.detector:
            self.detector.checkForDeadConnection(reason)

    def checkForNotifies(self):
        """
        Check if :pg:`NOTIFY <notify>` events have been received and if so,
        dispatch them to the registered observers, using the :tm:`Cooperator
        <internet.task.Cooperator>` provided in the constructor. This is done
        automatically, user code should never need to call this method.
        """
        # avoid creating a CooperativeTask in the common case of no notifies
        if self._connection.notifies:
            self.cooperator.cooperate(self._checkForNotifies())

    def _checkForNotifies(self):
        while self._connection.notifies:
            notify = self._connection.notifies.pop()
            # don't iterate over self._notifyObservers directly because the
            # observer function might call removeNotifyObserver, thus modifying
            # the set while it's being iterated
            for observer in self.getNotifyObservers():
                # this method is run from inside the global Cooperator, so
                # there's no one to report errors to -- just log them; use
                # maybeDeferred in case the observer returns a failing Deferred
                # that would stop the cooperator from processing remaining
                # observers
                yield defer.maybeDeferred(observer, notify).addErrback(log.err)

    def addNotifyObserver(self, observer):
        """
        Add an observer function that will get called whenever a :pg:`NOTIFY
        <notify>` event is delivered to this connection. Any number of
        observers can be added to a connection. Adding an observer that's
        already been added is ignored.

        Observer functions are processed using the :tm:`Cooperator
        <internet.task.Cooperator>` provided in the constructor to avoid
        blocking the reactor thread when processing large numbers of events. If
        an observer returns a :d:`Deferred`, processing waits until it fires or
        errbacks.

        There are no guarantees as to the order in which observer functions are
        called when :pg:`NOTIFY <notify>` events are delivered. Exceptions in
        observers are logged and discarded.

        :param observer: A callable whose first argument is a
            :psycopg:`psycopg2.extensions.Notify
            <extensions.html#psycopg2.extensions.Notify>`.
        :type observer: any callable
        """
        self._notifyObservers.add(observer)

    def removeNotifyObserver(self, observer):
        """
        Remove a previously added observer function. Removing an observer
        that's never been added will be ignored.

        :param observer: A callable that should no longer be called on
            :pg:`NOTIFY <notify>` events.
        :type observer: any callable
        """
        self._notifyObservers.discard(observer)

    def getNotifyObservers(self):
        """
        Get the currently registered notify observers.

        :return: A set of callables that will get called on :pg:`NOTIFY
            <notify>` events.
        :rtype: :class:`set`
        """
        return set(self._notifyObservers)


class ConnectionPool(object):
    """
    A poor man's pool of :class:`~txpostgres.txpostgres.Connection` instances.

    :var min: The amount of connections that will be open when
        :meth:`~ConnectionPool.start` is called. The pool never opens or closes
        connections on its own after starting. Defaults to 3.
    :vartype min: int

    :var connectionFactory: The factory used to produce connections, defaults
        to :class:`~txpostgres.txpostgres.Connection`.
    :vartype connectionFactory: any callable

    :var reactor: The reactor passed to :attr:`.connectionFactory`.
    :var cooperator: The cooperator passed to :attr:`.connectionFactory`.
    """

    min = 3
    connectionFactory = Connection
    reactor = None
    cooperator = None

    def __init__(self, _ignored, *connargs, **connkw):
        """
        Create a new connection pool.

        Any positional or keyword arguments other than the first one and a
        :obj:`min` keyword argument are passed to :attr:`connectionFactory`
        when connecting. Use these arguments to pass database names, usernames,
        passwords, etc.

        :param _ignored: Ignored, for :tm:`adbapi.ConnectionPool
            <enterprise.adbapi.ConnectionPool>` compatibility.
        :type _ignored: any object
        """
        if not self.reactor:
            from twisted.internet import reactor
            self.reactor = reactor
        # for adbapi compatibility, min can be passed in kwargs
        if 'min' in connkw:
            self.min = connkw.pop('min')
        self.connargs = connargs
        self.connkw = connkw
        self.connections = set(
            [self.connectionFactory(self.reactor, self.cooperator)
             for _ in range(self.min)])

        # to avoid checking out more connections than there are pooled in total
        self._semaphore = defer.DeferredSemaphore(self.min)

    def start(self):
        """
        Start the connection pool.

        This will create as many connections as the pool's :attr:`min` variable
        says.

        :return: A :d:`Deferred` that fires when all connection have succeeded.
        """
        # use DeferredList here, as gatherResults only got a consumeErrors
        # keyword argument in Twisted 11.1.0
        d = defer.DeferredList([c.connect(*self.connargs, **self.connkw)
                                 for c in self.connections],
                               fireOnOneErrback=True, consumeErrors=True)
        return d.addCallback(lambda _: self)

    def close(self):
        """
        Stop the pool.

        Disconnects all connections.

        :returns: :class:`None`
        """
        for c in self.connections:
            c.close()

    def remove(self, connection):
        """
        Remove a connection from the pool.

        Provided to be able to remove broken connections from the pool. The
        caller should make sure the removed connection does not have queries
        pending.

        :param connection: The connection to be removed.
        :type connection: an object produced by the pool's
            :attr:`connectionFactory`
        """
        if not self.connections:
            raise ValueError("Connection still in use")
        self.connections.remove(connection)
        self._semaphore.limit -= 1
        self._semaphore.acquire()  # bleargh...

    def add(self, connection):
        """
        Add a connection to the pool.

        Provided to be able to extend the pool with new connections.

        :param connection: The connection to be added.
        :type connection: an object compatible with those produced by the pool's
            :attr:`connectionFactory`
        """
        self.connections.add(connection)
        self._semaphore.limit += 1
        self._semaphore.release()  # uuuugh...

    def _putBackAndPassthrough(self, result, connection):
        self.connections.add(connection)
        return result

    def runQuery(self, *args, **kwargs):
        """
        Execute an SQL query using a pooled connection and return the result.

        One of the pooled connections will be chosen, its
        :meth:`~txpostgres.txpostgres.Connection.runQuery` method will be
        called and the resulting :d:`Deferred` will be returned.

        :return: A :d:`Deferred` obtained by a pooled connection's
            :meth:`~txpostgres.txpostgres.Connection.runQuery`
        """
        return self._semaphore.run(self._runQuery, *args, **kwargs)

    def _runQuery(self, *args, **kwargs):
        c = self.connections.pop()
        d = c.runQuery(*args, **kwargs)
        return d.addBoth(self._putBackAndPassthrough, c)

    def runOperation(self, *args, **kwargs):
        """
        Execute an SQL query using a pooled connection and discard the result.

        One of the pooled connections will be chosen, its
        :meth:`~txpostgres.txpostgres.Connection.runOperation` method will be
        called and the resulting :d:`Deferred` will be returned.

        :return: A :d:`Deferred` obtained by a pooled connection's
            :meth:`~txpostgres.txpostgres.Connection.runOperation`
        """
        return self._semaphore.run(self._runOperation, *args, **kwargs)

    def _runOperation(self, *args, **kwargs):
        c = self.connections.pop()
        d = c.runOperation(*args, **kwargs)
        return d.addBoth(self._putBackAndPassthrough, c)

    def runInteraction(self, interaction, *args, **kwargs):
        """
        Run commands in a transaction using a pooled connection and return the
        result.

        One of the pooled connections will be chosen, its
        :meth:`~txpostgres.txpostgres.Connection.runInteraction` method will be
        called and the resulting :d:`Deferred` will be returned.

        :param interaction: A callable that will be passed to
            :meth:`Connection.runInteraction
            <txpostgres.Connection.runInteraction>`
        :type interaction: any callable

        :return: A :d:`Deferred` obtained by a pooled connection's
            :meth:`Connection.runInteraction
            <txpostgres.Connection.runInteraction>`
        """
        return self._semaphore.run(
            self._runInteraction, interaction, *args, **kwargs)

    def _runInteraction(self, interaction, *args, **kwargs):
        c = self.connections.pop()
        d = c.runInteraction(interaction, *args, **kwargs)
        return d.addBoth(self._putBackAndPassthrough, c)

########NEW FILE########
